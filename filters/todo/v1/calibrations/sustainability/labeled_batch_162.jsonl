{"id":"science_arxiv_cs_e096b1ef03bc","title":"Improving Text-to-Image Generation with Input","content":"arXiv:2510.12041v1 Announce Type: new Abstract: Recent advances in text-to-image (T2I) generation have achieved impressive results, yet existing models often struggle with simple or underspecified prompts, leading to suboptimal image-text alignment, aesthetics, and quality. We propose a prompt rewriting framework that leverages large language models (LLMs) to refine user inputs before feeding them into T2I backbones. Our approach introduces a carefully designed reward system and an iterative direct preference optimization (DPO) training pipeline, enabling the rewriter to enhance prompts without requiring supervised fine-tuning data. We evaluate our method across diverse T2I models and benchmarks. Results show that our prompt rewriter consistently improves image-text alignment, visual quality, and aesthetics, outperforming strong baselines. Furthermore, we demonstrate strong transferability by showing that a prompt rewriter trained on one T2I backbone generalizes effectively to others without needing to be retrained. We also systematically study scalability, evaluating how performance gains scale with the capacity of the large LLM used as the rewriter. These findings highlight that prompt rewriting is an effective, scalable, and practical model-agnostic strategy for improving T2I systems. We plan to release the code and trained prompt rewriters soon.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12041","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.270043","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Ruibo Chen, Jiacheng Pan, Heng Huang, Zhenheng Yang","raw_content_length":1372,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["DPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1371,"language_detected":"en","key_concepts":{"key_phrases":["Image","Input","arXiv251012041v1 Announce Type","new Abstract","Recent advances","image","T2I","impressive results","existing models","simple or underspecified prompts"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Image":2.0,"Input":2.0,"arXiv251012041v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"image":1.0,"T2I":1.0,"impressive results":1.0,"existing models":1.0,"simple or underspecified prompts":1.0}},"age_hours":2.7384842341666666,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8923,"joy":0.0139,"surprise":0.0568,"sadness":0.0063,"fear":0.0103,"anger":0.0122,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving text-to-image generation using LLMs. While it demonstrates improved image-text alignment and visual quality, it's still in the research phase with no deployed units or real-world data on energy consumption or emissions reduction. The impact on sustainability is indirect and theoretical, potentially reducing energy consumption in image generation if it leads to more efficient models.","key_impact_metrics":["Improved image-text alignment","Improved visual quality"],"technology_tags":["Text-to-image generation","Large language models","Prompt rewriting"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:39:22.473152Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f519c90b648e","title":"Hierarchical Alignment: Surgical Fine","content":"arXiv:2510.12044v1 Announce Type: new Abstract: Existing alignment techniques for Large Language Models (LLMs), such as Direct Preference Optimization (DPO), typically treat the model as a monolithic entity, applying uniform optimization pressure across all layers. This approach overlooks the functional specialization within the Transformer architecture, where different layers are known to handle distinct tasks from syntax to abstract reasoning. In this paper, we challenge this one-size-fits-all paradigm by introducing Hierarchical Alignment, a novel method that applies targeted DPO to distinct functional blocks of a model's layers: local (syntax), intermediate (logic), and global (factuality). Through a series of controlled experiments on state-of-the-art models like Llama-3.1-8B and Qwen1.5-7B using LoRA for surgical fine-tuning, our results, evaluated by a powerful LLM-as-Judge, demonstrate significant and predictable improvements. Specifically, aligning the local layers (Local-Align) enhances grammatical fluency. More importantly, aligning the global layers (Global-Align) not only improves factual consistency as hypothesized but also proves to be the most effective strategy for enhancing logical coherence, outperforming all baselines. Critically, all hierarchical strategies successfully avoid the \"alignment tax\" observed in standard DPO, where gains in fluency come at the cost of degraded logical reasoning. These findings establish a more resource-efficient, controllable, and interpretable path for model alignment, highlighting the immense potential of shifting from monolithic optimization to structure-aware surgical fine-tuning to build more advanced and reliable LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12044","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.270455","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Yukun Zhang, Qi Dong","raw_content_length":1703,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Hierarchical Alignment","LoRA","Direct Preference Optimization","DPO","Large Language Models","LLM","Transformer"],"persons":[],"locations":[],"monetary":[]},"char_count":1702,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical Alignment","Surgical Fine","arXiv251012044v1 Announce Type","new Abstract","Existing alignment techniques","Large Language Models","LLMs","Direct Preference Optimization","DPO","the model"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical Alignment":2.0,"Surgical Fine":2.0,"arXiv251012044v1 Announce Type":1.0,"new Abstract":1.0,"Existing alignment techniques":1.0,"Large Language Models":1.0,"LLMs":1.0,"Direct Preference Optimization":1.0,"DPO":1.0,"the model":1.0}},"age_hours":2.7384993591666666,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7579,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8871,"joy":0.0076,"surprise":0.0329,"sadness":0.0126,"fear":0.0063,"anger":0.0229,"disgust":0.0306},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for aligning LLMs, showing improvements in grammatical fluency and factual consistency. The concrete action is the development and testing of the Hierarchical Alignment method using LoRA fine-tuning. The evidence supporting the claims comes from controlled experiments on state-of-the-art models, evaluated by an LLM-as-Judge, but it is still in the applied research stage with no real-world deployment yet.","key_impact_metrics":["Improvements in grammatical fluency","Improvements in factual consistency"],"technology_tags":["Large Language Models","AI Alignment","Fine-tuning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:39:30.300547Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_936d8d6d1a2b","title":"Over","content":"arXiv:2510.12045v1 Announce Type: new Abstract: An important function of collaborative network intrusion detection is to analyze the network logs of the collaborators for joint IP addresses. However, sharing IP addresses in plain is sensitive and may be even subject to privacy legislation as it is personally identifiable information. In this paper, we present the privacy-preserving collection of IP addresses. We propose a single collector, over-threshold private set intersection protocol. In this protocol $N$ participants identify the IP addresses that appear in at least $t$ participant's sets without revealing any information about other IP addresses. Using a novel hashing scheme, we reduce the computational complexity of the previous state-of-the-art solution from $O(M(N \\log{M}/t)^{2t})$ to $O(t^2M\\binom{N}{t})$, where $M$ denotes the dataset size. This reduction makes it practically feasible to apply our protocol to real network logs. We test our protocol using joint networks logs of multiple institutions. Additionally, we present two deployment options: a collusion-safe deployment, which provides stronger security guarantees at the cost of increased communication overhead, and a non-interactive deployment, which assumes a non-colluding collector but offers significantly lower communication costs and applicable to many use cases of collaborative network intrusion detection similar to ours.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12045","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.270877","language":"en","tags":["preprints","computer-science","csni","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Onur Eren Arpaci (University of Waterloo), Raouf Boutaba (University of Waterloo), Florian Kerschbaum (University of Waterloo)","raw_content_length":1417,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["O(M(N \\log{M}/t)^{2t})$"],"locations":[],"monetary":["at least $","O(t^2M\\binom{N}{t})$"]},"char_count":1416,"language_detected":"en","key_concepts":{"key_phrases":["IP addresses","arXiv251012045v1 Announce Type","new Abstract","An important function","collaborative network intrusion detection","the network logs","the collaborators","joint IP addresses","privacy legislation","personally identifiable information"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IP addresses":2.0,"arXiv251012045v1 Announce Type":1.0,"new Abstract":1.0,"An important function":1.0,"collaborative network intrusion detection":1.0,"the network logs":1.0,"the collaborators":1.0,"joint IP addresses":1.0,"privacy legislation":1.0,"personally identifiable information":1.0}},"age_hours":2.7385144455555555,"is_recent":true,"quality_score":0.7,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9148,"joy":0.0087,"surprise":0.0163,"sadness":0.0071,"fear":0.0224,"anger":0.0193,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a privacy-preserving protocol for collaborative network intrusion detection, specifically focusing on the collection of IP addresses. While it improves computational complexity, it's in the early stages of development and doesn't directly address climate change or other sustainability issues, though it could indirectly contribute to more secure and efficient networks. The impact is theoretical at this stage.","key_impact_metrics":["Computational complexity reduction from O(M(N log{M}/t)^{2t}) to O(t^2Mbinom{N}{t})"],"technology_tags":["privacy-preserving computation","network security","data anonymization"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:39:33.397837Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7f9ae32e5217","title":"Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract","content":"arXiv:2510.12047v1 Announce Type: new Abstract: Prevailing code generation benchmarks, such as HumanEval+ and MBPP+, primarily evaluate large language models (LLMs) with pass@k on functional correctness using well-formed inputs. However, they ignore a crucial aspect of real-world software: adherence to contracts-the preconditions and validity constraints that dictate how ill-formed inputs must be rejected. This critical oversight means that existing benchmarks fail to measure, and models consequently fail to generate, truly robust and reliable code snippets. We introduce PACT, a program assessment and contract-adherence evaluation framework, to bridge this gap. PACT is the first framework designed to systematically evaluate and enhance contract-adherence in LLM-generated code snippets alongside functional correctness. PACT's contributions are threefold: First, it provides a comprehensive test-suite corpus focused on contract violations, extending HumanEval+ and MBPP+. Second, it enables a systematic analysis of code generation under varied prompting conditions. This analysis demonstrates that augmenting prompts with contract-violating test cases significantly enhance a model's ability to respect contracts compared to using contract description alone. Finally, it introduces novel metrics to rigorously quantify contract adherence in both test generation and code generation. By revealing critical errors that conventional benchmarks overlook, PACT provides the rigorous and interpretable metrics to evaluate the robustness of LLM-generated code snippets in both functionality and contract-adherence.Our code and data are available at https://github.com/suhanmen/PACT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12047","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.271295","language":"en","tags":["preprints","csai","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Soohan Lim, Joonghyuk Hahn, Hyunwoo Park, Sang-Ki Ko, Yo-Sub Han","raw_content_length":1688,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Enforcing Contract arXiv:2510.12047v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1687,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models Respect Contracts","Evaluating","Enforcing Contract","arXiv251012047v1 Announce Type","new Abstract","Prevailing code generation","HumanEval","MBPP","large language models","LLMs"],"filter_categories":{"ai_ml":["Large Language Models Respect Contracts","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models Respect Contracts":2.0,"Evaluating":2.0,"Enforcing Contract":2.0,"arXiv251012047v1 Announce Type":1.0,"new Abstract":1.0,"Prevailing code generation":1.0,"HumanEval":1.0,"MBPP":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.738530133055556,"is_recent":true,"quality_score":1.0,"sentiment_score":1.743,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6514,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8997,"joy":0.0036,"surprise":0.0218,"sadness":0.0085,"fear":0.0149,"anger":0.0291,"disgust":0.0224},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new framework (PACT) for evaluating the contract adherence of LLM-generated code. While it aims to improve the reliability of software, its direct climate impact is minimal as it's focused on code generation rather than a specific climate technology. The research is credible, providing metrics to quantify contract adherence, but it's still in the applied research stage with no deployed units or economic viability demonstrated.","key_impact_metrics":["Contract adherence score","Functional correctness score"],"technology_tags":["Large Language Models","Code Generation","Software Reliability"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:39:36.453806Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_19b2a1af6e54","title":"Thin Trees via $k$","content":"arXiv:2510.12050v1 Announce Type: new Abstract: Thin spanning trees lie at the intersection of graph theory, approximation algorithms, and combinatorial optimization. They are central to the long-standing \\emph{thin tree conjecture}, which asks whether every $k$-edge-connected graph contains an $O(1/k)$-thin tree, and they underpin algorithmic breakthroughs such as the $O(\\log n/\\log\\log n)$-approximation for ATSP. Yet even the basic algorithmic task of \\emph{verifying} that a given tree is thin has remained elusive: checking thinness requires reasoning about exponentially many cuts, and no efficient certificates have been known. We introduce a new machinery of \\emph{$k$-respecting cut identities}, which express the weight of every cut that crosses a spanning tree in at most $k$ edges as a simple function of pairwise ($2$-respecting) cuts. This yields a tree-local oracle that, after $O(n^2)$ preprocessing, evaluates such cuts in $O_k(1)$ time. Building on this oracle, we give the first procedure to compute the exact $k$-thinness certificate $\\Theta_k(T)$ of any spanning tree for fixed $k$ in time $\\tilde O(n^2+n^k)$, outputting both the certificate value and a witnessing cut. Beyond general graphs, our framework yields sharper guarantees in structured settings. In planar graphs, duality with cycles and dual girth imply that every spanning tree admits a verifiable certificate $\\Theta_k(T)\\le k/\\lambda$ (hence $O(1/\\lambda)$ for constant $k$). In graphs embedded on a surface of genus $\\gamma$, refined counting gives certified (per-cut) bounds $O((\\log n+\\gamma)/\\lambda)$ via the same ensemble coverage.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12050","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.271732","language":"en","tags":["preprints","mathco","csdm","computer-science","research","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Mohit Daga","raw_content_length":1632,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["ATSP"],"persons":["Thin Trees"],"locations":[],"monetary":["2$-respecting","$O(1/k)$-thin"]},"char_count":1627,"language_detected":"en","key_concepts":{"key_phrases":["Thin Trees","arXiv251012050v1 Announce Type","new Abstract","Thin spanning trees","the intersection","graph theory","combinatorial optimization","tree conjecture","which","every k-edge-connected graph"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Thin Trees":2.0,"arXiv251012050v1 Announce Type":1.0,"new Abstract":1.0,"Thin spanning trees":1.0,"the intersection":1.0,"graph theory":1.0,"combinatorial optimization":1.0,"tree conjecture":1.0,"which":1.0,"every k-edge-connected graph":1.0}},"age_hours":2.7385452683333336,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8664,"joy":0.0175,"surprise":0.096,"sadness":0.0051,"fear":0.004,"anger":0.008,"disgust":0.0029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for verifying the thinness of spanning trees. While this is a theoretical advance in graph theory, it's unclear how it directly translates to concrete climate action or measurable outcomes. The research is at a very early stage and lacks immediate deployment potential.","key_impact_metrics":[],"technology_tags":["graph theory","algorithms","combinatorial optimization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:39:39.058372Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eedaef006bd5","title":"APCE: Adaptive Progressive Context Expansion for Long Context Processing","content":"arXiv:2510.12051v1 Announce Type: new Abstract: Deploying useful Long-Context Transformer Models (LCTMs) requires addressing two key challenges: (1) A growing memory footprint due to quadratic self-attention and linear KV-cache scaling in memory as sequence length increases; (2) the ContextRot phenomena where empirical evidence suggests that transformer architecture's performance degrades with increasing context length. Given the shared dependency on the input, a natural question arises: Can we surgically select the most important input chunks for processing to synergistically (a) reduce the memory footprint, and (b) mitigate the ContextRot effects? In this paper, we answer this question in the affirmative for long-context summarization tasks. We propose APCE as a context-aware solution to select the most important input chunks through low-dimensional semantic similarity matching with the current query. By directly operating on the input, APCE decouples from strict dependency on underlying hardware or CUDA environments, promising a compatible solution scalable to different deployment systems. Our empirical evaluations have demonstrated superior or on-par summarization performance for APCE compared to the full dense baseline using a fraction (50%-70%) of the input sequence resulting in KV-cache and self-attention memory efficiency improvements. We hope our findings inspire further research on context-aware efficiency solutions for LCTMs geared towards other relevant long-context tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12051","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.272132","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Baisub Lee, Sanghyun Byun, Mohanad Odema, Jung Guack, Jacob Song, Woo Seong Chung","raw_content_length":1510,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["ContextRot","Long-Context Transformer Models","Adaptive Progressive Context Expansion for Long Context Processing arXiv:2510.12051v1 Announce Type: new"],"persons":["APCE"],"locations":[],"monetary":[]},"char_count":1509,"language_detected":"en","key_concepts":{"key_phrases":["APCE","Adaptive Progressive Context Expansion","Long Context Processing","arXiv251012051v1 Announce Type","new Abstract","useful Long-Context Transformer Models","LCTMs","two key challenges","1 A growing memory footprint","quadratic self-attention and linear KV-cache scaling"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"APCE":2.0,"Adaptive Progressive Context Expansion":2.0,"Long Context Processing":2.0,"arXiv251012051v1 Announce Type":1.0,"new Abstract":1.0,"useful Long-Context Transformer Models":1.0,"LCTMs":1.0,"two key challenges":1.0,"1 A growing memory footprint":1.0,"quadratic self-attention and linear KV-cache scaling":1.0}},"age_hours":2.738560588611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7558,"joy":0.0054,"surprise":0.0745,"sadness":0.0374,"fear":0.0395,"anger":0.0528,"disgust":0.0346},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (APCE) to improve the efficiency of long-context transformer models, potentially reducing energy consumption by using only 50-70% of the input sequence. This leads to memory efficiency improvements, but it's still in the research phase with no deployed units or independent verification. The economic viability is uncertain as there's no cost analysis or market demand data.","key_impact_metrics":["50-70% reduction in input sequence length","KV-cache memory efficiency improvements"],"technology_tags":["Long-Context Transformer Models","Semantic Similarity Matching"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T15:39:42.350588Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d499139f0bab","title":"MIARec: Mutual","content":"arXiv:2510.12054v1 Announce Type: new Abstract: With the rapid expansion of scientific literature, scholars increasingly demand precise and high-quality paper recommendations. Among various recommendation methodologies, graph-based approaches have garnered attention by effectively exploiting the structural characteristics inherent in scholarly networks. However, these methods often overlook the asymmetric academic influence that is prevalent in scholarly networks when learning graph representations. To address this limitation, this study proposes the Mutual-Influence-Aware Recommendation (MIARec) model, which employs a gravity-based approach to measure the mutual academic influence between scholars and incorporates this influence into the feature aggregation process during message propagation in graph representation learning. Additionally, the model utilizes a multi-channel aggregation method to capture both individual embeddings of distinct single relational sub-networks and their interdependent embeddings, thereby enabling a more comprehensive understanding of the heterogeneous scholarly network. Extensive experiments conducted on real-world datasets demonstrate that the MIARec model outperforms baseline models across three primary evaluation metrics, indicating its effectiveness in scientific paper recommendation tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12054","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.272918","language":"en","tags":["preprints","csir","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Wenjin Xie, Tao Jia","raw_content_length":1345,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["the Mutual-Influence-Aware Recommendation"],"persons":[],"locations":[],"monetary":[]},"char_count":1344,"language_detected":"en","key_concepts":{"key_phrases":["MIARec","scholarly networks","arXiv251012054v1 Announce Type","new Abstract","the rapid expansion","scientific literature","scholars","precise and high-quality paper recommendations","various recommendation methodologies","graph-based approaches"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MIARec":2.0,"scholarly networks":2.0,"arXiv251012054v1 Announce Type":1.0,"new Abstract":1.0,"the rapid expansion":1.0,"scientific literature":1.0,"scholars":1.0,"precise and high-quality paper recommendations":1.0,"various recommendation methodologies":1.0,"graph-based approaches":1.0}},"age_hours":2.738588511666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8639,"joy":0.0222,"surprise":0.0793,"sadness":0.0079,"fear":0.0057,"anger":0.0144,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new algorithm (MIARec) for scientific paper recommendation. While it demonstrates improved performance on existing datasets, it's currently at the research stage and lacks concrete deployment or measurable environmental impact. The potential climate impact is indirect, as better research recommendations *could* lead to faster progress in climate-related fields, but this is speculative.","key_impact_metrics":["Effectiveness in scientific paper recommendation tasks"],"technology_tags":["Graph Neural Networks","Recommendation Systems","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:39:45.471324Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5056fb50fcf0","title":"APGNet: Adaptive Prior","content":"arXiv:2510.12056v1 Announce Type: new Abstract: Detecting camouflaged objects in underwater environments is crucial for marine ecological research and resource exploration. However, existing methods face two key challenges: underwater image degradation, including low contrast and color distortion, and the natural camouflage of marine organisms. Traditional image enhancement techniques struggle to restore critical features in degraded images, while camouflaged object detection (COD) methods developed for terrestrial scenes often fail to adapt to underwater environments due to the lack of consideration for underwater optical characteristics. To address these issues, we propose APGNet, an Adaptive Prior-Guided Network, which integrates a Siamese architecture with a novel prior-guided mechanism to enhance robustness and detection accuracy. First, we employ the Multi-Scale Retinex with Color Restoration (MSRCR) algorithm for data augmentation, generating illumination-invariant images to mitigate degradation effects. Second, we design an Extended Receptive Field (ERF) module combined with a Multi-Scale Progressive Decoder (MPD) to capture multi-scale contextual information and refine feature representations. Furthermore, we propose an adaptive prior-guided mechanism that hierarchically fuses position and boundary priors by embedding spatial attention in high-level features for coarse localization and using deformable convolution to refine contours in low-level features. Extensive experimental results on two public MAS datasets demonstrate that our proposed method APGNet outperforms 15 state-of-art methods under widely used evaluation metrics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12056","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.273323","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Xinxin Huang, Han Sun, Junmin Cai, Ningzhong Liu, Huiyu Zhou","raw_content_length":1669,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["COD","Adaptive Prior arXiv:2510.12056v1","Adaptive Prior-Guided Network","the Multi-Scale Retinex with Color Restoration (MSRCR"],"persons":[],"locations":[],"monetary":[]},"char_count":1664,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251012056v1","Announce Type","new Abstract","camouflaged objects","underwater environments","marine ecological research and resource exploration","existing methods","two key challenges","underwater image degradation","low contrast"],"filter_categories":{"research_academic":["marine ecological research and resource exploration"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251012056v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"camouflaged objects":1.0,"underwater environments":1.0,"marine ecological research and resource exploration":1.0,"existing methods":1.0,"two key challenges":1.0,"underwater image degradation":1.0,"low contrast":1.0}},"age_hours":2.738602370833333,"is_recent":true,"quality_score":1.0,"sentiment_score":1.408,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7184,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8799,"joy":0.0065,"surprise":0.0169,"sadness":0.0223,"fear":0.0281,"anger":0.0196,"disgust":0.0267},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (APGNet) for detecting camouflaged objects in underwater environments, which could aid in marine ecological research and resource exploration. The method is validated with experimental results on public datasets, demonstrating improved performance compared to existing methods. However, it is still in the applied research phase, with no evidence of real-world deployment or economic viability.","key_impact_metrics":["Detection accuracy on MAS datasets"],"technology_tags":["Underwater image processing","Camouflaged object detection","Deep learning","Marine ecology"],"sdg_alignment":[14],"analyzed_at":"2025-10-29T15:39:49.543531Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_905e56985a12","title":"Your VAR Model is Secretly an Efficient and Explainable Generative Classifier","content":"arXiv:2510.12060v1 Announce Type: new Abstract: Generative classifiers, which leverage conditional generative models for classification, have recently demonstrated desirable properties such as robustness to distribution shifts. However, recent progress in this area has been largely driven by diffusion-based models, whose substantial computational cost severely limits scalability. This exclusive focus on diffusion-based methods has also constrained our understanding of generative classifiers. In this work, we propose a novel generative classifier built on recent advances in visual autoregressive (VAR) modeling, which offers a new perspective for studying generative classifiers. To further enhance its performance, we introduce the Adaptive VAR Classifier$^+$ (A-VARC$^+$), which achieves a superior trade-off between accuracy and inference speed, thereby significantly improving practical applicability. Moreover, we show that the VAR-based method exhibits fundamentally different properties from diffusion-based methods. In particular, due to its tractable likelihood, the VAR-based classifier enables visual explainability via token-wise mutual information and demonstrates inherent resistance to catastrophic forgetting in class-incremental learning tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12060","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.273730","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Yi-Chung Chen, David I. Inouye, Jing Gao","raw_content_length":1268,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["VAR"],"persons":[],"locations":[],"monetary":[]},"char_count":1267,"language_detected":"en","key_concepts":{"key_phrases":["Your VAR Model","an Efficient and Explainable Generative Classifier","arXiv251012060v1","Announce Type","new Abstract","Generative classifiers","which","conditional generative models","classification","desirable properties"],"filter_categories":{"ai_ml":["an Efficient and Explainable Generative Classifier"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Your VAR Model":2.0,"an Efficient and Explainable Generative Classifier":2.0,"arXiv251012060v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Generative classifiers":1.0,"which":1.0,"conditional generative models":1.0,"classification":1.0,"desirable properties":1.0}},"age_hours":2.738616152777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1415,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8283,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8967,"joy":0.0388,"surprise":0.0338,"sadness":0.0032,"fear":0.0067,"anger":0.014,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel generative classifier based on visual autoregressive (VAR) modeling. While it claims improved accuracy and inference speed, it is still in the research phase with no deployed units or operational data. The potential climate impact is theoretical, as the application to specific sustainability challenges is not demonstrated.","key_impact_metrics":["Accuracy","Inference speed"],"technology_tags":["Generative Classifier","Visual Autoregressive Modeling","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:39:53.093201Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_37591a89e3a9","title":"Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response","content":"arXiv:2510.12061v1 Announce Type: new Abstract: Effective disaster response is essential for safeguarding lives and property. Existing statistical approaches often lack semantic context, generalize poorly across events, and offer limited interpretability. While Large language models (LLMs) provide few-shot generalization, they remain text-bound and blind to geography. To bridge this gap, we introduce a Geospatial Awareness Layer (GAL) that grounds LLM agents in structured earth data. Starting from raw wildfire detections, GAL automatically retrieves and integrates infrastructure, demographic, terrain, and weather information from external geodatabases, assembling them into a concise, unit-annotated perception script. This enriched context enables agents to produce evidence-based resource-allocation recommendations (e.g., personnel assignments, budget allocations), further reinforced by historical analogs and daily change signals for incremental updates. We evaluate the framework in real wildfire scenarios across multiple LLM models, showing that geospatially grounded agents can outperform baselines. The proposed framework can generalize to other hazards such as floods and hurricanes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12061","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.274242","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Yiheng Chen, Lingyao Li, Zihui Ma, Qikai Hu, Yilun Zhu, Min Deng, Runlong Yu","raw_content_length":1203,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Geospatial Awareness","GAL","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1202,"language_detected":"en","key_concepts":{"key_phrases":["LLM Agents","Geospatial Awareness","Grounded Reasoning","Wildfire Response","Announce Type","new Abstract","Effective disaster response","lives","property","Existing statistical approaches"],"filter_categories":{"ai_ml":["LLM Agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM Agents":2.0,"Geospatial Awareness":2.0,"Grounded Reasoning":2.0,"Wildfire Response":2.0,"Announce Type":1.0,"new Abstract":1.0,"Effective disaster response":1.0,"lives":1.0,"property":1.0,"Existing statistical approaches":1.0}},"age_hours":2.7386318033333334,"is_recent":true,"quality_score":1.0,"sentiment_score":1.4985,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7003,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9433,"joy":0.0047,"surprise":0.0082,"sadness":0.0056,"fear":0.0198,"anger":0.0104,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a Geospatial Awareness Layer (GAL) that enhances LLM agents for wildfire response by integrating structured earth data. The framework is evaluated in real wildfire scenarios and shows outperformance compared to baselines, indicating potential for improved resource allocation. However, it's still in the applied research phase with no mention of deployed units or customer contracts, hence the vaporware flag.","key_impact_metrics":["Outperforms baselines in wildfire scenarios"],"technology_tags":["LLM","Geospatial Awareness","Wildfire Response"],"sdg_alignment":[13,15],"analyzed_at":"2025-10-29T15:39:56.500417Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_099f6db7b627","title":"Adding All Flavors: A Hybrid Random Number Generator for dApps and Web3","content":"arXiv:2510.12062v1 Announce Type: new Abstract: Random numbers play a vital role in many decentralized applications (dApps), such as gaming and decentralized finance (DeFi) applications. Existing random number provision mechanisms can be roughly divided into two categories, on-chain, and off-chain. On-chain approaches usually rely on the blockchain as the major input and all computations are done by blockchain nodes. The major risk for this type of method is that the input itself is susceptible to the adversary's influence. Off-chain approaches, as the name suggested, complete the generation without the involvement of blockchain nodes and share the result directly with a dApp. These mechanisms usually have a strong security assumption and high complexity. To mitigate these limitations and provide a framework that allows a dApp to balance different factors involved in random number generation, we propose a hybrid random number generation solution that leverages IoT devices equipped with trusted execution environment (TEE) as the randomness sources, and then utilizes a set of cryptographic tools to aggregate the multiple sources and obtain the final random number that can be consumed by the dApp. The new approach only needs one honest random source to guarantee the unbiasedness of the final random number and a user can configure the system to tolerate malicious participants who can refuse to respond to avoid unfavored results. We also provide a concrete construction that can further reduce the on-chain computation complexity to lower the cost of the solution in practice. We evaluate the computation and gas costs to demonstrate the effectiveness of the improvement.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12062","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.274713","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Ranjith Chodavarapu, Rabimba Karanjai, Xinxin Fan, Weidong Shi, Lei Xu","raw_content_length":1709,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["dApp","dApps","DeFi"],"persons":[],"locations":[],"monetary":[]},"char_count":1690,"language_detected":"en","key_concepts":{"key_phrases":["dApps","All Flavors","A Hybrid Random Number Generator","Web3","arXiv251012062v1 Announce Type","new Abstract","Random numbers","a vital role","many decentralized applications","DeFi"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"dApps":3.0,"All Flavors":2.0,"A Hybrid Random Number Generator":2.0,"Web3":2.0,"arXiv251012062v1 Announce Type":1.0,"new Abstract":1.0,"Random numbers":1.0,"a vital role":1.0,"many decentralized applications":1.0,"DeFi":1.0}},"age_hours":2.738647668888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.114000000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4228,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5168,"joy":0.0102,"surprise":0.02,"sadness":0.0143,"fear":0.4047,"anger":0.0252,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a hybrid random number generation solution using IoT devices and TEE, aiming to reduce on-chain computation complexity and gas costs. It evaluates computation and gas costs, providing some metrics. However, it's still in the early stages with no deployed units or real-world data, making it vaporware.","key_impact_metrics":["on-chain computation complexity","gas costs"],"technology_tags":["random number generation","IoT","trusted execution environment","blockchain"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:40:00.325101Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6bf2ab4d4e13","title":"ThinkPilot: Steering Reasoning Models via Automated Think","content":"arXiv:2510.12063v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) are powerful, but they still suffer from inefficient and off-target reasoning. Currently, training-free methods are limited to either rigid heuristics or descriptive, non-actionable analyses. In this paper, we introduce ThinkPilot, a training-free framework that automatically optimizes LRMs reasoning. It uses an evolutionary process to generate think-prefixes, which are instructions that evolve driven by a taxonomy of reasoning behaviors to guide models toward superior performance. Extensive experiments demonstrate ThinkPilot's broad effectiveness: it significantly improves the accuracy-length trade-off for efficient reasoning, drastically improves safety (for example, cutting the StrongREJECT score of DeepSeek-R1-Distill-Qwen-32B from 27.0% to 0.7), and enhances instruction following. It also synergizes with existing training-based methods. Our analysis reveals that think-prefixes can reliably control LRMs' reasoning behaviors, and that different tasks have strong preferences for specific behavioral distributions. By automatically identifying and eliciting these behaviors, ThinkPilot provides a generalizable framework for aligning LRMs reasoning with task demands. Data and code are available at https://github.com/teqkilla/ThinkPilot","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12063","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.275112","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Sunzhu Li, Zhiyu Lin, Shuling Yang, Jiale Zhao, Wei Chen","raw_content_length":1332,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["ThinkPilot","DeepSeek-R1-Distill-Qwen-32B"],"persons":[],"locations":[],"monetary":[]},"char_count":1331,"language_detected":"en","key_concepts":{"key_phrases":["ThinkPilot","Steering Reasoning Models","Automated Think","arXiv251012063v1 Announce Type","new Abstract","Large Reasoning Models","LRMs","inefficient and off-target reasoning","training-free methods","either rigid heuristics"],"filter_categories":{"ai_ml":["training-free methods"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ThinkPilot":3.0,"Steering Reasoning Models":2.0,"Automated Think":2.0,"arXiv251012063v1 Announce Type":1.0,"new Abstract":1.0,"Large Reasoning Models":1.0,"LRMs":1.0,"inefficient and off-target reasoning":1.0,"training-free methods":1.0,"either rigid heuristics":1.0}},"age_hours":2.738663438611111,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8017,"joy":0.0107,"surprise":0.0318,"sadness":0.045,"fear":0.0114,"anger":0.0465,"disgust":0.053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a framework to improve the reasoning capabilities of large reasoning models (LRMs). The concrete action is the development of 'think-prefixes' that guide models, demonstrated by a reduction in the StrongREJECT score of DeepSeek-R1-Distill-Qwen-32B from 27.0% to 0.7. This is still in the applied research stage, with no indication of real-world deployment or economic viability.","key_impact_metrics":["StrongREJECT score reduction: 27.0% to 0.7"],"technology_tags":["Large Reasoning Models","AI Safety","Instruction Following"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:03.658111Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46b49f401712","title":"AI Agents as Universal Task Solvers","content":"arXiv:2510.12066v1 Announce Type: new Abstract: AI reasoning agents are already able to solve a variety of tasks by deploying tools, simulating outcomes of multiple hypotheses and reflecting on them. In doing so, they perform computation, although not in the classical sense -- there is no program being executed. Still, if they perform computation, can AI agents be universal? Can chain-of-thought reasoning solve any computable task? How does an AI Agent learn to reason? Is it a matter of model size? Or training dataset size? In this work, we reinterpret the role of learning in the context of AI Agents, viewing them as compute-capable stochastic dynamical systems, and highlight the role of time in a foundational principle for learning to reason. In doing so, we propose a shift from classical inductive learning to transductive learning -- where the objective is not to approximate the distribution of past data, but to capture their algorithmic structure to reduce the time needed to find solutions to new tasks. Transductive learning suggests that, counter to Shannon's theory, a key role of information in learning is about reduction of time rather than reconstruction error. In particular, we show that the optimal speed-up that a universal solver can achieve using past data is tightly related to their algorithmic information. Using this, we show a theoretical derivation for the observed power-law scaling of inference time versus training time. We then show that scaling model size can lead to behaviors that, while improving accuracy on benchmarks, fail any reasonable test of intelligence, let alone super-intelligence: In the limit of infinite space and time, large models can behave as savants, able to brute-force through any task without any insight. Instead, we argue that the key quantity to optimize when scaling reasoning models is time, whose critical role in learning has so far only been indirectly considered.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12066","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.276316","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":306,"author":"Alessandro Achille, Stefano Soatto","raw_content_length":1944,"priority":7,"update_frequency":1,"reading_time_minutes":1.53,"robust_parsing_used":true,"entities":{"organizations":["Universal Task Solvers arXiv:2510.12066v1 Announce Type","AI Agents","AI Agents as"],"persons":[],"locations":[],"monetary":[]},"char_count":1939,"language_detected":"en","key_concepts":{"key_phrases":["AI Agents","Universal Task Solvers","computation","arXiv251012066v1 Announce Type","new Abstract","AI reasoning agents","a variety","tasks","tools","outcomes"],"filter_categories":{"ai_ml":["AI Agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AI Agents":2.0,"Universal Task Solvers":2.0,"computation":2.0,"arXiv251012066v1 Announce Type":1.0,"new Abstract":1.0,"AI reasoning agents":1.0,"a variety":1.0,"tasks":1.0,"tools":1.0,"outcomes":1.0}},"age_hours":2.7387082969444445,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1795,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2359,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8814,"joy":0.0102,"surprise":0.0684,"sadness":0.0031,"fear":0.0057,"anger":0.0188,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents theoretical research on AI reasoning agents and their potential for solving computable tasks. While the research explores the theoretical limits of AI and learning, it does not describe any concrete actions or deployed technologies with measurable outcomes related to sustainability. The focus is on algorithmic structure and time reduction in learning, not direct environmental impact.","key_impact_metrics":[],"technology_tags":["AI","Reasoning Agents","Transductive Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:06.783311Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_10d8f6ce4eb5","title":"HiCoTraj:Zero-Shot Demographic Reasoning via Hierarchical Chain","content":"arXiv:2510.12067v1 Announce Type: new Abstract: Inferring demographic attributes such as age, sex, or income level from human mobility patterns enables critical applications such as targeted public health interventions, equitable urban planning, and personalized transportation services. Existing mobility-based demographic inference studies heavily rely on large-scale trajectory data with demographic labels, leading to limited interpretability and poor generalizability across different datasets and user groups. We propose HiCoTraj (Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory), a framework that leverages LLMs' zero-shot learning and semantic understanding capabilities to perform demographic inference without labeled training data. HiCoTraj transforms trajectories into semantically rich, natural language representations by creating detailed activity chronicles and multi-scale visiting summaries. Then HiCoTraj uses a novel hierarchical chain of thought reasoning to systematically guide LLMs through three cognitive stages: factual feature extraction, behavioral pattern analysis, and demographic inference with structured output. This approach addresses the scarcity challenge of labeled demographic data while providing transparent reasoning chains. Experimental evaluation on real-world trajectory data demonstrates that HiCoTraj achieves competitive performance across multiple demographic attributes in zero-shot scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12067","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.276733","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Junyi Xie, Yuankun Jiao, Jina Kim, Yao-Yi Chiang, Lingyi Zhao, Khurram Shafique","raw_content_length":1487,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Hierarchical Chain","Hierarchical Chain arXiv:2510.12067v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1486,"language_detected":"en","key_concepts":{"key_phrases":["HiCoTraj","Zero-Shot Demographic Reasoning","Hierarchical Chain","arXiv251012067v1 Announce Type","new Abstract","Inferring demographic attributes","age","sex","income level","human mobility patterns"],"filter_categories":{"ai_ml":["Hierarchical Chain","age"],"hydrogen_energy":["age"],"renewable_energy":["age"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HiCoTraj":2.0,"Zero-Shot Demographic Reasoning":2.0,"Hierarchical Chain":2.0,"arXiv251012067v1 Announce Type":1.0,"new Abstract":1.0,"Inferring demographic attributes":1.0,"age":1.0,"sex":1.0,"income level":1.0,"human mobility patterns":1.0}},"age_hours":2.7387220497222224,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5305,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4939,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7023,"joy":0.0144,"surprise":0.0302,"sadness":0.0101,"fear":0.174,"anger":0.0497,"disgust":0.0193},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":5,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a novel method (HiCoTraj) for demographic inference from mobility patterns using LLMs, potentially enabling more targeted and equitable urban planning and public health interventions. The framework is evaluated on real-world trajectory data, demonstrating competitive performance in zero-shot scenarios, but lacks information on actual deployment or quantified impact on sustainability metrics like emissions reduction or resource optimization. It is currently in the applied research phase, with no evidence of commercial viability or deployment readiness.","key_impact_metrics":["Competitive performance across multiple demographic attributes in zero-shot scenarios"],"technology_tags":["LLMs","Demographic Inference","Mobility Patterns","Zero-Shot Learning"],"sdg_alignment":[3,9,11],"analyzed_at":"2025-10-29T15:40:10.004833Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_238c46a9df2d","title":"MEASURE: Multi","content":"arXiv:2510.12070v1 Announce Type: new Abstract: Deep learning-based automatic sleep staging has significantly advanced in performance and plays a crucial role in the diagnosis of sleep disorders. However, those models often struggle to generalize on unseen subjects due to variability in physiological signals, resulting in degraded performance in out-of-distribution scenarios. To address this issue, domain generalization approaches have recently been studied to ensure generalized performance on unseen domains during training. Among those techniques, contrastive learning has proven its validity in learning domain-invariant features by aligning samples of the same class across different domains. Despite its potential, many existing methods are insufficient to extract adequately domain-invariant representations, as they do not explicitly address domain characteristics embedded within the unshared information across samples. In this paper, we posit that mitigating such domain-relevant attributes-referred to as excess domain-relevant information-is key to bridging the domain gap. However, the direct strategy to mitigate the domain-relevant attributes often overfits features at the high-level information, limiting their ability to leverage the diverse temporal and spectral information encoded in the multiple feature levels. To address these limitations, we propose a novel MEASURE (Multi-scalE minimAl SUfficient Representation lEarning) framework, which effectively reduces domain-relevant information while preserving essential temporal and spectral features for sleep stage classification. In our exhaustive experiments on publicly available sleep staging benchmark datasets, SleepEDF-20 and MASS, our proposed method consistently outperformed state-of-the-art methods. Our code is available at : https://github.com/ku-milab/Measure","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12070","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.277524","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Sangmin Jo, Jee Seok Yoon, Wootaek Jeong, Kwanseok Oh, Heung-Il Suk","raw_content_length":1851,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["MEASURE"],"persons":[],"locations":[],"monetary":[]},"char_count":1850,"language_detected":"en","key_concepts":{"key_phrases":["MEASURE","Multi","arXiv251012070v1 Announce Type","new Abstract","Deep learning-based automatic sleep staging","performance","a crucial role","the diagnosis","sleep disorders","those models"],"filter_categories":{"ai_ml":["Deep learning-based automatic sleep staging"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MEASURE":2.0,"Multi":2.0,"arXiv251012070v1 Announce Type":1.0,"new Abstract":1.0,"Deep learning-based automatic sleep staging":1.0,"performance":1.0,"a crucial role":1.0,"the diagnosis":1.0,"sleep disorders":1.0,"those models":1.0}},"age_hours":2.7387510025,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.856,"joy":0.0034,"surprise":0.0126,"sadness":0.0115,"fear":0.0504,"anger":0.0332,"disgust":0.0328},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel deep learning framework (MEASURE) for improved sleep staging, demonstrating outperformance on benchmark datasets (SleepEDF-20 and MASS). While the technology itself doesn't directly address climate change, improved sleep disorder diagnosis could potentially lead to indirect benefits such as reduced healthcare resource consumption. The research is at the applied research stage, with code available but lacking real-world deployment data.","key_impact_metrics":["Outperformed state-of-the-art methods on SleepEDF-20","Outperformed state-of-the-art methods on MASS"],"technology_tags":["Deep Learning","Sleep Staging","Domain Generalization"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:40:12.964799Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf455d5dfe1f","title":"EmboMatrix: A Scalable Training","content":"arXiv:2510.12072v1 Announce Type: new Abstract: Embodied decision-making enables agents to translate high-level goals into executable actions through continuous interactions within the physical world, forming a cornerstone of general-purpose embodied intelligence. Large language models (LLMs), with their general decision-making capabilities, offer a promising path to realize this potential; however, LLMs trained solely on language lack exposure to physical environments, limiting their true embodied understanding. To bridge this gap, we propose the concept of a training ground: a comprehensive infrastructure that provides task and scene simulation, embodied interaction, and feedback signals, offering a one-stop solution for LLM acquire genuine embodied decision-making skills. In this work, we present EmboMatrix, the first training ground of its kind, providing massive and diverse tasks with efficient simulation and precise rewards. EmboMatrix incorporates a series of novel techniques: a multi-agent data engine for large-scale task and scene generation, a distributed heterogeneous-hardware system for scalable simulation, and a multi-level reward architecture for precise supervision. Leveraging EmboMatrix, we cultivate EmboBrain, an LLM whose embodied decision-making abilities emerge from extensive embodied interactions. Experiments show that EmboBrain-7B surpasses the 671B DeepSeek-R1 baseline by 9.5\\% on two challenging embodied decision-making benchmarks, demonstrating the power of interactive, environment-grounded learning for building truly intelligent embodied agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12072","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.278425","language":"en","tags":["preprints","csai","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Zixing Lei, Sheng Yin, Yichen Xiong, Yuanzhuo Ding, Wenhao Huang, Yuxi Wei, Qingyao Xu, Yiming Li, Weixin Li, Yunhong Wang, Siheng Chen","raw_content_length":1598,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["EmboMatrix","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1597,"language_detected":"en","key_concepts":{"key_phrases":["EmboMatrix","A Scalable Training","LLMs","Announce Type","new Abstract","agents","high-level goals","executable actions","continuous interactions","the physical world"],"filter_categories":{"ai_ml":["A Scalable Training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EmboMatrix":2.0,"A Scalable Training":2.0,"LLMs":2.0,"Announce Type":1.0,"new Abstract":1.0,"agents":1.0,"high-level goals":1.0,"executable actions":1.0,"continuous interactions":1.0,"the physical world":1.0}},"age_hours":2.738779254722222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9134,"joy":0.0132,"surprise":0.0351,"sadness":0.0084,"fear":0.0125,"anger":0.0083,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel training ground for LLMs to improve embodied decision-making. While the EmboBrain-7B surpasses the DeepSeek-R1 baseline by 9.5% on benchmarks, it's still in the research phase with no real-world deployment or economic viability demonstrated. The impact on climate is indirect, potentially enabling more efficient robotics in various sectors, but not directly reducing emissions.","key_impact_metrics":["9.5% improvement on embodied decision-making benchmarks","7B parameters for EmboBrain"],"technology_tags":["Large Language Models","Embodied AI","Robotics"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:16.182068Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_186b704f3891","title":"BeSTAD: Behavior","content":"arXiv:2510.12076v1 Announce Type: new Abstract: Traditional anomaly detection in human mobility has primarily focused on trajectory-level analysis, identifying statistical outliers or spatiotemporal inconsistencies across aggregated movement traces. However, detecting individual-level anomalies, i.e., unusual deviations in a person's mobility behavior relative to their own historical patterns, within datasets encompassing large populations remains a significant challenge. In this paper, we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human Mobility Data), an unsupervised framework that captures individualized behavioral signatures across large populations and uncovers fine-grained anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD learns semantically enriched mobility representations that integrate location meaning and temporal patterns, enabling the detection of subtle deviations in individual movement behavior. BeSTAD further employs a behavior-cluster-aware modeling mechanism that builds personalized behavioral profiles from normal activity and identifies anomalies through cross-period behavioral comparison with consistent semantic alignment. Building on prior work in mobility behavior clustering, this approach enables not only the detection of behavioral shifts and deviations from established routines but also the identification of individuals exhibiting such changes within large-scale mobility datasets. By learning individual behaviors directly from unlabeled data, BeSTAD advances anomaly detection toward personalized and interpretable mobility analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12076","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.279969","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Junyi Xie, Jina Kim, Yao-Yi Chiang, Lingyi Zhao, Khurram Shafique","raw_content_length":1635,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Spatio-Temporal Anomaly Detection for Human Mobility Data"],"persons":["BeSTAD"],"locations":[],"monetary":[]},"char_count":1634,"language_detected":"en","key_concepts":{"key_phrases":["BeSTAD","Behavior","arXiv251012076v1 Announce Type","new Abstract","Traditional anomaly detection","human mobility","trajectory-level analysis","statistical outliers","spatiotemporal inconsistencies","aggregated movement traces"],"filter_categories":{"engineering":["spatiotemporal inconsistencies"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BeSTAD":2.0,"Behavior":2.0,"arXiv251012076v1 Announce Type":1.0,"new Abstract":1.0,"Traditional anomaly detection":1.0,"human mobility":1.0,"trajectory-level analysis":1.0,"statistical outliers":1.0,"spatiotemporal inconsistencies":1.0,"aggregated movement traces":1.0}},"age_hours":2.7388078680555554,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8981,"joy":0.0063,"surprise":0.0529,"sadness":0.0061,"fear":0.0169,"anger":0.0113,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an unsupervised framework (BeSTAD) for detecting anomalies in individual mobility behavior. While it could potentially contribute to more efficient transportation systems by identifying unusual travel patterns, it is currently in the applied research stage with no deployed units or measured outcomes. The impact on climate change is theoretical at this point.","key_impact_metrics":[],"technology_tags":["anomaly detection","human mobility","spatio-temporal analysis"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T15:40:22.021397Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e526166fe15","title":"FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine","content":"arXiv:2510.12078v1 Announce Type: new Abstract: Fine-tuning (FT) large language models (LLMs) is crucial for adapting general-purpose models to specific tasks, enhancing accuracy and relevance with minimal resources. To further enhance generalization ability while reducing training costs, this paper proposes Federated LoRA with Dropout (FedLoDrop), a new framework that applies dropout to the rows and columns of the trainable matrix in Federated LoRA. A generalization error bound and convergence analysis under sparsity regularization are obtained, which elucidate the fundamental trade-off between underfitting and overfitting. The error bound reveals that a higher dropout rate increases model sparsity, thereby lowering the upper bound of pointwise hypothesis stability (PHS). While this reduces the gap between empirical and generalization errors, it also incurs a higher empirical error, which, together with the gap, determines the overall generalization error. On the other hand, though dropout reduces communication costs, deploying FedLoDrop at the network edge still faces challenges due to limited network resources. To address this issue, an optimization problem is formulated to minimize the upper bound of the generalization error, by jointly optimizing the dropout rate and resource allocation subject to the latency and per-device energy consumption constraints. To solve this problem, a branch-and-bound (B\\&B)-based method is proposed to obtain its globally optimal solution. Moreover, to reduce the high computational complexity of the B\\&B-based method, a penalized successive convex approximation (P-SCA)-based algorithm is proposed to efficiently obtain its high-quality suboptimal solution. Finally, numerical results demonstrate the effectiveness of the proposed approach in mitigating overfitting and improving the generalization capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12078","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.280470","language":"en","tags":["preprints","csit","computer-science","cslg","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Sijing Xie, Dingzhu Wen, Changsheng You, Qimei Chen, Mehdi Bennis, Kaibin Huang","raw_content_length":1879,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Federated LoRA","Federated"],"persons":["Dropout"],"locations":[],"monetary":[]},"char_count":1870,"language_detected":"en","key_concepts":{"key_phrases":["Federated LoRA","FedLoDrop","Dropout","Generalized LLM Fine","arXiv251012078v1 Announce Type","new Abstract","Fine-tuning FT large language models","LLMs","general-purpose models","specific tasks"],"filter_categories":{"ai_ml":["Generalized LLM Fine","Fine-tuning FT large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Federated LoRA":4.0,"FedLoDrop":3.0,"Dropout":3.0,"Generalized LLM Fine":2.0,"arXiv251012078v1 Announce Type":1.0,"new Abstract":1.0,"Fine-tuning FT large language models":1.0,"LLMs":1.0,"general-purpose models":1.0,"specific tasks":1.0}},"age_hours":2.7388235450000002,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9347,"joy":0.0165,"surprise":0.0288,"sadness":0.0033,"fear":0.0038,"anger":0.0092,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new federated learning framework (FedLoDrop) to fine-tune large language models with reduced communication costs and improved generalization. While the research includes error bound analysis and optimization for resource allocation, it remains at the stage of numerical results and lacks real-world deployment data. The potential climate impact is indirect, stemming from reduced energy consumption during model training and deployment, but this is not quantified.","key_impact_metrics":["Generalization error bound","Dropout rate"],"technology_tags":["Federated Learning","LoRA","Dropout Regularization","Large Language Models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:25.182822Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dca5ebef5d87","title":"Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models","content":"arXiv:2510.12080v1 Announce Type: new Abstract: The rapid advancement of large language model (LLM) technology has led to diverse applications, many of which inherently require randomness, such as stochastic decision-making, gaming, scheduling, AI agents, and cryptography-related tasks. However, the capabilities of LLMs in handling randomness, particularly in generating and utilizing random numbers effectively, remain unclear. This paper investigates the capacity of LLMs for handling tasks that involve randomness through a series of experiments. We designed a set of experiments that consider various factors that can influence an LLM's performance in tasks involving randomness, such as accessibility to external tools, types of tasks, model states (fresh vs. non-fresh), and prompting strategies. The experiments cover a range of tasks, including generating random numbers, generating random strings such as passwords, shuffling items, and evaluating the quality of randomness using entropy and the NIST randomness test-suite. Our findings reveal that while LLMs can generate outputs that exhibit some degree of randomness, their performance is inconsistent and often deviates significantly from the expected behavior. The analysis of the experimental results highlights key limitations and areas where improvement is needed for the LLMs to effectively handle tasks involving randomness","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12080","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.280929","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Rabimba Karanjai, Yang Lu, Ranjith Chodavarapu, Lei Xu, Weidong Shi","raw_content_length":1395,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["LLM","the Quality of Randomness and Entropy"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1394,"language_detected":"en","key_concepts":{"key_phrases":["the Quality","Randomness","Entropy","Tasks","Large Language Models","randomness","LLMs","arXiv251012080v1 Announce Type","new Abstract","The rapid advancement"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Quality":2.0,"Randomness":2.0,"Entropy":2.0,"Tasks":2.0,"Large Language Models":2.0,"randomness":2.0,"LLMs":2.0,"arXiv251012080v1 Announce Type":1.0,"new Abstract":1.0,"The rapid advancement":1.0}},"age_hours":2.7388388055555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6369,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8907,"joy":0.0293,"surprise":0.0434,"sadness":0.0029,"fear":0.0102,"anger":0.0137,"disgust":0.0098},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper investigates the capabilities of LLMs in handling randomness. The concrete action is a series of experiments designed to test the LLM's ability to generate and utilize random numbers. The evidence is based on the analysis of the experimental results, which highlight limitations in the LLMs' performance. The stage of deployment is basic research, as it is focused on understanding the fundamental capabilities of LLMs.","key_impact_metrics":["deviation from expected behavior","entropy"],"technology_tags":["Large Language Models","Random Number Generation","Entropy"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:40:28.308304Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5398a552de04","title":"Social Simulation for Integrating Self","content":"arXiv:2510.12081v1 Announce Type: new Abstract: Despite growing interest in virtual and augmented reality (VR/AR) for mental well-being, prior work using immersive interventions to teach mental health skills has largely focused on calming or abstract settings. As a result, little is known about how realistic social simulation may better support the transfer and application of skills to in-person environments. In this work, we present a 14-day user study with 43-participants comparing an augmented reality intervention simulating a realistic contextual environment against a matched non-contextual control, applied to the public speaking context. We found that participants who practice mental health skills in the contextual environment showed significantly greater likelihood to apply self-care techniques and greater physiological stress reduction when using skills in mock in-person tasks. Overall, our work provides empirical evidence for the effects of realistic stressor simulation, and offers design implications for mental health technology that supports effective transfer of skills to the real-world.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12081","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.281321","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Anna Fang, Jiayang Shi, Hriday Chhabria, Bosi Li, Haiyi Zhu","raw_content_length":1116,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["Social Simulation for Integrating Self arXiv:2510.12081v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1115,"language_detected":"en","key_concepts":{"key_phrases":["Social Simulation","Integrating Self","arXiv251012081v1 Announce Type","new Abstract","growing interest","virtual and augmented reality","VRAR","mental well-being","prior work","immersive interventions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Social Simulation":2.0,"Integrating Self":2.0,"arXiv251012081v1 Announce Type":1.0,"new Abstract":1.0,"growing interest":1.0,"virtual and augmented reality":1.0,"VRAR":1.0,"mental well-being":1.0,"prior work":1.0,"immersive interventions":1.0}},"age_hours":2.7388541625,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9235,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7847,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9137,"joy":0.0224,"surprise":0.0298,"sadness":0.0083,"fear":0.0093,"anger":0.0073,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the use of AR/VR for mental health, showing a greater likelihood to apply self-care techniques and greater physiological stress reduction in a contextual environment. While the study demonstrates a positive impact on mental well-being, it has minimal direct impact on climate change or environmental sustainability. The technology is in the applied research phase, with a 14-day user study conducted.","key_impact_metrics":["greater likelihood to apply self-care techniques","greater physiological stress reduction"],"technology_tags":["Augmented Reality","Virtual Reality","Mental Health Technology"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:40:31.318385Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a2e71b1d8320","title":"Enhancing Neural Code Representation with Additional Context","content":"arXiv:2510.12082v1 Announce Type: new Abstract: Automated program comprehension underpins many software engineering tasks, from code summarisation to clone detection. Recent deep learning models achieve strong results but typically rely on source code alone, overlooking contextual information such as version history or structural relationships. This limits their ability to capture how code evolves and operates. We conduct an empirical study on how enriching code representations with such contextual signals affects neural model performance on key comprehension tasks. Two downstream tasks, code clone detection and code summarisation, are evaluated using SeSaMe (1,679 Java methods) and CodeSearchNet (63,259 methods). Five representative models (CodeBERT, GraphCodeBERT, CodeT5, PLBART, ASTNN) are fine-tuned under code-only and context-augmented settings. Results show that context generally improves performance: version history consistently boosts clone detection (e.g., CodeT5 +15.92% F1) and summarisation (e.g., GraphCodeBERT +5.56% METEOR), while call-graph effects vary by model and task. Combining multiple contexts yields further gains (up to +21.48% macro-F1). Human evaluation on 100 Java snippets confirms that context-augmented summaries are significantly preferred for Accuracy and Content Adequacy (p <= 0.026; |delta| up to 0.55). These findings highlight the potential of contextual signals to enhance code comprehension and open new directions for optimising contextual encoding in neural SE models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12082","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.281760","language":"en","tags":["preprints","csai","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Huy Nguyen, Christoph Treude, Patanamon Thongtanunam","raw_content_length":1525,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Java"],"locations":[],"monetary":[]},"char_count":1524,"language_detected":"en","key_concepts":{"key_phrases":["Neural Code Representation","Additional Context","Announce Type","new Abstract","Automated program comprehension","many software engineering tasks","code summarisation","clone detection","Recent deep learning models","strong results"],"filter_categories":{"engineering":["many software engineering tasks"],"ai_ml":["Recent deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neural Code Representation":2.0,"Additional Context":2.0,"Announce Type":1.0,"new Abstract":1.0,"Automated program comprehension":1.0,"many software engineering tasks":1.0,"code summarisation":1.0,"clone detection":1.0,"Recent deep learning models":1.0,"strong results":1.0}},"age_hours":2.7388690766666666,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9103,"joy":0.0063,"surprise":0.0261,"sadness":0.007,"fear":0.0143,"anger":0.018,"disgust":0.0179},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores improving code comprehension using contextual information to enhance software engineering tasks. The concrete action is the empirical study using existing datasets and models, showing performance improvements in code clone detection and summarization. While promising, it's still in the applied research phase with no clear path to economic viability or large-scale deployment.","key_impact_metrics":["CodeT5 +15.92% F1 (clone detection)","GraphCodeBERT +5.56% METEOR (summarisation)"],"technology_tags":["neural networks","code comprehension","software engineering"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:40:34.185456Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c8176dc3cb6a","title":"GraphShaper: Geometry","content":"arXiv:2510.12085v1 Announce Type: new Abstract: Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains. Recent methods leverage large language models to unify graph and text modalities into a shared representation space using contrastive learning. However, systematic evaluations reveal significant performance degradation at structural boundaries where distinct topological patterns converge, with accuracy losses exceeding 20 percentage points. This issue arises from a key limitation: current methods assume all graph structures can be encoded within a single Euclidean space. In reality, tree structures require hyperbolic geometry to preserve hierarchical branching, while cyclic patterns depend on spherical geometry for closure properties. At structural boundaries, nodes experience conflicting geometric constraints that uniform encoding spaces cannot resolve. This raises a crucial challenge: \\textbf{Can alignment frameworks be designed to respect the intrinsic geometric diversity of graph structures?} We introduce \\textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding through multi-geometric specialization. Our approach employs expert networks tailored to different geometric spaces, dynamically computing fusion weights to adaptively integrate geometric properties based on local structural characteristics. This adaptive fusion preserves structural integrity before alignment with text embeddings. Extensive experiments demonstrate that GraphShaper achieves 9.47\\% accuracy improvements on citation networks and 7.63\\% on social networks in zero-shot settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12085","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.283039","language":"en","tags":["preprints","computer-science","cslg","research","csgr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Heng Zhang, Tianyi Zhang, Yuling Shi, Xiaodong Gu, Yaomin Shen, Haochen You, Zijian Zhang, Yilei Yuan, Jin Huang","raw_content_length":1677,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1676,"language_detected":"en","key_concepts":{"key_phrases":["GraphShaper","Geometry","arXiv251012085v1 Announce Type","new Abstract","Graph foundation models","a transformative paradigm","transferable representations","diverse graph domains","Recent methods","large language models"],"filter_categories":{"ai_ml":["diverse graph domains","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GraphShaper":2.0,"Geometry":2.0,"arXiv251012085v1 Announce Type":1.0,"new Abstract":1.0,"Graph foundation models":1.0,"a transformative paradigm":1.0,"transferable representations":1.0,"diverse graph domains":1.0,"Recent methods":1.0,"large language models":1.0}},"age_hours":2.7389133069444447,"is_recent":true,"quality_score":0.7,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8777,"joy":0.0172,"surprise":0.0591,"sadness":0.0127,"fear":0.0079,"anger":0.0129,"disgust":0.0125},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new graph encoding framework (GraphShaper) that improves accuracy on citation and social networks. While the technology itself doesn't directly reduce GHG emissions, improved data analysis could potentially contribute to more efficient resource allocation or better climate modeling in the future. The research is still in the early stages (basic research) and lacks deployment data, but it does present quantified performance improvements (9.47% and 7.63% accuracy) and is published on arXiv, suggesting peer review.","key_impact_metrics":["9.47% accuracy improvements on citation networks","7.63% accuracy improvements on social networks"],"technology_tags":["graph neural networks","geometric deep learning","machine learning"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T15:40:38.116105Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3b9699a1c56","title":"Can Representation Gaps Be the Key to Enhancing Robustness in Graph","content":"arXiv:2510.12087v1 Announce Type: new Abstract: Representation learning on text-attributed graphs (TAGs) integrates structural connectivity with rich textual semantics, enabling applications in diverse domains. Current methods largely rely on contrastive learning to maximize cross-modal similarity, assuming tighter coupling between graph and text representations improves transfer performance. However, our empirical analysis reveals that both natural gap expansion and forced gap reduction result in performance degradation by disrupting pre-trained knowledge structures and impairing generalization. This arises from the geometric incompatibility between encoders, where graph encoders capture topological patterns, while text encoders capture semantic structures. Over-alignment compresses these distinct spaces into shared subspaces, causing structure collapse that diminishes both topological reasoning and semantic understanding. We propose \\textbf{LLM4GTA}, a gap-aware alignment framework that preserves representation gaps as geometric necessities for maintaining modality-specific knowledge and improving transfer performance. LLM4GTA includes an adaptive gap preservation module to prevent over-alignment by monitoring similarity evolution and an intra-modal compensation mechanism that boosts discriminative power using auxiliary classifiers in graph space. Extensive experiments show significant improvements over existing methods in zero-shot and few-shot scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12087","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.283447","language":"en","tags":["preprints","computer-science","research","csgr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Heng Zhang, Tianyi Zhang, Yuling Shi, Xiaodong Gu, Yaomin Shen, Zijian Zhang, Yilei Yuan, Hao Zhang, Jin Huang","raw_content_length":1483,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1482,"language_detected":"en","key_concepts":{"key_phrases":["Representation Gaps","the Key","Robustness","Graph","arXiv251012087v1 Announce Type","new Abstract","Representation","text-attributed graphs","TAGs","structural connectivity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Representation Gaps":2.0,"the Key":2.0,"Robustness":2.0,"Graph":2.0,"arXiv251012087v1 Announce Type":1.0,"new Abstract":1.0,"Representation":1.0,"text-attributed graphs":1.0,"TAGs":1.0,"structural connectivity":1.0}},"age_hours":2.7389274766666665,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8367,"joy":0.0525,"surprise":0.0377,"sadness":0.0047,"fear":0.0142,"anger":0.0261,"disgust":0.028},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method (LLM4GTA) for representation learning on text-attributed graphs. While it shows 'significant improvements over existing methods in zero-shot and few-shot scenarios', it is still in the research phase with no deployed units or real-world applications. The potential climate impact is indirect, relying on downstream applications in areas like energy efficiency or resource management.","key_impact_metrics":["Improvements over existing methods in zero-shot and few-shot scenarios"],"technology_tags":["Graph Neural Networks","Contrastive Learning","Representation Learning","LLM"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:40:41.301644Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fe259cf46e50","title":"One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration","content":"arXiv:2510.12088v1 Announce Type: new Abstract: Symbolic world modeling requires inferring and representing an environment's transitional dynamics as an executable program. Prior work has focused on largely deterministic environments with abundant interaction data, simple mechanics, and human guidance. We address a more realistic and challenging setting, learning in a complex, stochastic environment where the agent has only \"one life\" to explore a hostile environment without human guidance. We introduce OneLife, a framework that models world dynamics through conditionally-activated programmatic laws within a probabilistic programming framework. Each law operates through a precondition-effect structure, activating in relevant world states. This creates a dynamic computation graph that routes inference and optimization only through relevant laws, avoiding scaling challenges when all laws contribute to predictions about a complex, hierarchical state, and enabling the learning of stochastic dynamics even with sparse rule activation. To evaluate our approach under these demanding constraints, we introduce a new evaluation protocol that measures (a) state ranking, the ability to distinguish plausible future states from implausible ones, and (b) state fidelity, the ability to generate future states that closely resemble reality. We develop and evaluate our framework on Crafter-OO, our reimplementation of the Crafter environment that exposes a structured, object-oriented symbolic state and a pure transition function that operates on that state alone. OneLife can successfully learn key environment dynamics from minimal, unguided interaction, outperforming a strong baseline on 16 out of 23 scenarios tested. We also test OneLife's planning ability, with simulated rollouts successfully identifying superior strategies. Our work establishes a foundation for autonomously constructing programmatic world models of unknown, complex environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12088","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.283903","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":262,"author":"Zaid Khan, Archiki Prasad, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal","raw_content_length":1962,"priority":7,"update_frequency":1,"reading_time_minutes":1.31,"robust_parsing_used":true,"entities":{"organizations":["Unguided Exploration arXiv:2510.12088v1 Announce Type"],"persons":["Symbolic"],"locations":[],"monetary":[]},"char_count":1961,"language_detected":"en","key_concepts":{"key_phrases":["One Life","Inferring Symbolic World Models","Stochastic Environments","Unguided Exploration","human guidance","arXiv251012088v1 Announce Type","new Abstract","Symbolic world modeling","an environments transitional dynamics","an executable program"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"One Life":2.0,"Inferring Symbolic World Models":2.0,"Stochastic Environments":2.0,"Unguided Exploration":2.0,"human guidance":2.0,"arXiv251012088v1 Announce Type":1.0,"new Abstract":1.0,"Symbolic world modeling":1.0,"an environments transitional dynamics":1.0,"an executable program":1.0}},"age_hours":2.738941813055556,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7765,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7553,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9097,"joy":0.035,"surprise":0.0293,"sadness":0.0041,"fear":0.0109,"anger":0.0079,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new framework for AI agents to learn world dynamics in complex environments. While the research is promising, it is currently in the basic research phase with no deployed technology or measured outcomes related to climate change. The framework's potential for sustainability is theoretical at this stage.","key_impact_metrics":["State ranking success rate","State fidelity score"],"technology_tags":["AI","Reinforcement Learning","World Modeling","Probabilistic Programming"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:44.426664Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4d8b24c4c10c","title":"Playmate2: Training-Free Multi","content":"arXiv:2510.12089v1 Announce Type: new Abstract: Recent advances in diffusion models have significantly improved audio-driven human video generation, surpassing traditional methods in both quality and controllability. However, existing approaches still face challenges in lip-sync accuracy, temporal coherence for long video generation, and multi-character animation. In this work, we propose a diffusion transformer (DiT)-based framework for generating lifelike talking videos of arbitrary length, and introduce a training-free method for multi-character audio-driven animation. First, we employ a LoRA-based training strategy combined with a position shift inference approach, which enables efficient long video generation while preserving the capabilities of the foundation model. Moreover, we combine partial parameter updates with reward feedback to enhance both lip synchronization and natural body motion. Finally, we propose a training-free approach, Mask Classifier-Free Guidance (Mask-CFG), for multi-character animation, which requires no specialized datasets or model modifications and supports audio-driven animation for three or more characters. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches, achieving high-quality, temporally coherent, and multi-character audio-driven video generation in a simple, efficient, and cost-effective manner.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12089","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.284306","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Xingpei Ma, Shenneng Huang, Jiaran Cai, Yuansheng Guan, Shen Zheng, Hanfeng Zhao, Qiang Zhang, Shunsi Zhang","raw_content_length":1404,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["LoRA","Training-Free Multi arXiv:2510.12089v1 Announce Type"],"persons":["Classi"],"locations":[],"monetary":[]},"char_count":1403,"language_detected":"en","key_concepts":{"key_phrases":["Playmate2","Training-Free Multi","new Abstract","Recent advances","diffusion models","audio-driven human video generation","traditional methods","both quality","controllability","existing approaches"],"filter_categories":{"ai_ml":["Training-Free Multi"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Playmate2":2.0,"Training-Free Multi":2.0,"new Abstract":1.0,"Recent advances":1.0,"diffusion models":1.0,"audio-driven human video generation":1.0,"traditional methods":1.0,"both quality":1.0,"controllability":1.0,"existing approaches":1.0}},"age_hours":2.7389565005555556,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8373,"joy":0.0211,"surprise":0.0148,"sadness":0.0059,"fear":0.073,"anger":0.0298,"disgust":0.0181},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for generating lifelike talking videos, but its direct impact on sustainability is minimal. While it claims to be cost-effective, there are no specific metrics or deployment data to support its economic viability or environmental benefit. The research is still in the applied research phase with no deployed units.","key_impact_metrics":["High-quality video generation","Temporally coherent video generation"],"technology_tags":["Diffusion Models","Audio-driven animation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:40:47.665400Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_390d9e46030d","title":"Translating Milli/Microrobots with A Value","content":"arXiv:2510.12090v1 Announce Type: new Abstract: Untethered mobile milli/microrobots hold transformative potential for interventional medicine by enabling more precise and entirely non-invasive diagnosis and therapy. Realizing this promise requires bridging the gap between groundbreaking laboratory demonstrations and successful clinical integration. Despite remarkable technical progress over the past two decades, most millirobots and microrobots remain confined to laboratory proof-of-concept demonstrations, with limited real-world feasibility. In this Review, we identify key factors that slow translation from bench to bedside, focusing on the disconnect between technical innovation and real-world application. We argue that the long-term impact and sustainability of the field depend on aligning development with unmet medical needs, ensuring applied feasibility, and integrating seamlessly into existing clinical workflows, which are essential pillars for delivering meaningful patient outcomes. To support this shift, we introduce a strategic milli/microrobot Technology Readiness Level framework (mTRL), which maps system development from initial conceptualization to clinical adoption through clearly defined milestones and their associated stepwise activities. The mTRL model provides a structured gauge of technological maturity, a common language for cross-disciplinary collaboration and actionable guidance to accelerate translational development toward new, safer and more efficient interventions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12090","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.284733","language":"en","tags":["csro","preprints","computer-science","research","cset","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Hakan Ceylan, Edoardo Sinibaldi, Sanjay Misra, Pankaj J. Pasricha, Dietmar W. Hutmacher","raw_content_length":1515,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1514,"language_detected":"en","key_concepts":{"key_phrases":["MilliMicrorobots","A Value","arXiv251012090v1","Announce Type","new Abstract","Untethered mobile millimicrorobots","transformative potential","interventional medicine","more precise and entirely non-invasive diagnosis","therapy"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MilliMicrorobots":2.0,"A Value":2.0,"arXiv251012090v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Untethered mobile millimicrorobots":1.0,"transformative potential":1.0,"interventional medicine":1.0,"more precise and entirely non-invasive diagnosis":1.0,"therapy":1.0}},"age_hours":2.738970894722222,"is_recent":true,"quality_score":0.7,"sentiment_score":7.763999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5528,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7435,"joy":0.0318,"surprise":0.0318,"sadness":0.0063,"fear":0.1407,"anger":0.0305,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article discusses milli/microrobots for medical applications, focusing on translating lab demonstrations to clinical use. While the technology has potential for less invasive procedures, it is currently in the early stages of research and development with limited real-world deployment. The article proposes a framework to accelerate translation, but lacks concrete actions or measurable outcomes in terms of sustainability.","key_impact_metrics":[],"technology_tags":["microrobotics","medical robotics"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:40:50.499754Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_04ffd707f726","title":"ToPolyAgent: AI Agents for Coarse","content":"arXiv:2510.12091v1 Announce Type: new Abstract: We introduce ToPolyAgent, a multi-agent AI framework for performing coarse-grained molecular dynamics (MD) simulations of topological polymers through natural language instructions. By integrating large language models (LLMs) with domain-specific computational tools, ToPolyAgent supports both interactive and autonomous simulation workflows across diverse polymer architectures, including linear, ring, brush, and star polymers, as well as dendrimers. The system consists of four LLM-powered agents: a Config Agent for generating initial polymer-solvent configurations, a Simulation Agent for executing LAMMPS-based MD simulations and conformational analyses, a Report Agent for compiling markdown reports, and a Workflow Agent for streamlined autonomous operations. Interactive mode incorporates user feedback loops for iterative refinements, while autonomous mode enables end-to-end task execution from detailed prompts. We demonstrate ToPolyAgent's versatility through case studies involving diverse polymer architectures under varying solvent condition, thermostats, and simulation lengths. Furthermore, we highlight its potential as a research assistant by directing it to investigate the effect of interaction parameters on the linear polymer conformation, and the influence of grafting density on the persistence length of the brush polymer. By coupling natural language interfaces with rigorous simulation tools, ToPolyAgent lowers barriers to complex computational workflows and advances AI-driven materials discovery in polymer science. It lays the foundation for autonomous and extensible multi-agent scientific research ecosystems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12091","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.285862","language":"en","tags":["preprints","csai","computer-science","cond-matsoft","research","cond-matmtrl-sci","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Lijie Ding, Jan-Michael Carrillo, Changwoo Do","raw_content_length":1693,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["LAMMPS","linear"],"persons":["Config"],"locations":[],"monetary":[]},"char_count":1692,"language_detected":"en","key_concepts":{"key_phrases":["ToPolyAgent","AI Agents","Coarse","arXiv251012091v1 Announce Type","new Abstract","a multi-agent AI framework","topological polymers","natural language instructions","large language models","LLMs"],"filter_categories":{"ai_ml":["AI Agents","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ToPolyAgent":4.0,"AI Agents":2.0,"Coarse":2.0,"arXiv251012091v1 Announce Type":1.0,"new Abstract":1.0,"a multi-agent AI framework":1.0,"topological polymers":1.0,"natural language instructions":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7389860141666666,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9206,"joy":0.0189,"surprise":0.035,"sadness":0.0025,"fear":0.0076,"anger":0.0104,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new AI framework for molecular dynamics simulations, which could accelerate materials discovery, including polymers with potential applications in sustainability (e.g., lightweighting, biodegradable materials). However, it is currently in the basic research stage with no deployed technology or measured outcomes related to environmental impact. The technical credibility is relatively high due to the integration of LLMs with domain-specific tools and the potential for peer review.","key_impact_metrics":[],"technology_tags":["AI","Molecular Dynamics","Polymer Science","Materials Discovery"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:40:54.058462Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aeb9e0730d86","title":"H4G: Unlocking Faithful Inference for Zero","content":"arXiv:2510.12094v1 Announce Type: new Abstract: Text-attributed graphs are widely used across domains, offering rich opportunities for zero-shot learning via graph-text alignment. However, existing methods struggle with tasks requiring fine-grained pattern recognition, particularly on heterophilic graphs. Through empirical and theoretical analysis, we identify an \\textbf{over-abstraction problem}: current approaches operate at excessively large hyperbolic radii, compressing multi-scale structural information into uniform high-level abstractions. This abstraction-induced information loss obscures critical local patterns essential for accurate predictions. By analyzing embeddings in hyperbolic space, we demonstrate that optimal graph learning requires \\textbf{faithful preservation} of fine-grained structural details, better retained by representations positioned closer to the origin. To address this, we propose \\textbf{H4G}, a framework that systematically reduces embedding radii using learnable block-diagonal scaling matrices and M\\\"obius matrix multiplication. This approach restores access to fine-grained patterns while maintaining global receptive ability with minimal computational overhead. Experiments show H4G achieves state-of-the-art zero-shot performance with \\textbf{12.8\\%} improvement on heterophilic graphs and \\textbf{8.4\\%} on homophilic graphs, confirming that radius reduction enables faithful multi-scale representation for advancing zero-shot graph learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12094","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.286287","language":"en","tags":["preprints","computer-science","cslg","research","csgr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Heng Zhang, Tianyi Zhang, Zijun Liu, Yuling Shi, Yaomin Shen, Haochen You, Haichuan Hu, Lubin Gan, Jin Huang","raw_content_length":1495,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1494,"language_detected":"en","key_concepts":{"key_phrases":["H4G","Unlocking Faithful Inference","Zero","arXiv251012094v1 Announce Type","new Abstract","Text-attributed graphs","domains","rich opportunities","zero-shot learning","graph-text alignment"],"filter_categories":{"ai_ml":["Unlocking Faithful Inference"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"H4G":2.0,"Unlocking Faithful Inference":2.0,"Zero":2.0,"arXiv251012094v1 Announce Type":1.0,"new Abstract":1.0,"Text-attributed graphs":1.0,"domains":1.0,"rich opportunities":1.0,"zero-shot learning":1.0,"graph-text alignment":1.0}},"age_hours":2.7390004955555556,"is_recent":true,"quality_score":0.7,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8858,"joy":0.0164,"surprise":0.0309,"sadness":0.0115,"fear":0.0221,"anger":0.0216,"disgust":0.0117},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (H4G) for improving zero-shot graph learning, demonstrating a 12.8% improvement on heterophilic graphs and 8.4% on homophilic graphs. While the research is promising, it is currently in the basic research stage with no deployed applications or economic viability demonstrated. The potential climate impact is indirect, as improved graph learning could potentially optimize various sustainability-related processes, but this is not explicitly addressed or quantified.","key_impact_metrics":["12.8% improvement on heterophilic graphs","8.4% improvement on homophilic graphs"],"technology_tags":["zero-shot learning","graph neural networks","hyperbolic embeddings"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:40:57.501905Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_332c3584e6d8","title":"IL3D: A Large","content":"arXiv:2510.12095v1 Announce Type: new Abstract: In this study, we present IL3D, a large-scale dataset meticulously designed for large language model (LLM)-driven 3D scene generation, addressing the pressing demand for diverse, high-quality training data in indoor layout design. Comprising 27,816 indoor layouts across 18 prevalent room types and a library of 29,215 high-fidelity 3D object assets, IL3D is enriched with instance-level natural language annotations to support robust multimodal learning for vision-language tasks. We establish rigorous benchmarks to evaluate LLM-driven scene generation. Experimental results show that supervised fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and surpasses the performance of SFT on other datasets. IL3D offers flexible multimodal data export capabilities, including point clouds, 3D bounding boxes, multiview images, depth maps, normal maps, and semantic masks, enabling seamless adaptation to various visual tasks. As a versatile and robust resource, IL3D significantly advances research in 3D scene generation and embodied intelligence, by providing high-fidelity scene data to support environment perception tasks of embodied agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12095","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.286731","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Wenxu Zhou, Kaixuan Nie, Hang Du, Dong Yin, Wei Huang, Siqiang Guo, Xiaobo Zhang, Pengbo Hu","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["SFT"],"persons":["IL3D"],"locations":[],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["IL3D","arXiv251012095v1 Announce Type","new Abstract","this study","a large-scale dataset","large language model","LLM-driven 3D scene generation","the pressing demand","diverse high-quality training data","indoor layout design"],"filter_categories":{"research_academic":["this study"],"ai_ml":["large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"IL3D":4.0,"arXiv251012095v1 Announce Type":1.0,"new Abstract":1.0,"this study":1.0,"a large-scale dataset":1.0,"large language model":1.0,"LLM-driven 3D scene generation":1.0,"the pressing demand":1.0,"diverse high-quality training data":1.0,"indoor layout design":1.0}},"age_hours":2.7390158777777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5992,"joy":0.2162,"surprise":0.1557,"sadness":0.0078,"fear":0.0071,"anger":0.0108,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a large-scale dataset (IL3D) for LLM-driven 3D scene generation, which could indirectly contribute to sustainability by improving the efficiency of building design and resource allocation. However, the direct climate impact is minimal at this stage, as it's primarily a dataset and benchmark. The vaporware risk is present as it's an early-stage concept without deployed units.","key_impact_metrics":["27,816 indoor layouts","29,215 high-fidelity 3D object assets"],"technology_tags":["large language models","3D scene generation","indoor layout design"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T15:41:01.169453Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2fb915d156c2","title":"Rethinking the Role of Dynamic Sparse Training for Scalable Deep Reinforcement Learning","content":"arXiv:2510.12096v1 Announce Type: new Abstract: Scaling neural networks has driven breakthrough advances in machine learning, yet this paradigm fails in deep reinforcement learning (DRL), where larger models often degrade performance due to unique optimization pathologies such as plasticity loss. While recent works show that dynamically adapting network topology during training can mitigate these issues, existing studies have three critical limitations: (1) applying uniform dynamic training strategies across all modules despite encoder, critic, and actor following distinct learning paradigms, (2) focusing evaluation on basic architectures without clarifying the relative importance and interaction between dynamic training and architectural improvements, and (3) lacking systematic comparison between different dynamic approaches including sparse-to-sparse, dense-to-sparse, and sparse-to-dense. Through comprehensive investigation across modules and architectures, we reveal that dynamic sparse training strategies provide module-specific benefits that complement the primary scalability foundation established by architectural improvements. We finally distill these insights into Module-Specific Training (MST), a practical framework that further exploits the benefits of architectural improvements and demonstrates substantial scalability gains across diverse RL algorithms without algorithmic modifications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12096","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.287134","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Guozheng Ma, Lu Li, Zilin Wang, Haoyu Wang, Shengchao Hu, Leszek Rutkowski, Dacheng Tao","raw_content_length":1420,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["DRL"],"persons":[],"locations":[],"monetary":[]},"char_count":1419,"language_detected":"en","key_concepts":{"key_phrases":["the Role","Scalable Deep Reinforcement Learning","arXiv251012096v1 Announce Type","new Abstract","Scaling neural networks","breakthrough advances","machine learning","this paradigm","deep reinforcement learning","DRL"],"filter_categories":{"ai_ml":["Scalable Deep Reinforcement Learning","Scaling neural networks","machine learning","deep reinforcement learning"],"research_academic":["breakthrough advances"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Role":2.0,"Scalable Deep Reinforcement Learning":2.0,"arXiv251012096v1 Announce Type":1.0,"new Abstract":1.0,"Scaling neural networks":1.0,"breakthrough advances":1.0,"machine learning":1.0,"this paradigm":1.0,"deep reinforcement learning":1.0,"DRL":1.0}},"age_hours":2.7390304913888888,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7668,"joy":0.0054,"surprise":0.0348,"sadness":0.0583,"fear":0.0244,"anger":0.0409,"disgust":0.0694},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the scalability of deep reinforcement learning through dynamic sparse training. While the research aims to improve the efficiency of AI models, which could indirectly reduce energy consumption, it is currently in the basic research phase with no deployed technology or measured outcomes. The vaporware flag is raised because it is an early-stage concept without deployment.","key_impact_metrics":[],"technology_tags":["Deep Reinforcement Learning","Dynamic Sparse Training","AI Efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:41:03.972084Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a03c55c46b93","title":"An Adaptive Edge","content":"arXiv:2510.12098v1 Announce Type: new Abstract: Unlike general image deblurring that prioritizes perceptual quality, QR code deblurring focuses on ensuring successful decoding. QR codes are characterized by highly structured patterns with sharp edges, a robust prior for restoration. Yet existing deep learning methods rarely exploit these priors explicitly. To address this gap, we propose the Edge-Guided Attention Block (EGAB), which embeds explicit edge priors into a Transformer architecture. Based on EGAB, we develop Edge-Guided Restormer (EG-Restormer), an effective network that significantly boosts the decoding rate of severely blurred QR codes. For mildly blurred inputs, we design the Lightweight and Efficient Network (LENet) for fast deblurring. We further integrate these two networks into an Adaptive Dual-network (ADNet), which dynamically selects the suitable network based on input blur severity, making it ideal for resource-constrained mobile devices. Extensive experiments show that our EG-Restormer and ADNet achieve state-of-the-art performance with a competitive speed. Project page: https://github.com/leejianping/ADNet","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12098","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.287519","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Jianping Li, Dongyang Guo, Wenjie Li, Wei Zhao","raw_content_length":1147,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Edge-Guided Restormer","EGAB","the Edge-Guided Attention Block (EGAB","Transformer"],"persons":[],"locations":[],"monetary":[]},"char_count":1146,"language_detected":"en","key_concepts":{"key_phrases":["An Adaptive Edge","Announce Type","new Abstract","general image","perceptual quality","QR code deblurring","successful decoding","QR codes","highly structured patterns","sharp edges"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Adaptive Edge":2.0,"Announce Type":1.0,"new Abstract":1.0,"general image":1.0,"perceptual quality":1.0,"QR code deblurring":1.0,"successful decoding":1.0,"QR codes":1.0,"highly structured patterns":1.0,"sharp edges":1.0}},"age_hours":2.7390455486111107,"is_recent":true,"quality_score":1.0,"sentiment_score":8.452,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6904,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9389,"joy":0.0051,"surprise":0.0362,"sadness":0.0039,"fear":0.0026,"anger":0.0078,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to QR code deblurring using edge-guided attention, which could potentially reduce energy consumption by improving the efficiency of QR code scanning on mobile devices. However, the impact on climate change is minimal and unproven, as it's primarily focused on improving image processing rather than directly addressing GHG emissions. The technology is in the applied research stage, with no mention of deployment or commercialization.","key_impact_metrics":["Decoding rate of severely blurred QR codes","Competitive speed"],"technology_tags":["Image deblurring","QR code scanning","Transformer architecture"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:07.034633Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d44c703354e5","title":"G4Splat: Geometry","content":"arXiv:2510.12099v1 Announce Type: new Abstract: Despite recent advances in leveraging generative prior from pre-trained diffusion models for 3D scene reconstruction, existing methods still face two critical limitations. First, due to the lack of reliable geometric supervision, they struggle to produce high-quality reconstructions even in observed regions, let alone in unobserved areas. Second, they lack effective mechanisms to mitigate multi-view inconsistencies in the generated images, leading to severe shape-appearance ambiguities and degraded scene geometry. In this paper, we identify accurate geometry as the fundamental prerequisite for effectively exploiting generative models to enhance 3D scene reconstruction. We first propose to leverage the prevalence of planar structures to derive accurate metric-scale depth maps, providing reliable supervision in both observed and unobserved regions. Furthermore, we incorporate this geometry guidance throughout the generative pipeline to improve visibility mask estimation, guide novel view selection, and enhance multi-view consistency when inpainting with video diffusion models, resulting in accurate and consistent scene completion. Extensive experiments on Replica, ScanNet++, and DeepBlending show that our method consistently outperforms existing baselines in both geometry and appearance reconstruction, particularly for unobserved regions. Moreover, our method naturally supports single-view inputs and unposed videos, with strong generalizability in both indoor and outdoor scenarios with practical real-world applicability. The project page is available at https://dali-jack.github.io/g4splat-web/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12099","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.287954","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Junfeng Ni, Yixin Chen, Zhifei Yang, Yu Liu, Ruijie Lu, Song-Chun Zhu, Siyuan Huang","raw_content_length":1668,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1667,"language_detected":"en","key_concepts":{"key_phrases":["G4Splat","Geometry","arXiv251012099v1 Announce Type","new Abstract","recent advances","pre-trained diffusion models","3D scene reconstruction","existing methods","two critical limitations","the lack"],"filter_categories":{"ai_ml":["pre-trained diffusion models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"G4Splat":2.0,"Geometry":2.0,"arXiv251012099v1 Announce Type":1.0,"new Abstract":1.0,"recent advances":1.0,"pre-trained diffusion models":1.0,"3D scene reconstruction":1.0,"existing methods":1.0,"two critical limitations":1.0,"the lack":1.0}},"age_hours":2.7390601497222224,"is_recent":true,"quality_score":0.7,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8432,"joy":0.0042,"surprise":0.0255,"sadness":0.0514,"fear":0.0265,"anger":0.0229,"disgust":0.0262},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for 3D scene reconstruction using generative models and planar structure detection. While the method shows improved geometry and appearance reconstruction on datasets like Replica and ScanNet++, it remains in the applied research stage with no real-world deployment data. The climate impact is indirect, potentially enabling more efficient design or analysis of sustainable infrastructure in the future, but not directly reducing emissions.","key_impact_metrics":["Improved geometry reconstruction in unobserved regions","Outperforms existing baselines in geometry and appearance reconstruction"],"technology_tags":["3D scene reconstruction","Generative models","Computer vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:11.433186Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a1faa188ed64","title":"Gaussian Semantic Field for One","content":"arXiv:2510.12101v1 Announce Type: new Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic disambiguation ability based on a lightweight tri-layered scene graph. While landmark semantic registration-based methods have shown promising performance improvements in global localization compared with geometric-only methods, landmarks can be repetitive and misleading for correspondence establishment. We propose to mitigate this problem by modeling semantic distributions with continuous functions learned from a population of Gaussian processes. Compared with discrete semantic labels, the continuous functions capture finer-grained geo-semantic information and also provide more detailed metric information for correspondence establishment. We insert this continuous function as the middle layer between the object layer and the metric-semantic layer, forming a tri-layered 3D scene graph, serving as a light-weight yet performant backend for one-shot localization. We term our global localization pipeline Outram-GSF (Gaussian semantic field) and conduct a wide range of experiments on publicly available data sets, validating the superior performance against the current state-of-the-art.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12101","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.288337","language":"en","tags":["csro","preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Pengyu Yin, Shenghai Yuan, Haozhi Cao, Xingyu Ji, Ruofei Bai, Siyu Chen, Lihua Xie","raw_content_length":1223,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Gaussian Semantic Field"],"persons":[],"locations":[],"monetary":[]},"char_count":1222,"language_detected":"en","key_concepts":{"key_phrases":["Gaussian Semantic Field","arXiv251012101v1 Announce Type","new Abstract","a one-shot LiDAR global localization algorithm","semantic disambiguation ability","a lightweight tri-layered scene graph","While landmark semantic registration-based methods","promising performance improvements","global localization","geometric-only methods"],"filter_categories":{"ai_ml":["a one-shot LiDAR global localization algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gaussian Semantic Field":2.0,"arXiv251012101v1 Announce Type":1.0,"new Abstract":1.0,"a one-shot LiDAR global localization algorithm":1.0,"semantic disambiguation ability":1.0,"a lightweight tri-layered scene graph":1.0,"While landmark semantic registration-based methods":1.0,"promising performance improvements":1.0,"global localization":1.0,"geometric-only methods":1.0}},"age_hours":2.7390738966666666,"is_recent":true,"quality_score":1.0,"sentiment_score":4.71,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.058,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7728,"joy":0.0072,"surprise":0.0055,"sadness":0.0174,"fear":0.0909,"anger":0.0538,"disgust":0.0523},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel LiDAR global localization algorithm, which could potentially improve the efficiency of autonomous vehicles and robots. However, it is currently in the applied research stage, with no evidence of deployment or quantified environmental benefits. The vaporware flag is raised due to the lack of deployed units or operational data.","key_impact_metrics":[],"technology_tags":["LiDAR","global localization","semantic mapping"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:14.176895Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_281329faa205","title":"SpikePool: Event","content":"arXiv:2510.12102v1 Announce Type: new Abstract: Building on the success of transformers, Spiking Neural Networks (SNNs) have increasingly been integrated with transformer architectures, leading to spiking transformers that demonstrate promising performance on event-based vision tasks. However, despite these empirical successes, there remains limited understanding of how spiking transformers fundamentally process event-based data. Current approaches primarily focus on architectural modifications without analyzing the underlying signal processing characteristics. In this work, we analyze spiking transformers through the frequency spectrum domain and discover that they behave as high-pass filters, contrasting with Vision Transformers (ViTs) that act as low-pass filters. This frequency domain analysis reveals why certain designs work well for event-based data, which contains valuable high-frequency information but is also sparse and noisy. Based on this observation, we propose SpikePool, which replaces spike-based self-attention with max pooling attention, a low-pass filtering operation, to create a selective band-pass filtering effect. This design preserves meaningful high-frequency content while capturing critical features and suppressing noise, achieving a better balance for event-based data processing. Our approach demonstrates competitive results on event-based datasets for both classification and object detection tasks while significantly reducing training and inference time by up to 42.5% and 32.8%, respectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12102","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.288756","language":"en","tags":["preprints","computer-science","csne","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Donghyun Lee, Alex Sima, Yuhang Li, Panos Stinis, Priyadarshini Panda","raw_content_length":1542,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Spiking Neural Networks","Vision Transformers"],"persons":[],"locations":[],"monetary":[]},"char_count":1541,"language_detected":"en","key_concepts":{"key_phrases":["SpikePool","Event","spiking transformers","arXiv251012102v1 Announce Type","new Abstract","the success","transformers","Spiking Neural Networks","SNNs","transformer architectures"],"filter_categories":{"ai_ml":["spiking transformers","transformers","Spiking Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SpikePool":2.0,"Event":2.0,"spiking transformers":2.0,"arXiv251012102v1 Announce Type":1.0,"new Abstract":1.0,"the success":1.0,"transformers":1.0,"Spiking Neural Networks":1.0,"SNNs":1.0,"transformer architectures":1.0}},"age_hours":2.7390877347222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.768999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5538,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.865,"joy":0.0197,"surprise":0.0822,"sadness":0.0082,"fear":0.0092,"anger":0.0108,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (SpikePool) to improve the efficiency of spiking neural networks for event-based data processing. The concrete action is the proposal and evaluation of a new neural network architecture. The evidence supporting the claims includes competitive results on event-based datasets and a reported reduction in training and inference time.","key_impact_metrics":["training time reduction by 42.5%","inference time reduction by 32.8%"],"technology_tags":["spiking neural networks","event-based vision","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:18.075238Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b95801b6613","title":"DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning","content":"arXiv:2510.12107v1 Announce Type: new Abstract: With the excellent representation capabilities of Pre-Trained Models (PTMs), remarkable progress has been made in non-rehearsal Class-Incremental Learning (CIL) research. However, it remains an extremely challenging task due to three conundrums: increasingly large model complexity, non-smooth representation shift during incremental learning and inconsistency between stage-wise sub-problem optimization and global inference. In this work, we propose the Discriminative Representation Learning (DRL) framework to specifically address these challenges. To conduct incremental learning effectively and yet efficiently, the DRL's network, called Incremental Parallel Adapter (IPA) network, is built upon a PTM and increasingly augments the model by learning a lightweight adapter with a small amount of parameter learning overhead in each incremental stage. The adapter is responsible for adapting the model to new classes, it can inherit and propagate the representation capability from the current model through parallel connection between them by a transfer gate. As a result, this design guarantees a smooth representation shift between different incremental stages. Furthermore, to alleviate inconsistency and enable comparable feature representations across incremental stages, we design the Decoupled Anchor Supervision (DAS). It decouples constraints of positive and negative samples by respectively comparing them with the virtual anchor. This decoupling promotes discriminative representation learning and aligns the feature spaces learned at different stages, thereby narrowing the gap between stage-wise local optimization over a subset of data and global inference across all classes. Extensive experiments on six benchmarks reveal that our DRL consistently outperforms other state-of-the-art methods throughout the entire CIL period while maintaining high efficiency in both training and inference phases.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12107","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.289177","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":259,"author":"Jiawei Zhan, Jun Liu, Jinlong Peng, Xiaochen Chen, Bin-Bin Gao, Yong Liu, Chengjie Wang","raw_content_length":1966,"priority":7,"update_frequency":1,"reading_time_minutes":1.295,"robust_parsing_used":true,"entities":{"organizations":["Class-Incremental Learning","Incremental Parallel Adapter","the Discriminative Representation Learning","IPA","Pre-Trained Models","PTM","DRL"],"persons":[],"locations":[],"monetary":[]},"char_count":1965,"language_detected":"en","key_concepts":{"key_phrases":["DRL","Discriminative Representation Learning","Parallel Adapters","Class Incremental Learning","new Abstract","the excellent representation capabilities","Pre-Trained Models","PTMs","remarkable progress","non-rehearsal Class-Incremental Learning CIL research"],"filter_categories":{"ai_ml":["Pre-Trained Models"],"research_academic":["non-rehearsal Class-Incremental Learning CIL research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DRL":2.0,"Discriminative Representation Learning":2.0,"Parallel Adapters":2.0,"Class Incremental Learning":2.0,"new Abstract":1.0,"the excellent representation capabilities":1.0,"Pre-Trained Models":1.0,"PTMs":1.0,"remarkable progress":1.0,"non-rehearsal Class-Incremental Learning CIL research":1.0}},"age_hours":2.739102736111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.499500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8999,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6227,"joy":0.0254,"surprise":0.2487,"sadness":0.0098,"fear":0.0396,"anger":0.0417,"disgust":0.012},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning framework (DRL) for class-incremental learning, potentially improving the efficiency of AI models. The concrete action is the development of a new algorithm (IPA network) and training method (DAS). Evidence includes extensive experiments on six benchmarks showing improved performance, but it remains in the research phase with no real-world deployment.","key_impact_metrics":["Parameter learning overhead","Performance on six benchmarks"],"technology_tags":["Machine Learning","Class-Incremental Learning","Pre-Trained Models","Adapter Networks"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:41:21.032223Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8d2654c7a96b","title":"Chimera: State Space Models Beyond Sequences","content":"arXiv:2510.12111v1 Announce Type: new Abstract: Transformer-based deep learning methods have become the standard approach for modeling diverse data such as sequences, images, and graphs. These methods rely on self-attention, which treats data as an unordered set of elements. This ignores the neighborhood structure or graph topology of the data and requires inductive biases--such as position embeddings in sequences and images, or random walks in graphs--to incorporate topology. However, designing such task-specific biases requires significant effort and can introduce side effects that hinder generalization. We introduce Chimera, a unified model that directly incorporates data topology in a principled way, removing the need for domain-specific biases. The key idea is that state space models--which naturally do not require position embeddings--can be generalized to capture any graph topology. Our experiments show that Chimera achieves strong performance across language, vision, and graph domains, outperforming BERT on GLUE by 0.7 points, ViT on ImageNet-1k by 2.6%, and all baselines on the Long Range Graph Benchmark. We further propose algorithmic optimizations to improve Chimera's efficiency: (1) for Directed Acyclic Graphs, Chimera can be implemented as a linear-time recurrence; (2) for general graphs, a simple mathematical relaxation achieves Transformer's quadratic complexity without domain-specific heuristics. These results validate Chimera's core contribution and support the idea that data topology is a powerful inductive bias across modalities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12111","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.290347","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Aakash Lahoti, Tanya Marwah, Ratish Puduppully, Albert Gu","raw_content_length":1575,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["Chimera"],"persons":[],"locations":[],"monetary":[]},"char_count":1574,"language_detected":"en","key_concepts":{"key_phrases":["Chimera","State Space Models","Sequences","sequences","images","graphs","topology","arXiv251012111v1 Announce Type","new Abstract","Transformer-based deep learning methods"],"filter_categories":{"ai_ml":["Transformer-based deep learning methods"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chimera":2.0,"State Space Models":2.0,"Sequences":2.0,"sequences":2.0,"images":2.0,"graphs":2.0,"topology":2.0,"arXiv251012111v1 Announce Type":1.0,"new Abstract":1.0,"Transformer-based deep learning methods":1.0}},"age_hours":2.739148709722222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.327,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3346,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8826,"joy":0.0083,"surprise":0.0566,"sadness":0.0067,"fear":0.0066,"anger":0.0206,"disgust":0.0187},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel deep learning model (Chimera) that aims to improve efficiency across various data types. While it shows performance improvements in language, vision, and graph domains, its direct impact on climate change mitigation is currently theoretical. The model is in the early research stage, lacking deployment and concrete evidence of reducing GHG emissions.","key_impact_metrics":["BERT improvement on GLUE by 0.7 points","ViT improvement on ImageNet-1k by 2.6%"],"technology_tags":["deep learning","state space models","graph neural networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:24.014188Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9efc2a090aa2","title":"Tight Quantum Time","content":"arXiv:2510.12112v1 Announce Type: new Abstract: In permutation inversion, we are given a permutation $\\pi : [N] \\rightarrow [N]$, and want to prepare some advice of size $S$, such that we can efficiently invert any image in time $T$. This is a fundamental cryptographic problem with profound connections to communication complexity and circuit lower bounds. In the classical setting, a tight $ST = \\tilde{\\Theta}(N)$ bound has been established since the seminal work of Hellman (1980) and Yao (1990). In the quantum setting, a lower bound of $ST^2 = \\tilde{\\Omega}(N)$ is proved by Nayebi, Aaronson, Belovs, and Trevisan (2015) against classical advice, and by Hhan, Xagawa and Yamakawa (2019) against quantum advice. It left open an intriguing possibility that Grover's search can be sped up to time $\\tilde{O}(\\sqrt{N / S})$. In this work, we prove an $ST + T^2 = \\Omega(N)$ lower bound for permutation inversion with even quantum advice. This bound matches the best known attacks and shows that Grover's search and the classical Hellman's algorithm cannot be further sped up. Our proof combines recent techniques by Liu (2023) and by Rosmanis (2022). Specifically, we first reduce the permutation inversion problem against quantum advice to a variant by Liu's technique, then we analyze this variant via representation theory inspired by Rosmanis (2022).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12112","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.292496","language":"en","tags":["cscc","preprints","csit","computer-science","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Akshima, Tyler Besselman, Kai-Min Chung, Siyao Guo, Tzu-Yi Yang","raw_content_length":1364,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["Tight Quantum Time arXiv:2510.12112v1"],"persons":["Trevisan","Grover","Yao","N]$"],"locations":["Yamakawa","Aaronson","Nayebi","Hhan","Hellman","Belovs"],"monetary":["\\tilde{O}(\\sqrt{N","ST^2","T$.","\\pi"]},"char_count":1357,"language_detected":"en","key_concepts":{"key_phrases":["Tight Quantum Time","new Abstract","permutation inversion","a permutation","N rightarrow","some advice","size","any image","time","a fundamental cryptographic problem"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tight Quantum Time":2.0,"new Abstract":1.0,"permutation inversion":1.0,"a permutation":1.0,"N rightarrow":1.0,"some advice":1.0,"size":1.0,"any image":1.0,"time":1.0,"a fundamental cryptographic problem":1.0}},"age_hours":2.73916536,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8716,"joy":0.0089,"surprise":0.0614,"sadness":0.007,"fear":0.0209,"anger":0.0191,"disgust":0.011},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This is theoretical research in quantum computing, specifically focused on permutation inversion. While it doesn't directly address climate change, advancements in computing could indirectly impact sustainability by enabling more efficient simulations or optimization algorithms for climate solutions. The research is at a very early stage and has no immediate deployment or measurable outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["quantum computing","cryptography"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:41:28.659874Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2372f52b8062","title":"KnowledgeTrail: Generative Timeline for Exploration and Sensemaking of Historical Events and Knowledge Formation","content":"arXiv:2510.12113v1 Announce Type: new Abstract: The landscape of interactive systems is shifting toward dynamic, generative experiences that empower users to explore and construct knowledge in real time. Yet, timelines -- a fundamental tool for representing historical and conceptual development -- remain largely static, limiting user agency and curiosity. We introduce the concept of a generative timeline: an AI-powered timeline that adapts to users' evolving questions by expanding or contracting in response to input. We instantiate this concept through KnowledgeTrail, a system that enables users to co-construct timelines of historical events and knowledge formation processes. Two user studies showed that KnowledgeTrail fosters curiosity-driven exploration, serendipitous discovery, and the ability to trace complex relationships between ideas and events, while citation features supported verification yet revealed fragile trust shaped by perceptions of source credibility. We contribute a vision for generative timelines as a new class of exploratory interface, along with design insights for balancing serendipity and credibility.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12113","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.292973","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Sangho Suh, Rahul Hingorani, Bryan Wang, Tovi Grossman","raw_content_length":1143,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["KnowledgeTrail"],"persons":[],"locations":[],"monetary":[]},"char_count":1142,"language_detected":"en","key_concepts":{"key_phrases":["KnowledgeTrail","Generative Timeline","Exploration","Sensemaking","Historical Events","Knowledge Formation","arXiv251012113v1 Announce Type","new Abstract","The landscape","interactive systems"],"filter_categories":{"ai_ml":["KnowledgeTrail"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"KnowledgeTrail":2.0,"Generative Timeline":2.0,"Exploration":2.0,"Sensemaking":2.0,"Historical Events":2.0,"Knowledge Formation":2.0,"arXiv251012113v1 Announce Type":1.0,"new Abstract":1.0,"The landscape":1.0,"interactive systems":1.0}},"age_hours":2.7391801169444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9055,"joy":0.0092,"surprise":0.0453,"sadness":0.0026,"fear":0.0182,"anger":0.0128,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a prototype system (KnowledgeTrail) and its evaluation through user studies. While it fosters curiosity and discovery, it does not directly address GHG emissions or climate adaptation. The impact on sustainability is indirect, potentially aiding in understanding complex relationships related to climate change, but there are no concrete actions or measurable outcomes related to sustainability at this stage.","key_impact_metrics":[],"technology_tags":["AI","Generative Timeline","Knowledge Exploration"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T15:41:32.488824Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_025e6b320e0e","title":"Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English","content":"arXiv:2510.12115v1 Announce Type: new Abstract: Multilingual domain adaptation (ML-DA) is widely used to learn new domain knowledge across languages into large language models (LLMs). Although many methods have been proposed to improve domain adaptation, the mechanisms of multilingual knowledge acquisition, how domain knowledge is learned within a language and transferred across languages, remain underexplored. This gap leads to suboptimal performance, particularly in low-resource settings. This work examines the learning dynamics of LLMs during ML-DA. Because prior ML-DA studies often train and evaluate on datasets with mismatched knowledge coverage, we propose AdaXEval, an adaptive evaluation method that builds multiple-choice QA datasets from the same bilingual domain corpus used for training, thereby directly studying multilingual knowledge acquisition. Through continual training of LLMs with diverse data recipes, we track how LLMs acquire domain facts and pinpoint the mechanism behind the transformation process from domain training data to knowledge. Our experiments on a 13B English-Japanese bilingual LLM reveal that cross-lingual transfer remains challenging despite a high-quality bilingual corpus. The code has been released.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12115","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.293800","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Xin Zhao, Naoki Yoshinaga, Yuma Tsuta, Akiko Aizawa","raw_content_length":1252,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["ML-DA"],"persons":[],"locations":["Domain"],"monetary":[]},"char_count":1251,"language_detected":"en","key_concepts":{"key_phrases":["Multilingual Knowledge Acquisition Dynamics","Domain Adaptation","English","languages","arXiv251012115v1 Announce Type","new Abstract","Multilingual domain adaptation","ML-DA","new domain knowledge","large language models"],"filter_categories":{"business_innovation":["Multilingual Knowledge Acquisition Dynamics"],"ai_ml":["Domain Adaptation","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multilingual Knowledge Acquisition Dynamics":2.0,"Domain Adaptation":2.0,"English":2.0,"languages":2.0,"arXiv251012115v1 Announce Type":1.0,"new Abstract":1.0,"Multilingual domain adaptation":1.0,"ML-DA":1.0,"new domain knowledge":1.0,"large language models":1.0}},"age_hours":2.7392103147222224,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8987,"joy":0.0122,"surprise":0.0559,"sadness":0.0071,"fear":0.0091,"anger":0.0107,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores multilingual domain adaptation in LLMs, focusing on improving knowledge transfer across languages. While the research aims to enhance LLM performance, it's in the early stages (basic research) and lacks concrete actions or measurable outcomes related to sustainability. The work proposes a new evaluation method (AdaXEval) and releases code, but there's no deployment or quantified impact on climate or other sustainability dimensions.","key_impact_metrics":[],"technology_tags":["LLM","Multilingual Domain Adaptation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:41:35.352187Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0102281b00f7","title":"Understanding the Modality Gap: An Empirical Study on the Speech","content":"arXiv:2510.12116v1 Announce Type: new Abstract: End-to-end Large Speech Language Models (LSLMs) have demonstrated impressive conversational generation abilities, yet consistently fall short of traditional pipeline systems on semantic understanding benchmarks. In this work, we reveal through systematic experimentation that although LSLMs lose some text input performance after speech-text alignment training, the performance gap between speech and text inputs is more pronounced, which we refer to as the modality gap. To understand this gap, we analyze both coarse- and fine-grained text and speech representations. At the coarse-grained level, representations of speech and text in deeper layers are found to be increasingly aligned in direction (cosine similarity), while concurrently diverging in magnitude (Euclidean distance). We further find that representation similarity is strongly correlated with the modality gap. At the fine-grained level, a spontaneous token-level alignment pattern between text and speech representations is observed. Based on this, we introduce the Alignment Path Score to quantify token-level alignment quality, which exhibits stronger correlation with the modality gap. Building on these insights, we design targeted interventions on critical tokens through angle projection and length normalization. These strategies demonstrate the potential to improve correctness for speech inputs. Our study provides the first systematic empirical analysis of the modality gap and alignment mechanisms in LSLMs, offering both theoretical and methodological guidance for future optimization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12116","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.294217","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Bajian Xiang, Shuaijiang Zhao, Tingwei Guo, Wei Zou","raw_content_length":1615,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":["the Speech arXiv:2510.12116v1"],"persons":["Speech Language Models"],"locations":[],"monetary":[]},"char_count":1614,"language_detected":"en","key_concepts":{"key_phrases":["the Modality Gap","An Empirical Study","the Speech","LSLMs","arXiv251012116v1","Announce Type","new Abstract","Large Speech Language Models","impressive conversational generation abilities","traditional pipeline systems"],"filter_categories":{"research_academic":["An Empirical Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Modality Gap":2.0,"An Empirical Study":2.0,"the Speech":2.0,"LSLMs":2.0,"arXiv251012116v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Large Speech Language Models":1.0,"impressive conversational generation abilities":1.0,"traditional pipeline systems":1.0}},"age_hours":2.7392250847222224,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7276,"joy":0.0385,"surprise":0.1222,"sadness":0.0159,"fear":0.06,"anger":0.0165,"disgust":0.0193},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a systematic empirical analysis of the modality gap in Large Speech Language Models (LSLMs). The concrete action involves designing targeted interventions on critical tokens through angle projection and length normalization, demonstrating the potential to improve correctness for speech inputs. The evidence supporting claims includes representation similarity correlated with the modality gap and an Alignment Path Score quantifying token-level alignment quality. The stage of deployment is basic research.","key_impact_metrics":["cosine similarity","Euclidean distance"],"technology_tags":["Large Speech Language Models","speech-text alignment"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:41:38.568916Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_63bd51b5654e","title":"Locket: Robust Feature","content":"arXiv:2510.12117v1 Announce Type: new Abstract: Chatbot providers (e.g., OpenAI) rely on tiered subscription schemes to generate revenue, offering basic models for free users, and advanced models for paying subscribers. However, a finer-grained pay-to-unlock scheme for premium features (e.g., math, coding) is thought to be more economically viable for the providers. Such a scheme requires a feature-locking technique (FLoTE) which is (i) effective in refusing locked features, (ii) utility-preserving for unlocked features, (iii) robust against evasion or unauthorized credential sharing, and (iv) scalable to multiple features and users. However, existing FLoTEs (e.g., password-locked models) are not robust or scalable. We present Locket, the first robust and scalable FLoTE to enable pay-to-unlock schemes. Locket uses a novel merging approach to attach adapters to an LLM for refusing unauthorized features. Our comprehensive evaluation shows that Locket is effective ($100$% refusal on locked features), utility-preserving ($\\leq 7$% utility degradation in unlocked features), robust ($\\leq 5$% attack success rate), and scales to multiple features and clients.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12117","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.294628","language":"en","tags":["preprints","computer-science","cscr","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Lipeng He, Vasisht Duddu, N. Asokan","raw_content_length":1171,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["OpenAI","Locket","FLoTEs"],"locations":[],"monetary":[]},"char_count":1170,"language_detected":"en","key_concepts":{"key_phrases":["Locket","Robust Feature","arXiv251012117v1","Announce Type","new Abstract Chatbot providers","eg OpenAI","tiered subscription schemes","revenue","basic models","free users"],"filter_categories":{"ai_ml":["eg OpenAI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Locket":2.0,"Robust Feature":2.0,"arXiv251012117v1":1.0,"Announce Type":1.0,"new Abstract Chatbot providers":1.0,"eg OpenAI":1.0,"tiered subscription schemes":1.0,"revenue":1.0,"basic models":1.0,"free users":1.0}},"age_hours":2.7392413130555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9009,"joy":0.0102,"surprise":0.0422,"sadness":0.0082,"fear":0.0047,"anger":0.02,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel feature-locking technique (FLoTE) for chatbot providers. While it demonstrates effectiveness (100% refusal) and utility preservation (<=7% degradation) in a controlled environment, it's still in the early stages of development and lacks real-world deployment data. The potential climate impact is indirect, as it could enable more efficient resource allocation for AI services, but this is not quantified.","key_impact_metrics":["100% refusal on locked features","<=7% utility degradation in unlocked features"],"technology_tags":["feature-locking technique","large language models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:41.814526Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_415d8d6610fc","title":"ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval","content":"arXiv:2510.12119v1 Announce Type: new Abstract: The widespread adoption of Retrieval-Augmented Image Generation (RAIG) has raised significant concerns about the unauthorized use of private image datasets. While these systems have shown remarkable capabilities in enhancing generation quality through reference images, protecting visual datasets from unauthorized use in such systems remains a challenging problem. Traditional digital watermarking approaches face limitations in RAIG systems, as the complex feature extraction and recombination processes fail to preserve watermark signals during generation. To address these challenges, we propose ImageSentinel, a novel framework for protecting visual datasets in RAIG. Our framework synthesizes sentinel images that maintain visual consistency with the original dataset. These sentinels enable protection verification through randomly generated character sequences that serve as retrieval keys. To ensure seamless integration, we leverage vision-language models to generate the sentinel images. Experimental results demonstrate that ImageSentinel effectively detects unauthorized dataset usage while preserving generation quality for authorized applications. Code is available at https://github.com/luo-ziyuan/ImageSentinel.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12119","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.295023","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Ziyuan Luo, Yangyi Zhao, Ka Chun Cheung, Simon See, Renjie Wan","raw_content_length":1277,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Retrieval-Augmented Image Generation","ImageSentinel","RAIG"],"persons":[],"locations":[],"monetary":[]},"char_count":1276,"language_detected":"en","key_concepts":{"key_phrases":["ImageSentinel","Visual Datasets","Unauthorized Retrieval","Announce Type","new Abstract","The widespread adoption","Retrieval-Augmented Image Generation","RAIG","significant concerns","the unauthorized use"],"filter_categories":{"ai_ml":["RAIG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ImageSentinel":2.0,"Visual Datasets":2.0,"Unauthorized Retrieval":2.0,"Announce Type":1.0,"new Abstract":1.0,"The widespread adoption":1.0,"Retrieval-Augmented Image Generation":1.0,"RAIG":1.0,"significant concerns":1.0,"the unauthorized use":1.0}},"age_hours":2.7392547569444443,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5436,"joy":0.0112,"surprise":0.0184,"sadness":0.0191,"fear":0.2933,"anger":0.0933,"disgust":0.0211},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a framework to protect image datasets from unauthorized use in Retrieval-Augmented Image Generation (RAIG) systems. While it addresses a potential risk associated with AI technology, it does not directly contribute to climate change mitigation or adaptation. The framework is in the early stages of development, with experimental results demonstrating effectiveness but lacking real-world deployment data.","key_impact_metrics":["Detection of unauthorized dataset usage","Preservation of generation quality"],"technology_tags":["ImageSentinel","Retrieval-Augmented Image Generation","Vision-Language Models"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:41:45.050392Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_33f030775a61","title":"Towards Engineering Multi","content":"arXiv:2510.12120v1 Announce Type: new Abstract: The increasing demand for software development has driven interest in automating software engineering (SE) tasks using Large Language Models (LLMs). Recent efforts extend LLMs into multi-agent systems (MAS) that emulate collaborative development workflows, but these systems often fail due to three core deficiencies: under-specification, coordination misalignment, and inappropriate verification, arising from the absence of foundational SE structuring principles. This paper introduces Software Engineering Multi-Agent Protocol (SEMAP), a protocol-layer methodology that instantiates three core SE design principles for multi-agent LLMs: (1) explicit behavioral contract modeling, (2) structured messaging, and (3) lifecycle-guided execution with verification, and is implemented atop Google's Agent-to-Agent (A2A) infrastructure. Empirical evaluation using the Multi-Agent System Failure Taxonomy (MAST) framework demonstrates that SEMAP effectively reduces failures across different SE tasks. In code development, it achieves up to a 69.6% reduction in total failures for function-level development and 56.7% for deployment-level development. For vulnerability detection, SEMAP reduces failure counts by up to 47.4% on Python tasks and 28.2% on C/C++ tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12120","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.295420","language":"en","tags":["preprints","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Zhenyu Mao, Jacky Keung, Fengji Zhang, Shuo Liu, Yifei Wang, Jialong Li","raw_content_length":1310,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["Google","MAS","Large Language Models","Software Engineering Multi-Agent Protocol","SEMAP"],"persons":[],"locations":[],"monetary":[]},"char_count":1309,"language_detected":"en","key_concepts":{"key_phrases":["Engineering Multi","LLMs","arXiv251012120v1 Announce Type","new Abstract","The increasing demand","software development","interest","software engineering","tasks","Large Language Models"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"],"engineering":["software development","software engineering"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Engineering Multi":2.0,"LLMs":2.0,"arXiv251012120v1 Announce Type":1.0,"new Abstract":1.0,"The increasing demand":1.0,"software development":1.0,"interest":1.0,"software engineering":1.0,"tasks":1.0,"Large Language Models":1.0}},"age_hours":2.7392699016666664,"is_recent":true,"quality_score":1.0,"sentiment_score":2.1765,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5647,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6016,"joy":0.004,"surprise":0.0601,"sadness":0.2606,"fear":0.0212,"anger":0.0347,"disgust":0.0177},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new methodology (SEMAP) for multi-agent LLMs in software engineering, showing a reduction in failures across different SE tasks. The concrete action is the development and testing of SEMAP, with empirical evaluation using the MAST framework. The stage is applied research, as it's implemented atop Google's A2A infrastructure and demonstrates improvements, but isn't yet deployed commercially.","key_impact_metrics":["69.6% reduction in total failures for function-level development","56.7% reduction for deployment-level development"],"technology_tags":["Large Language Models","Multi-Agent Systems","Software Engineering"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:49.481040Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e5e2ee268433","title":"Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing","content":"arXiv:2510.12121v1 Announce Type: new Abstract: Precise attribute intensity control--generating Large Language Model (LLM) outputs with specific, user-defined attribute intensities--is crucial for AI systems adaptable to diverse user expectations. Current LLM alignment methods, however, typically provide only directional or open-ended guidance, failing to reliably achieve exact attribute intensities. We address this limitation with three key designs: (1) reformulating precise attribute intensity control as a target-reaching problem, rather than simple maximization; (2) training a lightweight value function via temporal-difference learning to predict final attribute intensity scores from partial generations, thereby steering LLM outputs; and (3) employing gradient-based interventions on hidden representations to navigate the model precisely towards specific attribute intensity targets. Our method enables fine-grained, continuous control over attribute intensities, moving beyond simple directional alignment. Experiments on LLaMA-3.2-3b and Phi-4-mini confirm our method's ability to steer text generation to user-specified attribute intensities with high accuracy. Finally, we demonstrate efficiency enhancements across three downstream tasks: preference data synthesis, Pareto frontier approximation and optimization, and distillation of aligned behaviors for intervention-free inference. Our code is available on https://github.com/Pre-Control/pre-control","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12121","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.295844","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Rongzhi Zhang, Liqin Ye, Yuzhao Heng, Xiang Chen, Tong Yu, Lingkai Kong, Sudheer Chava, Chao Zhang","raw_content_length":1472,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Precise Attribute Intensity Control"],"persons":[],"locations":[],"monetary":[]},"char_count":1471,"language_detected":"en","key_concepts":{"key_phrases":["Precise Attribute Intensity Control","Large Language Models","Targeted Representation Editing","Announce Type","new Abstract","Precise attribute intensity control","LLM","specific user-defined attribute intensities","AI systems","user expectations"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Precise Attribute Intensity Control":2.0,"Large Language Models":2.0,"Targeted Representation Editing":2.0,"Announce Type":1.0,"new Abstract":1.0,"Precise attribute intensity control":1.0,"LLM":1.0,"specific user-defined attribute intensities":1.0,"AI systems":1.0,"user expectations":1.0}},"age_hours":2.7392848944444443,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8862,"joy":0.0025,"surprise":0.0176,"sadness":0.0409,"fear":0.0152,"anger":0.0207,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for controlling attribute intensity in LLM outputs. While the method shows promise in steering text generation to user-specified attribute intensities with high accuracy, it is still in the early stages of development and lacks concrete deployment or real-world impact data. The method is demonstrated on LLaMA-3.2-3b and Phi-4-mini, suggesting it is at the applied research stage.","key_impact_metrics":["high accuracy in steering text generation","efficiency enhancements across three downstream tasks"],"technology_tags":["Large Language Models","Attribute Intensity Control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:52.553142Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ec13cf571499","title":"Hardware","content":"arXiv:2510.12123v1 Announce Type: new Abstract: Single-photon cameras are becoming increasingly popular in time-of-flight 3D imaging because they can time-tag individual photons with extreme resolution. However, their performance is susceptible to hardware limitations, such as system bandwidth, maximum laser power, sensor data rates, and in-sensor memory and compute resources. Compressive histograms were recently introduced as a solution to the challenge of data rates through an online in-sensor compression of photon timestamp data. Although compressive histograms work within limited in-sensor memory and computational resources, they underperform when subjected to real-world illumination hardware constraints. To address this, we present a constrained optimization approach for designing practical coding functions for compressive single-photon 3D imaging. Using gradient descent, we jointly optimize an illumination and coding matrix (i.e., the coding functions) that adheres to hardware constraints. We show through extensive simulations that our coding functions consistently outperform traditional coding designs under both bandwidth and peak power constraints. This advantage is particularly pronounced in systems constrained by peak power. Finally, we show that our approach adapts to arbitrary parameterized impulse responses by evaluating it on a real-world system with a non-ideal impulse response function.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12123","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.296247","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"David Parra, Felipe Gutierrez-Barragan, Trevor Seets, Andreas Velten","raw_content_length":1426,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Hardware arXiv:2510.12123v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1425,"language_detected":"en","key_concepts":{"key_phrases":["Hardware","arXiv251012123v1 Announce Type","new Abstract","Single-photon cameras","flight","time-tag individual photons","extreme resolution","their performance","hardware limitations","system"],"filter_categories":{"engineering":["Hardware","system"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hardware":2.0,"arXiv251012123v1 Announce Type":1.0,"new Abstract":1.0,"Single-photon cameras":1.0,"flight":1.0,"time-tag individual photons":1.0,"extreme resolution":1.0,"their performance":1.0,"hardware limitations":1.0,"system":1.0}},"age_hours":2.739299596388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8843,"joy":0.0144,"surprise":0.0728,"sadness":0.0052,"fear":0.0094,"anger":0.0086,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of single-photon cameras for 3D imaging, specifically addressing hardware limitations like bandwidth and power constraints. While the technology could potentially contribute to more efficient data acquisition in various fields, including environmental monitoring, the current impact is theoretical and demonstrated through simulations, not real-world deployments. The article shows improved performance under constraints, but lacks economic viability and deployment readiness data.","key_impact_metrics":["Outperforms traditional coding designs under bandwidth and peak power constraints","Adapts to arbitrary parameterized impulse responses"],"technology_tags":["single-photon cameras","3D imaging","compressive histograms","constrained optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:41:59.637636Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_30be5efe0726","title":"MetaCaptioner: Towards Generalist Visual Captioning with Open","content":"arXiv:2510.12126v1 Announce Type: new Abstract: Generalist visual captioning goes beyond a simple appearance description task, but requires integrating a series of visual cues into a caption and handling various visual domains. In this task, current open-source models present a large performance gap with commercial ones, which limits various applications such as data synthesis. To bridge the gap, this paper proposes CapFlow, a novel multi-agent collaboration workflow. CapFlow demonstrates for the first time that, by capitalizing on open-source models, it is possible to achieve caption quality on par with GPT-4.1 in various domains with an 89.5% reduction in costs. By leveraging CapFlow as the data synthesizer, we produce high-quality visual captions from image and video domains at scale, and obtain a generalist visual captioner via fine-tuning, namely MetaCaptioner. Through extensive experiments, we show that MetaCaptioner not only achieves comparable captioning capabilities with commercial models but also reaches top-tier multimodal performance in the open-source community. We hope CapFlow and MetaCaptioner can benefit future multimodal research by providing a strong and cost-effective visual captioning solution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12126","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.297071","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Zhenxin Lei, Zhangwei Gao, Changyao Tian, Erfei Cui, Guanzhou Chen, Danni Yang, Yuchen Duan, Zhaokai Wang, Wenhao Li, Weiyun Wang, Xiangyu Zhao, Jiayi Ji, Yu Qiao, Wenhai Wang, Gen Luo","raw_content_length":1234,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["MetaCaptioner","CapFlow"],"persons":["Generalist"],"locations":[],"monetary":[]},"char_count":1233,"language_detected":"en","key_concepts":{"key_phrases":["MetaCaptioner","Generalist Visual Captioning","Open","CapFlow","new Abstract","Generalist visual captioning","a simple appearance description task","a series","visual cues","a caption"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MetaCaptioner":2.0,"Generalist Visual Captioning":2.0,"Open":2.0,"CapFlow":2.0,"new Abstract":1.0,"Generalist visual captioning":1.0,"a simple appearance description task":1.0,"a series":1.0,"visual cues":1.0,"a caption":1.0}},"age_hours":2.739328698611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2485,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4497,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8357,"joy":0.0076,"surprise":0.0238,"sadness":0.0069,"fear":0.0487,"anger":0.0384,"disgust":0.0389},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel workflow (CapFlow) for visual captioning using open-source models, achieving performance comparable to GPT-4 with an 89.5% cost reduction. This could potentially reduce the energy consumption and cost associated with data synthesis, although the actual climate impact is not directly quantified. The research is still in the applied research stage, with no mention of deployment or commercialization.","key_impact_metrics":["89.5% reduction in costs"],"technology_tags":["visual captioning","multi-agent collaboration","data synthesis"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:42:02.704679Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_28481ce526a7","title":"nuGPR: GPU","content":"arXiv:2510.12128v1 Announce Type: new Abstract: Gaussian Process Regression (GPR) is an important type of supervised machine learning model with inherent uncertainty measure in its predictions. We propose a new framework, nuGPR, to address the well-known challenge of high computation cost associated with GPR training. Our framework includes several ideas from numerical linear algebra to reduce the amount of computation in key steps of GPR, and we combine them to establish an end-to-end training algorithm. Specifically, we leverage the preconditioned conjugate gradient method to accelerate the convergence of the linear solves required in GPR. We exploit clustering in the input data to identify block-diagonal structure of the covariance matrix and subsequently construct low-rank approximations of the off-diagonal blocks. These enhancements significantly reduce the time and space complexity of our computations. In addition, unlike other frameworks that rely on exact differentiation, we employ numerical gradients to optimize the hyperparameters of our GPR model, further reducing the training cost by eliminating the need for backpropagation. Lastly, we leverage the CUDA Toolkit to efficiently parallelize the training procedure on NVIDIA GPUs. As a result, nuGPR reduces total training time by up to 2x and peak memory consumption by up to 12x on various synthetic and real-world datasets when compared to the best existing GPU-based GPR implementation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12128","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.297482","language":"en","tags":["preprints","mathna","csna","computer-science","cslg","research","csdc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Ziqi Zhao, Vivek Sarin","raw_content_length":1468,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["linear","GPU","GPR"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1467,"language_detected":"en","key_concepts":{"key_phrases":["nuGPR","GPU","GPR","arXiv251012128v1 Announce Type","new Abstract","Gaussian Process Regression","an important type","supervised machine learning model","inherent uncertainty measure","its predictions"],"filter_categories":{"ai_ml":["supervised machine learning model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"nuGPR":2.0,"GPU":2.0,"GPR":2.0,"arXiv251012128v1 Announce Type":1.0,"new Abstract":1.0,"Gaussian Process Regression":1.0,"an important type":1.0,"supervised machine learning model":1.0,"inherent uncertainty measure":1.0,"its predictions":1.0}},"age_hours":2.7393432675000002,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8195,"joy":0.0148,"surprise":0.0212,"sadness":0.0062,"fear":0.095,"anger":0.0312,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new framework, nuGPR, that reduces the computational cost of Gaussian Process Regression, potentially leading to more efficient machine learning models. The concrete action is the development of this framework and its demonstrated reduction in training time and memory consumption. However, it's still in the early stages of development, lacking peer review and real-world deployment.","key_impact_metrics":["2x reduction in training time","12x reduction in peak memory consumption"],"technology_tags":["Gaussian Process Regression","GPU acceleration","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:42:05.730473Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5e8e80853136","title":"Functional Reasoning for Distributed Systems with Failures","content":"arXiv:2510.12131v1 Announce Type: new Abstract: Distributed system theory literature often argues for correctness using an informal, Hoare-like style of reasoning. While these arguments are intuitive, they have not all been foolproof, and whether they directly correspond to formal proofs is in question. We formally ground this kind of reasoning and connect it to standard formal approaches through language design and meta-analysis, which leads to a functional style of compositional formal reasoning for a class of distributed systems, including cases involving Byzantine faults. The core of our approach is twin languages: Sync and Async, which formalize the insight from distributed system theory that an asynchronous system can be reduced to a synchronous system for more straightforward reasoning under certain conditions. Sync describes a distributed system as a single, synchronous, data-parallel program. It restricts programs syntactically and has a functional denotational semantics suitable for Hoare-style formal reasoning. Async models a distributed system as a collection of interacting monadic programs, one for each non-faulty node in the system. It has a standard trace-based operational semantics, modeling asynchrony with interleaving. Sync compiles to Async and can then be extracted to yield executable code. We prove that any safety property proven for a Sync program in its denotational semantics is preserved in the operational semantics of its compiled Async programs. We implement the twin languages in Rocq and verify the safety properties of two fault-tolerant consensus protocols: BOSCO and SeqPaxos.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12131","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.298925","language":"en","tags":["preprints","computer-science","research","cspl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Haobin Ni, Robbert van Renesse, Greg Morrisett","raw_content_length":1632,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["Async","Sync","Hoare"],"persons":[],"locations":[],"monetary":[]},"char_count":1631,"language_detected":"en","key_concepts":{"key_phrases":["Functional Reasoning","Distributed Systems","Failures","reasoning","arXiv251012131v1 Announce Type","new Abstract","Distributed system theory literature","correctness","an informal Hoare-like style","these arguments"],"filter_categories":{"ai_ml":["Failures"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Functional Reasoning":2.0,"Distributed Systems":2.0,"Failures":2.0,"reasoning":2.0,"arXiv251012131v1 Announce Type":1.0,"new Abstract":1.0,"Distributed system theory literature":1.0,"correctness":1.0,"an informal Hoare-like style":1.0,"these arguments":1.0}},"age_hours":2.7393582180555556,"is_recent":true,"quality_score":1.0,"sentiment_score":0.7074999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8585,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8689,"joy":0.0064,"surprise":0.0156,"sadness":0.0058,"fear":0.0457,"anger":0.0281,"disgust":0.0294},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to formally reasoning about distributed systems, which could indirectly contribute to sustainability by improving the reliability and efficiency of systems that support climate solutions. The research is at a basic research stage and lacks concrete deployment or economic viability data. The technical credibility is supported by peer-reviewed research and formal proofs.","key_impact_metrics":[],"technology_tags":["distributed systems","formal verification","fault tolerance"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:42:08.609466Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_67160887fc8a","title":"SafeMT: Multi","content":"arXiv:2510.12133v1 Announce Type: new Abstract: With the widespread use of multi-modal Large Language models (MLLMs), safety issues have become a growing concern. Multi-turn dialogues, which are more common in everyday interactions, pose a greater risk than single prompts; however, existing benchmarks do not adequately consider this situation. To encourage the community to focus on the safety issues of these models in multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues of varying lengths generated from harmful queries accompanied by images. This benchmark consists of 10,000 samples in total, encompassing 17 different scenarios and four jailbreak methods. Additionally, we propose Safety Index (SI) to evaluate the general safety of MLLMs during conversations. We assess the safety of 17 models using this benchmark and discover that the risk of successful attacks on these models increases as the number of turns in harmful dialogues rises. This observation indicates that the safety mechanisms of these models are inadequate for recognizing the hazard in dialogue interactions. We propose a dialogue safety moderator capable of detecting malicious intent concealed within conversations and providing MLLMs with relevant safety policies. Experimental results from several open-source models indicate that this moderator is more effective in reducing multi-turn ASR compared to existed guard models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12133","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.299781","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Han Zhu, Juntao Dai, Jiaming Ji, Haoran Li, Chengkun Cai, Pengcheng Wen, Chi-Min Chan, Boyuan Chen, Yaodong Yang, Sirui Han, Yike Guo","raw_content_length":1434,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Safety"],"persons":[],"locations":[],"monetary":[]},"char_count":1433,"language_detected":"en","key_concepts":{"key_phrases":["SafeMT","Multi","arXiv251012133v1 Announce Type","new Abstract","the widespread use","multi-modal Large Language models","MLLMs","safety issues","a growing concern","Multi-turn dialogues"],"filter_categories":{"ai_ml":["multi-modal Large Language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SafeMT":3.0,"Multi":2.0,"arXiv251012133v1 Announce Type":1.0,"new Abstract":1.0,"the widespread use":1.0,"multi-modal Large Language models":1.0,"MLLMs":1.0,"safety issues":1.0,"a growing concern":1.0,"Multi-turn dialogues":1.0}},"age_hours":2.739388154166667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.375,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.875,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.2209,"joy":0.0056,"surprise":0.0108,"sadness":0.0111,"fear":0.7211,"anger":0.023,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article introduces a benchmark (SafeMT) and a safety moderator for MLLMs. While it presents experimental results showing the moderator's effectiveness in reducing multi-turn ASR, it's still in the early stages of development and lacks real-world deployment. The impact on climate change is indirect, as it focuses on AI safety rather than direct emissions reduction.","key_impact_metrics":["10,000 samples in benchmark","17 scenarios"],"technology_tags":["Large Language Models","AI Safety","Dialogue Moderator"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:42:16.984172Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
