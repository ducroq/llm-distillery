{"id":"science_arxiv_cs_2f67c0ff5f4d","title":"Interpretable and Granular Video","content":"arXiv:2506.18925v2 Announce Type: replace Abstract: Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.18925","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.886950","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Tahereh Zarrat Ehsan, Michael Tangermann, Ya\\u{g}mur G\\\"u\\c{c}l\\\"ut\\\"urk, Bastiaan R. Bloem, Luc J. W. Evers","raw_content_length":1959,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["bradykinesia","hypokinesia","the Personalized Park"],"monetary":[]},"char_count":1958,"language_detected":"en","key_concepts":{"key_phrases":["Interpretable and Granular Video","arXiv250618925v2 Announce Type","Abstract","Accurately quantifying motor characteristics","Parkinson disease","disease progression","treatment strategies","The finger-tapping test","a standard motor assessment","Clinicians"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Interpretable and Granular Video":2.0,"arXiv250618925v2 Announce Type":1.0,"Abstract":1.0,"Accurately quantifying motor characteristics":1.0,"Parkinson disease":1.0,"disease progression":1.0,"treatment strategies":1.0,"The finger-tapping test":1.0,"a standard motor assessment":1.0,"Clinicians":1.0}},"age_hours":2.772150106111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8332,"joy":0.005,"surprise":0.0324,"sadness":0.0363,"fear":0.0495,"anger":0.0165,"disgust":0.0272},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a computer vision method for quantifying Parkinson's disease motor characteristics from video recordings. While the technology shows promise for objective assessment, it is currently in the applied research stage with evaluation on 74 patients. There is no immediate or direct climate impact, but improved healthcare access could indirectly contribute to societal well-being.","key_impact_metrics":["Accuracy in MDS-UPDRS score prediction","Number of PD patients evaluated: 74"],"technology_tags":["computer vision","machine learning","medical diagnostics"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:53:28.177506Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c2e03029dac","title":"Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective","content":"arXiv:2506.19028v5 Announce Type: replace Abstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo (Fine-grained Semantic Comparison), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSCo more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.19028","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.887564","language":"en","tags":["research","csai","preprints","cscl","cscy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Weijie Xu, Yiwen Wang, Chi Xue, Xiangkun Hu, Xi Fang, Guimin Dong, Chandan K. Reddy","raw_content_length":1294,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["Semantic Comparison","LLM"],"persons":["Quantifying Fairness","Beyond Tokens"],"locations":[],"monetary":[]},"char_count":1293,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Quantifying Fairness","Tokens","A Semantic and Statistical Perspective","arXiv250619028v5 Announce Type","Large Language Models","responses","inherent biases","their reliability","real-world applications"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Quantifying Fairness":2.0,"Tokens":2.0,"A Semantic and Statistical Perspective":2.0,"arXiv250619028v5 Announce Type":1.0,"Large Language Models":1.0,"responses":1.0,"inherent biases":1.0,"their reliability":1.0,"real-world applications":1.0}},"age_hours":2.772166031111111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8365,"joy":0.0061,"surprise":0.0276,"sadness":0.0158,"fear":0.0219,"anger":0.0582,"disgust":0.034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":7,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a novel framework (FiSCo) for evaluating fairness in LLMs, focusing on semantic differences in responses across demographic groups. It uses entailment checks and statistical hypothesis testing. While it addresses a critical aspect of AI ethics and fairness, it's currently in the applied research stage with no deployment or economic viability demonstrated, and the direct climate impact is minimal.","key_impact_metrics":["Reduced bias in LLM outputs","Improved fairness metrics"],"technology_tags":["Large Language Models","Fairness","Bias Detection"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T09:53:31.875914Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d423d62469f2","title":"Learning to Disentangle Latent Reasoning Rules with Language VAEs: A Systematic Study","content":"arXiv:2506.19418v2 Announce Type: replace Abstract: Incorporating explicit reasoning rules within the latent space of language models (LMs) offers a promising pathway to enhance generalisation, interpretability, and controllability. While current Transformer-based language models have shown strong performance on Natural Language Inference (NLI) tasks, they often rely on memorisation rather than rule-based inference. This work investigates how reasoning rules can be explicitly embedded and memorised within the LMs through Language Variational Autoencoders (VAEs). We propose a complete pipeline for learning reasoning rules within Transformer-based language VAEs. This pipeline encompasses three rule-based reasoning tasks, a supporting theoretical framework, and a practical end-to-end architecture. The experiment illustrates the following findings: Disentangled reasoning: Under explicit signal supervision, reasoning rules - viewed as functional mappings - can be disentangled within the encoder's parametric space. This separation results in distinct clustering of rules in the output feature space. Prior knowledge injection: injecting reasoning information into the Query enables the model to more effectively retrieve the stored value Value from memory based on Key. This approach offers a simple method for integrating prior knowledge into decoder-only language models. Performance bottleneck: In mathematical reasoning tasks using Qwen2.5(0.5B), increasing sample count doesn't improve performance beyond a point. Moreover, ffn layers are better than attention layers at preserving the separation of reasoning rules in the model's parameters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.19418","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.887983","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Yingji Zhang, Marco Valentino, Danilo S. Carvalho, Andr\\'e Freitas","raw_content_length":1658,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":["NLI","Transformer","Natural Language Inference"],"persons":[],"locations":[],"monetary":[]},"char_count":1657,"language_detected":"en","key_concepts":{"key_phrases":["Disentangle Latent Reasoning Rules","Language VAEs","arXiv250619418v2 Announce Type","Abstract","explicit reasoning rules","the latent space","language models","LMs","a promising pathway","generalisation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Disentangle Latent Reasoning Rules":2.0,"Language VAEs":2.0,"arXiv250619418v2 Announce Type":1.0,"Abstract":1.0,"explicit reasoning rules":1.0,"the latent space":1.0,"language models":1.0,"LMs":1.0,"a promising pathway":1.0,"generalisation":1.0}},"age_hours":2.772181621666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7893,"joy":0.0331,"surprise":0.0169,"sadness":0.0077,"fear":0.0918,"anger":0.0351,"disgust":0.0261},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores improving language models to perform reasoning tasks, potentially leading to more efficient AI. While AI efficiency can indirectly reduce energy consumption, the article doesn't present concrete actions or measurable outcomes related to climate or sustainability. The research is at a very early stage, with no deployment or real-world impact demonstrated.","key_impact_metrics":["Performance on mathematical reasoning tasks using Qwen2.5(0.5B)"],"technology_tags":["Language Models","Variational Autoencoders","Natural Language Inference"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:53:34.827762Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_247bf56d2c82","title":"Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial","content":"arXiv:2506.19433v2 Announce Type: replace Abstract: Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce \\textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.19433","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.888445","language":"en","tags":["research","csai","preprints","cscl","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Lixuan He, Haoyu Dong, Zhenxing Chen, Yangcheng Yu, Jie Feng, Yong Li","raw_content_length":1658,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["VLN","LTM"],"persons":[],"locations":[],"monetary":[]},"char_count":1657,"language_detected":"en","key_concepts":{"key_phrases":["Vision-and-Language Navigation","Mem4Nav","Urban Environments","a Hierarchical Spatial","Announce Type","Abstract","VLN","large-scale urban environments","embodied agents","linguistic instructions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vision-and-Language Navigation":3.0,"Mem4Nav":2.0,"Urban Environments":2.0,"a Hierarchical Spatial":2.0,"Announce Type":1.0,"Abstract":1.0,"VLN":1.0,"large-scale urban environments":1.0,"embodied agents":1.0,"linguistic instructions":1.0}},"age_hours":2.7721977036111114,"is_recent":true,"quality_score":1.0,"sentiment_score":9.124,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8248,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9005,"joy":0.0086,"surprise":0.0247,"sadness":0.013,"fear":0.0165,"anger":0.023,"disgust":0.0135},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a novel navigation system, Mem4Nav, which improves task completion in urban environments. While it shows promising results with 7-13 pp gains in Task Completion and >10 pp nDTW improvement, it's currently in the applied research stage with no real-world deployments. The potential climate impact is indirect, as improved navigation could lead to more efficient routing and reduced emissions, but this is not directly measured or quantified.","key_impact_metrics":["Task Completion gains: 7-13 pp","nDTW improvement: >10 pp"],"technology_tags":["Vision-and-Language Navigation","Hierarchical Spatial Memory","Octree","Semantic Topology Graph"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:53:37.994126Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b83e4765f58b","title":"EFRame: Deeper Reasoning via Exploration","content":"arXiv:2506.22200v5 Announce Type: replace Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), a lightweight variant of Proximal Policy Optimization (PPO), improves efficiency but suffers from limited exploration and training instability, limiting its effectiveness on complex reasoning tasks. To address these challenges, we introduce EFRame, an Exploration-Filter-Replay framework that augments GRPO across three dimensions: additional rollouts enable deeper and more targeted exploration, online filtering removes low-quality samples to stabilize gradients and accelerate training, and experience replay amplifies rare yet informative trajectories for stable convergence. This unified framework establishes a principled training cycle that balances exploration, efficiency, and stability. Experiments on diverse reasoning benchmarks demonstrate that EFRame achieves consistent gains, including a 37.9\\% relative improvement on Geometry3K over GRPO. EFRame further supports fine-grained sample categorization and precise entropy control, highlighting it as a robust solution for advancing deeper reasoning in LLMs. Our code is available at https://github.com/597358816/EFRame.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.22200","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.889195","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Chen Wang, Lai Wei, Yanzhi Zhang, Chenyang Shao, Zedong Dan, Weiran Huang, Yuzhi Zhang, Yue Wang","raw_content_length":1314,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["Exploration-Filter-Replay","GRPO","PPO"],"persons":["Deeper Reasoning"],"locations":[],"monetary":[]},"char_count":1313,"language_detected":"en","key_concepts":{"key_phrases":["EFRame","Deeper Reasoning","Exploration","arXiv250622200v5","Announce Type","Abstract","Recent advances","reinforcement learning","the reasoning capabilities","large language models"],"filter_categories":{"ai_ml":["reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EFRame":3.0,"Deeper Reasoning":2.0,"Exploration":2.0,"arXiv250622200v5":1.0,"Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"reinforcement learning":1.0,"the reasoning capabilities":1.0,"large language models":1.0}},"age_hours":2.7722249850000003,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9295,"joy":0.0066,"surprise":0.0194,"sadness":0.0138,"fear":0.011,"anger":0.0121,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (EFRame) to improve the reasoning capabilities of LLMs, which could indirectly contribute to sustainability by enabling more efficient and accurate decision-making in various sectors. The concrete action is the development and testing of the EFRame framework, with a measurable outcome of a 37.9% relative improvement on the Geometry3K benchmark over GRPO. The technology is currently in the applied research stage, with code available but no deployed units or real-world applications mentioned.","key_impact_metrics":["37.9% relative improvement on Geometry3K"],"technology_tags":["Reinforcement Learning","Large Language Models","Policy Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:53:41.114813Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9a77148db925","title":"Towards the Training of Deeper Predictive Coding Neural Networks","content":"arXiv:2506.23800v3 Announce Type: replace Abstract: Predictive coding networks are neural models that perform inference through an iterative energy minimization process, whose operations are local in space and time. While effective in shallow architectures, they suffer significant performance degradation beyond five to seven layers. In this work, we show that this degradation is caused by exponentially imbalanced errors between layers during weight updates, and by predictions from the previous layers not being effective in guiding updates in deeper layers. Furthermore, when training models with skip connections, the energy propagated by the residuals reaches higher layers faster than that propagated by the main pathway, affecting test accuracy. We address the first issue by introducing a novel precision-weighted optimization of latent variables that balances error distributions during the relaxation phase, the second issue by proposing a novel weight update mechanism that reduces error accumulation in deeper layers, and the third one by using auxiliary neurons that slow down the propagation of the energy in the residual connections. Empirically, our methods achieve performance comparable to backpropagation on deep models such as ResNets, opening new possibilities for predictive coding in complex tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.23800","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.889618","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Chang Qi, Matteo Forasassi, Thomas Lukasiewicz, Tommaso Salvatori","raw_content_length":1324,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1323,"language_detected":"en","key_concepts":{"key_phrases":["the Training","Deeper Predictive Coding Neural Networks","Announce Type","Predictive coding networks","neural models","inference","an iterative energy minimization process","whose operations","space","time"],"filter_categories":{"ai_ml":["the Training","Deeper Predictive Coding Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Training":2.0,"Deeper Predictive Coding Neural Networks":2.0,"Announce Type":1.0,"Predictive coding networks":1.0,"neural models":1.0,"inference":1.0,"an iterative energy minimization process":1.0,"whose operations":1.0,"space":1.0,"time":1.0}},"age_hours":2.7722397877777776,"is_recent":true,"quality_score":0.7,"sentiment_score":0.963,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8074,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6371,"joy":0.0023,"surprise":0.0101,"sadness":0.0325,"fear":0.0764,"anger":0.0638,"disgust":0.1779},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to training deeper predictive coding neural networks, achieving performance comparable to backpropagation on deep models like ResNets. While the research shows promise in improving the efficiency of AI models, it is still in the applied research stage with no deployed units or operational data to quantify the actual energy savings or environmental benefits. The technical credibility is supported by the mention of empirical results and the source being arXiv, suggesting peer review.","key_impact_metrics":["Performance comparable to backpropagation"],"technology_tags":["Predictive Coding Neural Networks","Deep Learning","AI Efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:53:44.469477Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_11ed2315bb5a","title":"DiffMark: Diffusion","content":"arXiv:2507.01428v2 Announce Type: replace Abstract: Deepfakes pose significant security and privacy threats through malicious facial manipulations. While robust watermarking can aid in authenticity verification and source tracking, existing methods often lack the sufficient robustness against Deepfake manipulations. Diffusion models have demonstrated remarkable performance in image generation, enabling the seamless fusion of watermark with image during generation. In this study, we propose a novel robust watermarking framework based on diffusion model, called DiffMark. By modifying the training and sampling scheme, we take the facial image and watermark as conditions to guide the diffusion model to progressively denoise and generate corresponding watermarked image. In the construction of facial condition, we weight the facial image by a timestep-dependent factor that gradually reduces the guidance intensity with the decrease of noise, thus better adapting to the sampling process of diffusion model. To achieve the fusion of watermark condition, we introduce a cross information fusion (CIF) module that leverages a learnable embedding table to adaptively extract watermark features and integrates them with image features via cross-attention. To enhance the robustness of the watermark against Deepfake manipulations, we integrate a frozen autoencoder during training phase to simulate Deepfake manipulations. Additionally, we introduce Deepfake-resistant guidance that employs specific Deepfake model to adversarially guide the diffusion sampling process to generate more robust watermarked images. Experimental results demonstrate the effectiveness of the proposed DiffMark on typical Deepfakes. Our code will be available at https://github.com/vpsg-research/DiffMark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.01428","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.890454","language":"en","tags":["eessiv","research","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Chen Sun, Haiyang Sun, Zhiqing Guo, Yunfeng Diao, Liejun Wang, Dan Ma, Gaobo Yang, Keqin Li","raw_content_length":1786,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["DiffMark","Diffusion arXiv:2507.01428v2 Announce Type"],"persons":["sam"],"locations":[],"monetary":[]},"char_count":1785,"language_detected":"en","key_concepts":{"key_phrases":["DiffMark","Diffusion","Announce Type","Deepfakes","significant security and privacy threats","malicious facial manipulations","robust watermarking","authenticity verification","source tracking","existing methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DiffMark":2.0,"Diffusion":2.0,"Announce Type":1.0,"Deepfakes":1.0,"significant security and privacy threats":1.0,"malicious facial manipulations":1.0,"robust watermarking":1.0,"authenticity verification":1.0,"source tracking":1.0,"existing methods":1.0}},"age_hours":2.7722649922222224,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.2896,"joy":0.0156,"surprise":0.0259,"sadness":0.0095,"fear":0.5393,"anger":0.1064,"disgust":0.0137},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for robust watermarking of images using diffusion models to combat deepfakes. The concrete action is the development of a new watermarking framework (DiffMark), but it is still in the applied research stage with no deployed units or operational data. The evidence is based on experimental results, but lacks independent verification and real-world deployment data, thus limiting its immediate sustainability impact.","key_impact_metrics":[],"technology_tags":["diffusion models","watermarking","deepfake detection"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:53:47.247949Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_067f769c9001","title":"Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post","content":"arXiv:2507.01752v2 Announce Type: replace Abstract: Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, exposing gradients during training can leak sensitive information about the underlying data, raising privacy and security concerns such as susceptibility to data poisoning attacks. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide non-vacuous generalization bounds and strong theoretical guarantees for differential privacy, robustness to data poisoning attacks, and extraction attacks. In experiments with LLMs, we demonstrate empirically that black-box optimization methods-despite the scalability and computational challenges inherent to black-box approaches-are able to learn, showing how a few iterations of BBoxER improve performance, generalize well on a benchmark of reasoning datasets, and are robust to membership inference attacks. This positions BBoxER as an attractive add-on on top of gradient-based optimization, offering suitability for deployment in restricted or privacy-sensitive environments while also providing non-vacuous generalization guarantees.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.01752","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.890868","language":"en","tags":["cscr","research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud","raw_content_length":1624,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1623,"language_detected":"en","key_concepts":{"key_phrases":["Peeking","Provable Privacy","Generalization Bounds","LLM Post","Announce Type","Abstract","Gradient-based optimization","the workhorse","deep learning","efficient and scalable training"],"filter_categories":{"ai_ml":["LLM Post","deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Peeking":2.0,"Provable Privacy":2.0,"Generalization Bounds":2.0,"LLM Post":2.0,"Announce Type":1.0,"Abstract":1.0,"Gradient-based optimization":1.0,"the workhorse":1.0,"deep learning":1.0,"efficient and scalable training":1.0}},"age_hours":2.7722802733333336,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7896,"joy":0.0044,"surprise":0.0082,"sadness":0.0128,"fear":0.0803,"anger":0.0564,"disgust":0.0484},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new method (BBoxER) for LLM post-training that improves privacy and generalization. While it shows improved performance and robustness in experiments, it is still in the applied research stage with no deployment data. The climate impact is indirect, potentially reducing energy consumption of LLMs, but this is not quantified.","key_impact_metrics":["Improved performance on reasoning datasets","Robustness to membership inference attacks"],"technology_tags":["Black-box optimization","Differential privacy","LLM post-training"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:53:50.153932Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_924e7617718e","title":"Large Language Model Agent for Modular Task Execution in Drug Discovery","content":"arXiv:2507.02925v2 Announce Type: replace Abstract: We present a modular framework powered by large language models (LLMs) that automates and streamlines key tasks across the early-stage computational drug discovery pipeline. By combining LLM reasoning with domain-specific tools, the framework performs biomedical data retrieval, domain-specific question answering, molecular generation, property prediction, property-aware molecular refinement, and 3D protein-ligand structure generation. In a case study targeting BCL-2 in lymphocytic leukemia, the agent autonomously retrieved relevant biomolecular information, including FASTA sequences, SMILES representations, and literature, and answered mechanistic questions with improved contextual accuracy compared to standard LLMs. It then generated chemically diverse seed molecules and predicted 67 ADMET-related properties, which guided iterative molecular refinement. Across two refinement rounds, the number of molecules with QED > 0.6 increased from 34 to 55. The number of molecules satisfying empirical drug-likeness filters also rose; for example, compliance with the Ghose filter increased from 32 to 55 within a pool of 100 molecules. The framework also employed Boltz-2 to generate 3D protein-ligand complexes and provide rapid binding affinity estimates for candidate compounds. These results demonstrate that the approach effectively supports molecular screening, prioritization, and structure evaluation. Its modular design enables flexible integration of evolving tools and models, providing a scalable foundation for AI-assisted therapeutic discovery.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.02925","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.891269","language":"en","tags":["research","preprints","cscl","cslg","q-biobm","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Janghoon Ock, Radheesh Sharma Meda, Srivathsan Badrinarayanan, Neha S. Aluru, Achuth Chandrasekhar, Amir Barati Farimani","raw_content_length":1616,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["Modular Task Execution","ADMET"],"persons":["Language Model"],"locations":[],"monetary":[]},"char_count":1615,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Model Agent","Modular Task Execution","Drug Discovery","arXiv250702925v2 Announce Type","Abstract","a modular framework","large language models","LLMs","key tasks","the early-stage computational drug discovery pipeline"],"filter_categories":{"ai_ml":["Large Language Model Agent","large language models"],"research_academic":["Drug Discovery","the early-stage computational drug discovery pipeline"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Model Agent":2.0,"Modular Task Execution":2.0,"Drug Discovery":2.0,"arXiv250702925v2 Announce Type":1.0,"Abstract":1.0,"a modular framework":1.0,"large language models":1.0,"LLMs":1.0,"key tasks":1.0,"the early-stage computational drug discovery pipeline":1.0}},"age_hours":2.7722959194444448,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9109,"joy":0.0336,"surprise":0.0359,"sadness":0.0027,"fear":0.0046,"anger":0.0093,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a modular framework for drug discovery using LLMs, demonstrating improved molecular refinement based on property prediction. Concrete actions include generating molecules and predicting ADMET properties. The technology is at the applied research stage, with no deployment or commercialization mentioned, although metrics are provided on the increase of molecules meeting certain criteria.","key_impact_metrics":["QED > 0.6 increased from 34 to 55","Ghose filter compliance increased from 32 to 55"],"technology_tags":["Large Language Models","Drug Discovery","Molecular Generation","Property Prediction"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:53:53.361205Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_afc6118109bc","title":"Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength","content":"arXiv:2507.03466v3 Announce Type: replace Abstract: Sound-tracking refers to the process of determining the direction from which a sound originates, making it a fundamental component of sound source localization. This capability is essential in a variety of applications, including security systems, acoustic monitoring, and speaker tracking, where accurately identifying the direction of a sound source enables real-time responses, efficient resource allocation, and improved situational awareness. While sound-tracking is closely related to localization, it specifically focuses on identifying the direction of the sound source rather than estimating its exact position in space. Despite its utility, sound-tracking systems face several challenges, such as maintaining directional accuracy and precision, along with the need for sophisticated hardware configurations and complex signal processing algorithms. This paper presents a sound-tracking method using three electret microphones. We estimate the direction of a sound source using a lightweight method that analyzes signals from three strategically placed microphones. By comparing the average power of the received signals, the system infers the most probable direction of the sound. The results indicate that the power level from each microphone effectively determines the sound source direction. Our system employs a straightforward and cost-effective hardware design, ensuring simplicity and affordability in implementation. It achieves a localization error of less than 6 degrees and a precision of 98%. Additionally, its effortless integration with various systems makes it versatile and adaptable. Consequently, this technique presents a robust and reliable solution for sound-tracking and localization, with potential applications spanning diverse domains such as security systems, smart homes, and acoustic monitoring.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.03466","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.891737","language":"en","tags":["research","cssd","preprints","eesssy","cssy","eessas","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Mahdi Ali Pour, Zahra Habibzadeh","raw_content_length":1886,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["Signal Strength arXiv:2507.03466v3 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1885,"language_detected":"en","key_concepts":{"key_phrases":["Direction Estimation","Sound Sources","Microphone Arrays","Signal Strength","the direction","arXiv250703466v3 Announce Type","Abstract","Sound-tracking","the process","which"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Direction Estimation":2.0,"Sound Sources":2.0,"Microphone Arrays":2.0,"Signal Strength":2.0,"the direction":2.0,"arXiv250703466v3 Announce Type":1.0,"Abstract":1.0,"Sound-tracking":1.0,"the process":1.0,"which":1.0}},"age_hours":2.7723114275,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.922,"joy":0.018,"surprise":0.0281,"sadness":0.0037,"fear":0.0165,"anger":0.0071,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":5,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a sound-tracking method using three microphones. It achieves a localization error of less than 6 degrees and a precision of 98%. While the system is cost-effective and simple, it is still in the prototype phase with no evidence of real-world deployment or independent validation, limiting its immediate sustainability impact.","key_impact_metrics":["localization error of less than 6 degrees","precision of 98%"],"technology_tags":["sound tracking","microphone array","signal processing"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:53:56.296251Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f2a9f099ba6f","title":"Memory- and compute-optimized geometric multigrid GMGPolar for curvilinear coordinate representations -","content":"arXiv:2507.03812v2 Announce Type: replace Abstract: Tokamak fusion reactors are actively studied as a means of realizing energy production from plasma fusion. However, due to the substantial cost and time required to construct fusion reactors and run physical experiments, numerical experiments are indispensable for understanding plasma physics inside tokamaks, supporting the design and engineering phase, and optimizing future reactor designs. Geometric multigrid methods are optimal solvers for many problems that arise from the discretization of partial differential equations. It has been shown that the multigrid solver GMGPolar solves the 2D gyrokinetic Poisson equation in linear complexity and with only small memory requirements compared to other state-of-the-art solvers. In this paper, we present a completely refactored and object-oriented version of GMGPolar which offers two different matrix-free implementations. Among other things, we leverage the Sherman-Morrison formula to solve cyclic tridiagonal systems from circular line solvers without additional fill-in and we apply reordering to optimize cache access of circular and radial smoothing operations. With the Give approach, memory requirements are further reduced and speedups of four to seven are obtained for usual test cases. For the Take approach, speedups of 16 to 18 can be attained. In an additionally experimental setup of using GMGPolar as a preconditioner for conjugate gradients, this speedup could even be increased to factors between 25 and 37.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.03812","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.892143","language":"en","tags":["research","preprints","csms","computer-science","physicsplasm-ph","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Julian Litz, Philippe Leleux, Carola Kruse, Joscha Gedicke, Martin J. K\\\"uhn","raw_content_length":1533,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["GMGPolar"],"persons":["GMGPolar"],"locations":[],"monetary":[]},"char_count":1532,"language_detected":"en","key_concepts":{"key_phrases":["Memory-","compute-optimized geometric multigrid GMGPolar","curvilinear coordinate representations","Announce Type","Tokamak fusion reactors","a means","energy production","plasma fusion","the substantial cost","time"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Memory-":2.0,"compute-optimized geometric multigrid GMGPolar":2.0,"curvilinear coordinate representations":2.0,"Announce Type":1.0,"Tokamak fusion reactors":1.0,"a means":1.0,"energy production":1.0,"plasma fusion":1.0,"the substantial cost":1.0,"time":1.0}},"age_hours":2.7723264591666665,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7945,"joy":0.1163,"surprise":0.0366,"sadness":0.015,"fear":0.0148,"anger":0.0135,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a refactored version of GMGPolar, a solver for the gyrokinetic Poisson equation used in Tokamak fusion reactors. The concrete action is the optimization of the solver, resulting in speedups of 4-7x with the Give approach and 16-18x with the Take approach, and even higher when used as a preconditioner. The evidence supporting these claims comes from experimental setups, although deployment readiness is low as it's still in the research phase.","key_impact_metrics":["speedups of four to seven","speedups of 16 to 18"],"technology_tags":["geometric multigrid methods","plasma fusion"],"sdg_alignment":[7],"analyzed_at":"2025-10-29T09:53:59.556651Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_389af802f8ac","title":"Event","content":"arXiv:2507.05698v2 Announce Type: replace Abstract: Spacecraft pose estimation is crucial for autonomous in-space operations, such as rendezvous, docking and on-orbit servicing. Vision-based pose estimation methods, which typically employ RGB imaging sensors, is a compelling solution for spacecraft pose estimation, but are challenged by harsh lighting conditions, which produce imaging artifacts such as glare, over-exposure, blooming and lens flare. Due to their much higher dynamic range, neuromorphic or event sensors are more resilient to extreme lighting conditions. However, event sensors generally have lower spatial resolution and suffer from reduced signal-to-noise ratio during periods of low relative motion. This work addresses these individual sensor limitations by introducing a sensor fusion approach combining RGB and event sensors. A beam-splitter prism was employed to achieve precise optical and temporal alignment. Then, a RANSAC-based technique was developed to fuse the information from the RGB and event channels to achieve pose estimation that leveraged the strengths of the two modalities. The pipeline was complemented by dropout uncertainty estimation to detect extreme conditions that affect either channel. To benchmark the performance of the proposed event-RGB fusion method, we collected a comprehensive real dataset of RGB and event data for satellite pose estimation in a laboratory setting under a variety of challenging illumination conditions. Encouraging results on the dataset demonstrate the efficacy of our event-RGB fusion approach and further supports the usage of event sensors for spacecraft pose estimation. To support community research on this topic, our dataset has been released publicly.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.05698","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.892943","language":"en","tags":["research","preprints","csro","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Mohsi Jawaid, Marcus M\\\"artens, Tat-Jun Chin","raw_content_length":1740,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":["RGB","RANSAC"],"persons":[],"locations":[],"monetary":[]},"char_count":1739,"language_detected":"en","key_concepts":{"key_phrases":["Event","estimation","which","arXiv250705698v2 Announce Type","Abstract","Spacecraft","space","rendezvous","orbit","Vision-based pose estimation methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Event":2.0,"estimation":2.0,"which":2.0,"arXiv250705698v2 Announce Type":1.0,"Abstract":1.0,"Spacecraft":1.0,"space":1.0,"rendezvous":1.0,"orbit":1.0,"Vision-based pose estimation methods":1.0}},"age_hours":2.772355182222222,"is_recent":true,"quality_score":0.7,"sentiment_score":5.0645,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0129,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.3898,"joy":0.0056,"surprise":0.0264,"sadness":0.0343,"fear":0.157,"anger":0.2683,"disgust":0.1186},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a sensor fusion approach for spacecraft pose estimation, which could indirectly contribute to sustainability by improving the efficiency of on-orbit servicing and reducing space debris. The technology is currently in the applied research stage, with a real dataset collected in a laboratory setting. While the research is promising, it lacks deployment data and a clear path to economic viability, limiting its immediate sustainability impact.","key_impact_metrics":["Dataset released publicly"],"technology_tags":["sensor fusion","neuromorphic sensors","spacecraft pose estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:02.620865Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_60496c25e76a","title":"Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits","content":"arXiv:2507.06535v4 Announce Type: replace Abstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (BMSE) and balanced softmax cross-entropy (BSCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of $33.64\\% \\sim 44.20\\%$ for edge regression and F1-score gain of $0.9\\times \\sim 2.1\\times$ for node classification. Our code is available at https://github.com/ShenShan123/CircuitGCL.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.06535","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.893356","language":"en","tags":["research","preprints","eesssy","cssy","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Shan Shen, Shenglu Hua, Jiajun Zou, Jiawei Liu, Jianwang Zhai, Chuan Shi, Wenjian Yu","raw_content_length":1474,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Transferable Parasitic Estimation","Analog-Mixed Signal","Graph Contrastive Learning"],"persons":[],"locations":["node"],"monetary":[]},"char_count":1473,"language_detected":"en","key_concepts":{"key_phrases":["Transferable Parasitic Estimation","Graph Contrastive Learning","Label Rebalancing","AMS Circuits","arXiv250706535v4 Announce Type","Abstract","Graph representation learning","AMS","various downstream tasks","parasitic estimation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Transferable Parasitic Estimation":2.0,"Graph Contrastive Learning":2.0,"Label Rebalancing":2.0,"AMS Circuits":2.0,"arXiv250706535v4 Announce Type":1.0,"Abstract":1.0,"Graph representation learning":1.0,"AMS":1.0,"various downstream tasks":1.0,"parasitic estimation":1.0}},"age_hours":2.772370421666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8611,"joy":0.0088,"surprise":0.016,"sadness":0.012,"fear":0.0619,"anger":0.0238,"disgust":0.0164},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a novel graph contrastive learning framework (CircuitGCL) for parasitic estimation in AMS circuits, leading to improved accuracy in capacitance estimation. The concrete action is the development and evaluation of this framework on TSMC 28nm AMS designs, showing a 33.64%-44.20% improvement in R^2 for edge regression and a 0.9x-2.1x gain in F1-score for node classification. While promising, it's still in the applied research phase with no mention of commercial deployment.","key_impact_metrics":["R^2 improvement of 33.64%-44.20%","F1-score gain of 0.9x-2.1x"],"technology_tags":["Graph Contrastive Learning","Analog-Mixed Signal Circuits","Parasitic Estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:05.923937Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_71d7df2b824f","title":"AirScape: An Aerial Generative World Model with Motion Controllability","content":"arXiv:2507.08885v2 Announce Type: replace Abstract: How to enable agents to predict the outcomes of their own motion intentions in three-dimensional space has been a fundamental problem in embodied intelligence. To explore general spatial imagination capability, we present AirScape, the first world model designed for six-degree-of-freedom aerial agents. AirScape predicts future observation sequences based on current visual inputs and motion intentions. Specifically, we construct a dataset for aerial world model training and testing, which consists of 11k video-intention pairs. This dataset includes first-person-view videos capturing diverse drone actions across a wide range of scenarios, with over 1,000 hours spent annotating the corresponding motion intentions. Then we develop a two-phase schedule to train a foundation model--initially devoid of embodied spatial knowledge--into a world model that is controllable by motion intentions and adheres to physical spatio-temporal constraints. Experimental results demonstrate that AirScape significantly outperforms existing foundation models in 3D spatial imagination capabilities, especially with over a 50% improvement in metrics reflecting motion alignment. The project is available at: https://embodiedcity.github.io/AirScape/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.08885","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.893744","language":"en","tags":["research","csai","preprints","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Baining Zhao, Rongze Tang, Mingyuan Jia, Ziyou Wang, Fanghang Man, Xin Zhang, Yu Shang, Weichen Zhang, Wei Wu, Chen Gao, Xinlei Chen, Yong Li","raw_content_length":1291,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["AirScape"],"persons":[],"locations":[],"monetary":[]},"char_count":1290,"language_detected":"en","key_concepts":{"key_phrases":["AirScape","An Aerial Generative World Model","Motion","Controllability","arXiv250708885v2 Announce Type","Abstract","agents","the outcomes","their own motion intentions","three-dimensional space"],"filter_categories":{"ai_ml":["AirScape"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AirScape":4.0,"An Aerial Generative World Model":2.0,"Motion":2.0,"Controllability":2.0,"arXiv250708885v2 Announce Type":1.0,"Abstract":1.0,"agents":1.0,"the outcomes":1.0,"their own motion intentions":1.0,"three-dimensional space":1.0}},"age_hours":2.7723858944444446,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.879,"joy":0.0223,"surprise":0.0447,"sadness":0.004,"fear":0.0324,"anger":0.0129,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on developing a world model for aerial agents, which could potentially improve the efficiency of drone operations in various sectors. The article presents experimental results with a 50% improvement in motion alignment metrics, but it's still in the early stages of development with no clear path to economic viability or deployment at scale. The sustainability impact is theoretical at this stage.","key_impact_metrics":["50% improvement in motion alignment"],"technology_tags":["aerial robotics","world model","generative AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:09.094320Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c30e468656ea","title":"Networked Information Aggregation via Machine Learning","content":"arXiv:2507.09683v2 Announce Type: replace Abstract: We study a distributed learning problem in which learning agents are embedded in a directed acyclic graph (DAG). There is a fixed and arbitrary distribution over feature/label pairs, and each agent or vertex in the graph is able to directly observe only a subset of the features -- potentially a different subset for every agent. The agents learn sequentially in some order consistent with a topological sort of the DAG, committing to a model mapping observations to predictions of the real-valued label. Each agent observes the predictions of their parents in the DAG, and trains their model using both the features of the instance that they directly observe, and the predictions of their parents as additional features. We ask when this process is sufficient to achieve \\emph{information aggregation}, in the sense that some agent in the DAG is able to learn a model whose error is competitive with the best model that could have been learned (in some hypothesis class) with direct access to \\emph{all} features, despite the fact that no single agent in the network has such access. We give upper and lower bounds for this problem for both linear and general hypothesis classes. Our results identify the \\emph{depth} of the DAG as the key parameter: information aggregation can occur over sufficiently long paths in the DAG, assuming that all of the relevant features are well represented along the path, and there are distributions over which information aggregation cannot occur even in the linear case, and even in arbitrarily large DAGs that do not have sufficient depth (such as a hub-and-spokes topology in which the spoke vertices collectively see all the features). We complement our theoretical results with a comprehensive set of experiments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.09683","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.894571","language":"en","tags":["research","csgt","preprints","cslg","econth","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":289,"author":"Michael Kearns, Aaron Roth, Emily Ryu","raw_content_length":1807,"priority":7,"update_frequency":1,"reading_time_minutes":1.445,"robust_parsing_used":true,"entities":{"organizations":["Networked Information Aggregation","DAG"],"persons":["Machine Learning arXiv:2507.09683v2"],"locations":[],"monetary":[]},"char_count":1806,"language_detected":"en","key_concepts":{"key_phrases":["Networked Information Aggregation","Machine Learning","arXiv250709683v2 Announce Type","Abstract","a distributed learning problem","which","learning agents","a directed acyclic graph","DAG","a fixed and arbitrary distribution"],"filter_categories":{"ai_ml":["Machine Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Networked Information Aggregation":2.0,"Machine Learning":2.0,"arXiv250709683v2 Announce Type":1.0,"Abstract":1.0,"a distributed learning problem":1.0,"which":1.0,"learning agents":1.0,"a directed acyclic graph":1.0,"DAG":1.0,"a fixed and arbitrary distribution":1.0}},"age_hours":2.772416196388889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9108,"joy":0.006,"surprise":0.0348,"sadness":0.0041,"fear":0.0111,"anger":0.0193,"disgust":0.014},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical results and experiments on a distributed learning problem. While the research could potentially contribute to more efficient information aggregation in various domains, including those relevant to sustainability, it's currently at a basic research stage with no concrete deployments or quantified climate impact. The technical credibility is high due to the mathematical rigor and experimental validation.","key_impact_metrics":[],"technology_tags":["machine learning","distributed learning","information aggregation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:11.988538Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b245eb25c852","title":"MP1: MeanFlow Tames Policy Learning in 1","content":"arXiv:2507.10543v4 Announce Type: replace Abstract: In robot manipulation, robot learning has become a prevailing approach. However, generative models within this field face a fundamental trade-off between the slow, iterative sampling of diffusion models and the architectural constraints of faster Flow-based methods, which often rely on explicit consistency losses. To address these limitations, we introduce MP1, which pairs 3D point-cloud inputs with the MeanFlow paradigm to generate action trajectories in one network function evaluation (1-NFE). By directly learning the interval-averaged velocity via the \"MeanFlow Identity\", our policy avoids any additional consistency constraints. This formulation eliminates numerical ODE-solver errors during inference, yielding more precise trajectories. MP1 further incorporates CFG for improved trajectory controllability while retaining 1-NFE inference without reintroducing structural constraints. Because subtle scene-context variations are critical for robot learning, especially in few-shot learning, we introduce a lightweight Dispersive Loss that repels state embeddings during training, boosting generalization without slowing inference. We validate our method on the Adroit and Meta-World benchmarks, as well as in real-world scenarios. Experimental results show MP1 achieves superior average task success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Its average inference time is only 6.8 ms-19x faster than DP3 and nearly 2x faster than FlowPolicy. Our project page is available at https://mp1-2254.github.io/, and the code can be accessed at https://github.com/LogSSim/MP1.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.10543","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.895215","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Juyi Sheng, Ziyi Wang, Peiming Li, Mengyuan Liu","raw_content_length":1648,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["the \"MeanFlow Identity","MeanFlow"],"persons":[],"locations":[],"monetary":[]},"char_count":1647,"language_detected":"en","key_concepts":{"key_phrases":["MP1","MeanFlow Tames Policy Learning","which","arXiv250710543v4","Announce Type","Abstract","robot manipulation","robot learning","a prevailing approach","generative models"],"filter_categories":{"ai_ml":["a prevailing approach"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MP1":3.0,"MeanFlow Tames Policy Learning":2.0,"which":2.0,"arXiv250710543v4":1.0,"Announce Type":1.0,"Abstract":1.0,"robot manipulation":1.0,"robot learning":1.0,"a prevailing approach":1.0,"generative models":1.0}},"age_hours":2.7724311725,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9288,"joy":0.0054,"surprise":0.0271,"sadness":0.0096,"fear":0.0117,"anger":0.01,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel algorithm (MP1) for robot learning, demonstrating superior performance in simulation and real-world scenarios compared to existing methods. The concrete action is the development and validation of this new algorithm. The evidence supporting claims includes experimental results showing improved task success rates and faster inference times. However, it is still in the early stages of deployment, primarily validated in controlled environments.","key_impact_metrics":["average task success rates improved by 10.2% over DP3","average inference time of 6.8 ms"],"technology_tags":["robot learning","generative models","MeanFlow"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:15.328145Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_184b0992b7f6","title":"Towards a Non","content":"arXiv:2507.11678v2 Announce Type: replace Abstract: Twelve years have passed since World IPv6 Launch Day, but what is the current state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can a user do any IPv6? As deployment increases, we must consider a more nuanced, non-binary perspective on IPv6: how much and often can a user or a service use IPv6? We consider this question as a client, server, and cloud provider. Considering the client's perspective, we observe user traffic. We see that the fraction of IPv6 traffic a user sends varies greatly, both across users and day-by-day, with a standard deviation of over 15%. We show this variation occurs for two main reasons. First, IPv6 traffic is primarily human-generated, thus showing diurnal patterns. Second, some services lead with full IPv6 adoption, while others lag with partial or no support, so as users do different things their fraction of IPv6 varies. We look at server-side IPv6 adoption in two ways. First, we expand analysis of web services to examine how many are only partially IPv6 enabled due to their reliance on IPv4-only resources. Our findings reveal that only 12.6% of top 100k websites qualify as fully IPv6-ready. Finally, we examine cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that tenant deployment rates vary significantly across providers. We find that ease of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates, and recommend best practices for cloud providers to improve IPv6 adoption. Our results suggest IPv6 deployment is growing, but many services lag, presenting a potential for improvement.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.11678","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.895665","language":"en","tags":["preprints","computer-science","csni","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":267,"author":"Sulyab Thottungal Valapu, John Heidemann","raw_content_length":1656,"priority":7,"update_frequency":1,"reading_time_minutes":1.335,"robust_parsing_used":true,"entities":{"organizations":["IPv6"],"persons":[],"locations":[],"monetary":[]},"char_count":1655,"language_detected":"en","key_concepts":{"key_phrases":["a Non","Announce Type","Abstract","Twelve years","World IPv6 Launch Day","what","the current state","IPv6 deployment","Prior work","IPv6 status"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"a Non":2.0,"Announce Type":1.0,"Abstract":1.0,"Twelve years":1.0,"World IPv6 Launch Day":1.0,"what":1.0,"the current state":1.0,"IPv6 deployment":1.0,"Prior work":1.0,"IPv6 status":1.0}},"age_hours":2.7724489130555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9358,"joy":0.0026,"surprise":0.0333,"sadness":0.0062,"fear":0.0065,"anger":0.0082,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"impact_measurement","innovation_stage":"commercial","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":7,"systemic_impact":5,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article analyzes IPv6 deployment and its impact on network efficiency. While not directly climate-related, increased network efficiency can reduce energy consumption in data centers and network infrastructure. The study provides concrete data on IPv6 adoption rates and identifies areas for improvement, backed by research and analysis of real-world traffic data.","key_impact_metrics":["12.6% of top 100k websites fully IPv6-ready","Standard deviation of IPv6 traffic a user sends is over 15%"],"technology_tags":["IPv6","Network Efficiency","Cloud Computing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:18.148446Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6b8c85d4f66f","title":"Preprint: Poster: Did I Just Browse A Website Written by LLMs?","content":"arXiv:2507.13933v2 Announce Type: replace Abstract: Increasingly, web content is automatically generated by large language models (LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs plagiarize and hallucinate, LLM-dominant content can be unreliable and unethical. Yet, websites rarely disclose such content, and human readers struggle to distinguish it. Thus, we must develop reliable detectors for LLM-dominant content. However, state-of-the-art LLM detectors are inaccurate on web content, because web content has low positive rates, complex markup, and diverse genres, instead of clean, prose-like benchmark data SoTA detectors are optimized for. We propose a highly reliable, scalable pipeline that classifies entire websites. Instead of naively classifying text extracted from each page, we classify each site based on an LLM text detector's outputs of multiple prose-like pages to boost accuracies. We train and evaluate our detector by collecting 2 distinct ground truth datasets totaling 120 sites, and obtain 100% accuracies testing across them. In the wild, we detect a sizable portion of sites as LLM-dominant among 10k sites in search engine results and 10k in Common Crawl archives. We find LLM-dominant sites are growing in prevalence and rank highly in search results, raising questions about their impact on end users and the overall Web ecosystem.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.13933","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.896955","language":"en","tags":["csir","research","csai","csni","cscl","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Sichang Steven He, Ramesh Govindan, Harsha V. Madhyastha","raw_content_length":1395,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["LLM","SoTA"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Preprint","Poster","A Website","LLM-dominant content","Announce Type","Abstract","web content","large language models","little human input"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Preprint":2.0,"Poster":2.0,"A Website":2.0,"LLM-dominant content":2.0,"Announce Type":1.0,"Abstract":1.0,"web content":1.0,"large language models":1.0,"little human input":1.0}},"age_hours":2.7724972366666663,"is_recent":true,"quality_score":1.0,"sentiment_score":1.596,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6808,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6467,"joy":0.0048,"surprise":0.0122,"sadness":0.0112,"fear":0.0371,"anger":0.0735,"disgust":0.2146},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on detecting LLM-generated content on websites, which, while important for information integrity, has an indirect and theoretical impact on sustainability. The concrete action is the development of a detector pipeline, and the evidence is the reported 100% accuracy on test datasets. It's in the applied research stage, with no immediate path to economic viability or deployment.","key_impact_metrics":["100% accuracy on test datasets","Sizable portion of sites detected as LLM-dominant"],"technology_tags":["LLM detection","Web content analysis"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T09:54:20.928301Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9165c775154","title":"Enabling Self-Improving Agents to Learn at Test Time With Human-In","content":"arXiv:2507.17131v2 Announce Type: replace Abstract: Large language model (LLM) agents often struggle in environments where rules and required domain knowledge frequently change, such as regulatory compliance and user risk screening. Current approaches, like offline fine-tuning and standard prompting, are insufficient because they cannot effectively adapt to new knowledge during actual operation. To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time. ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts. It then systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries. We evaluate ARIA on the realistic customer due diligence name screening task on TikTok Pay, alongside publicly available dynamic knowledge tasks. Results demonstrate significant improvements in adaptability and accuracy compared to baselines using standard offline fine-tuning and existing self-improving agents. ARIA is deployed within TikTok Pay serving over 150 million monthly active users, confirming its practicality and effectiveness for operational use in rapidly evolving environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.17131","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.897405","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Yufei He, Ruoyu Li, Alex Chen, Yue Liu, Yulin Chen, Yuan Sui, Cheng Chen, Yi Zhu, Luca Luo, Frank Yang, Bryan Hooi","raw_content_length":1480,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["LLM","the Adaptive Reflective Interactive"],"persons":["ARIA","Announce Type"],"locations":[],"monetary":[]},"char_count":1479,"language_detected":"en","key_concepts":{"key_phrases":["Self-Improving Agents","Test Time","Human-In","arXiv250717131v2","Announce Type","Abstract","Large language model LLM agents","environments","rules","required domain knowledge"],"filter_categories":{"ai_ml":["Large language model LLM agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Self-Improving Agents":2.0,"Test Time":2.0,"Human-In":2.0,"arXiv250717131v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Large language model LLM agents":1.0,"environments":1.0,"rules":1.0,"required domain knowledge":1.0}},"age_hours":2.772512283888889,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2824999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7435,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8533,"joy":0.0046,"surprise":0.0202,"sadness":0.0341,"fear":0.0611,"anger":0.0157,"disgust":0.011},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":true},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AI agent, ARIA, used within TikTok Pay for customer due diligence. It demonstrates improved adaptability and accuracy compared to baselines, and is serving over 150 million monthly active users. The regulatory compliance aspect suggests some level of government oversight.","key_impact_metrics":["150 million monthly active users","Significant improvements in adaptability and accuracy"],"technology_tags":["LLM agent","AI","machine learning"],"sdg_alignment":[8,9,16],"analyzed_at":"2025-10-29T09:54:23.354593Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03559d1fc19b","title":"TTS-VAR: A Test","content":"arXiv:2507.18537v2 Announce Type: replace Abstract: Scaling visual generation models is essential for real-world content creation, yet requires substantial training and computational expenses. Alternatively, test-time scaling has garnered growing attention due to resource efficiency and promising performance. In this work, we present TTS-VAR, the first general test-time scaling framework for visual auto-regressive (VAR) models, modeling the generation process as a path searching problem. To dynamically balance computational efficiency with exploration capacity, we first introduce an adaptive descending batch size schedule throughout the causal generation process. Besides, inspired by VAR's hierarchical coarse-to-fine multi-scale generation, our framework integrates two key components: (i) At coarse scales, we observe that generated tokens are hard for evaluation, possibly leading to erroneous acceptance of inferior samples or rejection of superior samples. Noticing that the coarse scales contain sufficient structural information, we propose clustering-based diversity search. It preserves structural variety through semantic feature clustering, enabling later selection on samples with higher potential. (ii) In fine scales, resampling-based potential selection prioritizes promising candidates using potential scores, which are defined as reward functions incorporating multi-scale generation history. Experiments on the powerful VAR model Infinity show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights reveal that early-stage structural features effectively influence final quality, and resampling efficacy varies across generation scales. Code is available at https://github.com/ali-vilab/TTS-VAR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.18537","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.897862","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Zhekai Chen, Ruihang Chu, Yukang Chen, Shiwei Zhang, Yujie Wei, Yingya Zhang, Xihui Liu","raw_content_length":1743,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["VAR","TTS","TTS-VAR"],"persons":[],"locations":[],"monetary":[]},"char_count":1742,"language_detected":"en","key_concepts":{"key_phrases":["TTS-VAR","A Test","arXiv250718537v2 Announce Type","Abstract","visual generation models","real-world content creation","substantial training","computational expenses","test-time scaling","growing attention"],"filter_categories":{"ai_ml":["substantial training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TTS-VAR":3.0,"A Test":2.0,"arXiv250718537v2 Announce Type":1.0,"Abstract":1.0,"visual generation models":1.0,"real-world content creation":1.0,"substantial training":1.0,"computational expenses":1.0,"test-time scaling":1.0,"growing attention":1.0}},"age_hours":2.772527953888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8577,"joy":0.0809,"surprise":0.0345,"sadness":0.0047,"fear":0.0073,"anger":0.0096,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel test-time scaling framework (TTS-VAR) for visual auto-regressive models, aiming to improve computational efficiency in visual generation. It reports an 8.7% GenEval score improvement on the Infinity VAR model, suggesting a potential for resource reduction in AI model training. However, it remains in the applied research stage with no real-world deployment or economic viability demonstrated.","key_impact_metrics":["8.7% GenEval score improvement"],"technology_tags":["Visual Auto-Regressive Models","Test-Time Scaling","AI Efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:54:26.406490Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2df40da9eeaa","title":"Communication","content":"arXiv:2507.20424v2 Announce Type: replace Abstract: We study centralized distributed data parallel training of deep neural networks (DNNs), aiming to improve the trade-off between communication efficiency and model performance of the local gradient methods. To this end, we revisit the flat-minima hypothesis, which suggests that models with better generalization tend to lie in flatter regions of the loss landscape. We introduce a simple, yet effective, sharpness measure, Inverse Mean Valley, and demonstrate its strong correlation with the generalization gap of DNNs. We incorporate an efficient relaxation of this measure into the distributed training objective as a lightweight regularizer that encourages workers to collaboratively seek wide minima. The regularizer exerts a pushing force that counteracts the consensus step pulling the workers together, giving rise to the Distributed Pull-Push Force (DPPF) algorithm. Empirically, we show that DPPF outperforms other communication-efficient approaches and achieves better generalization performance than local gradient methods and synchronous gradient averaging, while maintaining communication efficiency. In addition, our loss landscape visualizations confirm the ability of DPPF to locate flatter minima. On the theoretical side, we show that DPPF guides workers to span flat valleys, with the final valley width governed by the interplay between push and pull strengths, and that its pull-push dynamics is self-stabilizing. We further provide generalization guarantees linked to the valley width and prove convergence in the non-convex setting.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.20424","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.898330","language":"en","tags":["csdc","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Tolga Dimlioglu, Anna Choromanska","raw_content_length":1608,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["Inverse Mean Valley","the Distributed Pull-Push Force"],"persons":[],"locations":[],"monetary":[]},"char_count":1607,"language_detected":"en","key_concepts":{"key_phrases":["Communication","Announce Type","Abstract","centralized distributed data parallel training","deep neural networks","DNNs","the trade-off","communication efficiency","model performance","the local gradient methods"],"filter_categories":{"ai_ml":["centralized distributed data parallel training","deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Communication":2.0,"Announce Type":1.0,"Abstract":1.0,"centralized distributed data parallel training":1.0,"deep neural networks":1.0,"DNNs":1.0,"the trade-off":1.0,"communication efficiency":1.0,"model performance":1.0,"the local gradient methods":1.0}},"age_hours":2.7725430513888885,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8591,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9138,"joy":0.0259,"surprise":0.0361,"sadness":0.0044,"fear":0.0032,"anger":0.0104,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (DPPF) for distributed training of deep neural networks, aiming to improve communication efficiency and model generalization. While the algorithm shows promising results in simulations and theoretical analysis, it is still in the early stages of development and lacks real-world deployment data. The potential climate impact is indirect, as improved AI training efficiency could reduce energy consumption in data centers, but this is not explicitly quantified.","key_impact_metrics":["Generalization gap of DNNs","Valley width"],"technology_tags":["Distributed training","Deep neural networks","Communication efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:29.409445Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_544fc774af93","title":"CAPE: A CLIP","content":"arXiv:2507.21888v2 Announce Type: replace Abstract: We address the problem of Embodied Reference Understanding, which involves predicting the object that a person in the scene is referring to through both pointing gesture and language. Accurately identifying the referent requires multimodal understanding: integrating textual instructions, visual pointing, and scene context. However, existing methods often struggle to effectively leverage visual clues for disambiguation. We also observe that, while the referent is often aligned with the head-to-fingertip line, it occasionally aligns more closely with the wrist-to-fingertip line. Therefore, relying on a single line assumption can be overly simplistic and may lead to suboptimal performance. To address this, we propose a dual-model framework, where one model learns from the head-to-fingertip direction and the other from the wrist-to-fingertip direction. We further introduce a Gaussian ray heatmap representation of these lines and use them as input to provide a strong supervisory signal that encourages the model to better attend to pointing cues. To combine the strengths of both models, we present the CLIP-Aware Pointing Ensemble module, which performs a hybrid ensemble based on CLIP features. Additionally, we propose an object center prediction head as an auxiliary task to further enhance referent localization. We validate our approach through extensive experiments and analysis on the benchmark YouRefIt dataset, achieving an improvement of approximately 4 mAP at the 0.25 IoU threshold. We further evaluate our approach on the CAESAR and ISL Pointing datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.21888","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.898759","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Fevziye Irem Eyiokur, Dogucan Yaman, Haz{\\i}m Kemal Ekenel, Alexander Waibel","raw_content_length":1632,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["Embodied Reference Understanding","CLIP"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1631,"language_detected":"en","key_concepts":{"key_phrases":["CAPE","arXiv250721888v2 Announce Type","Abstract","the problem","Embodied Reference Understanding","which","the object","a person","the scene","both pointing gesture"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CAPE":2.0,"arXiv250721888v2 Announce Type":1.0,"Abstract":1.0,"the problem":1.0,"Embodied Reference Understanding":1.0,"which":1.0,"the object":1.0,"a person":1.0,"the scene":1.0,"both pointing gesture":1.0}},"age_hours":2.7725578425,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9303,"joy":0.0022,"surprise":0.0157,"sadness":0.0138,"fear":0.0131,"anger":0.0128,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to Embodied Reference Understanding using a dual-model framework and CLIP features. The concrete action is the development of a new model and its validation on benchmark datasets, achieving an improvement of approximately 4 mAP at the 0.25 IoU threshold. The research is at a basic research stage with no deployment yet.","key_impact_metrics":["4 mAP improvement at 0.25 IoU"],"technology_tags":["Embodied Reference Understanding","CLIP","Machine Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:54:32.685135Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f910afa3228c","title":"UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing","content":"arXiv:2507.23278v2 Announce Type: replace Abstract: In this paper, we propose UniLIP, a unified framework that adapts CLIP for multimodal understanding, generation and editing. Although CLIP excels at understanding, it lacks reconstruction abilities required to be a unified visual encoder. However, previous CLIP-based unified methods fail to balance understanding and reconstruction, leading to semantic degradation or inconsistent reconstructions. In contrast, we introduce a novel two-stage training scheme with a self-distillation strategy that progressively endows CLIP with high-fidelity reconstruction abilities while preserving its original comprehension performance. For enhanced reasoning and consistency in generation and editing, we further develop a dual-condition architecture built upon the MetaQuery framework. Our architecture jointly utilizes multimodal hidden states for rich contextual details and learnable query embeddings to harness the powerful reasoning abilities of Multimodal Large Language Models (MLLMs). Leveraging advanced image representation and architectural design, UniLIP demonstrates superior instruction following and edit fidelity. With only 1B and 3B parameters, UniLIP can outperform larger unified models such as BAGEL (7B) and Uniworld-V1 (12B), achieving state-of-the-art performance of 0.90 on GenEval, 0.63 on WISE, and 3.94 on ImgEdit. These results demonstrate that UniLIP successfully expands the application of CLIP, establishing its continuous features to not only serve as the optimal choice for understanding tasks but also achieve highly competitive performance in generation and editing tasks. Code and models are available at https://github.com/nnnth/UniLIP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.23278","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.899178","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Hao Tang, Chenwei Xie, Xiaoyi Bao, Tingyu Weng, Pandeng Li, Yun Zheng, Liwei Wang","raw_content_length":1716,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["UniLIP","MetaQuery","CLIP"],"persons":[],"locations":[],"monetary":[]},"char_count":1715,"language_detected":"en","key_concepts":{"key_phrases":["CLIP","Unified Multimodal Understanding","Generation","Editing","understanding","arXiv250723278v2 Announce Type","Abstract","this paper","UniLIP","a unified framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CLIP":3.0,"Unified Multimodal Understanding":2.0,"Generation":2.0,"Editing":2.0,"understanding":2.0,"arXiv250723278v2 Announce Type":1.0,"Abstract":1.0,"this paper":1.0,"UniLIP":1.0,"a unified framework":1.0}},"age_hours":2.7725724291666665,"is_recent":true,"quality_score":1.0,"sentiment_score":8.953,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7906,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8072,"joy":0.011,"surprise":0.0421,"sadness":0.0673,"fear":0.0136,"anger":0.0276,"disgust":0.0312},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework (UniLIP) that improves multimodal understanding, generation, and editing. While it achieves state-of-the-art performance on specific benchmarks (GenEval, WISE, ImgEdit), it's still in the applied research stage with no evidence of real-world deployment or quantifiable environmental impact. The potential for sustainability impact is indirect, through improved efficiency in AI applications that could potentially contribute to climate solutions, but this is not explicitly demonstrated or quantified.","key_impact_metrics":["GenEval score: 0.90","WISE score: 0.63","ImgEdit score: 3.94"],"technology_tags":["Multimodal AI","CLIP adaptation","Image generation","Image editing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:35.971541Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c44ab98a3fe0","title":"TriP-LLM: A Tri-Branch Patch","content":"arXiv:2508.00047v2 Announce Type: replace Abstract: Time-series anomaly detection plays a central role across a wide range of application domains. With the increasing proliferation of the Internet of Things (IoT) and smart manufacturing, time-series data has dramatically increased in both scale and dimensionality. This growth has exposed the limitations of traditional statistical methods in handling the high heterogeneity and complexity of such data. Inspired by the recent success of large language models (LLMs) in multimodal tasks across language and vision domains, we propose a novel unsupervised anomaly detection framework: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection (TriP-LLM). TriP-LLM integrates local and global temporal features through a triple-branch design comprising Patching, Selecting, and Global modules, to encode the input time-series into patch-wise representations, which are then processed by a frozen, pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from which anomaly scores are derived. We evaluate TriP-LLM on several public benchmark datasets using PATE, a recently proposed threshold-free evaluation metric, and conduct all comparisons within a unified open-source framework to ensure fairness. Experimental results show that TriP-LLM consistently outperforms recent state-of-the-art (SOTA) methods across all datasets, demonstrating strong detection capabilities. Furthermore, through extensive ablation studies, we verify the substantial contribution of the LLM to the overall architecture. Compared to LLM-based approaches using Channel Independence (CI) patch processing, TriP-LLM achieves significantly lower memory consumption, making it more suitable for GPU memory-constrained environments. All code and model checkpoints of TriP-LLM are publicly available on https://github.com/YYZStart/TriP-LLM.git","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.00047","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.899811","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":246,"author":"Yuan-Cheng Yu, Yen-Chieh Ouyang, Chun-An Lin","raw_content_length":1914,"priority":7,"update_frequency":1,"reading_time_minutes":1.23,"robust_parsing_used":true,"entities":{"organizations":["Tri-Branch Patch arXiv:2508.00047v2 Announce Type: replace Abstract","IoT","Tri-Branch Patch-wise"],"persons":["Selecting"],"locations":["Patching"],"monetary":[]},"char_count":1913,"language_detected":"en","key_concepts":{"key_phrases":["TriP-LLM A Tri-Branch Patch","arXiv250800047v2 Announce Type","Abstract","Time-series anomaly detection","a central role","a wide range","application domains","the increasing proliferation","the Internet","Things"],"filter_categories":{"ai_ml":["TriP-LLM A Tri-Branch Patch"],"engineering":["Things"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TriP-LLM A Tri-Branch Patch":2.0,"arXiv250800047v2 Announce Type":1.0,"Abstract":1.0,"Time-series anomaly detection":1.0,"a central role":1.0,"a wide range":1.0,"application domains":1.0,"the increasing proliferation":1.0,"the Internet":1.0,"Things":1.0}},"age_hours":2.7725880666666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.467,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8934,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7985,"joy":0.0199,"surprise":0.1526,"sadness":0.0043,"fear":0.0113,"anger":0.0106,"disgust":0.0028},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel LLM-based framework for time-series anomaly detection, showing improved performance on benchmark datasets. While the research is promising, it's still in the applied research phase with no deployed units or real-world operational data. The reduction in memory consumption compared to other LLM approaches is a concrete benefit.","key_impact_metrics":["Lower memory consumption"],"technology_tags":["Large Language Models","Anomaly Detection","Time-Series Analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:39.018776Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0145afc08e1a","title":"Prototype Learning to Create Refined Interpretable Digital Phenotypes from ECGs","content":"arXiv:2508.01521v2 Announce Type: replace Abstract: Prototype-based neural networks offer interpretable predictions by comparing inputs to learned, representative signal patterns anchored in training data. While such models have shown promise in the classification of physiological data, it remains unclear whether their prototypes capture an underlying structure that aligns with broader clinical phenotypes. We use a prototype-based deep learning model trained for multi-label ECG classification using the PTB-XL dataset. Then without modification we performed inference on the MIMIC-IV clinical database. We assess whether individual prototypes, trained solely for classification, are associated with hospital discharge diagnoses in the form of phecodes in this external population. Individual prototypes demonstrate significantly stronger and more specific associations with clinical outcomes compared to the classifier's class predictions, NLP-extracted concepts, or broader prototype classes across all phecode categories. Prototype classes with mixed significance patterns exhibit significantly greater intra-class distances (p $<$ 0.0001), indicating the model learned to differentiate clinically meaningful variations within diagnostic categories. The prototypes achieve strong predictive performance across diverse conditions, with AUCs ranging from 0.89 for atrial fibrillation to 0.91 for heart failure, while also showing substantial signal for non-cardiac conditions such as sepsis and renal disease. These findings suggest that prototype-based models can support interpretable digital phenotyping from physiologic time-series data, providing transferable intermediate phenotypes that capture clinically meaningful physiologic signatures beyond their original training objectives.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.01521","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.900246","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Sahil Sethi, David Chen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones","raw_content_length":1795,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["Create Refined Interpretable Digital Phenotypes","Prototype Learning","PTB","ECG"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1794,"language_detected":"en","key_concepts":{"key_phrases":["Prototype Learning","Refined Interpretable Digital Phenotypes","ECGs","arXiv250801521v2 Announce Type","Abstract","Prototype-based neural networks","interpretable predictions","inputs","learned representative signal patterns","training data"],"filter_categories":{"ai_ml":["Prototype-based neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Prototype Learning":2.0,"Refined Interpretable Digital Phenotypes":2.0,"ECGs":2.0,"arXiv250801521v2 Announce Type":1.0,"Abstract":1.0,"Prototype-based neural networks":1.0,"interpretable predictions":1.0,"inputs":1.0,"learned representative signal patterns":1.0,"training data":1.0}},"age_hours":2.7726024208333335,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9189,"joy":0.0103,"surprise":0.0433,"sadness":0.0046,"fear":0.0076,"anger":0.0092,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a prototype deep learning model for ECG analysis, demonstrating its ability to identify clinically meaningful variations. The model achieves strong predictive performance across diverse conditions, with AUCs ranging from 0.89 for atrial fibrillation to 0.91 for heart failure. However, it is still in the applied research phase with no deployed units or customer contracts, limiting its immediate sustainability impact.","key_impact_metrics":["AUC of 0.89 for atrial fibrillation","AUC of 0.91 for heart failure"],"technology_tags":["deep learning","ECG analysis","digital phenotyping"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:54:42.069714Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9fc04e7753ad","title":"VAGPO: Vision","content":"arXiv:2508.01774v2 Announce Type: replace Abstract: Graph routing problems play a vital role in web-related networks, where finding optimal paths across graphs is essential for efficient data transmission and content delivery. Classic routing formulations such as the Traveling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) represent fundamental graph optimization challenges. Recent data-driven optimization methods have made significant progress, yet they often face limitations in training efficiency and generalization to large-scale instances. In this paper, we propose a novel Vision-augmented Asymmetric Group Preference Optimization (VAGPO) approach. By leveraging ResNet-based visual encoding and Transformer-based sequential modeling, VAGPO captures both spatial structure and temporal dependencies. Furthermore, we introduce an asymmetric group preference optimization strategy that significantly accelerates convergence compared to commonly used policy gradient methods. Experimental results on generated TSP and CVRP instances, as well as real-world datasets, demonstrate that the proposed VAGPO approach achieves highly competitive solution quality. Additionally, VAGPO exhibits strong generalization to larger instances (up to 1000 nodes) without re-training, highlighting its effectiveness in both learning efficiency and scalability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.01774","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.900692","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Shiyan Liu, Bohan Tan, Zhiguang Cao, Yan Jin","raw_content_length":1379,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Vision","Asymmetric Group Preference Optimization","the Capacitated Vehicle Routing Problem","VAGPO","Transformer","CVRP","ResNet","the Traveling Salesman Problem"],"persons":[],"locations":[],"monetary":[]},"char_count":1378,"language_detected":"en","key_concepts":{"key_phrases":["VAGPO","Vision","Announce Type","Abstract","problems","a vital role","web-related networks","optimal paths","graphs","efficient data transmission and content delivery"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VAGPO":2.0,"Vision":2.0,"Announce Type":1.0,"Abstract":1.0,"problems":1.0,"a vital role":1.0,"web-related networks":1.0,"optimal paths":1.0,"graphs":1.0,"efficient data transmission and content delivery":1.0}},"age_hours":2.7726168844444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8979,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5804,"joy":0.0051,"surprise":0.0166,"sadness":0.0163,"fear":0.2962,"anger":0.0482,"disgust":0.0373},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper proposes a novel approach to graph routing problems, which could potentially improve the efficiency of data transmission and content delivery in web-related networks. While the approach demonstrates competitive solution quality and generalization capabilities on generated and real-world datasets, it is still in the applied research phase with no concrete deployments. The impact on climate change is indirect, as more efficient routing could reduce energy consumption in data centers, but this is not quantified.","key_impact_metrics":["Solution quality on TSP and CVRP instances","Generalization to larger instances (up to 1000 nodes)"],"technology_tags":["Graph routing","Optimization algorithms","ResNet","Transformer networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:45.127607Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4ec766d3b456","title":"Modeling and Simulation of an Active Car Suspension with a Robust LQR Controller under Road Disturbance, Parameter Uncertainty and White Noise","content":"arXiv:2508.02906v4 Announce Type: replace Abstract: Vehicle suspension is important for passengers to travel comfortably and to be less exposed to effects such as vibration and shock. A good suspension system increases the road holding of vehicles, allows them to take turns safely, and reduces the risk of traffic accidents. A passive suspension system is the most widely used suspension system in vehicles due to its simple structure and low cost. Passive suspension systems do not have an actuator and therefore do not have a controller. Active suspension systems have an actuator and a controller. Although their structures are more complex and costly, they are safer. PID controller is widely used in active suspension systems due to its simple structure, reasonable cost, and easy adjustment of coefficients. In this study, a more robust LQR-controlled active suspension was designed than a passive suspension and a PID-controlled active suspension. Robustness analyses were performed for passive suspension, PID-controlled active suspension, and LQR-controlled active suspension. Suspension travel, sprung mass acceleration, and sprung mass motion simulations were performed for all three suspensions under road disturbance, under simultaneous road disturbance and parameter uncertainty and under road disturbance with white noise. A comparative analysis was performed by obtaining the rise time, overshoot, and settling time data of the suspensions under different conditions. It was observed that the LQR-controlled active suspension showed the fastest rise time, the least overshoot and had the shortest settling time. In this case, it was proven that the LQR controlled active suspension provided a more comfortable and safe ride compared to the other two suspension systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.02906","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.901545","language":"en","tags":["research","preprints","eesssy","cssy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":262,"author":"Mehmet Karahan","raw_content_length":1787,"priority":7,"update_frequency":1,"reading_time_minutes":1.31,"robust_parsing_used":true,"entities":{"organizations":["Parameter Uncertainty","PID","LQR"],"persons":["LQR Controller"],"locations":[],"monetary":[]},"char_count":1786,"language_detected":"en","key_concepts":{"key_phrases":["Modeling","Simulation","an Active Car Suspension","a Robust LQR Controller","Road Disturbance","Parameter Uncertainty","White Noise","vehicles","arXiv250802906v4","Announce Type"],"filter_categories":{"ai_ml":["Parameter Uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Modeling":2.0,"Simulation":2.0,"an Active Car Suspension":2.0,"a Robust LQR Controller":2.0,"Road Disturbance":2.0,"Parameter Uncertainty":2.0,"White Noise":2.0,"vehicles":2.0,"arXiv250802906v4":1.0,"Announce Type":1.0}},"age_hours":2.7726491927777777,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6801,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6085,"joy":0.022,"surprise":0.0142,"sadness":0.0135,"fear":0.321,"anger":0.0104,"disgust":0.0105},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a simulation study of an LQR-controlled active car suspension system. While it demonstrates improved performance in simulations (rise time, overshoot, settling time), it remains at the simulation stage with no evidence of real-world deployment or validation. The potential climate impact is indirect, through improved vehicle efficiency and safety, but is not quantified.","key_impact_metrics":["Fastest rise time","Least overshoot","Shortest settling time"],"technology_tags":["Active Suspension System","LQR Controller"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:54:48.350503Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_565d2ad3cd63","title":"Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov","content":"arXiv:2508.03105v2 Announce Type: replace Abstract: We analyze the convergence behavior of stochastic gradient descent with momentum (SGDM) under dynamic learning-rate and batch-size schedules by introducing a novel and simpler Lyapunov function. We extend the existing theoretical framework to cover three practical scheduling strategies commonly used in deep learning: a constant batch size with a decaying learning rate, an increasing batch size with a decaying learning rate, and an increasing batch size with an increasing learning rate. Our results reveal a clear hierarchy in convergence: a constant batch size does not guarantee convergence of the expected gradient norm, whereas an increasing batch size does, and simultaneously increasing both the batch size and learning rate achieves a provably faster decay. Empirical results validate our theory, showing that dynamically scheduled SGDM significantly outperforms its fixed-hyperparameter counterpart in convergence speed. We also evaluated a warm-up schedule in experiments, which empirically outperformed all other strategies in convergence behavior.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.03105","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.901931","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Yuichi Kondo, Hideaki Iiduka","raw_content_length":1115,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["Learning Rate","SGDM"],"persons":["Batch Size Schedules","Lyapunov"],"locations":[],"monetary":[]},"char_count":1114,"language_detected":"en","key_concepts":{"key_phrases":["SGDM","Learning Rate","Batch Size Schedules","a decaying learning rate","arXiv250803105v2","Announce Type","Abstract","the convergence behavior","stochastic gradient descent","momentum"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SGDM":3.0,"Learning Rate":2.0,"Batch Size Schedules":2.0,"a decaying learning rate":2.0,"arXiv250803105v2":1.0,"Announce Type":1.0,"Abstract":1.0,"the convergence behavior":1.0,"stochastic gradient descent":1.0,"momentum":1.0}},"age_hours":2.772664257777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8644,"joy":0.0121,"surprise":0.0196,"sadness":0.0057,"fear":0.0415,"anger":0.0377,"disgust":0.019},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical improvements to the SGDM algorithm, a core component of many machine learning models used in climate applications. While the paper shows improved convergence speed in experiments, it is still in the early research phase and doesn't directly translate to deployed climate solutions. The potential climate impact is indirect, as it could improve the efficiency of climate models or optimization of renewable energy systems.","key_impact_metrics":["faster decay of gradient norm","improved convergence speed"],"technology_tags":["stochastic gradient descent","machine learning","optimization"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T09:54:51.272214Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_25c2857e9148","title":"MedCAL","content":"arXiv:2508.03441v2 Announce Type: replace Abstract: Cold-Start Active Learning (CSAL) aims to select informative samples for annotation without prior knowledge, which is important for improving annotation efficiency and model performance under a limited annotation budget in medical image analysis. Most existing CSAL methods rely on Self-Supervised Learning (SSL) on the target dataset for feature extraction, which is inefficient and limited by insufficient feature representation. Recently, pre-trained Foundation Models (FMs) have shown powerful feature extraction ability with a potential for better CSAL. However, this paradigm has been rarely investigated, with a lack of benchmarks for comparison of FMs in CSAL tasks. To this end, we propose MedCAL-Bench, the first systematic FM-based CSAL benchmark for medical image analysis. We evaluate 14 FMs and 7 CSAL strategies across 7 datasets under different annotation budgets, covering classification and segmentation tasks from diverse medical modalities. It is also the first CSAL benchmark that evaluates both the feature extraction and sample selection stages. Our experimental results reveal that: 1) Most FMs are effective feature extractors for CSAL, with DINO family performing the best in segmentation; 2) The performance differences of these FMs are large in segmentation tasks, while small for classification; 3) Different sample selection strategies should be considered in CSAL on different datasets, with Active Learning by Processing Surprisal (ALPS) performing the best in segmentation while RepDiv leading for classification. The code is available at https://github.com/HiLab-git/MedCAL-Bench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.03441","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.902382","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Ning Zhu, Xiaochuan Ma, Shaoting Zhang, Guotai Wang","raw_content_length":1667,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Foundation Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1666,"language_detected":"en","key_concepts":{"key_phrases":["MedCAL","which","arXiv250803441v2 Announce Type","Abstract","Cold-Start Active Learning","CSAL","informative samples","annotation","prior knowledge","annotation efficiency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MedCAL":2.0,"which":2.0,"arXiv250803441v2 Announce Type":1.0,"Abstract":1.0,"Cold-Start Active Learning":1.0,"CSAL":1.0,"informative samples":1.0,"annotation":1.0,"prior knowledge":1.0,"annotation efficiency":1.0}},"age_hours":2.7726788763888885,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8131,"joy":0.0231,"surprise":0.0611,"sadness":0.0266,"fear":0.0088,"anger":0.0464,"disgust":0.0209},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a benchmark for foundation models in cold-start active learning for medical image analysis. While it shows improved annotation efficiency, the direct climate impact is indirect and difficult to quantify. The benchmark is in the applied research stage, with no deployed units or customer contracts, hence the vaporware risk.","key_impact_metrics":["Annotation budget reduction","Model performance improvement"],"technology_tags":["Active Learning","Foundation Models","Medical Image Analysis"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:54:54.314733Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1d7ed0743f8c","title":"EvoC2Rust: A Skeleton-guided Framework for Project-Level C","content":"arXiv:2508.04295v2 Announce Type: replace Abstract: Translating legacy C codebases to Rust is increasingly demanded for building safety-critical systems. While various approaches have emerged for this task, they face inherent trade-offs: rule-based methods often struggle to satisfy code safety and idiomaticity requirements, while LLM-based methods frequently fail to generate semantically equivalent Rust code, due to the heavy dependencies of modules across the entire codebase. Recent studies have revealed that both solutions are limited to small-scale programs. In this paper, we propose EvoC2Rust, an automated framework for converting complete C projects to equivalent Rust ones. EvoC2Rust employs a skeleton-guided translation strategy for project-level translation. The pipeline consists of three stages: 1) it first decomposes the C project into functional modules, employs a feature-mapping-enhanced LLM to transform definitions and macros, and generates type-checked function stubs, which form a compilable Rust skeleton; 2) it then incrementally translates functions, replacing the corresponding stub placeholders; 3) finally, it repairs compilation errors by integrating LLM and static analysis. Through evolutionary augmentation, EvoC2Rust combines the advantages of both rule-based and LLM-based solutions. Our evaluation on open-source benchmarks and six industrial projects demonstrates the superior performance of EvoC2Rust in project-level C-to-Rust translation. The results show that our approach outperforms the strongest LLM-based baseline by 17.24% in syntax accuracy and 14.32% in semantic accuracy, while also achieving a 43.59% higher code safety rate than the best rule-based tool.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.04295","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.902803","language":"en","tags":["csse","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Chaofan Wang, Tingrui Yu, Chen Xie, Jie Wang, Dong Chen, Wenrui Zhang, Yuling Shi, Xiaodong Gu, Beijun Shen","raw_content_length":1711,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["LLM","Project-Level C arXiv:2508.04295v2 Announce Type","Skeleton"],"persons":[],"locations":[],"monetary":[]},"char_count":1710,"language_detected":"en","key_concepts":{"key_phrases":["EvoC2Rust A Skeleton-guided Framework","Project-Level C","arXiv250804295v2 Announce Type","Abstract","legacy C","Rust","safety-critical systems","various approaches","this task","inherent trade-offs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"EvoC2Rust A Skeleton-guided Framework":2.0,"Project-Level C":2.0,"arXiv250804295v2 Announce Type":1.0,"Abstract":1.0,"legacy C":1.0,"Rust":1.0,"safety-critical systems":1.0,"various approaches":1.0,"this task":1.0,"inherent trade-offs":1.0}},"age_hours":2.772694548611111,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7504,"joy":0.0039,"surprise":0.0291,"sadness":0.1151,"fear":0.0294,"anger":0.0377,"disgust":0.0345},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework for translating C code to Rust, potentially improving code safety and reducing energy consumption in safety-critical systems. The framework has been evaluated on open-source benchmarks and industrial projects, showing improvements in syntax accuracy (17.24%) and semantic accuracy (14.32%) compared to LLM-based baselines. However, it is still in the applied research stage with no deployed units or customer contracts.","key_impact_metrics":["syntax accuracy 17.24%","semantic accuracy 14.32%"],"technology_tags":["C to Rust translation","LLM","static analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:54:57.254432Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_804952736ab3","title":"Reasoning through Exploration: A Reinforcement Learning Framework for Robust Function Calling","content":"arXiv:2508.05118v4 Announce Type: replace Abstract: The effective training of Large Language Models (LLMs) for function calling faces a critical challenge: balancing exploration of complex reasoning paths with stable policy optimization. Standard methods like Supervised Fine-Tuning (SFT) fail to instill robust reasoning, and traditional Reinforcement Learning (RL) struggles with inefficient exploration. We propose \\textbf{EGPO}, a new RL framework built upon Group Relative Policy Optimization (GRPO), designed to address this challenge directly. The core of EGPO is an entropy-enhanced advantage function that integrates the entropy of the model's Chain-of-Thought (CoT) into the policy gradient computation. This encourages the generation of diverse reasoning strategies. To maintain optimization direction, the entropy bonus is carefully constrained by a clipping mechanism. Complemented by a strict, binary reward signal, EGPO effectively guides the model towards discovering structured and accurate tool invocation patterns. On the challenging Berkeley Function Calling Leaderboard (BFCL), a 4B-parameter model trained with EGPO sets a new state-of-the-art among models of comparable size, surpassing a range of strong competitors, including GPT-4o and Gemini-2.5.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.05118","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.903657","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Bingguang Hao, Zengzhuang Xu, Maolin Wang, Yuntao Wen, Yicheng Chen, Cunyin Peng, Long Chen, Dong Wang, Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang, Ji Zhang","raw_content_length":1274,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Group Relative Policy Optimization","Reinforcement Learning","Large Language Models","CoT","SFT","GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1273,"language_detected":"en","key_concepts":{"key_phrases":["Exploration","Robust Function","Announce Type","Abstract","The effective training","Large Language Models","LLMs","function","a critical challenge","exploration"],"filter_categories":{"ai_ml":["The effective training","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Exploration":2.0,"Robust Function":2.0,"Announce Type":1.0,"Abstract":1.0,"The effective training":1.0,"Large Language Models":1.0,"LLMs":1.0,"function":1.0,"a critical challenge":1.0,"exploration":1.0}},"age_hours":2.7727258086111113,"is_recent":true,"quality_score":1.0,"sentiment_score":9.36,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.872,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.872,"joy":0.007,"surprise":0.0243,"sadness":0.0138,"fear":0.0188,"anger":0.0469,"disgust":0.0172},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new reinforcement learning framework (EGPO) for improving the function calling capabilities of large language models. While the framework achieves state-of-the-art performance on a specific benchmark (BFCL), its direct impact on sustainability is indirect and theoretical at this stage. The technology is still in the applied research phase, with no mention of real-world deployment or quantified environmental benefits.","key_impact_metrics":["State-of-the-art on Berkeley Function Calling Leaderboard (BFCL)"],"technology_tags":["Reinforcement Learning","Large Language Models","Function Calling"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:55:00.193621Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53aadbd9cbe1","title":"AMFT: Aligning LLM Reasoners by Meta","content":"arXiv:2508.06944v3 Announce Type: replace Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL), a process fraught with catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Recent single-stage methods attempt to unify SFT and RL using heuristics, but lack a principled mechanism for dynamically balancing the two paradigms. In this paper, we reframe this challenge through the theoretical lens of \\textbf{implicit rewards}, viewing SFT and RL not as distinct methods but as complementary reward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel single-stage algorithm that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward. The core of AMFT is a \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL balance as a learnable parameter, dynamically optimizing it to maximize long-term task performance. This forward-looking approach, regularized by policy entropy for stability, autonomously discovers an effective training curriculum. We conduct a comprehensive evaluation on challenging benchmarks spanning mathematical reasoning, abstract visual reasoning (General Points), and vision-language navigation (V-IRL). AMFT consistently establishes a new state-of-the-art and demonstrats superior generalization on out-of-distribution (OOD) tasks. Ablation studies and training dynamic analysis confirm that the meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance, offering a more principled and effective paradigm for LLM alignment. Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.06944","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.904471","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Lixuan He, Jie Feng, Yong Li","raw_content_length":1798,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["Meta arXiv:2508.06944v3 Announce Type: replace","Reinforcement Learning","SFT"],"persons":["Meta Fine-Tuning"],"locations":[],"monetary":[]},"char_count":1797,"language_detected":"en","key_concepts":{"key_phrases":["AMFT","LLM Reasoners","Meta","arXiv250806944v3 Announce Type","Abstract","Large Language Models","LLMs","reasoning tasks","a two-stage pipeline","Supervised Fine-Tuning SFT"],"filter_categories":{"ai_ml":["LLM Reasoners","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AMFT":2.0,"LLM Reasoners":2.0,"Meta":2.0,"arXiv250806944v3 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"reasoning tasks":1.0,"a two-stage pipeline":1.0,"Supervised Fine-Tuning SFT":1.0}},"age_hours":2.772757027777778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.55,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.09,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.662,"joy":0.0054,"surprise":0.0207,"sadness":0.024,"fear":0.2515,"anger":0.0222,"disgust":0.0142},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (AMFT) for improving the reasoning capabilities of LLMs. While it demonstrates superior performance on benchmarks, its direct climate impact is currently theoretical and unquantified. The research is at an early stage (basic research) with no deployed units or economic viability demonstrated.","key_impact_metrics":["Superior generalization on out-of-distribution (OOD) tasks","New state-of-the-art on challenging benchmarks"],"technology_tags":["Large Language Models","Meta-learning","Reinforcement Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:55:03.099634Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_922fe6d2b219","title":"Neural Beam Field for Spatial Beam RSRP Prediction","content":"arXiv:2508.06956v2 Announce Type: replace Abstract: Accurately predicting beam-level reference signal received power (RSRP) is essential for beam management in dense multi-user wireless networks, yet challenging due to high measurement overhead and fast channel variations. This paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for efficient and interpretable spatial beam RSRP prediction. Central to our approach is the introduction of the Multi-path Conditional Power Profile (MCPP), a learnable physical intermediary representing the site-specific propagation environment. This approach decouples the environment from specific antenna/beam configurations, which helps the model learn site-specific multipath features and enhances its generalization capability. We adopt a decoupled ``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN) learns the MCPP from sparse user measurements and positions, while a physics-inspired module analytically infers beam RSRP statistics. To improve convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC) strategy that leverages ray-tracing priors for physics-grounded pretraining and then RSRP data for on-site calibration. Extensive simulation results demonstrate that NBF significantly outperforms conventional table-based channel knowledge maps (CKMs) and pure blackbox DNNs in prediction accuracy, training efficiency, and generalization, while maintaining a compact model size. The proposed framework offers a scalable and physically grounded solution for intelligent beam management in next-generation dense wireless networks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.06956","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.904892","language":"en","tags":["research","csai","mathit","preprints","cslg","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Keqiang Guo, Yuheng Zhong, Xin Tong, Jiangbin Lyu, Rui Zhang","raw_content_length":1641,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["Conditional Power Profile","Transformer","MCPP","NBF","Neural Beam Field","Spatial Beam RSRP Prediction arXiv:2508.06956v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1640,"language_detected":"en","key_concepts":{"key_phrases":["Neural Beam Field","Spatial Beam RSRP Prediction","arXiv250806956v2 Announce Type","Abstract","beam-level reference signal","power","RSRP","beam management","dense multi-user wireless networks","This paper"],"filter_categories":{"renewable_energy":["power"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neural Beam Field":3.0,"Spatial Beam RSRP Prediction":2.0,"arXiv250806956v2 Announce Type":1.0,"Abstract":1.0,"beam-level reference signal":1.0,"power":1.0,"RSRP":1.0,"beam management":1.0,"dense multi-user wireless networks":1.0,"This paper":1.0}},"age_hours":2.7727724891666665,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.719,"joy":0.0175,"surprise":0.0151,"sadness":0.0063,"fear":0.1742,"anger":0.0419,"disgust":0.026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a novel neural network framework (NBF) for predicting beam-level RSRP in wireless networks, which can improve beam management and reduce measurement overhead. Simulation results demonstrate improved prediction accuracy and training efficiency compared to conventional methods. However, there are no real-world deployments or third-party verifications mentioned, placing it in the applied research stage.","key_impact_metrics":["Prediction accuracy improvement","Training efficiency improvement"],"technology_tags":["Neural Networks","Beam Management","Wireless Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:06.159254Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ff1f94ba3b52","title":"Using nonassociative algebras to classify skew polycyclic codes up to isometry and equivalence","content":"arXiv:2508.10139v2 Announce Type: replace Abstract: Employing isomorphisms between their ambient algebras, we propose new definitions of equivalence and isometry for skew polycyclic codes that will lead to tighter classifications than existing ones. This reduces the number of previously known isometry and equivalence classes. In the process, we classify classes of skew $(f,\\sigma,\\delta)$-polycyclic codes with the same performance parameters, to avoid duplicating already existing codes, and state precisely when different notions of equivalence coincide. The generator of a skew polycyclic code is in one-one correspondence with the generator of a principal left ideal in its ambient algebra. We allow the ambient algebras to be nonassociative, thus eliminating the need on restrictions on the length of the codes. Algebra isomorphisms that preserve the Hamming distance (called isometries) map generators of principal left ideals to generators of principal left ideals and preserve length, dimension and Hamming distance of the codes. The isometries between the ambient algebras can also be used to classify corresponding linear codes equipped with the rank metric.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10139","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.906478","language":"en","tags":["research","mathit","preprints","mathra","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Susanne Pumpluen","raw_content_length":1174,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["Algebra","Hamming"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1171,"language_detected":"en","key_concepts":{"key_phrases":["skew polycyclic codes","isometry","equivalence","nonassociative algebras","Announce Type","Abstract","isomorphisms","their ambient algebras","new definitions","tighter classifications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"skew polycyclic codes":3.0,"isometry":3.0,"equivalence":3.0,"nonassociative algebras":2.0,"Announce Type":1.0,"Abstract":1.0,"isomorphisms":1.0,"their ambient algebras":1.0,"new definitions":1.0,"tighter classifications":1.0}},"age_hours":2.7728321797222226,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8885,"joy":0.0196,"surprise":0.0345,"sadness":0.0048,"fear":0.0107,"anger":0.0277,"disgust":0.0143},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents theoretical research on classifying skew polycyclic codes. While potentially useful in data compression or error correction, its direct impact on sustainability is currently minimal as it is in the early stages of research and lacks concrete applications or deployment. The technical credibility is moderate due to its basis in mathematical principles and potential for peer review.","key_impact_metrics":[],"technology_tags":["coding theory","algebraic coding"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:55:08.996724Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_10567b8277ab","title":"From Entity Reliability to Clean Feedback: An Entity","content":"arXiv:2508.10851v2 Announce Type: replace Abstract: Implicit feedback is central to modern recommender systems but is inherently noisy, often impairing model training and degrading user experience. At scale, such noise can mislead learning processes, reducing both recommendation accuracy and platform value. Existing denoising strategies typically overlook the entity-specific nature of noise while introducing high computational costs and complex hyperparameter tuning. To address these challenges, we propose \\textbf{EARD} (\\textbf{E}ntity-\\textbf{A}ware \\textbf{R}eliability-\\textbf{D}riven Denoising), a lightweight framework that shifts the focus from interaction-level signals to entity-level reliability. Motivated by the empirical observation that training loss correlates with noise, EARD quantifies user and item reliability via their average training losses as a proxy for reputation, and integrates these entity-level factors with interaction-level confidence. The framework is \\textbf{model-agnostic}, \\textbf{computationally efficient}, and requires \\textbf{only two intuitive hyperparameters}. Extensive experiments across multiple datasets and backbone models demonstrate that EARD yields substantial improvements over state-of-the-art baselines (e.g., up to 27.01\\% gain in NDCG@50), while incurring negligible additional computational cost. Comprehensive ablation studies and mechanism analyses further confirm EARD's robustness to hyperparameter choices and its practical scalability. These results highlight the importance of entity-aware reliability modeling for denoising implicit feedback and pave the way for more robust recommendation research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10851","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.906887","language":"en","tags":["csir","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Ze Liu, Xianquan Wang, Shuochen Liu, Jie Ma, Huibo Xu, Yupeng Han, Kai Zhang, Jun Zhou","raw_content_length":1671,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":["Entity Reliability to Clean Feedback: An Entity arXiv:2508.10851v2 Announce Type: replace Abstract","EARD"],"persons":[],"locations":[],"monetary":[]},"char_count":1670,"language_detected":"en","key_concepts":{"key_phrases":["Entity Reliability","Clean Feedback","arXiv250810851v2 Announce Type","Abstract","Implicit feedback","modern recommender systems","model training","degrading user experience","scale","such noise"],"filter_categories":{"ai_ml":["model training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Entity Reliability":2.0,"Clean Feedback":2.0,"arXiv250810851v2 Announce Type":1.0,"Abstract":1.0,"Implicit feedback":1.0,"modern recommender systems":1.0,"model training":1.0,"degrading user experience":1.0,"scale":1.0,"such noise":1.0}},"age_hours":2.7728467119444447,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7352,"joy":0.0029,"surprise":0.012,"sadness":0.0322,"fear":0.0484,"anger":0.0387,"disgust":0.1305},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (EARD) for denoising implicit feedback in recommender systems, which could potentially reduce energy consumption by improving the efficiency of these systems. The method is model-agnostic and computationally efficient, showing a 27.01% gain in NDCG@50. However, it is still in the research phase with no deployed units or real-world operational data.","key_impact_metrics":["27.01% gain in NDCG@50"],"technology_tags":["recommender systems","machine learning","denoising"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:55:12.076146Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a0900d343c48","title":"Lower Bounds for $k$","content":"arXiv:2508.15562v2 Announce Type: replace Abstract: We develop a new lower bound for k-set agreement in synchronous message-passing systems connected by an arbitrary directed communication network, where up to t processes may crash. Our result thus generalizes the t/k+1 lower bound for complete networks in the t-resilient model by Chaudhuri, Herlihy, Lynch, and Tuttle [JACM'00]. Moreover, it generalizes two lower bounds for oblivious algorithms in synchronous systems connected by an arbitrary undirected communication network known to the processes, namely, the domination number-based lower bound by Castaneda, Fraigniaud, Paz, Rajsbaum, Roy, and Travers [TCS'21] for failure-free processes, and the radius-based lower bound in the t-resilient model by Fraigniaud, Nguyen, and Paz [STACS'24]. Our topological proof non-trivially generalizes and extends the connectivity-based approach for the complete network, as presented in the book by Herlihy, Kozlov, and Rajsbaum (2013). It is based on a sequence of shellable carrier maps that, starting from a shellable input complex, determine the evolution of the protocol complex: During the first t/k rounds, carrier maps that crash exactly k processes per round are used, ensuring high connectivity of their images. A Sperner's lemma style argument is used to prove that k-set agreement is still impossible by that round. From round t/k+1 up to our lower bound, we employ a novel carrier map that maintains high connectivity. Our proof also provides a strikingly simple lower bound for k-set agreement in synchronous systems with an arbitrary communication network with initial crashes. We express the resulting additional agreement overhead via an appropriately defined radius of the communication graphs. Finally, we prove that the usual input pseudosphere complex for k-set agreement can be replaced by an exponentially smaller input complex based on Kuhn triangulations, which we prove to be also shellable.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.15562","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.908192","language":"en","tags":["computer-science","csdc","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":288,"author":"Pierre Fraigniaud, Minh Hang Nguyen, Ami Paz, Ulrich Schmid, Hugo Rincon Galeana","raw_content_length":1966,"priority":7,"update_frequency":1,"reading_time_minutes":1.44,"robust_parsing_used":true,"entities":{"organizations":["Rajsbaum","Castaneda","Kozlov","Lynch","Herlihy"],"persons":["Roy","Nguyen","Paz"],"locations":["Chaudhuri","Herlihy","Fraigniaud"],"monetary":[]},"char_count":1963,"language_detected":"en","key_concepts":{"key_phrases":["Lower Bounds","arXiv250815562v2 Announce Type","Abstract","k-set agreement","synchronous message-passing systems","an arbitrary directed communication network","up to t processes","Our result","the tk1","complete networks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lower Bounds":2.0,"arXiv250815562v2 Announce Type":1.0,"Abstract":1.0,"k-set agreement":1.0,"synchronous message-passing systems":1.0,"an arbitrary directed communication network":1.0,"up to t processes":1.0,"Our result":1.0,"the tk1":1.0,"complete networks":1.0}},"age_hours":2.7728948922222223,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2850000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.743,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6906,"joy":0.004,"surprise":0.0515,"sadness":0.1028,"fear":0.1025,"anger":0.0351,"disgust":0.0134},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":8,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical lower bound for k-set agreement in distributed computing systems. While the research is mathematically rigorous and published in a reputable venue, it does not directly translate to concrete actions or measurable outcomes related to sustainability. The research is foundational and may indirectly contribute to more efficient algorithms in the future, but its immediate impact is minimal.","key_impact_metrics":[],"technology_tags":["distributed computing","algorithm design"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:55:15.054803Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b4f7c8cc44d7","title":"On Task Vectors and Gradients","content":"arXiv:2508.16082v5 Announce Type: replace Abstract: Task arithmetic has emerged as a simple yet powerful technique for model merging, enabling the combination of multiple finetuned models into one. Despite its empirical success, a clear theoretical explanation of why and when it works is lacking. This paper provides a rigorous theoretical foundation for task arithmetic by establishing a connection between task vectors and gradients of the task losses. We show that under standard gradient descent, a task vector generated from one epoch of finetuning is exactly equivalent to the negative gradient of the loss, scaled by the learning rate. For the practical multi-epoch setting, we prove that this equivalence holds approximately, with a second-order error term that we explicitly bound for feed-forward networks. Our empirical analysis across seven vision benchmarks corroborates our theory, demonstrating that the first-epoch gradient dominates the finetuning trajectory in both norm and direction. A key implication is that merging models finetuned for only a single epoch often yields performance comparable to merging fully converged models. These findings reframe task arithmetic as a form of approximate multitask learning, providing a clear rationale for its effectiveness and highlighting the critical role of early training dynamics in model merging.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16082","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.908613","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Luca Zhou, Daniele Solombrino, Donato Crisostomi, Maria Sofia Bucarelli, Giuseppe Alessio D'Inverno, Fabrizio Silvestri, Emanuele Rodol\\`a","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["Task Vectors","Gradients","arXiv250816082v5 Announce Type","Abstract","Task arithmetic","a simple yet powerful technique","model merging","the combination","multiple finetuned models","its empirical success"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Task Vectors":2.0,"Gradients":2.0,"arXiv250816082v5 Announce Type":1.0,"Abstract":1.0,"Task arithmetic":1.0,"a simple yet powerful technique":1.0,"model merging":1.0,"the combination":1.0,"multiple finetuned models":1.0,"its empirical success":1.0}},"age_hours":2.7729102269444446,"is_recent":true,"quality_score":0.7,"sentiment_score":3.3024999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3395,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8673,"joy":0.0334,"surprise":0.0422,"sadness":0.0081,"fear":0.0141,"anger":0.0232,"disgust":0.0116},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for task arithmetic in model merging, showing that task vectors are approximately equivalent to gradients of task losses. The empirical analysis corroborates the theory across seven vision benchmarks. While this could potentially lead to more efficient model training and deployment, its direct climate impact is currently theoretical and unquantified, hence the low climate impact score.","key_impact_metrics":["First-epoch gradient dominance in norm and direction"],"technology_tags":["Model Merging","Task Arithmetic","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:17.648242Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f638c569df1d","title":"Anemoi: A Semi-Centralized Multi-agent System Based on Agent","content":"arXiv:2508.17068v3 Announce Type: replace Abstract: Recent advances in generalist multi-agent systems (MAS) have largely followed a context-engineering plus centralized paradigm, where a planner agent coordinates multiple worker agents through unidirectional prompt passing. While effective under strong planner models, this design suffers from two critical limitations: (1) strong dependency on the planner's capability, which leads to degraded performance when a smaller LLM powers the planner; and (2) limited inter-agent communication, where collaboration relies on prompt concatenation rather than genuine refinement through structured discussions. To address these challenges, we propose Anemoi, a semi-centralized MAS built on the Agent-to-Agent (A2A) communication MCP server from Coral Protocol. Unlike traditional designs, Anemoi enables structured and direct inter-agent collaboration, allowing all agents to monitor progress, assess results, identify bottlenecks, and propose refinements in real time. This paradigm reduces reliance on a single planner, supports adaptive plan updates, and minimizes redundant context passing, resulting in more scalable execution. Evaluated on the GAIA benchmark, Anemoi achieved 52.73% accuracy with a small LLM (GPT-4.1-mini) as the planner, surpassing the strongest open-source baseline OWL (43.63%) by +9.09% under identical LLM settings. Our implementation is publicly available at https://github.com/Coral-Protocol/Anemoi.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17068","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.909016","language":"en","tags":["research","csma","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Xinxing Ren, Caelum Forder, Qianbo Zang, Ahsen Tahir, Roman J. Georgio, Suman Deb, Peter Carroll, \\\"Onder G\\\"urcan, Zekun Guo","raw_content_length":1475,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["MCP","System Based","MAS","LLM","Coral Protocol"],"persons":[],"locations":["Anemoi"],"monetary":[]},"char_count":1474,"language_detected":"en","key_concepts":{"key_phrases":["Anemoi","A Semi-Centralized Multi-agent System","Agent","Announce Type","Abstract","Recent advances","generalist multi-agent systems","MAS","a context-engineering plus centralized paradigm","multiple worker agents"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Anemoi":2.0,"A Semi-Centralized Multi-agent System":2.0,"Agent":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"generalist multi-agent systems":1.0,"MAS":1.0,"a context-engineering plus centralized paradigm":1.0,"multiple worker agents":1.0}},"age_hours":2.7729259361111107,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8686,"joy":0.0081,"surprise":0.0501,"sadness":0.0212,"fear":0.0114,"anger":0.0198,"disgust":0.0209},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel multi-agent system (Anemoi) that improves collaboration between AI agents, leading to better performance on the GAIA benchmark. While the system shows a +9.09% improvement over the baseline, it is still in the research phase with no clear path to real-world deployment or quantified environmental impact. The system is vaporware because it's a prototype with no deployed units or customer contracts.","key_impact_metrics":["+9.09% accuracy on GAIA benchmark","52.73% accuracy with GPT-4.1-mini"],"technology_tags":["Multi-agent systems","Artificial Intelligence","Large Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:20.869314Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_218bf4ba9980","title":"Evaluating the Quality of the Quantified Uncertainty for (Re)Calibration of Data","content":"arXiv:2508.17761v2 Announce Type: replace Abstract: In safety-critical applications data-driven models must not only be accurate but also provide reliable uncertainty estimates. This property, commonly referred to as calibration, is essential for risk-aware decision-making. In regression a wide variety of calibration metrics and recalibration methods have emerged. However, these metrics differ significantly in their definitions, assumptions and scales, making it difficult to interpret and compare results across studies. Moreover, most recalibration methods have been evaluated using only a small subset of metrics, leaving it unclear whether improvements generalize across different notions of calibration. In this work, we systematically extract and categorize regression calibration metrics from the literature and benchmark these metrics independently of specific modelling methods or recalibration approaches. Through controlled experiments with real-world, synthetic and artificially miscalibrated data, we demonstrate that calibration metrics frequently produce conflicting results. Our analysis reveals substantial inconsistencies: many metrics disagree in their evaluation of the same recalibration result, and some even indicate contradictory conclusions. This inconsistency is particularly concerning as it potentially allows cherry-picking of metrics to create misleading impressions of success. We identify the Expected Normalized Calibration Error (ENCE) and the Coverage Width-based Criterion (CWC) as the most dependable metrics in our tests. Our findings highlight the critical role of metric selection in calibration research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17761","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.909458","language":"en","tags":["statml","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Jelke Wibbeke, Nico Sch\\\"onfisch, Sebastian Rohjans, Andreas Rauh","raw_content_length":1650,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1649,"language_detected":"en","key_concepts":{"key_phrases":["the Quality","the Quantified Uncertainty","ReCalibration","Data","arXiv250817761v2","Announce Type","Abstract","safety-critical applications data-driven models","reliable uncertainty estimates","This property"],"filter_categories":{"ai_ml":["the Quantified Uncertainty","Data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Quality":2.0,"the Quantified Uncertainty":2.0,"ReCalibration":2.0,"Data":2.0,"arXiv250817761v2":1.0,"Announce Type":1.0,"Abstract":1.0,"safety-critical applications data-driven models":1.0,"reliable uncertainty estimates":1.0,"This property":1.0}},"age_hours":2.772941648888889,"is_recent":true,"quality_score":0.7,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.85,"joy":0.0137,"surprise":0.0111,"sadness":0.007,"fear":0.0975,"anger":0.0137,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on evaluating the quality of uncertainty quantification in data-driven models, which is crucial for risk-aware decision-making in safety-critical applications. While it doesn't directly reduce GHG emissions, improving the reliability of these models can indirectly support better decision-making in climate-related applications. The research identifies ENCE and CWC as dependable metrics, and uses real-world and synthetic data for validation, but it is still in the research phase with no deployed technology.","key_impact_metrics":["Expected Normalized Calibration Error (ENCE)","Coverage Width-based Criterion (CWC)"],"technology_tags":["Uncertainty Quantification","Calibration Metrics","Data-driven Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:23.983879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b1b544994984","title":"DiskJoin: Large","content":"arXiv:2508.18494v2 Announce Type: replace Abstract: Similarity join--a widely used operation in data science--finds all pairs of items that have distance smaller than a threshold. Prior work has explored distributed computation methods to scale similarity join to large data volumes but these methods require a cluster deployment, and efficiency suffers from expensive inter-machine communication. On the other hand, disk-based solutions are more cost-effective by using a single machine and storing the large dataset on high-performance external storage, such as NVMe SSDs, but in these methods the disk I/O time is a serious bottleneck. In this paper, we propose DiskJoin, the first disk-based similarity join algorithm that can process billion-scale vector datasets efficiently on a single machine. DiskJoin improves disk I/O by tailoring the data access patterns to avoid repetitive accesses and read amplification. It also uses main memory as a dynamic cache and carefully manages cache eviction to improve cache hit rate and reduce disk retrieval time. For further acceleration, we adopt a probabilistic pruning technique that can effectively prune a large number of vector pairs from computation. Our evaluation on real-world, large-scale datasets shows that DiskJoin significantly outperforms alternatives, achieving speedups from 50x to 1000x.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18494","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.909847","language":"en","tags":["csdb","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Yanqi Chen, Xiao Yan, Alexandra Meliou, Eric Lo","raw_content_length":1353,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1352,"language_detected":"en","key_concepts":{"key_phrases":["DiskJoin","arXiv250818494v2 Announce Type","Abstract","Similarity join","a widely used operation","data science","all pairs","items","distance","a threshold"],"filter_categories":{"ai_ml":["data science"],"research_academic":["data science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DiskJoin":2.0,"arXiv250818494v2 Announce Type":1.0,"Abstract":1.0,"Similarity join":1.0,"a widely used operation":1.0,"data science":1.0,"all pairs":1.0,"items":1.0,"distance":1.0,"a threshold":1.0}},"age_hours":2.772957818333333,"is_recent":true,"quality_score":0.7,"sentiment_score":8.6135,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7227,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8833,"joy":0.0211,"surprise":0.0329,"sadness":0.0264,"fear":0.0063,"anger":0.0155,"disgust":0.0144},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm, DiskJoin, for similarity joins on large datasets, claiming significant speedups (50x to 1000x) compared to alternatives. This could reduce energy consumption in data processing. However, it is currently in the research phase and lacks deployment data, so the actual impact is still uncertain.","key_impact_metrics":["speedups from 50x to 1000x"],"technology_tags":["data processing","similarity join","disk-based algorithm","NVMe SSDs"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:55:27.254326Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f361856e04c2","title":"LaTeXTrans: Structured LaTeX Translation with Multi","content":"arXiv:2508.18791v2 Announce Type: replace Abstract: Despite the remarkable progress of modern machine translation (MT) systems on general-domain texts, translating structured LaTeX-formatted documents remains a significant challenge. These documents typically interleave natural language with domain-specific syntax, such as mathematical equations, tables, figures, and cross-references, all of which must be accurately preserved to maintain semantic integrity and compilability. In this paper, we introduce LaTeXTrans, a collaborative multi-agent system designed to address this challenge. LaTeXTrans ensures format preservation, structural fidelity, and terminology consistency through six specialized agents: 1) a Parser that decomposes LaTeX into translation-friendly units via placeholder substitution and syntax filtering; 2) a Translator, Validator, Summarizer, and Terminology Extractor that work collaboratively to ensure context-aware, self-correcting, and terminology-consistent translations; 3) a Generator that reconstructs the translated content into well-structured LaTeX documents. Experimental results demonstrate that LaTeXTrans can outperform mainstream MT systems in both translation accuracy and structural fidelity, offering an effective and practical solution for translating LaTeX-formatted documents.The code of LaTeXTrans is available at https://github.com/NiuTrans/LaTeXTrans.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18791","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.910611","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Ziming Zhu, Chenglong Wang, Shunjie Xing, Yifu Huo, Fengning Tian, Quan Du, Di Yang, Chunliang Zhang, Tong Xiao, Jingbo Zhu","raw_content_length":1404,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["LaTeX","Terminology Extractor"],"persons":["Summarizer"],"locations":[],"monetary":[]},"char_count":1403,"language_detected":"en","key_concepts":{"key_phrases":["LaTeXTrans","Structured LaTeX Translation","Multi","arXiv250818791v2 Announce Type","Abstract","the remarkable progress","modern machine translation","MT systems","general-domain texts","structured LaTeX-formatted documents"],"filter_categories":{"ai_ml":["general-domain texts"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LaTeXTrans":2.0,"Structured LaTeX Translation":2.0,"Multi":2.0,"arXiv250818791v2 Announce Type":1.0,"Abstract":1.0,"the remarkable progress":1.0,"modern machine translation":1.0,"MT systems":1.0,"general-domain texts":1.0,"structured LaTeX-formatted documents":1.0}},"age_hours":2.7729868833333335,"is_recent":true,"quality_score":1.0,"sentiment_score":4.165,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.167,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8926,"joy":0.0199,"surprise":0.0669,"sadness":0.0052,"fear":0.0046,"anger":0.0072,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a system for translating LaTeX documents, which could indirectly support sustainability efforts by improving access to scientific knowledge. However, there are no direct or measurable outcomes related to climate change or other sustainability dimensions. The system is at the applied research stage, with experimental results demonstrating improved translation accuracy.","key_impact_metrics":["Translation accuracy improvement","Structural fidelity improvement"],"technology_tags":["Machine Translation","Natural Language Processing","LaTeX"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:55:30.188882Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03edcec07213","title":"Revisiting associative recall in modern recurrent models","content":"arXiv:2508.19029v2 Announce Type: replace Abstract: Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mamba's performance and optimization stability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.19029","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.911005","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Destiny Okpekpe, Antonio Orvieto","raw_content_length":1457,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1456,"language_detected":"en","key_concepts":{"key_phrases":["associative recall","modern recurrent models","Announce Type","Abstract","the advantageous subquadratic complexity","modern recurrent deep learning models","state-space models","SSMs","recent studies","their potential shortcomings"],"filter_categories":{"ai_ml":["modern recurrent deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"associative recall":3.0,"modern recurrent models":2.0,"Announce Type":1.0,"Abstract":1.0,"the advantageous subquadratic complexity":1.0,"modern recurrent deep learning models":1.0,"state-space models":1.0,"SSMs":1.0,"recent studies":1.0,"their potential shortcomings":1.0}},"age_hours":2.773001958888889,"is_recent":true,"quality_score":0.7,"sentiment_score":4.987,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0026,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7874,"joy":0.0174,"surprise":0.0447,"sadness":0.0474,"fear":0.0118,"anger":0.0286,"disgust":0.0627},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on improving the efficiency of recurrent deep learning models, specifically in associative recall tasks. While improved efficiency in computation can indirectly lead to reduced energy consumption, the impact is theoretical and not directly quantified. The research is at a basic research stage with no deployed technology or measured outcomes in a real-world setting.","key_impact_metrics":[],"technology_tags":["recurrent neural networks","state-space models","transformers","deep learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:32.830446Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b524698448d8","title":"Federated Fine-Tuning of Sparsely","content":"arXiv:2508.19078v2 Announce Type: replace Abstract: Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models (LLMs) is challenging due to their massive computational requirements and the resource constraints of participants. Existing working attempts to fill this gap through model quantization, computation offloading, or expert pruning. However, they cannot achieve desired performance due to impractical system assumptions and a lack of consideration for MoE-specific characteristics. In this paper, we propose FLUX, a system designed to enable federated fine-tuning of MoE-based LLMs across participants with constrained computing resources (e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX introduces three key innovations: (1) quantization-based local profiling to estimate expert activation with minimal overhead, (2) adaptive layer-aware expert merging to reduce resource consumption while preserving accuracy, and (3) dynamic expert role assignment using an exploration-exploitation strategy to balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE and DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX significantly outperforms existing methods, achieving up to 4.75X speedup in time-to-accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.19078","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.911418","language":"en","tags":["csdc","research","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Fahao Chen, Jie Wan, Peng Li, Zhou Su, Dongxiao Yu","raw_content_length":1287,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1286,"language_detected":"en","key_concepts":{"key_phrases":["Federated Fine-Tuning","Announce Type","Abstract","Federated fine-tuning","Experts","LLMs","their massive computational requirements","the resource constraints","participants","Existing working attempts"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Federated Fine-Tuning":2.0,"Announce Type":1.0,"Abstract":1.0,"Federated fine-tuning":1.0,"Experts":1.0,"LLMs":1.0,"their massive computational requirements":1.0,"the resource constraints":1.0,"participants":1.0,"Existing working attempts":1.0}},"age_hours":2.773018052222222,"is_recent":true,"quality_score":0.7,"sentiment_score":3.1795,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3641,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8838,"joy":0.0057,"surprise":0.024,"sadness":0.0307,"fear":0.0213,"anger":0.0232,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel system (FLUX) for federated fine-tuning of large language models, aiming to reduce computational requirements and improve time-to-accuracy. The concrete action is the development of this system with three key innovations. Evidence is provided through experiments on LLaMA-MoE and DeepSeek-MoE, demonstrating up to 4.75X speedup, but it's still in the applied research stage with no deployment mentioned.","key_impact_metrics":["4.75X speedup in time-to-accuracy","quantization-based local profiling"],"technology_tags":["Federated Learning","Mixture-of-Experts","Model Quantization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:55:35.782032Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f908a013a87","title":"SUMMA: A Multimodal Large Language Model for Advertisement Summarization","content":"arXiv:2508.20582v2 Announce Type: replace Abstract: Understanding multimodal video ads is crucial for improving query-ad matching and relevance ranking on short video platforms, enhancing advertising effectiveness and user experience. However, the effective utilization of multimodal information with high commercial value still largely constrained by reliance on highly compressed video embeddings-has long been inadequate. To address this, we propose SUMMA (the abbreviation of Summarizing MultiModal Ads), a multimodal model that automatically processes video ads into summaries highlighting the content of highest commercial value, thus improving their comprehension and ranking in Douyin search-advertising systems. SUMMA is developed via a two-stage training strategy-multimodal supervised fine-tuning followed by reinforcement learning with a mixed reward mechanism-on domain-specific data containing video frames and ASR/OCR transcripts, generating commercially valuable and explainable summaries. We integrate SUMMA-generated summaries into our production pipeline, directly enhancing the candidate retrieval and relevance ranking stages in real search-advertising systems. Both offline and online experiments show substantial improvements over baselines, with online results indicating a statistically significant 1.5% increase in advertising revenue. Our work establishes a novel paradigm for condensing multimodal information into representative texts, effectively aligning visual ad content with user query intent in retrieval and recommendation scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.20582","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.911817","language":"en","tags":["preprints","computer-science","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Weitao Jia, Shuo Yin, Zhoufutu Wen, Han Wang, Zehui Dai, Kun Zhang, Zhenyu Li, Tao Zeng, Xiaohui Lv","raw_content_length":1570,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["SUMMA","Douyin"],"persons":["Summarizing MultiModal Ads"],"locations":[],"monetary":[]},"char_count":1569,"language_detected":"en","key_concepts":{"key_phrases":["SUMMA","A Multimodal Large Language Model","Advertisement Summarization","arXiv250820582v2","Announce Type","Abstract","multimodal video ads","query-ad matching","relevance","short video platforms"],"filter_categories":{"ai_ml":["A Multimodal Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SUMMA":3.0,"A Multimodal Large Language Model":2.0,"Advertisement Summarization":2.0,"arXiv250820582v2":1.0,"Announce Type":1.0,"Abstract":1.0,"multimodal video ads":1.0,"query-ad matching":1.0,"relevance":1.0,"short video platforms":1.0}},"age_hours":2.7730332080555558,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6369,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8341,"joy":0.0105,"surprise":0.0241,"sadness":0.0136,"fear":0.0714,"anger":0.0239,"disgust":0.0224},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":2,"technical_credibility":6,"economic_viability":7,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AI model (SUMMA) within Douyin's search-advertising system. It provides a concrete outcome: a 1.5% increase in advertising revenue, indicating commercial viability. The technical credibility is supported by offline and online experiments, and the deployment readiness is high as it's integrated into a production pipeline.","key_impact_metrics":["1.5% increase in advertising revenue"],"technology_tags":["multimodal AI","advertisement summarization","search-advertising"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:38.517336Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0b615dbe3adb","title":"Quantifying Label-Induced Bias in Large Language Model Self","content":"arXiv:2508.21164v3 Announce Type: replace Abstract: Large language models (LLMs) are increasingly deployed as evaluators of text quality, yet the validity of their judgments remains underexplored. This study investigates systematic bias in self- and cross-model evaluations across three prominent LLMs: ChatGPT, Gemini, and Claude. We designed a controlled experiment in which blog posts authored by each model were evaluated by all three models under four labeling conditions: no attribution, true attribution, and two false-attribution scenarios. Evaluations employed both holistic preference voting and granular quality ratings across three dimensions Coherence, Informativeness, and Conciseness with all scores normalized to percentages for direct comparison. Our findings reveal pronounced asymmetries in model judgments: the \"Claude\" label consistently elevated scores regardless of actual authorship, while the \"Gemini\" label systematically depressed them. False attribution frequently reversed preference rankings, producing shifts of up to 50 percentage points in voting outcomes and up to 12 percentage points in quality ratings. Notably, Gemini exhibited severe self-deprecation under true labels, while Claude demonstrated intensified self-preference. These results demonstrate that perceived model identity can substantially distort both high-level judgments and fine-grained quality assessments, independent of content quality. Our findings challenge the reliability of LLM-as-judge paradigms and underscore the critical need for blind evaluation protocols and diverse multi-model validation frameworks to ensure fairness and validity in automated text evaluation and LLM benchmarking.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.21164","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.912224","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Muskan Saraf, Sajjad Rezvani Boroujeni, Justin Beaudry, Hossein Abedi, Tom Bush","raw_content_length":1700,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Informativeness"],"persons":["Claude","Announce Type"],"locations":["Gemini"],"monetary":[]},"char_count":1699,"language_detected":"en","key_concepts":{"key_phrases":["Quantifying Label-Induced Bias","Large Language Model Self","Announce Type","Large language models","LLMs","evaluators","text quality","the validity","their judgments","This study"],"filter_categories":{"ai_ml":["Large Language Model Self","Large language models"],"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantifying Label-Induced Bias":2.0,"Large Language Model Self":2.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"evaluators":1.0,"text quality":1.0,"the validity":1.0,"their judgments":1.0,"This study":1.0}},"age_hours":2.7730492097222226,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8091,"joy":0.0059,"surprise":0.0541,"sadness":0.0237,"fear":0.0172,"anger":0.0315,"disgust":0.0585},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":8,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a controlled experiment demonstrating bias in LLM evaluations, showing that perceived model identity can significantly distort quality assessments. The study quantifies these biases with metrics like percentage point shifts in voting outcomes (up to 50) and quality ratings (up to 12). While the research is rigorous and provides valuable insights, it is still in the applied research phase and does not directly translate to climate impact.","key_impact_metrics":["shifts of up to 50 percentage points in voting outcomes","shifts of up to 12 percentage points in quality ratings"],"technology_tags":["Large Language Models","AI Bias","Text Evaluation"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T09:55:41.362681Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_966f83757d32","title":"Can Large Language Models Master Complex Card Games?","content":"arXiv:2509.01328v3 Announce Type: replace Abstract: Complex games have long been an important benchmark for testing the progress of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have defeated top human players in Go and Chess, garnering widespread societal attention towards artificial intelligence. Concurrently, large language models (LLMs) have exhibited remarkable capabilities across various tasks, raising the question of whether LLMs can achieve similar success in complex games. In this paper, we explore the potential of LLMs in mastering complex card games. We systematically assess the learning capabilities of LLMs across eight diverse card games, evaluating the impact of fine-tuning on high-quality gameplay data, and examining the models' ability to retain general capabilities while mastering these games. Our findings indicate that: (1) LLMs can approach the performance of strong game AIs through supervised fine-tuning on high-quality data, (2) LLMs can achieve a certain level of proficiency in multiple complex card games simultaneously, with performance augmentation for games with similar rules and conflicts for dissimilar ones, and (3) LLMs experience a decline in general capabilities when mastering complex games, but this decline can be mitigated by integrating a certain amount of general instruction data. The evaluation results demonstrate strong learning ability and versatility of LLMs. The code is available at https://github.com/THUDM/LLM4CardGame","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.01328","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.912642","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Wei Wang, Fuqing Bie, Junzhe Chen, Dan Zhang, Shiyu Huang, Evgeny Kharlamov, Jie Tang","raw_content_length":1504,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["MuZero","AlphaZero","Chess"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1503,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Announce Type","Abstract","Complex games","an important benchmark","the progress","artificial intelligence algorithms","AlphaGo","AlphaZero","MuZero"],"filter_categories":{"ai_ml":["LLMs","artificial intelligence algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"Complex games":1.0,"an important benchmark":1.0,"the progress":1.0,"artificial intelligence algorithms":1.0,"AlphaGo":1.0,"AlphaZero":1.0,"MuZero":1.0}},"age_hours":2.7730642975,"is_recent":true,"quality_score":1.0,"sentiment_score":9.708,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9416,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5956,"joy":0.0216,"surprise":0.3416,"sadness":0.0034,"fear":0.0155,"anger":0.0168,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the potential of LLMs in mastering complex card games. While it demonstrates learning capabilities, there are no concrete actions or measurable outcomes related to sustainability. It is vaporware because it is early-stage research with no deployed units or operational data.","key_impact_metrics":["Performance of LLMs in card games","Decline in general capabilities of LLMs"],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:55:44.375648Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c111ca54131e","title":"Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation","content":"arXiv:2509.02579v2 Announce Type: replace Abstract: Protecting endangered wildlife from illegal poaching presents a critical challenge, particularly in vast and partially observable environments where real-time response is essential. This paper introduces a novel Expectation-Maximization (EM) based latent variable modeling approach in the context of Multi-Agent Reinforcement Learning (MARL) for Unmanned Aerial Vehicle (UAV) coordination in wildlife protection. By modeling hidden environmental factors and inter-agent dynamics through latent variables, our method enhances exploration and coordination under uncertainty.We implement and evaluate our EM-MARL framework using a custom simulation involving 10 UAVs tasked with patrolling protected habitats of the endangered Iranian leopard. Extensive experimental results demonstrate superior performance in detection accuracy, adaptability, and policy convergence when compared to standard algorithms such as Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG). Our findings underscore the potential of combining EM inference with MARL to improve decentralized decisionmaking in complex, high-stakes conservation scenarios. The full implementation, simulation environment, and training scripts are publicly available on GitHub.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.02579","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.913271","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Mazyar Taghavi, Rahman Farnoosh","raw_content_length":1310,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Expectation-Maximization","EM-MARL","UAVs","Multi-Agent Reinforcement Learning","UAV"],"persons":[],"locations":["Multi"],"monetary":[]},"char_count":1309,"language_detected":"en","key_concepts":{"key_phrases":["Multi-Agent Reinforcement Learning","Latent Variable Modeling","Expectation","arXiv250902579v2 Announce Type","Abstract","endangered wildlife","illegal poaching","a critical challenge","vast and partially observable environments","real-time response"],"filter_categories":{"ai_ml":["Multi-Agent Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multi-Agent Reinforcement Learning":3.0,"Latent Variable Modeling":2.0,"Expectation":2.0,"arXiv250902579v2 Announce Type":1.0,"Abstract":1.0,"endangered wildlife":1.0,"illegal poaching":1.0,"a critical challenge":1.0,"vast and partially observable environments":1.0,"real-time response":1.0}},"age_hours":2.7730797483333336,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7053,"joy":0.0416,"surprise":0.0449,"sadness":0.0128,"fear":0.1451,"anger":0.0399,"disgust":0.0105},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel EM-MARL framework for UAV coordination in wildlife protection, demonstrating superior performance in detection accuracy compared to standard algorithms. The implementation is available on GitHub, but it's a simulation environment, not a real-world deployment, thus limiting deployment readiness and economic viability. The focus on endangered species protection has positive justice and equity implications.","key_impact_metrics":["detection accuracy","policy convergence"],"technology_tags":["Multi-Agent Reinforcement Learning","Unmanned Aerial Vehicles"],"sdg_alignment":[15],"analyzed_at":"2025-10-29T09:55:47.214901Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fa46f8fb83db","title":"When Lifetimes Liberate: A Type System for Arenas with Higher","content":"arXiv:2509.04253v2 Announce Type: replace Abstract: Static resource management in languages remains challenging due to tensions among control, expressiveness, and flexibility. Region-based systems [Grossman et al . 2002; Tofte et al. 2001] offer bulk deallocation via lexically scoped regions, where all allocations follow a stack discipline. However, both regions and their resources are second-class, and neither can escape its scope nor be freely returned. Ownership and linear type systems, exemplified by Rust [Clarke et al. 2013], offer non-lexical lifetimes and robust static guarantees, but rely on invariants that limit higher-order patterns and expressive sharing. In this work, we propose a new type system that unifies these strengths. Our system treats all heap-allocated resources as first-class values, while allowing programmers to control lifetime and granularity through three allocation modes: (1) fresh allocation for individual, non-lexical references; (2) subsequent coallocation grouping resources collectively within shadow arenas; and (3) scoped allocation with lexically bounded lifetimes following stack discipline. Regardless of mode, all resources share a uniform type and have no distinction for generic abstractions, preserving the higher-order parametric nature of the language. Obtaining static safety in higher-order languages with flexible sharing is nontrivial. We address this by extending reachability types [Wei et al. 2024] to collectively track first-class resources, and by adopting flow-insensitive deallocation reasoning for selective stack discipline. These mechanisms yield Aq<: and {A}q<: atop, both formalized and proven type safe and memory safe in Rocq.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.04253","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.914092","language":"en","tags":["cspl","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Siyuan He, Songlin Jia, Yuyan Bao, Tiark Rompf","raw_content_length":1708,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["Tofte et al. 2001","Clarke"],"persons":["Lifetimes Liberate","Grossman"],"locations":[],"monetary":[]},"char_count":1703,"language_detected":"en","key_concepts":{"key_phrases":["When Lifetimes Liberate A Type System","Arenas","Announce Type","Abstract","Static resource management","languages","tensions","control","expressiveness","flexibility"],"filter_categories":{"engineering":["control"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"When Lifetimes Liberate A Type System":2.0,"Arenas":2.0,"Announce Type":1.0,"Abstract":1.0,"Static resource management":1.0,"languages":1.0,"tensions":1.0,"control":1.0,"expressiveness":1.0,"flexibility":1.0}},"age_hours":2.7731088747222223,"is_recent":true,"quality_score":1.0,"sentiment_score":3.0664999999999996,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3867,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8212,"joy":0.019,"surprise":0.0501,"sadness":0.025,"fear":0.0315,"anger":0.0476,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new type system for memory management in programming languages, aiming to improve resource efficiency. While the research is technically sound and peer-reviewed, it is currently in the basic research stage with no deployed technology or measured outcomes related to sustainability. The potential climate impact is theoretical, as improved memory management could lead to more efficient software and hardware, but this is not directly quantified.","key_impact_metrics":[],"technology_tags":["memory management","type systems","programming languages"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:55:50.058074Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a02abbbe8fd2","title":"DQS: A Low","content":"arXiv:2509.05663v2 Announce Type: replace Abstract: Truly unsupervised approaches for time series anomaly detection are rare in the literature. Those that exist suffer from a poorly set threshold, which hampers detection performance, while others, despite claiming to be unsupervised, need to be calibrated using a labelled data subset, which is often not available in the real world. This work integrates active learning with an existing unsupervised anomaly detection method by selectively querying the labels of multivariate time series, which are then used to refine the threshold selection process. To achieve this, we introduce a novel query strategy called the dissimilarity-based query strategy (DQS). DQS aims to maximise the diversity of queried samples by evaluating the similarity between anomaly scores using dynamic time warping. We assess the detection performance of DQS in comparison to other query strategies and explore the impact of mislabelling, a topic that is underexplored in the literature. Our findings indicate that DQS performs best in small-budget scenarios, though the others appear to be more robust when faced with mislabelling. Therefore, in the real world, the choice of query strategy depends on the expertise of the oracle and the number of samples they are willing to label. Regardless, all query strategies outperform the unsupervised threshold even in the presence of mislabelling. Thus, whenever it is feasible to query an oracle, employing an active learning-based threshold is recommended.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.05663","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.914944","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Lucas Correia, Jan-Christoph Goos, Thomas B\\\"ack, Anna V. Kononova","raw_content_length":1532,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["anomaly scores","DQS"],"persons":[],"locations":[],"monetary":[]},"char_count":1531,"language_detected":"en","key_concepts":{"key_phrases":["DQS","A Low","which","Announce Type","Abstract","Truly unsupervised approaches","time series anomaly detection","the literature","Those","a poorly set threshold"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DQS":2.0,"A Low":2.0,"which":2.0,"Announce Type":1.0,"Abstract":1.0,"Truly unsupervised approaches":1.0,"time series anomaly detection":1.0,"the literature":1.0,"Those":1.0,"a poorly set threshold":1.0}},"age_hours":2.7731399644444448,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8528,"joy":0.006,"surprise":0.0379,"sadness":0.0422,"fear":0.0142,"anger":0.0139,"disgust":0.033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel query strategy (DQS) for anomaly detection in time series data, potentially applicable to optimizing energy consumption or identifying equipment failures in renewable energy systems. The research is still in the applied research phase, with assessment of detection performance but no real-world deployment or quantified impact on emissions reduction. The vaporware flag is set because it is a prototype/early-stage concept.","key_impact_metrics":["Detection performance improvement compared to other query strategies","Impact of mislabelling on performance"],"technology_tags":["Anomaly Detection","Active Learning","Time Series Analysis"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T09:55:53.164136Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
