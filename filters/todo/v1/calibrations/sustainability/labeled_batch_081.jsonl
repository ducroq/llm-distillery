{"id":"science_arxiv_cs_10392deb51ce","title":"Preference Discerning with LLM","content":"arXiv:2412.08604v2 Announce Type: replace Abstract: In sequential recommendation, models recommend items based on user's interaction history. To this end, current models usually incorporate information such as item descriptions and user intent or preferences. User preferences are usually not explicitly given in open-source datasets, and thus need to be approximated, for example via large language models (LLMs). Current approaches leverage approximated user preferences only during training and rely solely on the past interaction history for recommendations, limiting their ability to dynamically adapt to changing preferences, potentially reinforcing echo chambers. To address this issue, we propose a new paradigm, namely preference discerning, which explicitly conditions a generative recommendation model on user preferences in natural language within its context. To evaluate preference discerning, we introduce a novel benchmark that provides a holistic evaluation across various scenarios, including preference steering and sentiment following. Upon evaluating current state-of-the-art methods on our benchmark, we discover that their ability to dynamically adapt to evolving user preferences is limited. To address this, we propose a new method named Mender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce $\\textbf{D}$iscern$\\textbf{er}$), which achieves state-of-the-art performance in our benchmark. Our results show that Mender effectively adapts its recommendation guided by human preferences, even if not observed during training, paving the way toward more flexible recommendation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2412.08604","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.833727","language":"en","tags":["statml","csir","research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Fabian Paischer, Liu Yang, Linfeng Liu, Shuai Shao, Kaveh Hassani, Jiacheng Li, Ricky Chen, Zhang Gabriel Li, Xiaoli Gao, Wei Shao, Xue Feng, Nima Noorshams, Sem Park, Bo Long, Hamid Eghbalzadeh","raw_content_length":1604,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1603,"language_detected":"en","key_concepts":{"key_phrases":["Preference Discerning","LLM","Announce Type","Abstract","sequential recommendation","models","items","users interaction history","this end","current models"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Preference Discerning":2.0,"LLM":2.0,"Announce Type":1.0,"Abstract":1.0,"sequential recommendation":1.0,"models":1.0,"items":1.0,"users interaction history":1.0,"this end":1.0,"current models":1.0}},"age_hours":2.7701963477777776,"is_recent":true,"quality_score":0.7,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9516,"joy":0.0034,"surprise":0.0212,"sadness":0.0073,"fear":0.0031,"anger":0.0067,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method (Mender) for improving recommendation models by explicitly incorporating user preferences. While it addresses the issue of echo chambers, it's still in the research phase with no deployed units or quantified environmental impact. The benchmark provides some metrics, but it's not directly tied to climate or environmental outcomes.","key_impact_metrics":["Improved recommendation accuracy on benchmark","Adaptation to evolving user preferences"],"technology_tags":["Large Language Models","Recommendation Systems","Artificial Intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:48:11.232775Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a9ef61b949d0","title":"On the Integrality Gap of Directed Steiner Tree LPs with Relatively Integral Solutions","content":"arXiv:2412.10744v3 Announce Type: replace Abstract: The Directed Steiner Tree (DST) problem is defined on a directed graph $G=(V,E)$, where we are given a designated root vertex $r$ and a set of $k$ terminals $K \\subseteq V \\setminus {r}$. The goal is to find a minimum-cost subgraph that provides directed $r \\rightarrow t$ paths for all terminals $t \\in K$. The approximability of DST has long been a central open problem in network design. While there exist polylogarithmic-approximation algorithms with quasi-polynomial running times (Charikar et al. 1998; Grandoni, Laekhanukit, and Li 2019; Ghuge and Nagarajan 2020), the best known polynomial-time approximation until now has remained at $k^\\epsilon$, for any constant $\\epsilon > 0$. Whether a polynomial-time algorithm achieving a polylogarithmic approximation exists has remained unresolved. In this paper, we present a flow-based LP-relaxation for DST that admits a polylogarithmic integrality gap under the relative integral condition -- there exists a fractional solution in which each edge $e$ either carries a zero flow ($f^t_e=0$) or uses its full capacity ($f^t_e=x_e$), where $f^t_e$ denotes the flow variable and $x_e$ denotes the indicator variable treated as capacities. This stands in contrast to known lower bounds, as the standard flow-based relaxation is known to exhibit a polynomial integrality gap even under relatively integral solutions. In fact, this relatively integral property is shared by all the known integrality gap instances of DST [Halperin~et~al., SODA'07; Zosin-Khuller, SODA'02; Li-Laekhanukit, SODA'22]. We further provide a randomized polynomial-time algorithm that gives an $O(\\log^3 k)$-approximation, assuming access to a relatively integral fractional solution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2412.10744","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.834548","language":"en","tags":["csds","research","csdm","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Bundit Laekhanukit","raw_content_length":1767,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["DST","Ghuge","Relatively Integral Solutions arXiv:2412.10744v3","\\in","The Directed Steiner Tree"],"persons":["Grandoni","k^\\epsilon$","Charikar et al"],"locations":[],"monetary":["$k$ terminals"]},"char_count":1760,"language_detected":"en","key_concepts":{"key_phrases":["the Integrality Gap","Directed Steiner Tree LPs","Relatively Integral Solutions","arXiv241210744v3 Announce Type","Abstract","The Directed Steiner Tree DST problem","a directed graph","a designated root vertex","a set","subseteq V setminus"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Integrality Gap":2.0,"Directed Steiner Tree LPs":2.0,"Relatively Integral Solutions":2.0,"arXiv241210744v3 Announce Type":1.0,"Abstract":1.0,"The Directed Steiner Tree DST problem":1.0,"a directed graph":1.0,"a designated root vertex":1.0,"a set":1.0,"subseteq V setminus":1.0}},"age_hours":2.7702289163888887,"is_recent":true,"quality_score":1.0,"sentiment_score":2.1405000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5719,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8483,"joy":0.009,"surprise":0.0236,"sadness":0.0081,"fear":0.0541,"anger":0.0382,"disgust":0.0187},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for the Directed Steiner Tree problem, which is relevant to network design and could potentially improve the efficiency of routing algorithms in various applications, including those related to energy distribution and resource management. The algorithm achieves an O(log^3 k)-approximation, assuming access to a relatively integral fractional solution. The technical credibility is high due to the peer-reviewed nature of the research and the mathematical rigor.","key_impact_metrics":["O(log^3 k)-approximation","polylogarithmic integrality gap"],"technology_tags":["network design","optimization algorithms","directed steiner tree"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:14.222599Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f75273942967","title":"Making Bias Amplification in Balanced Datasets Directional and Interpretable","content":"arXiv:2412.11060v2 Announce Type: replace Abstract: Most of the ML datasets we use today are biased. When we train models on these biased datasets, they often not only learn dataset biases but can also amplify them -- a phenomenon known as bias amplification. Several co-occurrence-based metrics have been proposed to measure bias amplification between a protected attribute A (e.g., gender) and a task T (e.g., cooking). However, these metrics fail to measure biases when A is balanced with T. To measure bias amplification in balanced datasets, recent work proposed a predictability-based metric called leakage amplification. However, leakage amplification cannot identify the direction in which biases are amplified. In this work, we propose a new predictability-based metric called directional predictability amplification (DPA). DPA measures directional bias amplification, even for balanced datasets. Unlike leakage amplification, DPA is easier to interpret and less sensitive to attacker models (a hyperparameter in predictability-based metrics). Our experiments on tabular and image datasets show that DPA is an effective metric for measuring directional bias amplification. The code will be available soon.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2412.11060","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.834930","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Bhanu Tokas, Rahul Nair, Hannah Kerner","raw_content_length":1216,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Balanced Datasets Directional","DPA"],"persons":["Bias Amplification"],"locations":[],"monetary":[]},"char_count":1215,"language_detected":"en","key_concepts":{"key_phrases":["Bias Amplification","Balanced Datasets Directional","bias amplification","arXiv241211060v2 Announce Type","Abstract","the ML datasets","models","these biased datasets","dataset biases","them"],"filter_categories":{"ai_ml":["the ML datasets"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bias Amplification":2.0,"Balanced Datasets Directional":2.0,"bias amplification":2.0,"arXiv241211060v2 Announce Type":1.0,"Abstract":1.0,"the ML datasets":1.0,"models":1.0,"these biased datasets":1.0,"dataset biases":1.0,"them":1.0}},"age_hours":2.770244936944444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.45,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.09,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8135,"joy":0.0035,"surprise":0.0395,"sadness":0.0178,"fear":0.0097,"anger":0.0369,"disgust":0.0791},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":7,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new metric, DPA, to measure directional bias amplification in datasets, even balanced ones. While it addresses a critical issue of fairness and equity in AI, its direct climate impact is minimal. The research is in early stages, with code to be released soon, but no deployed technology or measured outcomes are presented.","key_impact_metrics":["Directional bias amplification (DPA)","Predictability amplification"],"technology_tags":["Machine Learning","Bias Detection","AI Fairness"],"sdg_alignment":[5,10,16],"analyzed_at":"2025-10-29T09:48:17.244667Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c0ad8dc36c7f","title":"A Digital Twin for Diesel Engines: Operator","content":"arXiv:2412.11967v2 Announce Type: replace Abstract: Improving diesel engine efficiency, reducing emissions, and enabling robust health monitoring have been critical research topics in engine modelling. While recent advancements in the use of neural networks for system monitoring have shown promising results, such methods often focus on component-level analysis, lack generalizability, and physical interpretability. In this study, we propose a novel hybrid framework that combines physics-informed neural networks (PINNs) with deep operator networks (DeepONet) to enable accurate and computationally efficient parameter identification in mean-value diesel engine models. Our method leverages physics-based system knowledge in combination with data-driven training of neural networks to enhance model applicability. Incorporating offline-trained DeepONets to predict actuator dynamics significantly lowers the online computation cost when compared to the existing PINN framework. To address the re-training burden typical of PINNs under varying input conditions, we propose two transfer learning (TL) strategies: (i) a multi-stage TL scheme offering better runtime efficiency than full online training of the PINN model and (ii) a few-shot TL scheme that freezes a shared multi-head network body and computes physics-based derivatives required for model training outside the training loop. The second strategy offers a computationally inexpensive and physics-based approach for predicting engine dynamics and parameter identification, offering computational efficiency over the existing PINN framework. Compared to existing health monitoring methods, our framework combines the interpretability of physics-based models with the flexibility of deep learning, offering substantial gains in generalization, accuracy, and deployment efficiency for diesel engine diagnostics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2412.11967","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.836151","language":"en","tags":["research","preprints","eesssy","cssy","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Kamaljyoti Nath, Varun Kumar, Daniel J. Smith, George Em Karniadakis","raw_content_length":1872,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["Digital Twin"],"persons":[],"locations":[],"monetary":[]},"char_count":1871,"language_detected":"en","key_concepts":{"key_phrases":["A Digital Twin","Diesel Engines","Operator","arXiv241211967v2 Announce Type","Abstract","diesel engine efficiency","emissions","robust health monitoring","critical research topics","engine modelling"],"filter_categories":{"research_academic":["critical research topics"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Digital Twin":2.0,"Diesel Engines":2.0,"Operator":2.0,"arXiv241211967v2 Announce Type":1.0,"Abstract":1.0,"diesel engine efficiency":1.0,"emissions":1.0,"robust health monitoring":1.0,"critical research topics":1.0,"engine modelling":1.0}},"age_hours":2.770291515833333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8797,"joy":0.0244,"surprise":0.0636,"sadness":0.0074,"fear":0.0089,"anger":0.0097,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel hybrid framework for diesel engine modeling that combines physics-informed neural networks (PINNs) with deep operator networks (DeepONet) to improve engine efficiency and reduce emissions. The research is in the applied research phase, focusing on improving computational efficiency and generalizability. There are no deployed units or customer contracts mentioned, indicating it is still in the early stages of development.","key_impact_metrics":[],"technology_tags":["physics-informed neural networks","deep operator networks","digital twin","diesel engine modeling"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T09:48:20.379665Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2924f673f421","title":"Covariances for Free: Exploiting Mean Distributions for Training","content":"arXiv:2412.14326v3 Announce Type: replace Abstract: Using pre-trained models has been found to reduce the effect of data heterogeneity and speed up federated learning algorithms. Recent works have explored training-free methods using first- and second-order statistics to aggregate local client data distributions at the server and achieve high performance without any training. In this work, we propose a training-free method based on an unbiased estimator of class covariance matrices which only uses first-order statistics in the form of class means communicated by clients to the server. We show how these estimated class covariances can be used to initialize the global classifier, thus exploiting the covariances without actually sharing them. We also show that using only within-class covariances results in a better classifier initialization. Our approach improves performance in the range of 4-26% with exactly the same communication cost when compared to methods sharing only class means and achieves performance competitive or superior to methods sharing second-order statistics with dramatically less communication overhead. The proposed method is much more communication-efficient than federated prompt-tuning methods and still outperforms them. Finally, using our method to initialize classifiers and then performing federated fine-tuning or linear probing again yields better performance. Code is available at https://github.com/dipamgoswami/FedCOF.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2412.14326","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.836580","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Dipam Goswami, Simone Magistri, Kai Wang, Bart{\\l}omiej Twardowski, Andrew D. Bagdanov, Joost van de Weijer","raw_content_length":1465,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1464,"language_detected":"en","key_concepts":{"key_phrases":["Covariances","Free","Exploiting Mean Distributions","Training","arXiv241214326v3","Announce Type","Abstract","pre-trained models","the effect","data heterogeneity"],"filter_categories":{"ai_ml":["Training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Covariances":2.0,"Free":2.0,"Exploiting Mean Distributions":2.0,"Training":2.0,"arXiv241214326v3":1.0,"Announce Type":1.0,"Abstract":1.0,"pre-trained models":1.0,"the effect":1.0,"data heterogeneity":1.0}},"age_hours":2.7703069516666665,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7874,"joy":0.1376,"surprise":0.0491,"sadness":0.0046,"fear":0.0044,"anger":0.0127,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a training-free method for federated learning that improves performance by 4-26% compared to methods sharing only class means, with the same communication cost. While this could indirectly reduce energy consumption by improving the efficiency of machine learning models, the impact on GHG emissions is theoretical and not directly quantified. The method is still in the applied research stage, lacking deployment and real-world data.","key_impact_metrics":["Performance improvement 4-26%","Communication cost reduction"],"technology_tags":["Federated Learning","Machine Learning","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:23.110718Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aea87990e1af","title":"Network Dynamics","content":"arXiv:2501.02436v4 Announce Type: replace Abstract: Advancements in artificial intelligence call for a deeper understanding of the fundamental mechanisms underlying deep learning. In this work, we propose a theoretical framework to analyze learning dynamics through the lens of dynamical systems theory. We redefine the notions of linearity and nonlinearity in neural networks by introducing two fundamental transformation units at the neuron level: order-preserving transformations and non-order-preserving transformations. Different transformation modes lead to distinct collective behaviors in weight vector organization, different modes of information extraction, and the emergence of qualitatively different learning phases. Transitions between these phases may occur during training, accounting for key phenomena such as grokking. To further characterize generalization and structural stability, we introduce the concept of attraction basins in both sample and weight spaces. The distribution of neurons with different transformation modes across layers, along with the structural characteristics of the two types of attraction basins, forms a set of core metrics for analyzing the performance of learning models. Hyperparameters such as depth, width, learning rate, and batch size act as control variables for fine-tuning these metrics. Our framework not only sheds light on the intrinsic advantages of deep learning, but also provides a novel perspective for optimizing network architectures and training strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.02436","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.837381","language":"en","tags":["statml","research","preprints","cslg","computer-science","nlincd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Yuchen Lin, Yong Zhang, Sihan Feng, Hong Zhao","raw_content_length":1525,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Network Dynamics arXiv:2501.02436v4 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1524,"language_detected":"en","key_concepts":{"key_phrases":["Network Dynamics","arXiv250102436v4 Announce Type","Abstract","Advancements","artificial intelligence call","a deeper understanding","the fundamental mechanisms","deep learning","this work","a theoretical framework"],"filter_categories":{"ai_ml":["artificial intelligence call","deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Network Dynamics":2.0,"arXiv250102436v4 Announce Type":1.0,"Abstract":1.0,"Advancements":1.0,"artificial intelligence call":1.0,"a deeper understanding":1.0,"the fundamental mechanisms":1.0,"deep learning":1.0,"this work":1.0,"a theoretical framework":1.0}},"age_hours":2.770336323055555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8313,"joy":0.0311,"surprise":0.0847,"sadness":0.0077,"fear":0.0185,"anger":0.0195,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a theoretical framework for analyzing deep learning dynamics. While it proposes a novel perspective for optimizing network architectures, it remains at the basic research stage with no deployed technology or measured outcomes related to sustainability. The potential climate impact is theoretical, as the framework's application to reducing energy consumption in AI is not demonstrated.","key_impact_metrics":[],"technology_tags":["deep learning","neural networks","AI optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:25.978935Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e98b83dbf0f","title":"Coordinated Control of Deformation and Flight for Morphing Aircraft via Meta","content":"arXiv:2501.05102v2 Announce Type: replace Abstract: In this paper, the coordinated control problem of deformation and flight for morphing aircraft (MA) is studied by using meta-learning (ML) and coupled state-dependent Riccati equations (CSDREs). Our method is built on two principal observations that dynamic models of MA under varying morphing conditions share a morphing condition independent representation function and that the specific morphing condition part lies in a set of linear coefficients. To that end, the domain adversarially invariant meta-learning (DAIML) is employed to learn the shared representation with offline flight data. Based on the learned representation function, the coordinated control of the deformation and flight for MA is formulated as a non-cooperative differential game. The state-dependent feedback control solutions can be derived by addressing a pair of CSDREs. For this purpose, Lyapunov iterations are extended to obtain the positive semidefinite (definite) stabilizing solutions of the CSDREs, and the convergence proof of the proposed algorithm is provided. Finally, a simulation study is carried out to validate the efficacy of the developed coordinated game control strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.05102","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.837770","language":"en","tags":["research","preprints","eesssy","cssy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Hao-Chi Che, Huai-Ning Wu","raw_content_length":1224,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["linear","Coordinated Control of Deformation and Flight for Morphing Aircraft","Riccati","Meta arXiv:2501.05102v2 Announce Type: replace Abstract"],"persons":["Lya"],"locations":[],"monetary":[]},"char_count":1223,"language_detected":"en","key_concepts":{"key_phrases":["Coordinated Control","Deformation","Flight","Morphing Aircraft","Meta","Announce Type","Abstract","this paper","the coordinated control problem","deformation"],"filter_categories":{"ai_ml":["Morphing Aircraft"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Coordinated Control":2.0,"Deformation":2.0,"Flight":2.0,"Morphing Aircraft":2.0,"Meta":2.0,"Announce Type":1.0,"Abstract":1.0,"this paper":1.0,"the coordinated control problem":1.0,"deformation":1.0}},"age_hours":2.7703522477777778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8766,"joy":0.0307,"surprise":0.0529,"sadness":0.0069,"fear":0.0098,"anger":0.016,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel control strategy for morphing aircraft using meta-learning. While the simulation study validates the control strategy, it remains at the simulation stage with no evidence of real-world deployment or quantified environmental benefits. The potential climate impact is theoretical, relying on the assumption that more efficient flight can reduce fuel consumption, but this is not demonstrated.","key_impact_metrics":[],"technology_tags":["morphing aircraft","meta-learning","control systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:29.192184Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dae0e0447bb9","title":"Filtering out mislabeled training instances using black","content":"arXiv:2501.06916v2 Announce Type: replace Abstract: This study proposes an approach for removing mislabeled instances from contaminated training datasets by combining surrogate model-based black-box optimization (BBO) with postprocessing and quantum annealing. Mislabeled training instances, a common issue in real-world datasets, often degrade model generalization, necessitating robust and efficient noise-removal strategies. The proposed method evaluates filtered training subsets based on validation loss, iteratively refines loss estimates through surrogate model-based BBO with postprocessing, and leverages quantum annealing to efficiently sample diverse training subsets with low validation error. Experiments on a noisy majority bit task demonstrate the method's ability to prioritize the removal of high-risk mislabeled instances. Integrating D-Wave's clique sampler running on a physical quantum annealer achieves faster optimization and higher-quality training subsets compared to OpenJij's simulated quantum annealing sampler or Neal's simulated annealing sampler, offering a scalable framework for enhancing dataset quality. This work highlights the effectiveness of the proposed method for supervised learning tasks, with future directions including its application to unsupervised learning, real-world datasets, and large-scale implementations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.06916","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.838164","language":"en","tags":["research","preprints","cond-matstat-mech","quant-ph","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Makoto Otsuka, Kento Kodama, Keisuke Morita, Masayuki Ohzeki","raw_content_length":1361,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1360,"language_detected":"en","key_concepts":{"key_phrases":["mislabeled training instances","Announce Type","Abstract","This study","an approach","mislabeled instances","training datasets","surrogate model-based black-box optimization","BBO","postprocessing"],"filter_categories":{"ai_ml":["mislabeled training instances"],"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"mislabeled training instances":2.0,"Announce Type":1.0,"Abstract":1.0,"This study":1.0,"an approach":1.0,"mislabeled instances":1.0,"training datasets":1.0,"surrogate model-based black-box optimization":1.0,"BBO":1.0,"postprocessing":1.0}},"age_hours":2.7703667366666664,"is_recent":true,"quality_score":0.7,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9105,"joy":0.0076,"surprise":0.0178,"sadness":0.0095,"fear":0.0095,"anger":0.0191,"disgust":0.026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method for improving the quality of training datasets by removing mislabeled instances, which could indirectly improve the efficiency of machine learning models used in climate-related applications. The method is demonstrated on a noisy majority bit task, showing its ability to prioritize the removal of high-risk mislabeled instances. However, there are no concrete deployments or quantified environmental benefits at this stage, and it's still in the applied research phase.","key_impact_metrics":["Faster optimization using D-Wave's clique sampler","Higher-quality training subsets"],"technology_tags":["Machine learning","Quantum annealing","Data filtering"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:48:32.242319Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f8285382246","title":"SkipClick: Combining Quick Responses and Low","content":"arXiv:2501.07960v2 Announce Type: replace Abstract: In this paper, we present a novel architecture for interactive segmentation in winter sports contexts. The field of interactive segmentation deals with the prediction of high-quality segmentation masks by informing the network about the objects position with the help of user guidance. In our case the guidance consists of click prompts. For this task, we first present a baseline architecture which is specifically geared towards quickly responding after each click. Afterwards, we motivate and describe a number of architectural modifications which improve the performance when tasked with segmenting winter sports equipment on the WSESeg dataset. With regards to the average NoC@85 metric on the WSESeg classes, we outperform SAM and HQ-SAM by 2.336 and 7.946 clicks, respectively. When applied to the HQSeg-44k dataset, our system delivers state-of-the-art results with a NoC@90 of 6.00 and NoC@95 of 9.89. In addition to that, we test our model on a novel dataset containing masks for humans during skiing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.07960","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.838568","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Robin Sch\\\"on, Julian Lorenz, Daniel Kienzle, Rainer Lienhart","raw_content_length":1064,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["HQSeg-44k","SkipClick","HQ-SAM"],"persons":["Quick Responses"],"locations":["NoC@90"],"monetary":[]},"char_count":1063,"language_detected":"en","key_concepts":{"key_phrases":["SkipClick","Combining Quick Responses","Low","arXiv250107960v2 Announce Type","Abstract","this paper","a novel architecture","interactive segmentation","winter sports contexts","The field"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SkipClick":2.0,"Combining Quick Responses":2.0,"Low":2.0,"arXiv250107960v2 Announce Type":1.0,"Abstract":1.0,"this paper":1.0,"a novel architecture":1.0,"interactive segmentation":1.0,"winter sports contexts":1.0,"The field":1.0}},"age_hours":2.7703820680555555,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9423,"joy":0.0157,"surprise":0.0259,"sadness":0.0026,"fear":0.0043,"anger":0.0065,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel architecture for interactive segmentation, specifically for winter sports. While it demonstrates improved performance on segmentation tasks using specific datasets, it lacks concrete actions or measurable outcomes related to sustainability. It is still in the early stages of development and lacks deployment data.","key_impact_metrics":["NoC@85 on WSESeg classes 2.336 clicks better than SAM","NoC@90 on HQSeg-44k 6.00"],"technology_tags":["interactive segmentation","computer vision","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:35.078690Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_987601be0e36","title":"RPO: Retrieval Preference Optimization for Robust Retrieval","content":"arXiv:2501.13726v2 Announce Type: replace Abstract: While Retrieval-Augmented Generation (RAG) has exhibited promise in utilizing external knowledge, its generation process heavily depends on the quality and accuracy of the retrieved context. Large language models (LLMs) struggle to evaluate the correctness of non-parametric knowledge retrieved externally when it differs from internal memorization, leading to knowledge conflicts during response generation. To this end, we introduce the Retrieval Preference Optimization (RPO), a lightweight and effective alignment method to adaptively leverage multi-source knowledge based on retrieval relevance. An implicit representation of retrieval relevance is derived and incorporated into the reward model to integrate retrieval evaluation and response generation into a single model, solving the problem that previous methods necessitate the additional procedure to assess the retrieval quality. Notably, RPO is the only RAG-dedicated alignment approach that quantifies the awareness of retrieval relevance in training, overcoming mathematical obstacles. Experiments on four datasets demonstrate that RPO outperforms RAG by 4-10% in accuracy without any extra component, exhibiting its robust generalization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.13726","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.838955","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Shi-Qi Yan, Quan Liu, Zhen-Hua Ling","raw_content_length":1257,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["the Retrieval Preference Optimization","RPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1256,"language_detected":"en","key_concepts":{"key_phrases":["RPO","Retrieval Preference Optimization","Robust Retrieval","arXiv250113726v2 Announce Type","Abstract","Retrieval-Augmented Generation","RAG","promise","external knowledge","its generation process"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RPO":2.0,"Retrieval Preference Optimization":2.0,"Robust Retrieval":2.0,"arXiv250113726v2 Announce Type":1.0,"Abstract":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0,"promise":1.0,"external knowledge":1.0,"its generation process":1.0}},"age_hours":2.7703966247222223,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6459,"joy":0.0042,"surprise":0.0223,"sadness":0.0693,"fear":0.059,"anger":0.1494,"disgust":0.05},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method (RPO) to improve the accuracy of retrieval-augmented generation models, leading to a 4-10% accuracy improvement on four datasets. While this could indirectly improve the efficiency of AI systems used for sustainability applications, there are no concrete deployments or measurable outcomes related to climate impact at this stage. It is still in the applied research phase.","key_impact_metrics":["Accuracy improvement 4-10%"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:38.003237Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_134242683fd0","title":"Chain","content":"arXiv:2501.14342v3 Announce Type: replace Abstract: This paper introduces an approach for training o1-like RAG models that retrieve and reason over relevant information step by step before generating the final answer. Conventional RAG methods usually perform a single retrieval step before the generation process, which limits their effectiveness in addressing complex queries due to imperfect retrieval results. In contrast, our proposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the model to dynamically reformulate the query based on the evolving state. To train CoRAG effectively, we utilize rejection sampling to automatically generate intermediate retrieval chains, thereby augmenting existing RAG datasets that only provide the correct final answer. At test time, we propose various decoding strategies to scale the model's test-time compute by controlling the length and number of sampled retrieval chains. Experimental results across multiple benchmarks validate the efficacy of CoRAG, particularly in multi-hop question answering tasks, where we observe more than 10 points improvement in EM score compared to strong baselines. On the KILT benchmark, CoRAG establishes a new state-of-the-art performance across a diverse range of knowledge-intensive tasks. Furthermore, we offer comprehensive analyses to understand the scaling behavior of CoRAG, laying the groundwork for future research aimed at developing factual and grounded foundation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.14342","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.839381","language":"en","tags":["csir","research","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Liang Wang, Haonan Chen, Nan Yang, Xiaolong Huang, Zhicheng Dou, Furu Wei","raw_content_length":1481,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["RAG","Chain arXiv:2501.14342v3"],"persons":["RAG","Announce Type"],"locations":["CoRAG"],"monetary":[]},"char_count":1480,"language_detected":"en","key_concepts":{"key_phrases":["Chain","arXiv250114342v3 Announce Type","Abstract","This paper","an approach","o1-like RAG models","relevant information step","step","the final answer","Conventional RAG methods"],"filter_categories":{"ai_ml":["Chain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chain":2.0,"arXiv250114342v3 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"an approach":1.0,"o1-like RAG models":1.0,"relevant information step":1.0,"step":1.0,"the final answer":1.0,"Conventional RAG methods":1.0}},"age_hours":2.7704117124999996,"is_recent":true,"quality_score":0.7,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9048,"joy":0.0204,"surprise":0.0291,"sadness":0.0043,"fear":0.0119,"anger":0.0187,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel method (CoRAG) for improving RAG models, demonstrating a 10-point improvement in EM score on multi-hop question answering tasks. While this could indirectly contribute to sustainability by improving information access and decision-making, it's currently at the research stage with no concrete deployment or quantified environmental impact. The vaporware flag is raised because it's an early-stage concept without deployed units or operational data.","key_impact_metrics":["10 points improvement in EM score"],"technology_tags":["RAG models","AI","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:48:41.375605Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_22b00f8c9320","title":"Enabling Population","content":"arXiv:2501.17168v5 Announce Type: replace Abstract: Tree-based Genetic Programming (TGP) is a widely used evolutionary algorithm for tasks such as symbolic regression, classification, and robotic control. Due to the intensive computational demands of running TGP, GPU acceleration is crucial for achieving scalable performance. However, efficient GPU-based execution of TGP remains challenging, primarily due to three core issues: (1) the structural heterogeneity of program individuals, (2) the complexity of integrating multiple levels of parallelism, and (3) the incompatibility between high-performance CUDA execution and flexible Python-based environments. To address these issues, we propose EvoGP, a high-performance framework tailored for GPU acceleration of TGP via population-level parallel execution. First, EvoGP introduces a tensorized representation that encodes variable-sized trees into fixed-shape, memory-aligned arrays, enabling uniform memory access and parallel computation across diverse individuals. Second, EvoGP adopts an adaptive parallelism strategy that dynamically combines intra- and inter-individual parallelism based on dataset size, ensuring high GPU utilization across a broad spectrum of tasks. Third, EvoGP embeds custom CUDA kernels into the PyTorch runtime, achieving seamless integration with Python-based environments such as Gym, MuJoCo, Brax, and Genesis. Experiments show that EvoGP attains a peak throughput exceeding $10^{11}$ GPops/s, with speedups of up to $528\\times$ over GPU-based TGP implementations and $18\\times$ over the fastest CPU-based libraries, while maintaining comparable accuracy and improved scalability across large population sizes. EvoGP is open source and accessible at: https://github.com/EMI-Group/evogp.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.17168","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.839796","language":"en","tags":["csne","research","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Zhihong Wu, Lishuang Wang, Kebin Sun, Zhuozhao Li, Ran Cheng","raw_content_length":1774,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["EvoGP","TGP","GPU","Genetic Programming","CUDA"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1773,"language_detected":"en","key_concepts":{"key_phrases":["TGP","Enabling Population","arXiv250117168v5 Announce Type","Abstract","Tree-based Genetic Programming","a widely used evolutionary algorithm","tasks","symbolic regression","classification","robotic control"],"filter_categories":{"ai_ml":["TGP","a widely used evolutionary algorithm"],"engineering":["Tree-based Genetic Programming"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TGP":3.0,"Enabling Population":2.0,"arXiv250117168v5 Announce Type":1.0,"Abstract":1.0,"Tree-based Genetic Programming":1.0,"a widely used evolutionary algorithm":1.0,"tasks":1.0,"symbolic regression":1.0,"classification":1.0,"robotic control":1.0}},"age_hours":2.7704277541666666,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9307,"joy":0.0104,"surprise":0.0242,"sadness":0.0081,"fear":0.0085,"anger":0.0111,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (EvoGP) for accelerating genetic programming on GPUs, which could indirectly contribute to sustainability by enabling faster optimization of algorithms used in climate modeling, renewable energy design, and other sustainability-related applications. The concrete action is the development of the EvoGP framework and the measurable outcome is a reported speedup of up to 528x over existing GPU-based implementations. It's still in the applied research stage, with no deployment data.","key_impact_metrics":["peak throughput exceeding 10^11 GPops/s","speedups of up to 528x"],"technology_tags":["GPU acceleration","Genetic Programming","Evolutionary Algorithms"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:48:44.261972Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_543a81f7a37e","title":"IG-MCTS: Human-in","content":"arXiv:2502.01857v2 Announce Type: replace Abstract: Human-robot cooperative navigation is challenging under incomplete information. We introduce CoNav-Maze, a simulated environment where a robot navigates with local perception while a human operator provides guidance based on an inaccurate map. The robot can share its onboard camera views to help the operator refine their understanding of the environment. To enable efficient cooperation, we propose Information Gain Monte Carlo Tree Search (IG-MCTS), an online planning algorithm that jointly optimizes autonomous movement and informative communication. IG-MCTS leverages a learned Neural Human Perception Model (NHPM) -- trained on a crowdsourced mapping dataset -- to predict how the human's internal map evolves as new observations are shared. User studies show that IG-MCTS significantly reduces communication demands and yields eye-tracking metrics indicative of lower cognitive load, while maintaining task performance comparable to teleoperation and instruction-following baselines. Finally, we illustrate generalization beyond discrete mazes through a continuous-space waterway navigation setting, in which NHPM benefits from deeper encoder-decoder architectures and IG-MCTS leverages a dynamically constructed Voronoi-partitioned traversability graph.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.01857","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.840950","language":"en","tags":["research","csai","preprints","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Shenghui Chen, Ruihan Zhao, Sandeep Chinchali, Ufuk Topcu","raw_content_length":1315,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Neural Human Perception Model","IG-MCTS: Human","CoNav-Maze","IG-MCTS"],"persons":[],"locations":[],"monetary":[]},"char_count":1314,"language_detected":"en","key_concepts":{"key_phrases":["IG-MCTS","Human","arXiv250201857v2 Announce Type","Abstract","Human-robot cooperative navigation","incomplete information","CoNav-Maze","a simulated environment","a robot","local perception"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IG-MCTS":2.0,"Human":2.0,"arXiv250201857v2 Announce Type":1.0,"Abstract":1.0,"Human-robot cooperative navigation":1.0,"incomplete information":1.0,"CoNav-Maze":1.0,"a simulated environment":1.0,"a robot":1.0,"local perception":1.0}},"age_hours":2.7704731627777774,"is_recent":true,"quality_score":1.0,"sentiment_score":9.467,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8934,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9247,"joy":0.0067,"surprise":0.0228,"sadness":0.0089,"fear":0.0154,"anger":0.0152,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm (IG-MCTS) for human-robot cooperative navigation, aiming to reduce communication demands and cognitive load. User studies show reduced communication demands and eye-tracking metrics indicative of lower cognitive load. However, it's currently in a simulated environment, so deployment readiness is low.","key_impact_metrics":["communication demands reduced","lower cognitive load"],"technology_tags":["human-robot interaction","AI navigation","Monte Carlo Tree Search"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:47.306879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_64c1264b6ea4","title":"SWE","content":"arXiv:2502.01860v5 Announce Type: replace Abstract: Foundation models (FMs), particularly large language models (LLMs), have shown significant promise in various software engineering (SE) tasks, including code generation, debugging, and requirement refinement. Despite these advances, existing evaluation frameworks are insufficient for assessing model performance in iterative, context-rich workflows characteristic of SE activities. To address this limitation, we introduce \\emph{SWE-Arena}, an interactive platform designed to evaluate FMs in SE tasks. SWE-Arena provides a transparent, open-source leaderboard, supports multi-round conversational workflows, and enables end-to-end model comparisons. The platform introduces novel metrics, including \\emph{model consistency score} that measures the consistency of model outputs through self-play matches, and \\emph{conversation efficiency index} that evaluates model performance while accounting for the number of interaction rounds required to reach conclusions. Moreover, SWE-Arena incorporates a new feature called \\emph{RepoChat}, which automatically injects repository-related context (e.g., issues, commits, pull requests) into the conversation, further aligning evaluations with real-world development processes. This paper outlines the design and capabilities of SWE-Arena, emphasizing its potential to advance the evaluation and practical application of FMs in software engineering.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.01860","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.841645","language":"en","tags":["research","csse","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Zhimin Zhao","raw_content_length":1445,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["\\emph{SWE-Arena"],"locations":[],"monetary":[]},"char_count":1444,"language_detected":"en","key_concepts":{"key_phrases":["SWE","Announce Type","Abstract","Foundation models","FMs","particularly large language models","LLMs","significant promise","various software engineering SE tasks","code generation"],"filter_categories":{"ai_ml":["particularly large language models"],"engineering":["various software engineering SE tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SWE":2.0,"Announce Type":1.0,"Abstract":1.0,"Foundation models":1.0,"FMs":1.0,"particularly large language models":1.0,"LLMs":1.0,"significant promise":1.0,"various software engineering SE tasks":1.0,"code generation":1.0}},"age_hours":2.770489361666667,"is_recent":true,"quality_score":0.7,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9276,"joy":0.0087,"surprise":0.0408,"sadness":0.0072,"fear":0.0049,"anger":0.007,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a platform for evaluating foundation models in software engineering tasks. While it introduces novel metrics like 'model consistency score' and 'conversation efficiency index', it's still in the early stages of development with no deployed units or operational data to demonstrate concrete climate impact. The potential for sustainability impact is theoretical, relying on the assumption that improved software engineering practices can lead to more efficient resource utilization and reduced energy consumption in software development and deployment.","key_impact_metrics":["model consistency score","conversation efficiency index"],"technology_tags":["large language models","software engineering","AI"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:48:50.438690Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f79b2cf80b4","title":"RadVLM: A Multitask Conversational Vision","content":"arXiv:2502.03333v2 Announce Type: replace Abstract: The widespread use of chest X-rays (CXRs), coupled with a shortage of radiologists, has driven growing interest in automated CXR analysis and AI-assisted reporting. While existing vision-language models (VLMs) show promise in specific tasks such as report generation or abnormality detection, they often lack support for interactive diagnostic capabilities. In this work we present RadVLM, a compact, multitask conversational foundation model designed for CXR interpretation. To this end, we curate a large-scale instruction dataset comprising over 1 million image-instruction pairs containing both single-turn tasks -- such as report generation, abnormality classification, and visual grounding -- and multi-turn, multi-task conversational interactions. After fine-tuning RadVLM on this instruction dataset, we evaluate it across different tasks along with re-implemented baseline VLMs. Our results show that RadVLM achieves state-of-the-art performance in conversational capabilities and visual grounding while remaining competitive in other radiology tasks. Ablation studies further highlight the benefit of joint training across multiple tasks, particularly for scenarios with limited annotated data. Together, these findings highlight the potential of RadVLM as a clinically relevant AI assistant, providing structured CXR interpretation and conversational capabilities to support more effective and accessible diagnostic workflows.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.03333","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.842093","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruip\\'erez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Bl\\\"uthgen, Farhad Nooralahzadeh, Michael Krauthammer","raw_content_length":1490,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["RadVLM","CXR"],"persons":[],"locations":[],"monetary":[]},"char_count":1489,"language_detected":"en","key_concepts":{"key_phrases":["RadVLM","A Multitask Conversational Vision","Announce Type","Abstract","The widespread use","chest X","rays","CXRs","a shortage","radiologists"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"RadVLM":3.0,"A Multitask Conversational Vision":2.0,"Announce Type":1.0,"Abstract":1.0,"The widespread use":1.0,"chest X":1.0,"rays":1.0,"CXRs":1.0,"a shortage":1.0,"radiologists":1.0}},"age_hours":2.7705052341666665,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9267,"joy":0.0118,"surprise":0.0401,"sadness":0.0041,"fear":0.0075,"anger":0.0056,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel AI model (RadVLM) for CXR interpretation, showing state-of-the-art performance in conversational capabilities and visual grounding. The model is fine-tuned on a large-scale instruction dataset, and its performance is evaluated across different tasks. While promising, it's still in the research and development phase, lacking real-world deployment and concrete data on its impact on healthcare resource utilization or patient outcomes.","key_impact_metrics":["State-of-the-art performance in conversational capabilities","Over 1 million image-instruction pairs in the dataset"],"technology_tags":["AI","Vision-Language Models","Medical Imaging","Radiology"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:48:53.676499Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_82d41f0d329b","title":"Orthogonal Representation Learning for Estimating Causal Quantities","content":"arXiv:2502.04274v2 Announce Type: replace Abstract: End-to-end representation learning has become a powerful tool for estimating causal quantities from high-dimensional observational data, but its efficiency remained unclear. Here, we face a central tension: End-to-end representation learning methods often work well in practice but lack asymptotic optimality in the form of the quasi-oracle efficiency. In contrast, two-stage Neyman-orthogonal learners provide such a theoretical optimality property but do not explicitly benefit from the strengths of representation learning. In this work, we step back and ask two research questions: (1) When do representations strengthen existing Neyman-orthogonal learners? and (2) Can a balancing constraint - commonly proposed technique in the representation learning literature - provide improvements to Neyman-orthogonality? We address these two questions through our theoretical and empirical analysis, where we introduce a unifying framework that connects representation learning with Neyman-orthogonal learners (namely, OR-learners). In particular, we show that, under the low-dimensional manifold hypothesis, the OR-learners can strictly improve the estimation error of the standard Neyman-orthogonal learners. At the same time, we find that the balancing constraint requires an additional inductive bias and cannot generally compensate for the lack of Neyman-orthogonality of the end-to-end approaches. Building on these insights, we offer guidelines for how users can effectively combine representation learning with the classical Neyman-orthogonal learners to achieve both practical performance and theoretical guarantees.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.04274","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.842536","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Valentyn Melnychuk, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel","raw_content_length":1674,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["Orthogonal Representation Learning for Estimating Causal Quantities"],"persons":[],"locations":[],"monetary":[]},"char_count":1673,"language_detected":"en","key_concepts":{"key_phrases":["Orthogonal Representation Learning","Estimating Causal Quantities","end","Announce Type","Abstract","a powerful tool","causal quantities","high-dimensional observational data","its efficiency","a central tension"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Orthogonal Representation Learning":2.0,"Estimating Causal Quantities":2.0,"end":2.0,"Announce Type":1.0,"Abstract":1.0,"a powerful tool":1.0,"causal quantities":1.0,"high-dimensional observational data":1.0,"its efficiency":1.0,"a central tension":1.0}},"age_hours":2.7705205333333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7579,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6095,"joy":0.0113,"surprise":0.0245,"sadness":0.0257,"fear":0.1507,"anger":0.1317,"disgust":0.0465},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for improving causal inference in representation learning, which could potentially be applied to optimize climate mitigation strategies. However, it is currently at the basic research stage with no deployed technology or measured outcomes. The impact potential is modest as it is an enabling technology, but the lack of economic viability and deployment readiness limit its current sustainability impact.","key_impact_metrics":[],"technology_tags":["representation learning","causal inference","Neyman-orthogonal learners"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:48:56.675583Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_425b1ce8bf46","title":"AnyEdit: Edit Any Knowledge Encoded in Language Models","content":"arXiv:2502.05628v3 Announce Type: replace Abstract: Large language models (LLMs) often produce incorrect or outdated information, necessitating efficient and precise knowledge updates. Current model editing methods, however, struggle with long-form knowledge in diverse formats, such as poetry, code snippets, and mathematical derivations. These limitations arise from their reliance on editing a single token's hidden state, a limitation we term \"efficacy barrier\". To solve this, we propose AnyEdit, a new autoregressive editing paradigm. It decomposes long-form knowledge into sequential chunks and iteratively edits the key token in each chunk, ensuring consistent and accurate outputs. Theoretically, we ground AnyEdit in the Chain Rule of Mutual Information, showing its ability to update any knowledge within LLMs. Empirically, it outperforms strong baselines by 21.5% on benchmarks including UnKEBench, AKEW, and our new EditEverything dataset for long-form diverse-formatted knowledge. Additionally, AnyEdit serves as a plug-and-play framework, enabling current editing methods to update knowledge with arbitrary length and format, significantly advancing the scope and practicality of LLM knowledge editing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.05628","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.842932","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Houcheng Jiang, Junfeng Fang, Ningyu Zhang, Guojun Ma, Mingyang Wan, Xiang Wang, Xiangnan He, Tat-seng Chua","raw_content_length":1218,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["AnyEdit","the Chain Rule of Mutual Information","EditEverything","Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1217,"language_detected":"en","key_concepts":{"key_phrases":["AnyEdit","Language Models","Announce Type","Large language models","LLMs","incorrect or outdated information","necessitating efficient and precise knowledge updates","Current model editing methods","long-form knowledge","diverse formats"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AnyEdit":3.0,"Language Models":2.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"incorrect or outdated information":1.0,"necessitating efficient and precise knowledge updates":1.0,"Current model editing methods":1.0,"long-form knowledge":1.0,"diverse formats":1.0}},"age_hours":2.7705361311111107,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9212,"joy":0.0027,"surprise":0.0246,"sadness":0.0171,"fear":0.0094,"anger":0.0108,"disgust":0.0143},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method for editing knowledge in LLMs. While it shows a 21.5% improvement on benchmarks, it is still in the research phase with no deployed units or customer contracts, limiting its immediate sustainability impact. The potential for reducing energy consumption in LLM training and inference is there, but not yet quantified.","key_impact_metrics":["21.5% improvement on benchmarks"],"technology_tags":["large language models","knowledge editing","autoregressive editing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:48:59.357999Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a1045b4bca6b","title":"Make the Fastest Faster: Importance Mask Synthesis for Interactive Volume Visualization using Reconstruction Neural Networks","content":"arXiv:2502.06053v2 Announce Type: replace Abstract: Visualizing a large-scale volumetric dataset with high resolution is challenging due to the substantial computational time and space complexity. Recent deep learning-based image inpainting methods significantly improve rendering latency by reconstructing a high-resolution image for visualization in constant time on GPU from a partially rendered image where only a portion of pixels go through the expensive rendering pipeline. However, existing solutions need to render every pixel of either a predefined regular sampling pattern or an irregular sample pattern predicted from a low-resolution image rendering. Both methods require a significant amount of expensive pixel-level rendering. In this work, we provide Importance Mask Learning (IML) and Synthesis (IMS) networks, which are the first attempts to directly synthesize important regions of the regular sampling pattern from the user's view parameters, to further minimize the number of pixels to render by jointly considering the dataset, user behavior, and the downstream reconstruction neural network. Our solution is a unified framework to handle various types of inpainting methods through the proposed differentiable compaction/decompaction layers. Experiments show our method can further improve the overall rendering latency of state-of-the-art volume visualization methods using reconstruction neural network for free when rendering scientific volumetric datasets. Our method can also directly optimize the off-the-shelf pre-trained reconstruction neural networks without elongated retraining.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.06053","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.843379","language":"en","tags":["csgr","research","preprints","cshc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Jianxin Sun, David Lenz, Hongfeng Yu, Tom Peterka","raw_content_length":1613,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["IMS","IML","GPU","Reconstruction Neural Networks arXiv:2502.06053v2","Synthesis","Importance Mask Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1612,"language_detected":"en","key_concepts":{"key_phrases":["the Fastest","Importance Mask Synthesis","Interactive Volume Visualization","Reconstruction Neural Networks","arXiv250206053v2","Announce Type","Abstract","a large-scale volumetric dataset","high resolution","Recent deep learning-based image inpainting methods"],"filter_categories":{"ai_ml":["Reconstruction Neural Networks","Recent deep learning-based image inpainting methods"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Fastest":2.0,"Importance Mask Synthesis":2.0,"Interactive Volume Visualization":2.0,"Reconstruction Neural Networks":2.0,"arXiv250206053v2":1.0,"Announce Type":1.0,"Abstract":1.0,"a large-scale volumetric dataset":1.0,"high resolution":1.0,"Recent deep learning-based image inpainting methods":1.0}},"age_hours":2.7705514219444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8644,"joy":0.0216,"surprise":0.0756,"sadness":0.0065,"fear":0.0092,"anger":0.017,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (Importance Mask Learning and Synthesis networks) to improve the rendering latency of volume visualization, potentially reducing energy consumption by minimizing the number of pixels rendered. The method is in the applied research stage, with experiments showing improved rendering latency. However, there are no deployed units or real-world data on energy savings.","key_impact_metrics":["rendering latency improvement"],"technology_tags":["neural networks","image inpainting","volume visualization"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:49:02.073448Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2021d67476fb","title":"A view on learning robust goal","content":"arXiv:2502.06996v2 Announce Type: replace Abstract: Reinforcement learning (RL) and model predictive control (MPC) offer a wealth of distinct approaches for automatic decision-making under uncertainty. Given the impact both fields have had independently across numerous domains, there is growing interest in combining the general-purpose learning capability of RL with the safety and robustness features of MPC. To this end, this paper presents a tutorial-style treatment of RL and MPC, treating them as alternative approaches to solving Markov decision processes. In our formulation, RL aims to learn a global value function through offline exploration in an uncertain environment, whereas MPC constructs a local value function through online optimization. This local-global perspective suggests new ways to design policies that combine robustness and goal-conditioned learning. Robustness is incorporated into the RL and MPC pipelines through a scenario-based approach. Goal-conditioned learning aims to alleviate the burden of engineering a reward function for RL. Combining the two leads to a single policy that unites a robust, high-level RL terminal value function with short-term, scenario-based MPC planning for reliable constraint satisfaction. This approach leverages the benefits of both RL and MPC, the effectiveness of which is demonstrated on classical control benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.06996","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.844153","language":"en","tags":["research","preprints","eesssy","cssy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Nathan P. Lawrence, Philip D. Loewen, Michael G. Forbes, R. Bhushan Gopaluni, Ali Mesbah","raw_content_length":1387,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["MPC"],"persons":["Markov"],"locations":[],"monetary":[]},"char_count":1386,"language_detected":"en","key_concepts":{"key_phrases":["MPC","A view","robust goal","Announce Type","Abstract","Reinforcement learning","predictive control","a wealth","distinct approaches","automatic decision-making"],"filter_categories":{"ai_ml":["Reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MPC":3.0,"A view":2.0,"robust goal":2.0,"Announce Type":1.0,"Abstract":1.0,"Reinforcement learning":1.0,"predictive control":1.0,"a wealth":1.0,"distinct approaches":1.0,"automatic decision-making":1.0}},"age_hours":2.770579597222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.329,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8658,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8282,"joy":0.0478,"surprise":0.0197,"sadness":0.0049,"fear":0.0827,"anger":0.0113,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical approach combining reinforcement learning and model predictive control for decision-making under uncertainty. While it demonstrates effectiveness on classical control benchmarks, there's no mention of real-world deployment or quantified impact on GHG emissions. The research is at an early stage, lacking concrete actions and measurable outcomes in a sustainability context.","key_impact_metrics":[],"technology_tags":["Reinforcement Learning","Model Predictive Control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:05.318045Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b21874e3446","title":"Causal Additive Models with Unobserved Causal Paths and Backdoor Paths","content":"arXiv:2502.07646v2 Announce Type: replace Abstract: Causal additive models provide a tractable yet expressive framework for causal discovery in the presence of hidden variables. However, when unobserved backdoor or causal paths exist between two variables, their causal relationship is often unidentifiable under existing theories. We establish sufficient conditions under which causal directions can be identified in many such cases. In particular, we derive conditions that enable identification of the parent-child relationship in a bow, an adjacent pair of observed variables sharing a hidden common parent. This represents a notoriously difficult case in causal discovery, and, to our knowledge, no prior work has established such identifiability in any causal model without imposing assumptions on the hidden variables. Our conditions rely on new characterizations of regression sets and a hybrid approach that combines independence among regression residuals with conditional independencies among observed variables. We further provide a sound and complete algorithm that incorporates these insights, and empirical evaluations demonstrate competitive performance with state-of-the-art methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.07646","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.844574","language":"en","tags":["statml","statme","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Thong Pham, Takashi Nicholas Maeda, Shohei Shimizu","raw_content_length":1201,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Causal Additive Models","Unobserved Causal Paths and Backdoor Paths arXiv:2502.07646v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1200,"language_detected":"en","key_concepts":{"key_phrases":["Causal Additive Models","Unobserved Causal Paths","Backdoor Paths","Announce Type","Causal additive models","a tractable yet expressive framework","causal discovery","the presence","hidden variables","unobserved backdoor or causal paths"],"filter_categories":{"research_academic":["causal discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Causal Additive Models":2.0,"Unobserved Causal Paths":2.0,"Backdoor Paths":2.0,"Announce Type":1.0,"Causal additive models":1.0,"a tractable yet expressive framework":1.0,"causal discovery":1.0,"the presence":1.0,"hidden variables":1.0,"unobserved backdoor or causal paths":1.0}},"age_hours":2.7705946866666666,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9258,"joy":0.0153,"surprise":0.0309,"sadness":0.0048,"fear":0.006,"anger":0.0106,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on causal discovery in the presence of hidden variables, a theoretical advancement. While it could potentially improve the accuracy of climate models in the future, it does not directly lead to concrete climate action or measurable outcomes in its current state. The research is at a basic research stage and lacks deployment readiness or economic viability.","key_impact_metrics":[],"technology_tags":["causal inference","machine learning","statistical modeling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:08.012598Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6a6d15eb1547","title":"Training","content":"arXiv:2506.04285v2 Announce Type: replace Abstract: Earth observations from low Earth orbit satellites provide vital information for decision makers to better manage time-sensitive events such as natural disasters. For the data to be most effective for first responders, low latency is required between data capture and its arrival to decision makers. A major bottleneck is in the bandwidth-limited downlinking of the data from satellites to ground stations. One approach to overcome this challenge is to process at least some of the data on-board and prioritise pertinent data to be downlinked. In this work we propose a Physics Aware Neuromorphic Network (PANN) to detect changes caused by natural disasters from a sequence of multi-spectral satellite images and produce a change map, enabling relevant data to be prioritised for downlinking. The PANN used in this study is motivated by physical neural networks comprised of nano-electronic circuit elements known as \"memristors\" (nonlinear resistors with memory). The weights in the network are dynamic and update in response to varying input signals according to memristor equations of state and electrical circuit conservation laws. The PANN thus generates physics-constrained dynamical output features which are used to detect changes in a natural disaster detection task by applying a distance-based metric. Importantly, this makes the whole model training-free, allowing it to be implemented with minimal computing resources. The PANN was benchmarked against a state-of-the-art AI model and achieved comparable or better results in each natural disaster category. It thus presents a promising solution to the challenge of resource-constrained on-board processing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04285","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.880433","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Stephen Smith, Cormac Purcell, Zdenka Kuncic","raw_content_length":1722,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["nonlinea","Announce Type"],"locations":["Earth"],"monetary":[]},"char_count":1721,"language_detected":"en","key_concepts":{"key_phrases":["decision makers","the data","arXiv250604285v2 Announce Type","Abstract","Earth observations","low Earth orbit satellites","vital information","time-sensitive events","natural disasters","first responders"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"decision makers":2.0,"the data":2.0,"arXiv250604285v2 Announce Type":1.0,"Abstract":1.0,"Earth observations":1.0,"low Earth orbit satellites":1.0,"vital information":1.0,"time-sensitive events":1.0,"natural disasters":1.0,"first responders":1.0}},"age_hours":2.7719109672222224,"is_recent":true,"quality_score":1.0,"sentiment_score":7.763,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5526,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8121,"joy":0.0037,"surprise":0.0121,"sadness":0.0108,"fear":0.1151,"anger":0.0301,"disgust":0.0161},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to on-board satellite data processing for natural disaster detection, using a Physics Aware Neuromorphic Network (PANN). The PANN is benchmarked against a state-of-the-art AI model and achieves comparable or better results, suggesting potential for reduced computing resource needs. However, it is still in the prototype/pilot stage, with no mention of deployed units or operational data.","key_impact_metrics":["Comparable or better results in each natural disaster category"],"technology_tags":["Neuromorphic Computing","On-board Satellite Processing","Natural Disaster Detection"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T09:49:11.316596Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_835ce06fd61c","title":"Detecting and Filtering Unsafe Training Data via Data Attribution with Denoised Representation","content":"arXiv:2502.11411v2 Announce Type: replace Abstract: Large language models (LLMs) are highly sensitive to even small amounts of unsafe training data, making effective detection and filtering essential for trustworthy model development. Current state-of-the-art (SOTA) detection approaches primarily rely on moderation classifiers, which require significant computation overhead for training and are limited to predefined taxonomies. In this work, we explore data attribution approaches that measure the similarity between individual training samples and a small set of unsafe target examples, based on data representations such as hidden states or gradients. We identify a key limitation in existing methods: unsafe target texts contain both critical tokens that make them unsafe and neutral tokens (e.g., stop words or benign facts) that are necessary to form fluent language, and the latter of which makes the overall representations ``noisy'' for the purpose of detecting unsafe training data. To address this challenge, we propose Denoised Representation Attribution (DRA), a novel representation-based data attribution approach that denoises training and target representations for unsafe data detection. Across tasks of filtering jailbreaks and detecting gender bias, the proposed approach leads to significant improvement for data attribution methods, outperforming SOTA methods that are mostly based on moderation classifiers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.11411","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.846162","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Yijun Pan, Taiwei Shi, Jieyu Zhao, Jiaqi W. Ma","raw_content_length":1434,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["Data Attribution with Denoised Representation arXiv:2502.11411v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1433,"language_detected":"en","key_concepts":{"key_phrases":["Filtering Unsafe Training Data","Data Attribution","Denoised Representation","Announce Type","Large language models","LLMs","even small amounts","unsafe training data","effective detection","trustworthy model development"],"filter_categories":{"ai_ml":["Filtering Unsafe Training Data","Large language models"],"engineering":["trustworthy model development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Filtering Unsafe Training Data":2.0,"Data Attribution":2.0,"Denoised Representation":2.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"even small amounts":1.0,"unsafe training data":1.0,"effective detection":1.0,"trustworthy model development":1.0}},"age_hours":2.77065657,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6463,"joy":0.0116,"surprise":0.0119,"sadness":0.0132,"fear":0.2562,"anger":0.0295,"disgust":0.0312},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (DRA) for improving the detection of unsafe training data in LLMs, which can indirectly improve sustainability by reducing biases and harmful content. The technical credibility is relatively high due to the focus on data attribution and denoising, but it's still in the applied research phase with no clear path to economic viability or deployment readiness. The impact is theoretical at this stage.","key_impact_metrics":["Significant improvement for data attribution methods","Outperforming SOTA methods"],"technology_tags":["Large Language Models","Data Attribution","Denoising"],"sdg_alignment":[4,5,16],"analyzed_at":"2025-10-29T09:49:14.442815Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a9774f272d45","title":"LightMamba: Efficient Mamba Acceleration on FPGA with Quantization and Hardware Co","content":"arXiv:2502.15260v2 Announce Type: replace Abstract: State space models (SSMs) like Mamba have recently attracted much attention. Compared to Transformer-based large language models (LLMs), Mamba achieves linear computation complexity with the sequence length and demonstrates superior performance. However, Mamba is hard to accelerate due to the scattered activation outliers and the complex computation dependency, rendering existing LLM accelerators inefficient. In this paper, we propose LightMamba that co-designs the quantization algorithm and FPGA accelerator architecture for efficient Mamba inference. We first propose an FPGA-friendly post-training quantization algorithm that features rotation-assisted quantization and power-of-two SSM quantization to reduce the majority of computation to 4-bit. We further design an FPGA accelerator that partially unrolls the Mamba computation to balance the efficiency and hardware costs. Through computation reordering as well as fine-grained tiling and fusion, the hardware utilization and memory efficiency of the accelerator get drastically improved. We implement LightMamba on Xilinx Versal VCK190 FPGA and achieve 4.65x to 6.06x higher energy efficiency over the GPU baseline. When evaluated on Alveo U280 FPGA, LightMamba reaches 93 tokens/s, which is 1.43x that of the GPU baseline. Our code is available at https://github.com/PKU-SEC-Lab/LightMamba.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.15260","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.846956","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Renjie Wei, Songqiang Xu, Linfeng Zhong, Zebin Yang, Qingyu Guo, Yuan Wang, Runsheng Wang, Meng Li","raw_content_length":1407,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["LLM","LightMamba","FPGA","Mamba"],"persons":["Mamba"],"locations":[],"monetary":[]},"char_count":1406,"language_detected":"en","key_concepts":{"key_phrases":["Mamba","LightMamba","Efficient Mamba Acceleration","FPGA","Quantization and Hardware Co","arXiv250215260v2 Announce Type","Abstract","State space models","SSMs","much attention"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mamba":3.0,"LightMamba":2.0,"Efficient Mamba Acceleration":2.0,"FPGA":2.0,"Quantization and Hardware Co":2.0,"arXiv250215260v2 Announce Type":1.0,"Abstract":1.0,"State space models":1.0,"SSMs":1.0,"much attention":1.0}},"age_hours":2.7706868655555557,"is_recent":true,"quality_score":1.0,"sentiment_score":9.403500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8807,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8356,"joy":0.0241,"surprise":0.101,"sadness":0.0092,"fear":0.0045,"anger":0.0156,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel FPGA accelerator design (LightMamba) that improves energy efficiency for Mamba inference, achieving 4.65x to 6.06x higher energy efficiency over a GPU baseline. The research is validated by implementation on Xilinx Versal VCK190 FPGA and Alveo U280 FPGA, with performance metrics reported (93 tokens/s on Alveo U280). However, it is still in the applied research stage, with no evidence of commercial deployment.","key_impact_metrics":["4.65x to 6.06x higher energy efficiency","93 tokens/s"],"technology_tags":["FPGA","Mamba","Quantization","Hardware Acceleration"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:49:17.565188Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_460918de8f56","title":"Contrastive Learning Augmented Social Recommendations","content":"arXiv:2502.15695v3 Announce Type: replace Abstract: Recommender systems are essential for modern content platforms, yet traditional behavior-based models often struggle with cold users who have limited interaction data. Engaging these users is crucial for platform growth. To bridge this gap, we propose leveraging the social-relation graph to enrich interest representations from behavior-based models. However, extracting value from social graphs is challenging due to relation noise and cross-domain inconsistency. To address the noise propagation and obtain accurate social interest, we employ a dual-view denoising strategy, employing low-rank SVD to the user-item interaction matrix for a denoised social graph and contrastive learning to align the original and reconstructed social graphs. Addressing the interest inconsistency between social and behavioral interests, we adopt a \"mutual distillation\" technique to isolate the original interests into aligned social/behavior interests and social/behavior specific interests, maximizing the utility of both. Experimental results on widely adopted industry datasets verify the method's effectiveness, particularly for cold users, offering a fresh perspective for future research. The implementation can be accessed at https://github.com/WANGLin0126/CLSRec.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.15695","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.847372","language":"en","tags":["csir","research","csai","preprints","cssi","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Lin Wang, Weisong Wang, Xuanji Xiao, Qing Li","raw_content_length":1312,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["Contrastive Learning Augmented Social Recommendations arXiv:2502.15695v3 Announce Type","SVD"],"persons":[],"locations":[],"monetary":[]},"char_count":1311,"language_detected":"en","key_concepts":{"key_phrases":["Contrastive Learning Augmented Social Recommendations","arXiv250215695v3","Announce Type","Abstract","Recommender systems","modern content platforms","traditional behavior-based models","cold users","who","these users"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contrastive Learning Augmented Social Recommendations":2.0,"arXiv250215695v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Recommender systems":1.0,"modern content platforms":1.0,"traditional behavior-based models":1.0,"cold users":1.0,"who":1.0,"these users":1.0}},"age_hours":2.7707020816666668,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9385,"joy":0.0084,"surprise":0.0118,"sadness":0.0114,"fear":0.0079,"anger":0.0107,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new algorithm for recommender systems, which could potentially reduce energy consumption by improving the efficiency of content delivery. However, the impact is theoretical and not quantified in terms of energy savings or emissions reduction. The research is in the applied research stage, with experimental results on industry datasets but no real-world deployment.","key_impact_metrics":["Effectiveness for cold users","Performance on industry datasets"],"technology_tags":["Recommender Systems","Contrastive Learning","Social Graph Analysis"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:49:20.258196Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7b08f5deb997","title":"RobustMerge: Parameter","content":"arXiv:2502.17159v3 Announce Type: replace Abstract: Fine-tuning pre-trained models with custom data leads to numerous expert models on specific tasks. Merging models into one universal model to empower multi-task ability refraining from data leakage has gained popularity. With the expansion in data and model size, parameter-efficient tuning becomes the common practice for obtaining task-specific models efficiently. However, few methods are dedicated to efficient merging, and existing methods designed for full fine-tuning merging fail under efficient merging. To address the issue, we analyze from low-rank decomposition and reveal that direction robustness during merging is crucial for merging efficient modules. We furthermore uncover that compensating for the gap between stark singular values contributes to direction robustness. Therefore, we propose RobustMerge, a training-free parameter-efficient merging method with complementary parameter adaptation to maintain direction robustness. Specifically, we (1) prune parameters and scale coefficients from inter-parameter relation for singular values to maintain direction stability away from task interference, and (2) perform cross-task normalization to enhance unseen task generalization. We establish a benchmark consisting of diverse multimodal tasks, on which we conduct experiments to certify the outstanding performance and generalizability of our method. Additional studies and extensive analyses further showcase the effectiveness. Code is available at https://github.com/AuroraZengfh/RobustMerge.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.17159","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.847789","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Fanhu Zeng, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang","raw_content_length":1568,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["RobustMerge"],"persons":[],"locations":[],"monetary":[]},"char_count":1567,"language_detected":"en","key_concepts":{"key_phrases":["RobustMerge","Parameter","arXiv250217159v3 Announce Type","Abstract","Fine-tuning pre-trained models","custom data","numerous expert models","specific tasks","Merging models","one universal model"],"filter_categories":{"ai_ml":["Fine-tuning pre-trained models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RobustMerge":2.0,"Parameter":2.0,"arXiv250217159v3 Announce Type":1.0,"Abstract":1.0,"Fine-tuning pre-trained models":1.0,"custom data":1.0,"numerous expert models":1.0,"specific tasks":1.0,"Merging models":1.0,"one universal model":1.0}},"age_hours":2.770717276388889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.691,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9382,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9258,"joy":0.0142,"surprise":0.0423,"sadness":0.0046,"fear":0.0026,"anger":0.0071,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for merging parameter-efficient models, which could potentially reduce the computational resources required for AI training and deployment. The method is still in the research phase, with code available but no real-world deployment data. The climate impact is indirect, through potential energy savings in AI model training.","key_impact_metrics":["singular values to maintain direction stability away from task interference","cross-task normalization to enhance unseen task generalization"],"technology_tags":["parameter-efficient merging","low-rank decomposition","model compression"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:49:23.296533Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0dec85b2b0bf","title":"COSMOS: A Hybrid Adaptive Optimizer for Memory","content":"arXiv:2502.17410v3 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains, yet their optimization remains a significant challenge due to the complex and high-dimensional loss landscapes they inhabit. While adaptive optimizers such as AdamW are widely used, they suffer from critical limitations, including an inability to capture interdependencies between coordinates and high memory consumption. Subsequent research, exemplified by SOAP, attempts to better capture coordinate interdependence but incurs greater memory overhead, limiting scalability for massive LLMs. An alternative approach aims to reduce memory consumption through low-dimensional projection, but this leads to substantial approximation errors, resulting in less effective optimization (e.g., in terms of per-token efficiency). In this paper, we propose COSMOS, a novel hybrid optimizer that leverages the varying importance of eigensubspaces in the gradient matrix to achieve memory efficiency without compromising optimization performance. The design of COSMOS is motivated by our empirical insights and practical considerations. Specifically, COSMOS applies SOAP to the leading eigensubspace, which captures the primary optimization dynamics, and MUON to the remaining eigensubspace, which is less critical but computationally expensive to handle with SOAP. This hybrid strategy significantly reduces memory consumption while maintaining robust optimization performance, making it particularly suitable for massive LLMs. Numerical experiments on various datasets and transformer architectures are provided to demonstrate the effectiveness of COSMOS. Our code is available at https://github.com/lliu606/COSMOS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.17410","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.848206","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Liming Liu, Zhenghao Xu, Zixuan Zhang, Hao Kang, Zichong Li, Chen Liang, Weizhu Chen, Tuo Zhao","raw_content_length":1749,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["SOAP","AdamW"],"persons":[],"locations":[],"monetary":[]},"char_count":1748,"language_detected":"en","key_concepts":{"key_phrases":["COSMOS","A Hybrid Adaptive Optimizer","Memory","arXiv250217410v3 Announce Type","Large Language Models","LLMs","remarkable success","various domains","their optimization","a significant challenge"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"COSMOS":2.0,"A Hybrid Adaptive Optimizer":2.0,"Memory":2.0,"arXiv250217410v3 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable success":1.0,"various domains":1.0,"their optimization":1.0,"a significant challenge":1.0}},"age_hours":2.7707324041666666,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7711,"joy":0.005,"surprise":0.0222,"sadness":0.0354,"fear":0.0857,"anger":0.0377,"disgust":0.043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel optimizer (COSMOS) for LLMs that aims to reduce memory consumption. While it shows promise in improving efficiency, it is still in the applied research stage with numerical experiments but no real-world deployment. The potential climate impact is indirect, stemming from potentially enabling more efficient AI development, but this is not quantified.","key_impact_metrics":["Memory consumption reduction","Optimization performance on datasets"],"technology_tags":["Large Language Models","Optimization Algorithms","Memory Efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:26.532319Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53d691f03dd4","title":"JuliaGrid: An Open","content":"arXiv:2502.18229v2 Announce Type: replace Abstract: Modern electric power systems have an increasingly complex structure due to rise in power demand and integration of diverse energy sources. Monitoring these large-scale systems, which relies on efficient state estimation, represents a challenging computational task and requires efficient simulation tools for power system steady-state analyses. Motivated by this observation, we propose JuliaGrid, an open-source framework written in the Julia programming language, designed for high performance execution across multiple platforms. The framework implements observability analysis, weighted least-squares and least-absolute value estimators, bad data analysis, and various algorithms related to phasor measurements. To complete power system analysis, the framework includes power flow and optimal power flow, enabling measurement generation for the state estimation routines. Leveraging computationally efficient algorithms, JuliaGrid solves large-scale systems across all methods, offering competitive performance compared to other open-source tools. It is specifically designed for quasi-steady-state analysis, with automatic detection and reuse of computed data to boost performance. These capabilities are validated on systems with 10000, 20000 and 70000 buses.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.18229","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.848618","language":"en","tags":["csse","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Mirsad Cosovic, Ognjen Kundacina, Muhamed Delalic, Armin Teskeredzic, Darijo Raca, Amer Mesanovic, Dragisa Miskovic, Dejan Vukobratovic, Antonello Monti","raw_content_length":1319,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["JuliaGrid"],"persons":[],"locations":["Julia"],"monetary":[]},"char_count":1318,"language_detected":"en","key_concepts":{"key_phrases":["JuliaGrid","An Open","Announce Type","Abstract","Modern electric power systems","an increasingly complex structure","power demand","integration","diverse energy sources","these large-scale systems"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"JuliaGrid":3.0,"An Open":2.0,"Announce Type":1.0,"Abstract":1.0,"Modern electric power systems":1.0,"an increasingly complex structure":1.0,"power demand":1.0,"integration":1.0,"diverse energy sources":1.0,"these large-scale systems":1.0}},"age_hours":2.770746993888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3445,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8689,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7384,"joy":0.1083,"surprise":0.0873,"sadness":0.0041,"fear":0.0358,"anger":0.0225,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":6,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"JuliaGrid is an open-source framework designed for high-performance power system analysis, which can indirectly reduce GHG emissions by enabling more efficient integration of renewable energy sources. The framework has been validated on systems with 10000, 20000 and 70000 buses, demonstrating its capability to handle large-scale systems. However, there is no direct measurement of emissions reduction or cost-effectiveness data.","key_impact_metrics":["System sizes: 10000, 20000, 70000 buses","Competitive performance compared to other open-source tools"],"technology_tags":["Power system analysis","State estimation","Optimal power flow"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:49:29.417831Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e3abf45d9e1","title":"On the Interpolation Effect of Score Smoothing in Diffusion Models","content":"arXiv:2502.19499v2 Announce Type: replace Abstract: Score-based diffusion models have achieved remarkable progress in various domains with the ability to generate new data samples that do not exist in the training set. In this work, we study the hypothesis that such creativity arises from an interpolation effect caused by a smoothing of the empirical score function. Focusing on settings where the training set lies uniformly in a one-dimensional subspace, we show theoretically how regularized two-layer ReLU neural networks tend to learn approximately a smoothed version of the empirical score function, and further probe the interplay between score smoothing and the denoising dynamics with analytical solutions and numerical experiments. In particular, we demonstrate how a smoothed score function can lead to the generation of samples that interpolate the training data along their subspace while avoiding full memorization. Moreover, we present experimental evidence that learning score functions with neural networks indeed induces a score smoothing effect, including in simple nonlinear settings and without explicit regularization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.19499","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.849009","language":"en","tags":["statml","research","preprints","cslg","computer-science","mathoc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Zhengdao Chen","raw_content_length":1143,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Diffusion Models","the Interpolation Effect of Score Smoothing","ReLU"],"persons":[],"locations":[],"monetary":[]},"char_count":1142,"language_detected":"en","key_concepts":{"key_phrases":["the Interpolation Effect","Score Smoothing","Diffusion Models","Announce Type","Abstract","Score-based diffusion models","remarkable progress","various domains","the ability","new data samples"],"filter_categories":{"ai_ml":["various domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Interpolation Effect":2.0,"Score Smoothing":2.0,"Diffusion Models":2.0,"Announce Type":1.0,"Abstract":1.0,"Score-based diffusion models":1.0,"remarkable progress":1.0,"various domains":1.0,"the ability":1.0,"new data samples":1.0}},"age_hours":2.7707621925000003,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6518,"joy":0.0825,"surprise":0.1944,"sadness":0.0068,"fear":0.011,"anger":0.0359,"disgust":0.0176},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical research on diffusion models and score smoothing. While the research is technically credible and innovative, it is at a very early stage with no deployed technology or measured outcomes related to climate impact. The potential climate impact is currently theoretical and unquantified.","key_impact_metrics":[],"technology_tags":["diffusion models","machine learning","data generation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:49:32.094501Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b4f0805e9c8c","title":"What Are They Filtering Out? An Experimental Benchmark of Filtering Strategies for Harm Reduction in Pretraining Datasets","content":"arXiv:2503.05721v2 Announce Type: replace Abstract: Data filtering strategies are a crucial component to develop safe Large Language Models (LLM), since they support the removal of harmful contents from pretraining datasets. There is a lack of research on the actual impact of these strategies on vulnerable groups to discrimination, though, and their effectiveness has not been yet systematically addressed. In this paper we present a benchmark study of data filtering strategies for harm reduction aimed at providing a systematic evaluation on these approaches. We provide an overview $55$ technical reports of English LMs and LLMs to identify the existing filtering strategies in literature and implement an experimental setting to test their impact against vulnerable groups. Our results show that the positive impact that strategies have in reducing harmful contents from documents has the side effect of increasing the underrepresentation of vulnerable groups to discrimination in datasets. WARNING: the paper could contain racist, sexist, violent, and generally offensive contents","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.05721","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.849860","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Marco Antonio Stranisci, Christian Hardmeier","raw_content_length":1090,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["Filtering Strategies","Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1087,"language_detected":"en","key_concepts":{"key_phrases":["What","An Experimental Benchmark","Filtering Strategies","Harm Reduction","Pretraining Datasets","arXiv250305721v2","Announce Type","Abstract","Data filtering strategies","a crucial component"],"filter_categories":{"ai_ml":["Pretraining Datasets"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"An Experimental Benchmark":2.0,"Filtering Strategies":2.0,"Harm Reduction":2.0,"Pretraining Datasets":2.0,"arXiv250305721v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Data filtering strategies":1.0,"a crucial component":1.0}},"age_hours":2.770794106111111,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.786,"joy":0.0082,"surprise":0.0257,"sadness":0.014,"fear":0.0408,"anger":0.0432,"disgust":0.0821},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a benchmark study of data filtering strategies for harm reduction in LLMs. While it doesn't directly address climate change, it highlights the potential for unintended consequences on vulnerable groups, which is relevant to climate justice. The study provides an overview of existing filtering strategies and implements an experimental setting to test their impact, providing some metrics.","key_impact_metrics":["Underrepresentation of vulnerable groups in datasets","Reduction of harmful content in documents"],"technology_tags":["Large Language Models","Data Filtering","Harm Reduction"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T09:49:34.747281Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4465af214030","title":"The piston effect in supercritical fluids investigated via a reversible","content":"arXiv:2503.07449v3 Announce Type: replace Abstract: In the vicinity of the liquid--vapor critical point, supercritical fluids behave strongly compressibly and, in parallel, thermophysical properties have strong state dependence. These lead to various peculiar phenomena, one of which being the piston effect where a sudden heating induces a mechanical pulse. The coupling between thermal and mechanical processes, in the linear approximation, yields a non-trivially rich thermoacoustics. The numerous applications of supercritical fluids raise the need for reliable yet fast and efficient numerical solution for thermoacoustic time and space dependence in this sensitive domain. Here, we present a second-order accurate, fully explicit staggered space-time grid finite difference method for such coupled linear thermoacoustic problems. Time integration is based on the splitting of the state space vector field representing the interactions that affect the dynamics into reversible and irreversible parts, which splitting procedure leads to decoupled wave and heat equations. The former is a hyperbolic partial differential equation, while the latter is a parabolic one, therefore, different time integration algorithms must be amalgamated to obtain a reliable, dispersion error-free, and dissipation error-free numerical solution. Finally, the thermoacoustic approximation of the supercritical piston effect is investigated via the developed method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.07449","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.850808","language":"en","tags":["research","mathna","preprints","physicsflu-dyn","csna","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Don\\'at M. Tak\\'acs, Tam\\'as F\\\"ul\\\"op, R\\'obert Kov\\'acs, M\\'aty\\'as Sz\\\"ucs","raw_content_length":1451,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1450,"language_detected":"en","key_concepts":{"key_phrases":["supercritical fluids","The piston effect","arXiv250307449v3 Announce Type","Abstract","the vicinity","--vapor critical point","thermophysical properties","strong state dependence","These","various peculiar phenomena"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"supercritical fluids":3.0,"The piston effect":2.0,"arXiv250307449v3 Announce Type":1.0,"Abstract":1.0,"the vicinity":1.0,"--vapor critical point":1.0,"thermophysical properties":1.0,"strong state dependence":1.0,"These":1.0,"various peculiar phenomena":1.0}},"age_hours":2.770824050277778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6444,"joy":0.0081,"surprise":0.1648,"sadness":0.0067,"fear":0.0495,"anger":0.0297,"disgust":0.0968},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a numerical method for simulating thermoacoustic phenomena in supercritical fluids, which could be relevant for various applications. However, it's currently at the basic research stage with no deployed technology or measured outcomes. The potential climate impact is theoretical and depends on future applications of this method.","key_impact_metrics":[],"technology_tags":["supercritical fluids","thermoacoustics","numerical simulation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:49:37.466990Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_df392cc237f8","title":"Measuring directional bias amplification in image captions using predictability","content":"arXiv:2503.07878v3 Announce Type: replace Abstract: When we train models on biased ML datasets, they not only learn these biases but can inflate them at test time - a phenomenon called bias amplification. To measure bias amplification in ML datasets, many co-occurrence-based metrics have been proposed. Co-occurrence-based metrics are effective in measuring bias amplification in simple problems like image classification. However, these metrics are ineffective for complex problems like image captioning as they cannot capture the semantics of a caption. To measure bias amplification in captions, prior work introduced a predictability-based metric called Leakage in Captioning (LIC). While LIC captures the semantics and context of captions, it has limitations. LIC cannot identify the direction in which bias is amplified, poorly estimates dataset bias due to a weak vocabulary substitution strategy, and is highly sensitive to attacker models (a hyperparameter in predictability-based metrics). To overcome these issues, we propose Directional Predictability Amplification in Captioning (DPAC). DPAC measures directional bias amplification in captions, provides a better estimate of dataset bias using an improved substitution strategy, and is less sensitive to attacker models. Our experiments on the COCO captioning dataset show how DPAC is the most reliable metric to measure bias amplification in captions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.07878","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.851277","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Rahul Nair, Bhanu Tokas, Hannah Kerner","raw_content_length":1417,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["LIC"],"persons":[],"locations":[],"monetary":[]},"char_count":1416,"language_detected":"en","key_concepts":{"key_phrases":["bias amplification","directional bias amplification","image captions","predictability","arXiv250307878v3","Announce Type","Abstract","models","biased ML datasets","these biases"],"filter_categories":{"ai_ml":["biased ML datasets"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"bias amplification":3.0,"directional bias amplification":2.0,"image captions":2.0,"predictability":2.0,"arXiv250307878v3":1.0,"Announce Type":1.0,"Abstract":1.0,"models":1.0,"biased ML datasets":1.0,"these biases":1.0}},"age_hours":2.7708395783333333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8546,"joy":0.0054,"surprise":0.03,"sadness":0.009,"fear":0.0166,"anger":0.0289,"disgust":0.0555},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a new metric (DPAC) to measure bias amplification in image captioning. While the research is technically sound and published on arXiv, it is very early stage and does not have direct, measurable impact on sustainability. The focus is on improving the accuracy of bias detection in AI models, which could indirectly support more equitable outcomes in the long term.","key_impact_metrics":[],"technology_tags":["AI","Bias Detection","Image Captioning"],"sdg_alignment":[10],"analyzed_at":"2025-10-29T09:49:40.340888Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e47abed8730","title":"A Survey on Self","content":"arXiv:2503.11101v5 Announce Type: replace Abstract: Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of \"positive\" and \"negative\" samples, where positive pairs (e.g., variation of the same image/object) are brought together in the embedding space, and negative pairs (e.g., views from different images/objects) are pushed farther away. This methodology has shown significant improvements in image understanding and image text analysis without much reliance on labeled data. In this paper, we comprehensively discuss the terminologies, recent developments and applications of contrastive learning with respect to text-image models. Specifically, we provide an overview of the approaches of contrastive learning in text-image models in recent years. Secondly, we categorize the approaches based on different model structures. Thirdly, we further introduce and discuss the latest advances of the techniques used in the process such as pretext tasks for both images and text, architectural structures, and key trends. Lastly, we discuss the recent state-of-art applications of self-supervised contrastive learning Text-Image based models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.11101","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.852102","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif","raw_content_length":1334,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1333,"language_detected":"en","key_concepts":{"key_phrases":["A Survey","Self","arXiv250311101v5 Announce Type","Abstract","Self-supervised learning","a machine learning approach","implicit labels","underlined patterns","discriminative features","unlabeled data"],"filter_categories":{"ai_ml":["a machine learning approach"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Survey":2.0,"Self":2.0,"arXiv250311101v5 Announce Type":1.0,"Abstract":1.0,"Self-supervised learning":1.0,"a machine learning approach":1.0,"implicit labels":1.0,"underlined patterns":1.0,"discriminative features":1.0,"unlabeled data":1.0}},"age_hours":2.770870363055556,"is_recent":true,"quality_score":0.7,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7151,"joy":0.0117,"surprise":0.0359,"sadness":0.0075,"fear":0.0437,"anger":0.059,"disgust":0.127},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper is a survey of contrastive learning techniques for text-image models. While self-supervised learning can potentially reduce the energy consumption of data labeling, it is still in the research phase and lacks concrete deployment or measurable outcomes related to climate impact. The article primarily discusses methodologies and applications, not deployed technology or quantified environmental benefits.","key_impact_metrics":[],"technology_tags":["self-supervised learning","contrastive learning","text-image models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:49:43.402194Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9a6c7129ceaa","title":"Aggregation on Learnable Manifolds for Asynchronous Federated Optimization","content":"arXiv:2503.14396v3 Announce Type: replace Abstract: Asynchronous federated learning (FL) with heterogeneous clients faces two key issues: curvature-induced loss barriers encountered by standard linear parameter interpolation techniques (e.g. FedAvg) and interference from stale updates misaligned with the server's current optimisation state. To alleviate these issues, we introduce a geometric framework that casts aggregation as curve learning in a Riemannian model space and decouples trajectory selection from update conflict resolution. Within this, we propose AsyncBezier, which replaces linear aggregation with low-degree polynomial (Bezier) trajectories to bypass loss barriers, and OrthoDC, which projects delayed updates via inner product-based orthogonality to reduce interference. We establish framework-level convergence guarantees covering each variant given simple assumptions on their components. On three datasets spanning general-purpose and healthcare domains, including LEAF Shakespeare and FEMNIST, our approach consistently improves accuracy and client fairness over strong asynchronous baselines; finally, we show that these gains are preserved even when other methods are allocated a higher local compute budget.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.14396","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.852920","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Archie Licudi, Anshul Thakur, Soheila Molaei, Danielle Belgrave, David Clifton","raw_content_length":1237,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["AsyncBezier"],"persons":["Bezier"],"locations":[],"monetary":[]},"char_count":1236,"language_detected":"en","key_concepts":{"key_phrases":["Aggregation","Learnable Manifolds","Asynchronous Federated Optimization","arXiv250314396v3 Announce Type","Abstract","Asynchronous federated learning","heterogeneous clients","two key issues","curvature-induced loss barriers","standard linear parameter interpolation techniques"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Aggregation":2.0,"Learnable Manifolds":2.0,"Asynchronous Federated Optimization":2.0,"arXiv250314396v3 Announce Type":1.0,"Abstract":1.0,"Asynchronous federated learning":1.0,"heterogeneous clients":1.0,"two key issues":1.0,"curvature-induced loss barriers":1.0,"standard linear parameter interpolation techniques":1.0}},"age_hours":2.770901093888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9266,"joy":0.0045,"surprise":0.0231,"sadness":0.0109,"fear":0.0091,"anger":0.0173,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm (AsyncBezier, OrthoDC) for asynchronous federated learning, which could potentially improve the efficiency and fairness of machine learning models. The impact on climate is indirect, as it improves the efficiency of computation, but there's no concrete deployment or quantification of energy savings. The research is validated on datasets like LEAF Shakespeare and FEMNIST, but it's still in the research phase with no real-world deployments.","key_impact_metrics":["accuracy improvement","client fairness improvement"],"technology_tags":["federated learning","asynchronous optimization","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:46.652824Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_531fad86004e","title":"CCDP: Composition of Conditional Diffusion Policies with Guided Sampling","content":"arXiv:2503.15386v2 Announce Type: replace Abstract: Imitation Learning offers a promising approach to learn directly from data without requiring explicit models, simulations, or detailed task definitions. During inference, actions are sampled from the learned distribution and executed on the robot. However, sampled actions may fail for various reasons, and simply repeating the sampling step until a successful action is obtained can be inefficient. In this work, we propose an enhanced sampling strategy that refines the sampling distribution to avoid previously unsuccessful actions. We demonstrate that by solely utilizing data from successful demonstrations, our method can infer recovery actions without the need for additional exploratory behavior or a high-level controller. Furthermore, we leverage the concept of diffusion model decomposition to break down the primary problem, which may require long-horizon history to manage failures, into multiple smaller, more manageable sub-problems in learning, data collection, and inference, thereby enabling the system to adapt to variable failure counts. Our approach yields a low-level controller that dynamically adjusts its sampling space to improve efficiency when prior samples fall short. We validate our method across several tasks, including door opening with unknown directions, object manipulation, and button-searching scenarios, demonstrating that our approach outperforms traditional baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.15386","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.853334","language":"en","tags":["research","csai","preprints","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Amirreza Razmjoo, Sylvain Calinon, Michael Gienger, Fan Zhang","raw_content_length":1463,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":["Composition of Conditional Diffusion Policies with Guided Sampling arXiv:2503.15386v2 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1462,"language_detected":"en","key_concepts":{"key_phrases":["Composition","Conditional Diffusion Policies","Guided Sampling","Announce Type","Abstract","Imitation Learning","a promising approach","data","explicit models","simulations"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Composition":2.0,"Conditional Diffusion Policies":2.0,"Guided Sampling":2.0,"Announce Type":1.0,"Abstract":1.0,"Imitation Learning":1.0,"a promising approach":1.0,"data":1.0,"explicit models":1.0,"simulations":1.0}},"age_hours":2.770916337777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9507,"joy":0.0083,"surprise":0.0112,"sadness":0.0071,"fear":0.0046,"anger":0.0088,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to imitation learning for robotics, improving the efficiency of action sampling. While it demonstrates improved performance in simulated tasks, it is still in the early stages of development and lacks real-world deployment data. The potential climate impact is indirect, as it could improve the efficiency of robots used in sustainable applications, but this is not explicitly quantified or demonstrated.","key_impact_metrics":["Improved sampling efficiency","Adaptation to variable failure counts"],"technology_tags":["Imitation Learning","Robotics","Diffusion Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:49.343950Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f584c90c9c39","title":"PeRoI: A Pedestrian","content":"arXiv:2503.16481v2 Announce Type: replace Abstract: Robots are increasingly being deployed in public spaces such as shopping malls, sidewalks, and hospitals, where safe and socially aware navigation depends on anticipating how pedestrians respond to their presence. However, existing datasets rarely capture the full spectrum of robot-induced reactions, e.g., avoidance, neutrality, attraction, which limits progress in modeling these interactions. In this paper, we present the Pedestrian-Robot Interaction~(PeRoI) dataset that captures pedestrian motions categorized into attraction, neutrality, and repulsion across two outdoor sites under three controlled conditions: no robot present, with stationary robot, and with moving robot. This design explicitly reveals how pedestrian behavior varies across robot contexts, and we provide qualitative and quantitative comparisons to established state-of-the-art datasets. Building on these data, we propose the Neural Robot Social Force Model~(NeuRoSFM), an extension of the Social Force Model that integrates neural networks to augment inter-human dynamics with learned components and explicit robot-induced forces to better predict pedestrian motion in vicinity of robots. We evaluate NeuRoSFM by generating trajectories on multiple real-world datasets. The results demonstrate improved modeling of pedestrian-robot interactions, leading to better prediction accuracy, and highlight the value of our dataset and method for advancing socially aware navigation strategies in human-centered environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.16481","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.853737","language":"en","tags":["research","preprints","cshc","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Subham Agrawal, Nico Ostermann-Myrau, Nils Dengler, Maren Bennewitz","raw_content_length":1551,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["the Neural Robot Social Fo"],"persons":[],"locations":[],"monetary":[]},"char_count":1550,"language_detected":"en","key_concepts":{"key_phrases":["PeRoI","A Pedestrian","Announce Type","Abstract","Robots","public spaces","shopping malls","sidewalks","hospitals","safe and socially aware navigation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PeRoI":2.0,"A Pedestrian":2.0,"Announce Type":1.0,"Abstract":1.0,"Robots":1.0,"public spaces":1.0,"shopping malls":1.0,"sidewalks":1.0,"hospitals":1.0,"safe and socially aware navigation":1.0}},"age_hours":2.7709321802777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9342,"joy":0.0095,"surprise":0.0238,"sadness":0.0038,"fear":0.0123,"anger":0.01,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a dataset and model for predicting pedestrian behavior around robots. While it improves robot navigation, the direct climate impact is minimal as it's in the early research phase and doesn't directly address GHG emissions or carbon sequestration. The technical credibility is relatively high due to the peer-reviewed nature and quantitative comparisons.","key_impact_metrics":["Prediction accuracy improvement","Qualitative comparisons to state-of-the-art datasets"],"technology_tags":["Robot navigation","Pedestrian behavior modeling","Social Force Model"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:49:52.174156Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be1e5b600335","title":"Understanding and Improving Information Preservation in Prompt Compression for LLMs","content":"arXiv:2503.19114v2 Announce Type: replace Abstract: Recent advancements in large language models (LLMs) have enabled their successful application to a broad range of tasks. However, in information-intensive tasks, the prompt length can grow fast, leading to increased computational requirements, performance degradation, and induced biases from irrelevant or redundant information. Recently, various prompt compression techniques have been introduced to optimize the trade-off between reducing input length and retaining performance. We propose a holistic evaluation framework that allows for in-depth analysis of prompt compression methods. We focus on three key aspects, besides compression ratio: (i) downstream task performance, (ii) grounding in the input context, and (iii) information preservation. Using our framework, we analyze state-of-the-art soft and hard compression methods and show that some fail to preserve key details from the original prompt, limiting performance on complex tasks. By identifying these limitations, we are able to improve one soft prompting method by controlling compression granularity, achieving up to +23% in downstream performance, +8 BERTScore points in grounding, and 2.7x more entities preserved in compression. Ultimately, we find that the best effectiveness/compression rate trade-off is achieved with soft prompting combined with sequence-level training.The code is available at https://github.com/amazon-science/information-preservation-in-prompt-compression.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.19114","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.854918","language":"en","tags":["csir","research","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Weronika {\\L}ajewska, Momchil Hardalov, Laura Aina, Neha Anna John, Hang Su, Llu\\'is M\\`arquez","raw_content_length":1508,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["Improving Information Preservation"],"persons":[],"locations":[],"monetary":[]},"char_count":1507,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Improving Information Preservation","Prompt Compression","Announce Type","Abstract","Recent advancements","large language models","their successful application","a broad range","tasks"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Improving Information Preservation":2.0,"Prompt Compression":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent advancements":1.0,"large language models":1.0,"their successful application":1.0,"a broad range":1.0,"tasks":1.0}},"age_hours":2.770976052222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8658,"joy":0.0208,"surprise":0.0796,"sadness":0.0055,"fear":0.0066,"anger":0.0147,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving prompt compression for LLMs, which could indirectly reduce energy consumption by making LLMs more efficient. The study shows improvements in downstream performance (+23%), grounding (+8 BERTScore points), and entity preservation (2.7x more entities) using their framework. However, it's still in the applied research phase with no real-world deployment.","key_impact_metrics":["+23% downstream performance","+8 BERTScore points in grounding","2.7x more entities preserved"],"technology_tags":["prompt compression","large language models","soft prompting"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:49:55.063622Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3960ab8cf6e3","title":"Upper and Lower Bounds for the Linear Ordering Principle","content":"arXiv:2503.19188v2 Announce Type: replace Abstract: Korten and Pitassi (FOCS, 2024) defined a new complexity class $L_2P$ as the polynomial-time Turing closure of the Linear Ordering Principle. They put it between $MA$ (Merlin--Arthur protocols) and $S_2P$ (the second symmetric level of the polynomial hierarchy). In this paper we sandwich $L_2P$ between $P^{prMA}$ and $P^{prSBP}$. (The oracles here are promise problems, and $SBP$ is the only known class between $MA$ and $AM$.) The containment in $P^{prSBP}$ is proved via an iterative process that uses a $prSBP$ oracle to estimate the average order rank of a subset and find the minimum of a linear order. Another containment result of this paper is $P^{prO_2P} \\subseteq O_2P$ (where $O_2P$ is the input-oblivious version of $S_2P$). These containment results altogether have several byproducts: We give an affirmative answer to an open question posed by of Chakaravarthy and Roy (Computational Complexity, 2011) whether $P^{prMA} \\subseteq S_2P$, thereby settling the relative standing of the existing (non-oblivious) Karp-Lipton-style collapse results of Chakaravarthy and Roy (2011) and Cai (2007), We give an affirmative answer to an open question of Korten and Pitassi whether a Karp-Lipton-style collapse can be proven for $L_2P$, We show that the Karp-Lipton-style collapse to $P^{prOMA}$ is actually better than both known collapses to $P^{prMA}$ due to Chakaravarthy and Roy (Computational Complexity, 2011) and to $O_2P$ also due to Chakaravarthy and Roy (STACS, 2006). Thus we resolve the controversy between previously incomparable Karp-Lipton collapses stemming from these two lines of research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.19188","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.855348","language":"en","tags":["cscc","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Edward A. Hirsch, Ilya Volkovich","raw_content_length":1676,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Compu","\\subseteq O_2P$","Korten","Chakaravarthy","L_2P$","O_2P$","Pitassi","Roy","Arthur"],"locations":[],"monetary":["S_2P$","between $MA$","SBP$","between $MA$ and $AM$.","between $P^{prMA}$ and $P^{prSBP}$."]},"char_count":1665,"language_detected":"en","key_concepts":{"key_phrases":["the Linear Ordering Principle","Upper and Lower Bounds","arXiv250319188v2 Announce Type","Abstract","FOCS","a new complexity class","the polynomial-time Turing closure","MA Merlin","Arthur protocols","S_2P"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Linear Ordering Principle":3.0,"Upper and Lower Bounds":2.0,"arXiv250319188v2 Announce Type":1.0,"Abstract":1.0,"FOCS":1.0,"a new complexity class":1.0,"the polynomial-time Turing closure":1.0,"MA Merlin":1.0,"Arthur protocols":1.0,"S_2P":1.0}},"age_hours":2.770993558055556,"is_recent":true,"quality_score":1.0,"sentiment_score":3.091,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3818,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9326,"joy":0.0079,"surprise":0.037,"sadness":0.0057,"fear":0.0043,"anger":0.0075,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical computer science research on the complexity class L2P and its relationship to other complexity classes. While it answers open questions in the field, it does not directly address any concrete actions or measurable outcomes related to sustainability. The research is at a very early stage and has no immediate deployment or economic viability.","key_impact_metrics":[],"technology_tags":["computational complexity","linear ordering principle"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:49:57.795127Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d461c5e57b5","title":"How Secure is Forgetting? Linking Machine Unlearning to Machine Learning Attacks","content":"arXiv:2503.20257v2 Announce Type: replace Abstract: As Machine Learning (ML) evolves, the complexity and sophistication of security threats against this paradigm continue to grow as well, threatening data privacy and model integrity. In response, Machine Unlearning (MU) is a recent technology that aims to remove the influence of specific data from a trained model, enabling compliance with privacy regulations and user requests. This can be done for privacy compliance (e.g., GDPR's right to be forgotten) or model refinement. However, the intersection between classical threats in ML and MU remains largely unexplored. In this Systematization of Knowledge (SoK), we provide a structured analysis of security threats in ML and their implications for MU. We analyze four major attack classes, namely, Backdoor Attacks, Membership Inference Attacks (MIA), Adversarial Attacks, and Inversion Attacks, we investigate their impact on MU and propose a novel classification based on how they are usually used in this context. Finally, we identify open challenges, including ethical considerations, and explore promising future research directions, paving the way for future research in secure and privacy-preserving Machine Unlearning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.20257","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.855742","language":"en","tags":["computer-science","cscr","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Muhammed Shafi K. P., Serena Nicolazzo, Antonino Nocera, Vinod P","raw_content_length":1231,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Backdoor Attacks, Membership Inference Attacks","MIA","Adversarial Attacks","GDPR"],"persons":["SoK","Machine Unlearning","arXiv:2503.20257v2 Announce Type","thei","Machine Learning"],"locations":[],"monetary":[]},"char_count":1230,"language_detected":"en","key_concepts":{"key_phrases":["Machine Unlearning","Machine Learning Attacks","arXiv250320257v2 Announce Type","Abstract","Machine Learning","the complexity","sophistication","security threats","this paradigm","data privacy"],"filter_categories":{"ai_ml":["Machine Learning Attacks","Machine Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Machine Unlearning":3.0,"Machine Learning Attacks":2.0,"arXiv250320257v2 Announce Type":1.0,"Abstract":1.0,"Machine Learning":1.0,"the complexity":1.0,"sophistication":1.0,"security threats":1.0,"this paradigm":1.0,"data privacy":1.0}},"age_hours":2.7710096766666665,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.2702,"joy":0.0044,"surprise":0.0178,"sadness":0.0064,"fear":0.6429,"anger":0.0487,"disgust":0.0096},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper analyzes the security implications of machine unlearning, a technology that could potentially support privacy regulations like GDPR. While it doesn't directly reduce GHG emissions, improved data privacy can indirectly support sustainability initiatives by enabling better data governance and trust. The research is at an early stage, with no deployed technology or measured outcomes.","key_impact_metrics":[],"technology_tags":["machine unlearning","data privacy","machine learning security"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:50:00.212700Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95179351d118","title":"Issue Localization via LLM","content":"arXiv:2503.22424v3 Announce Type: replace Abstract: Issue solving aims to generate patches to fix reported issues in real-world code repositories according to issue descriptions. Issue localization forms the basis for accurate issue solving. Recently, LLM-based issue localization methods have demonstrated state-of-the-art performance. However, these methods either search from files mentioned in issue descriptions or in the whole repository and struggle to balance the breadth and depth of the search space to converge on the target efficiently. Moreover, they allow LLM to explore whole repositories freely, making it challenging to control the search direction to prevent the LLM from searching for incorrect targets. This paper introduces CoSIL, an LLM-driven, powerful function-level issue localization method without training or indexing. CoSIL employs a two-phase code graph search strategy. It first conducts broad exploration at the file level using dynamically constructed module call graphs, and then performs in-depth analysis at the function level by expanding the module call graph into a function call graph and executing iterative searches. To precisely control the search direction, CoSIL designs a pruner to filter unrelated directions and irrelevant contexts. To avoid incorrect interaction formats in long contexts, CoSIL introduces a reflection mechanism that uses additional independent queries in short contexts to enhance formatted abilities. Experiment results demonstrate that CoSIL achieves a Top-1 localization accuracy of 43.3\\% and 44.6\\% on SWE-bench Lite and SWE-bench Verified, respectively, with Qwen2.5-Coder-32B, average outperforming the state-of-the-art methods by 96.04\\%. When CoSIL is integrated into an issue-solving method, Agentless, the issue resolution rate improves by 2.98\\%--30.5\\%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.22424","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.856163","language":"en","tags":["research","csse","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Zhonghao Jiang, Xiaoxue Ren, Meng Yan, Wei Jiang, Yong Li, Zhongxin Liu","raw_content_length":1834,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":["CoSIL"],"monetary":[]},"char_count":1833,"language_detected":"en","key_concepts":{"key_phrases":["Issue Localization","LLM","issue descriptions","Announce Type","Abstract","Issue","patches","reported issues","real-world code repositories","Issue localization"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Issue Localization":2.0,"LLM":2.0,"issue descriptions":2.0,"Announce Type":1.0,"Abstract":1.0,"Issue":1.0,"patches":1.0,"reported issues":1.0,"real-world code repositories":1.0,"Issue localization":1.0}},"age_hours":2.7710248325,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.874,"joy":0.006,"surprise":0.0112,"sadness":0.0145,"fear":0.0377,"anger":0.0326,"disgust":0.0239},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new method (CoSIL) for issue localization in code repositories using LLMs, improving the accuracy of issue solving. The concrete action is the development and testing of this method on SWE-bench Lite and SWE-bench Verified. The evidence supporting the claims is the reported Top-1 localization accuracy of 43.3% and 44.6% and the improved issue resolution rate when integrated into an issue-solving method.","key_impact_metrics":["Top-1 localization accuracy of 43.3%","issue resolution rate improves by 2.98%--30.5%"],"technology_tags":["LLM","code graph search"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:03.372975Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fbe8b514c9bd","title":"ProbRes: Probabilistic Jump Diffusion for Open","content":"arXiv:2504.03948v2 Announce Type: replace Abstract: Open-world egocentric activity recognition poses a fundamental challenge due to its unconstrained nature, requiring models to infer unseen activities from an expansive, partially observed search space. We introduce ProbRes, a Probabilistic Residual search framework based on jump-diffusion that efficiently navigates this space by balancing prior-guided exploration with likelihood-driven exploitation. Our approach integrates structured commonsense priors to construct a semantically coherent search space, adaptively refines predictions using Vision-Language Models (VLMs) and employs a stochastic search mechanism to locate high-likelihood activity labels while minimizing exhaustive enumeration efficiently. We systematically evaluate ProbRes across multiple openness levels (L0-L3), demonstrating its adaptability to increasing search space complexity. In addition to achieving state-of-the-art performance on benchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, and Charades-Ego), we establish a clear taxonomy for open-world recognition, delineating the challenges and methodological advancements necessary for egocentric activity understanding. Our results highlight the importance of structured search strategies, paving the way for scalable and efficient open-world activity recognition.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.03948","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.856571","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Sanjoy Kundu, Shanmukha Vellamcheti, Sathyanarayanan N. Aakur","raw_content_length":1355,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Vision-Language Models","Probabilistic Residual","ProbRes"],"persons":["ProbRes"],"locations":[],"monetary":[]},"char_count":1354,"language_detected":"en","key_concepts":{"key_phrases":["ProbRes","Probabilistic Jump Diffusion","Open","Announce Type","Abstract","Open-world egocentric activity recognition","a fundamental challenge","its unconstrained nature","models","unseen activities"],"filter_categories":{"ai_ml":["its unconstrained nature"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ProbRes":3.0,"Probabilistic Jump Diffusion":2.0,"Open":2.0,"Announce Type":1.0,"Abstract":1.0,"Open-world egocentric activity recognition":1.0,"a fundamental challenge":1.0,"its unconstrained nature":1.0,"models":1.0,"unseen activities":1.0}},"age_hours":2.7710400097222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8786,"joy":0.0201,"surprise":0.0516,"sadness":0.0054,"fear":0.0269,"anger":0.0138,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a new AI framework (ProbRes) for activity recognition. While it demonstrates improved performance on benchmark datasets, it's currently in the research phase with no deployed applications or quantified environmental impact. The potential for sustainability impact is indirect, through improved efficiency in resource management or other applications, but this is not explicitly addressed or quantified.","key_impact_metrics":["State-of-the-art performance on benchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, and Charades-Ego)","Adaptability to increasing search space complexity (L0-L3)"],"technology_tags":["AI","Activity Recognition","Vision-Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:06.646287Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1b1d37c80318","title":"DeepOHeat","content":"arXiv:2504.03955v2 Announce Type: replace Abstract: Thermal analysis is crucial in 3D-IC design due to increased power density and complex heat dissipation paths. Although operator learning frameworks such as DeepOHeat~\\cite{liu2023deepoheat} have demonstrated promising preliminary results in accelerating thermal simulation, they face critical limitations in prediction capability for multi-scale thermal patterns, training efficiency, and trustworthiness of results during design optimization. This paper presents DeepOHeat-v1, an enhanced physics-informed operator learning framework that addresses these challenges through three key innovations. First, we integrate Kolmogorov-Arnold Networks with learnable activation functions as trunk networks, enabling an adaptive representation of multi-scale thermal patterns. This approach achieves a 1.25x and 6.29x reduction in error in two representative test cases. Second, we introduce a separable training method that decomposes the basis function along the coordinate axes, achieving 62x training speedup and 31x GPU memory reduction in our baseline case, and enabling thermal analysis at resolutions previously infeasible due to GPU memory constraints. Third, we propose a confidence score to evaluate the trustworthiness of the predicted results, and further develop a hybrid optimization workflow that combines operator learning with finite difference (FD) using Generalized Minimal Residual (GMRES) method for incremental solution refinement, enabling efficient and trustworthy thermal optimization. Experimental results demonstrate that DeepOHeat-v1 achieves accuracy comparable to optimization using high-fidelity finite difference solvers, while speeding up the entire optimization process by $70.6\\times$ in our test cases, effectively minimizing the peak temperature through optimal placement of heat-generating components. Open source code is available at https://github.com/xlyu0127/DeepOHeat-v1.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.03955","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.856993","language":"en","tags":["research","csai","physicsdata-an","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Xinling Yu, Ziyue Liu, Hai Li, Yixing Li, Xin Ai, Zhiyu Zeng, Ian Young, Zheng Zhang","raw_content_length":1961,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":["Kolmogorov-Arnold Networks"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1960,"language_detected":"en","key_concepts":{"key_phrases":["DeepOHeat","arXiv250403955v2","Announce Type","Abstract","Thermal analysis","3D-IC design","increased power density","complex heat dissipation paths","operator","frameworks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepOHeat":2.0,"arXiv250403955v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Thermal analysis":1.0,"3D-IC design":1.0,"increased power density":1.0,"complex heat dissipation paths":1.0,"operator":1.0,"frameworks":1.0}},"age_hours":2.7710537683333336,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8555,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9117,"joy":0.008,"surprise":0.016,"sadness":0.0128,"fear":0.0337,"anger":0.011,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (DeepOHeat-v1) for thermal analysis in 3D-IC design, which can lead to more efficient placement of heat-generating components, potentially reducing energy consumption. The method achieves a 1.25x and 6.29x reduction in error in test cases and a 70.6x speedup in the optimization process compared to high-fidelity finite difference solvers. However, it's still in the applied research stage with no deployed units.","key_impact_metrics":["1.25x reduction in error","6.29x reduction in error","70.6x speedup in optimization"],"technology_tags":["Thermal Analysis","Operator Learning","3D-IC Design"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T09:50:09.695899Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9d2a1cd2a764","title":"SMF: Template","content":"arXiv:2504.04831v2 Announce Type: replace Abstract: Animation retargetting applies sparse motion description (e.g., keypoint sequences) to a character mesh to produce a semantically plausible and temporally coherent full-body mesh sequence. Existing approaches come with restrictions -- they require access to template-based shape priors or artist-designed deformation rigs, suffer from limited generalization to unseen motion and/or shapes, or exhibit motion jitter. We propose Self-supervised Motion Fields (SMF), a self-supervised framework that is trained with only sparse motion representations, without requiring dataset-specific annotations, templates, or rigs. At the heart of our method are Kinetic Codes, a novel autoencoder-based sparse motion encoding, that exposes a semantically rich latent space, simplifying large-scale training. Our architecture comprises dedicated spatial and temporal gradient predictors, which are jointly trained in an end-to-end fashion. The combined network, regularized by the Kinetic Codes' latent space, has good generalization across both unseen shapes and new motions. We evaluated our method on unseen motion sampled from AMASS, D4D, Mixamo, and raw monocular video for animation transfer on various characters with varying shapes and topology. We report a new SoTA on the AMASS dataset in the context of generalization to unseen motion. Code, weights, and supplementary are available on the project webpage at https://motionfields.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.04831","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.857795","language":"en","tags":["csgr","research","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Sanjeev Muralikrishnan, Niladri Shekhar Dutt, Niloy J. Mitra","raw_content_length":1489,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["SMF","Kinetic Codes"],"persons":[],"locations":[],"monetary":[]},"char_count":1488,"language_detected":"en","key_concepts":{"key_phrases":["SMF Template","arXiv250404831v2 Announce Type","Abstract","Animation","sparse motion description","keypoint sequences","a character mesh","Existing approaches","restrictions","access"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SMF Template":2.0,"arXiv250404831v2 Announce Type":1.0,"Abstract":1.0,"Animation":1.0,"sparse motion description":1.0,"keypoint sequences":1.0,"a character mesh":1.0,"Existing approaches":1.0,"restrictions":1.0,"access":1.0}},"age_hours":2.7710850919444443,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8952,"joy":0.004,"surprise":0.0223,"sadness":0.0246,"fear":0.0169,"anger":0.0176,"disgust":0.0194},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel self-supervised framework (SMF) for animation retargeting. While the technology itself doesn't directly reduce GHG emissions, it could potentially reduce the energy consumption associated with manual animation processes. The method is evaluated on unseen motion sampled from AMASS, D4D, Mixamo, and raw monocular video, demonstrating generalization capabilities, but it is still in the research phase.","key_impact_metrics":["SoTA on the AMASS dataset"],"technology_tags":["animation retargeting","self-supervised learning","motion fields"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:12.850362Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a000069ff01d","title":"RAISE: Reinforced Adaptive Instruction Selection For Large Language Models","content":"arXiv:2504.07282v4 Announce Type: replace Abstract: In the instruction fine-tuning of large language models (LLMs), it is widely recognized that a few high-quality instructions are superior to a large number of low-quality instructions. At present, many instruction selection methods have been proposed, but most of these methods select instruction based on heuristic quality metrics, and only consider data selection before training. These designs lead to insufficient optimization of instruction fine-tuning, and fixed heuristic indicators are often difficult to optimize for specific tasks. Therefore, we design a dynamic, task-objective-driven instruction selection framework RAISE(Reinforced Adaptive Instruction SElection), which incorporates the entire instruction fine-tuning process into optimization, selecting instructions at each step based on the expected impact of each instruction on model performance improvement. Our approach is well interpretable and has strong task-specific optimization capabilities. By modeling dynamic instruction selection as a sequential decision-making process, we use RL to train our selection strategy. Extensive experiments and result analysis prove the superiority of our method compared with other instruction selection methods. Notably, RAISE achieves superior performance by updating only 1% of the training steps compared to full-data training, demonstrating its efficiency and effectiveness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.07282","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.858632","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Qingsong Lv, Yangning Li, Zihua Lan, Zishan Xu, Jiwei Tang, Tingwei Lu, Yinghui Li, Wenhao Jiang, Hong-Gee Kim, Hai-Tao Zheng, Philip S. Yu","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Instruction SElection","Reinforced Adaptive Instruction Selection For Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1442,"language_detected":"en","key_concepts":{"key_phrases":["RAISE","Reinforced Adaptive Instruction Selection","Large Language Models","Announce Type","Abstract","the instruction fine-tuning","large language models","LLMs","a few high-quality instructions","a large number"],"filter_categories":{"ai_ml":["RAISE","Large Language Models","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RAISE":2.0,"Reinforced Adaptive Instruction Selection":2.0,"Large Language Models":2.0,"Announce Type":1.0,"Abstract":1.0,"the instruction fine-tuning":1.0,"large language models":1.0,"LLMs":1.0,"a few high-quality instructions":1.0,"a large number":1.0}},"age_hours":2.7711159550000004,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.939,"joy":0.0087,"surprise":0.0241,"sadness":0.0053,"fear":0.0031,"anger":0.0121,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (RAISE) for instruction selection in LLMs, showing improved efficiency by achieving superior performance with only 1% of the training steps compared to full-data training. While this could indirectly reduce energy consumption of training LLMs, the direct climate impact is theoretical and not quantified. The method is still in the applied research phase, without deployed units or customer contracts.","key_impact_metrics":["1% training steps","superior performance"],"technology_tags":["large language models","instruction fine-tuning","reinforcement learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:50:16.243558Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d7320a2a258","title":"Differentially Private 2D Human Pose Estimation","content":"arXiv:2504.10190v3 Announce Type: replace Abstract: Human pose estimation (HPE) has become essential in numerous applications including healthcare, activity recognition, and human-computer interaction. However, the privacy implications of processing sensitive visual data present significant deployment barriers in critical domains. While traditional anonymization techniques offer limited protection and often compromise data utility for broader motion analysis, Differential Privacy (DP) provides formal privacy guarantees but typically degrades model performance when applied naively. In this work, we present the first comprehensive framework for differentially private 2D human pose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient Descent (DP-SGD) to this task. To effectively balance privacy with performance, we adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a low-dimensional subspace. Next, we incorporate Feature Differential Privacy(FDP) to selectively privatize only sensitive features while retaining public visual cues. Finally, we propose a hybrid feature-projective DP framework that combines both approaches to balance privacy and accuracy for HPE. We evaluate our approach on the MPII dataset across varying privacy budgets, training strategies, and clipping norms. Our combined feature-projective method consistently outperforms vanilla DP-SGD and individual baselines, achieving up to 82.61\\% mean PCKh@0.5 at $\\epsilon = 0.8$, substantially closing the gap to the non-private performance. This work lays foundation for privacy-preserving human pose estimation in real-world, sensitive applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.10190","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.859030","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni","raw_content_length":1672,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["Differential Privacy","Differentially Private Stochastic Gradient Descent","PDP-SGD","HPE","Projected DP-SGD"],"persons":[],"locations":[],"monetary":[]},"char_count":1671,"language_detected":"en","key_concepts":{"key_phrases":["Differentially Private 2D Human Pose Estimation","Announce Type","Abstract","Human pose estimation","HPE","numerous applications","healthcare","activity recognition","human-computer interaction","the privacy implications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Differentially Private 2D Human Pose Estimation":2.0,"Announce Type":1.0,"Abstract":1.0,"Human pose estimation":1.0,"HPE":1.0,"numerous applications":1.0,"healthcare":1.0,"activity recognition":1.0,"human-computer interaction":1.0,"the privacy implications":1.0}},"age_hours":2.771130971388889,"is_recent":true,"quality_score":1.0,"sentiment_score":3.3,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.34,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8772,"joy":0.0051,"surprise":0.0108,"sadness":0.012,"fear":0.0492,"anger":0.0228,"disgust":0.0229},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for differentially private 2D human pose estimation, aiming to balance privacy and accuracy. The concrete action is the development and evaluation of a new algorithm (feature-projective DP). Evidence is provided through experiments on the MPII dataset, showing improved performance compared to baselines. However, it is still in the applied research stage with no real-world deployment.","key_impact_metrics":["82.61% mean PCKh@0.5 at $\\epsilon = 0.8$"],"technology_tags":["Differential Privacy","Human Pose Estimation","Privacy-Preserving AI"],"sdg_alignment":[3,9,16],"analyzed_at":"2025-10-29T09:50:19.065440Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_567190e6a0ae","title":"GestureCoach: Rehearsing for Engaging Talks with LLM","content":"arXiv:2504.10706v2 Announce Type: replace Abstract: This paper introduces GestureCoach, a system designed to help speakers deliver more engaging talks by guiding them to gesture effectively during rehearsal. GestureCoach combines an LLM-driven gesture recommendation model with a rehearsal interface that proactively cues speakers to gesture appropriately. Trained on experts' gesturing patterns from TED talks, the model consists of two modules: an emphasis proposal module, which predicts when to gesture by identifying gesture-worthy text segments in the presenter notes, and a gesture identification module, which determines what gesture to use by retrieving semantically appropriate gestures from a curated gesture database. Results of a model performance evaluation and user study (N=30) show that the emphasis proposal module outperforms off-the-shelf LLMs in identifying suitable gesture regions, and that participants rated the majority of these predicted regions and their corresponding gestures as highly appropriate. A subsequent user study (N=10) showed that rehearsing with GestureCoach encouraged speakers to gesture and significantly increased gesture diversity, resulting in more engaging talks. We conclude with design implications for future AI-driven rehearsal systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.10706","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.859643","language":"en","tags":["research","computer-science","preprints","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Ashwin Ram, Varsha Suresh, Artin Saberpour Abadian, Vera Demberg, J\\\"urgen Steimle","raw_content_length":1290,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["GestureCoach"],"persons":["TED","GestureCoach"],"locations":[],"monetary":[]},"char_count":1289,"language_detected":"en","key_concepts":{"key_phrases":["GestureCoach","Engaging Talks","LLM","speakers","arXiv250410706v2 Announce Type","Abstract","This paper","a system","more engaging talks","them"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GestureCoach":4.0,"Engaging Talks":2.0,"LLM":2.0,"speakers":2.0,"arXiv250410706v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"a system":1.0,"more engaging talks":1.0,"them":1.0}},"age_hours":2.7711458772222226,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3275,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8655,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8898,"joy":0.0492,"surprise":0.0376,"sadness":0.0035,"fear":0.0081,"anger":0.0088,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a system for improving public speaking, not directly related to climate or sustainability. The system is in the prototype stage, with user studies showing increased gesture diversity. While innovative, it lacks concrete actions or measurable outcomes related to environmental sustainability.","key_impact_metrics":["Increased gesture diversity","User ratings of gesture appropriateness"],"technology_tags":["LLM","Gesture recognition","AI-driven rehearsal"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:50:21.560803Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_387ef6a3c166","title":"zkFuzz: Foundation and Framework for Effective Fuzzing of Zero","content":"arXiv:2504.11961v2 Announce Type: replace Abstract: Zero-knowledge (ZK) circuits enable privacy-preserving computations and are central to many cryptographic protocols. Systems like Circom simplify ZK development by combining witness computation and circuit constraints in one program. However, even small errors can compromise security of ZK programs -- under-constrained circuits may accept invalid witnesses, while over-constrained ones may reject valid ones. Static analyzers are often imprecise with high false positives, and formal tools struggle with real-world circuit scale. Additionally, existing tools overlook several critical behaviors, such as intermediate computations and program aborts, and thus miss many vulnerabilities. Our theoretical contribution is the Trace-Constraint Consistency Test (TCCT), a foundational, language-independent formulation of ZK circuit bugs. TCCT provides a unified semantics that subsumes prior definitions and captures both under- and over-constrained vulnerabilities, exposing the full space of ZK bugs that elude prior tools. Our systems contribution is zkFuzz, a novel program mutation-based fuzzing framework for detecting TCCT violations. zkFuzz systematically mutates the computational logic of Zk programs guided by a novel fitness function, and injects carefully crafted inputs using tailored heuristics to expose bugs. We evaluated zkFuzz on 452 real-world ZK circuits written in Circom, a leading programming system for ZK development. zkFuzz successfully identified 85 bugs, including 59 zero-days-39 of which were confirmed by developers and \\nfixed fixed, including bugs undetectable by prior works due to their fundamentally limited formulations, earning thousands of bug bounties. Our preliminary research on Noir, another emerging DSL for ZK circuit, also demonstrates the feasibility of zkFuzz to support multiple DSLs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.11961","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.860073","language":"en","tags":["computer-science","cscr","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Hideaki Takahashi, Jihwan Kim, Suman Jana, Junfeng Yang","raw_content_length":1884,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Circom","Trace-Constraint Consistency Test","TCCT"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1883,"language_detected":"en","key_concepts":{"key_phrases":["zkFuzz Foundation","Framework","Effective Fuzzing","Zero","arXiv250411961v2 Announce Type","Abstract","Zero-knowledge ZK circuits","privacy-preserving computations","many cryptographic protocols","Systems"],"filter_categories":{"engineering":["Systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"zkFuzz Foundation":2.0,"Framework":2.0,"Effective Fuzzing":2.0,"Zero":2.0,"arXiv250411961v2 Announce Type":1.0,"Abstract":1.0,"Zero-knowledge ZK circuits":1.0,"privacy-preserving computations":1.0,"many cryptographic protocols":1.0,"Systems":1.0}},"age_hours":2.7711617016666668,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.935,"joy":0.0083,"surprise":0.0174,"sadness":0.0077,"fear":0.0104,"anger":0.0164,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a novel fuzzing framework (zkFuzz) for detecting bugs in zero-knowledge circuits. While ZK circuits can enable privacy-preserving computations with potential applications in sustainability (e.g., secure data sharing for carbon accounting), the direct climate impact is currently theoretical. The framework identified 85 bugs in real-world ZK circuits, including 59 zero-days, demonstrating its effectiveness.","key_impact_metrics":["85 bugs identified","59 zero-days identified"],"technology_tags":["zero-knowledge circuits","fuzzing","program mutation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:24.526587Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0b81370cd90d","title":"Diffusion Generative Recommendation with Continuous Tokens","content":"arXiv:2504.12007v2 Announce Type: replace Abstract: Recent advances in generative artificial intelligence, particularly large language models (LLMs), have opened new opportunities for enhancing recommender systems (RecSys). Most existing LLM-based RecSys approaches operate in a discrete space, using vector-quantized tokenizers to align with the inherent discrete nature of language models. However, these quantization methods often result in lossy tokenization and suboptimal learning, primarily due to inaccurate gradient propagation caused by the non-differentiable argmin operation in standard vector quantization. Inspired by the emerging trend of embracing continuous tokens in language models, we propose ContRec, a novel framework that seamlessly integrates continuous tokens into LLM-based RecSys. Specifically, ContRec consists of two key modules: a sigma-VAE Tokenizer, which encodes users/items with continuous tokens; and a Dispersive Diffusion module, which captures implicit user preference. The tokenizer is trained with a continuous Variational Auto-Encoder (VAE) objective, where three effective techniques are adopted to avoid representation collapse. By conditioning on the previously generated tokens of the LLM backbone during user modeling, the Dispersive Diffusion module performs a conditional diffusion process with a novel Dispersive Loss, enabling high-quality user preference generation through next-token diffusion. Finally, ContRec leverages both the textual reasoning output from the LLM and the latent representations produced by the diffusion model for Top-K item retrieval, thereby delivering comprehensive recommendation results. Extensive experiments on four datasets demonstrate that \\ourname{} consistently outperforms both traditional and SOTA LLM-based recommender systems. Our results highlight the potential of continuous tokenization and generative modeling for advancing the next generation of recommender systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12007","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.860520","language":"en","tags":["csir","research","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Haohao Qu, Shanru Lin, Yujuan Ding, Yiqi Wang, Wenqi Fan","raw_content_length":1961,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["RecSys","Dis","LLM","ContRec"],"persons":["Continuous Tokens"],"locations":[],"monetary":[]},"char_count":1960,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Generative Recommendation","Continuous Tokens","arXiv250412007v2 Announce Type","Abstract","Recent advances","generative artificial intelligence","particularly large language models","LLMs","new opportunities","recommender systems"],"filter_categories":{"ai_ml":["generative artificial intelligence","particularly large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Generative Recommendation":2.0,"Continuous Tokens":2.0,"arXiv250412007v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"generative artificial intelligence":1.0,"particularly large language models":1.0,"LLMs":1.0,"new opportunities":1.0,"recommender systems":1.0}},"age_hours":2.7711765466666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9184,"joy":0.0071,"surprise":0.0441,"sadness":0.0063,"fear":0.0065,"anger":0.0104,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel framework for recommender systems using continuous tokens and diffusion models. While it shows improved performance on datasets, it is still in the research phase with no real-world deployment or quantified environmental impact. The potential for reducing energy consumption in recommendation systems is there, but currently unproven.","key_impact_metrics":["Improved performance on four datasets","High-quality user preference generation"],"technology_tags":["Generative AI","Recommender Systems","Diffusion Models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:50:27.593527Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f606bf3c5f5c","title":"Fast and Rigorous Modeling of Antenna-","content":"arXiv:2504.12613v2 Announce Type: replace Abstract: A rigorous and computationally efficient method is presented for evaluating the reflection coefficients of antennas operating above planar layered media. The approach reformulates the problem within the framework of the antenna's generalized scattering matrix (GSM), expressed in terms of spherical vector wave functions (SVWFs). The mutual interaction between the antenna and the layered structure is modeled through spherical-to-planar vector wave transformations that incorporate the exact Fresnel reflection response of the medium, without introducing any simplifying approximations. This formulation dramatically reduces algebraic complexity and enables fast, stable numerical implementation. Excluding the one-time preprocessing required to obtain the antenna's free-space GSM, each evaluation for a given layered configuration can be completed within milliseconds -- achieving several orders of magnitude speed improvement over full-wave solvers such as FEKO, while maintaining virtually identical accuracy. The proposed framework thus provides a powerful foundation for real-time electromagnetic characterization and inverse modeling involving planar layered environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12613","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.860904","language":"en","tags":["csce","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Chenbo Shi, Shichen Liang, Xin Gu, Jin Pan","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["antennas","GSM"],"persons":["antenna","Announce Type"],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["Fast and Rigorous Modeling","arXiv250412613v2 Announce Type","Abstract","A rigorous and computationally efficient method","the reflection coefficients","antennas","planar layered media","The approach","the problem","the framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fast and Rigorous Modeling":2.0,"arXiv250412613v2 Announce Type":1.0,"Abstract":1.0,"A rigorous and computationally efficient method":1.0,"the reflection coefficients":1.0,"antennas":1.0,"planar layered media":1.0,"The approach":1.0,"the problem":1.0,"the framework":1.0}},"age_hours":2.7711913430555555,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7887,"joy":0.0744,"surprise":0.0697,"sadness":0.0064,"fear":0.0161,"anger":0.0307,"disgust":0.0139},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a computationally efficient method for antenna modeling. While it achieves several orders of magnitude speed improvement over full-wave solvers, its direct climate impact is limited. The technology is at the applied research stage, with potential for future deployment but lacking concrete deployment data.","key_impact_metrics":["milliseconds evaluation time","several orders of magnitude speed improvement"],"technology_tags":["antenna modeling","electromagnetic characterization","spherical vector wave functions"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:30.824439Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f1a95613d0e6","title":"ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos","content":"arXiv:2504.12882v3 Announce Type: replace Abstract: The growing influence of video content as a medium for communication and misinformation underscores the urgent need for effective tools to analyze claims in multilingual and multi-topic settings. Existing efforts in misinformation detection largely focus on written text, leaving a significant gap in addressing the complexity of spoken text in video transcripts. We introduce ViClaim, a dataset of 1,798 annotated video transcripts across three languages (English, German, Spanish) and six topics. Each sentence in the transcripts is labeled with three claim-related categories: fact-check-worthy, fact-non-check-worthy, or opinion. We developed a custom annotation tool to facilitate the highly complex annotation process. Experiments with state-of-the-art multilingual language models demonstrate strong performance in cross-validation (macro F1 up to 0.896) but reveal challenges in generalization to unseen topics, particularly for distinct domains. Our findings highlight the complexity of claim detection in video transcripts. ViClaim offers a robust foundation for advancing misinformation detection in video-based communication, addressing a critical gap in multimodal analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12882","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.861303","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Patrick Giedemann, Pius von D\\\"aniken, Jan Deriu, Alvaro Rodrigo, Anselmo Pe\\~nas, Mark Cieliebak","raw_content_length":1240,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["ViClaim"],"persons":["Announce Type"],"locations":["Videos"],"monetary":[]},"char_count":1239,"language_detected":"en","key_concepts":{"key_phrases":["ViClaim","A Multilingual Multilabel Dataset","Automatic Claim Detection","Videos","arXiv250412882v3 Announce Type","Abstract","The growing influence","video content","a medium","communication"],"filter_categories":{"ai_ml":["ViClaim"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ViClaim":3.0,"A Multilingual Multilabel Dataset":2.0,"Automatic Claim Detection":2.0,"Videos":2.0,"arXiv250412882v3 Announce Type":1.0,"Abstract":1.0,"The growing influence":1.0,"video content":1.0,"a medium":1.0,"communication":1.0}},"age_hours":2.7712069958333334,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8051,"joy":0.006,"surprise":0.0293,"sadness":0.0092,"fear":0.1277,"anger":0.0177,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes the creation of a multilingual dataset (ViClaim) for detecting misinformation in videos. While this could indirectly support climate action by helping to identify and combat climate misinformation, it doesn't directly reduce GHG emissions or promote specific climate technologies. The dataset is in the applied research phase, with experiments showing strong performance in cross-validation (macro F1 up to 0.896).","key_impact_metrics":["macro F1 score 0.896"],"technology_tags":["misinformation detection","natural language processing","machine learning"],"sdg_alignment":[16,17],"analyzed_at":"2025-10-29T09:50:33.930245Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
