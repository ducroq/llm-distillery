{"id":"science_arxiv_cs_f6e09ca6023b","title":"EmoDebt: Bayesian-Optimized Emotional Intelligence for Strategic Agent","content":"arXiv:2503.21080v5 Announce Type: replace Abstract: The emergence of autonomous Large Language Model (LLM) agents has created a new ecosystem of strategic, agent-to-agent interactions. However, a critical challenge remains unaddressed: in high-stakes, emotion-sensitive domains like debt collection, LLM agents pre-trained on human dialogue are vulnerable to exploitation by adversarial counterparts who simulate negative emotions to derail negotiations. To fill this gap, we first contribute a novel dataset of simulated debt recovery scenarios and a multi-agent simulation framework. Within this framework, we introduce EmoDebt, an LLM agent architected for robust performance. Its core innovation is a Bayesian-optimized emotional intelligence engine that reframes a model's ability to express emotion in negotiation as a sequential decision-making problem. Through online learning, this engine continuously tunes EmoDebt's emotional transition policies, discovering optimal counter-strategies against specific debtor tactics. Extensive experiments on our proposed benchmark demonstrate that EmoDebt achieves significant strategic robustness, substantially outperforming non-adaptive and emotion-agnostic baselines across key performance metrics, including success rate and operational efficiency. By introducing both a critical benchmark and a robustly adaptive agent, this work establishes a new foundation for deploying strategically robust LLM agents in adversarial, emotion-sensitive debt interactions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.21080","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.546130","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Yunbo Long, Yuhan Liu, Liming Xu, Alexandra Brintrup","raw_content_length":1511,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["EmoDebt","Bayesian-Optimized Emotional Intelligence for Strategic Agent","LLM"],"persons":["Language Model"],"locations":[],"monetary":[]},"char_count":1510,"language_detected":"en","key_concepts":{"key_phrases":["EmoDebt","Bayesian-Optimized Emotional Intelligence","Strategic Agent","arXiv250321080v5 Announce Type","Abstract","The emergence","autonomous Large Language Model LLM agents","a new ecosystem","agent","a critical challenge"],"filter_categories":{"ai_ml":["autonomous Large Language Model LLM agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EmoDebt":2.0,"Bayesian-Optimized Emotional Intelligence":2.0,"Strategic Agent":2.0,"arXiv250321080v5 Announce Type":1.0,"Abstract":1.0,"The emergence":1.0,"autonomous Large Language Model LLM agents":1.0,"a new ecosystem":1.0,"agent":1.0,"a critical challenge":1.0}},"age_hours":2.746529335,"is_recent":true,"quality_score":1.0,"sentiment_score":1.596,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6808,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2456,"joy":0.0067,"surprise":0.0169,"sadness":0.0156,"fear":0.6764,"anger":0.0261,"disgust":0.0128},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":1,"justice_equity":1,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This is research into AI for debt collection. While it demonstrates improved performance in simulated scenarios, it has no direct climate or sustainability impact and is at an early stage of development. The metrics are related to success rate and operational efficiency within the simulation, not environmental outcomes.","key_impact_metrics":["success rate","operational efficiency"],"technology_tags":["LLM agent","Bayesian optimization","emotional intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:41:30.964844Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d1b733e322ed","title":"Dynamics","content":"arXiv:2504.00236v3 Announce Type: replace Abstract: This paper addresses the problem of generating dynamically admissible trajectories for control tasks using diffusion models, particularly in scenarios where the environment is complex and system dynamics are crucial for practical application. We propose a novel framework that integrates system dynamics directly into the diffusion model's denoising process through a sequential prediction and projection mechanism. This mechanism, aligned with the diffusion model's noising schedule, ensures generated trajectories are both consistent with expert demonstrations and adhere to underlying physical constraints. Notably, our approach can generate maximum likelihood trajectories and accurately recover trajectories generated by linear feedback controllers, even when explicit dynamics knowledge is unavailable. We validate the effectiveness of our method through experiments on standard control tasks and a complex non-convex optimal control problem involving waypoint tracking and collision avoidance, demonstrating its potential for efficient trajectory generation in practical applications. Our code repository is available at www.github.com/darshangm/dynamics-aware-diffusion.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.00236","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.546525","language":"en","tags":["preprints","computer-science","mathoc","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Darshan Gadginmath, Fabio Pasqualetti","raw_content_length":1231,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["linear"],"persons":[],"locations":[],"monetary":[]},"char_count":1230,"language_detected":"en","key_concepts":{"key_phrases":["Dynamics","arXiv250400236v3 Announce Type","Abstract","This paper","the problem","dynamically admissible trajectories","control tasks","diffusion models","scenarios","the environment"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dynamics":2.0,"arXiv250400236v3 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"the problem":1.0,"dynamically admissible trajectories":1.0,"control tasks":1.0,"diffusion models":1.0,"scenarios":1.0,"the environment":1.0}},"age_hours":2.746542321388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8154,"joy":0.0454,"surprise":0.1027,"sadness":0.0069,"fear":0.0109,"anger":0.0142,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for generating dynamically admissible trajectories using diffusion models. While the research shows promise in improving control tasks and trajectory generation, it is still in the applied research phase with no deployed units or real-world data demonstrating climate impact. The potential climate impact is theoretical, as the application to specific emissions-reducing technologies is not yet demonstrated.","key_impact_metrics":["Maximum likelihood trajectories","Accurately recover trajectories generated by linear feedback controllers"],"technology_tags":["Diffusion Models","Trajectory Generation","Control Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:41:35.069985Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0652eabed790","title":"GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling","content":"arXiv:2504.01483v4 Announce Type: replace Abstract: Realistic digital garment modeling remains a labor-intensive task due to the intricate process of translating 2D sewing patterns into high-fidelity, simulation-ready 3D garments. We introduce GarmageNet, a unified generative framework that automates the creation of 2D sewing patterns, the construction of sewing relationships, and the synthesis of 3D garment initializations compatible with physics-based simulation. Central to our approach is Garmage, a novel garment representation that encodes each panel as a structured geometry image, effectively bridging the semantic and geometric gap between 2D structural patterns and 3D garment geometries. Followed by GarmageNet, a latent diffusion transformer to synthesize panel-wise geometry images and GarmageJigsaw, a neural module for predicting point-to-point sewing connections along panel contours. To support training and evaluation, we build GarmageSet, a large-scale dataset comprising 14,801 professionally designed garments with detailed structural and style annotations. Our method demonstrates versatility and efficacy across multiple application scenarios, including scalable garment generation from multi-modal design concepts (text prompts, sketches, photographs), automatic modeling from raw flat sewing patterns, pattern recovery from unstructured point clouds, and progressive garment editing using conventional instructions, laying the foundation for fully automated, production-ready pipelines in digital fashion. Project page: https://style3d.github.io/garmagenet/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.01483","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.546958","language":"en","tags":["preprints","computer-science","research","csgr","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Siran Li, Ruiyang Liu, Chen Liu, Zhendong Wang, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang","raw_content_length":1588,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["GarmageNet","Garmage"],"persons":["GarmageJigsaw"],"locations":[],"monetary":[]},"char_count":1587,"language_detected":"en","key_concepts":{"key_phrases":["GarmageNet A Multimodal Generative Framework","2D sewing patterns","Announce Type","Abstract","Realistic digital garment modeling","a labor-intensive task","the intricate process","high-fidelity","simulation-ready 3D garments","GarmageNet"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GarmageNet A Multimodal Generative Framework":2.0,"2D sewing patterns":2.0,"Announce Type":1.0,"Abstract":1.0,"Realistic digital garment modeling":1.0,"a labor-intensive task":1.0,"the intricate process":1.0,"high-fidelity":1.0,"simulation-ready 3D garments":1.0,"GarmageNet":1.0}},"age_hours":2.74655691,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8405,"joy":0.0738,"surprise":0.056,"sadness":0.0041,"fear":0.0094,"anger":0.0122,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (GarmageNet) for automating garment design, potentially reducing waste in the fashion industry by optimizing material use and reducing the need for physical prototypes. The framework is evaluated on a dataset of 14,801 garments, but there's no information on real-world deployment or quantified impact on material waste or energy consumption. It is still in the applied research phase.","key_impact_metrics":["14,801 professionally designed garments"],"technology_tags":["AI","Generative Models","Fashion Technology","Digital Garment Modeling"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:41:37.852398Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a450fc0aeda6","title":"Gen","content":"arXiv:2504.01924v3 Announce Type: replace Abstract: Over the past two decades, researchers have made significant steps in simulating agent-based human crowds, yet most efforts remain focused on low-level tasks such as collision avoidance, path following, and flocking. Realistic simulations, however, require modeling high-level behaviors that emerge from agents interacting with each other and with their environment over time. We introduce Generative Crowds (Gen-C), a generative framework that produces crowd scenarios capturing agent-agent and agent-environment interactions, shaping coherent high-level crowd plans. To avoid the labor-intensive process of collecting and annotating real crowd video data, we leverage large language models (LLMs) to bootstrap synthetic datasets of crowd scenarios. We propose a time-expanded graph representation, encoding actions, interactions, and spatial context. Gen-C employs a dual Variational Graph Autoencoder (VGAE) architecture that jointly learns connectivity patterns and node features conditioned on textual and structural signals, overcoming the limitations of direct LLM generation to enable scalable, environment-aware multi-agent crowd simulations. We demonstrate the effectiveness of Gen-C on scenarios with diverse behaviors such as a University Campus and a Train Station, showing that it generates heterogeneous crowds, coherent interactions, and high-level decision-making patterns consistent with real-world crowd dynamics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.01924","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.547373","language":"en","tags":["preprints","computer-science","cslg","research","csgr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Andreas Panayiotou, Panayiotis Charalambous, Ioannis Karamouzas","raw_content_length":1485,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Gen-C"],"persons":["Gen-C","Gen arXiv:2504.01924v3 Announce Type","Generative Crowds"],"locations":[],"monetary":[]},"char_count":1484,"language_detected":"en","key_concepts":{"key_phrases":["Gen","arXiv250401924v3 Announce Type","Abstract","the past two decades","researchers","significant steps","agent-based human crowds","most efforts","low-level tasks","collision avoidance"],"filter_categories":{"ai_ml":["Gen"],"hydrogen_energy":["Gen"],"research_academic":["researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gen":3.0,"arXiv250401924v3 Announce Type":1.0,"Abstract":1.0,"the past two decades":1.0,"researchers":1.0,"significant steps":1.0,"agent-based human crowds":1.0,"most efforts":1.0,"low-level tasks":1.0,"collision avoidance":1.0}},"age_hours":2.7465721419444447,"is_recent":true,"quality_score":0.7,"sentiment_score":4.314,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1372,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9229,"joy":0.0106,"surprise":0.0297,"sadness":0.0036,"fear":0.0155,"anger":0.0133,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a generative framework (Gen-C) for simulating crowd behavior, which could potentially optimize urban planning and resource allocation to reduce energy consumption and improve pedestrian flow. However, it's currently in the applied research phase with no deployed units or measured outcomes related to sustainability. The technical credibility is moderate due to the use of LLMs and VGAE, but economic viability and deployment readiness are low at this stage.","key_impact_metrics":[],"technology_tags":["agent-based modeling","large language models","urban planning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:41:41.396718Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b9f8e8ef0714","title":"A Cyber Insurance Policy for Hedging Against Load","content":"arXiv:2504.04287v4 Announce Type: replace Abstract: Uncertainties in renewable energy resources (RES) and load variations can lead to elevated system operational costs. Moreover, the emergence of large-scale distributed threats, such as load-altering attacks (LAAs), can induce substantial load variations, further exacerbating these costs. Although traditional defense measures can reduce the likelihood of such attacks, considerable residual risks remain. Thus, this paper proposes a cyber insurance framework designed to hedge against additional operational costs resulting from LAAs and substantial load variations in renewable-rich grids. The insurance framework determines both the insurance coverage and premium based on the Value at Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated using the system failure probability and the probability density function (PDF) of the system operation cost. The system failure probability is assessed through a semi-Markov process (SMP), while the cost distribution is estimated through a cost minimization model of a distribution grid combined with a Monte-Carlo simulation to capture load variability. Furthermore, we employ a bi-level optimization scheme that identifies the specific load distribution leading to the maximum system cost, thereby enhancing the accuracy of the operation cost PDF estimation. The effectiveness and scalability of the proposed cyber insurance policy are evaluated considering a modified IEEE-118 test bus system and the IEEE European low-voltage (LV) test feeders model. The case study shows that with a relatively low premium, the network operator can hedge against additional operational costs caused by malicious load manipulations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.04287","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.547816","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Shijie Pan, Zaint A. Alexakis, S Subhash Lakshminarayana, Charalambos Konstantinou","raw_content_length":1738,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["the Value at Risk (VaR","Hedging Against Load arXiv:2504.04287v4 Announce Type","PDF"],"persons":["Tail Value at Risk"],"locations":[],"monetary":[]},"char_count":1737,"language_detected":"en","key_concepts":{"key_phrases":["A Cyber Insurance Policy","Hedging","Load","arXiv250404287v4 Announce Type","Abstract","Uncertainties","renewable energy resources","RES","load variations","elevated system operational costs"],"filter_categories":{"ai_ml":["Uncertainties"],"renewable_energy":["renewable energy resources"],"healthcare_tech":["RES"],"research_academic":["RES"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Cyber Insurance Policy":2.0,"Hedging":2.0,"Load":2.0,"arXiv250404287v4 Announce Type":1.0,"Abstract":1.0,"Uncertainties":1.0,"renewable energy resources":1.0,"RES":1.0,"load variations":1.0,"elevated system operational costs":1.0}},"age_hours":2.7465873663888885,"is_recent":true,"quality_score":1.0,"sentiment_score":0.8034999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8393,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6902,"joy":0.0074,"surprise":0.0102,"sadness":0.0198,"fear":0.209,"anger":0.0484,"disgust":0.0149},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a cyber insurance framework to hedge against operational costs from load-altering attacks in renewable-rich grids. It uses VaR and TVaR risk metrics and a bi-level optimization scheme. The effectiveness is evaluated using modified IEEE test systems, but there is no real-world deployment data, making it vaporware.","key_impact_metrics":["Relatively low premium","Additional operational costs caused by malicious load manipulations"],"technology_tags":["Cyber insurance","Renewable energy grid security","Load-altering attack mitigation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:41:44.363179Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dd240fca79ba","title":"A Customized SAT","content":"arXiv:2504.04821v2 Announce Type: replace Abstract: We introduce ZykovColor, a novel SAT-based algorithm to solve the graph coloring problem working on top of an encoding that mimics the Zykov tree. Our method is based on an approach of H\\'ebrard and Katsirelos (2020) that employs a propagator to enforce transitivity constraints, incorporate lower bounds for search tree pruning, and enable inferred propagations. We leverage the recently introduced IPASIR-UP interface for CaDiCaL to implement these techniques with a SAT solver. Furthermore, we propose new features that take advantage of the underlying SAT solver. These include modifying the integrated decision strategy with vertex domination hints and using incremental bottom-up search that allows to reuse learned clauses from previous calls. Additionally, we integrate a more effective clique computation and an algorithm for computing the fractional chromatic number to improve the lower bounds used for pruning during the search. We validate the effectiveness of each new feature through an experimental analysis. ZykovColor outperforms other state-of-the-art graph coloring implementations on the DIMACS benchmark set. Further experiments on random Erd\\H{o}s-R\\'enyi graphs show that our new approach matches or outperforms state-of-the-art SAT-based methods for both very sparse and highly dense graphs. We give an additional configuration of ZykovColor that dominates other SAT-based methods on the Erd\\H{o}s-R\\'enyi graphs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.04821","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.548231","language":"en","tags":["preprints","csai","csdm","computer-science","research","csds","cslo","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Timo Brand, Daniel Faber, Stephan Held, Petra Mutzel","raw_content_length":1495,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["SAT","ZykovColor"],"persons":["Zykov","Katsirelos"],"locations":[],"monetary":[]},"char_count":1490,"language_detected":"en","key_concepts":{"key_phrases":["A Customized SAT","Announce Type","Abstract","ZykovColor","a novel SAT-based algorithm","the graph coloring problem","top","an encoding","the Zykov tree","Our method"],"filter_categories":{"business_innovation":["ZykovColor"],"ai_ml":["a novel SAT-based algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Customized SAT":2.0,"Announce Type":1.0,"Abstract":1.0,"ZykovColor":1.0,"a novel SAT-based algorithm":1.0,"the graph coloring problem":1.0,"top":1.0,"an encoding":1.0,"the Zykov tree":1.0,"Our method":1.0}},"age_hours":2.746602125,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8913,"joy":0.0241,"surprise":0.0648,"sadness":0.0035,"fear":0.0025,"anger":0.0099,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel SAT-based algorithm (ZykovColor) for solving the graph coloring problem, which has potential applications in optimizing resource allocation and scheduling, indirectly impacting energy efficiency. The algorithm's effectiveness is validated through experimental analysis on benchmark datasets, demonstrating improved performance compared to state-of-the-art methods. However, it is still in the applied research stage with no deployed units or real-world applications mentioned, limiting its immediate sustainability impact.","key_impact_metrics":["Outperforms other state-of-the-art graph coloring implementations on the DIMACS benchmark set","Matches or outperforms state-of-the-art SAT-based methods on Erdős-Rényi graphs"],"technology_tags":["SAT solver","Graph coloring algorithm","Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:41:47.311434Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_35b6bea0d57d","title":"Who cares about testing?: Co","content":"arXiv:2504.07208v2 Announce Type: replace Abstract: Software testing is crucial for ensuring software quality, yet developers' engagement with it varies widely. Identifying the technical, organizational and social factors that lead to differences in engagement is required to remove barriers and utilize enablers for testing. While much research emphasizes the usefulness of testing strategies and technical solutions, less is known about why developers do (not) test. This study investigates the lived experience of software developers to illuminate how their opinions about testing change. Learning about personal evolutions of practice, we explore when and why testing is used. Employing socio-technical grounded theory (STGT), we construct a theory by systematically analyzing data from 19 in-depth, semi-structured interviews with software developers. Allowing interviewees to reflect on how and why they approach software testing, we explore perspectives that are rooted in their contextual experiences. We develop eleven categories of circumstances that act as conditions for the application and adaptation of testing practices and introduce three concepts that we then use to present our theory of emerging testing strategies (ETS) that explains why developers do (not) use testing practices. This study reveals a new perspective on the connection between testing artifacts and collective reflection of practitioners, and it embraces testing as an experience in which human- and social aspects are entangled with organizational and technical circumstances.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.07208","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.549052","language":"en","tags":["preprints","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Mark Swillus, Rashina Hoda, Andy Zaidman","raw_content_length":1565,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Software"],"persons":[],"locations":[],"monetary":[]},"char_count":1564,"language_detected":"en","key_concepts":{"key_phrases":["testing","Who","arXiv250407208v2 Announce Type","Abstract","Software testing","software quality","developers engagement","the technical organizational and social factors","differences","engagement"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"testing":3.0,"Who":2.0,"arXiv250407208v2 Announce Type":1.0,"Abstract":1.0,"Software testing":1.0,"software quality":1.0,"developers engagement":1.0,"the technical organizational and social factors":1.0,"differences":1.0,"engagement":1.0}},"age_hours":2.7466317852777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.593,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9186,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9135,"joy":0.0042,"surprise":0.0521,"sadness":0.0094,"fear":0.0033,"anger":0.0105,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":1,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores developer engagement with software testing and its impact on software quality. While improved software quality can indirectly contribute to sustainability (e.g., more efficient resource use), the article doesn't present any concrete actions or measurable outcomes related to climate change, environmental protection, or social equity. The research is in the early stages, focusing on understanding developer behavior rather than deploying specific technologies or solutions.","key_impact_metrics":[],"technology_tags":["Software Testing","Software Development"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:41:50.199210Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0d3d702d47ad","title":"AgentAda: Skill","content":"arXiv:2504.07421v3 Announce Type: replace Abstract: We introduce AgentAda, the first LLM-powered analytics agent that can learn and use new analytics skills to extract more specialized insights. Unlike existing methods that require users to manually decide which data analytics method to apply, AgentAda automatically identifies the skill needed from a library of analytical skills to perform the analysis. This also allows AgentAda to use skills that existing LLMs cannot perform out of the box. The library covers a range of methods, including clustering, predictive modeling, and NLP techniques like BERT, which allow AgentAda to handle complex analytics tasks based on what the user needs. AgentAda's dataset-to-insight extraction strategy consists of three key steps: (I) a question generator to generate queries relevant to the user's goal and persona, (II) a hybrid Retrieval-Augmented Generation (RAG)-based skill matcher to choose the best data analytics skill from the skill library, and (III) a code generator that produces executable code based on the retrieved skill's documentation to extract key patterns. We also introduce KaggleBench, a benchmark of curated notebooks across diverse domains, to evaluate AgentAda's performance. We conducted a human evaluation demonstrating that AgentAda provides more insightful analytics than existing tools, with 48.78% of evaluators preferring its analyses, compared to 27.67% for the unskilled agent. We also propose a novel LLM-as-a-judge approach that we show is aligned with human evaluation as a way to automate insight quality evaluation at larger scale.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.07421","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.550777","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Amirhossein Abaskohi, Amrutha Varshini Ramesh, Shailesh Nanisetty, Chirag Goel, David Vazquez, Christopher Pal, Spandana Gella, Giuseppe Carenini, Issam H. Laradji","raw_content_length":1615,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["Retrieval-Augmented Generation","AgentAda","NLP","BERT"],"persons":["Skill arXiv:2504.07421v3 Announce Type"],"locations":[],"monetary":[]},"char_count":1614,"language_detected":"en","key_concepts":{"key_phrases":["AgentAda","AgentAda Skill","arXiv250407421v3 Announce Type","Abstract","the first LLM-powered analytics agent","new analytics skills","more specialized insights","existing methods","users","which data analytics method"],"filter_categories":{"ai_ml":["the first LLM-powered analytics agent"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AgentAda":3.0,"AgentAda Skill":2.0,"arXiv250407421v3 Announce Type":1.0,"Abstract":1.0,"the first LLM-powered analytics agent":1.0,"new analytics skills":1.0,"more specialized insights":1.0,"existing methods":1.0,"users":1.0,"which data analytics method":1.0}},"age_hours":2.7466626416666666,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8518,"joy":0.0321,"surprise":0.0979,"sadness":0.0047,"fear":0.0035,"anger":0.0081,"disgust":0.002},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"AgentAda is an LLM-powered analytics agent that can learn and use new analytics skills. The article mentions a human evaluation where 48.78% of evaluators preferred its analyses, compared to 27.67% for the unskilled agent, providing some evidence. However, it is still in the prototype stage and lacks real-world deployment data.","key_impact_metrics":["48.78% evaluator preference","27.67% unskilled agent preference"],"technology_tags":["LLM","Data Analytics","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:41:53.474738Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ed07ee549f5e","title":"DSM: Constructing a Diverse Semantic Map for 3D Visual Grounding","content":"arXiv:2504.08307v2 Announce Type: replace Abstract: Effective scene representation is critical for the visual grounding ability of representations, yet existing methods for 3D Visual Grounding are often constrained. They either only focus on geometric and visual cues, or, like traditional 3D scene graphs, lack the multi-dimensional attributes needed for complex reasoning. To bridge this gap, we introduce the Diverse Semantic Map (DSM) framework, a novel scene representation framework that enriches robust geometric models with a spectrum of VLM-derived semantics, including appearance, physical properties, and affordances. The DSM is first constructed online by fusing multi-view observations within a temporal sliding window, creating a persistent and comprehensive world model. Building on this foundation, we propose DSM-Grounding, a new paradigm that shifts grounding from free-form VLM queries to a structured reasoning process over the semantic-rich map, markedly improving accuracy and interpretability. Extensive evaluations validate our approach's superiority. On the ScanRefer benchmark, DSM-Grounding achieves a state-of-the-art 59.06% overall accuracy of IoU@0.5, surpassing others by 10%. In semantic segmentation, our DSM attains a 67.93% F-mIoU, outperforming all baselines, including privileged ones. Furthermore, successful deployment on physical robots for complex navigation and grasping tasks confirms the framework's practical utility in real-world scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.08307","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.551205","language":"en","tags":["preprints","computer-science","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Qinghongbing Xie, Zijian Liang, Fuhao Li, Long Zeng","raw_content_length":1487,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["DSM","VLM","DSM-Grounding"],"persons":[],"locations":[],"monetary":[]},"char_count":1486,"language_detected":"en","key_concepts":{"key_phrases":["3D Visual Grounding","DSM","a Diverse Semantic Map","arXiv250408307v2 Announce Type","Abstract","Effective scene representation","the visual grounding ability","representations","existing methods","geometric and visual cues"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"3D Visual Grounding":3.0,"DSM":2.0,"a Diverse Semantic Map":2.0,"arXiv250408307v2 Announce Type":1.0,"Abstract":1.0,"Effective scene representation":1.0,"the visual grounding ability":1.0,"representations":1.0,"existing methods":1.0,"geometric and visual cues":1.0}},"age_hours":2.7466777644444442,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9362,"joy":0.0043,"surprise":0.0261,"sadness":0.0084,"fear":0.0081,"anger":0.0106,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a novel scene representation framework (DSM) that improves accuracy in visual grounding and semantic segmentation. It reports a state-of-the-art 59.06% overall accuracy of IoU@0.5 on the ScanRefer benchmark and a 67.93% F-mIoU in semantic segmentation. The framework has been deployed on physical robots for navigation and grasping, demonstrating real-world utility, but the economic viability and climate impact are not directly addressed.","key_impact_metrics":["59.06% overall accuracy of IoU@0.5","67.93% F-mIoU"],"technology_tags":["3D Visual Grounding","Semantic Segmentation","Robotics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:41:56.852749Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e008353b462e","title":"A Hybrid ABM","content":"arXiv:2504.08430v2 Announce Type: replace Abstract: This paper presents a hybrid modeling approach that couples an Agent-Based Model (ABM) with a partial differential equation (PDE) model in an epidemic setting to simulate the spatial spread of infectious diseases using a compartmental structure with seven health states. The goal is to reduce the computational complexity of a full-ABM by introducing a coupled ABM-PDE model that offers significantly faster simulations while maintaining comparable accuracy. Our results demonstrate that the hybrid model not only reduces the overall simulation runtime (defined as the number of runs required for stable results multiplied by the duration of a single run) but also achieves smaller errors across both 25% and 100% population samples. The coupling mechanism ensures consistency at the model interface: agents crossing from the ABM into the PDE domain are removed and represented as density contributions, while surplus density in the PDE domain is used to generate agents with plausible trajectories derived from mobile phone data. We evaluate the hybrid model using real-world mobility and infection data for the Berlin-Brandenburg region in Germany, showing that it captures the core epidemiological dynamics while enabling efficient large-scale simulations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.08430","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.551632","language":"en","tags":["preprints","computer-science","research","q-biope","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Kristina Maier, Tim O. F. Conrad","raw_content_length":1312,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["PDE","ABM"],"persons":[],"locations":[],"monetary":[]},"char_count":1311,"language_detected":"en","key_concepts":{"key_phrases":["A Hybrid ABM","arXiv250408430v2 Announce Type","Abstract","This paper","a hybrid modeling approach","an Agent-Based Model ABM","a partial differential equation","PDE model","an epidemic setting","the spatial spread"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Hybrid ABM":2.0,"arXiv250408430v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"a hybrid modeling approach":1.0,"an Agent-Based Model ABM":1.0,"a partial differential equation":1.0,"PDE model":1.0,"an epidemic setting":1.0,"the spatial spread":1.0}},"age_hours":2.7466928622222224,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8246,"joy":0.072,"surprise":0.0767,"sadness":0.006,"fear":0.0043,"anger":0.0124,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a hybrid modeling approach (ABM-PDE) for simulating infectious disease spread, aiming to reduce computational complexity. The concrete action is the development and validation of this model using real-world data from Berlin-Brandenburg. Evidence includes demonstrated reduction in simulation runtime and error rates compared to a full-ABM. It is currently in the applied research stage, validated with real-world data but not yet deployed for real-time decision-making.","key_impact_metrics":["Simulation runtime reduction","Error reduction across 25% and 100% population samples"],"technology_tags":["Agent-Based Modeling","Partial Differential Equations","Epidemiological Modeling"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:42:00.268476Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_df878adbd66b","title":"MooseAgent: A LLM Based Multi","content":"arXiv:2504.08621v2 Announce Type: replace Abstract: The Finite Element Method (FEM) is widely used in engineering and scientific computing, but its pre-processing, solver configuration, and post-processing stages are often time-consuming and require specialized knowledge. This paper proposes an automated solution framework, MooseAgent, for the multi-physics simulation framework MOOSE, which combines large-scale pre-trained language models (LLMs) with a multi-agent system. The framework uses LLMs to understand user-described simulation requirements in natural language and employs task decomposition and multi-round iterative verification strategies to automatically generate MOOSE input files. To improve accuracy and reduce model hallucinations, the system builds and utilizes a vector database containing annotated MOOSE input cards and function documentation. We conducted experimental evaluations on several typical cases, including heat transfer, mechanics, phase field, and multi-physics coupling. The results show that MooseAgent can automate the MOOSE simulation process to a certain extent, especially demonstrating a high success rate when dealing with relatively simple single-physics problems. The main contribution of this research is the proposal of a multi-agent automated framework for MOOSE, which validates its potential in simplifying finite element simulation processes and lowering the user barrier, providing new ideas for the development of intelligent finite element simulation software. The code for the MooseAgent framework proposed in this paper has been open-sourced and is available at https://github.com/taozhan18/MooseAgent","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.08621","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.552063","language":"en","tags":["preprints","computer-science","csse","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Tao Zhang, Zhenhai Liu, Yong Xin, Yongjun Jiao","raw_content_length":1661,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1660,"language_detected":"en","key_concepts":{"key_phrases":["MooseAgent","A LLM Based Multi","LLMs","Announce Type","Abstract","The Finite Element Method","FEM","engineering and scientific computing","its pre-processing solver configuration","post-processing stages"],"filter_categories":{"ai_ml":["A LLM Based Multi"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MooseAgent":3.0,"A LLM Based Multi":2.0,"LLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"The Finite Element Method":1.0,"FEM":1.0,"engineering and scientific computing":1.0,"its pre-processing solver configuration":1.0,"post-processing stages":1.0}},"age_hours":2.746708475277778,"is_recent":true,"quality_score":0.7,"sentiment_score":7.2485,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4497,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8682,"joy":0.0052,"surprise":0.0167,"sadness":0.0104,"fear":0.0482,"anger":0.0291,"disgust":0.0222},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a multi-agent system (MooseAgent) that automates the MOOSE simulation process, which could potentially accelerate the development and optimization of sustainable technologies simulated using MOOSE. However, the impact is theoretical at this stage, with experimental evaluations on typical cases but no real-world deployment. The open-sourced code and demonstrated success in simplifying simulations provide some evidence of its potential.","key_impact_metrics":["High success rate for simple single-physics problems"],"technology_tags":["Finite Element Method","Multi-agent system","Large Language Models","Simulation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:42:03.330677Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2537b41d8c6f","title":"Generative Deep Learning Framework for Inverse Design of Fuels","content":"arXiv:2504.12075v3 Announce Type: replace Abstract: In the present work, a generative deep learning framework combining a Co-optimized Variational Autoencoder (Co-VAE) architecture with quantitative structure-property relationship (QSPR) techniques is developed to enable accelerated inverse design of fuels. The Co-VAE integrates a property prediction component coupled with the VAE latent space, enhancing molecular reconstruction and accurate estimation of Research Octane Number (RON) (chosen as the fuel property of interest). A subset of the GDB-13 database, enriched with a curated RON database, is used for model training. Hyperparameter tuning is further utilized to optimize the balance among reconstruction fidelity, chemical validity, and RON prediction. An independent regression model is then used to refine RON prediction, while a differential evolution algorithm is employed to efficiently navigate the VAE latent space and identify promising fuel molecule candidates with high RON. This methodology addresses the limitations of traditional fuel screening approaches by capturing complex structure-property relationships within a comprehensive latent representation. The generative model can be adapted to different target properties, enabling systematic exploration of large chemical spaces relevant to fuel design applications. Furthermore, the demonstrated framework can be readily extended by incorporating additional synthesizability criteria to improve applicability and reliability for de novo design of new fuels.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12075","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.552469","language":"en","tags":["preprints","computer-science","cslg","research","physicschem-ph","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Kiran K. Yalamanchi, Pinaki Pal, Balaji Mohan, Abdullah S. AlRamadan, Jihad A. Badra, Yuanjiang Pei","raw_content_length":1538,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["RON","VAE","QSPR","Variational Autoencoder (Co-VAE"],"persons":["RON"],"locations":[],"monetary":[]},"char_count":1537,"language_detected":"en","key_concepts":{"key_phrases":["Generative Deep Learning Framework","Inverse Design","Fuels","VAE","arXiv250412075v3","Announce Type","Abstract","the present work","a generative deep learning framework","quantitative structure-property relationship"],"filter_categories":{"ai_ml":["Generative Deep Learning Framework","a generative deep learning framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative Deep Learning Framework":2.0,"Inverse Design":2.0,"Fuels":2.0,"VAE":2.0,"arXiv250412075v3":1.0,"Announce Type":1.0,"Abstract":1.0,"the present work":1.0,"a generative deep learning framework":1.0,"quantitative structure-property relationship":1.0}},"age_hours":2.7467232886111113,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.833,"joy":0.0594,"surprise":0.0709,"sadness":0.005,"fear":0.0092,"anger":0.0157,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a deep learning framework for designing fuels with high Research Octane Number (RON). While it uses a curated database and optimizes for RON prediction, it remains at the applied research stage with no deployed technology or measured real-world outcomes. The potential climate impact is theoretical, as the actual emissions reduction depends on the properties of the fuels designed and their lifecycle emissions.","key_impact_metrics":["RON prediction accuracy","Chemical validity of generated molecules"],"technology_tags":["Generative Deep Learning","Variational Autoencoder","Fuel Design","Inverse Design"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:42:07.167113Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_984aec749aae","title":"Cottontail: Large Language Model","content":"arXiv:2504.17542v2 Announce Type: replace Abstract: How can we perform concolic execution to generate highly structured test inputs for systematically testing parsing programs? Existing concolic execution engines are significantly restricted by (1) input structure-agnostic path constraint selection, leading to the waste of testing effort or missing coverage; (2) limited constraint-solving capability, yielding many syntactically invalid test inputs; (3) reliance on manual acquisition of highly structured seed inputs, resulting in non-continuous testing. This paper proposes Cottontail, a new Large Language Model (LLM)-driven concolic execution engine, to mitigate the above limitations. A more complete program path representation, named Expressive Structural Coverage Tree (ESCT), is first constructed to select structure-aware path constraints. Later, an LLM-driven constraint solver based on a Solve-Complete paradigm is designed to solve the path constraints smartly to get test inputs that are not only satisfiable to the constraints but also valid to the input syntax. Finally, a history-guided seed acquisition is employed to obtain new highly structured test inputs either before testing starts or after testing is saturated. We implemented Cottontail on top of SymCC and evaluated eight extensively tested open-source libraries across four different formats (XML, SQL, JavaScript, and JSON). Cottontail significantly outperforms baseline approaches by 30.73% and 41.32% on average in terms of line and branch coverage. Besides, Cottontail found six previously unknown vulnerabilities (six CVEs assigned). We have reported these issues to developers, and four out of them have been fixed so far.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.17542","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.554487","language":"en","tags":["preprints","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Haoxin Tu, Seongmin Lee, Yuxian Li, Peng Chen, Lingxiao Jiang, Marcel B\\\"ohme","raw_content_length":1714,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["Solve-Complete","Expressive Structural Coverage Tree"],"persons":["Cottontail"],"locations":["Cottontail"],"monetary":[]},"char_count":1709,"language_detected":"en","key_concepts":{"key_phrases":["Cottontail Large Language Model","arXiv250417542v2","Announce Type","Abstract","concolic execution","highly structured test inputs","systematically testing parsing programs","Existing concolic execution engines","1 input structure-agnostic path constraint selection","the waste"],"filter_categories":{"ai_ml":["Cottontail Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cottontail Large Language Model":2.0,"arXiv250417542v2":1.0,"Announce Type":1.0,"Abstract":1.0,"concolic execution":1.0,"highly structured test inputs":1.0,"systematically testing parsing programs":1.0,"Existing concolic execution engines":1.0,"1 input structure-agnostic path constraint selection":1.0,"the waste":1.0}},"age_hours":2.746793362777778,"is_recent":true,"quality_score":1.0,"sentiment_score":0.912,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8176,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7919,"joy":0.006,"surprise":0.0754,"sadness":0.0426,"fear":0.0198,"anger":0.0413,"disgust":0.0229},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new LLM-driven concolic execution engine, Cottontail, for testing parsing programs. While it shows significant improvements in line and branch coverage (30.73% and 41.32% on average), and found six previously unknown vulnerabilities, it's still in the applied research stage and lacks real-world deployment data. The climate impact is indirect, potentially improving the reliability of software used in sustainable applications, but not directly reducing emissions.","key_impact_metrics":["30.73% improvement in line coverage","41.32% improvement in branch coverage"],"technology_tags":["Large Language Model","Concolic Execution","Software Testing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:10.810218Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c9b2e96df138","title":"Newton","content":"arXiv:2504.19176v2 Announce Type: replace Abstract: Complex-valued neural networks (CVNNs) are particularly suitable for handling phase-sensitive signals, including electrocardiography (ECG), radar/sonar, and wireless in-phase/quadrature (I/Q) streams. Nevertheless, their \\emph{interpretability} and \\emph{probability calibration} remain insufficiently investigated. In this work, we present a Newton--Puiseux framework that examines the \\emph{local decision geometry} of a trained CVNN by (i) fitting a small, kink-aware polynomial surrogate to the \\emph{logit difference} in the vicinity of uncertain inputs, and (ii) factorizing this surrogate using Newton--Puiseux expansions to derive analytic branch descriptors, including exponents, multiplicities, and orientations. These descriptors provide phase-aligned directions that induce class flips in the original network and allow for a straightforward, \\emph{multiplicity-guided} temperature adjustment for improved calibration. We outline assumptions and diagnostic measures under which the surrogate proves informative and characterize potential failure modes arising from piecewise-holomorphic activations (e.g., modReLU). Our phase-aware analysis identifies sensitive directions and enhances Expected Calibration Error in two case studies beyond a controlled $\\C^2$ synthetic benchmark -- namely, the MIT--BIH arrhythmia (ECG) dataset and RadioML 2016.10a (wireless modulation) -- when compared to uncalibrated softmax and standard post-hoc baselines. We also present confidence intervals, non-parametric tests, and quantify sensitivity to inaccuracies in estimating branch multiplicity. Crucially, this method requires no modifications to the architecture and applies to any CVNN with complex logits transformed to real moduli.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.19176","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.554919","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Piotr Migus","raw_content_length":1787,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["\\emph{logit","ECG","Newton"],"persons":["CVNN"],"locations":["Newton"],"monetary":[]},"char_count":1786,"language_detected":"en","key_concepts":{"key_phrases":["Newton","arXiv250419176v2 Announce Type","Abstract","CVNNs","phase-sensitive signals","electrocardiography","ECG","radarsonar","phase","their emphinterpretability"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Newton":2.0,"arXiv250419176v2 Announce Type":1.0,"Abstract":1.0,"CVNNs":1.0,"phase-sensitive signals":1.0,"electrocardiography":1.0,"ECG":1.0,"radarsonar":1.0,"phase":1.0,"their emphinterpretability":1.0}},"age_hours":2.7468086591666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8872,"joy":0.0249,"surprise":0.0493,"sadness":0.0129,"fear":0.0074,"anger":0.0116,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for improving the interpretability and calibration of complex-valued neural networks, which could potentially be applied to phase-sensitive signals relevant to sustainability (e.g., wireless modulation for energy efficiency). The method is validated on datasets like RadioML, showing improved calibration error, but it is still in the research phase with no deployed applications or economic viability demonstrated. The impact on climate change is indirect and depends on the downstream applications of this improved neural network technology.","key_impact_metrics":["Expected Calibration Error improvement","Sensitivity to inaccuracies in estimating branch multiplicity"],"technology_tags":["Complex-valued neural networks","Machine learning","Signal processing"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:42:14.151041Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5aebc24e7949","title":"GPA","content":"arXiv:2504.19683v2 Announce Type: replace Abstract: Most existing robot manipulation methods prioritize task learning by enhancing perception through complex deep network architectures. However, they face challenges in real-time collision-free planning. Hence, Robotic Attention Mamba (RAM) is designed for refined planning. Specifically, by integrating Mamba and parallel single-view attention, RAM aligns multi-view vision and task-related language features, ensuring efficient fine-grained task planning with linear complexity and robust real-time performance. Nevertheless, it has the potential for further improvement in high-precision grasping and manipulation. Thus, Grasp-Pretraining Augmentation (GPA) is devised, with a grasp pose feature extractor pretrained utilizing object grasp poses directly inherited from whole-task demonstrations. Subsequently, the extracted grasp features are fused with the spatially aligned planning features from RAM through attention-based Pre-trained Location Fusion, preserving high-resolution grasping cues overshadowed by an overemphasis on global planning. To summarize, we propose Grasp-Pretraining Augmented Robotic Attention Mamba (GPA-RAM), dividing spatial task learning into RAM for planning skill learning and GPA for grasping skill learning. GPA-RAM demonstrates superior performance across three robot systems with distinct camera configurations in simulation and the real world. Compared with previous state-of-the-art methods, it improves the absolute success rate by 8.2% (from 79.3% to 87.5%) on the RLBench multi-task benchmark and 40% (from 16% to 56%), 12% (from 86% to 98%) on the ALOHA bimanual manipulation tasks, while delivering notably faster inference. Furthermore, experimental results demonstrate that both RAM and GPA enhance task learning, with GPA proving robust to different architectures of pretrained grasp pose feature extractors. The project is https://logssim.github.io/GPA_RAM_website/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.19683","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.560727","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Juyi Sheng, Yangjun Liu, Sheng Xu, Zhixin Yang, Mengyuan Liu","raw_content_length":1967,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["RAM","GPA arXiv:2504.19683v2 Announce Type","Mamba","GPA"],"persons":["Loc"],"locations":[],"monetary":[]},"char_count":1966,"language_detected":"en","key_concepts":{"key_phrases":["GPA","Announce Type","Abstract","Most existing robot manipulation methods","task","perception","complex deep network","challenges","real-time collision-free planning","Robotic Attention Mamba"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GPA":2.0,"Announce Type":1.0,"Abstract":1.0,"Most existing robot manipulation methods":1.0,"task":1.0,"perception":1.0,"complex deep network":1.0,"challenges":1.0,"real-time collision-free planning":1.0,"Robotic Attention Mamba":1.0}},"age_hours":2.7468231088888886,"is_recent":true,"quality_score":0.7,"sentiment_score":7.885,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.577,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8934,"joy":0.0066,"surprise":0.0123,"sadness":0.0047,"fear":0.0482,"anger":0.0238,"disgust":0.011},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel robotic manipulation method (GPA-RAM) that improves task success rates in simulation and real-world environments. The concrete action is the development and testing of this new algorithm. The evidence supporting claims includes improved success rates on benchmarks, but it is still in the early stages of deployment, with no mention of commercial applications.","key_impact_metrics":["success rate improvement on RLBench by 8.2%","success rate improvement on ALOHA by 40%"],"technology_tags":["robotics","machine learning","grasping","manipulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:17.689153Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b1c10b8f55ae","title":"The Distribution of Dependency Distance and Hierarchical Distance in Contemporary Written Japanese and Its Influencing Factors","content":"arXiv:2504.21421v2 Announce Type: replace Abstract: To explore the relationship between dependency distance (DD) and hierarchical distance (HD) in Japanese, we compared the probability distributions of DD and HD with and without sentence length fixed, and analyzed the changes in mean dependency distance (MDD) and mean hierarchical distance (MHD) as sentence length increases, along with their correlation coefficient based on the Balanced Corpus of Contemporary Written Japanese. It was found that the valency of the predicates is the underlying factor behind the trade-off relation between MDD and MHD in Japanese. Native speakers of Japanese regulate the linear complexity and hierarchical complexity through the valency of the predicates, and the relative sizes of MDD and MHD depend on whether the threshold of valency has been reached. Apart from the cognitive load, the valency of the predicates also affects the probability distributions of DD and HD. The effect of the valency of the predicates on the distribution of HD is greater than on that of DD, which leads to differences in their probability distributions and causes the mean of MDD to be lower than that of MHD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.21421","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.561172","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Linxuan Wang, Shuiyuan Yu","raw_content_length":1181,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["MDD","the Balanced Corpus of Contemporary Written Japanese","MHD"],"persons":[],"locations":[],"monetary":[]},"char_count":1180,"language_detected":"en","key_concepts":{"key_phrases":["Contemporary Written Japanese","The Distribution","Dependency Distance","Hierarchical Distance","Its Influencing Factors","hierarchical distance","Announce Type","Abstract","the relationship","dependency distance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contemporary Written Japanese":3.0,"The Distribution":2.0,"Dependency Distance":2.0,"Hierarchical Distance":2.0,"Its Influencing Factors":2.0,"hierarchical distance":2.0,"Announce Type":1.0,"Abstract":1.0,"the relationship":1.0,"dependency distance":1.0}},"age_hours":2.746837693611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1005,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0201,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.852,"joy":0.0088,"surprise":0.0287,"sadness":0.0073,"fear":0.0423,"anger":0.0331,"disgust":0.0279},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":4,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article analyzes linguistic structures in Japanese text. While interesting from a cognitive science perspective, it has no direct or measurable impact on climate change, sustainability, or any related environmental issues. The research is at a basic research stage with no deployment or commercialization potential related to sustainability.","key_impact_metrics":["MDD","MHD"],"technology_tags":["Natural Language Processing","Linguistics"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:42:21.056102Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_54a7fd5c6919","title":"PSN Game: Game","content":"arXiv:2505.00213v2 Announce Type: replace Abstract: While game-theoretic planning frameworks are effective at modeling multi-agent interactions, they require solving large optimization problems where the number of variables increases with the number of agents, resulting in long computation times that limit their use in large-scale, real-time systems. To address this issue, we propose 1) PSN Game: a learning-based, game-theoretic prediction and planning framework that reduces runtime by learning a Player Selection Network (PSN); and 2) a Goal Inference Network (GIN) that makes it possible to use the PSN in incomplete information games where agents' intentions are unknown. A PSN outputs a player selection mask that distinguishes influential players from less relevant ones, enabling the ego player to solve a smaller, masked game involving only selected players. By reducing the number of players in the game, and therefore reducing the number of variables in the corresponding optimization problem, PSN directly lowers computation time. The PSN Game framework is more flexible than existing player selection methods as it 1) relies solely on observations of players' past trajectories, without requiring full state, action, or other game-specific information; and 2) requires no online parameter tuning. Experiments in both simulated scenarios and human trajectory datasets demonstrate that PSNs outperform baseline selection methods in 1) prediction accuracy; and 2) planning safety. PSNs also generalize effectively to real-world scenarios in which agents' objectives are unknown without fine-tuning. By selecting only the most relevant players for decision-making, PSN Game offers a general mechanism for reducing planning complexity that can be seamlessly integrated into existing multi-agent planning frameworks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.00213","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.561644","language":"en","tags":["preprints","computer-science","mathoc","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":257,"author":"Tianyu Qiu, Eric Ouano, Fernando Palafox, Christian Ellis, David Fridovich-Keil","raw_content_length":1827,"priority":7,"update_frequency":1,"reading_time_minutes":1.285,"robust_parsing_used":true,"entities":{"organizations":["Goal Inference Network","PSN"],"persons":[],"locations":[],"monetary":[]},"char_count":1826,"language_detected":"en","key_concepts":{"key_phrases":["PSN Game","Game","the number","Announce Type","Abstract","game-theoretic planning frameworks","multi-agent interactions","large optimization problems","variables","agents"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PSN Game":3.0,"Game":2.0,"the number":2.0,"Announce Type":1.0,"Abstract":1.0,"game-theoretic planning frameworks":1.0,"multi-agent interactions":1.0,"large optimization problems":1.0,"variables":1.0,"agents":1.0}},"age_hours":2.7468525716666665,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9231,"joy":0.0091,"surprise":0.0251,"sadness":0.0132,"fear":0.0084,"anger":0.0152,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a learning-based framework (PSN Game) that reduces computation time in multi-agent planning. While it shows promise in simulated scenarios and human trajectory datasets, it's still in the early stages of development with no real-world deployments mentioned. The reduction in computation time could potentially lead to more efficient systems, but the climate impact is indirect and not quantified.","key_impact_metrics":["prediction accuracy","planning safety"],"technology_tags":["game theory","machine learning","multi-agent systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:24.161678Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d274e3534017","title":"Adaptive DRL for IRS Mirror Orientation in Dynamic OWC Networks","content":"arXiv:2505.01818v2 Announce Type: replace Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a promising solution to mitigate line-of-sight (LoS) blockages and enhance signal coverage in optical wireless communication (OWC) systems with minimal additional power. In this work, we consider a mirror-based IRS to assist a dynamic indoor visible light communication (VLC) environment. We formulate an optimization problem that aims to maximize the sum rate by adjusting the orientation of the IRS mirrors. To enable real-time adaptability, the problem is modelled as a Markov decision process (MDP), and a deep reinforcement learning (DRL) algorithm is developed based on the deterministic policy gradient for real-time mirror-based IRS optimization in dynamic VLC networks. The proposed DRL is employed to optimize mirror orientation toward mobile users under blockage and mobility constraints. Simulation results demonstrate that our proposed DRL algorithm outperforms the conventional deep Q- learning (DQL) algorithm and achieves substantial improvements in sum rate compared to random-orientation IRS configurations","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.01818","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.562052","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Ahrar N. Hamad, Ahmad Adnan Qidan, Taisir E. H. El-Gorashi, Jaafar M. H. Elmirghani","raw_content_length":1132,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["OWC","Adaptive DRL","IRS Mirror Orientation in Dynamic OWC Networks","LoS","IRS","VLC","DRL","MDP"],"persons":["Markov"],"locations":[],"monetary":[]},"char_count":1131,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive DRL","IRS Mirror Orientation","Dynamic OWC Networks","Announce Type","Abstract","Intelligent reflecting surfaces","IRSs","a promising solution","sight","signal coverage"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive DRL":2.0,"IRS Mirror Orientation":2.0,"Dynamic OWC Networks":2.0,"Announce Type":1.0,"Abstract":1.0,"Intelligent reflecting surfaces":1.0,"IRSs":1.0,"a promising solution":1.0,"sight":1.0,"signal coverage":1.0}},"age_hours":2.7468677519444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.511000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9022,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9143,"joy":0.0215,"surprise":0.03,"sadness":0.0049,"fear":0.0103,"anger":0.0151,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a DRL algorithm to optimize IRS mirror orientation in VLC networks. While it shows improved sum rate in simulations compared to other methods, it's still in the early stages of development with no real-world deployments or independent verification. The impact on climate is indirect, potentially reducing energy consumption for communication, but not quantified.","key_impact_metrics":["substantial improvements in sum rate compared to random-orientation IRS configurations"],"technology_tags":["Intelligent Reflecting Surfaces","Optical Wireless Communication","Deep Reinforcement Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:26.957439Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e15fb4aea3d4","title":"Visual Affordance Prediction: Survey and Reproducibility","content":"arXiv:2505.05074v2 Announce Type: replace Abstract: Affordances are the potential actions an agent can perform on an object, as observed by a camera. Visual affordance prediction is formulated differently for tasks such as grasping detection, affordance classification, affordance segmentation, and hand pose estimation. This diversity in formulations leads to inconsistent definitions that prevent fair comparisons between methods. In this paper, we propose a unified formulation of visual affordance prediction by accounting for the complete information on the objects of interest and the interaction of the agent with the objects to accomplish a task. This unified formulation allows us to comprehensively and systematically review disparate visual affordance works, highlighting strengths and limitations of both methods and datasets. We also discuss reproducibility issues, such as the unavailability of methods implementation and experimental setups details, making benchmarks for visual affordance prediction unfair and unreliable. To favour transparency, we introduce the Affordance Sheet, a document that details the solution, datasets, and validation of a method, supporting future reproducibility and fairness in the community.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.05074","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.562449","language":"en","tags":["preprints","computer-science","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Tommaso Apicella, Alessio Xompero, Andrea Cavallaro","raw_content_length":1239,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1238,"language_detected":"en","key_concepts":{"key_phrases":["Visual Affordance Prediction","Survey","Reproducibility","arXiv250505074v2","Announce Type","Abstract","Affordances","the potential actions","an agent","an object"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Visual Affordance Prediction":2.0,"Survey":2.0,"Reproducibility":2.0,"arXiv250505074v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Affordances":1.0,"the potential actions":1.0,"an agent":1.0,"an object":1.0}},"age_hours":2.7468815897222223,"is_recent":true,"quality_score":0.7,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.906,"joy":0.0127,"surprise":0.0259,"sadness":0.0083,"fear":0.0179,"anger":0.0222,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper proposes a unified formulation for visual affordance prediction to improve reproducibility and fairness in the field. While the research aims to improve the methodology of AI, it does not directly address a specific climate or sustainability challenge. The focus is on improving the research process itself, not on deploying a technology with measurable environmental outcomes.","key_impact_metrics":[],"technology_tags":["computer vision","artificial intelligence","affordance prediction"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:42:30.934451Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b11d4c3eaba7","title":"Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results","content":"arXiv:2505.08685v2 Announce Type: replace Abstract: Deep learning (DL) has become the dominant approach for medical image segmentation, yet ensuring the reliability and clinical applicability of these models requires addressing key challenges such as annotation variability, calibration, and uncertainty estimation. This is why we created the Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS), which highlights the critical role of multiple annotators in establishing a more comprehensive ground truth, emphasizing that segmentation is inherently subjective and that leveraging inter-annotator variability is essential for robust model evaluation. Seven teams participated in the challenge, submitting a variety of DL models evaluated using metrics such as Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and Continuous Ranked Probability Score (CRPS). By incorporating consensus and dissensus ground truth, we assess how DL models handle uncertainty and whether their confidence estimates align with true segmentation performance. Our findings reinforce the importance of well-calibrated models, as better calibration is strongly correlated with the quality of the results. Furthermore, we demonstrate that segmentation models trained on diverse datasets and enriched with pre-trained knowledge exhibit greater robustness, particularly in cases deviating from standard anatomical structures. Notably, the best-performing models achieved high DSC and well-calibrated uncertainty estimates. This work underscores the need for multi-annotator ground truth, thorough calibration assessments, and uncertainty-aware evaluations to develop trustworthy and clinically reliable DL-based medical image segmentation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.08685","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.563314","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick, Andrea Prenner, Cedric Hemon, Valentin Boussot, Jean-Louis Dillenseger, Jean-Claude Nunes, Abdul Qayyum, Moona Mazher, Steven A Niederer, Kaisar Kushibar, Carlos Martin-Isla, Petia Radeva, Karim Lekadir, Theodore Barfoot, Luis C. Garcia Peraza Herrera, Ben Glocker, Tom Vercauteren, Lucas Gago, Justin Englemann, Joy-Marie Kleiss, Anton Aubanell, Andreu Antolin, Javier Garcia-Lopez, Miguel A. Gonzalez Ballester, Adrian Galdran","raw_content_length":1782,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["the Calibration and Uncertainty for multiRater Volume Assessment","ECE","DSC","Expected Calibration Error","Dice Similarity Coefficient","CURVAS"],"persons":[],"locations":[],"monetary":[]},"char_count":1781,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty","multiRater Volume Assessment","CURVAS","Calibration","arXiv250508685v2 Announce Type","Abstract","Deep learning","the dominant approach","medical image segmentation","the reliability and clinical applicability"],"filter_categories":{"ai_ml":["Uncertainty","Deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty":3.0,"multiRater Volume Assessment":3.0,"CURVAS":3.0,"Calibration":2.0,"arXiv250508685v2 Announce Type":1.0,"Abstract":1.0,"Deep learning":1.0,"the dominant approach":1.0,"medical image segmentation":1.0,"the reliability and clinical applicability":1.0}},"age_hours":2.7469096072222223,"is_recent":true,"quality_score":1.0,"sentiment_score":1.408,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7184,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6806,"joy":0.0075,"surprise":0.0153,"sadness":0.0122,"fear":0.2564,"anger":0.0194,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the reliability of medical image segmentation using deep learning, specifically addressing annotation variability and uncertainty. While it doesn't directly impact climate change, it improves the accuracy of medical diagnoses, which can indirectly improve resource allocation in healthcare. The research is in the applied research stage, with metrics like Dice Similarity Coefficient (DSC) and Expected Calibration Error (ECE) used for evaluation.","key_impact_metrics":["Dice Similarity Coefficient (DSC)","Expected Calibration Error (ECE)"],"technology_tags":["Deep Learning","Medical Image Segmentation"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:42:34.041217Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_70a9bf3f52f9","title":"Variational Rank Reduction Autoencoders","content":"arXiv:2505.09458v2 Announce Type: replace Abstract: Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a regularization on the latent space by applying a truncated SVD. While this regularization makes Autoencoders more powerful, using them for generative purposes is counter-intuitive due to their deterministic nature. On the other hand, Variational Autoencoders (VAEs) are well known for their generative abilities by learning a probabilistic latent space. In this paper, we present Variational Rank Reduction Autoencoders (VRRAEs), a model that leverages the advantages of both RRAEs and VAEs. Our claims and results show that when carefully sampling the latent space of RRAEs and further regularizing with the Kullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs and VAEs. Additionally, we show that the regularization induced by the SVD not only makes VRRAEs better generators than VAEs, but also reduces the possibility of posterior collapse. Our results include a synthetic dataset of a small size that showcases the robustness of VRRAEs against collapse, and three real-world datasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to outperform both VAEs and RRAEs on many random generation and interpolation tasks based on the FID score. We developed an open-source implementation of VRRAEs in JAX (Equinox), available at https://github.com/JadM133/RRAEs.git.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.09458","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.563745","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Jad Mounayer, Alicia Tierz, Jerome Tomezyk, Chady Ghnatios, Francisco Chinesta","raw_content_length":1433,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Variational Rank Reduction Autoencoders","VRRAEs outperform RRAEs","SVD","RRAEs","the Kullback-Leibler"],"persons":["Variational Autoencoders"],"locations":[],"monetary":[]},"char_count":1432,"language_detected":"en","key_concepts":{"key_phrases":["Variational Rank Reduction Autoencoders","Announce Type","Abstract","RRAEs","construction","a regularization","the latent space","a truncated SVD","this regularization","Autoencoders"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Variational Rank Reduction Autoencoders":2.0,"Announce Type":1.0,"Abstract":1.0,"RRAEs":1.0,"construction":1.0,"a regularization":1.0,"the latent space":1.0,"a truncated SVD":1.0,"this regularization":1.0,"Autoencoders":1.0}},"age_hours":2.746924102222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2765,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8553,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.751,"joy":0.0091,"surprise":0.0549,"sadness":0.0101,"fear":0.0239,"anger":0.079,"disgust":0.0721},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning model (VRRAE) and demonstrates its performance on image datasets. While the model itself doesn't directly address climate change, improved generative models could potentially contribute to sustainability efforts in the future by optimizing resource use or designing more efficient systems. The current stage is applied research with a publicly available implementation, but no real-world deployment or economic viability is demonstrated.","key_impact_metrics":["FID score on MNIST, CelebA, and CIFAR-10 datasets"],"technology_tags":["Variational Autoencoders","Rank Reduction Autoencoders","Machine Learning","Generative Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:42:37.272482Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ea95b211f623","title":"Creativity or Brute Force? Using Brainteasers as a Window into the Problem","content":"arXiv:2505.10844v3 Announce Type: replace Abstract: Accuracy remains a standard metric for evaluating AI systems, but it offers limited insight into how models arrive at their solutions. In this work, we introduce a benchmark based on brainteasers written in long narrative form to probe more deeply into the types of reasoning strategies that models use. Brainteasers are well-suited for this goal because they can be solved with multiple approaches, such as a few-step solution that uses a creative insight or a longer solution that uses more brute force. We investigate large language models (LLMs) across multiple layers of reasoning, focusing not only on correctness but also on the quality and creativity of their solutions. We investigate many aspects of the reasoning process: (1) semantic parsing of the brainteasers into precise mathematical competition style formats; (2) generating solutions from these mathematical forms; (3) self-correcting solutions based on gold solutions; (4) producing step-by-step sketches of solutions; and (5) making use of hints. We find that LLMs are in many cases able to find creative, insightful solutions to brainteasers, suggesting that they capture some of the capacities needed to solve novel problems in creative ways. Nonetheless, there also remain situations where they rely on brute force despite the availability of more efficient, creative solutions, highlighting a potential direction for improvement in the reasoning abilities of LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.10844","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.564611","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Simeng Han, Howard Dai, Stephen Xia, Grant Zhang, Chen Liu, Lichang Chen, Hoang Huy Nguyen, Hongyuan Mei, Jiayuan Mao, R. Thomas McCoy","raw_content_length":1491,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["Brute Force"],"persons":["Accuracy"],"locations":[],"monetary":[]},"char_count":1490,"language_detected":"en","key_concepts":{"key_phrases":["Brainteasers","Creativity","Brute Force","a Window","the Problem","Announce Type","Abstract","Accuracy","AI systems","limited insight"],"filter_categories":{"ai_ml":["Brainteasers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Brainteasers":3.0,"Creativity":2.0,"Brute Force":2.0,"a Window":2.0,"the Problem":2.0,"Announce Type":1.0,"Abstract":1.0,"Accuracy":1.0,"AI systems":1.0,"limited insight":1.0}},"age_hours":2.746953873611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9426,"joy":0.007,"surprise":0.032,"sadness":0.0023,"fear":0.003,"anger":0.008,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on using brainteasers to evaluate the reasoning capabilities of large language models (LLMs). While the research is technically sound and potentially innovative, it's at a very early stage and doesn't have any direct, measurable impact on sustainability at this point. The work is focused on improving AI reasoning, which *could* indirectly contribute to sustainability if applied to climate modeling or optimization of resource use, but this is speculative.","key_impact_metrics":[],"technology_tags":["large language models","artificial intelligence","reasoning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:40.706007Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b6c20289fde1","title":"Time Travel is Cheating: Going Live with DeepFund for Real","content":"arXiv:2505.11065v2 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated notable capabilities across financial tasks, including financial report summarization, earnings call transcript analysis, and asset classification. However, their real-world effectiveness in managing complex fund investment remains inadequately assessed. A fundamental limitation of existing benchmarks for evaluating LLM-driven trading strategies is their reliance on historical back-testing, inadvertently enabling LLMs to \"time travel\"-leveraging future information embedded in their training corpora, thus resulting in possible information leakage and overly optimistic performance estimates. To address this issue, we introduce DeepFund, a live fund benchmark tool designed to rigorously evaluate LLM in real-time market conditions. Utilizing a multi-agent architecture, DeepFund connects directly with real-time stock market data-specifically data published after each model pretraining cutoff-to ensure fair and leakage-free evaluations. Empirical tests on nine flagship LLMs from leading global institutions across multiple investment dimensions-including ticker-level analysis, investment decision-making, portfolio management, and risk control-reveal significant practical challenges. Notably, even cutting-edge models such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses within DeepFund real-time evaluation environment, underscoring the present limitations of LLMs for active fund management. Our code is available at https://github.com/HKUSTDial/DeepFund.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11065","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.565037","language":"en","tags":["csce","preprints","csai","computer-science","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Changlun Li, Yao Shi, Chen Wang, Qiqi Duan, Runke Ruan, Weijie Huang, Haonan Long, Lijun Huang, Nan Tang, Yuyu Luo","raw_content_length":1582,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["LLM","Time Travel"],"persons":[],"locations":[],"monetary":[]},"char_count":1581,"language_detected":"en","key_concepts":{"key_phrases":["Time Travel","DeepFund","arXiv250511065v2 Announce Type","Large Language Models","LLMs","notable capabilities","financial tasks","financial report summarization","earnings call transcript analysis","asset classification"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Time Travel":2.0,"DeepFund":2.0,"arXiv250511065v2 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"notable capabilities":1.0,"financial tasks":1.0,"financial report summarization":1.0,"earnings call transcript analysis":1.0,"asset classification":1.0}},"age_hours":2.746968319722222,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7570000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6486,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9004,"joy":0.0074,"surprise":0.0191,"sadness":0.0184,"fear":0.0195,"anger":0.022,"disgust":0.0131},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article introduces DeepFund, a live fund benchmark tool for evaluating LLMs in real-time market conditions. While it identifies limitations of LLMs in active fund management, it doesn't directly address climate change or environmental sustainability. The code is available, suggesting a pilot deployment stage.","key_impact_metrics":["Net trading losses within DeepFund real-time evaluation environment"],"technology_tags":["Large Language Models","Financial Modeling"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:42:43.819027Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_85b759b113e1","title":"Aux-Think: Exploring Reasoning Strategies for Data","content":"arXiv:2505.11886v4 Announce Type: replace Abstract: Vision-Language Navigation (VLN) is a critical task for developing embodied agents that can follow natural language instructions to navigate in complex real-world environments. Recent advances in VLN by large pretrained models have significantly improved generalization and instruction grounding compared to traditional approaches. However, the role of reasoning strategies in navigation-an action-centric, long-horizon task-remains underexplored, despite Chain-of-Thought (CoT) reasoning's demonstrated success in static tasks like visual question answering. To address this gap, we conduct the first systematic evaluation of reasoning strategies for VLN, including No-Think (direct action prediction), Pre-Think (reason before action), and Post-Think (reason after action). Surprisingly, our findings reveal the Inference-time Reasoning Collapse issue, where inference-time reasoning degrades navigation accuracy, highlighting the challenges of integrating reasoning into VLN. Based on this insight, we propose Aux-Think, a framework that trains models to internalize structured reasoning patterns through CoT supervision, while inferring action directly without reasoning in online prediction. To support this framework, we release R2R-CoT-320k, the first Chain-of-Thought annotated dataset for VLN. Extensive experiments show that Aux-Think reduces training effort greatly and achieves the best performance under the same data scale.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11886","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.565448","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Shuo Wang, Yongcai Wang, Wanting Li, Xudong Cai, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Deying Li, Zhaoxin Fan","raw_content_length":1490,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Post-Think","Collapse","CoT","VLN","Inference","Pre-Think"],"persons":[],"locations":[],"monetary":[]},"char_count":1489,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning Strategies","Data","VLN","arXiv250511886v4 Announce Type","Abstract","Vision-Language Navigation","a critical task","embodied agents","natural language instructions","complex real-world environments"],"filter_categories":{"ai_ml":["Data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning Strategies":2.0,"Data":2.0,"VLN":2.0,"arXiv250511886v4 Announce Type":1.0,"Abstract":1.0,"Vision-Language Navigation":1.0,"a critical task":1.0,"embodied agents":1.0,"natural language instructions":1.0,"complex real-world environments":1.0}},"age_hours":2.746983658888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9057,"joy":0.0185,"surprise":0.0379,"sadness":0.0077,"fear":0.0162,"anger":0.0094,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores reasoning strategies for Vision-Language Navigation (VLN) and proposes a new framework, Aux-Think, to improve navigation accuracy. The concrete action is the development of a new dataset (R2R-CoT-320k) and a framework for training models. The evidence is based on experiments showing improved performance, but it's still in the research phase with no deployed units or real-world validation.","key_impact_metrics":["Navigation accuracy","Training effort reduction"],"technology_tags":["Vision-Language Navigation","Chain-of-Thought Reasoning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:46.978701Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_08b3afdc38e0","title":"APC waivers and Ukraine's publishing output in Gold OA journals: Evidence from five commercial publishers","content":"arXiv:2505.12134v3 Announce Type: replace Abstract: This study examines the effect of article processing charge (APC) waivers on the participation of Ukrainian researchers in fully Gold Open Access (Gold OA) journals published by the five largest academic publishers - Elsevier, SAGE, Springer Nature, Taylor & Francis, and Wiley - during the period 2019-2024. These publishers were selected because, in response to the full-scale war launched against Ukraine in 2022, all five introduced emergency 100% APC-waiver policies for Ukrainian authors. Using bibliometric data from the Web of Science Core Collection, the study analyses publication trends in Ukrainian-authored articles in fully Gold OA journals of these publishers before and after 2022. The results show a marked post-2022 increase in Ukraine's Gold OA output, particularly in journals published by Springer Nature and Elsevier. Disciplinary and publisher-specific patterns are evident, with especially strong growth in the medical and applied sciences. The findings underscore the potential of targeted support measures during times of crisis, while also illustrating the inherent limitations of APC-based publishing models in fostering equitable scholarly communication.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12134","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.571058","language":"en","tags":["preprints","computer-science","csdl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Serhii Nazarovets","raw_content_length":1236,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["APC","Gold OA"],"persons":["Wiley","Springer Nature"],"locations":["Ukrainian","Ukraine"],"monetary":[]},"char_count":1235,"language_detected":"en","key_concepts":{"key_phrases":["APC waivers","Ukraines publishing output","Gold OA journals","Evidence","five commercial publishers","arXiv250512134v3 Announce Type","Abstract","This study","the effect","article processing charge"],"filter_categories":{"ai_ml":["APC waivers"],"research_academic":["Gold OA journals","This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"APC waivers":2.0,"Ukraines publishing output":2.0,"Gold OA journals":2.0,"Evidence":2.0,"five commercial publishers":2.0,"arXiv250512134v3 Announce Type":1.0,"Abstract":1.0,"This study":1.0,"the effect":1.0,"article processing charge":1.0}},"age_hours":2.7469995583333335,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7987,"joy":0.0769,"surprise":0.0638,"sadness":0.011,"fear":0.0097,"anger":0.0319,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"impact_measurement","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":4,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The study analyzes publication trends of Ukrainian researchers in Gold OA journals before and after the introduction of APC waivers. The concrete action is the implementation of APC waivers by major publishers, and the measurable outcome is the increase in Ukrainian-authored articles in these journals. The study uses bibliometric data from Web of Science, providing evidence for the observed trends.","key_impact_metrics":["Post-2022 increase in Ukraine's Gold OA output","100% APC-waiver policies for Ukrainian authors"],"technology_tags":["Open Access Publishing","Academic Research"],"sdg_alignment":[4,10,16],"analyzed_at":"2025-10-29T16:42:50.084985Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ca3b3d0794d3","title":"MTIL: Encoding Full History with Mamba for Temporal Imitation Learning","content":"arXiv:2505.12410v2 Announce Type: replace Abstract: Standard imitation learning (IL) methods have achieved considerable success in robotics, yet often rely on the Markov assumption, which falters in long-horizon tasks where history is crucial for resolving perceptual ambiguity. This limitation stems not only from a conceptual gap but also from a fundamental computational barrier: prevailing architectures like Transformers are often constrained by quadratic complexity, rendering the processing of long, high-dimensional observation sequences infeasible. To overcome this dual challenge, we introduce Mamba Temporal Imitation Learning (MTIL). Our approach represents a new paradigm for robotic learning, which we frame as a practical synthesis of World Model and Dynamical System concepts. By leveraging the linear-time recurrent dynamics of State Space Models (SSMs), MTIL learns an implicit, action-oriented world model that efficiently encodes the entire trajectory history into a compressed, evolving state. This allows the policy to be conditioned on a comprehensive temporal context, transcending the confines of Markovian approaches. Through extensive experiments on simulated benchmarks (ACT, Robomimic, LIBERO) and on challenging real-world tasks, MTIL demonstrates superior performance against SOTA methods like ACT and Diffusion Policy, particularly in resolving long-term temporal ambiguities. Our findings not only affirm the necessity of full temporal context but also validate MTIL as a powerful and a computationally feasible approach for learning long-horizon, non-Markovian behaviors from high-dimensional observations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12410","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.571507","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Yulin Zhou, Yuankai Lin, Fanzhe Peng, Jiahui Chen, Kaiji Huang, Hua Yang, Zhouping Yin","raw_content_length":1641,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["Mamba for Temporal Imitation Learning arXiv:2505.12410v2","World Model","Mamba Temporal Imitation Learning","State Space Models","MTIL","Dynamical System"],"persons":["Markov"],"locations":[],"monetary":[]},"char_count":1640,"language_detected":"en","key_concepts":{"key_phrases":["MTIL","Full History","Mamba","Temporal Imitation Learning","arXiv250512410v2 Announce Type","Abstract","Standard imitation learning IL methods","considerable success","robotics","the Markov assumption"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MTIL":2.0,"Full History":2.0,"Mamba":2.0,"Temporal Imitation Learning":2.0,"arXiv250512410v2 Announce Type":1.0,"Abstract":1.0,"Standard imitation learning IL methods":1.0,"considerable success":1.0,"robotics":1.0,"the Markov assumption":1.0}},"age_hours":2.747014187777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.0915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6183,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5412,"joy":0.0043,"surprise":0.0522,"sadness":0.1776,"fear":0.1379,"anger":0.0427,"disgust":0.0442},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (MTIL) to imitation learning for robotics, showing superior performance in simulated benchmarks. While the technology addresses a computational barrier and demonstrates potential for improved efficiency in robotic tasks, its direct climate impact is currently limited and theoretical. The technology is still in the applied research stage, with no real-world deployments mentioned.","key_impact_metrics":["Superior performance against SOTA methods in simulated benchmarks"],"technology_tags":["Imitation Learning","Robotics","State Space Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:53.209771Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ebc9cbb71798","title":"VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine","content":"arXiv:2505.12434v4 Announce Type: replace Abstract: Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VideoRFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VideoRFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a multi-expert-driven, cognition-inspired CoT curation pipeline. First, we devise a cognition-inspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a MLLM conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets, i.e.VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strengthen the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning and visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VideoRFT achieves state-of-the-art performance on six video reasoning benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12434","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.572514","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":247,"author":"Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou","raw_content_length":1827,"priority":7,"update_frequency":1,"reading_time_minutes":1.235,"robust_parsing_used":true,"entities":{"organizations":["RFT","CoT","Large Language Models","Reinforced Fine arXiv:2505.12434v4 Announce Type","SFT"],"persons":["VideoRFT"],"locations":[],"monetary":[]},"char_count":1826,"language_detected":"en","key_concepts":{"key_phrases":["VideoRFT","MLLMs","Incentivizing Video Reasoning Capability","Reinforced Fine","arXiv250512434v4 Announce Type","Abstract","Reinforcement","fine-tuning RFT","great promise","humanlevel reasoning capabilities"],"filter_categories":{"ai_ml":["MLLMs","Reinforcement"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VideoRFT":3.0,"MLLMs":3.0,"Incentivizing Video Reasoning Capability":2.0,"Reinforced Fine":2.0,"arXiv250512434v4 Announce Type":1.0,"Abstract":1.0,"Reinforcement":1.0,"fine-tuning RFT":1.0,"great promise":1.0,"humanlevel reasoning capabilities":1.0}},"age_hours":2.7470419355555555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.455,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.891,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9303,"joy":0.0141,"surprise":0.0233,"sadness":0.0038,"fear":0.0082,"anger":0.0138,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (VideoRFT) to improve video reasoning capabilities in MLLMs using reinforcement learning. The concrete action is the creation of two new datasets (VideoRFT-CoT-102K and VideoRFT-RL-310K) and a semantic-consistency reward. The evidence supporting the claims is based on experiments showing state-of-the-art performance on six video reasoning benchmarks, but it remains at the applied research stage with no real-world deployment.","key_impact_metrics":["State-of-the-art performance on six video reasoning benchmarks"],"technology_tags":["Reinforcement Learning","Large Language Models","Video Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:42:56.636939Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_648e88f1854f","title":"Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning","content":"arXiv:2505.12477v2 Announce Type: replace Abstract: Reconstruction and joint embedding have emerged as two leading paradigms in Self Supervised Learning (SSL). Reconstruction methods focus on recovering the original sample from a different view in input space. On the other hand, joint embedding methods align the representations of different views in latent space. Both approaches offer compelling advantages, yet practitioners lack clear guidelines for choosing between them. In this work, we unveil the core mechanisms that distinguish each paradigm. By leveraging closed form solutions for both approaches, we precisely characterize how the view generation process, e.g. data augmentation, impacts the learned representations. We then demonstrate that, unlike supervised learning, both SSL paradigms require a minimal alignment between augmentations and irrelevant features to achieve asymptotic optimality with increasing sample size. Our findings indicate that in scenarios where these irrelevant features have a large magnitude, joint embedding methods are preferable because they impose a strictly weaker alignment condition compared to reconstruction based methods. These results not only clarify the trade offs between the two paradigms but also substantiate the empirical success of joint embedding approaches on real world challenging datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12477","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.572971","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Hugues Van Assel, Mark Ibrahim, Tommaso Biancalani, Aviv Regev, Randall Balestriero","raw_content_length":1357,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["SSL","Joint Embedding vs Reconstruction"],"persons":[],"locations":[],"monetary":[]},"char_count":1356,"language_detected":"en","key_concepts":{"key_phrases":["Reconstruction","Self Supervised Learning","Joint","Provable Benefits","Latent Space Prediction","arXiv250512477v2 Announce Type","Abstract","two leading paradigms","SSL","Reconstruction methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reconstruction":3.0,"Self Supervised Learning":3.0,"Joint":2.0,"Provable Benefits":2.0,"Latent Space Prediction":2.0,"arXiv250512477v2 Announce Type":1.0,"Abstract":1.0,"two leading paradigms":1.0,"SSL":1.0,"Reconstruction methods":1.0}},"age_hours":2.7470563080555555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.200999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9404,"joy":0.0206,"surprise":0.0151,"sadness":0.004,"fear":0.0065,"anger":0.0085,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents theoretical research on self-supervised learning methods. While the research is technically credible and innovative, it is at an early stage with no deployed technology or measured outcomes related to climate impact. The potential for climate impact is indirect and depends on future applications of the research.","key_impact_metrics":[],"technology_tags":["self-supervised learning","machine learning","data augmentation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:42:59.531201Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cff48b2275a1","title":"Panda: A pretrained forecast model for chaotic dynamics","content":"arXiv:2505.13755v2 Announce Type: replace Abstract: Chaotic systems are intrinsically sensitive to small errors, challenging efforts to construct predictive data-driven models of real-world dynamical systems such as fluid flows or neuronal activity. Prior efforts comprise either specialized models trained separately on individual time series, or foundation models trained on vast time series databases with little underlying dynamical structure. Motivated by dynamical systems theory, we present Panda, Patched Attention for Nonlinear Dynamics. We train Panda on a novel synthetic, extensible dataset of $2 \\times 10^4$ chaotic dynamical systems that we discover using an evolutionary algorithm. Trained purely on simulated data, Panda exhibits emergent properties: zero-shot forecasting of unseen chaotic systems preserving both short-term accuracy and long-term statistics. Despite having been trained only on low-dimensional ordinary differential equations, Panda spontaneously develops the ability to predict partial differential equations without retraining. We also demonstrate a neural scaling law for differential equations, underscoring the potential of pretrained models for probing abstract mathematical domains like nonlinear dynamics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13755","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.573810","language":"en","tags":["preprints","csne","statml","computer-science","cslg","research","nlincd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Jeffrey Lai, Anthony Bao, William Gilpin","raw_content_length":1250,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Panda"],"persons":["Panda"],"locations":[],"monetary":[]},"char_count":1249,"language_detected":"en","key_concepts":{"key_phrases":["Panda","A pretrained forecast model","chaotic dynamics","arXiv250513755v2 Announce Type","Chaotic systems","small errors","efforts","predictive data-driven models","real-world dynamical systems","fluid flows"],"filter_categories":{"ai_ml":["A pretrained forecast model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Panda":2.0,"A pretrained forecast model":2.0,"chaotic dynamics":2.0,"arXiv250513755v2 Announce Type":1.0,"Chaotic systems":1.0,"small errors":1.0,"efforts":1.0,"predictive data-driven models":1.0,"real-world dynamical systems":1.0,"fluid flows":1.0}},"age_hours":2.747084666944444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.7254999999999994,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4549,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8394,"joy":0.0171,"surprise":0.0875,"sadness":0.0084,"fear":0.0235,"anger":0.0201,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel forecasting model (Panda) trained on simulated chaotic systems. While the model shows emergent properties like predicting partial differential equations without retraining, it's currently in the research phase with no real-world deployment or quantified impact on climate change. The potential for sustainability impact is theoretical, as it could potentially improve modeling of climate systems, but there are no concrete actions or measurable outcomes yet.","key_impact_metrics":[],"technology_tags":["machine learning","forecasting","dynamical systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:02.692838Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f13a6c4da5ac","title":"AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole","content":"arXiv:2505.15058v2 Announce Type: replace Abstract: Whole-body audio-driven avatar pose and expression generation is a critical task for creating lifelike digital humans and enhancing the capabilities of interactive virtual agents, with wide-ranging applications in virtual reality, digital entertainment, and remote communication. Existing approaches often generate audio-driven facial expressions and gestures independently, which introduces a significant limitation: the lack of seamless coordination between facial and gestural elements, resulting in less natural and cohesive animations. To address this limitation, we propose AsynFusion, a novel framework that leverages diffusion transformers to achieve harmonious expression and gesture synthesis. The proposed method is built upon a dual-branch DiT architecture, which enables the parallel generation of facial expressions and gestures. Within the model, we introduce a Cooperative Synchronization Module to facilitate bidirectional feature interaction between the two modalities, and an Asynchronous LCM Sampling strategy to reduce computational overhead while maintaining high-quality outputs. Extensive experiments demonstrate that AsynFusion achieves state-of-the-art performance in generating real-time, synchronized whole-body animations, consistently outperforming existing methods in both quantitative and qualitative evaluations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15058","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.574224","language":"en","tags":["preprints","csai","computer-science","eessas","research","cssd","csgr","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, Zhaoxin Fan, Wenjun Wu, Xuelong Li","raw_content_length":1398,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["AsynFusion","DiT"],"persons":[],"locations":[],"monetary":[]},"char_count":1397,"language_detected":"en","key_concepts":{"key_phrases":["AsynFusion","Asynchronous Latent Consistency Models","Decoupled Whole","Announce Type","Abstract","Whole-body audio-driven avatar pose","expression generation","a critical task","lifelike digital humans","the capabilities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"AsynFusion":2.0,"Asynchronous Latent Consistency Models":2.0,"Decoupled Whole":2.0,"Announce Type":1.0,"Abstract":1.0,"Whole-body audio-driven avatar pose":1.0,"expression generation":1.0,"a critical task":1.0,"lifelike digital humans":1.0,"the capabilities":1.0}},"age_hours":2.7470985166666666,"is_recent":true,"quality_score":1.0,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8894,"joy":0.0279,"surprise":0.0461,"sadness":0.0044,"fear":0.013,"anger":0.014,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for generating realistic digital avatars. While it demonstrates improved performance in animation quality, it lacks concrete actions or measurable outcomes related to environmental sustainability. The technology is at the applied research stage, with no evidence of deployment or economic viability.","key_impact_metrics":["Real-time animation generation","Improved synchronization of facial expressions and gestures"],"technology_tags":["AI","Diffusion Transformers","Avatar Generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:05.462482Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e74a7e8d24cc","title":"Modelling the Spread of New Information on Social Networks","content":"arXiv:2505.15370v3 Announce Type: replace Abstract: There has been considerable interest in modelling the spread of information on social networks using machine learning models. Here, we consider the problem of predicting the spread of new information, i.e. when a user propagates information about a topic previously unseen by the user. In existing work, information and users are randomly assigned to a test or training set, ensuring that both sets are drawn from the same distribution. In the spread of new information, the problem becomes an out-of-distribution generalisation classification task. Our experimental results reveal that while existing algorithms, which predominantly use features derived from the content of messages, perform well when the training and test distributions are the same, these algorithms perform much worse when the test set is out-of-distribution, i.e. when the topic (hashtag) of the testing data is absent from the training data. We then show that if the message features are supplemented or replaced with features derived from users' profile and past behaviour, the out-of-distribution prediction is greatly improved, with the F1 score increasing from 0.117 to 0.705. Our experimental results suggest that a significant component of reposting behaviour for previously unseen topics can be predicted from users' profile and past behaviour, and is largely content-agnostic.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15370","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.574657","language":"en","tags":["preprints","cssi","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Ziming Xu, Shi Zhou, Vasileios Lampos, Ingemar J. Cox","raw_content_length":1410,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["the Spread of New Information on Social Networks arXiv:2505.15370v3"],"persons":[],"locations":["absen"],"monetary":[]},"char_count":1409,"language_detected":"en","key_concepts":{"key_phrases":["information","the Spread","New Information","Social Networks","the spread","arXiv250515370v3","Announce Type","Abstract","considerable interest","social networks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"information":3.0,"the Spread":2.0,"New Information":2.0,"Social Networks":2.0,"the spread":2.0,"arXiv250515370v3":1.0,"Announce Type":1.0,"Abstract":1.0,"considerable interest":1.0,"social networks":1.0}},"age_hours":2.7471135041666663,"is_recent":true,"quality_score":1.0,"sentiment_score":7.0025,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4005,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8732,"joy":0.0284,"surprise":0.0527,"sadness":0.0052,"fear":0.0069,"anger":0.0217,"disgust":0.0119},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the prediction of information spread on social networks, specifically focusing on out-of-distribution generalization. The concrete action is the development and testing of a machine learning model. The evidence supporting claims is the reported increase in F1 score from 0.117 to 0.705 when using user profile and past behavior features. This is currently at the basic research stage.","key_impact_metrics":["F1 score increase from 0.117 to 0.705"],"technology_tags":["machine learning","social network analysis","information diffusion"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T16:43:08.596400Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1716d47cac84","title":"Highlighting What Matters: Promptable Embeddings for Attribute","content":"arXiv:2505.15877v2 Announce Type: replace Abstract: While an image is worth more than a thousand words, only a few provide crucial information for a given task and thus should be focused on. In light of this, ideal text-to-image (T2I) retrievers should prioritize specific visual attributes relevant to queries. To evaluate current retrievers on handling attribute-focused queries, we build COCO-Facet, a COCO-based benchmark with 9,112 queries about diverse attributes of interest. We find that CLIP-like retrievers, which are widely adopted due to their efficiency and zero-shot ability, have poor and imbalanced performance, possibly because their image embeddings focus on global semantics and subjects while leaving out other details. Notably, we reveal that even recent Multimodal Large Language Model (MLLM)-based, stronger retrievers with a larger output dimension struggle with this limitation. Hence, we hypothesize that retrieving with general image embeddings is suboptimal for performing such queries. As a solution, we propose to use promptable image embeddings enabled by these multimodal retrievers, which boost performance by highlighting required attributes. Our pipeline for deriving such embeddings generalizes across query types, image pools, and base retriever architectures. To enhance real-world applicability, we offer two acceleration strategies: Pre-processing promptable embeddings and using linear approximations. We show that the former yields a 15% improvement in Recall@5 when prompts are predefined, while the latter achieves an 8% improvement when prompts are only available during inference.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15877","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.575481","language":"en","tags":["preprints","computer-science","cslg","research","cscl","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Siting Li, Xiang Gao, Simon Shaolei Du","raw_content_length":1627,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["Attribute arXiv:2505.15877v2","CLIP"],"persons":[],"locations":[],"monetary":[]},"char_count":1626,"language_detected":"en","key_concepts":{"key_phrases":["What","Promptable Embeddings","Attribute","arXiv250515877v2","Announce Type","Abstract","an image","crucial information","a given task","light"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Promptable Embeddings":2.0,"Attribute":2.0,"arXiv250515877v2":1.0,"Announce Type":1.0,"Abstract":1.0,"an image":1.0,"crucial information":1.0,"a given task":1.0,"light":1.0}},"age_hours":2.7471449788888886,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9415,"joy":0.0061,"surprise":0.024,"sadness":0.0039,"fear":0.0042,"anger":0.0147,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for image retrieval that could potentially improve the efficiency of systems used for environmental monitoring or resource management. The concrete action is the development of a new benchmark dataset (COCO-Facet) and a promptable image embedding pipeline. The evidence is the reported 15% and 8% improvement in Recall@5 using the proposed acceleration strategies, but this is still in the research phase.","key_impact_metrics":["15% improvement in Recall@5","8% improvement in Recall@5"],"technology_tags":["image retrieval","machine learning","multimodal models"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T16:43:11.796340Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_01a9cff68d6c","title":"Steering Large Language Models for Machine Translation Personalization","content":"arXiv:2505.16612v2 Announce Type: replace Abstract: Large language models have simplified the production of personalized translations reflecting predefined stylistic constraints. However, these systems still struggle when stylistic requirements are implicitly represented by a set of examples, such as texts produced by a specific human translator. In this work, we explore various strategies for personalizing automatically generated translations when few examples are available, with a focus on the challenging domain of literary translation. We begin by determining the feasibility of the task and how style information is encoded within model representations. Then, we evaluate various prompting strategies and inference-time interventions for steering model generations towards a personalized style, with a particular focus on contrastive steering with sparse autoencoder (SAE) latents to identify salient personalization properties. We demonstrate that contrastive SAE steering yields robust style conditioning and translation quality, resulting in higher inference-time computational efficiency than prompting approaches. We further examine the impact of steering on model activations, finding that layers encoding personalization properties are impacted similarly by prompting and SAE steering, suggesting a similar mechanism at play.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16612","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.581064","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Daniel Scalena, Gabriele Sarti, Arianna Bisazza, Elisabetta Fersini, Malvina Nissim","raw_content_length":1343,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["SAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1342,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Machine Translation Personalization","arXiv250516612v2 Announce Type","Large language models","the production","personalized translations","predefined stylistic constraints","these systems","stylistic requirements","a set"],"filter_categories":{"ai_ml":["Large Language Models","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":2.0,"Machine Translation Personalization":2.0,"arXiv250516612v2 Announce Type":1.0,"Large language models":1.0,"the production":1.0,"personalized translations":1.0,"predefined stylistic constraints":1.0,"these systems":1.0,"stylistic requirements":1.0,"a set":1.0}},"age_hours":2.7471587333333334,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9377,"joy":0.0109,"surprise":0.0222,"sadness":0.0065,"fear":0.0095,"anger":0.0077,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes research into improving the efficiency of machine translation personalization using large language models. While improved efficiency in computation is mentioned, there are no concrete actions or measurable outcomes related to climate impact or sustainability. The technology is in an early stage of development (applied research) with no deployment.","key_impact_metrics":["Inference-time computational efficiency"],"technology_tags":["Large Language Models","Machine Translation","Sparse Autoencoders"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:43:14.902048Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_44643bcd61fb","title":"Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences (October 2025 -","content":"arXiv:2505.16619v2 Announce Type: replace Abstract: Artificial intelligence (AI) has recently seen transformative breakthroughs in the life sciences, expanding possibilities for researchers to interpret biological information at an unprecedented capacity, with novel applications and advances being made almost daily. In order to maximise return on the growing investments in AI-based life science research and accelerate this progress, it has become urgent to address the exacerbation of long-standing research challenges arising from the rapid adoption of AI methods. We review the increased erosion of trust in AI research outputs, driven by the issues of poor reusability and reproducibility, and highlight their consequent impact on environmental sustainability. Furthermore, we discuss the fragmented components of the AI ecosystem and lack of guiding pathways to best support Open and Sustainable AI (OSAI) model development. In response, this perspective introduces a practical set of OSAI recommendations directly mapped to over 300 components of the AI ecosystem. Our work connects researchers with relevant AI resources, facilitating the implementation of sustainable, reusable and transparent AI. Built upon life science community consensus and aligned to existing efforts, the outputs of this perspective are designed to aid the future development of policy and structured pathways for guiding AI implementation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16619","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.581517","language":"en","tags":["preprints","csai","computer-science","research","q-bioot","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Gavin Farrell (Department of Biomedical Sciences, University of Padova, Padova, Italy), Eleni Adamidi (Athena Research,Innovation Center, Marousi, Greece), Rafael Andrade Buono (VIB.AI Center for AI,Computational Biology, Ghent, Belgium), Mihail Anton (ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom), Omar Abdelghani Attafi (Department of Biomedical Sciences, University of Padova, Padova, Italy), Salvador Capella Gutierrez (Barcelona Supercomputing Center), Emidio Capriotti (Department of Pharmacy,Biotechnology, University of Bologna, Bologna, Italy,Computational Genomics Platform, IRCCS University Hospital of Bologna, Bologna, Italy), Leyla Jael Castro (ZB MED Information Centre for Life Sciences, Cologne, Germany), Davide Cirillo (Barcelona Supercomputing Center), Lisa Crossman (SequenceAnalysis.co.uk, United Kingdom,University of East Anglia, Norwich, United Kingdom), Christophe Dessimoz (Department of Computational Biology, University of Lausanne, Lausanne, Switzerland,Swiss Institute of Bioinformatics, Lausanne, Switzerland), Alexandros Dimopoulos (Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center Alexander Fleming, Vari, Greece,Department of Informatics,Telematics, School of Digital Technology, Harokopio University, Athens, Greece), Raul Fernandez-Diaz (School of Medicine, University College Dublin, Dublin, Ireland,Conway Institute of Biomolecular,Biomedical Research, University College Dublin, Dublin, Ireland,IBM Research Dublin, Dublin, Ireland), Styliani-Christina Fragkouli (Institute of Applied Biosciences, Centre for Research,Technology Hellas, Thessaloniki, Greece,Department of Biology, National,Kapodistrian University of Athens, Athens, Greece), Carole Goble (Department of Computer Science, University of Manchester, Manchester, United Kingdom), Wei Gu (Luxembourg National Data Service, Esch-sur-Alzette, Luxembourg), John M. Hancock (Institute of Biochemistry,Molecular Genetics, Faculty of Medicine, University of Ljubljana, Ljubljana, Slovenia), Alireza Khanteymoori (Department of Psychology, University of Freiburg, Freiburg, Germany), Tom Lenaerts (Machine Learning Group, Universite Libre de Bruxelles, Brussels, Belgium,Artificial Intelligence Lab, Vrije Universiteit Brussel, Brussels, Belgium,Interuniversity Institute of Bioinformatics in Brussels, ULB-VUB, Brussels, Belgium,FARI, AI for the common good institute, ULB-VUB, Brussels, Belgium,Center for Human-Compatible AI, UC Berkeley, Berkeley, CA, USA), Fabio G. Liberante (ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom), Peter Maccallum (ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom), Alexander Miguel Monzon (Department of Biomedical Sciences, University of Padova, Padova, Italy), Magnus Palmblad (Leiden University Medical Center, Leiden, Netherlands), Lucy Poveda (Swiss Institute of Bioinformatics, Lausanne, Switzerland), Ovidiu Radulescu (LPHI, University of Montpellier, CNRS, INSERM, Montpellier, France), Denis C. Shields (School of Medicine, University College Dublin, Dublin, Ireland,Conway Institute of Biomolecular,Biomedical Research, University College Dublin, Dublin, Ireland), Shoaib Sufi (Department of Computer Science, University of Manchester, Manchester, United Kingdom), Thanasis Vergoulis (Athena Research,Innovation Center, Marousi, Greece), Fotis Psomopoulos (Institute of Applied Biosciences, Centre for Research,Technology Hellas, Thessaloniki, Greece), Silvio C. E. Tosatto (Department of Biomedical Sciences, University of Padova, Padova, Italy,Institute of Biomembranes, Bioenergetics,Molecular Biotechnologies, National Research Council)","raw_content_length":1426,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1425,"language_detected":"en","key_concepts":{"key_phrases":["the life sciences","Open and Sustainable AI challenges","opportunities","the road","October","Announce Type","Abstract","Artificial intelligence","transformative breakthroughs","possibilities"],"filter_categories":{"research_academic":["the life sciences","transformative breakthroughs"],"ai_ml":["Open and Sustainable AI challenges","Artificial intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the life sciences":3.0,"Open and Sustainable AI challenges":2.0,"opportunities":2.0,"the road":2.0,"October":2.0,"Announce Type":1.0,"Abstract":1.0,"Artificial intelligence":1.0,"transformative breakthroughs":1.0,"possibilities":1.0}},"age_hours":2.747173529722222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.200999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6483,"joy":0.1575,"surprise":0.143,"sadness":0.0048,"fear":0.0238,"anger":0.0179,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article discusses a set of recommendations for Open and Sustainable AI (OSAI) in life sciences, aiming to improve reusability, reproducibility, and transparency. While it connects researchers to AI resources, it's still in the early stages of development with no concrete deployments or measurable outcomes. The impact on environmental sustainability is theoretical at this point.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Open Source","Sustainability"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T16:43:17.522293Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_09bea134f906","title":"Image Quality Assessment for Embodied AI","content":"arXiv:2505.16815v2 Announce Type: replace Abstract: Embodied AI has developed rapidly in recent years, but it is still mainly deployed in laboratories, with various distortions in the Real-world limiting its application. Traditionally, Image Quality Assessment (IQA) methods are applied to predict human preferences for distorted images; however, there is no IQA method to assess the usability of an image in embodied tasks, namely, the perceptual quality for robots. To provide accurate and reliable quality indicators for future embodied scenarios, we first propose the topic: IQA for Embodied AI. Specifically, we (1) based on the Mertonian system and meta-cognitive theory, constructed a perception-cognition-decision-execution pipeline and defined a comprehensive subjective score collection process; (2) established the Embodied-IQA database, containing over 36k reference/distorted image pairs, with more than 5m fine-grained annotations provided by Vision Language Models/Vision Language Action-models/Real-world robots; (3) trained and validated the performance of mainstream IQA methods on Embodied-IQA, demonstrating the need to develop more accurate quality indicators for Embodied AI. We sincerely hope that through evaluation, we can promote the application of Embodied AI under complex distortions in the Real-world. Project page: https://github.com/lcysyzxdxc/EmbodiedIQA","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16815","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.582415","language":"en","tags":["preprints","computer-science","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Chunyi Li, Jiaohao Xiao, Jianbo Zhang, Farong Wen, Zicheng Zhang, Yuan Tian, Xiangyang Zhu, Xiaohong Liu, Zhengxue Cheng, Weisi Lin, Guangtao Zhai","raw_content_length":1388,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Image Quality Assessment for Embodied AI arXiv:2505.16815v2 Announce Type","Image Quality Assessment","the Embodied-IQA"],"persons":[],"locations":[],"monetary":[]},"char_count":1387,"language_detected":"en","key_concepts":{"key_phrases":["Embodied AI","Image Quality Assessment","Announce Type","Abstract","recent years","laboratories","various distortions","the Real-world","its application","IQA"],"filter_categories":{"ai_ml":["Embodied AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Embodied AI":3.0,"Image Quality Assessment":2.0,"Announce Type":1.0,"Abstract":1.0,"recent years":1.0,"laboratories":1.0,"various distortions":1.0,"the Real-world":1.0,"its application":1.0,"IQA":1.0}},"age_hours":2.747203869722222,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2654999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7469,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.921,"joy":0.0056,"surprise":0.0365,"sadness":0.0085,"fear":0.006,"anger":0.0103,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new IQA database for embodied AI. While the research aims to improve the application of embodied AI in real-world scenarios, its direct impact on climate change is currently minimal. The database contains 36k image pairs and 5m annotations, but there is no deployment data or economic viability information.","key_impact_metrics":["36k image pairs","5m annotations"],"technology_tags":["Image Quality Assessment","Embodied AI","Vision Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:20.854879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_385657fe7235","title":"ALLSTaR: Automated LLM","content":"arXiv:2505.18389v4 Announce Type: replace Abstract: The evolution toward open, programmable O-RAN and AI-RAN 6G networks creates unprecedented opportunities for Intent-Based Networking (IBN) to dynamically optimize RAN[...]. However, applying IBN effectively to the RAN scheduler [...] remains a significant challenge. Current approaches predominantly rely on coarse-grained network slicing, lacking the granularity for dynamic adaptation to individual user conditions and traffic patterns. Despite the existence of a vast body of scheduling algorithms [...], their practical utilization is hindered by implementation heterogeneity, insufficient systematic evaluation in production environments, and the complexity of developing high-performance scheduler implementations.[...] To address these limitations, we propose ALLSTaR (Automated LLm-driven Scheduler generation and Testing for intent-based RAN), a novel framework leveraging LLMs for automated, intent-driven scheduler design, implementation, and evaluation. ALLSTaR interprets NL intents, automatically generates functional scheduler code from the research literature using OCR and LLMs, and intelligently matches operator intents to the most suitable scheduler(s). Our implementation deploys these schedulers as O-RAN dApps, enabling on-the-fly deployment and testing on a production-grade, 5G-compliant testbed. This approach has enabled the largest-scale OTA experimental comparison of 18 scheduling algorithms automatically synthesized from the academic literature. The resulting performance profiles serve as the input for our Intent-Based Scheduling (IBS) framework, which dynamically selects and deploys appropriate schedulers that optimally satisfy operator intents. We validate our approach through multiple use cases unattainable with current slicing-based optimization techniques, demonstrating fine-grained control based on buffer status, physical layer conditions, and heterogeneous traffic types","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18389","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.583285","language":"en","tags":["preprints","csni","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Maxime Elkael, Michele Polese, Reshma Prasad, Stefano Maxenti, Tommaso Melodia","raw_content_length":1970,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["Intent-Based Networking","AI-RAN 6","IBN","RAN","O-RAN"],"persons":["Scheduler"],"locations":[],"monetary":[]},"char_count":1969,"language_detected":"en","key_concepts":{"key_phrases":["ALLSTaR","Automated LLM","IBN","arXiv250518389v4 Announce Type","Abstract","The evolution","unprecedented opportunities","Intent-Based Networking","RAN","a significant challenge"],"filter_categories":{"ai_ml":["Automated LLM","RAN"],"business_innovation":["RAN"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ALLSTaR":2.0,"Automated LLM":2.0,"IBN":2.0,"arXiv250518389v4 Announce Type":1.0,"Abstract":1.0,"The evolution":1.0,"unprecedented opportunities":1.0,"Intent-Based Networking":1.0,"RAN":1.0,"a significant challenge":1.0}},"age_hours":2.747233292222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.716000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9432,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8924,"joy":0.0079,"surprise":0.0594,"sadness":0.008,"fear":0.0097,"anger":0.0147,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":6,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":true},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed framework (ALLSTaR) that automates the generation and testing of RAN schedulers using LLMs. It has been validated through OTA experimental comparison of 18 scheduling algorithms on a 5G-compliant testbed. The framework is O-RAN compliant, indicating regulatory approval and deployment readiness.","key_impact_metrics":["Largest-scale OTA experimental comparison of 18 scheduling algorithms","Fine-grained control based on buffer status, physical layer conditions, and heterogeneous traffic types"],"technology_tags":["AI-RAN","Intent-Based Networking","LLM","O-RAN","5G"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:23.752182Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d5ecfd2c7d3d","title":"MetaMind: Modeling Human Social Thoughts with Metacognitive Multi","content":"arXiv:2505.18943v3 Announce Type: replace Abstract: Human social interactions depend on the ability to infer others' unspoken intentions, emotions, and beliefs-a cognitive skill grounded in the psychological concept of Theory of Mind (ToM). While large language models (LLMs) excel in semantic understanding tasks, they struggle with the ambiguity and contextual nuance inherent in human communication. To bridge this gap, we introduce MetaMind, a multi-agent framework inspired by psychological theories of metacognition, designed to emulate human-like social reasoning. MetaMind decomposes social understanding into three collaborative stages: (1) a Theory-of-Mind Agent generates hypotheses about user mental states (e.g., intent, emotion), (2) a Moral Agent refines these hypotheses using cultural norms and ethical constraints, and (3) a Response Agent generates contextually appropriate responses while validating alignment with inferred intent. Our framework achieves state-of-the-art performance across three challenging benchmarks, with 35.7% improvement in real-world social scenarios and 6.2% gain in ToM reasoning. Notably, it enables LLMs to match human-level performance on key ToM tasks for the first time. Ablation studies confirm the necessity of all components, which showcase the framework's ability to balance contextual plausibility, social appropriateness, and user adaptation. This work advances AI systems toward human-like social intelligence, with applications in empathetic dialogue and culturally sensitive interactions. Code is available at https://github.com/XMZhangAI/MetaMind.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18943","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.583727","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Xuanming Zhang, Yuxuan Chen, Samuel Yeh, Sharon Li","raw_content_length":1609,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Response","Theory of Mind"],"persons":["ToM"],"locations":[],"monetary":[]},"char_count":1608,"language_detected":"en","key_concepts":{"key_phrases":["MetaMind","Modeling Human Social Thoughts","Metacognitive Multi","Announce Type","Abstract","Human social interactions","the ability","others unspoken intentions","emotions","beliefs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MetaMind":3.0,"Modeling Human Social Thoughts":2.0,"Metacognitive Multi":2.0,"Announce Type":1.0,"Abstract":1.0,"Human social interactions":1.0,"the ability":1.0,"others unspoken intentions":1.0,"emotions":1.0,"beliefs":1.0}},"age_hours":2.7472487900000004,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9054,"joy":0.0054,"surprise":0.022,"sadness":0.0129,"fear":0.0292,"anger":0.015,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework, MetaMind, for improved social reasoning in LLMs. While it shows a 35.7% improvement in real-world social scenarios and a 6.2% gain in ToM reasoning on benchmarks, it's still in the research phase with no clear path to direct climate impact. The code is available, suggesting potential for further development and validation.","key_impact_metrics":["35.7% improvement in real-world social scenarios","6.2% gain in ToM reasoning"],"technology_tags":["Artificial Intelligence","Large Language Models","Theory of Mind","Metacognition"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:43:29.694591Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a069f50514ac","title":"Protein Design with Dynamic Protein Vocabulary","content":"arXiv:2505.18966v2 Announce Type: replace Abstract: Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.6%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18966","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.584133","language":"en","tags":["preprints","csai","computer-science","q-biobm","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Nuowei Liu, Jiahao Kuang, Yanting Liu, Tao Ji, Changzhi Sun, Man Lan, Yuanbin Wu","raw_content_length":1412,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Protein Design with Dynamic Protein Vocabulary arXiv:2505.18966v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1411,"language_detected":"en","key_concepts":{"key_phrases":["Protein Design","Dynamic Protein Vocabulary","arXiv250518966v2 Announce Type","Protein design","a fundamental challenge","biotechnology","novel sequences","specific functions","the vast space","possible proteins"],"filter_categories":{"engineering":["biotechnology"],"healthcare_tech":["biotechnology"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Protein Design":2.0,"Dynamic Protein Vocabulary":2.0,"arXiv250518966v2 Announce Type":1.0,"Protein design":1.0,"a fundamental challenge":1.0,"biotechnology":1.0,"novel sequences":1.0,"specific functions":1.0,"the vast space":1.0,"possible proteins":1.0}},"age_hours":2.7472628502777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7007,"joy":0.0484,"surprise":0.0961,"sadness":0.0074,"fear":0.0948,"anger":0.0375,"disgust":0.0151},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel protein design approach (ProDVa) that improves foldability and function alignment compared to state-of-the-art models. It achieves comparable function alignment using less than 0.04% of the training data, while increasing the proportion of well-folded proteins (pLDDT > 70) by 7.38% and those with PAE < 10 by 9.6%. This is currently in the applied research stage, with no deployment yet.","key_impact_metrics":["pLDDT above 70 increasing by 7.38%","PAE below 10 increasing by 9.6%"],"technology_tags":["protein design","deep generative models","protein language model"],"sdg_alignment":[2,9],"analyzed_at":"2025-10-29T16:43:33.300462Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a9e94776bedc","title":"DoctorAgent-RL: A Multi","content":"arXiv:2505.19630v3 Announce Type: replace Abstract: Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Single-round consultation systems require patients to describe all symptoms upfront, leading to vague diagnosis with unclear complaints. Traditional multi-turn dialogue models, constrained by static supervised learning, lack flexibility and fail to intelligently extract key clinical information. To address these limitations, we propose \\Ours{}, a reinforcement learning (RL)-based multi-agent collaborative framework that models medical consultations as a dynamic decision-making process under uncertainty. The doctor agent continuously optimizes its questioning strategy within the RL framework through multi-turn interactions with the patient agent, dynamically adjusting its information-gathering path based on comprehensive rewards from the Consultation Evaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop interaction strategies aligned with clinical reasoning logic, rather than superficially imitating patterns in existing dialogue data. Notably, we constructed MTMedDialog, the first English multi-turn medical consultation dataset capable of simulating patient interactions. Experiments demonstrate that \\Ours{} outperforms existing models in both multi-turn reasoning capability and final diagnostic performance. This approach shows immense practical value by reducing misdiagnosis risks in time-pressured settings, freeing clinicians for complex cases, and pioneering a strategy to optimize medical resource allocation and alleviate workforce shortages. Code and data are available at https://github.com/JarvisUSTC/DoctorAgent-RL","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19630","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.584562","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Yichun Feng, Jiawei Wang, Lu Zhou, Zhen Lei, Yixue Li","raw_content_length":1825,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1824,"language_detected":"en","key_concepts":{"key_phrases":["DoctorAgent-RL","Announce Type","Large language models","LLMs","excellent capabilities","the field","biomedical question answering","their application","real-world clinical consultations","core challenges"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DoctorAgent-RL":2.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"excellent capabilities":1.0,"the field":1.0,"biomedical question answering":1.0,"their application":1.0,"real-world clinical consultations":1.0,"core challenges":1.0}},"age_hours":2.7472771997222223,"is_recent":true,"quality_score":0.7,"sentiment_score":0.937,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8126,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8775,"joy":0.0026,"surprise":0.0274,"sadness":0.0325,"fear":0.0288,"anger":0.0205,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a reinforcement learning-based multi-agent framework for medical consultations. While it demonstrates improved diagnostic performance in experiments, it's still in the early stages of development with no real-world deployment. The potential climate impact is indirect, through optimized resource allocation, but not directly quantified.","key_impact_metrics":["Improved diagnostic performance","Reduced misdiagnosis risks"],"technology_tags":["Reinforcement Learning","Large Language Models","Medical AI"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:43:35.916321Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e44718284644","title":"Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models","content":"arXiv:2505.19700v2 Announce Type: replace Abstract: The widespread adoption of large language models (LLMs) across industries has increased the demand for high-quality and customizable outputs. However, traditional alignment methods often require retraining large pretrained models, making it difficult to quickly adapt and optimize LLMs for diverse applications. To address this limitation, we propose a novel \\textit{Residual Alignment Model} (\\textit{RAM}) that formalizes the alignment process as a type of importance sampling. In this framework, the unaligned upstream model serves as the proposal distribution, while the alignment process is framed as secondary sampling based on an autoregressive alignment module that acts as an estimator of the importance weights. This design enables a natural detachment of the alignment module from the target aligned model, improving flexibility and scalability. Based on this model, we derive an efficient sequence-level training strategy for the alignment module, which operates independently of the proposal module. Additionally, we develop a resampling algorithm with iterative token-level decoding to address the common first-token latency issue in comparable methods. Experimental evaluations on two leading open-source LLMs across diverse tasks, including instruction following, domain adaptation, and preference optimization, demonstrate that our approach consistently outperforms baseline models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19700","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.584968","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Yi Liu, Dianqing Liu, Mingye Zhu, Junbo Guo, Yongdong Zhang, Zhendong Mao","raw_content_length":1452,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Detach Alignment Modules","Large Language Models arXiv:2505.19700v2 Announce Type"],"persons":["Alignment Model"],"locations":[],"monetary":[]},"char_count":1451,"language_detected":"en","key_concepts":{"key_phrases":["Importance Sampling","Detach Alignment Modules","Large Language Models","LLMs","Announce Type","The widespread adoption","large language models","industries","the demand","high-quality and customizable outputs"],"filter_categories":{"ai_ml":["Large Language Models","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Importance Sampling":2.0,"Detach Alignment Modules":2.0,"Large Language Models":2.0,"LLMs":2.0,"Announce Type":1.0,"The widespread adoption":1.0,"large language models":1.0,"industries":1.0,"the demand":1.0,"high-quality and customizable outputs":1.0}},"age_hours":2.7472913761111113,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.914,"joy":0.0093,"surprise":0.0395,"sadness":0.012,"fear":0.009,"anger":0.0094,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel method (Residual Alignment Model) for improving the flexibility and scalability of LLMs, which could indirectly contribute to sustainability by enabling more efficient and customizable AI applications. The experimental evaluations demonstrate improved performance compared to baseline models, but there are no concrete actions or measurable outcomes related to direct GHG emission reductions or other environmental benefits. It is still in the applied research stage with no deployed units.","key_impact_metrics":["Outperforms baseline models on instruction following","Outperforms baseline models on domain adaptation"],"technology_tags":["Large Language Models","Importance Sampling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:38.871842Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d5bef9b74ddc","title":"The Price of a Second Thought: On the Evaluation of Reasoning Efficiency in Large Language Models","content":"arXiv:2505.22017v2 Announce Type: replace Abstract: Recent thinking models trained with reinforcement learning and backward-checking CoT often suffer from overthinking: they produce excessively long outputs even on simple problems, wasting computation. Existing evaluations, based on token efficiency, give an incomplete view as they neglect problem difficulty and intermediate computation costs. We formalize reasoning efficiency as a relative measure between thinking and instruct models, treating instruct models as the minimal-effort baseline. A systematic study across four thinking models and multiple benchmarks reveals two consistent patterns: (i) instruct models achieve higher efficiency overall, and (ii) problem difficulty affects efficiency, with thinking models wasting computation on easy problems but providing value on harder ones. Building on this insight, we propose COTHINK, a simple two-stage pipeline: an instruct model drafts a brief outline, and a thinking model expands it. On GSM8K, MATH500, and AIME24, COTHINK cuts token usage by 21.1% while keeping accuracy on four thinking models, and remains competitive with strong efficiency baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.22017","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.585747","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Siqi Fan, Bowen Qin, Peng Han, Shuo Shang, Yequan Wang, Aixin Sun","raw_content_length":1170,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["COTHINK","CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1169,"language_detected":"en","key_concepts":{"key_phrases":["The Price","a Second Thought","the Evaluation","Reasoning Efficiency","Large Language Models","arXiv250522017v2 Announce Type","Abstract","Recent thinking models","reinforcement learning","backward-checking CoT"],"filter_categories":{"ai_ml":["Large Language Models","reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Price":2.0,"a Second Thought":2.0,"the Evaluation":2.0,"Reasoning Efficiency":2.0,"Large Language Models":2.0,"arXiv250522017v2 Announce Type":1.0,"Abstract":1.0,"Recent thinking models":1.0,"reinforcement learning":1.0,"backward-checking CoT":1.0}},"age_hours":2.7473189777777773,"is_recent":true,"quality_score":1.0,"sentiment_score":0.49949999999999994,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9001,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4738,"joy":0.0046,"surprise":0.0249,"sadness":0.193,"fear":0.0134,"anger":0.0988,"disgust":0.1916},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (COTHINK) to improve the efficiency of large language models, reducing computational waste. The concrete action is the development and testing of this pipeline, showing a 21.1% reduction in token usage on benchmark datasets. While promising, it's still in the applied research stage with no real-world deployments yet.","key_impact_metrics":["Token usage reduction 21.1%"],"technology_tags":["Large Language Models","Reasoning Efficiency","Artificial Intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:43:41.882749Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1281c62eb9c2","title":"Enhancing Long-Chain Reasoning Distillation through Error","content":"arXiv:2505.22131v2 Announce Type: replace Abstract: Large Language Models (LLMs) have exhibited strong reasoning capabilities and achieved remarkable performance in mathematical problem-solving tasks. Recently, distilling reasoning ability from long-form Chains-of-Thought (CoTs) has emerged as a promising approach for enhancing Small Language Models (SLMs). Existing studies typically treat SLMs as student models and use long-form CoTs as supervision signals for Supervised Fine-Tuning (SFT) to transfer reasoning ability. However, such long-form CoT teachers are usually unaware of the student model's capacity, which limits the effective utilization of the provided reasoning traces. To overcome this limitation, we propose errOr-aware self-ReflectION (ORION), a framework that refines teacher CoTs through an Error-Aware Reflection process. ORION enables the student model to construct more tailored teacher CoTs by refining teacher CoTs and incorporating its own reasoning errors. Experiments on multiple mathematical reasoning benchmarks demonstrate that ORION consistently improves performance by more than 2% over all baselines. Further analysis reveals that the CoTs constructed by ORION exhibit higher coherence and logical consistency, thereby serving as more effective supervision signals for SFT. All codes are available at https://github.com/NEUIR/ORION.git.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.22131","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.591300","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Zhuoyang Wu, Xinze Li, Zhenghao Liu, Yukun Yan, Zhiyuan Liu, Minghe Yu, Cheng Yang, Yu Gu, Ge Yu, Maosong Sun","raw_content_length":1375,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["CoT","Small Language Models","CoTs","an Error-Aware Reflection","SFT"],"persons":["Chains"],"locations":[],"monetary":[]},"char_count":1374,"language_detected":"en","key_concepts":{"key_phrases":["Long-Chain Reasoning Distillation","Error","SLMs","arXiv250522131v2","Announce Type","Large Language Models","LLMs","strong reasoning capabilities","remarkable performance","mathematical problem-solving tasks"],"filter_categories":{"ai_ml":["Long-Chain Reasoning Distillation","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Long-Chain Reasoning Distillation":2.0,"Error":2.0,"SLMs":2.0,"arXiv250522131v2":1.0,"Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"strong reasoning capabilities":1.0,"remarkable performance":1.0,"mathematical problem-solving tasks":1.0}},"age_hours":2.7473342552777775,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8979,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8542,"joy":0.0168,"surprise":0.0794,"sadness":0.006,"fear":0.0232,"anger":0.0144,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (ORION) to improve the reasoning capabilities of small language models (SLMs) by refining teacher Chains-of-Thought (CoTs). The concrete action is the development and testing of this framework on mathematical reasoning benchmarks, showing a 2% improvement over baselines. However, the impact on sustainability is indirect and theoretical, as it focuses on improving AI algorithms rather than directly addressing environmental issues. The stage is applied research, with experimental results but no real-world deployment.","key_impact_metrics":["Performance improvement over baselines: 2%"],"technology_tags":["Large Language Models","Small Language Models","Reasoning Distillation","Error-Aware Reflection"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:43:45.531105Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03e7282ed0d9","title":"Can LLMs Reason Structurally? An Evaluation via the Lens of Data Structures","content":"arXiv:2505.24069v2 Announce Type: replace Abstract: As large language models (LLMs) take on increasingly complex tasks, understanding their algorithmic reasoning abilities has become essential. However, existing evaluations focus on distinct and isolated tasks. We propose a unified diagnostic lens: structural reasoning--understanding and manipulating relationships like order, hierarchy, and connectivity. We introduce DSR-Bench, the first benchmark to systematically evaluate LLM structural reasoning through canonical data structures, which serve as interpretable, algorithmically meaningful abstractions. DSR-Bench spans 20 data structures, 35 operations, and 4,140 synthetically generated problem instances with minimal contamination. The benchmark's hierarchical design pinpoints specific failure modes, while its fully automated evaluation ensures objective and consistent assessment. Benchmarking ten state-of-the-art LLMs reveals critical limitations: the top-performing model scores only 0.498 out of 1 on challenging instances. Three additional evaluation suites reveal further weaknesses: models perform poorly on spatial data and natural language scenarios, and fail to reason over their own generated code. DSR-Bench offers a principled diagnostic tool for structural reasoning, helping expose reasoning bottlenecks and guide the development of more capable and reliable LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.24069","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.591782","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Yu He, Yingxi Li, Colin White, Ellen Vitercik","raw_content_length":1392,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["DSR","DSR-Bench"],"persons":[],"locations":[],"monetary":[]},"char_count":1391,"language_detected":"en","key_concepts":{"key_phrases":["Can LLMs","An Evaluation","the Lens","Data Structures","arXiv250524069v2 Announce Type","Abstract","large language models","LLMs","increasingly complex tasks","their algorithmic reasoning abilities"],"filter_categories":{"ai_ml":["Can LLMs","large language models","their algorithmic reasoning abilities"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Can LLMs":2.0,"An Evaluation":2.0,"the Lens":2.0,"Data Structures":2.0,"arXiv250524069v2 Announce Type":1.0,"Abstract":1.0,"large language models":1.0,"LLMs":1.0,"increasingly complex tasks":1.0,"their algorithmic reasoning abilities":1.0}},"age_hours":2.7473490702777776,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8803,"joy":0.0087,"surprise":0.0604,"sadness":0.0058,"fear":0.0196,"anger":0.0159,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on evaluating the reasoning capabilities of LLMs using data structures. While improved LLMs could potentially contribute to sustainability efforts in the future, this article itself does not present any concrete actions or measurable outcomes related to climate or other sustainability dimensions. The benchmark reveals limitations in current LLMs, with the top-performing model scoring only 0.498 out of 1 on challenging instances.","key_impact_metrics":["Top model score: 0.498"],"technology_tags":["Large Language Models","Data Structures","Algorithmic Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:43:48.693135Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be5fef92818c","title":"DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments","content":"arXiv:2506.00739v4 Announce Type: replace Abstract: Large language model (LLM) agents have shown impressive capabilities in human language comprehension and reasoning, yet their potential in cybersecurity remains underexplored. We introduce DefenderBench, a practical, open-source toolkit for evaluating language agents across offense, defense, and cybersecurity knowledge-based tasks. DefenderBench includes environments for network intrusion, malicious content detection, code vulnerability analysis, and cybersecurity knowledge assessment. It is intentionally designed to be affordable and easily accessible for researchers while providing fair and rigorous assessment. We benchmark several state-of-the-art (SoTA) and popular LLMs, including both open- and closed-weight models, using a standardized agentic framework. Our results show that Claude-3.7-sonnet performs best with a DefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40, while the best open-weight model, Llama 3.3 70B, is not far behind with a DefenderBench score of 71.81. DefenderBench's modular design allows seamless integration of custom LLMs and tasks, promoting reproducibility and fair comparisons. An anonymized version of DefenderBench is available at https://github.com/microsoft/DefenderBench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00739","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.592616","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Chiyu Zhang, Marc-Alexandre Cote, Michael Albada, Anush Sankaran, Jack W. Stokes, Tong Wang, Amir Abdi, William Blum, Muhammad Abdul-Mageed","raw_content_length":1298,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["DefenderBench","SoTA"],"persons":[],"locations":[],"monetary":[]},"char_count":1297,"language_detected":"en","key_concepts":{"key_phrases":["DefenderBench","A Toolkit","Evaluating Language Agents","Cybersecurity Environments","arXiv250600739v4 Announce Type","Large language model LLM agents","impressive capabilities","human language comprehension","reasoning","their potential"],"filter_categories":{"ai_ml":["Large language model LLM agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DefenderBench":4.0,"A Toolkit":2.0,"Evaluating Language Agents":2.0,"Cybersecurity Environments":2.0,"arXiv250600739v4 Announce Type":1.0,"Large language model LLM agents":1.0,"impressive capabilities":1.0,"human language comprehension":1.0,"reasoning":1.0,"their potential":1.0}},"age_hours":2.7473780058333332,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9154,"joy":0.0186,"surprise":0.0364,"sadness":0.0043,"fear":0.0112,"anger":0.009,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article introduces a toolkit for evaluating language agents in cybersecurity, providing a benchmark score for various LLMs. While it's open-source and accessible, it's still in the applied research stage with no real-world deployment data to demonstrate climate impact. The toolkit itself doesn't directly reduce emissions, but could indirectly contribute by improving cybersecurity for climate-related infrastructure.","key_impact_metrics":["DefenderBench score of 81.65","DefenderBench score of 71.81"],"technology_tags":["Language Agents","Cybersecurity"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:43:51.806131Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_768ff857f418","title":"EgoBrain: Synergizing Minds and Eyes For Human Action Understanding","content":"arXiv:2506.01353v2 Announce Type: replace Abstract: The integration of brain-computer interfaces (BCIs), in particular electroencephalography (EEG), with artificial intelligence (AI) has shown tremendous promise in decoding human cognition and behavior from neural signals. In particular, the rise of multimodal AI models have brought new possibilities that have never been imagined before. Here, we present EgoBrain --the world's first large-scale, temporally aligned multimodal dataset that synchronizes egocentric vision and EEG of human brain over extended periods of time, establishing a new paradigm for human-centered behavior analysis. This dataset comprises 61 hours of synchronized 32-channel EEG recordings and first-person video from 40 participants engaged in 29 categories of daily activities. We then developed a muiltimodal learning framework to fuse EEG and vision for action understanding, validated across both cross-subject and cross-environment challenges, achieving an action recognition accuracy of 66.70%. EgoBrain paves the way for a unified framework for brain-computer interface with multiple modalities. All data, tools, and acquisition protocols are openly shared to foster open science in cognitive computing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01353","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.593022","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Nie Lin, Yansen Wang, Dongqi Han, Weibang Jiang, Jingyuan Li, Ryosuke Furuta, Yoichi Sato, Dongsheng Li","raw_content_length":1240,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["EEG","Eyes For Human Action Understanding"],"persons":[],"locations":["EgoBrain"],"monetary":[]},"char_count":1239,"language_detected":"en","key_concepts":{"key_phrases":["EgoBrain","Minds","Eyes","Human Action Understanding","arXiv250601353v2 Announce Type","Abstract","The integration","brain-computer interfaces","BCIs","particular electroencephalography"],"filter_categories":{"ai_ml":["EgoBrain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EgoBrain":2.0,"Minds":2.0,"Eyes":2.0,"Human Action Understanding":2.0,"arXiv250601353v2 Announce Type":1.0,"Abstract":1.0,"The integration":1.0,"brain-computer interfaces":1.0,"BCIs":1.0,"particular electroencephalography":1.0}},"age_hours":2.7473928711111113,"is_recent":true,"quality_score":1.0,"sentiment_score":8.450500000000002,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6901,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6409,"joy":0.2313,"surprise":0.0875,"sadness":0.0053,"fear":0.0144,"anger":0.0134,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new multimodal dataset (EgoBrain) and a learning framework for action understanding using EEG and vision data. While the dataset and framework are significant innovations, they are still in the research phase with no clear path to immediate climate impact or economic viability. The action recognition accuracy of 66.70% is a measurable outcome, but the technology is not yet deployed.","key_impact_metrics":["Action recognition accuracy 66.70%","Dataset comprises 61 hours"],"technology_tags":["Brain-Computer Interface","Artificial Intelligence","EEG","Egocentric Vision"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:43:55.420608Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8d24770b7b54","title":"EvolveNav: Empowering LLM-Based Vision","content":"arXiv:2506.01551v3 Announce Type: replace Abstract: Recent studies have revealed the potential of training open-source Large Language Models (LLMs) to unleash LLMs' reasoning ability for enhancing vision-language navigation (VLN) performance, and simultaneously mitigate the domain gap between LLMs' training corpus and the VLN task. However, these approaches predominantly adopt straightforward input-output mapping paradigms, causing the mapping learning difficult and the navigational decisions unexplainable. Chain-of-Thought (CoT) training is a promising way to improve both navigational decision accuracy and interpretability, while the complexity of the navigation task makes the perfect CoT labels unavailable and may lead to overfitting through pure CoT supervised fine-tuning. To address these issues, we propose EvolveNav, a novel sElf-improving embodied reasoning paradigm that realizes adaptable and generalizable navigational reasoning for boosting LLM-based vision-language Navigation. Specifically, EvolveNav involves a two-stage training process: (1) Formalized CoT Supervised Fine-Tuning, where we train the model with curated formalized CoT labels to first activate the model's navigational reasoning capabilities, and simultaneously increase the reasoning speed; (2) Self-Reflective Post-Training, where the model is iteratively trained with its own reasoning outputs as self-enriched CoT labels to enhance the supervision diversity. A self-reflective auxiliary task is also designed to encourage the model to learn correct reasoning patterns by contrasting with wrong ones. Experimental results under both task-specific and cross-task training paradigms demonstrate the consistent superiority of EvolveNav over previous LLM-based VLN approaches on various popular benchmarks, including R2R, REVERIE, CVDN, and SOON. Code is available at https://github.com/expectorlin/EvolveNav.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01551","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.593456","language":"en","tags":["preprints","csai","computer-science","research","cscl","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Bingqian Lin, Yunshuang Nie, Khun Loun Zai, Ziming Wei, Mingfei Han, Rongtao Xu, Minzhe Niu, Jianhua Han, Hanwang Zhang, Liang Lin, Bokui Chen, Cewu Lu, Xiaodan Liang","raw_content_length":1900,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["EvolveNav","VLN","CoT","sElf"],"persons":[],"locations":[],"monetary":[]},"char_count":1899,"language_detected":"en","key_concepts":{"key_phrases":["EvolveNav","LLM-Based Vision","Announce Type","Abstract","Recent studies","the potential","open-source Large Language Models","LLMs","LLMs reasoning ability","vision-language navigation VLN performance"],"filter_categories":{"ai_ml":["LLM-Based Vision","open-source Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EvolveNav":2.0,"LLM-Based Vision":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent studies":1.0,"the potential":1.0,"open-source Large Language Models":1.0,"LLMs":1.0,"LLMs reasoning ability":1.0,"vision-language navigation VLN performance":1.0}},"age_hours":2.7474073097222225,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8464,"joy":0.0665,"surprise":0.0307,"sadness":0.0067,"fear":0.0239,"anger":0.0196,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI-based navigation system. While it improves navigation accuracy on benchmarks, it's in the early stages of development (applied research) and lacks concrete deployment or measurable environmental impact. The technical credibility is high due to the research nature and benchmark results.","key_impact_metrics":["Navigational decision accuracy improvement","Reasoning speed increase"],"technology_tags":["Large Language Models","Vision-Language Navigation","Chain-of-Thought"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:43:58.321594Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9025649eba90","title":"Normalize Filters! Classical Wisdom for Deep Vision","content":"arXiv:2506.04401v2 Announce Type: replace Abstract: Classical image filters, such as those for averaging or differencing, are carefully normalized to ensure consistency, interpretability, and to avoid artifacts like intensity shifts, halos, or ringing. In contrast, convolutional filters learned end-to-end in deep networks lack such constraints. Although they may resemble wavelets and blob/edge detectors, they are not normalized in the same or any way. Consequently, when images undergo atmospheric transfer, their responses become distorted, leading to incorrect outcomes. We address this limitation by proposing filter normalization, followed by learnable scaling and shifting, akin to batch normalization. This simple yet effective modification ensures that the filters are atmosphere-equivariant, enabling co-domain symmetry. By integrating classical filtering principles into deep learning (applicable to both convolutional neural networks and convolution-dependent vision transformers), our method achieves significant improvements on artificial and natural intensity variation benchmarks. Our ResNet34 could even outperform CLIP by a large margin. Our analysis reveals that unnormalized filters degrade performance, whereas filter normalization regularizes learning, promotes diversity, and improves robustness and generalization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04401","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.593876","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Gustavo Perez, Stella X. Yu","raw_content_length":1341,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Normalize Filters"],"persons":[],"locations":[],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["Normalize Filters","Classical Wisdom","Deep Vision","end","arXiv250604401v2 Announce Type","Abstract","Classical image filters","those","differencing","consistency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Normalize Filters":2.0,"Classical Wisdom":2.0,"Deep Vision":2.0,"end":2.0,"arXiv250604401v2 Announce Type":1.0,"Abstract":1.0,"Classical image filters":1.0,"those":1.0,"differencing":1.0,"consistency":1.0}},"age_hours":2.747422483333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.888499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7777,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9447,"joy":0.005,"surprise":0.029,"sadness":0.0043,"fear":0.0038,"anger":0.008,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to image processing that improves robustness and generalization in deep learning models. While the method shows significant improvements on benchmarks, it's still in the research phase with no deployed units or customer contracts. The potential climate impact is indirect, as improved image processing could enhance the efficiency of climate-related technologies (e.g., satellite monitoring), but this is not explicitly quantified.","key_impact_metrics":["ResNet34 outperforms CLIP by a large margin","Significant improvements on artificial and natural intensity variation benchmarks"],"technology_tags":["deep learning","image processing","convolutional neural networks","vision transformers"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:01.211982Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_440b83c8f0d6","title":"Beyond Per","content":"arXiv:2506.05290v2 Announce Type: replace Abstract: We analyze the privacy guarantees of the Attribution API, an upcoming W3C standard for privacy-preserving advertising measurement. Its central guarantee--separate individual differential privacy (IDP) budgets per querier--proves unsound once data adaptivity across queriers is considered, a condition we argue is unavoidable in practice. The issue lies not with IDP or its device-epoch unit, but with the per-querier enforcement model, which has also appeared in other DP systems; we show formally that no per-querier accounting scheme, under either individual or traditional DP, remains sound under adaptivity, a gap missed by prior analyses. By contrast, a global device-epoch IDP guarantee remains sound, and we introduce Big Bird, a privacy budget manager for the Attribution API that enforces this guarantee. The challenge is that a global budget shared across many untrusted queriers creates denial-of-service (DoS) risks, undermining utility. Building on prior work that treats global budgets as a computing resource, we adapt resource isolation and scheduling techniques to the constraints of IDP, embedding DoS resilience into the budget management layer. Our Rust implementation with Firefox integration, evaluated on real-world ad data, shows that Big Bird supports benign workloads while mitigating DoS risks. Still, achieving both utility and robustness requires global budgets to be configured more loosely than per-site budgets; we therefore recommend that the Attribution API continue using tight per-site budgets but clarify their limited formal meaning, and complement them with global budgets tuned for benign load with added slack for DoS resilience.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05290","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.594317","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Pierre Tholoniat, Alison Caulfield, Giorgio Cavicchioli, Mark Chen, Nikos Goutzoulias, Benjamin Case, Asaf Cidon, Roxana Geambasu, Mathias L\\'ecuyer, Martin Thomson","raw_content_length":1723,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["DoS","the Attribution API","IDP"],"persons":[],"locations":[],"monetary":[]},"char_count":1722,"language_detected":"en","key_concepts":{"key_phrases":["querier","arXiv250605290v2 Announce Type","Abstract","the privacy guarantees","the Attribution API","an upcoming W3C standard","privacy-preserving advertising measurement","Its central guarantee","separate individual differential privacy","IDP budgets"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"querier":2.0,"arXiv250605290v2 Announce Type":1.0,"Abstract":1.0,"the privacy guarantees":1.0,"the Attribution API":1.0,"an upcoming W3C standard":1.0,"privacy-preserving advertising measurement":1.0,"Its central guarantee":1.0,"separate individual differential privacy":1.0,"IDP budgets":1.0}},"age_hours":2.7474380641666665,"is_recent":true,"quality_score":1.0,"sentiment_score":3.091,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3818,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5801,"joy":0.0062,"surprise":0.0161,"sadness":0.0418,"fear":0.1233,"anger":0.054,"disgust":0.1785},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a privacy budget manager (Big Bird) for the Attribution API, addressing denial-of-service risks associated with global privacy budgets. It includes a Rust implementation with Firefox integration and evaluation on real-world ad data, demonstrating mitigation of DoS risks. However, it acknowledges the need for looser global budgets than per-site budgets, indicating a trade-off between utility and robustness, and the climate impact is indirect.","key_impact_metrics":["DoS resilience","privacy budget management"],"technology_tags":["privacy-preserving advertising","differential privacy","budget management"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:44:04.521829Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_177972d21bcf","title":"Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment","content":"arXiv:2506.05670v2 Announce Type: replace Abstract: As LLMs become central to interactive applications, ranging from tutoring to mental health, the ability to express personality in culturally appropriate ways is increasingly important. While recent works have explored personality evaluation of LLMs, they largely overlook the interplay between culture and personality. To address this, we introduce CulturalPersonas, the first large-scale benchmark with human validation for evaluating LLMs' personality expression in culturally grounded, behaviorally rich contexts. Our dataset spans 3,000 scenario-based questions across six diverse countries, designed to elicit personality through everyday scenarios rooted in local values. We evaluate three LLMs, using both multiple-choice and open-ended response formats. Our results show that CulturalPersonas improves alignment with country-specific human personality distributions (over a 20% reduction in Wasserstein distance across models and countries) and elicits more expressive, culturally coherent outputs compared to existing benchmarks. CulturalPersonas surfaces meaningful modulated trait outputs in response to culturally grounded prompts, offering new directions for aligning LLMs to global norms of behavior. By bridging personality expression and cultural nuance, we envision that CulturalPersonas will pave the way for more socially intelligent and globally adaptive LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05670","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.594741","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Priyanka Dey, Yugal Khanter, Aayush Bothra, Jieyu Zhao, Emilio Ferrara","raw_content_length":1433,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["CulturalPersonas"],"persons":[],"locations":[],"monetary":[]},"char_count":1432,"language_detected":"en","key_concepts":{"key_phrases":["CulturalPersonas","Can LLMs","Express Personality","Cultures","Evaluating Trait Alignment","LLMs","personality","arXiv250605670v2 Announce Type","Abstract","interactive applications"],"filter_categories":{"ai_ml":["Can LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CulturalPersonas":3.0,"Can LLMs":2.0,"Express Personality":2.0,"Cultures":2.0,"Evaluating Trait Alignment":2.0,"LLMs":2.0,"personality":2.0,"arXiv250605670v2 Announce Type":1.0,"Abstract":1.0,"interactive applications":1.0}},"age_hours":2.7474520952777777,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9233,"joy":0.0123,"surprise":0.042,"sadness":0.0026,"fear":0.0066,"anger":0.0088,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (CulturalPersonas) for evaluating LLMs' ability to express personality across cultures. The concrete action is the creation and validation of a dataset spanning six countries. The evidence is the reported 20% reduction in Wasserstein distance, indicating improved alignment with human personality distributions. This is still in the applied research stage, with no real-world deployment.","key_impact_metrics":["20% reduction in Wasserstein distance"],"technology_tags":["LLMs","Cultural AI","Personality Alignment"],"sdg_alignment":[4,10,16],"analyzed_at":"2025-10-29T16:44:07.917284Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
