{"id":"science_arxiv_cs_849943db441c","title":"PicoAudio2: Temporal Controllable Text","content":"arXiv:2509.00683v2 Announce Type: replace Abstract: While recent work in controllable text-to-audio (TTA) generation has achieved fine-grained control through timestamp conditioning, its scope remains limited by audio quality and input format. These models often suffer from poor audio quality in real datasets due to sole reliance on synthetic data. Moreover, some models are constrained to a closed vocabulary of sound events, preventing them from controlling audio generation for open-ended, free-text queries. This paper introduces PicoAudio2, a framework that advances temporal-controllable TTA by mitigating these data and architectural limitations. Specifically, we use a grounding model to annotate event timestamps of real audio-text datasets to curate temporally-strong real data, in addition to simulation data from existing works. The model is trained on the combination of real and simulation data. Moreover, we propose an enhanced architecture that integrates the fine-grained information from a timestamp matrix with coarse-grained free-text input. Experiments show that PicoAudio2 exhibits superior performance in terms of temporal controllability and audio quality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.00683","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.261314","language":"en","tags":["eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Zihao Zheng, Zeyu Xie, Xuenan Xu, Wen Wu, Chao Zhang, Mengyue Wu","raw_content_length":1183,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1182,"language_detected":"en","key_concepts":{"key_phrases":["PicoAudio2 Temporal Controllable Text","Announce Type","recent work","audio","fine-grained control","timestamp conditioning","its scope","audio quality and input format","These models","poor audio quality"],"filter_categories":{"ai_ml":["fine-grained control"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PicoAudio2 Temporal Controllable Text":2.0,"Announce Type":1.0,"recent work":1.0,"audio":1.0,"fine-grained control":1.0,"timestamp conditioning":1.0,"its scope":1.0,"audio quality and input format":1.0,"These models":1.0,"poor audio quality":1.0}},"age_hours":2.7696062383333335,"is_recent":true,"quality_score":0.7,"sentiment_score":0.7990000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8402,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7337,"joy":0.0055,"surprise":0.0352,"sadness":0.0919,"fear":0.0226,"anger":0.0321,"disgust":0.0789},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new framework for temporal-controllable text-to-audio generation. While it improves audio quality and controllability, its direct impact on sustainability is minimal. It's currently in the applied research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["Superior performance in temporal controllability","Improved audio quality"],"technology_tags":["Text-to-audio generation","Machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:48:49.653998Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c202c1bd1c3d","title":"Updating the Complex Systems Keyword Diagram Using Collective Feedback and Latest Literature Data","content":"arXiv:2509.11997v2 Announce Type: replace Abstract: The complex systems keyword diagram generated by the author in 2010 has been used widely in a variety of educational and outreach purposes, but it definitely needs a major update and reorganization. This short paper reports our recent attempt to update the keyword diagram using information collected from the following multiple sources: (a) collective feedback posted on social media, (b) recent reference books on complex systems and network science, (c) online resources on complex systems, and (d) keyword search hits obtained using OpenAlex, an open-access bibliographic catalogue of scientific publications. The data (a), (b) and (c) were used to incorporate the research community's and other public communities' perceptions of the relevant topics, whereas the data (d) was used to obtain more objective measurements of the keywords' relevance and associations from publications made in complex systems science. Results revealed differences and overlaps between public perception and actual usage of keywords in publications on complex systems. Four topical communities were obtained from the keyword association network, although they were highly intertwined with each other. We hope that the resulting network visualization of complex systems keywords provides a more up-to-date, accurate topic map of the field of complex systems as of today.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.11997","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.274892","language":"en","tags":["physicsed-ph","nlinao","csdl","preprints","research","computer-science","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Hiroki Sayama","raw_content_length":1405,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1404,"language_detected":"en","key_concepts":{"key_phrases":["the Complex Systems Keyword Diagram","Collective Feedback","arXiv250911997v2 Announce Type","Abstract","The complex systems keyword diagram","the author","a variety","educational and outreach purposes","a major update","reorganization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Complex Systems Keyword Diagram":2.0,"Collective Feedback":2.0,"arXiv250911997v2 Announce Type":1.0,"Abstract":1.0,"The complex systems keyword diagram":1.0,"the author":1.0,"a variety":1.0,"educational and outreach purposes":1.0,"a major update":1.0,"reorganization":1.0}},"age_hours":2.770101262222222,"is_recent":true,"quality_score":0.7,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9095,"joy":0.0307,"surprise":0.0414,"sadness":0.0067,"fear":0.0023,"anger":0.0065,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper updates a complex systems keyword diagram using collective feedback and recent literature. While it aims to improve understanding of complex systems, it does not directly result in concrete actions or measurable outcomes related to sustainability. The research is in an early stage, lacking deployment or economic viability.","key_impact_metrics":["Differences and overlaps between public perception and actual usage of keywords in publications on complex systems"],"technology_tags":["complex systems analysis","network science","data analysis"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T12:48:57.921370Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_438bf381d1dc","title":"Is Research Software Science a Metascience?","content":"arXiv:2509.13436v2 Announce Type: replace Abstract: As research increasingly relies on computational methods, the reliability of scientific results depends on the quality, reproducibility, and transparency of research software. Ensuring these qualities is critical for scientific integrity and discovery. This paper asks whether Research Software Science (RSS)--the empirical study of how research software is developed and used--should be considered a form of metascience, the science of science. Classification matters because it could affect recognition, funding, and integration of RSS into research improvement. We define metascience and RSS, compare their principles and objectives, and examine their overlaps. Arguments for classification highlight shared commitments to reproducibility, transparency, and empirical study of research processes. Arguments against portraying RSS as a specialized domain focused on a tool rather than the broader scientific enterprise. Our analysis finds RSS advances core goals of metascience, especially in computational reproducibility, and bridges technical, social, and cognitive aspects of research. Its classification depends on whether one adopts a broad definition of metascience--any empirical effort to improve science--or a narrow one focused on systemic and epistemological structures. We argue RSS is best understood as a distinct interdisciplinary domain that aligns with, and in some definitions fits within, metascience. Recognizing it as such can strengthen its role in improving reliability, justify funding, and elevate software development in research institutions. Regardless of classification, applying scientific rigor to research software ensures the tools of discovery meet the standards of the discoveries themselves.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.13436","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.276082","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Evan Eisinger, Michael A. Heroux","raw_content_length":1783,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["RSS","Research Software Science"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1782,"language_detected":"en","key_concepts":{"key_phrases":["Research Software Science","a Metascience","research software","Announce Type","Abstract","research","computational methods","the reliability","scientific results","the quality"],"filter_categories":{"research_academic":["Research Software Science","research software","research"],"healthcare_tech":["research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Research Software Science":3.0,"a Metascience":2.0,"research software":2.0,"Announce Type":1.0,"Abstract":1.0,"research":1.0,"computational methods":1.0,"the reliability":1.0,"scientific results":1.0,"the quality":1.0}},"age_hours":2.770144740277778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8669,"joy":0.0124,"surprise":0.0567,"sadness":0.005,"fear":0.0223,"anger":0.0205,"disgust":0.0162},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores the classification of Research Software Science (RSS) as a metascience. While it doesn't directly address climate change, improving the reliability of research software can indirectly enhance the quality and reproducibility of climate-related research, leading to more robust findings and potentially faster progress in developing sustainable solutions. The paper is theoretical and does not present concrete deployments or measured outcomes.","key_impact_metrics":[],"technology_tags":["research software","metascience","reproducibility"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:01.113767Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f2799a31b98d","title":"Distribution","content":"arXiv:2509.15888v3 Announce Type: replace Abstract: Adapting billion-parameter language models to a downstream task is still costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task adaptation as output-distribution alignment: the objective is to steer the output distribution toward the task distribution directly during decoding rather than indirectly through weight updates. Building on this view, we introduce Steering Vector Decoding (SVDecode), a lightweight, PEFT-compatible, and theoretically grounded method. We start with a short warm-start fine-tune and extract a task-aware steering vector from the Kullback-Leibler (KL) divergence gradient between the output distribution of the warm-started and pre-trained models. This steering vector is then used to guide the decoding process to steer the model's output distribution towards the task distribution. We theoretically prove that SVDecode is first-order equivalent to the gradient step of full fine-tuning and derive a globally optimal solution for the strength of the steering vector. Across three tasks and nine benchmarks, SVDecode paired with four standard PEFT methods improves multiple-choice accuracy by up to 5 percentage points and open-ended truthfulness by 2 percentage points, with similar gains (1-2 percentage points) on commonsense datasets without adding trainable parameters beyond the PEFT adapter. SVDecode thus offers a lightweight, theoretically grounded path to stronger task adaptation for large language models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.15888","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.277246","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Senkang Hu, Xudong Han, Jinqi Jiang, Yihang Tao, Zihan Fang, Yong Dai, Sam Tak Wu Kwong, Yuguang Fang","raw_content_length":1516,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["the Kullback-Leibler","SVDecode","Steering Vector Decoding"],"persons":[],"locations":[],"monetary":[]},"char_count":1515,"language_detected":"en","key_concepts":{"key_phrases":["Distribution","Announce Type","Adapting billion-parameter language models","a downstream task","parameter-efficient fine-tuning PEFT","cast task adaptation","output-distribution alignment","the objective","the output distribution","the task distribution"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Distribution":2.0,"Announce Type":1.0,"Adapting billion-parameter language models":1.0,"a downstream task":1.0,"parameter-efficient fine-tuning PEFT":1.0,"cast task adaptation":1.0,"output-distribution alignment":1.0,"the objective":1.0,"the output distribution":1.0,"the task distribution":1.0}},"age_hours":2.770189496111111,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9274,"joy":0.0093,"surprise":0.0212,"sadness":0.0187,"fear":0.0051,"anger":0.0105,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (SVDecode) for improving the efficiency of large language models, potentially reducing the computational resources required for task adaptation. The method is theoretically grounded and shows improvements in multiple-choice accuracy and open-ended truthfulness across several benchmarks. However, it is still in the applied research stage with no deployed units and the environmental impact of reduced computational needs is not explicitly quantified.","key_impact_metrics":["multiple-choice accuracy by up to 5 percentage points","open-ended truthfulness by 2 percentage points"],"technology_tags":["large language models","parameter-efficient fine-tuning","machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:49:04.615165Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6f183983ad69","title":"ORN","content":"arXiv:2509.16614v2 Announce Type: replace Abstract: Control barrier functions (CBFs) have been demonstrated as an effective method for safety-critical control of autonomous systems. Although CBFs are simple to deploy, their design remains challenging, motivating the development of learning-based approaches. Yet, issues such as suboptimal safe sets, applicability in partially observable environments, and lack of rigorous safety guarantees persist. In this work, we propose observation-conditioned neural CBFs based on Hamilton-Jacobi (HJ) reachability analysis, which approximately recover the maximal safe sets. We exploit certain mathematical properties of the HJ value function, ensuring that the predicted safe set never intersects with the observed failure set. Moreover, we leverage a hypernetwork-based architecture that is particularly suitable for the design of observation-conditioned safety filters. The proposed method is examined both in simulation and hardware experiments for a ground robot and a quadcopter. The results show improved success rates and generalization to out-of-domain environments compared to the baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.16614","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.277652","language":"en","tags":["cslg","eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Bojan Deraji\\'c, Sebastian Bernhard, Wolfgang H\\\"onig","raw_content_length":1143,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Hamilton-Jacobi"],"persons":[],"locations":[],"monetary":[]},"char_count":1142,"language_detected":"en","key_concepts":{"key_phrases":["ORN","CBFs","arXiv250916614v2 Announce Type","Abstract","Control barrier functions","an effective method","safety-critical control","autonomous systems","their design","the development"],"filter_categories":{"engineering":["the development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ORN":2.0,"CBFs":2.0,"arXiv250916614v2 Announce Type":1.0,"Abstract":1.0,"Control barrier functions":1.0,"an effective method":1.0,"safety-critical control":1.0,"autonomous systems":1.0,"their design":1.0,"the development":1.0}},"age_hours":2.770204341111111,"is_recent":true,"quality_score":0.7,"sentiment_score":9.1355,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8271,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9085,"joy":0.0086,"surprise":0.0121,"sadness":0.0075,"fear":0.0347,"anger":0.0179,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a learning-based approach to improve the safety of autonomous systems, specifically ground robots and quadcopters, which could indirectly reduce energy consumption by optimizing routes and preventing accidents. The method is examined in simulation and hardware experiments, showing improved success rates. However, the direct climate impact is not quantified, and economic viability is not addressed.","key_impact_metrics":["Improved success rates","Generalization to out-of-domain environments"],"technology_tags":["Control barrier functions","Neural networks","Autonomous systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:07.719933Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d41e750421d8","title":"Temporal Logic-Based Multi-Vehicle Backdoor Attacks against Offline RL Agents in End","content":"arXiv:2509.16950v2 Announce Type: replace Abstract: Assessing the safety of autonomous driving (AD) systems against security threats, particularly backdoor attacks, is a stepping stone for real-world deployment. However, existing works mainly focus on pixel-level triggers that are impractical to deploy in the real world. We address this gap by introducing a novel backdoor attack against the end-to-end AD systems that leverage one or more other vehicles' trajectories as triggers. To generate precise trigger trajectories, we first use temporal logic (TL) specifications to define the behaviors of attacker vehicles. Configurable behavior models are then used to generate these trajectories, which are quantitatively evaluated and iteratively refined based on the TL specifications. We further develop a negative training strategy by incorporating patch trajectories that are similar to triggers but are designated not to activate the backdoor. It enhances the stealthiness of the attack and refines the system's responses to trigger scenarios. Through extensive experiments on 5 offline reinforcement learning (RL) driving agents with 6 trigger patterns and target action combinations, we demonstrate the flexibility and effectiveness of our proposed attack, showing the under-exploration of existing end-to-end AD systems' vulnerabilities to such trajectory-based backdoor attacks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.16950","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.278040","language":"en","tags":["preprints","research","computer-science","cscr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Xuan Chen, Shiwei Feng, Zikang Xiong, Shengwei An, Yunshu Mao, Lu Yan, Guanhong Tao, Wenbo Guo, Xiangyu Zhang","raw_content_length":1387,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1386,"language_detected":"en","key_concepts":{"key_phrases":["Temporal Logic-Based Multi-Vehicle Backdoor Attacks","Offline RL Agents","End","arXiv250916950v2 Announce Type","Abstract","the safety","autonomous driving AD systems","security threats","particularly backdoor attacks","a stepping stone"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Temporal Logic-Based Multi-Vehicle Backdoor Attacks":2.0,"Offline RL Agents":2.0,"End":2.0,"arXiv250916950v2 Announce Type":1.0,"Abstract":1.0,"the safety":1.0,"autonomous driving AD systems":1.0,"security threats":1.0,"particularly backdoor attacks":1.0,"a stepping stone":1.0}},"age_hours":2.7702197155555557,"is_recent":true,"quality_score":0.7,"sentiment_score":1.4175,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7165,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7447,"joy":0.0073,"surprise":0.0297,"sadness":0.01,"fear":0.1596,"anger":0.0322,"disgust":0.0164},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on backdoor attacks against autonomous driving systems, specifically offline reinforcement learning agents. While the research itself is technically sound and uses quantitative evaluation, it is still in the early stages of development and does not directly address climate impact or sustainability. The experiments are conducted on simulated driving agents, not deployed systems.","key_impact_metrics":["effectiveness of attack with 6 trigger patterns","performance of 5 offline RL driving agents"],"technology_tags":["autonomous driving","reinforcement learning","cybersecurity","temporal logic"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:16.857461Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f5a042264682","title":"EpiCache: Episodic KV Cache Management for Long Conversational Question Answering","content":"arXiv:2509.17396v3 Announce Type: replace Abstract: Modern large language models (LLMs) extend context lengths to millions of tokens, enabling coherent, personalized responses grounded in long conversational histories. This ability, however, hinges on Key-Value (KV) caching, whose memory grows linearly with dialogue length and quickly becomes the bottleneck in resource-constrained environments. An active line of research for reducing memory bottleneck is KV cache compression, which seeks to limit cache size while preserving accuracy. Yet existing methods face two major limitations: (i) evicting the KV cache after full-context prefill causes unbounded peak memory, and (ii) query-dependent eviction narrows the cache to a single query, leading to failure cases in multi-turn conversations. We introduce EpiCache, a training-free KV cache management framework for long conversational question answering (LongConvQA) under fixed memory budgets. EpiCache bounds cache growth through block-wise prefill and preserves topic-relevant context via episodic KV compression, which clusters conversation history into coherent episodes and applies episode-specific KV cache eviction. We further design an adaptive layer-wise budget allocation strategy that measures each layer's sensitivity to eviction and distributes the memory budget across layers accordingly. Across three LongConvQA benchmarks, EpiCache improves accuracy by up to 40%, maintains near-full KV accuracy under 4-6x compression, and reduces latency/memory by up to 2.4x/3.5x, enabling efficient multi-turn interaction under strict resource limits. Our code is available at https://github.com/apple/ml-epicache.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.17396","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.278438","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Minsoo Kim, Arnav Kundu, Han-Byul Kim, Richa Dixit, Minsik Cho","raw_content_length":1674,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["Key-Value","EpiCache","LongConv"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1673,"language_detected":"en","key_concepts":{"key_phrases":["EpiCache","Episodic KV Cache Management","Long Conversational Question Answering","arXiv250917396v3 Announce Type","Abstract","Modern large language models","LLMs","context lengths","millions","tokens"],"filter_categories":{"ai_ml":["Modern large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EpiCache":2.0,"Episodic KV Cache Management":2.0,"Long Conversational Question Answering":2.0,"arXiv250917396v3 Announce Type":1.0,"Abstract":1.0,"Modern large language models":1.0,"LLMs":1.0,"context lengths":1.0,"millions":1.0,"tokens":1.0}},"age_hours":2.7702352669444443,"is_recent":true,"quality_score":1.0,"sentiment_score":8.603000000000002,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7206,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8999,"joy":0.0054,"surprise":0.0169,"sadness":0.0041,"fear":0.0417,"anger":0.0184,"disgust":0.0135},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel KV cache management framework (EpiCache) that reduces memory and latency in large language models, potentially enabling more efficient AI applications. The framework achieves up to 40% accuracy improvement and reduces latency/memory by up to 2.4x/3.5x. While promising, it is currently in the applied research stage with no mention of deployed units or real-world applications beyond benchmarks.","key_impact_metrics":["accuracy improvement by up to 40%","latency reduction by up to 2.4x"],"technology_tags":["KV cache compression","large language models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:20.600252Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_87702e03be52","title":"A Comparative Study of Different Edit Distance","content":"arXiv:2509.17974v2 Announce Type: replace Abstract: Feature tracking in time-varying scalar fields is a fundamental task in scientific computing. Topological descriptors, which summarize important features of data, have proved to be viable tools to facilitate this task. The merge tree is a topological descriptor that captures the connectivity behaviors of the sub- or superlevel sets of a scalar field. Edit distances between merge trees play a vital role in effective temporal data tracking. Existing methods to compute them fall into two main classes, namely whether they are dependent or independent of the branch decomposition. These two classes represent the most prominent approaches for producing tracking results. In this paper, we compare four different merge tree edit distance-based methods for feature tracking. We demonstrate that these methods yield distinct results with both analytical and real-world data sets. Furthermore, we investigate how these results vary and identify the factors that influence them. Our experiments reveal significant differences in tracked features over time, even among those produced by techniques within the same category.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.17974","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.278839","language":"en","tags":["research","csgr","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Son Le Thanh, Tino Weinkauf","raw_content_length":1171,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1170,"language_detected":"en","key_concepts":{"key_phrases":["A Comparative Study","Different Edit Distance","arXiv250917974v2","Announce Type","Abstract","time-varying scalar fields","a fundamental task","scientific computing","Topological descriptors","which"],"filter_categories":{"research_academic":["A Comparative Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Comparative Study":2.0,"Different Edit Distance":2.0,"arXiv250917974v2":1.0,"Announce Type":1.0,"Abstract":1.0,"time-varying scalar fields":1.0,"a fundamental task":1.0,"scientific computing":1.0,"Topological descriptors":1.0,"which":1.0}},"age_hours":2.770250205555555,"is_recent":true,"quality_score":0.7,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9114,"joy":0.017,"surprise":0.0416,"sadness":0.0047,"fear":0.0127,"anger":0.0074,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper compares different methods for feature tracking in time-varying scalar fields, specifically focusing on merge tree edit distances. While the research is scientifically sound and uses real-world datasets, it's in an early stage (applied research) and doesn't directly translate to concrete climate action or measurable outcomes in terms of GHG reduction or other sustainability metrics. The impact is indirect, potentially improving scientific computing related to climate data analysis.","key_impact_metrics":["Differences in tracked features over time"],"technology_tags":["feature tracking","merge tree edit distance","topological descriptors"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:34.836700Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f82c97a7e549","title":"Prompt Optimization Meets Subspace Representation Learning for Few-shot Out","content":"arXiv:2509.18111v2 Announce Type: replace Abstract: The reliability of artificial intelligence (AI) systems in open-world settings depends heavily on their ability to flag out-of-distribution (OOD) inputs unseen during training. Recent advances in large-scale vision-language models (VLMs) have enabled promising few-shot OOD detection frameworks using only a handful of in-distribution (ID) samples. However, existing prompt learning-based OOD methods rely solely on softmax probabilities, overlooking the rich discriminative potential of the feature embeddings learned by VLMs trained on millions of samples. To address this limitation, we propose a novel context optimization (CoOp)-based framework that integrates subspace representation learning with prompt tuning. Our approach improves ID-OOD separability by projecting the ID features into a subspace spanned by prompt vectors, while projecting ID-irrelevant features into an orthogonal null space. To train such OOD detection framework, we design an easy-to-handle end-to-end learning criterion that ensures strong OOD detection performance as well as high ID classification accuracy. Experiments on real-world datasets showcase the effectiveness of our approach.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.18111","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.279229","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Faizul Rakib Sayem, Shahana Ibrahim","raw_content_length":1223,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1222,"language_detected":"en","key_concepts":{"key_phrases":["Prompt Optimization","Subspace Representation Learning","Few-shot","distribution","arXiv250918111v2 Announce Type","Abstract","The reliability","artificial intelligence AI systems","open-world settings","their ability"],"filter_categories":{"ai_ml":["artificial intelligence AI systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Prompt Optimization":2.0,"Subspace Representation Learning":2.0,"Few-shot":2.0,"distribution":2.0,"arXiv250918111v2 Announce Type":1.0,"Abstract":1.0,"The reliability":1.0,"artificial intelligence AI systems":1.0,"open-world settings":1.0,"their ability":1.0}},"age_hours":2.7702657230555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.329,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8658,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9002,"joy":0.0226,"surprise":0.0468,"sadness":0.0049,"fear":0.0104,"anger":0.0097,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for improving the reliability of AI systems in identifying out-of-distribution inputs. While it shows promise in improving ID-OOD separability, it is still in the early stages of development, with experiments on real-world datasets but no deployed units or operational data to demonstrate concrete climate impact. The vaporware flag is set because it is an early-stage concept.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Machine Learning","Out-of-Distribution Detection"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:47.655205Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8934163fa165","title":"FedIA: A Plug-and-Play Importance","content":"arXiv:2509.18171v2 Announce Type: replace Abstract: Federated Graph Learning (FGL) under domain skew -- as observed on platforms such as \\emph{Twitch Gamers} and multilingual \\emph{Wikipedia} networks -- drives client models toward incompatible representations, rendering naive aggregation both unstable and ineffective. We find that the culprit is not the weighting scheme but the \\emph{noisy gradient signal}: empirical analysis of baseline methods suggests that a vast majority of gradient dimensions can be dominated by domain-specific variance. We therefore shift focus from \"aggregation-first\" to a \\emph{projection-first} strategy that denoises client updates \\emph{before} they are combined. The proposed FedIA framework realises this \\underline{I}mportance-\\underline{A}ware idea through a two-stage, plug-and-play pipeline: (i) a server-side top-$\\rho$ mask keeps only the most informative about 5% of coordinates, and (ii) a lightweight influence-regularised momentum weight suppresses outlier clients. FedIA adds \\emph{no extra uplink traffic and only negligible server memory}, making it readily deployable. On both homogeneous (Twitch Gamers) and heterogeneous (Wikipedia) graphs, it yields smoother, more stable convergence and higher final accuracy than nine strong baselines. A convergence sketch further shows that dynamic projection maintains the optimal $\\mathcal{O}(\\sigma^{2}/\\sqrt{T})$ rate.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.18171","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.279654","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Zhanting Zhou, KaHou Tam, Zeqin Wu, Pengzhao Sun, Jinbo Wang, Fengli Zhang","raw_content_length":1415,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["FedIA","Federated Graph Learning"],"persons":["FedIA","\\emph{noisy"],"locations":[],"monetary":[]},"char_count":1414,"language_detected":"en","key_concepts":{"key_phrases":["FedIA","A Plug-and-Play Importance","arXiv250918171v2","Announce Type","Abstract","Federated Graph Learning","FGL","domain skew","platforms","emphTwitch Gamers"],"filter_categories":{"ai_ml":["domain skew"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FedIA":2.0,"A Plug-and-Play Importance":2.0,"arXiv250918171v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Federated Graph Learning":1.0,"FGL":1.0,"domain skew":1.0,"platforms":1.0,"emphTwitch Gamers":1.0}},"age_hours":2.7702810894444445,"is_recent":true,"quality_score":1.0,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6668,"joy":0.0052,"surprise":0.0512,"sadness":0.0738,"fear":0.023,"anger":0.0921,"disgust":0.088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel federated learning framework (FedIA) that improves the stability and accuracy of graph learning models in distributed settings. While the framework shows promise in improving model performance, it is currently in the applied research stage with no evidence of real-world deployment or quantifiable environmental impact. The vaporware flag is raised due to the lack of deployed units and operational data.","key_impact_metrics":["5% of coordinates kept","O(sigma^{2}/sqrt{T}) rate"],"technology_tags":["Federated Learning","Graph Neural Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:49:58.344762Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5908963f0892","title":"Large Language Models and Operations Research: A Structured Survey","content":"arXiv:2509.18180v2 Announce Type: replace Abstract: Operations research (OR) provides fundamental methodologies for complex system decision-making, with established applications in transportation, supply chain management, and production scheduling. Traditional approaches, which depend on expert-based modeling and manual parameter adjustment, often face challenges in handling large-scale, dynamic, and multi-constraint problems. Recently, large language models (LLMs) have shown potential to address these limitations through semantic understanding, structured generation, and reasoning control. LLMs can translate natural language descriptions into mathematical models or executable code, generate heuristics, evolve algorithms, and directly tackle optimization tasks. This paper surveys recent progress on the integration of LLMs into OR, organizing methods into three main directions: automatic modeling, auxiliary optimization, and direct solving. It further reviews evaluation benchmarks and domain-specific applications, and summarizes key open issues such as unstable semantic-to-structure mapping, fragmented research progress, limited generalization, and insufficient evaluation systems. Finally, the survey outlines possible research avenues for advancing the role of LLMs in OR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.18180","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.280040","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Yang Wang, Kai Li","raw_content_length":1292,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1291,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models and Operations Research","A Structured Survey","arXiv250918180v2 Announce Type","Abstract","Operations research","fundamental methodologies","complex system decision-making","established applications","transportation","supply chain management"],"filter_categories":{"ai_ml":["Large Language Models and Operations Research"],"research_academic":["Large Language Models and Operations Research","Operations research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models and Operations Research":2.0,"A Structured Survey":2.0,"arXiv250918180v2 Announce Type":1.0,"Abstract":1.0,"Operations research":1.0,"fundamental methodologies":1.0,"complex system decision-making":1.0,"established applications":1.0,"transportation":1.0,"supply chain management":1.0}},"age_hours":2.7702957302777778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7206,"joy":0.0103,"surprise":0.0473,"sadness":0.021,"fear":0.1724,"anger":0.0211,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This survey paper explores the potential of LLMs in operations research, specifically in areas like automatic modeling and optimization. While the paper itself doesn't present concrete deployments or measured outcomes, it reviews research that could lead to more efficient resource allocation and potentially reduce emissions in sectors like transportation and supply chain. The research is still in early stages, with challenges in generalization and evaluation.","key_impact_metrics":[],"technology_tags":["Large Language Models","Operations Research","Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:50:01.526878Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fb136a2c00e1","title":"Part","content":"arXiv:2509.19343v3 Announce Type: replace Abstract: This paper investigates part-of-speech tagging, an important task in Natural Language Processing (NLP) for the Nagamese language. The Nagamese language, a.k.a. Naga Pidgin, is an Assamese-lexified Creole language developed primarily as a means of communication in trade between the Nagas and people from Assam in northeast India. A substantial amount of work in part-of-speech-tagging has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in the Nagamese language. To the best of our knowledge, this is the first attempt at part-of-speech tagging for the Nagamese Language. The aim of this work is to identify the part-of-speech for a given sentence in the Nagamese language. An annotated corpus of 16,112 tokens is created and applied machine learning technique known as Conditional Random Fields (CRF). Using CRF, an overall tagging accuracy of 85.70%; precision, recall of 86%, and f1-score of 85% is achieved. Keywords. Nagamese, NLP, part-of-speech, machine learning, CRF.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.19343","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.280827","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Alovi N Shohe, Chonglio Khiamungam, Teisovi Angami","raw_content_length":1077,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["NLP","Conditional Random Fields","Natural Language Processing","Nagas"],"persons":["Naga Pidgin"],"locations":["India","Hindi","Assam"],"monetary":[]},"char_count":1074,"language_detected":"en","key_concepts":{"key_phrases":["Part","arXiv250919343v3 Announce Type","Abstract","This paper","speech","an important task","Natural Language Processing","NLP","the Nagamese language","The Nagamese language"],"filter_categories":{"ai_ml":["Natural Language Processing"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Part":2.0,"arXiv250919343v3 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"speech":1.0,"an important task":1.0,"Natural Language Processing":1.0,"NLP":1.0,"the Nagamese language":1.0,"The Nagamese language":1.0}},"age_hours":2.7703264366666667,"is_recent":true,"quality_score":0.7,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8384,"joy":0.0682,"surprise":0.0679,"sadness":0.0083,"fear":0.0055,"anger":0.0083,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on part-of-speech tagging for the Nagamese language, a task within Natural Language Processing. While the research itself doesn't directly impact climate or sustainability, it contributes to the preservation and understanding of a language, which can indirectly support cultural sustainability. The concrete action is the creation of an annotated corpus and the application of machine learning techniques, resulting in a tagging accuracy of 85.70%.","key_impact_metrics":["Tagging accuracy: 85.70%","Corpus size: 16,112 tokens"],"technology_tags":["NLP","Machine Learning","CRF"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:50:11.781336Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7f2e618f7b2f","title":"Tree Search for LLM Agent Reinforcement Learning","content":"arXiv:2509.21240v2 Announce Type: replace Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs). In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision. To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step. By sharing common prefixes, the tree search sampling increases the number of rollouts achievable within a fixed budget of tokens or tool calls. Moreover, we find that the tree-structured trajectory naturally allows the construction of step-wise process supervised signals even using only the outcome reward. Based on this, Tree-GRPO estimates the grouped relative advantages both on intra-tree and inter-tree levels. Through theoretical analysis, we demonstrate that the objective of intra-tree level group relative policy optimization is equivalent to that of step-level direct preference learning. Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.21240","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.281218","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Yuxiang Ji, Ziyu Ma, Yong Wang, Guanhua Chen, Xiangxiang Chu, Liaoni Wu","raw_content_length":1290,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Tree-GRPO","Group Relative Policy Optimization","Tree"],"persons":[],"locations":[],"monetary":[]},"char_count":1289,"language_detected":"en","key_concepts":{"key_phrases":["Tree Search","LLM Agent Reinforcement Learning","arXiv250921240v2 Announce Type","Abstract","Recent advances","reinforcement learning","the agentic capabilities","large language models","LLMs","long-term and multi-turn agent tasks"],"filter_categories":{"ai_ml":["LLM Agent Reinforcement Learning","reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tree Search":2.0,"LLM Agent Reinforcement Learning":2.0,"arXiv250921240v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"reinforcement learning":1.0,"the agentic capabilities":1.0,"large language models":1.0,"LLMs":1.0,"long-term and multi-turn agent tasks":1.0}},"age_hours":2.7703417344444445,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.86,"joy":0.0064,"surprise":0.0259,"sadness":0.0448,"fear":0.0202,"anger":0.0222,"disgust":0.0205},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel tree-based reinforcement learning method (Tree-GRPO) for LLM agents, aiming to improve performance in long-term tasks. While the research is theoretically sound and demonstrates superiority over chain-based RL in experiments, it remains at the research stage with no concrete deployment or measurable impact on sustainability. The potential climate impact is currently theoretical and unquantified.","key_impact_metrics":[],"technology_tags":["reinforcement learning","large language models","tree search"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:50:14.759021Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4c0f41a6e832","title":"Question","content":"arXiv:2509.22211v2 Announce Type: replace Abstract: Unsupervised analysis of text corpora is challenging, especially in data-scarce domains where traditional topic models struggle. While these models offer a solution, they typically describe clusters with lists of keywords that require significant manual effort to interpret and often lack semantic coherence. To address this critical interpretability gap, we introduce Recursive Thematic Partitioning (RTP), a novel framework that leverages Large Language Models (LLMs) to interactively build a binary tree. Each node in the tree is a natural language question that semantically partitions the data, resulting in a fully interpretable taxonomy where the logic of each cluster is explicit. Our experiments demonstrate that RTP's question-driven hierarchy is more interpretable than the keyword-based topics from a strong baseline like BERTopic. Furthermore, we establish the quantitative utility of these clusters by showing they serve as powerful features in downstream classification tasks, particularly when the data's underlying themes correlate with the task labels. RTP introduces a new paradigm for data exploration, shifting the focus from statistical pattern discovery to knowledge-driven thematic analysis. Furthermore, we demonstrate that the thematic paths from the RTP tree can serve as structured, controllable prompts for generative models. This transforms our analytical framework into a powerful tool for synthesis, enabling the consistent imitation of specific characteristics discovered in the source corpus.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22211","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.281648","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Tiago Fernandes Tavares","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":["RTP"],"persons":["Large Language Models"],"locations":["BERTopic"],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["Question","arXiv250922211v2 Announce Type","Abstract","Unsupervised analysis","text corpora","data-scarce domains","traditional topic models","these models","a solution","clusters"],"filter_categories":{"ai_ml":["data-scarce domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Question":2.0,"arXiv250922211v2 Announce Type":1.0,"Abstract":1.0,"Unsupervised analysis":1.0,"text corpora":1.0,"data-scarce domains":1.0,"traditional topic models":1.0,"these models":1.0,"a solution":1.0,"clusters":1.0}},"age_hours":2.770356408888889,"is_recent":true,"quality_score":1.0,"sentiment_score":4.71,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.058,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8677,"joy":0.0067,"surprise":0.0537,"sadness":0.0116,"fear":0.0377,"anger":0.0139,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (RTP) for unsupervised text analysis using LLMs. While it demonstrates improved interpretability and utility in downstream tasks, it is still in the applied research phase with no concrete deployment or measurable climate impact. The vaporware flag is raised because it describes a framework with experiments, but no real-world deployment.","key_impact_metrics":["Interpretability improvement vs BERTopic","Performance in downstream classification tasks"],"technology_tags":["Large Language Models","Text Analysis","Unsupervised Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:50:17.931047Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f6dc0d557cc2","title":"IIET: Efficient Numerical Transformer via Implicit Iterative Euler Method","content":"arXiv:2509.22463v2 Announce Type: replace Abstract: High-order numerical methods enhance Transformer performance in tasks like NLP and CV, but introduce a performance-efficiency trade-off due to increased computational overhead. Our analysis reveals that conventional efficiency techniques, such as distillation, can be detrimental to the performance of these models, exemplified by PCformer. To explore more optimizable ODE-based Transformer architectures, we propose the Iterative Implicit Euler Transformer (IIET), which simplifies high-order methods using an iterative implicit Euler approach. This simplification not only leads to superior performance but also facilitates model compression compared to PCformer. To enhance inference efficiency, we introduce Iteration Influence-Aware Distillation (IIAD). Through a flexible threshold, IIAD allows users to effectively balance the performance-efficiency trade-off. On lm-evaluation-harness, IIET boosts average accuracy by 2.65% over vanilla Transformers and 0.8% over PCformer. Its efficient variant, E-IIET, significantly cuts inference overhead by 55% while retaining 99.4% of the original task accuracy. Moreover, the most efficient IIET variant achieves an average performance gain exceeding 1.6% over vanilla Transformer with comparable speed.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22463","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.282039","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Xinyu Liu, Bei Li, Jiahao Liu, Junhao Ruan, Kechen Jiao, Hongyin Tang, Jingang Wang, Xiao Tong, Jingbo Zhu","raw_content_length":1305,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["Iteration Influence-Aware Distillation","Implicit Iterative Euler Method arXiv:2509.22463v2","NLP","the Iterative Implicit Euler Transformer","Transformer","Efficient Numerical Transformer"],"persons":["Euler","PCformer"],"locations":[],"monetary":[]},"char_count":1304,"language_detected":"en","key_concepts":{"key_phrases":["Implicit Iterative Euler Method","arXiv250922463v2 Announce Type","Abstract","High-order numerical methods","Transformer performance","tasks","NLP","a performance-efficiency trade-off","increased computational overhead","Our analysis"],"filter_categories":{"ai_ml":["NLP"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Implicit Iterative Euler Method":2.0,"arXiv250922463v2 Announce Type":1.0,"Abstract":1.0,"High-order numerical methods":1.0,"Transformer performance":1.0,"tasks":1.0,"NLP":1.0,"a performance-efficiency trade-off":1.0,"increased computational overhead":1.0,"Our analysis":1.0}},"age_hours":2.7703711055555553,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8201,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7865,"joy":0.0263,"surprise":0.0339,"sadness":0.0469,"fear":0.0158,"anger":0.04,"disgust":0.0507},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel transformer architecture (IIET) that improves efficiency and performance in NLP and CV tasks. It reports a 2.65% accuracy boost over vanilla Transformers and a 55% reduction in inference overhead. However, it's still in the research phase with no deployed units, hence the low deployment readiness score.","key_impact_metrics":["2.65% accuracy boost","55% inference overhead reduction"],"technology_tags":["Transformer architecture","Iterative Implicit Euler Method","Model compression","Iteration Influence-Aware Distillation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:50:27.299419Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7558c0076499","title":"Coordination Requires Simplification: Thermodynamic Bounds on Multi","content":"arXiv:2509.23144v2 Announce Type: replace Abstract: Information-processing systems coordinating across multiple agents and objectives face fundamental thermodynamic constraints. We show that solutions with maximum utility to act as coordination focal points have much higher selection pressure for being findable across agents rather than accuracy. We derive that the information-theoretic minimum description length of coordination protocols to precision $\\varepsilon$ scales as $L(P)\\geq NK\\log_2 K+N^2d^2\\log (1/\\varepsilon)$ for $N$ agents with $d$ potentially conflicting objectives and internal model complexity $K$. This scaling forces progressive simplification, with coordination dynamics changing the environment itself and shifting optimization across hierarchical levels. Moving from established focal points requires re-coordination, creating persistent metastable states and hysteresis until significant environmental shifts trigger phase transitions through spontaneous symmetry breaking. We operationally define coordination temperature to predict critical phenomena and estimate coordination work costs, identifying measurable signatures across systems from neural networks to restaurant bills to bureaucracies. Extending the topological version of Arrow's theorem on the impossibility of consistent preference aggregation, we find it recursively binds whenever preferences are combined. This potentially explains the indefinite cycling in multi-objective gradient descent and alignment faking in Large Language Models trained with reinforcement learning with human feedback. We term this framework Thermodynamic Coordination Theory (TCT), which demonstrates that coordination requires radical information loss.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23144","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.282863","language":"en","tags":["physicssoc-ph","csma","csai","nlinao","preprints","research","cond-matstat-mech","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Atma Anand","raw_content_length":1729,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["\\varepsilon$"],"locations":[],"monetary":["$L(P)\\geq NK\\log_2"]},"char_count":1728,"language_detected":"en","key_concepts":{"key_phrases":["Coordination","Simplification","Thermodynamic Bounds","Multi","arXiv250923144v2","Announce Type","Abstract","Information-processing systems","multiple agents","objectives"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Coordination":2.0,"Simplification":2.0,"Thermodynamic Bounds":2.0,"Multi":2.0,"arXiv250923144v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Information-processing systems":1.0,"multiple agents":1.0,"objectives":1.0}},"age_hours":2.7703990933333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8073,"joy":0.0112,"surprise":0.0124,"sadness":0.0091,"fear":0.0806,"anger":0.0484,"disgust":0.0311},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This theoretical research explores thermodynamic constraints on coordination in multi-agent systems, deriving a scaling law for the minimum description length of coordination protocols. While it identifies measurable signatures across systems, including potential applications to LLMs and bureaucracies, it remains at a basic research stage with no deployed technology or concrete emissions reductions demonstrated. The vaporware flag is raised because the research is theoretical and lacks deployment.","key_impact_metrics":["L(P) scales as NKlog2K+N^2d^2log (1/)"],"technology_tags":["Thermodynamic Coordination Theory","Information Theory","Multi-Agent Systems"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:50:47.490832Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2936811cd5db","title":"WavJEPA: Semantic learning unlocks robust audio foundation models for raw waveforms","content":"arXiv:2509.23238v2 Announce Type: replace Abstract: Learning audio representations from raw waveforms overcomes key limitations of spectrogram-based audio representation learning, such as the long latency of spectrogram computation and the loss of phase information. Yet, while self-supervised speech representation learning from raw waveforms has been remarkably successful, these approaches have not achieved similar feats for general-purpose audio representation learning from waveforms. Here, we propose WavJEPA, a waveform-based version of the Joint-Embedding Predictive Architecture. WavJEPA leverages high-level semantic representation learning to tackle the shortcomings of representation learning at the speech unit or token level. We show that this approach substantially outperforms state-of-the-art time-domain audio foundation models across a wide variety of downstream benchmark tasks, while requiring considerably fewer computational resources. Additionally, to overcome the performance drop that time-domain models typically exhibit in noisy and reverberant real-world acoustic environments, we present WavJEPA-Nat. WavJEPA-Nat is a multi-channel extension of the WavJEPA architecture trained on simulated naturalistic scenes. We find that WavJEPA-Nat is highly robust to reverberation and noise. These results highlight the feasibility and computational efficiency of general-purpose audio representation learning from raw waveforms, showcasing the potential for low-latency, robust time-domain audio foundation models for real-world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23238","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.283261","language":"en","tags":["eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Goksenin Yuksel, Pierre Guetschel, Michael Tangermann, Marcel van Gerven, Kiki van der Heijden","raw_content_length":1565,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["the Joint-Embedding Predictive Architecture"],"persons":[],"locations":[],"monetary":[]},"char_count":1564,"language_detected":"en","key_concepts":{"key_phrases":["raw waveforms","WavJEPA","Semantic learning","robust audio foundation models","arXiv250923238v2 Announce Type","Abstract","audio representations","key limitations","spectrogram-based audio representation learning","the long latency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"raw waveforms":4.0,"WavJEPA":2.0,"Semantic learning":2.0,"robust audio foundation models":2.0,"arXiv250923238v2 Announce Type":1.0,"Abstract":1.0,"audio representations":1.0,"key limitations":1.0,"spectrogram-based audio representation learning":1.0,"the long latency":1.0}},"age_hours":2.7704137255555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.180499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6361,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7699,"joy":0.0476,"surprise":0.1294,"sadness":0.0121,"fear":0.0157,"anger":0.0179,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel audio representation learning model (WavJEPA) that requires fewer computational resources than existing methods. While it outperforms state-of-the-art models on benchmark tasks, it is still in the early stages of development with no deployed units or operational data. The potential climate impact is indirect, stemming from reduced computational needs, but is not quantified.","key_impact_metrics":["Computational resources reduction"],"technology_tags":["audio representation learning","machine learning","waveform processing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:50:52.806949Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_682724850518","title":"Graph Your Own Prompt","content":"arXiv:2509.23373v2 Announce Type: replace Abstract: We propose Graph Consistency Regularization (GCR), a novel framework that injects relational graph structures, derived from model predictions, into the learning process to promote class-aware, semantically meaningful feature representations. Functioning as a form of self-prompting, GCR enables the model to refine its internal structure using its own outputs. While deep networks learn rich representations, these often capture noisy inter-class similarities that contradict the model's predicted semantics. GCR addresses this issue by introducing parameter-free Graph Consistency Layers (GCLs) at arbitrary depths. Each GCL builds a batch-level feature similarity graph and aligns it with a global, class-aware masked prediction graph, derived by modulating softmax prediction similarities with intra-class indicators. This alignment enforces that feature-level relationships reflect class-consistent prediction behavior, acting as a semantic regularizer throughout the network. Unlike prior work, GCR introduces a multi-layer, cross-space graph alignment mechanism with adaptive weighting, where layer importance is learned from graph discrepancy magnitudes. This allows the model to prioritize semantically reliable layers and suppress noisy ones, enhancing feature quality without modifying the architecture or training procedure. GCR is model-agnostic, lightweight, and improves semantic structure across various networks and datasets. Experiments show that GCR promotes cleaner feature structure, stronger intra-class cohesion, and improved generalization, offering a new perspective on learning from prediction structure. [Project website](https://darcyddx.github.io/gcr/) [Code](https://github.com/Darcyddx/graph-prompt)","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23373","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.284086","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Xi Ding, Lei Wang, Piotr Koniusz, Yongsheng Gao","raw_content_length":1782,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1781,"language_detected":"en","key_concepts":{"key_phrases":["Graph","Your Own Prompt","GCR","arXiv250923373v2 Announce Type","Abstract","Graph Consistency Regularization","a novel framework","relational graph structures","model predictions","the learning process"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Graph":2.0,"Your Own Prompt":2.0,"GCR":2.0,"arXiv250923373v2 Announce Type":1.0,"Abstract":1.0,"Graph Consistency Regularization":1.0,"a novel framework":1.0,"relational graph structures":1.0,"model predictions":1.0,"the learning process":1.0}},"age_hours":2.7704435036111112,"is_recent":true,"quality_score":0.7,"sentiment_score":9.221,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8442,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9559,"joy":0.0074,"surprise":0.0193,"sadness":0.0027,"fear":0.0044,"anger":0.0079,"disgust":0.0025},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel machine learning framework (GCR) to improve model accuracy. While it could potentially improve the efficiency of models used in climate-related applications, there are no concrete actions or measurable outcomes related to GHG emissions reduction or climate adaptation. It is currently in the basic research stage with no deployment.","key_impact_metrics":[],"technology_tags":["machine learning","graph neural networks","artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:50:59.572126Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d5b381df2e85","title":"Navigating the Labyrinth: Path","content":"arXiv:2509.23812v2 Announce Type: replace Abstract: Unit testing is essential for software quality assurance, yet writing and maintaining tests remains time-consuming and error-prone. To address this challenge, researchers have proposed various techniques for automating unit test generation, including traditional heuristic-based methods and more recent approaches that leverage large language models (LLMs). However, these existing approaches are inherently path-insensitive because they rely on fixed heuristics or limited contextual information and fail to reason about deep control-flow structures. As a result, they often struggle to achieve adequate coverage, particularly for deep or complex execution paths. In this work, we present a path-sensitive framework, JUnitGenie, to fill this gap by combining code knowledge with the semantic capabilities of LLMs in guiding context-aware unit test generation. After extracting code knowledge from Java projects, JUnitGenie distills this knowledge into structured prompts to guide the generation of high-coverage unit tests. We evaluate JUnitGenie on 2,258 complex focal methods from ten real-world Java projects. The results show that JUnitGenie generates valid tests and improves branch and line coverage by 29.60% and 31.00% on average over both heuristic and LLM-based baselines. We further demonstrate that the generated test cases can uncover real-world bugs, which were later confirmed and fixed by developers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23812","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.285708","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Dianshu Liao, Xin Yin, Shidong Pan, Chao Ni, Zhenchang Xing, Xiaoyu Sun","raw_content_length":1470,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["JUni"],"persons":["Java"],"locations":[],"monetary":[]},"char_count":1469,"language_detected":"en","key_concepts":{"key_phrases":["the Labyrinth","arXiv250923812v2","Announce Type","Abstract","Unit testing","software quality assurance","tests","this challenge","researchers","various techniques"],"filter_categories":{"research_academic":["researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Labyrinth":2.0,"arXiv250923812v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Unit testing":1.0,"software quality assurance":1.0,"tests":1.0,"this challenge":1.0,"researchers":1.0,"various techniques":1.0}},"age_hours":2.770502114166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.083,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4166,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.903,"joy":0.0036,"surprise":0.0172,"sadness":0.0228,"fear":0.0352,"anger":0.0113,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new framework, JUnitGenie, for automated unit test generation that improves branch and line coverage. While the research is promising and demonstrates improved coverage metrics, it is still in the applied research stage with no deployment. The potential climate impact is indirect, related to improving software quality which could contribute to more efficient resource use in software applications, but this is not directly measured or quantified.","key_impact_metrics":["branch coverage improvement by 29.60%","line coverage improvement by 31.00%"],"technology_tags":["automated unit test generation","large language models","software testing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:51:09.055733Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b747149a645b","title":"Rethinking Reward Miscalibration of GRPO in Agentic RL","content":"arXiv:2509.23870v2 Announce Type: replace Abstract: Building autonomous agents capable of solving long-horizon, real-world tasks has garnered significant research interest. But outcome based rewards may cause reward miscalibration which means it might mistakenly allocate positive reward to flawed middle steps which is regarded as the key reason making the bad actions being reinforced during training. However we reveal that outcome based reward ensures expected negative advantage for those flawed middle steps, which means the flawed actions should be punished during training. Even accounting for the ``squeezing effect\", the probability mass of good actions should increase and the actor should gradually get rid of harmful actions. This shows that flawed actions should be punished during training. We further identify gradient coupling between similar samples as a key issue in agentic RL, the input prompt is extremely similar and the output action space is limited, therefore during training, gradients from well-performing samples can inadvertently strengthen suboptimal or incorrect actions due to similar input observation and output actions. We show that with gradient coupling, some flawed actions might be enhanced. To address this, we propose training the actor to classify good or bad actions to separate the embedding of good/bad actions and alleviate the gradient interference, extensive experiments shows its effectiveness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23870","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.286104","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Jingyu Liu, Xiaopeng Wu, Jingquan Peng, Kehan Chen, Chuan Yu, Lizhong Ding, Yong Liu","raw_content_length":1445,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1444,"language_detected":"en","key_concepts":{"key_phrases":["Reward Miscalibration","GRPO","Agentic RL","which","arXiv250923870v2 Announce Type","Abstract","autonomous agents","long-horizon","real-world tasks","significant research interest"],"filter_categories":{"research_academic":["significant research interest"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reward Miscalibration":2.0,"GRPO":2.0,"Agentic RL":2.0,"which":2.0,"arXiv250923870v2 Announce Type":1.0,"Abstract":1.0,"autonomous agents":1.0,"long-horizon":1.0,"real-world tasks":1.0,"significant research interest":1.0}},"age_hours":2.7705163991666666,"is_recent":true,"quality_score":1.0,"sentiment_score":9.836,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9672,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7771,"joy":0.009,"surprise":0.0062,"sadness":0.0173,"fear":0.0897,"anger":0.0646,"disgust":0.036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a method to improve reinforcement learning agents by addressing reward miscalibration. The concrete action is training the actor to classify good or bad actions to separate embeddings. The evidence is based on 'extensive experiments' which are not detailed, and the stage is basic research.","key_impact_metrics":[],"technology_tags":["reinforcement learning","agentic RL","gradient coupling"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:51:19.583251Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_68c7e00bb26d","title":"Efficient Decomposition Identification of Deterministic Finite Automata from Examples","content":"arXiv:2509.24347v2 Announce Type: replace Abstract: The identification of deterministic finite automata (DFAs) from labeled examples is a cornerstone of automata learning, yet traditional methods focus on learning monolithic DFAs, which often yield a large DFA lacking simplicity and interoperability. Recent work addresses these limitations by exploring DFA decomposition identification problems (DFA-DIPs), which model system behavior as intersections of multiple DFAs, offering modularity for complex tasks. However, existing DFA-DIP approaches depend on SAT encodings derived from Augmented Prefix Tree Acceptors (APTAs), incurring scalability limitations due to their inherent redundancy. In this work, we advance DFA-DIP research through studying two variants: the traditional Pareto-optimal DIP and the novel states-optimal DIP, which prioritizes a minimal number of states. We propose a novel framework that bridges DFA decomposition with recent advancements in automata representation. One of our key innovations replaces APTA with 3-valued DFA (3DFA) derived directly from labeled examples. This compact representation eliminates redundancies of APTA, thus drastically reducing variables in the improved SAT encoding. Experimental results demonstrate that our 3DFA-based approach achieves significant efficiency gains for the Pareto-optimal DIP while enabling a scalable solution for the states-optimal DIP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24347","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.286501","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Junjie Meng, Jie An, Yong Li, Andrea Turrini, Fanjiang Xu, Naijun Zhan, Miaomiao Zhang","raw_content_length":1418,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["SAT","DIP","Augmented Prefix Tree Acceptors","DFA-DIP","DFA-DIPs","DFA","Efficient Decomposition Identification of Deterministic"],"persons":["Finite Automata"],"locations":[],"monetary":[]},"char_count":1417,"language_detected":"en","key_concepts":{"key_phrases":["Efficient Decomposition Identification","Deterministic Finite Automata","Examples","which","arXiv250924347v2 Announce Type","Abstract","The identification","deterministic finite automata","DFAs","labeled examples"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Efficient Decomposition Identification":2.0,"Deterministic Finite Automata":2.0,"Examples":2.0,"which":2.0,"arXiv250924347v2 Announce Type":1.0,"Abstract":1.0,"The identification":1.0,"deterministic finite automata":1.0,"DFAs":1.0,"labeled examples":1.0}},"age_hours":2.7705313305555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9235,"joy":0.006,"surprise":0.0311,"sadness":0.0136,"fear":0.0068,"anger":0.0084,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of identifying deterministic finite automata (DFAs) through a novel 3DFA-based approach. The concrete action is the development of a new framework that reduces redundancy in SAT encodings, leading to efficiency gains in DFA decomposition. While the experimental results demonstrate efficiency gains, the technology is still in the applied research stage with no deployed units or operational data available.","key_impact_metrics":["Significant efficiency gains for Pareto-optimal DIP","Drastically reducing variables in the improved SAT encoding"],"technology_tags":["Automata learning","DFA decomposition","SAT encoding","3DFA"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:51:26.629396Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7c2607740da9","title":"The 2025 OpenAI Preparedness Framework does not guarantee any AI risk mitigation practices: a proof","content":"arXiv:2509.24394v2 Announce Type: replace Abstract: Prominent AI companies are producing 'safety frameworks' as a type of voluntary self-governance. These statements purport to establish risk thresholds and safety procedures for the development and deployment of highly capable AI. Understanding which AI risks are covered and what actions are allowed, refused, demanded, encouraged, or discouraged by these statements is vital for assessing how these frameworks actually govern AI development and deployment. We draw on affordance theory to analyse the OpenAI 'Preparedness Framework Version 2' (April 2025) using the Mechanisms & Conditions model of affordances and the MIT AI Risk Repository. We find that this safety policy requests evaluation of a small minority of AI risks, encourages deployment of systems with 'Medium' capabilities for unintentionally enabling 'severe harm' (which OpenAI defines as >1000 deaths or >$100B in damages), and allows OpenAI's CEO to deploy even more dangerous capabilities. These findings suggest that effective mitigation of AI risks requires more robust governance interventions beyond current industry self-regulation. Our affordance analysis provides a replicable method for evaluating what safety frameworks actually permit versus what they claim.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24394","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.286900","language":"en","tags":["computer-science","cscy","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Sam Coggins, Alexander K. Saeri, Katherine A. Daniell, Lorenn P. Ruster, Jessie Liu, Jenny L. Davis","raw_content_length":1292,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["the MIT AI Risk Repository","the Mechanisms & Conditions","OpenAI de"],"persons":["OpenAI"],"locations":[],"monetary":[]},"char_count":1291,"language_detected":"en","key_concepts":{"key_phrases":["The 2025 OpenAI Preparedness Framework","any AI risk mitigation practices","a proof","arXiv250924394v2","Announce Type","Abstract","Prominent AI companies","safety frameworks","a type","voluntary self-governance"],"filter_categories":{"ai_ml":["The 2025 OpenAI Preparedness Framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The 2025 OpenAI Preparedness Framework":2.0,"any AI risk mitigation practices":2.0,"a proof":2.0,"arXiv250924394v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Prominent AI companies":1.0,"safety frameworks":1.0,"a type":1.0,"voluntary self-governance":1.0}},"age_hours":2.770546760833333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.581,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1162,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8783,"joy":0.0059,"surprise":0.0082,"sadness":0.0128,"fear":0.0284,"anger":0.0396,"disgust":0.0267},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper analyzes the OpenAI Preparedness Framework, finding it inadequate for mitigating AI risks. It uses affordance theory and the MIT AI Risk Repository to evaluate the framework, providing a replicable method for assessing safety policies. The analysis identifies specific shortcomings, such as allowing deployment of systems with 'Medium' capabilities for unintentionally enabling 'severe harm'.","key_impact_metrics":[">1000 deaths",">$100B in damages"],"technology_tags":["AI Safety","Risk Assessment","Governance"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:51:34.456426Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c680c322407a","title":"LaMoGen: Laban Movement-Guided Diffusion for Text","content":"arXiv:2509.24469v2 Announce Type: replace Abstract: Diverse human motion generation is an increasingly important task, having various applications in computer vision, human-computer interaction and animation. While text-to-motion synthesis using diffusion models has shown success in generating high-quality motions, achieving fine-grained expressive motion control remains a significant challenge. This is due to the lack of motion style diversity in datasets and the difficulty of expressing quantitative characteristics in natural language. Laban movement analysis has been widely used by dance experts to express the details of motion including motion quality as consistent as possible. Inspired by that, this work aims for interpretable and expressive control of human motion generation by seamlessly integrating the quantification methods of Laban Effort and Shape components into the text-guided motion generation models. Our proposed zero-shot, inference-time optimization method guides the motion generation model to have desired Laban Effort and Shape components without any additional motion data by updating the text embedding of pretrained diffusion models during the sampling step. We demonstrate that our approach yields diverse expressive motion qualities while preserving motion identity by successfully manipulating motion attributes according to target Laban tags.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24469","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.287287","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Heechang Kim, Gwanghyun Kim, Se Young Chun","raw_content_length":1384,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Laban Movement-Guided Diffusion for Text arXiv:2509.24469v2 Announce Type: replace Abstract","Laban Effort","Shape"],"persons":[],"locations":[],"monetary":[]},"char_count":1383,"language_detected":"en","key_concepts":{"key_phrases":[" Laban Movement-Guided Diffusion","Text","Announce Type","Abstract","Diverse human motion generation","an increasingly important task","various applications","computer vision","human-computer interaction","animation"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{" Laban Movement-Guided Diffusion":2.0,"Text":2.0,"Announce Type":1.0,"Abstract":1.0,"Diverse human motion generation":1.0,"an increasingly important task":1.0,"various applications":1.0,"computer vision":1.0,"human-computer interaction":1.0,"animation":1.0}},"age_hours":2.7705613730555556,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7333,"joy":0.0064,"surprise":0.0138,"sadness":0.0147,"fear":0.1352,"anger":0.0442,"disgust":0.0524},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for controlling human motion generation using Laban movement analysis within diffusion models. While innovative, it's currently in the research phase with no deployed applications or quantified climate impact. The technical credibility is moderate due to peer-review, but economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["diffusion models","Laban movement analysis","motion generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:51:37.734969Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_48952a2f20fc","title":"Specialization after Generalization: Towards Understanding Test","content":"arXiv:2509.24510v2 Announce Type: replace Abstract: Recent empirical studies have explored the idea of continuing to train a model at test-time for a given task, known as test-time training (TTT), and have found it to yield significant performance improvements. However, there is limited understanding of why and when TTT is effective. Earlier explanations mostly focused on the observation that TTT may help when applied to out-of-distribution adaptation or used with privileged data. However, the growing scale of foundation models with most test data being in-distribution questions these explanations. We instead posit that foundation models remain globally underparameterized, with TTT providing a mechanism for specialization after generalization, focusing capacity on concepts relevant to the test task. Specifically, under the linear representation hypothesis, we propose a model in which TTT achieves a substantially smaller in-distribution test error than global training. We empirically validate our model's key assumptions by training a sparse autoencoder on ImageNet, showing that semantically related data points are explained by only a few shared concepts. Finally, we perform scaling studies across image and language tasks that confirm the practical implications of our model, identifying the regimes where specialization is most effective.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24510","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.287693","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Jonas H\\\"ubotter, Patrik Wolf, Alexander Shevchenko, Dennis J\\\"uni, Andreas Krause, Gil Kur","raw_content_length":1358,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["TTT"],"persons":[],"locations":[],"monetary":[]},"char_count":1357,"language_detected":"en","key_concepts":{"key_phrases":["TTT","Specialization","Generalization","Understanding Test","arXiv250924510v2 Announce Type","Abstract","Recent empirical studies","the idea","a model","test-time"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"TTT":3.0,"Specialization":2.0,"Generalization":2.0,"Understanding Test":2.0,"arXiv250924510v2 Announce Type":1.0,"Abstract":1.0,"Recent empirical studies":1.0,"the idea":1.0,"a model":1.0,"test-time":1.0}},"age_hours":2.770577043333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8625,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8946,"joy":0.0151,"surprise":0.0629,"sadness":0.0064,"fear":0.0061,"anger":0.0089,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a theoretical model for test-time training (TTT) and its potential to improve model performance. The research validates the model's assumptions by training a sparse autoencoder on ImageNet and performing scaling studies. While the research shows potential for improving model efficiency, it is still in the basic research stage with no deployed technology or measured environmental outcomes.","key_impact_metrics":["In-distribution test error reduction"],"technology_tags":["Test-time training","Sparse autoencoders","Foundation models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:51:47.781945Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8feb5299d83b","title":"NeMo: Needle in a Montage for Video","content":"arXiv:2509.24563v2 Announce Type: replace Abstract: Recent advances in video large language models (VideoLLMs) call for new evaluation protocols and benchmarks for complex temporal reasoning in video-language understanding. Inspired by the needle in a haystack test widely used by LLMs, we introduce a novel task of Needle in a Montage (NeMo), designed to assess VideoLLMs' critical reasoning capabilities, including long-context recall and temporal grounding. To generate video question answering data for our task, we develop a scalable automated data generation pipeline that facilitates high-quality data synthesis. Built upon the proposed pipeline, we present NeMoBench, a video-language benchmark centered on our task. Specifically, our full set of NeMoBench features 31,378 automatically generated question-answer (QA) pairs from 13,486 videos with various durations ranging from seconds to hours. Experiments demonstrate that our pipeline can reliably and automatically generate high-quality evaluation data, enabling NeMoBench to be continuously updated with the latest videos. We evaluate 20 state-of-the-art models on our benchmark, providing extensive results and key insights into their capabilities and limitations. Our project page is available at: https://lavi-lab.github.io/NeMoBench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24563","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.288075","language":"en","tags":["computer-science","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Zi-Yuan Hu, Shuo Liang, Duo Zheng, Yanyang Li, Yeyao Tao, Shijia Huang, Wei Feng, Jia Qin, Jianguang Yu, Jing Huang, Meng Fang, Yin Li, Liwei Wang","raw_content_length":1302,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["VideoLLMs","NeMoBench"],"persons":["NeMo"],"locations":[],"monetary":[]},"char_count":1301,"language_detected":"en","key_concepts":{"key_phrases":["a Montage","Video","arXiv250924563v2 Announce Type","Abstract","video large language models","VideoLLMs","new evaluation protocols","complex temporal reasoning","video-language understanding","the needle"],"filter_categories":{"ai_ml":["video large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"a Montage":2.0,"Video":2.0,"arXiv250924563v2 Announce Type":1.0,"Abstract":1.0,"video large language models":1.0,"VideoLLMs":1.0,"new evaluation protocols":1.0,"complex temporal reasoning":1.0,"video-language understanding":1.0,"the needle":1.0}},"age_hours":2.770592666388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.86,"joy":0.0303,"surprise":0.0766,"sadness":0.0031,"fear":0.0114,"anger":0.0144,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark (NeMoBench) for evaluating video large language models. While the research itself doesn't directly impact climate change, the development of more efficient and accurate AI models *could* indirectly contribute to sustainability efforts in the future by improving resource allocation or optimizing energy consumption in other sectors. However, this is a very indirect and speculative link at this stage.","key_impact_metrics":["31,378 question-answer pairs","13,486 videos"],"technology_tags":["video large language models","AI","machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:52:07.792633Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_12c38741b008","title":"Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in","content":"arXiv:2509.24637v2 Announce Type: replace Abstract: Large Language Models (LLMs) have significantly advanced code completion, yet they often fail when the developer's intent is underspecified in the code context. To address this, developers usually add natural language instructions (e.g., comments) into the code context to clarify their intent. However, existing code LLMs applied for code completion systems merely undergo a fill-in-the-middle (FIM) pre-training, which struggles to leverage this information effectively due to the lack of instruction-like training data. Existing instruction-tuning techniques, improving instruction-following in general code generation, paradoxically degrades FIM performance, forcing a trade-off between instruction-following and infilling capabilities. To address this gap, we introduce Instruction-aware Fill-in-the-Middle (IFIM), an instruction-tuning method specifically designed to enhance FIM code completion models. IFIM extends the conventional FIM training objective by incorporating an explicit instruction section into the input, enabling the model to learn from (prefix, instruction, suffix) triplets. This approach allows the model to effectively leverage developer-provided directives while preserving its core completion abilities when no instructions are present. To facilitate this, we constructed a large-scale dataset by using GPT-4o to generate concise, intent-focused instructions for code infilling examples. We evaluated IFIM by applying it to two popular base models, Deepseek-Coder and Qwen2.5-Coder, on the benchmarks derived from HumanEval-infilling and RepoMasterEval. The results demonstrate that IFIM significantly improves instruction-following capabilities, boosting the Pass@1 score from 84.6% to 93.6%. Moreover, this enhancement does not compromise the models' original performance on FIM code completion tasks with no instructions provided.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24637","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.288616","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Zhensu Sun, Chengran Yang, Chao Peng, Pengfei Gao, Xiaoning Du, Li Li, David Lo","raw_content_length":1916,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["FIM"],"persons":[],"locations":[],"monetary":[]},"char_count":1915,"language_detected":"en","key_concepts":{"key_phrases":["Bridging Developer Instructions","Code Completion","Instruction-Aware Fill","the code context","arXiv250924637v2 Announce Type","Abstract","Large Language Models","LLMs","significantly advanced code completion","the developers intent"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bridging Developer Instructions":2.0,"Code Completion":2.0,"Instruction-Aware Fill":2.0,"the code context":2.0,"arXiv250924637v2 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"significantly advanced code completion":1.0,"the developers intent":1.0}},"age_hours":2.7706091694444446,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9177,"joy":0.0021,"surprise":0.018,"sadness":0.0268,"fear":0.0064,"anger":0.0148,"disgust":0.0142},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving code completion using LLMs, which could indirectly contribute to sustainability by making software development more efficient. The concrete action is the development of the IFIM method and its evaluation on benchmark datasets, showing an improvement in Pass@1 score from 84.6% to 93.6%. However, it's still in the applied research stage with no clear path to deployment or direct climate impact.","key_impact_metrics":["Pass@1 score improvement: 9%"],"technology_tags":["Large Language Models","Code Completion","Instruction Tuning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:52:13.678173Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_42f5584dc47d","title":"SANA","content":"arXiv:2509.24695v2 Announce Type: replace Abstract: We introduce SANA-Video, a small diffusion model that can efficiently generate videos up to 720x1280 resolution and minute-length duration. SANA-Video synthesizes high-resolution, high-quality and long videos with strong text-video alignment at a remarkably fast speed, deployable on RTX 5090 GPU. Two core designs ensure our efficient, effective and long video generation: (1) Linear DiT: We leverage linear attention as the core operation, which is more efficient than vanilla attention given the large number of tokens processed in video generation. (2) Constant-Memory KV cache for Block Linear Attention: we design block-wise autoregressive approach for long video generation by employing a constant-memory state, derived from the cumulative properties of linear attention. This KV cache provides the Linear DiT with global context at a fixed memory cost, eliminating the need for a traditional KV cache and enabling efficient, minute-long video generation. In addition, we explore effective data filters and model training strategies, narrowing the training cost to 12 days on 64 H100 GPUs, which is only 1% of the cost of MovieGen. Given its low cost, SANA-Video achieves competitive performance compared to modern state-of-the-art small diffusion models (e.g., Wan 2.1-1.3B and SkyReel-V2-1.3B) while being 16x faster in measured latency. Moreover, SANA-Video can be deployed on RTX 5090 GPUs with NVFP4 precision, accelerating the inference speed of generating a 5-second 720p video from 71s to 29s (2.4x speedup). In summary, SANA-Video enables low-cost, high-quality video generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24695","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.289038","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Junsong Chen, Yuyang Zhao, Jincheng Yu, Ruihang Chu, Junyu Chen, Shuai Yang, Xianbang Wang, Yicheng Pan, Daquan Zhou, Huan Ling, Haozhe Liu, Hongwei Yi, Hao Zhang, Muyang Li, Yukang Chen, Han Cai, Sanja Fidler, Ping Luo, Song Han, Enze Xie","raw_content_length":1648,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["Linear","SANA-Video","GPU","Block Linear Attention"],"persons":["SANA arXiv:2509.24695v2 Announce Type"],"locations":[],"monetary":[]},"char_count":1647,"language_detected":"en","key_concepts":{"key_phrases":["SANA-Video","arXiv250924695v2 Announce Type","Abstract","a small diffusion model","videos","720x1280 resolution and minute-length duration","high-resolution high-quality and long videos","strong text-video alignment","a remarkably fast speed","RTX 5090 GPU"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SANA-Video":2.0,"arXiv250924695v2 Announce Type":1.0,"Abstract":1.0,"a small diffusion model":1.0,"videos":1.0,"720x1280 resolution and minute-length duration":1.0,"high-resolution high-quality and long videos":1.0,"strong text-video alignment":1.0,"a remarkably fast speed":1.0,"RTX 5090 GPU":1.0}},"age_hours":2.7706250858333332,"is_recent":true,"quality_score":0.7,"sentiment_score":9.63,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.926,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8547,"joy":0.0555,"surprise":0.0736,"sadness":0.0026,"fear":0.0023,"anger":0.0085,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel diffusion model for video generation that is more efficient and faster than existing models. The reduction in computational cost (training cost narrowed to 12 days on 64 H100 GPUs, which is only 1% of the cost of MovieGen) could indirectly reduce energy consumption associated with AI model training and inference. However, there are no deployed units or real-world data available, making it difficult to assess the actual impact.","key_impact_metrics":["1% training cost reduction compared to MovieGen","2.4x speedup in inference"],"technology_tags":["diffusion model","video generation","linear attention"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:52:18.692016Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2bb4dc13f634","title":"MemGen: Weaving Generative Latent Memory for Self","content":"arXiv:2509.24704v2 Announce Type: replace Abstract: Agent memory shapes how Large Language Model (LLM)-powered agents, akin to the human brain, progressively refine themselves through environment interactions. Existing paradigms remain constrained: parametric memory forcibly adjusts model parameters, and retrieval-based memory externalizes experience into structured databases, yet neither captures the fluid interweaving of reasoning and memory that underlies human cognition. To address this gap, we propose MemGen, a dynamic generative memory framework that equips agents with a human-esque cognitive faculty. It consists of a \\textit{memory trigger}, which monitors the agent's reasoning state to decide explicit memory invocation, and a \\textit{memory weaver}, which takes the agent's current state as stimulus to construct a latent token sequence as machine-native memory to enrich its reasoning. In this way, MemGen enables agents to recall and augment latent memory throughout reasoning, producing a tightly interwoven cycle of memory and cognition. Extensive experiments across eight benchmarks show that MemGen surpasses leading external memory systems such as ExpeL and AWM by up to $38.22\\%$, exceeds GRPO by up to $13.44\\%$, and exhibits strong cross-domain generalization ability. More importantly, we find that without explicit supervision, MemGen spontaneously evolves distinct human-like memory faculties, including planning memory, procedural memory, and working memory, suggesting an emergent trajectory toward more naturalistic forms of machine cognition.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24704","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.289434","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Guibin Zhang, Muxin Fu, Shuicheng Yan","raw_content_length":1578,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["MemGen","\\textit{memory"],"persons":[],"locations":[],"monetary":[]},"char_count":1577,"language_detected":"en","key_concepts":{"key_phrases":["MemGen","Generative Latent Memory","Self","arXiv250924704v2","Announce Type","Abstract","Large Language Model","LLM-powered agents","the human brain","themselves"],"filter_categories":{"ai_ml":["Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MemGen":2.0,"Generative Latent Memory":2.0,"Self":2.0,"arXiv250924704v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Large Language Model":1.0,"LLM-powered agents":1.0,"the human brain":1.0,"themselves":1.0}},"age_hours":2.7706395294444444,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8981,"joy":0.0041,"surprise":0.0415,"sadness":0.0078,"fear":0.0107,"anger":0.0222,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (MemGen) that improves agent performance on benchmarks. While the technology itself doesn't directly address climate change, it could potentially be applied to optimize energy consumption or resource management in the future. The research is in its early stages, with no current deployment, but shows promising results on benchmarks, surpassing existing memory systems by up to 38.22%.","key_impact_metrics":["38.22% performance increase","13.44% performance increase"],"technology_tags":["Artificial Intelligence","Large Language Models","Memory Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:52:41.739748Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c390f3fc907","title":"DiaCDM: Cognitive Diagnosis in Teacher-Student Dialogues using the Initiation","content":"arXiv:2509.24821v2 Announce Type: replace Abstract: While cognitive diagnosis (CD) effectively assesses students' knowledge mastery from structured test data, applying it to real-world teacher-student dialogues presents two fundamental challenges. Traditional CD models lack a suitable framework for handling dynamic, unstructured dialogues, and it's difficult to accurately extract diagnostic semantics from lengthy dialogues. To overcome these hurdles, we propose DiaCDM, an innovative model. We've adapted the initiation-response-evaluation (IRE) framework from educational theory to design a diagnostic framework tailored for dialogue. We also developed a unique graph-based encoding method that integrates teacher questions with relevant knowledge components to capture key information more precisely. To our knowledge, this is the first exploration of cognitive diagnosis in a dialogue setting. Experiments on three real-world dialogue datasets confirm that DiaCDM not only significantly improves diagnostic accuracy but also enhances the results' interpretability, providing teachers with a powerful tool for assessing students' cognitive states. The code is available at https://github.com/Mind-Lab-ECNU/DiaCDM/tree/main.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24821","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.289834","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Rui Jia, Yuang Wei, Ruijia Li, Yuan-Hao Jiang, Xinyu Xie, Yaomin Shen, Min Zhang, Bo Jiang","raw_content_length":1230,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["IRE"],"persons":[],"locations":[],"monetary":[]},"char_count":1229,"language_detected":"en","key_concepts":{"key_phrases":["DiaCDM","Cognitive Diagnosis","Teacher-Student Dialogues","the Initiation","arXiv250924821v2 Announce Type","Abstract","cognitive diagnosis","students knowledge mastery","structured test data","real-world teacher-student dialogues"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DiaCDM":2.0,"Cognitive Diagnosis":2.0,"Teacher-Student Dialogues":2.0,"the Initiation":2.0,"arXiv250924821v2 Announce Type":1.0,"Abstract":1.0,"cognitive diagnosis":1.0,"students knowledge mastery":1.0,"structured test data":1.0,"real-world teacher-student dialogues":1.0}},"age_hours":2.770654666111111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.897,"joy":0.0047,"surprise":0.0313,"sadness":0.0111,"fear":0.0342,"anger":0.0098,"disgust":0.0119},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel model (DiaCDM) for cognitive diagnosis in teacher-student dialogues. While the model shows improved diagnostic accuracy on real-world dialogue datasets, it is still in the early stages of development and deployment. The impact on climate change is minimal as it is primarily an educational tool.","key_impact_metrics":["Diagnostic accuracy improvement","Interpretability enhancement"],"technology_tags":["Cognitive Diagnosis","Machine Learning","Educational Technology"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:52:51.960203Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_24d402a88d00","title":"Retro*: Optimizing LLMs for Reasoning","content":"arXiv:2509.24869v2 Announce Type: replace Abstract: With the growing popularity of LLM agents and RAG, it has become increasingly important to retrieve documents that are essential for solving a task, even when their connection to the task is indirect or implicit. Addressing this problem requires fine-grained reasoning to accurately assess the relevance between the task and each candidate document. This capability, however, poses a significant challenge for existing IR techniques. Despite recent progress in reasoning-enhanced IR, existing approaches still face significant challenges in applicability, scalability, and efficiency. In this work, we propose Retro*, a novel approach for reasoning-intensive document retrieval. Our method introduces a rubric-based relevance scoring mechanism, enabling the model to reason about the relationship between a task and a document based on explicitly defined criteria, whereby producing a fine-grained, interpretable relevance score. Retro* also supports test-time scaling by combining multiple reasoning trajectories via score integration, which produces more reliable relevance estimates. To optimize Retro*'s reasoning capabilities, we introduce a novel reinforcement learning algorithm tailored for its relevance scoring mechanism, which employs two composite rewards to fully exploit the trajectories of each training sample. Our experiments show that Retro* outperforms existing document retrieval methods with notable advantages, leading to state-of-the-art performance on the BRIGHT benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24869","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.290235","language":"en","tags":["computer-science","csai","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Junwei Lan, Jianlyu Chen, Zheng Liu, Chaofan Li, Siqi Bao, Defu Lian","raw_content_length":1550,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["RAG","Retro"],"locations":[],"monetary":[]},"char_count":1549,"language_detected":"en","key_concepts":{"key_phrases":["Retro","LLMs","Reasoning","the task","Announce Type","Abstract","the growing popularity","LLM agents","RAG","documents"],"filter_categories":{"ai_ml":["LLMs"],"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Retro":2.0,"LLMs":2.0,"Reasoning":2.0,"the task":2.0,"Announce Type":1.0,"Abstract":1.0,"the growing popularity":1.0,"LLM agents":1.0,"RAG":1.0,"documents":1.0}},"age_hours":2.770669274722222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8391,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9221,"joy":0.0089,"surprise":0.036,"sadness":0.004,"fear":0.0055,"anger":0.0171,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel approach (Retro*) for improving document retrieval in LLMs, which could indirectly support sustainability efforts by improving access to relevant information. However, the article focuses on the algorithm itself and lacks concrete actions or measurable outcomes related to environmental impact. It's currently in the applied research stage with experimental validation, but no real-world deployment.","key_impact_metrics":["State-of-the-art performance on the BRIGHT benchmark"],"technology_tags":["LLM","Document Retrieval","Reinforcement Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:52:55.213820Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1feba8128ec9","title":"From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones","content":"arXiv:2509.25123v2 Announce Type: replace Abstract: Does RL teach LLMs genuinely new skills, or does it merely activate existing ones? This question lies at the core of ongoing debates about the role of RL in LLM post-training. On one side, strong empirical results can be achieved with RL even without preceding supervised finetuning; on the other, critics argue that RL contributes little beyond reweighting existing reasoning strategies. This work provides concrete evidence that LLMs can acquire genuinely new skills during RL by composing existing ones, mirroring one of the central mechanisms by which humans acquire new cognitive skills. To mitigate data contamination and other confounding factors, and to allow precise control over task complexity, we develop a synthetic framework for our investigation. Specifically, we define a skill as the ability to infer the output of a string transformation function f(x) given x. When an LLM has already learned f and g prior to RL, our experiments reveal that RL enables it to learn unseen compositions of them h(x)=g(f(x)). Further, this compositional ability generalizes to more difficult problems such as compositions of >2 functions unseen during RL training. Surprisingly, our experiments show that compositional skill acquired on a source task transfers to a different target task. This transfer happens even without compositional training on the target, requiring only prior knowledge of the target's atomic skills. Our qualitative analysis shows that RL fundamentally changes the reasoning behaviors of the models. In contrast, next-token training with the same data yields none of these findings. Our systematic experiments provide fresh insights into LLM learning, suggesting the value of first building base models with basic skills, then using RL to incentivize advanced, generalizable skills for complex problems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.25123","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.291039","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":281,"author":"Lifan Yuan, Weize Chen, Yuchen Zhang, Ganqu Cui, Hanbin Wang, Ziming You, Ning Ding, Zhiyuan Liu, Maosong Sun, Hao Peng","raw_content_length":1879,"priority":7,"update_frequency":1,"reading_time_minutes":1.405,"robust_parsing_used":true,"entities":{"organizations":["Composing Old Ones arXiv:2509.25123v2","LLM","Learn New Skills"],"persons":[],"locations":[],"monetary":["f(x)$"]},"char_count":1878,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","fgx","New Skills","Composing Old Ones","arXiv250925123v2 Announce Type","Abstract","LLMs genuinely new skills","existing ones","This question","the core"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"fgx":2.0,"New Skills":2.0,"Composing Old Ones":2.0,"arXiv250925123v2 Announce Type":1.0,"Abstract":1.0,"LLMs genuinely new skills":1.0,"existing ones":1.0,"This question":1.0,"the core":1.0}},"age_hours":2.770699405,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8694,"joy":0.0062,"surprise":0.0549,"sadness":0.006,"fear":0.0066,"anger":0.04,"disgust":0.0169},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving LLM capabilities through reinforcement learning. While it doesn't directly address climate change, the potential for more efficient AI models could indirectly reduce energy consumption in the future. The research is in the early stages, with no deployed applications yet.","key_impact_metrics":[],"technology_tags":["Large Language Models","Reinforcement Learning","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:53:06.113165Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_63d9cedb8a20","title":"How Effective Are Time","content":"arXiv:2509.25263v2 Announce Type: replace Abstract: Rainfall nowcasting, which aims to predict precipitation within the next 0 to 3 hours, is critical for disaster mitigation and real-time response planning. However, most time series forecasting benchmarks in meteorology are evaluated on variables with strong periodicity, such as temperature and humidity, which fail to reflect model capabilities in more complex and practically meteorology scenarios like rainfall nowcasting. To address this gap, we propose RainfallBench, a benchmark designed for rainfall nowcasting, a highly challenging and practically relevant task characterized by zero inflation, temporal decay, and non-stationarity, focused on predicting precipitation within the next 0 to 3 hours. The dataset is derived from five years of meteorological observations, recorded at 15-minute intervals across six essential variables, and collected from more than 12,000 GNSS stations globally. In particular, it incorporates precipitable water vapor (PWV), a crucial indicator of rainfall that is absent in other datasets. We further design specialized evaluation strategies to assess model performance on key meteorological challenges, such as multi-scale prediction and extreme rainfall events, and evaluate over 20 state-of-the-art models across six major architectures on RainfallBench. Additionally, to address the zero-inflation and temporal decay issues overlooked by existing models, we introduce Bi-Focus Precipitation Forecaster (BFPF), a plug-and-play module that incorporates domain-specific priors to enhance rainfall time series forecasting. Statistical analysis and ablation studies validate the comprehensiveness of our dataset as well as the superiority of our methodology. Code and datasets are available at https://anonymous.4open.science/r/RainfallBench-A710.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.25263","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.291912","language":"en","tags":["statml","cslg","csai","physicsao-ph","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Yifang Zhang, Pengfei Duan, Henan Wang, Wenjie Yin, Chen Zhou, Shengwu Xiong","raw_content_length":1841,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["RainfallBench"],"persons":["Rainfall"],"locations":[],"monetary":[]},"char_count":1840,"language_detected":"en","key_concepts":{"key_phrases":["Time","which","arXiv250925263v2 Announce Type","Abstract","Rainfall nowcasting","precipitation","the next 0 to 3 hours","disaster mitigation","real-time response planning","most time series forecasting benchmarks"],"filter_categories":{"ai_ml":["Rainfall nowcasting"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Time":2.0,"which":2.0,"arXiv250925263v2 Announce Type":1.0,"Abstract":1.0,"Rainfall nowcasting":1.0,"precipitation":1.0,"the next 0 to 3 hours":1.0,"disaster mitigation":1.0,"real-time response planning":1.0,"most time series forecasting benchmarks":1.0}},"age_hours":2.7707285208333334,"is_recent":true,"quality_score":1.0,"sentiment_score":3.75,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.25,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8879,"joy":0.0043,"surprise":0.0573,"sadness":0.0248,"fear":0.0065,"anger":0.0152,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a new benchmark dataset and forecasting module for rainfall nowcasting, which is crucial for disaster mitigation. The technical credibility is supported by statistical analysis, ablation studies, and evaluation of multiple models. However, it's still in the applied research stage with no actual deployment or economic viability demonstrated.","key_impact_metrics":["Precipitation prediction within 0-3 hours","Meteorological observations at 15-minute intervals"],"technology_tags":["Rainfall Nowcasting","Time Series Forecasting","GNSS"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T12:53:14.337523Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b68edf3753f4","title":"RL in the Wild: Characterizing RLVR Training in LLM Deployment","content":"arXiv:2509.25279v2 Announce Type: replace Abstract: Large Language Models (LLMs) are now widely used across many domains. With their rapid development, Reinforcement Learning with Verifiable Rewards (RLVR) has surged in recent months to enhance their reasoning and understanding abilities. However, its complex data flows and diverse tasks pose substantial challenges to RL training systems, and there is limited understanding of RLVR from a system perspective. To thoroughly understand the system challenges introduced by RLVR, we present a characterization study of RLVR tasks in our LLM deployment. Specifically, we investigate the distribution and variation trends of workloads across different RL tasks across training steps. We identify issues such as GPU idling caused by skewed sequence length distribution, inefficient parallel strategies in dynamically varying workloads, inefficient data management mechanisms, and load imbalance. We describe our observations and call for further investigation into the remaining open challenges. Furthermore, we propose PolyTrace benchmark suite to conduct evaluation with realistic workloads, and a practical use case validates that PolyTrace benchmark suite exhibits 94.7% accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.25279","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.292304","language":"en","tags":["cslg","csai","preprints","csdc","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Jiecheng Zhou, Qinghao Hu, Yuyang Jin, Zerui Wang, Peng Sun, Yuzhe Gu, Wenwei Zhang, Mingshu Zhai, Xingcheng Zhang, Weiming Zhang","raw_content_length":1231,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["LLM","Reinforcement Learning","GPU"],"persons":[],"locations":["imbala"],"monetary":[]},"char_count":1230,"language_detected":"en","key_concepts":{"key_phrases":["the Wild","RLVR Training","LLM Deployment","RLVR","arXiv250925279v2 Announce Type","Large Language Models","LLMs","many domains","their rapid development","Reinforcement Learning"],"filter_categories":{"ai_ml":["RLVR Training","Large Language Models","Reinforcement Learning"],"engineering":["their rapid development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Wild":2.0,"RLVR Training":2.0,"LLM Deployment":2.0,"RLVR":2.0,"arXiv250925279v2 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"many domains":1.0,"their rapid development":1.0,"Reinforcement Learning":1.0}},"age_hours":2.770743102222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8889,"joy":0.0112,"surprise":0.054,"sadness":0.0038,"fear":0.0229,"anger":0.0158,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a characterization study of RLVR tasks in LLM deployment, identifying system challenges like GPU idling and inefficient data management. It proposes a benchmark suite (PolyTrace) and validates its accuracy (94.7%), but lacks information on actual deployment or quantifiable environmental impact. The focus is on improving the efficiency of LLM training, which could indirectly reduce energy consumption, but this is not explicitly quantified.","key_impact_metrics":["Accuracy of PolyTrace benchmark suite: 94.7%"],"technology_tags":["Reinforcement Learning","Large Language Models","System Optimization"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:53:23.247226Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_20c4ad6e2991","title":"Learning to Reason as Action Abstractions with Scalable Mid","content":"arXiv:2509.25810v3 Announce Type: replace Abstract: Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.25810","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.293167","language":"en","tags":["statml","cslg","csai","preprints","research","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Shenao Zhang, Donghan Yu, Yihao Feng, Bowen Jin, Zhaoran Wang, John Peebles, Zirui Wang","raw_content_length":1779,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["Scalable Mid arXiv:2509.25810v3 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1778,"language_detected":"en","key_concepts":{"key_phrases":["Reason","Action Abstractions","Scalable Mid","arXiv250925810v3 Announce Type","Abstract","Large language models","reinforcement learning","this potential","a mid-training stage","An effective mid-training phase"],"filter_categories":{"ai_ml":["Large language models","reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reason":2.0,"Action Abstractions":2.0,"Scalable Mid":2.0,"arXiv250925810v3 Announce Type":1.0,"Abstract":1.0,"Large language models":1.0,"reinforcement learning":1.0,"this potential":1.0,"a mid-training stage":1.0,"An effective mid-training phase":1.0}},"age_hours":2.770772973611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.375,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.875,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9058,"joy":0.0169,"surprise":0.0298,"sadness":0.004,"fear":0.0238,"anger":0.0117,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm (RA3) for improving the performance of large language models in reinforcement learning, specifically for code generation. The concrete action is the development and testing of this algorithm. The evidence supporting the claims is the experimental results on code generation tasks, showing improvements in performance metrics like HumanEval and MBPP. The stage of deployment is currently at the applied research level, with experiments conducted but no indication of real-world deployment.","key_impact_metrics":["HumanEval improvement by 8 points","MBPP improvement by 4 points"],"technology_tags":["Large Language Models","Reinforcement Learning","Code Generation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:53:35.604541Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ac8bce12031f","title":"Scaling Equilibrium Propagation to Deeper Neural Network Architectures","content":"arXiv:2509.26003v2 Announce Type: replace Abstract: Equilibrium propagation has been proposed as a biologically plausible alternative to the backpropagation algorithm. The local nature of gradient computations, combined with the use of convergent RNNs to reach equilibrium states, make this approach well-suited for implementation on neuromorphic hardware. However, previous studies on equilibrium propagation have been restricted to networks containing only dense layers or relatively small architectures with a few convolutional layers followed by a final dense layer. These networks have a significant gap in accuracy compared to similarly sized feedforward networks trained with backpropagation. In this work, we introduce the Hopfield-Resnet architecture, which incorporates residual (or skip) connections in Hopfield networks with clipped $\\mathrm{ReLU}$ as the activation function. The proposed architectural enhancements enable the training of networks with nearly twice the number of layers reported in prior works. For example, Hopfield-Resnet13 achieves 93.92\\% accuracy on CIFAR-10, which is $\\approx$3.5\\% higher than the previous best result and comparable to that provided by Resnet13 trained using backpropagation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26003","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.293567","language":"en","tags":["cslg","preprints","research","csne","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Sankar Vinayak Elayedam, Gopalakrishnan Srinivasan","raw_content_length":1231,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Deeper Neural Network Architectures arXiv:2509.26003v2"],"persons":["\\mathrm{ReLU}$"],"locations":["Hopfield"],"monetary":[]},"char_count":1230,"language_detected":"en","key_concepts":{"key_phrases":["Scaling Equilibrium Propagation","Deeper Neural Network Architectures","Announce Type","Abstract","Equilibrium propagation","a biologically plausible alternative","the backpropagation algorithm","The local nature","gradient computations","the use"],"filter_categories":{"ai_ml":["the backpropagation algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scaling Equilibrium Propagation":2.0,"Deeper Neural Network Architectures":2.0,"Announce Type":1.0,"Abstract":1.0,"Equilibrium propagation":1.0,"a biologically plausible alternative":1.0,"the backpropagation algorithm":1.0,"The local nature":1.0,"gradient computations":1.0,"the use":1.0}},"age_hours":2.770786919166667,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8507,"joy":0.0585,"surprise":0.0514,"sadness":0.0062,"fear":0.013,"anger":0.0111,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural network architecture (Hopfield-Resnet) that improves accuracy on CIFAR-10 compared to previous equilibrium propagation methods. While the research aims for biologically plausible and neuromorphic hardware implementation, there are no deployed units or concrete actions demonstrating climate impact. The improvement in accuracy (3.5%) is the primary metric, but it's unclear how this translates to energy savings or other sustainability benefits.","key_impact_metrics":["Accuracy on CIFAR-10: 93.92%","Accuracy improvement: 3.5%"],"technology_tags":["Equilibrium Propagation","Neuromorphic Computing","Hopfield Networks","Residual Networks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:53:39.724512Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dedb76abb9c7","title":"DA$^2$: Depth Anything in Any Direction","content":"arXiv:2509.26618v2 Announce Type: replace Abstract: Panorama has a full FoV (360$^\\circ\\times$180$^\\circ$), offering a more complete visual description than perspective images. Thanks to this characteristic, panoramic depth estimation is gaining increasing traction in 3D vision. However, due to the scarcity of panoramic data, previous methods are often restricted to in-domain settings, leading to poor zero-shot generalization. Furthermore, due to the spherical distortions inherent in panoramas, many approaches rely on perspective splitting (e.g., cubemaps), which leads to suboptimal efficiency. To address these challenges, we propose $\\textbf{DA}$$^{\\textbf{2}}$: $\\textbf{D}$epth $\\textbf{A}$nything in $\\textbf{A}$ny $\\textbf{D}$irection, an accurate, zero-shot generalizable, and fully end-to-end panoramic depth estimator. Specifically, for scaling up panoramic data, we introduce a data curation engine for generating high-quality panoramic depth data from perspective, and create $\\sim$543K panoramic RGB-depth pairs, bringing the total to $\\sim$607K. To further mitigate the spherical distortions, we present SphereViT, which explicitly leverages spherical coordinates to enforce the spherical geometric consistency in panoramic image features, yielding improved performance. A comprehensive benchmark on multiple datasets clearly demonstrates DA$^{2}$'s SoTA performance, with an average 38% improvement on AbsRel over the strongest zero-shot baseline. Surprisingly, DA$^{2}$ even outperforms prior in-domain methods, highlighting its superior zero-shot generalization. Moreover, as an end-to-end solution, DA$^{2}$ exhibits much higher efficiency over fusion-based approaches. Both the code and the curated panoramic data has be released. Project page: https://depth-any-in-any-dir.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26618","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.294817","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Haodong Li, Wangguangdong Zheng, Jing He, Yuhao Liu, Xin Lin, Xin Yang, Ying-Cong Chen, Chunchao Guo","raw_content_length":1811,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Panorama","FoV"],"persons":["Depth Anything"],"locations":["panoramas"],"monetary":["$\\textbf{D}$epth $","$\\textbf{A}$ny $"]},"char_count":1810,"language_detected":"en","key_concepts":{"key_phrases":["Depth Anything","Any Direction","arXiv250926618v2 Announce Type","Abstract","Panorama","a full FoV","360circtimes180circ","a more complete visual description","perspective images","Thanks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Depth Anything":2.0,"Any Direction":2.0,"arXiv250926618v2 Announce Type":1.0,"Abstract":1.0,"Panorama":1.0,"a full FoV":1.0,"360circtimes180circ":1.0,"a more complete visual description":1.0,"perspective images":1.0,"Thanks":1.0}},"age_hours":2.770831596111111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8702,"joy":0.0068,"surprise":0.0748,"sadness":0.0141,"fear":0.0063,"anger":0.014,"disgust":0.0136},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for panoramic depth estimation, improving accuracy and efficiency. The creation of a large panoramic RGB-depth dataset (543K pairs) is a concrete action. However, it's still in the research phase with no clear deployment or economic viability demonstrated, hence the low scores for deployment readiness and economic viability.","key_impact_metrics":["38% improvement on AbsRel"],"technology_tags":["panoramic depth estimation","3D vision","spherical geometry"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:53:53.136496Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7bb312d29d8e","title":"SecureBERT 2.0: Advanced Language Model for Cybersecurity Intelligence","content":"arXiv:2510.00240v2 Announce Type: replace Abstract: Effective analysis of cybersecurity and threat intelligence data demands language models that can interpret specialized terminology, complex document structures, and the interdependence of natural language and source code. Encoder-only transformer architectures provide efficient and robust representations that support critical tasks such as semantic search, technical entity extraction, and semantic analysis, which are key to automated threat detection, incident triage, and vulnerability assessment. However, general-purpose language models often lack the domain-specific adaptation required for high precision. We present SecureBERT 2.0, an enhanced encoder-only language model purpose-built for cybersecurity applications. Leveraging the ModernBERT architecture, SecureBERT 2.0 introduces improved long-context modeling and hierarchical encoding, enabling effective processing of extended and heterogeneous documents, including threat reports and source code artifacts. Pretrained on a domain-specific corpus more than thirteen times larger than its predecessor, comprising over 13 billion text tokens and 53 million code tokens from diverse real-world sources, SecureBERT 2.0 achieves state-of-the-art performance on multiple cybersecurity benchmarks. Experimental results demonstrate substantial improvements in semantic search for threat intelligence, semantic analysis, cybersecurity-specific named entity recognition, and automated vulnerability detection in code within the cybersecurity domain.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.00240","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.295217","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Ehsan Aghaei, Sarthak Jain, Prashanth Arun, Arjun Sambamoorthy","raw_content_length":1560,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["ModernBERT"],"persons":[],"locations":[],"monetary":[]},"char_count":1559,"language_detected":"en","key_concepts":{"key_phrases":["Advanced Language Model","Cybersecurity Intelligence","arXiv251000240v2 Announce Type","Abstract","Effective analysis","cybersecurity and threat intelligence data","language models","specialized terminology","complex document structures","the interdependence"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Advanced Language Model":2.0,"Cybersecurity Intelligence":2.0,"arXiv251000240v2 Announce Type":1.0,"Abstract":1.0,"Effective analysis":1.0,"cybersecurity and threat intelligence data":1.0,"language models":1.0,"specialized terminology":1.0,"complex document structures":1.0,"the interdependence":1.0}},"age_hours":2.7708453219444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.662500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9325,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9238,"joy":0.0214,"surprise":0.0293,"sadness":0.0028,"fear":0.0086,"anger":0.0107,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"SecureBERT 2.0 is an enhanced language model for cybersecurity, demonstrating improved performance on benchmarks. The model is pretrained on a large domain-specific corpus, but there is no evidence of real-world deployment or economic viability. The impact on climate is indirect, potentially reducing energy consumption from cybersecurity tasks, but this is not quantified.","key_impact_metrics":["13 billion text tokens","53 million code tokens"],"technology_tags":["language model","cybersecurity","threat intelligence"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:54:01.621027Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_82855bb6d159","title":"Vicinity","content":"arXiv:2510.00478v2 Announce Type: replace Abstract: Recent work on latent diffusion models (LDMs) has focused almost exclusively on generative tasks, leaving their potential for discriminative transfer largely unexplored. We introduce Discriminative Vicinity Diffusion (DVD), a novel LDM-based framework for a more practical variant of source-free domain adaptation (SFDA): the source provider may share not only a pre-trained classifier but also an auxiliary latent diffusion module, trained once on the source data and never exposing raw source samples. DVD encodes each source feature's label information into its latent vicinity by fitting a Gaussian prior over its k-nearest neighbors and training the diffusion network to drift noisy samples back to label-consistent representations. During adaptation, we sample from each target feature's latent vicinity, apply the frozen diffusion module to generate source-like cues, and use a simple InfoNCE loss to align the target encoder to these cues, explicitly transferring decision boundaries without source access. Across standard SFDA benchmarks, DVD outperforms state-of-the-art methods. We further show that the same latent diffusion module enhances the source classifier's accuracy on in-domain data and boosts performance in supervised classification and domain generalization experiments. DVD thus reinterprets LDMs as practical, privacy-preserving bridges for explicit knowledge transfer, addressing a core challenge in source-free domain adaptation that prior methods have yet to solve.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.00478","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.295638","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Jing Wang, Wonho Bae, Jiahong Chen, Wenxu Wang, Junhyug Noh","raw_content_length":1547,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["LDM","Discriminative Vicinity Diffusion","SFDA"],"persons":[],"locations":[],"monetary":[]},"char_count":1546,"language_detected":"en","key_concepts":{"key_phrases":["Vicinity","arXiv251000478v2","Announce Type","Abstract","Recent work","latent diffusion models","LDMs","generative tasks","their potential","discriminative transfer"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vicinity":2.0,"arXiv251000478v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Recent work":1.0,"latent diffusion models":1.0,"LDMs":1.0,"generative tasks":1.0,"their potential":1.0,"discriminative transfer":1.0}},"age_hours":2.770860327777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.339,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4678,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9008,"joy":0.0295,"surprise":0.0491,"sadness":0.0043,"fear":0.0043,"anger":0.0077,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning framework (DVD) for source-free domain adaptation, potentially improving the efficiency of existing classifiers. While the technology itself doesn't directly reduce emissions, it could indirectly contribute by optimizing resource allocation in various sectors. The research is peer-reviewed and presents performance metrics, but it's still in the basic research stage with no deployed units.","key_impact_metrics":["Accuracy improvement on SFDA benchmarks","Performance boost in supervised classification"],"technology_tags":["Latent Diffusion Models","Source-Free Domain Adaptation","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:54:14.994189Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f91829e8c33","title":"Downgrade to Upgrade: Optimizer Simplification Enhances Robustness in LLM Unlearning","content":"arXiv:2510.00761v3 Announce Type: replace Abstract: Large language model (LLM) unlearning aims to surgically remove the influence of undesired data or knowledge from an existing model while preserving its utility on unrelated tasks. This paradigm has shown promise in addressing privacy and safety concerns. However, recent findings reveal that unlearning effects are often fragile: post-unlearning manipulations such as weight quantization or fine-tuning can quickly neutralize the intended forgetting. Prior efforts to improve robustness primarily reformulate unlearning objectives by explicitly assuming the role of vulnerability sources. In this work, we take a different perspective by investigating the role of the optimizer, independent of unlearning objectives and formulations, in shaping unlearning robustness. We show that the 'grade' of the optimizer, defined by the level of information it exploits, ranging from zeroth-order (gradient-free) to first-order (gradient-based) to second-order (Hessian-based), is tightly linked to the resilience of unlearning. Surprisingly, we find that downgrading the optimizer, such as using zeroth-order methods or compressed-gradient variants (e.g., gradient sign-based optimizers), often leads to stronger robustness. While these optimizers produce noisier and less precise updates, they encourage convergence to harder-to-disturb basins in the loss landscape, thereby resisting post-training perturbations. By connecting zeroth-order methods with randomized smoothing, we further highlight their natural advantage for robust unlearning. Motivated by these insights, we propose a hybrid optimizer that combines first-order and zeroth-order updates, preserving unlearning efficacy while enhancing robustness. Extensive experiments on the MUSE and WMDP benchmarks, across multiple LLM unlearning algorithms, validate that our approach achieves more resilient forgetting without sacrificing unlearning quality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.00761","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.296053","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Yicheng Lang, Yihua Zhang, Chongyu Fan, Changsheng Wang, Jinghan Jia, Sijia Liu","raw_content_length":1958,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1957,"language_detected":"en","key_concepts":{"key_phrases":["Downgrade","Upgrade","Optimizer Simplification","Robustness","LLM Unlearning","arXiv251000761v3 Announce Type","Abstract","Large language model","LLM unlearning aims","the influence"],"filter_categories":{"ai_ml":["LLM Unlearning","Large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Downgrade":2.0,"Upgrade":2.0,"Optimizer Simplification":2.0,"Robustness":2.0,"LLM Unlearning":2.0,"arXiv251000761v3 Announce Type":1.0,"Abstract":1.0,"Large language model":1.0,"LLM unlearning aims":1.0,"the influence":1.0}},"age_hours":2.7708749102777777,"is_recent":true,"quality_score":0.7,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.893,"joy":0.0082,"surprise":0.028,"sadness":0.0071,"fear":0.0383,"anger":0.014,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the robustness of LLM unlearning. While the research has potential implications for data privacy and safety, its direct impact on climate change is minimal. The paper includes experimental validation on benchmarks, suggesting some level of technical credibility, but it is still in the early stages of development and deployment.","key_impact_metrics":["Resilience of forgetting","Unlearning quality"],"technology_tags":["LLM unlearning","Optimizer simplification","Zeroth-order methods"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T12:54:18.301735Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e2050700c6b1","title":"AIReg","content":"arXiv:2510.01474v2 Announce Type: replace Abstract: As governments move to regulate AI, there is growing interest in using Large Language Models (LLMs) to assess whether or not an AI system complies with a given AI Regulation (AIR). However, there is presently no way to benchmark the performance of LLMs at this task. To fill this void, we introduce AIReg-Bench: the first benchmark dataset designed to test how well LLMs can assess compliance with the EU AI Act (AIA). We created this dataset through a two-step process: (1) by prompting an LLM with carefully structured instructions, we generated 120 technical documentation excerpts (samples), each depicting a fictional, albeit plausible, AI system - of the kind an AI provider might produce to demonstrate their compliance with AIR; (2) legal experts then reviewed and annotated each sample to indicate whether, and in what way, the AI system described therein violates specific Articles of the AIA. The resulting dataset, together with our evaluation of whether frontier LLMs can reproduce the experts' compliance labels, provides a starting point to understand the opportunities and limitations of LLM-based AIR compliance assessment tools and establishes a benchmark against which subsequent LLMs can be compared. The dataset and evaluation code are available at https://github.com/camlsys/aireg-bench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.01474","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.296812","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Bill Marino, Rosco Hunter, Zubair Jamali, Marinos Emmanouil Kalpakos, Mudra Kashyap, Isaiah Hinton, Alexa Hanson, Maahum Nazir, Christoph Schnabl, Felix Steffek, Hongkai Wen, Nicholas D. Lane","raw_content_length":1362,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["AIR","Large Language Models","AI Regulation","AIReg-Bench","AIReg","AIA","LLM"],"persons":["Articles"],"locations":[],"monetary":[]},"char_count":1361,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","AIReg","arXiv251001474v2","Announce Type","Abstract","governments","Large Language Models","a given AI Regulation","AIR","no way"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"AIReg":2.0,"arXiv251001474v2":1.0,"Announce Type":1.0,"Abstract":1.0,"governments":1.0,"Large Language Models":1.0,"a given AI Regulation":1.0,"AIR":1.0,"no way":1.0}},"age_hours":2.770903065,"is_recent":true,"quality_score":0.7,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8618,"joy":0.0154,"surprise":0.0224,"sadness":0.0054,"fear":0.0543,"anger":0.0323,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":true,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research creates a benchmark dataset (AIReg-Bench) to evaluate LLMs' ability to assess AI system compliance with regulations like the EU AI Act. While it doesn't directly reduce emissions, it could indirectly support sustainability by improving regulatory compliance and accountability of AI systems. The dataset is reviewed by legal experts, increasing technical credibility.","key_impact_metrics":["120 technical documentation excerpts","Expert compliance labels"],"technology_tags":["Large Language Models","AI Regulation"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:54:21.917665Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_27610381b4d7","title":"TetriServe: Efficient DiT Serving for Heterogeneous Image Generation","content":"arXiv:2510.01565v2 Announce Type: replace Abstract: Diffusion Transformer (DiT) models excel at generating highquality images through iterative denoising steps, but serving them under strict Service Level Objectives (SLOs) is challenging due to their high computational cost, particularly at large resolutions. Existing serving systems use fixed degree sequence parallelism, which is inefficient for heterogeneous workloads with mixed resolutions and deadlines, leading to poor GPU utilization and low SLO attainment. In this paper, we propose step-level sequence parallelism to dynamically adjust the parallel degree of individual requests according to their deadlines. We present TetriServe, a DiT serving system that implements this strategy for highly efficient image generation. Specifically, TetriServe introduces a novel round-based scheduling mechanism that improves SLO attainment: (1) discretizing time into fixed rounds to make deadline-aware scheduling tractable, (2) adapting parallelism at the step level and minimize GPU hour consumption, and (3) jointly packing requests to minimize late completions. Extensive evaluation on state-of-the-art DiT models shows that TetriServe achieves up to 32% higher SLO attainment compared to existing solutions without degrading image quality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.01565","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.297198","language":"en","tags":["computer-science","cslg","preprints","csdc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Runyu Lu, Shiqi He, Wenxuan Tan, Shenggui Li, Ruofan Wu, Jeff J. Ma, Ang Chen, Mosharaf Chowdhury","raw_content_length":1298,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Service Level Objectives","GPU","TetriServe","DiT","Diffusion Transformer","SLO"],"persons":["DiT Serving"],"locations":[],"monetary":[]},"char_count":1295,"language_detected":"en","key_concepts":{"key_phrases":["TetriServe","Efficient DiT","Heterogeneous Image Generation","arXiv251001565v2 Announce Type","Abstract","Diffusion Transformer DiT models","highquality images","iterative denoising steps","them","strict Service Level Objectives"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"TetriServe":2.0,"Efficient DiT":2.0,"Heterogeneous Image Generation":2.0,"arXiv251001565v2 Announce Type":1.0,"Abstract":1.0,"Diffusion Transformer DiT models":1.0,"highquality images":1.0,"iterative denoising steps":1.0,"them":1.0,"strict Service Level Objectives":1.0}},"age_hours":2.77091744,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8768,"joy":0.0103,"surprise":0.0385,"sadness":0.0157,"fear":0.0069,"anger":0.0348,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel system (TetriServe) for efficient serving of Diffusion Transformer models, potentially reducing the energy consumption associated with image generation. The system achieves up to 32% higher SLO attainment compared to existing solutions, indicating a measurable improvement in efficiency. However, it is still in the research phase, with no evidence of real-world deployment.","key_impact_metrics":["32% higher SLO attainment"],"technology_tags":["Diffusion Transformer","Image Generation","GPU Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:54:33.207396Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_834d683e2581","title":"Contrastive Representation Regularization for Vision","content":"arXiv:2510.01711v2 Announce Type: replace Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot manipulation by leveraging rich representations from pre-trained Vision-Language Models (VLMs). However, their representations arguably remain suboptimal, lacking sensitivity to robotic signals such as control actions and proprioceptive states. To address the issue, we introduce Robot State-aware Contrastive Loss (RS-CL), a simple and effective representation regularization for VLA models, designed to bridge the gap between VLM representations and robotic signals. In particular, RS-CL aligns the representations more closely with the robot's proprioceptive states, by using relative distances between the states as soft supervision. Complementing the original action prediction objective, RS-CL effectively enhances control-relevant representation learning, while being lightweight and fully compatible with standard VLA training pipeline. Our empirical results demonstrate that RS-CL substantially improves the manipulation performance of state-of-the-art VLA models; it pushes the prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen, through more accurate positioning during grasping and placing, and boosts success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.01711","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.297605","language":"en","tags":["computer-science","cslg","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Taeyoung Kim, Jimin Lee, Myungkyu Koo, Dongyoung Kim, Kyungmin Lee, Changyeon Kim, Younggyo Seo, Jinwoo Shin","raw_content_length":1342,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["VLM","Contrastive Loss","VLA","Vision-Language Models","Vision-Language-Action","Contrastive Representation Regularization for Vision arXiv:2510.01711v2 Announce Type: replace Abstract"],"persons":["Robot State-aware"],"locations":[],"monetary":[]},"char_count":1341,"language_detected":"en","key_concepts":{"key_phrases":["Contrastive Representation Regularization","Vision","arXiv251001711v2 Announce Type","Abstract","VLA","its capabilities","robot manipulation","rich representations","pre-trained Vision-Language Models","VLMs"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contrastive Representation Regularization":2.0,"Vision":2.0,"arXiv251001711v2 Announce Type":1.0,"Abstract":1.0,"VLA":1.0,"its capabilities":1.0,"robot manipulation":1.0,"rich representations":1.0,"pre-trained Vision-Language Models":1.0,"VLMs":1.0}},"age_hours":2.7709394475,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8717,"joy":0.0048,"surprise":0.0099,"sadness":0.0086,"fear":0.0547,"anger":0.0269,"disgust":0.0234},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on improving robot manipulation using vision-language-action models. While the research shows improved performance on pick-and-place tasks, it is still in the applied research phase with no clear path to commercial deployment or quantifiable climate impact. The improved robot manipulation could potentially contribute to more efficient manufacturing or logistics in the future, but this is speculative at this stage.","key_impact_metrics":["Success rate on pick-and-place tasks in RoboCasa-Kitchen: 41.5%","Success rates on real-robot manipulation tasks: 58.3%"],"technology_tags":["Vision-Language-Action models","Robot manipulation","Contrastive learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:54:41.587395Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8c1c2de2de17","title":"Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product","content":"arXiv:2510.02167v2 Announce Type: replace Abstract: In a circular economy, products in their end-of-life phase should be either remanufactured or recycled. Both of these processes are crucial for sustainability and environmental conservation. However, manufacturers frequently do not support these processes enough in terms of not sharing relevant data about the products nor their (re-)manufacturing processes. This paper proposes to accompany each product with a digital twin technology, specifically the Product Digital Twin (PDT), which can carry information for facilitating and optimizing production and remanufacturing processes. This paper introduces a knowledge representation called Bi-Flow Product-Process-Resource Asset Network (Bi-PAN). Bi-PAN extends a well-proven Product-Process-Resource Asset Network (PAN) paradigm by integrating both assembly and disassembly workflows into a single information model. Such networks enable capturing relevant relationships across products, production resources, manufacturing processes, and specific production operations that have to be done in the manufacturing phase of a product. The proposed approach is demonstrated in a use-case of disassembling electric vehicle (EV) batteries. By utilizing PDTs with Bi-PAN knowledge models, challenges associated with disassembling of EV batteries can be solved flexibly and efficiently for various battery types, enhancing the sustainability of the EV battery life-cycle management.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02167","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.298385","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Sara Strakosova, Petr Novak, Petr Kadera","raw_content_length":1479,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["PAN","Phase of Electric Vehicle Batteries Utilizing Product arXiv:2510.02167v2 Announce Type","Product-Process-Resource Asset Network","Bi-PAN","Bi-Flow Product-Process-Resource Asset Network"],"persons":["Bi-PAN"],"locations":[],"monetary":[]},"char_count":1478,"language_detected":"en","key_concepts":{"key_phrases":["life","Product","Digital Twin","Electric Vehicle Batteries","Utilizing Product","these processes","arXiv251002167v2 Announce Type","Abstract","a circular economy","products"],"filter_categories":{"hydrogen_energy":["Product"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"life":3.0,"Product":2.0,"Digital Twin":2.0,"Electric Vehicle Batteries":2.0,"Utilizing Product":2.0,"these processes":2.0,"arXiv251002167v2 Announce Type":1.0,"Abstract":1.0,"a circular economy":1.0,"products":1.0}},"age_hours":2.77097258,"is_recent":true,"quality_score":1.0,"sentiment_score":4.123,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1754,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.893,"joy":0.0063,"surprise":0.0157,"sadness":0.0202,"fear":0.0053,"anger":0.03,"disgust":0.0295},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a digital twin technology (PDT) with Bi-PAN knowledge models to improve the disassembly of EV batteries, which could enhance sustainability in EV battery lifecycle management. The article focuses on a concept and knowledge representation rather than deployed technology, placing it in the applied research phase. There are no concrete metrics or deployment data provided, limiting the assessment of economic viability and deployment readiness.","key_impact_metrics":[],"technology_tags":["digital twin","electric vehicle battery disassembly","Bi-Flow Product-Process-Resource Asset Network"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:54:44.969274Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b3ce3b17d158","title":"NeuroSwift: A Lightweight Cross","content":"arXiv:2510.02266v2 Announce Type: replace Abstract: Reconstructing visual information from brain activity via computer vision technology provides an intuitive understanding of visual neural mechanisms. Despite progress in decoding fMRI data with generative models, achieving accurate cross-subject reconstruction of visual stimuli remains challenging and computationally demanding. This difficulty arises from inter-subject variability in neural representations and the brain's abstract encoding of core semantic features in complex visual inputs. To address these challenges, we propose NeuroSwift, which integrates complementary adapters via diffusion: AutoKL for low-level features and CLIP for semantics. NeuroSwift's CLIP Adapter is trained on Stable Diffusion generated images paired with COCO captions to emulate higher visual cortex encoding. For cross-subject generalization, we pretrain on one subject and then fine-tune only 17 percent of parameters (fully connected layers) for new subjects, while freezing other components. This enables state-of-the-art performance with only one hour of training per subject on lightweight GPUs (three RTX 4090), and it outperforms existing methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02266","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.298789","language":"en","tags":["computer-science","preprints","cscv","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Shiyi Zhang, Dong Liang, Yihang Zhou","raw_content_length":1197,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Stable Diffusion","NeuroSwift","CLIP Adapter","A Lightweight Cross","CLIP"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1196,"language_detected":"en","key_concepts":{"key_phrases":["NeuroSwift","A Lightweight Cross","Announce Type","Abstract","visual information","brain activity","computer vision technology","an intuitive understanding","visual neural mechanisms","progress"],"filter_categories":{"ai_ml":["brain activity","computer vision technology"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"NeuroSwift":2.0,"A Lightweight Cross":2.0,"Announce Type":1.0,"Abstract":1.0,"visual information":1.0,"brain activity":1.0,"computer vision technology":1.0,"an intuitive understanding":1.0,"visual neural mechanisms":1.0,"progress":1.0}},"age_hours":2.7709866,"is_recent":true,"quality_score":1.0,"sentiment_score":2.3804999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5239,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.781,"joy":0.0193,"surprise":0.0654,"sadness":0.0192,"fear":0.0937,"anger":0.014,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"NeuroSwift is a novel approach to reconstructing visual information from brain activity, demonstrating state-of-the-art performance with reduced training time and computational resources. However, it's currently in the applied research phase with no deployed units or real-world data beyond the research setting. The sustainability impact is limited as it's not directly related to climate change mitigation or adaptation, but the reduced computational requirements could lead to energy savings compared to previous methods.","key_impact_metrics":["1 hour training time per subject","17 percent of parameters fine-tuned"],"technology_tags":["fMRI decoding","diffusion models","computer vision"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:54:48.644126Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_de3538020775","title":"Equilibrium Matching: Generative Modeling with Implicit Energy","content":"arXiv:2510.02300v3 Announce Type: replace Abstract: We introduce Equilibrium Matching (EqM), a generative modeling framework built from an equilibrium dynamics perspective. EqM discards the non-equilibrium, time-conditional dynamics in traditional diffusion and flow-based generative models and instead learns the equilibrium gradient of an implicit energy landscape. Through this approach, we can adopt an optimization-based sampling process at inference time, where samples are obtained by gradient descent on the learned landscape with adjustable step sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation performance of diffusion/flow models empirically, achieving an FID of 1.90 on ImageNet 256$\\times$256. EqM is also theoretically justified to learn and sample from the data manifold. Beyond generation, EqM is a flexible framework that naturally handles tasks including partially noised image denoising, OOD detection, and image composition. By replacing time-conditional velocities with a unified equilibrium landscape, EqM offers a tighter bridge between flow and energy-based models and a simple route to optimization-driven inference.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02300","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.299173","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Runqian Wang, Yilun Du","raw_content_length":1172,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["ImageNet","EqM","Equilibrium Matching"],"persons":[],"locations":[],"monetary":[]},"char_count":1171,"language_detected":"en","key_concepts":{"key_phrases":["Equilibrium Matching","Generative Modeling","Implicit Energy","EqM","Announce Type","Abstract","a generative modeling framework","an equilibrium dynamics perspective","the non","equilibrium time-conditional dynamics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Equilibrium Matching":3.0,"Generative Modeling":2.0,"Implicit Energy":2.0,"EqM":2.0,"Announce Type":1.0,"Abstract":1.0,"a generative modeling framework":1.0,"an equilibrium dynamics perspective":1.0,"the non":1.0,"equilibrium time-conditional dynamics":1.0}},"age_hours":2.7710015194444444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9007,"joy":0.0305,"surprise":0.0395,"sadness":0.0042,"fear":0.0069,"anger":0.013,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new generative modeling framework (EqM) that achieves a specific FID score (1.90 on ImageNet 256x256). While the technology is theoretically justified and shows improved performance, it is still in the research phase with no deployed units or real-world applications to demonstrate its impact on climate change or sustainability. The potential for climate impact is based on the assumption that more efficient generative models could reduce computational energy consumption, but this is not directly addressed or quantified.","key_impact_metrics":["FID score of 1.90 on ImageNet 256x256"],"technology_tags":["Generative Modeling","Implicit Energy","Equilibrium Matching"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:54:52.909122Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_56bcff7f370b","title":"Measuring Physical","content":"arXiv:2510.02356v2 Announce Type: replace Abstract: The deployment of Large Language Models (LLMs) in embodied agents creates an urgent need to measure their privacy awareness in the physical world. Existing evaluation methods, however, are confined to natural language based scenarios. To bridge this gap, we introduce EAPrivacy, a comprehensive evaluation benchmark designed to quantify the physical-world privacy awareness of LLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across four tiers to test an agent's ability to handle sensitive objects, adapt to changing environments, balance task execution with privacy constraints, and resolve conflicts with social norms. Our measurements reveal a critical deficit in current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\\% accuracy in scenarios involving changing physical environments. Furthermore, when a task was accompanied by a privacy request, models prioritized completion over the constraint in up to 86\\% of cases. In high-stakes situations pitting privacy against critical social norms, leading models like GPT-4o and Claude-3.5-haiku disregarded the social norm over 15\\% of the time. These findings, demonstrated by our benchmark, underscore a fundamental misalignment in LLMs regarding physically grounded privacy and establish the need for more robust, physically-aware alignment. Codes and datasets will be available at https://github.com/Graph-COM/EAPrivacy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02356","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.299593","language":"en","tags":["computer-science","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Xinjie Shen, Mufei Li, Pan Li","raw_content_length":1472,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","EAPrivacy"],"persons":[],"locations":[],"monetary":[]},"char_count":1471,"language_detected":"en","key_concepts":{"key_phrases":["Physical","EAPrivacy","Announce Type","Abstract","The deployment","Large Language Models","LLMs","embodied agents","an urgent need","their privacy awareness"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Physical":2.0,"EAPrivacy":2.0,"Announce Type":1.0,"Abstract":1.0,"The deployment":1.0,"Large Language Models":1.0,"LLMs":1.0,"embodied agents":1.0,"an urgent need":1.0,"their privacy awareness":1.0}},"age_hours":2.7710161458333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9012,"joy":0.0091,"surprise":0.0257,"sadness":0.0063,"fear":0.034,"anger":0.0173,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on evaluating the privacy awareness of LLM-powered agents in physical environments, revealing a deficit in current models. The EAPrivacy benchmark provides measurable outcomes, such as the top-performing model achieving only 59% accuracy in changing environments and models prioritizing task completion over privacy in up to 86% of cases. While the research highlights a critical issue, it's still in the applied research stage with no deployed technology directly impacting climate or sustainability.","key_impact_metrics":["59% accuracy in changing environments","86% prioritization of task completion over privacy"],"technology_tags":["Large Language Models","Embodied Agents","Privacy"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:54:56.367785Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_635bbed6c304","title":"AP2O: Correcting LLM","content":"arXiv:2510.02393v2 Announce Type: replace Abstract: LLMs' code generation capabilities have yielded substantial improvements in the effectiveness of programming tasks. However, LLM-generated code still suffers from compilation and runtime errors. Existing offline preference optimization methods primarily focus on enhancing LLMs' coding abilities using pass/fail signals in the preference data, overlooking the deep-level error types in the failed codes. To address this, we propose Adaptively Progressive Preference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that guides LLMs adaptively and methodically to reduce code errors for code generation. Specifically, we construct an error notebook from failed codes and progressively optimize the LLM to correct errors type by type. Furthermore, we adaptively replay error types to tailor to the LLM's changing weaknesses throughout the training process. Through extensive experiments on both code and general LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from 0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in pass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02393","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.299973","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Jianqing Zhang, Wei Xia, Hande Dong, Qiang Lin, Jian Cao","raw_content_length":1201,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Adaptively Progressive Preference Optimization","LLM"],"persons":["AP2O-Coder"],"locations":[],"monetary":[]},"char_count":1200,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251002393v2","Announce Type","Abstract","LLMs code generation capabilities","substantial improvements","the effectiveness","programming tasks","LLM-generated code","compilation","runtime errors"],"filter_categories":{"ai_ml":["LLMs code generation capabilities"],"engineering":["programming tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251002393v2":1.0,"Announce Type":1.0,"Abstract":1.0,"LLMs code generation capabilities":1.0,"substantial improvements":1.0,"the effectiveness":1.0,"programming tasks":1.0,"LLM-generated code":1.0,"compilation":1.0,"runtime errors":1.0}},"age_hours":2.7710312383333333,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7570000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6486,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8155,"joy":0.007,"surprise":0.0204,"sadness":0.1174,"fear":0.0083,"anger":0.0125,"disgust":0.0189},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method (AP2O-Coder) to improve code generation by LLMs, reducing compilation and runtime errors. The concrete action is the development and testing of this method on code and general LLMs. Evidence includes experimental results showing up to 3% improvement in pass@k, but there is no deployment or real-world application yet, placing it in the applied research stage.","key_impact_metrics":["3% improvement in pass@k","Less preference data used"],"technology_tags":["Large Language Models","Code Generation","Preference Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:54:59.708369Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
