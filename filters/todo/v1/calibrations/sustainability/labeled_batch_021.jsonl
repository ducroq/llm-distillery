{"id":"science_arxiv_cs_4406a3e420d8","title":"ASBench: Image Anomalies Synthesis Benchmark for Anomaly Detection","content":"arXiv:2510.07927v1 Announce Type: new Abstract: Anomaly detection plays a pivotal role in manufacturing quality control, yet its application is constrained by limited abnormal samples and high manual annotation costs. While anomaly synthesis offers a promising solution, existing studies predominantly treat anomaly synthesis as an auxiliary component within anomaly detection frameworks, lacking systematic evaluation of anomaly synthesis algorithms. Current research also overlook crucial factors specific to anomaly synthesis, such as decoupling its impact from detection, quantitative analysis of synthetic data and adaptability across different scenarios. To address these limitations, we propose ASBench, the first comprehensive benchmarking framework dedicated to evaluating anomaly synthesis methods. Our framework introduces four critical evaluation dimensions: (i) the generalization performance across different datasets and pipelines (ii) the ratio of synthetic to real data (iii) the correlation between intrinsic metrics of synthesis images and anomaly detection performance metrics , and (iv) strategies for hybrid anomaly synthesis methods. Through extensive experiments, ASBench not only reveals limitations in current anomaly synthesis methods but also provides actionable insights for future research directions in anomaly synthesis","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07927","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.212324","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Qunyi Zhang, Songan Zhang, Jinbao Wang, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu","raw_content_length":1352,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1351,"language_detected":"en","key_concepts":{"key_phrases":["anomaly synthesis","Image Anomalies Synthesis Benchmark","Anomaly Detection","arXiv251007927v1 Announce Type","new Abstract","Anomaly detection","a pivotal role","quality control","its application","limited abnormal samples"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"anomaly synthesis":3.0,"Image Anomalies Synthesis Benchmark":2.0,"Anomaly Detection":2.0,"arXiv251007927v1 Announce Type":1.0,"new Abstract":1.0,"Anomaly detection":1.0,"a pivotal role":1.0,"quality control":1.0,"its application":1.0,"limited abnormal samples":1.0}},"age_hours":2.7722682888888888,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8202,"joy":0.0043,"surprise":0.0361,"sadness":0.0462,"fear":0.036,"anger":0.0232,"disgust":0.0341},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a benchmarking framework (ASBench) for evaluating anomaly synthesis methods, which could indirectly improve manufacturing quality control and reduce waste. However, it is still in the research phase, with no deployed technology or measured outcomes related to emissions reduction or resource efficiency. The framework introduces four evaluation dimensions, suggesting a quantitative approach, but the actual impact on sustainability is theoretical at this stage.","key_impact_metrics":["Generalization performance across different datasets","Ratio of synthetic to real data"],"technology_tags":["Anomaly detection","Image synthesis","Manufacturing quality control"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:35:36.175845Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ccc637c52262","title":"Scaling crossover of the generalized Jeffreys","content":"arXiv:2510.07930v1 Announce Type: new Abstract: The generalized Jeffreys-type law is formulated as a multi-term time-fractional Jeffreys-type equation, whose dynamics exhibit rich scaling crossover phenomena entailing different diffusion mechanisms. In this work, we provide a novel physical explanation for the equation from first principles, beginning with a microscopic description based on the continuous-time random walk framework with a generalized waiting time distribution and further deriving the equation from an overdamped Langevin equation subject to a stochastic time-change (subordination). Employing the Laplace transform method, we conduct a rigorous analysis of the equation, establishing its well-posedness and providing a detailed Sobolev regularity analysis. We also develop a novel numerical scheme, termed the CIM-CLG algorithm, which achieves spectral accuracy in both time and space while substantially relaxing the temporal regularity requirements on the solution. The algorithm reduces the computational complexity to $\\mathcal{O}(N)$ in time and $\\mathcal{O}(M\\log M)$ in space and is fully parallelizable. Detailed implementation guidelines and new technical error estimates are provided. Extensive numerical experiments in 1D and 2D settings validate the efficiency, robustness, and accuracy of the proposed method. By integrating stochastic modeling, mathematical analysis, and numerical computation, this work advances the understanding of the generalized Jeffreys-type law and offers a mathematically rigorous and computationally efficient framework for tackling complex nonlocal problems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07930","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.212747","language":"en","tags":["csna","computer-science","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Fugui Ma","raw_content_length":1622,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["Laplace","Jeffreys arXiv:2510.07930v1 Announce Type: new Abstract"],"persons":[],"locations":["Langevin"],"monetary":[]},"char_count":1621,"language_detected":"en","key_concepts":{"key_phrases":["crossover","the generalized Jeffreys","Announce Type","new Abstract","The generalized Jeffreys-type law","a multi-term time-fractional Jeffreys-type equation","whose dynamics","rich scaling crossover phenomena","different diffusion mechanisms","this work"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"crossover":2.0,"the generalized Jeffreys":2.0,"Announce Type":1.0,"new Abstract":1.0,"The generalized Jeffreys-type law":1.0,"a multi-term time-fractional Jeffreys-type equation":1.0,"whose dynamics":1.0,"rich scaling crossover phenomena":1.0,"different diffusion mechanisms":1.0,"this work":1.0}},"age_hours":2.772282816388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.953,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7906,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8399,"joy":0.024,"surprise":0.0904,"sadness":0.0034,"fear":0.018,"anger":0.0163,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel numerical scheme for solving a generalized Jeffreys-type equation. While the research is mathematically rigorous and computationally efficient, it is still in the basic research phase and lacks concrete application to climate change mitigation or adaptation. The potential climate impact is theoretical and depends on future applications.","key_impact_metrics":["Computational complexity reduced to O(N) in time","Computational complexity reduced to O(MlogM) in space"],"technology_tags":["Numerical methods","Fractional calculus","Computational science"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:35:38.980987Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_62d9824ea7ee","title":"Vision","content":"arXiv:2510.07931v1 Announce Type: new Abstract: This article presents research conducted at the Institute of the Estonian Language between 2022 and 2025 on the application of large language models (LLMs) to the study of 17th and 18th century Estonian dictionaries. The authors address three main areas: enriching historical dictionaries with modern word forms and meanings; using vision-enabled LLMs to perform text recognition on sources printed in Gothic script (Fraktur); and preparing for the creation of a unified, cross-source dataset. Initial experiments with J. Gutslaff's 1648 dictionary indicate that LLMs have significant potential for semi-automatic enrichment of dictionary information. When provided with sufficient context, Claude 3.7 Sonnet accurately provided meanings and modern equivalents for 81% of headword entries. In a text recognition experiment with A. T. Helle's 1732 dictionary, a zero-shot method successfully identified and structured 41% of headword entries into error-free JSON-formatted output. For digitising the Estonian-German dictionary section of A. W. Hupel's 1780 grammar, overlapping tiling of scanned image files is employed, with one LLM being used for text recognition and a second for merging the structured output. These findings demonstrate that even for minor languages LLMs have a significant potential for saving time and financial resources.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07931","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.213133","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Madis J\\\"urviste, Joonatan Jakobson","raw_content_length":1393,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Fraktur","Claude 3.7 Sonnet","the Institute of the Estonian Language","Gothic"],"persons":["A. T. Helle's","J. Gutslaff's"],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["Vision","arXiv251007931v1 Announce Type","new Abstract","This article","research","the Institute","the Estonian Language","the application","large language models","LLMs"],"filter_categories":{"ai_ml":["Vision","large language models"],"healthcare_tech":["research"],"research_academic":["research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vision":2.0,"arXiv251007931v1 Announce Type":1.0,"new Abstract":1.0,"This article":1.0,"research":1.0,"the Institute":1.0,"the Estonian Language":1.0,"the application":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.772298094166667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8268,"joy":0.0997,"surprise":0.0469,"sadness":0.0084,"fear":0.0052,"anger":0.0088,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":5,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research into using LLMs to digitize and enrich historical dictionaries. While this doesn't directly address climate change, it can indirectly contribute to sustainability by preserving cultural heritage and potentially reducing the need for physical resources. The project is in the applied research stage, with some initial experiments showing promising results, such as 81% accuracy in providing meanings and modern equivalents for headword entries.","key_impact_metrics":["81% accuracy for meaning equivalents","41% error-free headword structuring"],"technology_tags":["Large Language Models","Optical Character Recognition","Text Digitization"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-28T20:35:41.961406Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7def788d850d","title":"An AUTOSAR","content":"arXiv:2510.07941v1 Announce Type: new Abstract: Cooperative, Connected and Automated Mobility (CCAM) are complex cyber-physical systems (CPS) that integrate computation, communication, and control in safety-critical environments. At their core, System-on-Chip (SoC) platforms consolidate processing units, communication interfaces, AI accelerators, and security modules into a single chip. AUTOSAR (AUTomotive Open System ARchitecture) standard was developed in the automotive domain to better manage this complexity, defining layered software structures and interfaces to facilitate reuse of HW/SW components. However, in practice, this integrated SoC software architecture still poses security challenges, particularly in real-time, safety-critical environments. Recent reports highlight a surge in SoC-related vulnerabilities, yet systematic analysis of their root causes and impact within AUTOSAR-aligned architectures is lacking. This study fills that gap by analyzing 180 publicly reported automotive SoC vulnerabilities, mapped to a representative SoC software architecture model that is aligned with AUTOSAR principles for layered abstraction and service orientation. We identify 16 root causes and 56 affected software modules, and examine mitigation delays across Common Weakness Enumeration (CWE) categories and architectural layers. We uncover dominant vulnerability patterns and critical modules with prolonged patch delays, and provide actionable insights for securing automotive CPS platforms, including guides for improved detection, prioritization, and localization strategies for SoC software architectures in SoC-based vehicle platforms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07941","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.214288","language":"en","tags":["research","preprints","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Srijita Basu, Haraldsson Bengt, Miroslaw Staron, Christian Berger, Jennifer Horkoff, Magnus Almgren","raw_content_length":1657,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["Connected","CCAM","HW/SW","CPS"],"persons":[],"locations":[],"monetary":[]},"char_count":1656,"language_detected":"en","key_concepts":{"key_phrases":["An AUTOSAR","Announce Type","new Abstract","Automated Mobility","CCAM","complex cyber-physical systems","CPS","computation","communication","control"],"filter_categories":{"engineering":["control"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"An AUTOSAR":2.0,"Announce Type":1.0,"new Abstract":1.0,"Automated Mobility":1.0,"CCAM":1.0,"complex cyber-physical systems":1.0,"CPS":1.0,"computation":1.0,"communication":1.0,"control":1.0}},"age_hours":2.7723426808333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8703,"joy":0.0172,"surprise":0.0811,"sadness":0.0059,"fear":0.0123,"anger":0.0107,"disgust":0.0025},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research analyzes vulnerabilities in automotive SoC software architectures, identifying root causes and affected modules. While it doesn't directly reduce GHG emissions, improving the security and reliability of automotive systems, especially in the context of autonomous driving, could indirectly contribute to safer and more efficient transportation. The study provides actionable insights for securing automotive CPS platforms, but it's still in the applied research phase with no deployed technology mentioned.","key_impact_metrics":["180 automotive SoC vulnerabilities analyzed","16 root causes identified"],"technology_tags":["AUTOSAR","System-on-Chip","Cyber-Physical Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:35:44.937444Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4edd260fe42b","title":"CVD-STORM: Cross","content":"arXiv:2510.07944v1 Announce Type: new Abstract: Generative models have been widely applied to world modeling for environment simulation and future state prediction. With advancements in autonomous driving, there is a growing demand not only for high-fidelity video generation under various controls, but also for producing diverse and meaningful information such as depth estimation. To address this, we propose CVD-STORM, a cross-view video diffusion model utilizing a spatial-temporal reconstruction Variational Autoencoder (VAE) that generates long-term, multi-view videos with 4D reconstruction capabilities under various control inputs. Our approach first fine-tunes the VAE with an auxiliary 4D reconstruction task, enhancing its ability to encode 3D structures and temporal dynamics. Subsequently, we integrate this VAE into the video diffusion process to significantly improve generation quality. Experimental results demonstrate that our model achieves substantial improvements in both FID and FVD metrics. Additionally, the jointly-trained Gaussian Splatting Decoder effectively reconstructs dynamic scenes, providing valuable geometric information for comprehensive scene understanding.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07944","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.215046","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Tianrui Zhang, Yichen Liu, Zilin Guo, Yuxin Guo, Jingcheng Ni, Chenjing Ding, Dan Xu, Lewei Lu, Zehuan Wu","raw_content_length":1198,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["CVD-STORM:","VAE","CVD-STORM"],"persons":["Variational Autoencoder"],"locations":[],"monetary":[]},"char_count":1197,"language_detected":"en","key_concepts":{"key_phrases":["CVD-STORM","Announce Type","new Abstract","Generative models","world modeling","environment simulation","future state prediction","advancements","autonomous driving","a growing demand"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CVD-STORM":3.0,"Announce Type":1.0,"new Abstract":1.0,"Generative models":1.0,"world modeling":1.0,"environment simulation":1.0,"future state prediction":1.0,"advancements":1.0,"autonomous driving":1.0,"a growing demand":1.0}},"age_hours":2.7723709444444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.339,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4678,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.864,"joy":0.0431,"surprise":0.0711,"sadness":0.0033,"fear":0.0059,"anger":0.0093,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to video generation for autonomous driving, potentially leading to more efficient simulations and training. However, it is currently in the applied research stage, with no deployed units or real-world impact data. The model achieves improvements in FID and FVD metrics, but the connection to concrete sustainability outcomes is indirect and theoretical at this point.","key_impact_metrics":["FID improvement","FVD improvement"],"technology_tags":["Generative Models","Autonomous Driving","Video Diffusion Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:35:47.897753Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_65588881adee","title":"Likelihood","content":"arXiv:2510.07950v1 Announce Type: new Abstract: Bayesian inverse problems use data to update a prior probability distribution on uncertain parameter values to a posterior distribution. Such problems arise in many structural engineering applications, but computational solution of Bayesian inverse problems is often expensive because standard solution approaches require many evaluations of the forward model mapping the parameter value to predicted observations. In many settings, this forward model is expensive because it requires the solution of a high-dimensional discretization of a partial differential equation. However, Bayesian inverse problems often exhibit low-dimensional structure because the available data are primarily informative (relative to the prior) in a low-dimensional subspace, sometimes called the likelihood-informed subspace (LIS). This paper proposes a new projection-based model reduction method for static linear systems that exploits this low-dimensional structure in the setting where the unknown parameter is the right-hand-side forcing. The proposed method projects the governing partial differential equation onto the likelihood-informed subspace, yielding a computationally efficient reduced model that can be used to accelerate the solution of the inverse problem. Numerical experiments on two structural engineering model problems demonstrate that the proposed approach can successfully exploit the intrinsic low-dimensionality of the problem, obtaining relative errors of O(10^{-10}) in the inverse problem solution with a 10x-100x lower-dimensional model.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07950","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.215464","language":"en","tags":["csna","computer-science","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Jakob Scheffels, Elizabeth Qian, Iason Papaioannou, Elisabeth Ullmann","raw_content_length":1596,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1595,"language_detected":"en","key_concepts":{"key_phrases":["Likelihood","Bayesian inverse problems","arXiv251007950v1 Announce Type","new Abstract","data","a prior probability distribution","uncertain parameter values","a posterior distribution","Such problems","many structural engineering applications"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Likelihood":2.0,"Bayesian inverse problems":2.0,"arXiv251007950v1 Announce Type":1.0,"new Abstract":1.0,"data":1.0,"a prior probability distribution":1.0,"uncertain parameter values":1.0,"a posterior distribution":1.0,"Such problems":1.0,"many structural engineering applications":1.0}},"age_hours":2.7723844125,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6296,"joy":0.0053,"surprise":0.0174,"sadness":0.0375,"fear":0.1464,"anger":0.0908,"disgust":0.073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a model reduction method for structural engineering problems, leading to computationally efficient reduced models. Numerical experiments show relative errors of O(10^{-10}) with a 10x-100x lower-dimensional model. This could potentially reduce energy consumption associated with computationally intensive structural simulations, but it's still in the applied research phase.","key_impact_metrics":["relative errors of O(10^{-10})","10x-100x lower-dimensional model"],"technology_tags":["model reduction","Bayesian inverse problems","structural engineering"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:35:50.767807Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae66cc97bd3a","title":"A Large","content":"arXiv:2510.07951v1 Announce Type: new Abstract: Current text detection datasets primarily target natural or document scenes, where text typically appear in regular font and shapes, monotonous colors, and orderly layouts. The text usually arranged along straight or curved lines. However, these characteristics differ significantly from anime scenes, where text is often diverse in style, irregularly arranged, and easily confused with complex visual elements such as symbols and decorative patterns. Text in anime scene also includes a large number of handwritten and stylized fonts. Motivated by this gap, we introduce AnimeText, a large-scale dataset containing 735K images and 4.2M annotated text blocks. It features hierarchical annotations and hard negative samples tailored for anime scenarios. %Cross-dataset evaluations using state-of-the-art methods demonstrate that models trained on AnimeText achieve superior performance in anime text detection tasks compared to existing datasets. To evaluate the robustness of AnimeText in complex anime scenes, we conducted cross-dataset benchmarking using state-of-the-art text detection methods. Experimental results demonstrate that models trained on AnimeText outperform those trained on existing datasets in anime scene text detection tasks. AnimeText on HuggingFace: https://huggingface.co/datasets/deepghs/AnimeText","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07951","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.215846","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Ziyi Dong, Yurui Zhang, Changmao Li, Naomi Rue Golding, Qing Long","raw_content_length":1371,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["AnimeText"],"persons":[],"locations":[],"monetary":[]},"char_count":1370,"language_detected":"en","key_concepts":{"key_phrases":["text","arXiv251007951v1 Announce Type","new Abstract","Current text detection datasets","natural or document scenes","regular font","shapes","monotonous colors","orderly layouts","The text"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"text":2.0,"arXiv251007951v1 Announce Type":1.0,"new Abstract":1.0,"Current text detection datasets":1.0,"natural or document scenes":1.0,"regular font":1.0,"shapes":1.0,"monotonous colors":1.0,"orderly layouts":1.0,"The text":1.0}},"age_hours":2.7723991058333333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8154,"joy":0.0416,"surprise":0.1101,"sadness":0.0101,"fear":0.0055,"anger":0.0091,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new dataset for anime text detection. While the dataset itself doesn't directly impact climate change, it could potentially be used to improve AI models that could be applied to sustainability challenges in the future. The dataset contains 735K images and 4.2M annotated text blocks, providing a large-scale resource for research.","key_impact_metrics":["735K images","4.2M annotated text blocks"],"technology_tags":["text detection","image recognition","dataset"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:35:53.966911Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_848a288530e6","title":"SimCast: Enhancing Precipitation Nowcasting with Short","content":"arXiv:2510.07953v1 Announce Type: new Abstract: Precipitation nowcasting predicts future radar sequences based on current observations, which is a highly challenging task driven by the inherent complexity of the Earth system. Accurate nowcasting is of utmost importance for addressing various societal needs, including disaster management, agriculture, transportation, and energy optimization. As a complementary to existing non-autoregressive nowcasting approaches, we investigate the impact of prediction horizons on nowcasting models and propose SimCast, a novel training pipeline featuring a short-to-long term knowledge distillation technique coupled with a weighted MSE loss to prioritize heavy rainfall regions. Improved nowcasting predictions can be obtained without introducing additional overhead during inference. As SimCast generates deterministic predictions, we further integrate it into a diffusion-based framework named CasCast, leveraging the strengths from probabilistic models to overcome limitations such as blurriness and distribution shift in deterministic outputs. Extensive experimental results on three benchmark datasets validate the effectiveness of the proposed framework, achieving mean CSI scores of 0.452 on SEVIR, 0.474 on HKO-7, and 0.361 on MeteoNet, which outperforms existing approaches by a significant margin.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07953","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.216355","language":"en","tags":["computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Yifang Yin, Shengkai Chen, Yiyao Li, Lu Wang, Ruibing Jin, Wei Cui, Shili Xiang","raw_content_length":1348,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["SimCast","CasCast","MSE","Accurate"],"persons":[],"locations":["Earth"],"monetary":[]},"char_count":1347,"language_detected":"en","key_concepts":{"key_phrases":["SimCast","Enhancing Precipitation Nowcasting","arXiv251007953v1 Announce Type","new Abstract","Precipitation","predicts","future radar sequences","current observations","which","a highly challenging task"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SimCast":2.0,"Enhancing Precipitation Nowcasting":2.0,"arXiv251007953v1 Announce Type":1.0,"new Abstract":1.0,"Precipitation":1.0,"predicts":1.0,"future radar sequences":1.0,"current observations":1.0,"which":1.0,"a highly challenging task":1.0}},"age_hours":2.7724132558333334,"is_recent":true,"quality_score":1.0,"sentiment_score":7.288,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4576,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.897,"joy":0.0263,"surprise":0.0311,"sadness":0.0074,"fear":0.0233,"anger":0.0111,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel nowcasting model (SimCast) that improves precipitation prediction accuracy, which can benefit agriculture, disaster management, and energy optimization. The model's effectiveness is validated on three benchmark datasets, achieving improved CSI scores (0.452 on SEVIR, 0.474 on HKO-7, and 0.361 on MeteoNet). However, it remains in the applied research stage with no evidence of real-world deployment.","key_impact_metrics":["CSI score on SEVIR: 0.452","CSI score on HKO-7: 0.474","CSI score on MeteoNet: 0.361"],"technology_tags":["precipitation nowcasting","machine learning","knowledge distillation"],"sdg_alignment":[2,9,11,13],"analyzed_at":"2025-10-28T20:35:57.006951Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1355cfaa5f12","title":"Robust Geometric Predicates for Bivariate Computational Topology","content":"arXiv:2510.07955v1 Announce Type: new Abstract: We present theory and practice for robust implementations of bivariate Jacobi set and Reeb space algorithms. Robustness is a fundamental topic in computational geometry that deals with the issues of numerical errors and degenerate cases in algorithm implementations. Computational topology already uses some robustness techniques for the development of scalar field algorithms, such as those for computing critical points, merge trees, contour trees, Reeb graphs, Morse-Smale complexes, and persistent homology. In most cases, robustness can be ensured with floating-point arithmetic, and degenerate cases can be resolved with a standard symbolic perturbation technique called Simulation of Simplicity. However, this becomes much more complex for topological data structures of multifields, such as Jacobi sets and Reeb spaces. The geometric predicates used in their computation require exact arithmetic and a more involved treatment of degenerate cases to ensure correctness. Neither of these challenges has been fully addressed in the literature so far. In this paper, we describe how exact arithmetic and symbolic perturbation schemes can be used to enable robust implementations of bivariate Jacobi set and Reeb space algorithms. In the process, we develop a method for automatically evaluating predicates that can be expressed as large symbolic polynomials, which are difficult to factor appropriately by hand, as is typically done in the computational geometry literature. We provide implementations of all proposed approaches and evaluate their efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07955","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.216782","language":"en","tags":["cscg","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Petar Hristov, Ingrid Hotz, Talha Bin Masood","raw_content_length":1612,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Computational","Simulation of Simplicity","Morse-Smale","Reeb"],"persons":["Jacobi"],"locations":[],"monetary":[]},"char_count":1611,"language_detected":"en","key_concepts":{"key_phrases":["Robust Geometric Predicates","Bivariate Computational Topology","arXiv251007955v1 Announce Type","new Abstract","theory","practice","robust implementations","Jacobi","Reeb space","Robustness"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Geometric Predicates":2.0,"Bivariate Computational Topology":2.0,"arXiv251007955v1 Announce Type":1.0,"new Abstract":1.0,"theory":1.0,"practice":1.0,"robust implementations":1.0,"Jacobi":1.0,"Reeb space":1.0,"Robustness":1.0}},"age_hours":2.7724279722222223,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9214,"joy":0.0141,"surprise":0.0252,"sadness":0.0041,"fear":0.0067,"anger":0.0165,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on improving the robustness of computational topology algorithms, specifically for bivariate Jacobi sets and Reeb spaces. While the research provides implementations and evaluates their efficiency, it is still in the applied research phase with no clear path to economic viability or immediate climate impact. The technical credibility is high due to the use of exact arithmetic and symbolic perturbation schemes.","key_impact_metrics":["Efficiency of predicate evaluation","Computational cost reduction"],"technology_tags":["Computational topology","Algorithm optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:36:02.500664Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7de6a254f90c","title":"Zero","content":"arXiv:2510.07957v1 Announce Type: new Abstract: Forecasting state evolution of network systems, such as the spread of information on social networks, is significant for effective policy interventions and resource management. However, the underlying propagation dynamics constantly shift with new topics or events, which are modeled as changing coefficients of the underlying dynamics. Deep learning models struggle to adapt to these out-of-distribution shifts without extensive new data and retraining. To address this, we present Zero-Shot Forecasting of Network Dynamics through Weight Flow Matching (FNFM), a generative, coefficient-conditioned framework that generates dynamic model weights for an unseen target coefficient, enabling zero-shot forecasting. Our framework utilizes a Variational Encoder to summarize the forecaster weights trained in observed environments into compact latent tokens. A Conditional Flow Matching (CFM) module then learns a continuous transport from a simple Gaussian distribution to the empirical distribution of these weights, conditioned on the dynamical coefficients. This process is instantaneous at test time and requires no gradient-based optimization. Across varied dynamical coefficients, empirical results indicate that FNFM yields more reliable zero-shot accuracy than baseline methods, particularly under pronounced coefficient shift.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07957","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.217169","language":"en","tags":["research","csce","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Shihe Zhou, Ruikun Li, Huandong Wang, Yong Li","raw_content_length":1381,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["CFM"],"persons":[],"locations":[],"monetary":[]},"char_count":1380,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251007957v1 Announce Type","new Abstract","Forecasting state evolution","network systems","the spread","information","social networks","effective policy interventions","resource management","the underlying propagation dynamics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251007957v1 Announce Type":1.0,"new Abstract":1.0,"Forecasting state evolution":1.0,"network systems":1.0,"the spread":1.0,"information":1.0,"social networks":1.0,"effective policy interventions":1.0,"resource management":1.0,"the underlying propagation dynamics":1.0}},"age_hours":2.7724419866666667,"is_recent":true,"quality_score":0.7,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6771,"joy":0.0076,"surprise":0.0159,"sadness":0.0139,"fear":0.2255,"anger":0.0371,"disgust":0.023},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for forecasting network dynamics, potentially improving resource management. While the method shows promise in zero-shot accuracy compared to baselines, it is currently in the research phase with no deployed units or real-world data. The potential climate impact is theoretical, as the application to sustainability is not explicitly defined or quantified.","key_impact_metrics":[],"technology_tags":["deep learning","network dynamics","forecasting"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-28T20:36:05.013461Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2ebf3ecfb975","title":"A$^2$Search: Ambiguity","content":"arXiv:2510.07958v1 Announce Type: new Abstract: Recent advances in Large Language Models (LLMs) and Reinforcement Learning (RL) have led to strong performance in open-domain question answering (QA). However, existing models still struggle with questions that admit multiple valid answers. Standard QA benchmarks, which typically assume a single gold answer, overlook this reality and thus produce inappropriate training signals. Existing attempts to handle ambiguity often rely on costly manual annotation, which is difficult to scale to multi-hop datasets such as HotpotQA and MuSiQue. In this paper, we present A$^2$Search, an annotation-free, end-to-end training framework to recognize and handle ambiguity. At its core is an automated pipeline that detects ambiguous questions and gathers alternative answers via trajectory sampling and evidence verification. The model is then optimized with RL using a carefully designed $\\mathrm{AnsF1}$ reward, which naturally accommodates multiple answers. Experiments on eight open-domain QA benchmarks demonstrate that A$^2$Search achieves new state-of-the-art performance. With only a single rollout, A$^2$Search-7B yields an average $\\mathrm{AnsF1}@1$ score of $48.4\\%$ across four multi-hop benchmarks, outperforming all strong baselines, including the substantially larger ReSearch-32B ($46.2\\%$). Extensive analyses further show that A$^2$Search resolves ambiguity and generalizes across benchmarks, highlighting that embracing ambiguity is essential for building more reliable QA systems. Our code, data, and model weights can be found at https://github.com/zfj1998/A2Search","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07958","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.217596","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Fengji Zhang, Xinyao Niu, Chengyang Ying, Guancheng Lin, Zhongkai Hao, Zhou Fan, Chengen Huang, Jacky Keung, Bei Chen, Junyang Lin","raw_content_length":1625,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning","Large Language Models"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1624,"language_detected":"en","key_concepts":{"key_phrases":["A2Search","Ambiguity","arXiv251007958v1 Announce Type","new Abstract","Recent advances","Large Language Models","LLMs","Reinforcement Learning","strong performance","existing models"],"filter_categories":{"ai_ml":["Large Language Models","Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A2Search":2.0,"Ambiguity":2.0,"arXiv251007958v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"Large Language Models":1.0,"LLMs":1.0,"Reinforcement Learning":1.0,"strong performance":1.0,"existing models":1.0}},"age_hours":2.772457031666667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7793,"joy":0.0021,"surprise":0.0118,"sadness":0.024,"fear":0.0435,"anger":0.0645,"disgust":0.0748},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework to improve the accuracy of question-answering systems by handling ambiguity. While improved AI could indirectly contribute to sustainability by optimizing resource use, there is no direct or measurable climate impact at this stage. The framework is in the applied research phase, with experiments on benchmarks but no real-world deployment.","key_impact_metrics":["AnsF1@1 score of 48.4%"],"technology_tags":["Large Language Models","Reinforcement Learning","Question Answering"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:36:07.647686Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6afdee13b5a4","title":"DISCO: Diversifying Sample Condensation for Efficient Model Evaluation","content":"arXiv:2510.07959v1 Announce Type: new Abstract: Evaluating modern machine learning models has become prohibitively expensive. Benchmarks such as LMMs-Eval and HELM demand thousands of GPU hours per model. Costly evaluation reduces inclusivity, slows the cycle of innovation, and worsens environmental impact. The typical approach follows two steps. First, select an anchor subset of data. Second, train a mapping from the accuracy on this subset to the final test result. The drawback is that anchor selection depends on clustering, which can be complex and sensitive to design choices. We argue that promoting diversity among samples is not essential; what matters is to select samples that $\\textit{maximise diversity in model responses}$. Our method, $\\textbf{Diversifying Sample Condensation (DISCO)}$, selects the top-k samples with the greatest model disagreements. This uses greedy, sample-wise statistics rather than global clustering. The approach is conceptually simpler. From a theoretical view, inter-model disagreement provides an information-theoretically optimal rule for such greedy selection. $\\textbf{DISCO}$ shows empirical gains over prior methods, achieving state-of-the-art results in performance prediction across MMLU, Hellaswag, Winogrande, and ARC. Code is available here: https://github.com/arubique/disco-public.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07959","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.217992","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Alexander Rubinstein, Benjamin Raible, Martin Gubri, Seong Joon Oh","raw_content_length":1341,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["HELM","Diversifying Sample Condensation for"],"persons":["\\textit{maximise"],"locations":[],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["DISCO","Sample Condensation","Efficient Model Evaluation","arXiv251007959v1 Announce Type","new Abstract","modern machine learning models","Benchmarks","LMMs","Eval","thousands"],"filter_categories":{"research_academic":["DISCO"],"ai_ml":["modern machine learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DISCO":2.0,"Sample Condensation":2.0,"Efficient Model Evaluation":2.0,"arXiv251007959v1 Announce Type":1.0,"new Abstract":1.0,"modern machine learning models":1.0,"Benchmarks":1.0,"LMMs":1.0,"Eval":1.0,"thousands":1.0}},"age_hours":2.772472135,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8663,"joy":0.0059,"surprise":0.0166,"sadness":0.0195,"fear":0.008,"anger":0.0455,"disgust":0.0382},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a method (DISCO) to reduce the computational cost of evaluating machine learning models, which indirectly reduces energy consumption and associated GHG emissions. The method shows empirical gains over prior methods on several benchmarks. However, it is still in the applied research stage, with no mention of deployment or scaling.","key_impact_metrics":["GPU hours reduced","State-of-the-art results in performance prediction"],"technology_tags":["Machine Learning","Model Evaluation","Sample Condensation"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-28T20:36:10.747738Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_20a940748060","title":"A Systematic Evaluation of Self","content":"arXiv:2510.07960v1 Announce Type: new Abstract: Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07960","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.218428","language":"en","tags":["computer-science","cslg","csai","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":248,"author":"Emilio Estevan, Mar\\'ia Sierra-Torralba, Eduardo L\\'opez-Larraz, Luis Montesano","raw_content_length":1801,"priority":7,"update_frequency":1,"reading_time_minutes":1.24,"robust_parsing_used":true,"entities":{"organizations":["BOAS","HOGAR","EEG","SSL"],"persons":[],"locations":[],"monetary":[]},"char_count":1800,"language_detected":"en","key_concepts":{"key_phrases":["A Systematic Evaluation","Self","Announce Type","new Abstract","Wearable EEG devices","a promising alternative","polysomnography","PSG","affordable and scalable solutions","their widespread adoption"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Systematic Evaluation":2.0,"Self":2.0,"Announce Type":1.0,"new Abstract":1.0,"Wearable EEG devices":1.0,"a promising alternative":1.0,"polysomnography":1.0,"PSG":1.0,"affordable and scalable solutions":1.0,"their widespread adoption":1.0}},"age_hours":2.7724870202777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.36,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.872,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8811,"joy":0.049,"surprise":0.04,"sadness":0.0034,"fear":0.0095,"anger":0.01,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on self-supervised learning for sleep staging using wearable EEG, demonstrating a 10% improvement in classification performance over supervised baselines and achieving clinical-grade accuracy with less labeled data. While promising, it is still in the applied research stage, with no deployed units or customer contracts mentioned. The sustainability impact is indirect, potentially reducing the need for resource-intensive clinical sleep studies.","key_impact_metrics":["10% improvement in classification performance","80% clinical-grade accuracy with 5-10% labeled data"],"technology_tags":["self-supervised learning","wearable EEG","sleep staging"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:36:13.809861Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_839f14c9e2a2","title":"Latent Harmony: Synergistic Unified UHD Image Restoration via Latent Space Regularization and Controllable Refinement","content":"arXiv:2510.07961v1 Announce Type: new Abstract: Ultra-High Definition (UHD) image restoration faces a trade-off between computational efficiency and high-frequency detail retention. While Variational Autoencoders (VAEs) improve efficiency via latent-space processing, their Gaussian constraint often discards degradation-specific high-frequency information, hurting reconstruction fidelity. To overcome this, we propose Latent Harmony, a two-stage framework that redefines VAEs for UHD restoration by jointly regularizing the latent space and enforcing high-frequency-aware reconstruction.In Stage One, we introduce LH-VAE, which enhances semantic robustness through visual semantic constraints and progressive degradation perturbations, while latent equivariance strengthens high-frequency reconstruction.Stage Two jointly trains this refined VAE with a restoration model using High-Frequency Low-Rank Adaptation (HF-LoRA): an encoder LoRA guided by a fidelity-oriented high-frequency alignment loss to recover authentic details, and a decoder LoRA driven by a perception-oriented loss to synthesize realistic textures. Both LoRA modules are trained via alternating optimization with selective gradient propagation to preserve the pretrained latent structure.At inference, a tunable parameter {\\alpha} enables flexible fidelity-perception trade-offs.Experiments show Latent Harmony achieves state-of-the-art performance across UHD and standard-resolution tasks, effectively balancing efficiency, perceptual quality, and reconstruction accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07961","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.218837","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Yidi Liu, Xueyang Fu, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Zheng-Jun Zha","raw_content_length":1546,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["UHD","LH-VAE","VAE"],"persons":["Variational Autoencoders","Gaussian","Latent Harmony"],"locations":[],"monetary":[]},"char_count":1545,"language_detected":"en","key_concepts":{"key_phrases":["Latent Harmony","Synergistic Unified UHD Image Restoration","Latent Space Regularization","Controllable Refinement","VAEs","arXiv251007961v1 Announce Type","new Abstract","Ultra-High Definition UHD image restoration","a trade-off","computational efficiency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Latent Harmony":3.0,"Synergistic Unified UHD Image Restoration":2.0,"Latent Space Regularization":2.0,"Controllable Refinement":2.0,"VAEs":2.0,"arXiv251007961v1 Announce Type":1.0,"new Abstract":1.0,"Ultra-High Definition UHD image restoration":1.0,"a trade-off":1.0,"computational efficiency":1.0}},"age_hours":2.7725026680555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8989,"joy":0.0058,"surprise":0.0116,"sadness":0.0198,"fear":0.0071,"anger":0.0248,"disgust":0.032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for UHD image restoration using VAEs. While it improves efficiency and perceptual quality, its climate impact is indirect and theoretical, potentially reducing energy consumption in image processing. The technology is at the applied research stage, with no deployed units or customer contracts mentioned, making it vaporware at this point.","key_impact_metrics":["Improved perceptual quality","State-of-the-art performance across UHD and standard-resolution tasks"],"technology_tags":["Variational Autoencoders","Image Restoration","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:36:16.306379Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_14ca8dc13d63","title":"LightReasoner: Can Small Language Models Teach Large Language Models Reasoning?","content":"arXiv:2510.07962v1 Announce Type: new Abstract: Large language models (LLMs) have demonstrated remarkable progress in reasoning, often through supervised fine-tuning (SFT). However, SFT is resource-intensive, relying on large curated datasets, rejection-sampled demonstrations, and uniform optimization across all tokens, even though only a fraction carry meaningful learning value. In this work, we explore a counterintuitive idea: can smaller language models (SLMs) teach larger language models (LLMs) by revealing high-value reasoning moments that reflect the latter's unique strength? We propose LightReasoner, a novel framework that leverages the behavioral divergence between a stronger expert model (LLM) and a weaker amateur model (SLM). LightReasoner operates in two stages: (1) a sampling stage that pinpoints critical reasoning moments and constructs supervision examples capturing the expert's advantage through expert-amateur contrast, and (2) a fine-tuning stage that aligns the expert model with these distilled examples, amplifying its reasoning strengths. Across seven mathematical benchmarks, LightReasoner improves accuracy by up to 28.1%, while reducing time consumption by 90%, sampled problems by 80%, and tuned token usage by 99%, all without relying on ground-truth labels. By turning weaker SLMs into effective teaching signals, LightReasoner offers a scalable and resource-efficient approach for advancing LLM reasoning. Code is available at: https://github.com/HKUDS/LightReasoner","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07962","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.219240","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Jingyuan Wang, Yankai Chen, Zhonghang Li, Chao Huang","raw_content_length":1508,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":["LLM","SFT"],"persons":["LightReasoner"],"locations":[],"monetary":[]},"char_count":1507,"language_detected":"en","key_concepts":{"key_phrases":["Small Language Models","Large Language Models Reasoning","arXiv251007962v1 Announce Type","new Abstract","Large language models","LLMs","remarkable progress","reasoning","supervised fine-tuning SFT","SFT"],"filter_categories":{"ai_ml":["Large Language Models Reasoning","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Small Language Models":2.0,"Large Language Models Reasoning":2.0,"arXiv251007962v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"remarkable progress":1.0,"reasoning":1.0,"supervised fine-tuning SFT":1.0,"SFT":1.0}},"age_hours":2.772518546666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.568,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9136,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5153,"joy":0.0125,"surprise":0.3823,"sadness":0.0041,"fear":0.0344,"anger":0.0356,"disgust":0.0158},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores a method to improve the efficiency of large language models (LLMs), potentially reducing the computational resources required for training and operation. The concrete action is the development and testing of the LightReasoner framework, which aims to reduce time consumption by 90% and tuned token usage by 99%. The evidence supporting these claims comes from experiments on seven mathematical benchmarks, although it is still in the applied research stage with code available but no real-world deployments.","key_impact_metrics":["time consumption reduction by 90%","tuned token usage reduction by 99%"],"technology_tags":["large language models","artificial intelligence","machine learning","model optimization"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-28T20:36:19.408045Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_70d327efc7bd","title":"PRESCRIBE: Predicting Single","content":"arXiv:2510.07964v1 Announce Type: new Abstract: In single-cell perturbation prediction, a central task is to forecast the effects of perturbing a gene unseen in the training data. The efficacy of such predictions depends on two factors: (1) the similarity of the target gene to those covered in the training data, which informs model (epistemic) uncertainty, and (2) the quality of the corresponding training data, which reflects data (aleatoric) uncertainty. Both factors are critical for determining the reliability of a prediction, particularly as gene perturbation is an inherently stochastic biochemical process. In this paper, we propose PRESCRIBE (PREdicting Single-Cell Response wIth Bayesian Estimation), a multivariate deep evidential regression framework designed to measure both sources of uncertainty jointly. Our analysis demonstrates that PRESCRIBE effectively estimates a confidence score for each prediction, which strongly correlates with its empirical accuracy. This capability enables the filtering of untrustworthy results, and in our experiments, it achieves steady accuracy improvements of over 3% compared to comparable baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07964","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.220039","language":"en","tags":["computer-science","cslg","q-bioqm","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Jiabei Cheng, Changxi Chi, Jingbo Zhou, Hongyi Xin, Jun Xia","raw_content_length":1155,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["PREdicting Single-Cell Response wIth Bayesian Estimation"],"persons":[],"locations":[],"monetary":[]},"char_count":1154,"language_detected":"en","key_concepts":{"key_phrases":["the training data","which","Announce Type","new Abstract","single-cell perturbation prediction","a central task","the effects","a gene","The efficacy","such predictions"],"filter_categories":{"ai_ml":["the training data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the training data":2.0,"which":2.0,"Announce Type":1.0,"new Abstract":1.0,"single-cell perturbation prediction":1.0,"a central task":1.0,"the effects":1.0,"a gene":1.0,"The efficacy":1.0,"such predictions":1.0}},"age_hours":2.7725479822222225,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9,"joy":0.0222,"surprise":0.0221,"sadness":0.005,"fear":0.0311,"anger":0.0138,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel deep learning framework (PRESCRIBE) for predicting single-cell responses to gene perturbations. The concrete action is the development of an algorithm that improves prediction accuracy by over 3% compared to baselines. The evidence supporting the claims comes from experimental results, but it's still in the research phase with no real-world deployment.","key_impact_metrics":["Accuracy improvements of over 3%"],"technology_tags":["Deep learning","Single-cell perturbation prediction","Bayesian estimation"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-28T20:36:22.581373Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_61c50fccd76c","title":"Pre/Absence: Prompting Cultural Awareness and Understanding for Lost Architectural Heritage in Virtual Reality","content":"arXiv:2510.07967v1 Announce Type: new Abstract: Lost architectural heritage presents interpretive challenges due to vanished structures and fragmented historical records. Using Hanyuan Hall of the Tang dynasty's Daming Palace as a case study, we conducted a formative investigation with archaeologists, heritage administrators, and visitors to identify key issues in current interpretation practices. We found that these practices often compress complex cultural layers into factual summaries and rely on linear narratives that overlook the continuing reinterpretations following a site's disappearance. In response, we designed Pre/Absence, a virtual reality experience grounded in the presence-absence dialectic to interweave tangible and vanished aspects of heritage within a spatiotemporal narrative. A mixed-method study with 28 participants compared Pre/Absence to a paper-based experience. Both improved users' factual understanding, but the VR experience more strongly enhanced cultural awareness, evoked emotional engagement with loss, and encouraged critical reflection on the evolving social and political meanings of heritage. The findings suggest that VR can move beyond static reconstruction to engage users as co-constructors of cultural meaning, providing a nuanced framework for critical heritage narrative design in human-computer interaction.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07967","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.220451","language":"en","tags":["cshc","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Yaning Li, Ke Zhao, Shucheng Zheng, Xingyu Chen, Chenyi Chen, Wenxi Dai, Weile Jiang, Qi Dong, Yiqing Zhao, Meng Li, Lin-Ping Yuan","raw_content_length":1362,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Pre/Absence:","Pre/Absence","Daming Palace","linear","Lost Architectural Heritage"],"persons":[],"locations":[],"monetary":[]},"char_count":1361,"language_detected":"en","key_concepts":{"key_phrases":["PreAbsence","Cultural Awareness","Understanding","Lost Architectural Heritage","Virtual Reality","arXiv251007967v1 Announce Type","new Abstract","Lost architectural heritage","interpretive challenges","structures"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PreAbsence":2.0,"Cultural Awareness":2.0,"Understanding":2.0,"Lost Architectural Heritage":2.0,"Virtual Reality":2.0,"arXiv251007967v1 Announce Type":1.0,"new Abstract":1.0,"Lost architectural heritage":1.0,"interpretive challenges":1.0,"structures":1.0}},"age_hours":2.7725633558333334,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8842,"joy":0.0163,"surprise":0.046,"sadness":0.0084,"fear":0.027,"anger":0.0146,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the use of VR to enhance cultural awareness and understanding of lost architectural heritage. While it demonstrates improved user understanding and emotional engagement compared to paper-based methods, it doesn't directly address climate change or environmental sustainability. The study is based on a mixed-method approach with 28 participants and peer-reviewed research, increasing its credibility, but it is still in the pilot stage.","key_impact_metrics":["Improved factual understanding","Enhanced cultural awareness"],"technology_tags":["Virtual Reality","Cultural Heritage","Human-Computer Interaction"],"sdg_alignment":[4,11],"analyzed_at":"2025-10-28T20:36:25.286519Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d4d3719870ed","title":"From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses","content":"arXiv:2510.07968v1 Announce Type: new Abstract: Large Language Models (LLMs) have shown remarkable performance across various applications, but their deployment in sensitive domains raises significant concerns. To mitigate these risks, numerous defense strategies have been proposed. However, most existing studies assess these defenses in isolation, overlooking their broader impacts across other risk dimensions. In this work, we take the first step in investigating unintended interactions caused by defenses in LLMs, focusing on the complex interplay between safety, fairness, and privacy. Specifically, we propose CrossRiskEval, a comprehensive evaluation framework to assess whether deploying a defense targeting one risk inadvertently affects others. Through extensive empirical studies on 14 defense-deployed LLMs, covering 12 distinct defense strategies, we reveal several alarming side effects: 1) safety defenses may suppress direct responses to sensitive queries related to bias or privacy, yet still amplify indirect privacy leakage or biased outputs; 2) fairness defenses increase the risk of misuse and privacy leakage; 3) privacy defenses often impair safety and exacerbate bias. We further conduct a fine-grained neuron-level analysis to uncover the underlying mechanisms of these phenomena. Our analysis reveals the existence of conflict-entangled neurons in LLMs that exhibit opposing sensitivities across multiple risk dimensions. Further trend consistency analysis at both task and neuron levels confirms that these neurons play a key role in mediating the emergence of unintended behaviors following defense deployment. We call for a paradigm shift in LLM risk evaluation, toward holistic, interaction-aware assessment of defense strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07968","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.220861","language":"en","tags":["research","cscr","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Xiangtao Meng, Tianshuo Cong, Li Wang, Wenyu Chen, Zheng Li, Shanqing Guo, Xiaoyun Wang","raw_content_length":1764,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["Defender to Devil"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1763,"language_detected":"en","key_concepts":{"key_phrases":["Defender","Devil","Unintended Risk Interactions","LLM Defenses","arXiv251007968v1 Announce Type","new Abstract","Large Language Models","LLMs","remarkable performance","various applications"],"filter_categories":{"ai_ml":["LLM Defenses","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Defender":2.0,"Devil":2.0,"Unintended Risk Interactions":2.0,"LLM Defenses":2.0,"arXiv251007968v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable performance":1.0,"various applications":1.0}},"age_hours":2.772578416944444,"is_recent":true,"quality_score":1.0,"sentiment_score":3.1420000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3716,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4624,"joy":0.0052,"surprise":0.0379,"sadness":0.0222,"fear":0.4311,"anger":0.0288,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (CrossRiskEval) and empirical studies on LLM defenses, revealing unintended side effects across safety, fairness, and privacy. It identifies conflict-entangled neurons and their role in mediating unintended behaviors. While the research is technically credible and innovative, it's in an early stage with no deployed technology or measurable climate impact.","key_impact_metrics":["14 defense-deployed LLMs","12 distinct defense strategies"],"technology_tags":["Large Language Models","AI Safety","AI Fairness","AI Privacy"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-28T20:36:28.483785Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2ef1f544d7a1","title":"Climate Surrogates for Scalable Multi","content":"arXiv:2510.07971v1 Announce Type: new Abstract: Climate policy studies require models that capture the combined effects of multiple greenhouse gases on global temperature, but these models are computationally expensive and difficult to embed in reinforcement learning. We present a multi-agent reinforcement learning (MARL) framework that integrates a high-fidelity, highly efficient climate surrogate directly in the environment loop, enabling regional agents to learn climate policies under multi-gas dynamics. As a proof of concept, we introduce a recurrent neural network architecture pretrained on ($20{,}000$) multi-gas emission pathways to surrogate the climate model CICERO-SCM. The surrogate model attains near-simulator accuracy with global-mean temperature RMSE $\\approx 0.0004 \\mathrm{K}$ and approximately $1000\\times$ faster one-step inference. When substituted for the original simulator in a climate-policy MARL setting, it accelerates end-to-end training by $>\\!100\\times$. We show that the surrogate and simulator converge to the same optimal policies and propose a methodology to assess this property in cases where using the simulator is intractable. Our work allows to bypass the core computational bottleneck without sacrificing policy fidelity, enabling large-scale multi-agent experiments across alternative climate-policy regimes with multi-gas dynamics and high-fidelity climate response.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07971","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.221257","language":"en","tags":["csma","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Oskar Bohn Lassen, Serio Angelo Maria Agriesti, Filipe Rodrigues, Francisco Camara Pereira","raw_content_length":1415,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["CICERO-SCM"],"persons":[],"locations":[],"monetary":["$20{,}000$","approximately $1000\\times$"]},"char_count":1414,"language_detected":"en","key_concepts":{"key_phrases":["Climate Surrogates","Scalable Multi","arXiv251007971v1 Announce Type","new Abstract","Climate policy studies","models","the combined effects","multiple greenhouse gases","global temperature","these models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Climate Surrogates":2.0,"Scalable Multi":2.0,"arXiv251007971v1 Announce Type":1.0,"new Abstract":1.0,"Climate policy studies":1.0,"models":1.0,"the combined effects":1.0,"multiple greenhouse gases":1.0,"global temperature":1.0,"these models":1.0}},"age_hours":2.7725943580555557,"is_recent":true,"quality_score":1.0,"sentiment_score":6.119,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2238,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8182,"joy":0.0088,"surprise":0.0387,"sadness":0.0479,"fear":0.0145,"anger":0.0413,"disgust":0.0306},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":8,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":true,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a climate surrogate model that accelerates climate policy research by 100x. The model achieves near-simulator accuracy with a global-mean temperature RMSE of approximately 0.0004 K. While promising, this is still in the applied research stage with no mention of deployment or economic viability.","key_impact_metrics":["100x faster training","0.0004 K RMSE"],"technology_tags":["climate modeling","reinforcement learning","neural networks"],"sdg_alignment":[13],"analyzed_at":"2025-10-28T20:36:31.042916Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f5fde8fc34d3","title":"TaoSR","content":"arXiv:2510.08048v1 Announce Type: new Abstract: Query-product relevance prediction is fundamental to e-commerce search and has become even more critical in the era of AI-powered shopping, where semantic understanding and complex reasoning directly shape the user experience and business conversion. Large Language Models (LLMs) enable generative, reasoning-based approaches, typically aligned via supervised fine-tuning (SFT) or preference optimization methods like Direct Preference Optimization (DPO). However, the increasing complexity of business rules and user queries exposes the inability of existing methods to endow models with robust reasoning capacity for long-tail and challenging cases. Efforts to address this via reinforcement learning strategies like Group Relative Policy Optimization (GRPO) often suffer from sparse terminal rewards, offering insufficient guidance for multi-step reasoning and slowing convergence. To address these challenges, we propose TaoSR-AGRL, an Adaptive Guided Reinforcement Learning framework for LLM-based relevance prediction in Taobao Search Relevance. TaoSR-AGRL introduces two key innovations: (1) Rule-aware Reward Shaping, which decomposes the final relevance judgment into dense, structured rewards aligned with domain-specific relevance criteria; and (2) Adaptive Guided Replay, which identifies low-accuracy rollouts during training and injects targeted ground-truth guidance to steer the policy away from stagnant, rule-violating reasoning patterns toward compliant trajectories. TaoSR-AGRL was evaluated on large-scale real-world datasets and through online side-by-side human evaluations on Taobao Search. It consistently outperforms DPO and standard GRPO baselines in offline experiments, improving relevance accuracy, rule adherence, and training stability. The model trained with TaoSR-AGRL has been successfully deployed in the main search scenario on Taobao, serving hundreds of millions of users.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08048","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.237581","language":"en","tags":["computer-science","preprints","csai","csir","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Jianhui Yang, Yiming Jin, Pengkun Jiao, Chenhe Dong, Zerui Huang, Shaowei Yao, Xiaojiang Zhou, Dan Ou, Haihong Tang","raw_content_length":1960,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["TaoSR","Group Relative Policy Optimization","GRPO","Direct Preference Optimization","DPO","SFT","Adapti"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1959,"language_detected":"en","key_concepts":{"key_phrases":["TaoSR","arXiv251008048v1 Announce Type","new Abstract","Query-product relevance prediction","e-commerce search","the era","AI-powered shopping","semantic understanding","complex reasoning","the user experience"],"filter_categories":{"ai_ml":["AI-powered shopping"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TaoSR":2.0,"arXiv251008048v1 Announce Type":1.0,"new Abstract":1.0,"Query-product relevance prediction":1.0,"e-commerce search":1.0,"the era":1.0,"AI-powered shopping":1.0,"semantic understanding":1.0,"complex reasoning":1.0,"the user experience":1.0}},"age_hours":2.773174993055555,"is_recent":true,"quality_score":0.7,"sentiment_score":8.129,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6258,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9199,"joy":0.0166,"surprise":0.0445,"sadness":0.0027,"fear":0.0065,"anger":0.0071,"disgust":0.0028},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"scaling","climate_impact_potential":3,"technical_credibility":7,"economic_viability":6,"deployment_readiness":8,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AI system (TaoSR-AGRL) on Taobao, serving hundreds of millions of users. It improves relevance accuracy and rule adherence compared to existing methods. While the impact on e-commerce efficiency is clear, the direct climate impact is limited, although increased efficiency could lead to reduced energy consumption for servers.","key_impact_metrics":["relevance accuracy improvement","rule adherence improvement"],"technology_tags":["AI","Large Language Models","Relevance Prediction","Reinforcement Learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:36:34.190817Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_124cb26db605","title":"Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning","content":"arXiv:2510.07974v1 Announce Type: new Abstract: While large language models (LLMs) excel in mathematical and code reasoning, we observe they struggle with social reasoning tasks, exhibiting cognitive confusion, logical inconsistencies, and conflation between objective world states and subjective belief states. Through deteiled analysis of DeepSeek-R1's reasoning trajectories, we find that LLMs frequently encounter reasoning impasses and tend to output contradictory terms like \"tricky\" and \"confused\" when processing scenarios with multiple participants and timelines, leading to erroneous reasoning or infinite loops. The core issue is their inability to disentangle objective reality from agents' subjective beliefs. To address this, we propose an adaptive world model-enhanced reasoning mechanism that constructs a dynamic textual world model to track entity states and temporal sequences. It dynamically monitors reasoning trajectories for confusion indicators and promptly intervenes by providing clear world state descriptions, helping models navigate through cognitive dilemmas. The mechanism mimics how humans use implicit world models to distinguish between external events and internal beliefs. Evaluations on three social benchmarks demonstrate significant improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational costs (up to 33.8% token reduction), offering a simple yet effective solution for deploying LLMs in social contexts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07974","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.222125","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Jialu Du, Guiyang Hou, Yihui Fu, Chen Wu, Wenqi Zhang, Yongliang Shen, Weiming Lu","raw_content_length":1466,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["DeepSeek-R1's","Better Social Reasoning arXiv:2510.07974v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1465,"language_detected":"en","key_concepts":{"key_phrases":["Active Confusion Expression","Large Language Models","World Models","Better Social Reasoning","LLMs","arXiv251007974v1 Announce Type","new Abstract","large language models","mathematical and code reasoning","social reasoning tasks"],"filter_categories":{"ai_ml":["Large Language Models","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Active Confusion Expression":2.0,"Large Language Models":2.0,"World Models":2.0,"Better Social Reasoning":2.0,"LLMs":2.0,"arXiv251007974v1 Announce Type":1.0,"new Abstract":1.0,"large language models":1.0,"mathematical and code reasoning":1.0,"social reasoning tasks":1.0}},"age_hours":2.772624851111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8409,"joy":0.0056,"surprise":0.0472,"sadness":0.0404,"fear":0.0153,"anger":0.0218,"disgust":0.0289},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the social reasoning capabilities of LLMs, which could indirectly contribute to sustainability by enabling more effective communication and collaboration on climate action. The concrete action is the development of an adaptive world model-enhanced reasoning mechanism. The evidence supporting the claims is the reported +10% improvement in accuracy on social benchmarks and up to 33.8% token reduction, but this is still in the research phase.","key_impact_metrics":["+10% accuracy in Hi-ToM","33.8% token reduction"],"technology_tags":["Large Language Models","World Models","Social Reasoning"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-28T20:36:36.902573Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1662bcb92621","title":"Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation","content":"arXiv:2510.07975v1 Announce Type: new Abstract: Enabling robots to perform precise and generalized manipulation in unstructured environments remains a fundamental challenge in embodied AI. While Vision-Language Models (VLMs) have demonstrated remarkable capabilities in semantic reasoning and task planning, a significant gap persists between their high-level understanding and the precise physical execution required for real-world manipulation. To bridge this \"semantic-to-physical\" gap, we introduce GRACE, a novel framework that grounds VLM-based reasoning through executable analytic concepts (EAC)-mathematically defined blueprints that encode object affordances, geometric constraints, and semantics of manipulation. Our approach integrates a structured policy scaffolding pipeline that turn natural language instructions and visual information into an instantiated EAC, from which we derive grasp poses, force directions and plan physically feasible motion trajectory for robot execution. GRACE thus provides a unified and interpretable interface between high-level instruction understanding and low-level robot control, effectively enabling precise and generalizable manipulation through semantic-physical grounding. Extensive experiments demonstrate that GRACE achieves strong zero-shot generalization across a variety of articulated objects in both simulated and real-world environments, without requiring task-specific training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07975","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.222545","language":"en","tags":["csro","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Mingyang Sun, Jiude Wei, Qichen He, Donglin Wang, Cewu Lu, Jianhua Sun","raw_content_length":1441,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["GRACE","EAC","Vision-Language Models","Executable Analytic Concepts","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1440,"language_detected":"en","key_concepts":{"key_phrases":["Executable Analytic Concepts","the Missing Link","VLM Insight","Precise Manipulation","arXiv251007975v1 Announce Type","new Abstract","Enabling robots","precise and generalized manipulation","unstructured environments","a fundamental challenge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Executable Analytic Concepts":2.0,"the Missing Link":2.0,"VLM Insight":2.0,"Precise Manipulation":2.0,"arXiv251007975v1 Announce Type":1.0,"new Abstract":1.0,"Enabling robots":1.0,"precise and generalized manipulation":1.0,"unstructured environments":1.0,"a fundamental challenge":1.0}},"age_hours":2.7726403138888887,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8552,"joy":0.0069,"surprise":0.0682,"sadness":0.0081,"fear":0.0278,"anger":0.0195,"disgust":0.0143},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (GRACE) for robotic manipulation using VLMs, demonstrating zero-shot generalization in simulated and real-world environments. While promising, it's still in the early stages of development, lacking deployment data and economic viability analysis. The potential climate impact is indirect, relying on future applications of improved robotic manipulation in sustainable industries.","key_impact_metrics":[],"technology_tags":["Robotics","Vision-Language Models","AI","Automation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:36:39.653418Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ad6222e4fd91","title":"VoiceAgentBench: Are Voice Assistants ready for agentic tasks?","content":"arXiv:2510.07978v1 Announce Type: new Abstract: Large-scale Speech Language Models (SpeechLMs) have enabled voice assistants capable of understanding natural spoken queries and performing complex tasks. However, existing speech benchmarks primarily focus on isolated capabilities such as transcription, or question-answering, and do not systematically evaluate agentic scenarios encompassing multilingual and cultural understanding, as well as adversarial robustness. To address this, we introduce VoiceAgentBench, a comprehensive benchmark designed to evaluate SpeechLMs in realistic spoken agentic settings. It comprises over 5,500 synthetic spoken queries, including dialogues grounded in Indian context, covering single-tool invocations, multi-tool workflows, multi-turn interactions, and safety evaluations. The benchmark supports English, Hindi, and 5 other Indian languages, reflecting real-world linguistic and cultural diversity. We simulate speaker variability using a novel sampling algorithm that selects audios for TTS voice conversion based on its speaker embeddings, maximizing acoustic and speaker diversity. Our evaluation measures tool selection accuracy, structural consistency, and the correctness of tool invocations, including adversarial robustness. Our experiments reveal significant gaps in contextual tool orchestration tasks, Indic generalization, and adversarial robustness, exposing critical limitations of current SpeechLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07978","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.223306","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Dhruv Jain, Harshit Shukla, Gautam Rajeev, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal","raw_content_length":1455,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Speech Language Models"],"persons":["SpeechLMs","Announce Type"],"locations":["Hindi"],"monetary":[]},"char_count":1454,"language_detected":"en","key_concepts":{"key_phrases":["Voice Assistants","agentic tasks","arXiv251007978v1 Announce Type","new Abstract","Large-scale Speech Language Models","SpeechLMs","voice assistants","natural spoken queries","complex tasks","existing speech"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Voice Assistants":2.0,"agentic tasks":2.0,"arXiv251007978v1 Announce Type":1.0,"new Abstract":1.0,"Large-scale Speech Language Models":1.0,"SpeechLMs":1.0,"voice assistants":1.0,"natural spoken queries":1.0,"complex tasks":1.0,"existing speech":1.0}},"age_hours":2.77266965,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8509,"joy":0.0051,"surprise":0.115,"sadness":0.0063,"fear":0.0091,"anger":0.0099,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on developing a benchmark (VoiceAgentBench) to evaluate SpeechLMs in agentic settings. While it addresses multilingual and cultural understanding, including Indian languages, and evaluates adversarial robustness, it is currently in the applied research stage with no deployed technology or measured outcomes related to climate impact. The benchmark includes 5,500 synthetic spoken queries, but the impact on sustainability is indirect and theoretical at this point.","key_impact_metrics":["5,500 synthetic spoken queries","7 languages supported"],"technology_tags":["Speech Language Models","Voice Assistants","TTS"],"sdg_alignment":[4,9,10],"analyzed_at":"2025-10-28T20:36:42.470840Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d7f2a2011c2e","title":"IntMeanFlow: Few","content":"arXiv:2510.07979v1 Announce Type: new Abstract: Flow-based generative models have greatly improved text-to-speech (TTS) synthesis quality, but inference speed remains limited by the iterative sampling process and multiple function evaluations (NFE). The recent MeanFlow model accelerates generation by modeling average velocity instead of instantaneous velocity. However, its direct application to TTS encounters challenges, including GPU memory overhead from Jacobian-vector products (JVP) and training instability due to self-bootstrap processes. To address these issues, we introduce IntMeanFlow, a framework for few-step speech generation with integral velocity distillation. By approximating average velocity with the teacher's instantaneous velocity over a temporal interval, IntMeanFlow eliminates the need for JVPs and self-bootstrap, improving stability and reducing GPU memory usage. We also propose the Optimal Step Sampling Search (O3S) algorithm, which identifies the model-specific optimal sampling steps, improving speech synthesis without additional inference overhead. Experiments show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis. Demo samples are available at https://vvwangvv.github.io/intmeanflow.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07979","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.223707","language":"en","tags":["cssd","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Wei Wang, Rong Cao, Yi Guo, Zhengyang Chen, Kuan Chen, Yuanyuan Huo","raw_content_length":1322,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["JVP","NFE","GPU","Jacobian-vector","TTS","the Optimal Step Sampling Search"],"persons":["GPU"],"locations":[],"monetary":[]},"char_count":1321,"language_detected":"en","key_concepts":{"key_phrases":["IntMeanFlow","arXiv251007979v1 Announce Type","new Abstract","Flow-based generative models","speech","TTS","inference speed","the iterative sampling process","multiple function evaluations","NFE"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IntMeanFlow":2.0,"arXiv251007979v1 Announce Type":1.0,"new Abstract":1.0,"Flow-based generative models":1.0,"speech":1.0,"TTS":1.0,"inference speed":1.0,"the iterative sampling process":1.0,"multiple function evaluations":1.0,"NFE":1.0}},"age_hours":2.7726846066666666,"is_recent":true,"quality_score":1.0,"sentiment_score":5.3815,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0763,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8967,"joy":0.0138,"surprise":0.0649,"sadness":0.014,"fear":0.0038,"anger":0.0043,"disgust":0.0025},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new framework (IntMeanFlow) for improving the efficiency of text-to-speech synthesis. It achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks. While this is a technical improvement, its direct climate impact is limited, and it is currently in the early stages of development (demo samples available).","key_impact_metrics":["1-NFE inference for token-to-spectrogram","3-NFE for text-to-spectrogram"],"technology_tags":["text-to-speech synthesis","flow-based generative models","integral velocity distillation"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:36:45.624601Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae03797cd2b3","title":"Unveiling the Power of Multiple Gossip Steps: A Stability","content":"arXiv:2510.07980v1 Announce Type: new Abstract: Decentralized training removes the centralized server, making it a communication-efficient approach that can significantly improve training efficiency, but it often suffers from degraded performance compared to centralized training. Multi-Gossip Steps (MGS) serve as a simple yet effective bridge between decentralized and centralized training, significantly reducing experiment performance gaps. However, the theoretical reasons for its effectiveness and whether this gap can be fully eliminated by MGS remain open questions. In this paper, we derive upper bounds on the generalization error and excess error of MGS using stability analysis, systematically answering these two key questions. 1). Optimization Error Reduction: MGS reduces the optimization error bound at an exponential rate, thereby exponentially tightening the generalization error bound and enabling convergence to better solutions. 2). Gap to Centralization: Even as MGS approaches infinity, a non-negligible gap in generalization error remains compared to centralized mini-batch SGD ($\\mathcal{O}(T^{\\frac{c\\beta}{c\\beta +1}}/{n m})$ in centralized and $\\mathcal{O}(T^{\\frac{2c\\beta}{2c\\beta +2}}/{n m^{\\frac{1}{2c\\beta +2}}})$ in decentralized). Furthermore, we provide the first unified analysis of how factors like learning rate, data heterogeneity, node count, per-node sample size, and communication topology impact the generalization of MGS under non-convex settings without the bounded gradients assumption, filling a critical theoretical gap in decentralized training. Finally, promising experiments on CIFAR datasets support our theoretical findings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07980","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.224110","language":"en","tags":["csna","computer-science","cslg","csai","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Qinglun Li, Yingqi Liu, Miao Zhang, Xiaochun Cao, Quanjun Yin, Li Shen","raw_content_length":1679,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["MGS","the Power of Multiple Gossip Steps"],"persons":[],"locations":[],"monetary":[]},"char_count":1678,"language_detected":"en","key_concepts":{"key_phrases":["the Power","Multiple Gossip Steps","arXiv251007980v1","Announce Type","new Abstract","Decentralized training","the centralized server","training efficiency","degraded performance","centralized training"],"filter_categories":{"ai_ml":["Decentralized training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Power":2.0,"Multiple Gossip Steps":2.0,"arXiv251007980v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Decentralized training":1.0,"the centralized server":1.0,"training efficiency":1.0,"degraded performance":1.0,"centralized training":1.0}},"age_hours":2.7726991719444443,"is_recent":true,"quality_score":1.0,"sentiment_score":3.3545000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3291,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8431,"joy":0.011,"surprise":0.0337,"sadness":0.0439,"fear":0.0078,"anger":0.0179,"disgust":0.0426},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical analysis and experimental results on decentralized training using Multi-Gossip Steps. While it demonstrates a reduction in optimization error and provides insights into factors impacting generalization, it remains in the basic research stage with no concrete deployment or measured outcomes in real-world climate applications. The experiments are limited to CIFAR datasets, and the economic viability and deployment readiness are low.","key_impact_metrics":["Optimization error reduction at an exponential rate","Generalization error gap compared to centralized mini-batch SGD"],"technology_tags":["Decentralized training","Multi-Gossip Steps","Machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:36:48.602042Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b5e33212ce35","title":"ZeroCard: Cardinality Estimation with Zero Dependence on Target Databases -","content":"arXiv:2510.07983v1 Announce Type: new Abstract: Cardinality estimation is a fundamental task in database systems and plays a critical role in query optimization. Despite significant advances in learning-based cardinality estimation methods, most existing approaches remain difficult to generalize to new datasets due to their strong dependence on raw data or queries, thus limiting their practicality in real scenarios. To overcome these challenges, we argue that semantics in the schema may benefit cardinality estimation, and leveraging such semantics may alleviate these dependencies. To this end, we introduce ZeroCard, the first semantics-driven cardinality estimation method that can be applied without any dependence on raw data access, query logs, or retraining on the target database. Specifically, we propose to predict data distributions using schema semantics, thereby avoiding raw data dependence. Then, we introduce a query template-agnostic representation method to alleviate query dependence. Finally, we construct a large-scale query dataset derived from real-world tables and pretrain ZeroCard on it, enabling it to learn cardinality from schema semantics and predicate representations. After pretraining, ZeroCard's parameters can be frozen and applied in an off-the-shelf manner. We conduct extensive experiments to demonstrate the distinct advantages of ZeroCard and show its practical applications in query optimization. Its zero-dependence property significantly facilitates deployment in real-world scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07983","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.224524","language":"en","tags":["csdb","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Xianghong Xu, Rong Kang, Xiao He, Lei Zhang, Jianjun Chen, Tieying Zhang","raw_content_length":1534,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1533,"language_detected":"en","key_concepts":{"key_phrases":["ZeroCard","Cardinality Estimation","Zero Dependence","Target Databases","arXiv251007983v1 Announce Type","new Abstract","Cardinality estimation","a fundamental task","database systems","a critical role"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ZeroCard":2.0,"Cardinality Estimation":2.0,"Zero Dependence":2.0,"Target Databases":2.0,"arXiv251007983v1 Announce Type":1.0,"new Abstract":1.0,"Cardinality estimation":1.0,"a fundamental task":1.0,"database systems":1.0,"a critical role":1.0}},"age_hours":2.7727141569444442,"is_recent":true,"quality_score":0.7,"sentiment_score":6.814,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3628,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9025,"joy":0.0096,"surprise":0.0468,"sadness":0.0089,"fear":0.0159,"anger":0.0098,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to cardinality estimation in databases, potentially improving query optimization. While the method is pre-trained on a large dataset, it's still in the research phase with no mention of real-world deployment or quantified impact on energy consumption or resource usage. The 'zero-dependence' property could facilitate deployment, but it remains theoretical at this stage.","key_impact_metrics":["Cardinality estimation accuracy","Query optimization time"],"technology_tags":["Database optimization","Machine learning","Cardinality estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:36:51.502328Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_358e55d9db0c","title":"Is Architectural Complexity Always the Answer? A Case Study on SwinIR vs. an Efficient CNN","content":"arXiv:2510.07984v1 Announce Type: new Abstract: The simultaneous restoration of high-frequency details and suppression of severe noise in low-light imagery presents a significant and persistent challenge in computer vision. While large-scale Transformer models like SwinIR have set the state of the art in performance, their high computational cost can be a barrier for practical applications. This paper investigates the critical trade-off between performance and efficiency by comparing the state-of-the-art SwinIR model against a standard, lightweight Convolutional Neural Network (CNN) on this challenging task. Our experimental results reveal a nuanced but important finding. While the Transformer-based SwinIR model achieves a higher peak performance, with a Peak Signal-to-Noise Ratio (PSNR) of 39.03 dB, the lightweight CNN delivers a surprisingly competitive PSNR of 37.4 dB. Crucially, the CNN reached this performance after converging in only 10 epochs of training, whereas the more complex SwinIR model required 132 epochs. This efficiency is further underscored by the model's size; the CNN is over 55 times smaller than SwinIR. This work demonstrates that a standard CNN can provide a near state-of-the-art result with significantly lower computational overhead, presenting a compelling case for its use in real-world scenarios where resource constraints are a primary concern.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07984","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.224918","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Chandresh Sutariya, Nitin Singh","raw_content_length":1392,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Answer","Transformer","CNN","PSNR","SwinIR","dB. Crucially","Convolutional Neural Network"],"persons":["Announce Type"],"locations":["Peak Signal"],"monetary":[]},"char_count":1391,"language_detected":"en","key_concepts":{"key_phrases":["SwinIR","Architectural Complexity","Always the Answer","A Case Study","an Efficient CNN","performance","arXiv251007984v1","Announce Type","new Abstract","The simultaneous restoration"],"filter_categories":{"research_academic":["A Case Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SwinIR":3.0,"Architectural Complexity":2.0,"Always the Answer":2.0,"A Case Study":2.0,"an Efficient CNN":2.0,"performance":2.0,"arXiv251007984v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"The simultaneous restoration":1.0}},"age_hours":2.7727297166666665,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4664,"joy":0.0111,"surprise":0.0313,"sadness":0.0177,"fear":0.3843,"anger":0.0513,"disgust":0.0378},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a comparison of two image restoration models, focusing on computational efficiency. The concrete action is the comparison of SwinIR and a CNN, with measured outcomes in terms of PSNR and training epochs. The evidence is based on experimental results, but it is still in the applied research stage, without deployment.","key_impact_metrics":["PSNR of 37.4 dB","55 times smaller model size"],"technology_tags":["Convolutional Neural Network","Transformer model","Image restoration"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:36:54.099361Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_44499cfcf660","title":"Fewer Weights, More Problems: A Practical Attack on LLM Pruning","content":"arXiv:2510.07985v1 Announce Type: new Abstract: Model pruning, i.e., removing a subset of model weights, has become a prominent approach to reducing the memory footprint of large language models (LLMs) during inference. Notably, popular inference engines, such as vLLM, enable users to conveniently prune downloaded models before they are deployed. While the utility and efficiency of pruning methods have improved significantly, the security implications of pruning remain underexplored. In this work, for the first time, we show that modern LLM pruning methods can be maliciously exploited. In particular, an adversary can construct a model that appears benign yet, once pruned, exhibits malicious behaviors. Our method is based on the idea that the adversary can compute a proxy metric that estimates how likely each parameter is to be pruned. With this information, the adversary can first inject a malicious behavior into those parameters that are unlikely to be pruned. Then, they can repair the model by using parameters that are likely to be pruned, effectively canceling out the injected behavior in the unpruned model. We demonstrate the severity of our attack through extensive evaluation on five models; after any of the pruning in vLLM are applied (Magnitude, Wanda, and SparseGPT), it consistently exhibits strong malicious behaviors in a diverse set of attack scenarios (success rates of up to $95.7\\%$ for jailbreak, $98.7\\%$ for benign instruction refusal, and $99.5\\%$ for targeted content injection). Our results reveal a critical deployment-time security gap and underscore the urgent need for stronger security awareness in model compression.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07985","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.225328","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Kazuki Egashira, Robin Staab, Thibaud Gloaguen, Mark Vero, Martin Vechev","raw_content_length":1664,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1663,"language_detected":"en","key_concepts":{"key_phrases":["Fewer Weights","More Problems","A Practical Attack","LLM Pruning","arXiv251007985v1 Announce Type","new Abstract","Model pruning","a subset","model weights","a prominent approach"],"filter_categories":{"ai_ml":["LLM Pruning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fewer Weights":2.0,"More Problems":2.0,"A Practical Attack":2.0,"LLM Pruning":2.0,"arXiv251007985v1 Announce Type":1.0,"new Abstract":1.0,"Model pruning":1.0,"a subset":1.0,"model weights":1.0,"a prominent approach":1.0}},"age_hours":2.772744688611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.594999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9273,"joy":0.0087,"surprise":0.0146,"sadness":0.0127,"fear":0.0129,"anger":0.016,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel attack on LLM pruning methods, demonstrating how malicious behavior can be injected into pruned models. While the research is technically sound and includes quantified metrics on attack success rates (up to 99.5%), it's currently in the applied research phase with no deployed technology or real-world impact on sustainability. The vaporware flag is set because it's a proof-of-concept with no deployed units.","key_impact_metrics":["jailbreak success rate 95.7%","benign instruction refusal 98.7%"],"technology_tags":["LLM pruning","model security","adversarial attacks"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:36:56.812839Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d96854d39091","title":"Orientation Learning and Adaptation towards Simultaneous Incorporation of Multiple Local Constraints","content":"arXiv:2510.07986v1 Announce Type: new Abstract: Orientation learning plays a pivotal role in many tasks. However, the rotation group SO(3) is a Riemannian manifold. As a result, the distortion caused by non-Euclidean geometric nature introduces difficulties to the incorporation of local constraints, especially for the simultaneous incorporation of multiple local constraints. To address this issue, we propose the Angle-Axis Space-based orientation representation method to solve several orientation learning problems, including orientation adaptation and minimization of angular acceleration. Specifically, we propose a weighted average mechanism in SO(3) based on the angle-axis representation method. Our main idea is to generate multiple trajectories by considering different local constraints at different basepoints. Then these multiple trajectories are fused to generate a smooth trajectory by our proposed weighted average mechanism, achieving the goal to incorporate multiple local constraints simultaneously. Compared with existing solution, ours can address the distortion issue and make the off-theshelf Euclidean learning algorithm be re-applicable in non-Euclidean space. Simulation and Experimental evaluations validate that our solution can not only adapt orientations towards arbitrary desired via-points and cope with angular acceleration constraints, but also incorporate multiple local constraints simultaneously to achieve extra benefits, e.g., achieving smaller acceleration costs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07986","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.225738","language":"en","tags":["research","csro","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Gaofeng Li, Peisen Xu, Ruize Wang, Qi Ye, Jiming Chen, Dezhen Song, Yanlong Huang","raw_content_length":1506,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Orientation Learning and Adaptation"],"persons":[],"locations":[],"monetary":[]},"char_count":1505,"language_detected":"en","key_concepts":{"key_phrases":["Orientation Learning","Adaptation","Simultaneous Incorporation","Multiple Local Constraints","arXiv251007986v1 Announce Type","new Abstract","Orientation learning","a pivotal role","many tasks","the rotation group"],"filter_categories":{"ai_ml":["Multiple Local Constraints"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Orientation Learning":2.0,"Adaptation":2.0,"Simultaneous Incorporation":2.0,"Multiple Local Constraints":2.0,"arXiv251007986v1 Announce Type":1.0,"new Abstract":1.0,"Orientation learning":1.0,"a pivotal role":1.0,"many tasks":1.0,"the rotation group":1.0}},"age_hours":2.7727590308333334,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7944,"joy":0.0077,"surprise":0.0339,"sadness":0.0395,"fear":0.0615,"anger":0.0302,"disgust":0.0329},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for orientation learning to improve robotic movement and adaptation. It is currently in the simulation and experimental evaluation phase, so deployment is not yet proven. The impact on climate is indirect, potentially reducing energy consumption in robotics applications, but this is not quantified.","key_impact_metrics":["smaller acceleration costs"],"technology_tags":["robotics","orientation learning","angle-axis representation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:36:59.170222Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5f1649cc193b","title":"Quantifying Locomotion Differences Between Virtual Reality Users With and Without Motor Impairments","content":"arXiv:2510.07987v1 Announce Type: new Abstract: Today's virtual reality (VR) systems and environments assume that users have typical abilities, which can make VR inaccessible to people with physical impairments. However, there is not yet an understanding of how inaccessible locomotion techniques are, and which interactions make them inaccessible. To this end, we conducted a study in which people with and without upper-body impairments navigated a virtual environment with six locomotion techniques to quantify performance differences among groups. We found that groups performed similarly with Sliding Looking on all performance measures, suggesting that this might be a good default locomotion technique for VR apps. To understand the nature of performance differences with the other techniques, we collected low-level interaction data from the controllers and headset and analyzed interaction differences with a set of movement-, button-, and target-related metrics. We found that movement-related metrics from headset data reveal differences among groups with all techniques, suggesting these are good metrics for identifying whether a user has an upper-body impairment. We also identify movement-, button, and target- related metrics that can explain performance differences between groups for particular locomotion techniques.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07987","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.226121","language":"en","tags":["cshc","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Rachel L. Franz, Jacob O. Wobbrock","raw_content_length":1336,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Without Motor Impairments arXiv:2510.07987v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1335,"language_detected":"en","key_concepts":{"key_phrases":["Quantifying Locomotion Differences","Virtual Reality Users","Motor Impairments","which","people","arXiv251007987v1 Announce Type","new Abstract","Todays virtual reality VR systems","environments","users"],"filter_categories":{"ai_ml":["Motor Impairments"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantifying Locomotion Differences":2.0,"Virtual Reality Users":2.0,"Motor Impairments":2.0,"which":2.0,"people":2.0,"arXiv251007987v1 Announce Type":1.0,"new Abstract":1.0,"Todays virtual reality VR systems":1.0,"environments":1.0,"users":1.0}},"age_hours":2.772773052777778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8946,"joy":0.004,"surprise":0.0474,"sadness":0.0197,"fear":0.0094,"anger":0.0076,"disgust":0.0172},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":6,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on quantifying locomotion differences in VR for users with and without motor impairments. While it doesn't directly address climate change, it contributes to accessibility and inclusivity, which can indirectly support sustainability by enabling broader participation in climate solutions. The study uses measurable performance metrics, but is still in early stages.","key_impact_metrics":["Performance measures with Sliding Looking","Movement-related metrics from headset data"],"technology_tags":["Virtual Reality","Accessibility Technology","Motion Tracking"],"sdg_alignment":[3,10],"analyzed_at":"2025-10-28T20:37:02.608323Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7183412e528a","title":"ReInAgent: A Context-Aware GUI Agent Enabling Human-in","content":"arXiv:2510.07988v1 Announce Type: new Abstract: Mobile GUI agents exhibit substantial potential to facilitate and automate the execution of user tasks on mobile phones. However, exist mobile GUI agents predominantly privilege autonomous operation and neglect the necessity of active user engagement during task execution. This omission undermines their adaptability to information dilemmas including ambiguous, dynamically evolving, and conflicting task scenarios, leading to execution outcomes that deviate from genuine user requirements and preferences. To address these shortcomings, we propose ReInAgent, a context-aware multi-agent framework that leverages dynamic information management to enable human-in-the-loop mobile task navigation. ReInAgent integrates three specialized agents around a shared memory module: an information-managing agent for slot-based information management and proactive interaction with the user, a decision-making agent for conflict-aware planning, and a reflecting agent for task reflection and information consistency validation. Through continuous contextual information analysis and sustained user-agent collaboration, ReInAgent overcomes the limitation of existing approaches that rely on clear and static task assumptions. Consequently, it enables more adaptive and reliable mobile task navigation in complex, real-world scenarios. Experimental results demonstrate that ReInAgent effectively resolves information dilemmas and produces outcomes that are more closely aligned with genuine user preferences. Notably, on complex tasks involving information dilemmas, ReInAgent achieves a 25% higher success rate than Mobile-Agent-v2.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07988","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.226538","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Haitao Jia, Ming He, Zimo Yin, Likang Wu, Jianping Fan, Jitao Sang","raw_content_length":1671,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Context-Aware","GUI","ReInAgent"],"persons":["Enabling Human-"],"locations":[],"monetary":[]},"char_count":1670,"language_detected":"en","key_concepts":{"key_phrases":["A Context-Aware GUI Agent Enabling Human","arXiv251007988v1 Announce Type","new Abstract","Mobile GUI agents","substantial potential","the execution","user tasks","mobile phones","mobile GUI agents","autonomous operation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Context-Aware GUI Agent Enabling Human":2.0,"arXiv251007988v1 Announce Type":1.0,"new Abstract":1.0,"Mobile GUI agents":1.0,"substantial potential":1.0,"the execution":1.0,"user tasks":1.0,"mobile phones":1.0,"mobile GUI agents":1.0,"autonomous operation":1.0}},"age_hours":2.7727868652777774,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8712,"joy":0.0096,"surprise":0.0168,"sadness":0.016,"fear":0.0154,"anger":0.0434,"disgust":0.0276},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI agent framework (ReInAgent) designed to improve the adaptability and reliability of mobile task navigation. The primary evidence is a reported 25% higher success rate compared to Mobile-Agent-v2 on complex tasks. However, this is still in the research phase with no indication of real-world deployment or concrete sustainability outcomes, hence the low scores.","key_impact_metrics":["25% higher success rate"],"technology_tags":["AI agent","context-aware computing","human-in-the-loop systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:06.129607Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aed6e0f607fb","title":"GraphEnet: Event","content":"arXiv:2510.07990v1 Announce Type: new Abstract: Human Pose Estimation is a crucial module in human-machine interaction applications and, especially since the rise in deep learning technology, robust methods are available to consumers using RGB cameras and commercial GPUs. On the other hand, event-based cameras have gained popularity in the vision research community for their low latency and low energy advantages that make them ideal for applications where those resources are constrained like portable electronics and mobile robots. In this work we propose a Graph Neural Network, GraphEnet, that leverages the sparse nature of event camera output, with an intermediate line based event representation, to estimate 2D Human Pose of a single person at a high frequency. The architecture incorporates a novel offset vector learning paradigm with confidence based pooling to estimate the human pose. This is the first work that applies Graph Neural Networks to event data for Human Pose Estimation. The code is open-source at https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07990","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.227293","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Gaurvi Goyal, Pham Cong Thuong, Arren Glover, Masayoshi Mizuno, Chiara Bartolozzi","raw_content_length":1093,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Graph Neural Networks","RGB","GraphEnet"],"persons":["Pose Estimation"],"locations":[],"monetary":[]},"char_count":1092,"language_detected":"en","key_concepts":{"key_phrases":["GraphEnet","Event","arXiv251007990v1 Announce Type","new Abstract","Human Pose Estimation","a crucial module","human-machine interaction applications","the rise","deep learning technology","robust methods"],"filter_categories":{"ai_ml":["deep learning technology"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GraphEnet":2.0,"Event":2.0,"arXiv251007990v1 Announce Type":1.0,"new Abstract":1.0,"Human Pose Estimation":1.0,"a crucial module":1.0,"human-machine interaction applications":1.0,"the rise":1.0,"deep learning technology":1.0,"robust methods":1.0}},"age_hours":2.7728150463888888,"is_recent":true,"quality_score":1.0,"sentiment_score":9.701500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9403,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8395,"joy":0.0669,"surprise":0.07,"sadness":0.0049,"fear":0.0052,"anger":0.0102,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel Graph Neural Network (GraphEnet) for human pose estimation using event data, aiming for low-latency and low-energy applications. The open-source code is a positive step, but it's still in the research phase with no reported deployments or measured energy savings in real-world scenarios. The potential climate impact is modest as it focuses on energy efficiency in specific applications like portable electronics and mobile robots, but it's not directly tied to large-scale emissions reduction.","key_impact_metrics":[],"technology_tags":["Graph Neural Network","Event Cameras","Human Pose Estimation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-28T20:37:09.345434Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_367c38669a40","title":"TDoA","content":"arXiv:2510.08001v1 Announce Type: new Abstract: Channel Charting (CC) has emerged as a promising framework for data-driven radio localization, yet existing approaches often struggle to scale globally and to handle the distortions introduced by non-line-of-sight (NLoS) conditions. In this work, we propose a novel CC method that leverages Channel Impulse Response (CIR) data enriched with practical features such as Time Difference of Arrival (TDoA) and Transmission Reception Point (TRP) locations, enabling a self-supervised localization function on a global scale. The proposed framework is further enhanced with short-interval User Equipment (UE) displacement measurements, which improve the continuity and robustness of the learned positioning function. Our algorithm incorporates a mechanism to identify and mask NLoS-induced noisy measurements, leading to significant performance gains. We present the evaluations of our proposed models in a real 5G testbed and benchmarked against centimeter-accurate Real-Time Kinematic (RTK) positioning, in an O-RAN--based 5G network by OpenAirInterface (OAI) software at EURECOM. It demonstrated outperforming results against the state-of-the-art semi-supervised and self-supervised CC approaches in a real-world scenario. The results show localization accuracies of 2-4 meters in 90% of cases, across a range of NLoS ratios. Furthermore, we provide public datasets of CIR recordings, along with the true position labels used in this paper's evaluation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08001","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.228553","language":"en","tags":["research","csni","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Mohsen Ahadi, Omid Esrafilian, Florian Kaltenberger, Adeel Malik","raw_content_length":1499,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["CIR","Transmission Reception Point","TRP","Time Difference of Arrival (","User Equipment","Channel Impulse Response"],"persons":[],"locations":[],"monetary":[]},"char_count":1498,"language_detected":"en","key_concepts":{"key_phrases":["Announce Type","new Abstract","Channel Charting","a promising framework","data-driven radio localization","existing approaches","the distortions","sight","NLoS","this work"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Announce Type":1.0,"new Abstract":1.0,"Channel Charting":1.0,"a promising framework":1.0,"data-driven radio localization":1.0,"existing approaches":1.0,"the distortions":1.0,"sight":1.0,"NLoS":1.0,"this work":1.0}},"age_hours":2.7728571052777777,"is_recent":true,"quality_score":0.7,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.886,"joy":0.012,"surprise":0.0668,"sadness":0.0075,"fear":0.0108,"anger":0.0114,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"pilot","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":5,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a novel channel charting method for radio localization tested in a real 5G testbed. It demonstrates localization accuracies of 2-4 meters in 90% of cases. The potential climate impact is indirect, as improved localization could enable more efficient resource management in various sectors, but this is not explicitly quantified.","key_impact_metrics":["localization accuracies of 2-4 meters","90% of cases"],"technology_tags":["radio localization","channel charting","5G","O-RAN"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:11.756892Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_615e3673575b","title":"Learning on the Job: An Experience-Driven Self","content":"arXiv:2510.08002v1 Announce Type: new Abstract: Large Language Models have demonstrated remarkable capabilities across diverse domains, yet significant challenges persist when deploying them as AI agents for real-world long-horizon tasks. Existing LLM agents suffer from a critical limitation: they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job. To address this challenge, we propose MUSE, a novel agent framework that introduces an experience-driven, self-evolving system centered around a hierarchical Memory Module. MUSE organizes diverse levels of experience and leverages them to plan and execute long-horizon tasks across multiple applications. After each sub-task execution, the agent autonomously reflects on its trajectory, converting the raw trajectory into structured experience and integrating it back into the Memory Module. This mechanism enables the agent to evolve beyond its static pretrained parameters, fostering continuous learning and self-evolution. We evaluate MUSE on the long-horizon productivity benchmark TAC. It achieves new SOTA performance by a significant margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments demonstrate that as the agent autonomously accumulates experience, it exhibits increasingly superior task completion capabilities, as well as robust continuous learning and self-evolution capabilities. Moreover, the accumulated experience from MUSE exhibits strong generalization properties, enabling zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI agents capable of real-world productivity task automation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08002","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.228954","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Cheng Yang, Xuemeng Yang, Licheng Wen, Daocheng Fu, Jianbiao Mei, Rong Wu, Pinlong Cai, Yufan Shen, Nianchen Deng, Botian Shi, Yu Qiao, Haifeng Li","raw_content_length":1690,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["the Memory Module","MUSE","Memory Module"],"persons":[],"locations":[],"monetary":[]},"char_count":1689,"language_detected":"en","key_concepts":{"key_phrases":["the Job","arXiv251008002v1 Announce Type","new Abstract","Large Language Models","remarkable capabilities","diverse domains","significant challenges","them","AI agents","real-world long-horizon tasks"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Job":2.0,"arXiv251008002v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"remarkable capabilities":1.0,"diverse domains":1.0,"significant challenges":1.0,"them":1.0,"AI agents":1.0,"real-world long-horizon tasks":1.0}},"age_hours":2.772872731111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.5325,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5065,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.716,"joy":0.0064,"surprise":0.0362,"sadness":0.0608,"fear":0.1528,"anger":0.0148,"disgust":0.0129},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI agent framework (MUSE) that learns from experience to improve task completion. While it achieves state-of-the-art performance on a benchmark, it's still in the early stages of development with no real-world deployment data. The climate impact is indirect, potentially improving efficiency in various sectors, but not directly reducing emissions.","key_impact_metrics":["SOTA performance on TAC benchmark","Zero-shot improvement on new tasks"],"technology_tags":["Large Language Models","AI Agents","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:37:14.521219Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_741407760b9a","title":"CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain","content":"arXiv:2510.08003v1 Announce Type: new Abstract: Composed Image Retrieval (CIR), which aims to find a target image from a reference image and a modification text, presents the core challenge of performing unified reasoning across visual and semantic modalities. While current approaches based on Vision-Language Models (VLMs, e.g., CLIP) and more recent Multimodal Large Language Models (MLLMs, e.g., Qwen-VL) have shown progress, they predominantly function as ``black boxes.\" This inherent opacity not only prevents users from understanding the retrieval rationale but also restricts the models' ability to follow complex, fine-grained instructions. To overcome these limitations, we introduce CIR-CoT, the first end-to-end retrieval-oriented MLLM designed to integrate explicit Chain-of-Thought (CoT) reasoning. By compelling the model to first generate an interpretable reasoning chain, CIR-CoT enhances its ability to capture crucial cross-modal interactions, leading to more accurate retrieval while making its decision process transparent. Since existing datasets like FashionIQ and CIRR lack the necessary reasoning data, a key contribution of our work is the creation of structured CoT annotations using a three-stage process involving a caption, reasoning, and conclusion. Our model is then fine-tuned to produce this structured output before encoding its final retrieval intent into a dedicated embedding. Comprehensive experiments show that CIR-CoT achieves highly competitive performance on in-domain datasets (FashionIQ, CIRR) and demonstrates remarkable generalization on the out-of-domain CIRCO dataset, establishing a new path toward more effective and trustworthy retrieval systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08003","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.229362","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Weihuang Lin, Yiwei Ma, Jiayi Ji, Xiaoshuai Sun, Rongrong Ji","raw_content_length":1700,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["CIR","CoT","Multimodal Large Language Models","Vision-Language Models","CLIP"],"persons":["Qwen-VL"],"locations":[],"monetary":[]},"char_count":1699,"language_detected":"en","key_concepts":{"key_phrases":["CIR-CoT","Interpretable Composed Image Retrieval","End","arXiv251008003v1 Announce Type","new Abstract","Composed Image Retrieval","CIR","which","a target image","a reference image"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CIR-CoT":2.0,"Interpretable Composed Image Retrieval":2.0,"End":2.0,"arXiv251008003v1 Announce Type":1.0,"new Abstract":1.0,"Composed Image Retrieval":1.0,"CIR":1.0,"which":1.0,"a target image":1.0,"a reference image":1.0}},"age_hours":2.772889585,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8896,"joy":0.0166,"surprise":0.0517,"sadness":0.0062,"fear":0.0108,"anger":0.0192,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI model (CIR-CoT) for image retrieval. While it improves the accuracy and interpretability of image retrieval, it doesn't directly address climate change or environmental sustainability. The model is currently in the applied research stage, with no evidence of deployment or real-world impact.","key_impact_metrics":["Improved retrieval accuracy on FashionIQ and CIRR datasets"],"technology_tags":["Artificial Intelligence","Image Retrieval","Vision-Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:37:17.294676Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c6c758a3fc0a","title":"Past, Present, and Future of Bug Tracking in the Generative AI Era","content":"arXiv:2510.08005v1 Announce Type: new Abstract: Traditional bug tracking systems rely heavily on manual reporting, reproduction, triaging, and resolution, each carried out by different stakeholders such as end users, customer support, developers, and testers. This division of responsibilities requires significant coordination and widens the communication gap between non-technical users and technical teams, slowing the process from bug discovery to resolution. Moreover, current systems are highly asynchronous; users often wait hours or days for a first response, delaying fixes and contributing to frustration. This paper examines the evolution of bug tracking, from early paper-based reporting to today's web-based and SaaS platforms. Building on this trajectory, we propose an AI-powered bug tracking framework that augments existing tools with intelligent, large language model (LLM)-driven automation. Our framework addresses two main challenges: reducing time-to-fix and minimizing human overhead. Users report issues in natural language, while AI agents refine reports, attempt reproduction, and request missing details. Reports are then classified, invalid ones resolved through no-code fixes, and valid ones localized and assigned to developers. LLMs also generate candidate patches, with human oversight ensuring correctness. By integrating automation into each phase, our framework accelerates response times, improves collaboration, and strengthens software maintenance practices for a more efficient, user-centric future.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08005","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.230159","language":"en","tags":["csse","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Utku Boran Torun, Mehmet Taha Demircan, Mahmut Furkan G\\\"on, Eray T\\\"uz\\\"un","raw_content_length":1539,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["Future of Bug Tracking"],"persons":[],"locations":[],"monetary":[]},"char_count":1538,"language_detected":"en","key_concepts":{"key_phrases":["Present","Future","Bug Tracking","the Generative AI Era","resolution","arXiv251008005v1 Announce Type","new Abstract","Traditional bug tracking systems","manual reporting","reproduction"],"filter_categories":{"ai_ml":["the Generative AI Era"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Present":2.0,"Future":2.0,"Bug Tracking":2.0,"the Generative AI Era":2.0,"resolution":2.0,"arXiv251008005v1 Announce Type":1.0,"new Abstract":1.0,"Traditional bug tracking systems":1.0,"manual reporting":1.0,"reproduction":1.0}},"age_hours":2.7729202688888885,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9199,"joy":0.005,"surprise":0.0343,"sadness":0.0118,"fear":0.0056,"anger":0.0157,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes an AI-powered bug tracking framework to reduce time-to-fix and human overhead in software development. While it aims to improve efficiency, there's no concrete deployment or measurable outcome data provided, placing it in the applied research stage. The potential climate impact is indirect, as more efficient software development could lead to reduced energy consumption in data centers, but this is not quantified.","key_impact_metrics":[],"technology_tags":["AI","LLM","Software Development"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:37:20.170697Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2ea1c22c0c98","title":"Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of","content":"arXiv:2510.08008v1 Announce Type: new Abstract: The rapidly increasing computational cost of pretraining Large Language Models necessitates more efficient approaches. Numerous computational costs have been invested in existing well-trained checkpoints, but many of them remain underutilized due to engineering constraints or limited model capacity. To efficiently reuse this \"sunk\" cost, we propose to recycle pretrained checkpoints by expanding their parameter counts and continuing training. We propose orthogonal growth method well-suited for converged Mixture-of-Experts model: interpositional layer copying for depth growth and expert duplication with injected noise for width growth. To determine the optimal timing for such growth across checkpoints sequences, we perform comprehensive scaling experiments revealing that the final accuracy has a strong positive correlation with the amount of sunk cost, indicating that greater prior investment leads to better performance. We scale our approach to models with 70B parameters and over 1T training tokens, achieving 10.66% accuracy gain over training from scratch under the same additional compute budget. Our checkpoint recycling approach establishes a foundation for economically efficient large language model pretraining.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08008","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.230564","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Ruizhe Wang, Yucheng Ding, Xiao Liu, Yaoxiang Wang, Peng Cheng, Baining Guo, Zhengjun Zha, Yeyun Gong","raw_content_length":1282,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1281,"language_detected":"en","key_concepts":{"key_phrases":["Pretrained Checkpoints","Orthogonal Growth","Mixture","arXiv251008008v1 Announce Type","new Abstract","The rapidly increasing computational cost","Large Language Models","more efficient approaches","Numerous computational costs","existing well-trained checkpoints"],"filter_categories":{"ai_ml":["Pretrained Checkpoints","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Pretrained Checkpoints":2.0,"Orthogonal Growth":2.0,"Mixture":2.0,"arXiv251008008v1 Announce Type":1.0,"new Abstract":1.0,"The rapidly increasing computational cost":1.0,"Large Language Models":1.0,"more efficient approaches":1.0,"Numerous computational costs":1.0,"existing well-trained checkpoints":1.0}},"age_hours":2.7729345247222223,"is_recent":true,"quality_score":1.0,"sentiment_score":8.0915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6183,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.783,"joy":0.0129,"surprise":0.0566,"sadness":0.0756,"fear":0.0105,"anger":0.0392,"disgust":0.0222},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method for recycling pretrained language model checkpoints, which could reduce the computational cost of training new models. This could lead to lower energy consumption for AI development. The claim of 10.66% accuracy gain is a measurable outcome, but the research is still in the applied research phase with no deployed units.","key_impact_metrics":["10.66% accuracy gain","70B parameters"],"technology_tags":["Large Language Models","Mixture-of-Experts","Orthogonal Growth"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:37:22.761768Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf9c2cda03b3","title":"Language Models Do Not Embed Numbers Continuously","content":"arXiv:2510.08009v1 Announce Type: new Abstract: Recent research has extensively studied how large language models manipulate integers in specific arithmetic tasks, and on a more fundamental level, how they represent numeric values. These previous works have found that language model embeddings can be used to reconstruct the original values, however, they do not evaluate whether language models actually model continuous values as continuous. Using expected properties of the embedding space, including linear reconstruction and principal component analysis, we show that language models not only represent numeric spaces as non-continuous but also introduce significant noise. Using models from three major providers (OpenAI, Google Gemini and Voyage AI), we show that while reconstruction is possible with high fidelity ($R^2 \\geq 0.95$), principal components only explain a minor share of variation within the embedding space. This indicates that many components within the embedding space are orthogonal to the simple numeric input space. Further, both linear reconstruction and explained variance suffer with increasing decimal precision, despite the ordinal nature of the input space being fundamentally unchanged. The findings of this work therefore have implications for the many areas where embedding models are used, in-particular where high numerical precision, large magnitudes or mixed-sign values are common.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08009","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.230954","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Alex O. Davies, Roussel Nzoyem, Nirav Ajmeri, Telmo M. Silva Filho","raw_content_length":1425,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Language Models Do Not Embed Numbers Continuously arXiv:2510.08009v1 Announce Type","OpenAI","Voyage AI","Google Gemini"],"persons":[],"locations":[],"monetary":["0.95$","R^2"]},"char_count":1424,"language_detected":"en","key_concepts":{"key_phrases":["Language Models","Numbers","arXiv251008009v1 Announce Type","new Abstract","Recent research","how large language models","integers","specific arithmetic tasks","a more fundamental level","numeric values"],"filter_categories":{"research_academic":["Recent research"],"ai_ml":["how large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Language Models":2.0,"Numbers":2.0,"arXiv251008009v1 Announce Type":1.0,"new Abstract":1.0,"Recent research":1.0,"how large language models":1.0,"integers":1.0,"specific arithmetic tasks":1.0,"a more fundamental level":1.0,"numeric values":1.0}},"age_hours":2.7729487777777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8555,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9209,"joy":0.0051,"surprise":0.0411,"sadness":0.008,"fear":0.0032,"anger":0.011,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research investigates the numerical representation within language models, finding limitations in their ability to model continuous values. While reconstruction of numeric values is possible with high fidelity (R^2 >= 0.95), the study reveals that principal components explain only a minor share of variation, indicating significant noise and non-continuity in the embedding space. This impacts areas requiring high numerical precision, large magnitudes, or mixed-sign values, which could indirectly affect the efficiency of AI-driven climate models or resource management systems.","key_impact_metrics":["R^2 >= 0.95","minor share of variation explained by principal components"],"technology_tags":["Language Models","Embeddings","Principal Component Analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:25.759680Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e18dbf38b9c","title":"Accelerated Evolving Set Processes for Local PageRank Computation","content":"arXiv:2510.08010v1 Announce Type: new Abstract: This work proposes a novel framework based on nested evolving set processes to accelerate Personalized PageRank (PPR) computation. At each stage of the process, we employ a localized inexact proximal point iteration to solve a simplified linear system. We show that the time complexity of such localized methods is upper bounded by $\\min\\{\\tilde{\\mathcal{O}}(R^2/\\epsilon^2), \\tilde{\\mathcal{O}}(m)\\}$ to obtain an $\\epsilon$-approximation of the PPR vector, where $m$ denotes the number of edges in the graph and $R$ is a constant defined via nested evolving set processes. Furthermore, the algorithms induced by our framework require solving only $\\tilde{\\mathcal{O}}(1/\\sqrt{\\alpha})$ such linear systems, where $\\alpha$ is the damping factor. When $1/\\epsilon^2\\ll m$, this implies the existence of an algorithm that computes an $\\ epsilon $-approximation of the PPR vector with an overall time complexity of $\\tilde{\\mathcal{O}}\\left(R^2 / (\\sqrt{\\alpha}\\epsilon^2)\\right)$, independent of the underlying graph size. Our result resolves an open conjecture from existing literature. Experimental results on real-world graphs validate the efficiency of our methods, demonstrating significant convergence in the early stages.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08010","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.231331","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Binbin Huang, Luo Luo, Yanghua Xiao, Deqing Yang, Baojian Zhou","raw_content_length":1276,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["linear","PPR"],"persons":["\\min\\{\\tilde{\\mathcal{O}}(R^2/\\epsilon^2","\\tilde{\\mathcal{O}}(m)\\}$"],"locations":["Personalized PageRank"],"monetary":["\\alpha$","only $","1/\\epsilon^2\\ll","$\\ epsilon"]},"char_count":1275,"language_detected":"en","key_concepts":{"key_phrases":["Accelerated","Evolving Set Processes","Local PageRank Computation","arXiv251008010v1 Announce Type","new Abstract","This work","a novel framework","nested evolving set processes","Personalized PageRank PPR computation","each stage"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Accelerated":2.0,"Evolving Set Processes":2.0,"Local PageRank Computation":2.0,"arXiv251008010v1 Announce Type":1.0,"new Abstract":1.0,"This work":1.0,"a novel framework":1.0,"nested evolving set processes":1.0,"Personalized PageRank PPR computation":1.0,"each stage":1.0}},"age_hours":2.7729632475000003,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8713,"joy":0.0192,"surprise":0.0737,"sadness":0.0041,"fear":0.0042,"anger":0.0197,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for Personalized PageRank computation, which could potentially improve the efficiency of large-scale data processing. While the algorithm's efficiency is demonstrated through experimental results, its direct impact on climate change is indirect and theoretical at this stage. The research is primarily at the basic research stage with no deployed units or operational data.","key_impact_metrics":["Time complexity of $\\tilde{\\mathcal{O}}(R^2 / (\\sqrt{\\alpha}\\epsilon^2))$","$\\epsilon$-approximation of the PPR vector"],"technology_tags":["Personalized PageRank","Graph Algorithms","Proximal Point Iteration"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:28.597341Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3547ae1bd0d8","title":"Do We Really Need SFT? Prompt-as","content":"arXiv:2510.08012v1 Announce Type: new Abstract: Next point-of-interest (POI) recommendation is crucial for smart urban services such as tourism, dining, and transportation, yet most approaches struggle under cold-start conditions where user-POI interactions are sparse. Recent efforts leveraging large language models (LLMs) address this challenge through either supervised fine-tuning (SFT) or in-context learning (ICL). However, SFT demands costly annotations and fails to generalize to inactive users, while static prompts in ICL cannot adapt to diverse user contexts. To overcome these limitations, we propose Prompt-as-Policy over knowledge graphs, a reinforcement-guided prompting framework that learns to construct prompts dynamically through contextual bandit optimization. Our method treats prompt construction as a learnable policy that adaptively determines (i) which relational evidences to include, (ii) the number of evidence per candidate, and (iii) their organization and ordering within prompts. More specifically, we construct a knowledge graph (KG) to discover candidates and mine relational paths, which are transformed into evidence cards that summarize rationales for each candidate POI. The frozen LLM then acts as a reasoning engine, generating recommendations from the KG-discovered candidate set based on the policy-optimized prompts. Experiments on three real-world datasets demonstrate that Prompt-as-Policy consistently outperforms state-of-the-art baselines, achieving average 7.7\\% relative improvements in Acc@1 for inactive users, while maintaining competitive performance on active users, without requiring model fine-tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08012","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.231758","language":"en","tags":["cssi","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Jinze Wang, Lu Zhang, Yiyang Cui, Zhishu Shen, Xingjun Ma, Jiong Jin, Tiehua Zhang","raw_content_length":1660,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["POI","SFT","ICL"],"persons":[],"locations":[],"monetary":[]},"char_count":1659,"language_detected":"en","key_concepts":{"key_phrases":["SFT","Announce Type","new Abstract","interest","smart urban services","tourism","dining","transportation","struggle","cold-start conditions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SFT":3.0,"Announce Type":1.0,"new Abstract":1.0,"interest":1.0,"smart urban services":1.0,"tourism":1.0,"dining":1.0,"transportation":1.0,"struggle":1.0,"cold-start conditions":1.0}},"age_hours":2.7729790869444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9869999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4026,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.833,"joy":0.0029,"surprise":0.0687,"sadness":0.0256,"fear":0.034,"anger":0.0254,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for improving POI recommendations using LLMs and knowledge graphs. The concrete action is the development of a reinforcement-guided prompting framework. Evidence comes from experiments on real-world datasets, showing a 7.7% relative improvement in Acc@1 for inactive users. The innovation is at the applied research stage, with no deployment mentioned.","key_impact_metrics":["7.7% relative improvements in Acc@1"],"technology_tags":["Large Language Models","Knowledge Graphs","Reinforcement Learning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-28T20:37:31.298799Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_79268d717735","title":"Unsupervised Radio Map Construction in Mixed LoS/NLoS Indoor Environments","content":"arXiv:2510.08015v1 Announce Type: new Abstract: Radio maps are essential for enhancing wireless communications and localization. However, existing methods for constructing radio maps typically require costly calibration pro- cesses to collect location-labeled channel state information (CSI) datasets. This paper aims to recover the data collection trajectory directly from the channel propagation sequence, eliminating the need for location calibration. The key idea is to employ a hidden Markov model (HMM)-based framework to conditionally model the channel propagation matrix, while simultaneously modeling the location correlation in the trajectory. The primary challenges involve modeling the complex relationship between channel propagation in multiple-input multiple-output (MIMO) networks and geographical locations, and addressing both line-of-sight (LOS) and non-line-of-sight (NLOS) indoor conditions. In this paper, we propose an HMM-based framework that jointly characterizes the conditional propagation model and the evolution of the user trajectory. Specifically, the channel propagation in MIMO networks is modeled separately in terms of power, delay, and angle, with distinct models for LOS and NLOS conditions. The user trajectory is modeled using a Gaussian-Markov model. The parameters for channel propagation, the mobility model, and LOS/NLOS classification are optimized simultaneously. Experimental validation using simulated MIMO-Orthogonal Frequency-Division Multiplexing (OFDM) networks with a multi-antenna uniform linear arrays (ULA) configuration demonstrates that the proposed method achieves an average localization accuracy of 0.65 meters in an indoor environment, covering both LOS and NLOS regions. Moreover, the constructed radio map enables localization with a reduced error compared to conventional supervised methods, such as k-nearest neighbors (KNN), support vector machine (SVM), and deep neural network (DNN).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08015","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.232560","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Zheng Xing, Junting Chen","raw_content_length":1952,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["Radio Map Construction","CSI","NLOS"],"persons":["MIMO","Markov"],"locations":[],"monetary":[]},"char_count":1951,"language_detected":"en","key_concepts":{"key_phrases":["Unsupervised Radio Map Construction","Mixed LoSNLoS Indoor Environments","arXiv251008015v1 Announce Type","new Abstract","Radio maps","wireless communications","localization","existing methods","radio maps","costly calibration pro- cesses"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unsupervised Radio Map Construction":2.0,"Mixed LoSNLoS Indoor Environments":2.0,"arXiv251008015v1 Announce Type":1.0,"new Abstract":1.0,"Radio maps":1.0,"wireless communications":1.0,"localization":1.0,"existing methods":1.0,"radio maps":1.0,"costly calibration pro- cesses":1.0}},"age_hours":2.773007080833333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9033,"joy":0.022,"surprise":0.042,"sadness":0.0076,"fear":0.0065,"anger":0.0142,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for constructing radio maps, which could potentially improve the efficiency of wireless communication and localization systems. The method is validated using simulated data and achieves an average localization accuracy of 0.65 meters. However, it is still in the research phase and lacks real-world deployment data, thus limiting its immediate sustainability impact.","key_impact_metrics":["localization accuracy of 0.65 meters"],"technology_tags":["radio map construction","hidden Markov model","MIMO-OFDM networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:33.965082Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0dc6d73b0f07","title":"Backdoor Vectors: a Task Arithmetic View on Backdoor Attacks and Defenses","content":"arXiv:2510.08016v1 Announce Type: new Abstract: Model merging (MM) recently emerged as an effective method for combining large deep learning models. However, it poses significant security risks. Recent research shows that it is highly susceptible to backdoor attacks, which introduce a hidden trigger into a single fine-tuned model instance that allows the adversary to control the output of the final merged model at inference time. In this work, we propose a simple framework for understanding backdoor attacks by treating the attack itself as a task vector. $Backdoor\\ Vector\\ (BV)$ is calculated as the difference between the weights of a fine-tuned backdoored model and fine-tuned clean model. BVs reveal new insights into attacks understanding and a more effective framework to measure their similarity and transferability. Furthermore, we propose a novel method that enhances backdoor resilience through merging dubbed $Sparse\\ Backdoor\\ Vector\\ (SBV)$ that combines multiple attacks into a single one. We identify the core vulnerability behind backdoor threats in MM: $inherent\\ triggers$ that exploit adversarial weaknesses in the base model. To counter this, we propose $Injection\\ BV\\ Subtraction\\ (IBVS)$ - an assumption-free defense against backdoors in MM. Our results show that SBVs surpass prior attacks and is the first method to leverage merging to improve backdoor effectiveness. At the same time, IBVS provides a lightweight, general defense that remains effective even when the backdoor threat is entirely unknown.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08016","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.232956","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Stanis{\\l}aw Pawlak, Jan Dubi\\'nski, Daniel Marczak, Bart{\\l}omiej Twardowski","raw_content_length":1536,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":["Backdoor\\"]},"char_count":1535,"language_detected":"en","key_concepts":{"key_phrases":["Backdoor Vectors","a Task Arithmetic View","Backdoor Attacks","Defenses","arXiv251008016v1 Announce Type","new Abstract","Model","merging","an effective method","large deep learning models"],"filter_categories":{"ai_ml":["Model","large deep learning models"],"business_innovation":["Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Backdoor Vectors":2.0,"a Task Arithmetic View":2.0,"Backdoor Attacks":2.0,"Defenses":2.0,"arXiv251008016v1 Announce Type":1.0,"new Abstract":1.0,"Model":1.0,"merging":1.0,"an effective method":1.0,"large deep learning models":1.0}},"age_hours":2.7730221383333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.2246,"joy":0.0032,"surprise":0.0077,"sadness":0.0137,"fear":0.6483,"anger":0.0572,"disgust":0.0454},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on the security of machine learning models used in model merging, specifically addressing backdoor attacks. While the research is technically sound and peer-reviewed, it is in the early stages and does not directly translate to concrete climate action or measurable environmental outcomes. The research is theoretical and lacks deployment or real-world impact data.","key_impact_metrics":[],"technology_tags":["machine learning","model merging","backdoor attacks","AI security"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:37:36.722191Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fa9e087f1b8c","title":"FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large","content":"arXiv:2510.08022v1 Announce Type: new Abstract: Data-driven robotic manipulation learning depends on large-scale, high-quality expert demonstration datasets. However, existing datasets, which primarily rely on human teleoperated robot collection, are limited in terms of scalability, trajectory smoothness, and applicability across different robotic embodiments in real-world environments. In this paper, we present FastUMI-100K, a large-scale UMI-style multimodal demonstration dataset, designed to overcome these limitations and meet the growing complexity of real-world manipulation tasks. Collected by FastUMI, a novel robotic system featuring a modular, hardware-decoupled mechanical design and an integrated lightweight tracking system, FastUMI-100K offers a more scalable, flexible, and adaptable solution to fulfill the diverse requirements of real-world robot demonstration data. Specifically, FastUMI-100K contains over 100K+ demonstration trajectories collected across representative household environments, covering 54 tasks and hundreds of object types. Our dataset integrates multimodal streams, including end-effector states, multi-view wrist-mounted fisheye images and textual annotations. Each trajectory has a length ranging from 120 to 500 frames. Experimental results demonstrate that FastUMI-100K enables high policy success rates across various baseline algorithms, confirming its robustness, adaptability, and real-world applicability for solving complex, dynamic manipulation challenges. The source code and dataset will be released in this link https://github.com/MrKeee/FastUMI-100K.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08022","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.233872","language":"en","tags":["csro","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Kehui Liu, Zhongjie Jia, Yang Li,  Zhaxizhuoma, Pengan Chen, Song Liu, Xin Liu, Pingrui Zhang, Haoming Song, Xinyi Ye, Nieqing Cao, Zhigang Wang, Jia Zeng, Dong Wang, Yan Ding, Bin Zhao, Xuelong Li","raw_content_length":1610,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["FastUMI-100K"],"persons":["FastUMI-100K"],"locations":[],"monetary":[]},"char_count":1609,"language_detected":"en","key_concepts":{"key_phrases":["FastUMI-100K","Advancing Data-driven Robotic Manipulation","arXiv251008022v1 Announce Type","new Abstract","Data-driven robotic manipulation learning","large-scale high-quality expert demonstration datasets","existing datasets","which","human teleoperated robot collection","terms"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"FastUMI-100K":3.0,"Advancing Data-driven Robotic Manipulation":2.0,"arXiv251008022v1 Announce Type":1.0,"new Abstract":1.0,"Data-driven robotic manipulation learning":1.0,"large-scale high-quality expert demonstration datasets":1.0,"existing datasets":1.0,"which":1.0,"human teleoperated robot collection":1.0,"terms":1.0}},"age_hours":2.7730512394444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8987,"joy":0.0254,"surprise":0.0475,"sadness":0.0045,"fear":0.0074,"anger":0.0109,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a large-scale dataset for robotic manipulation learning, which could indirectly contribute to sustainability by improving the efficiency of robots used in various sectors. However, the direct climate impact is low as it's primarily a research tool at the applied research stage with no deployed units. The technical credibility is relatively high due to the experimental results demonstrating policy success rates.","key_impact_metrics":["100K+ demonstration trajectories","120 to 500 frames per trajectory"],"technology_tags":["Robotics","Data-driven learning","Robotic manipulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:39.558274Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8c8f6a57f05c","title":"Do We Really Need Permutations? Impact of Width Expansion on Linear Mode Connectivity","content":"arXiv:2510.08023v1 Announce Type: new Abstract: Recently, Ainsworth et al. empirically demonstrated that, given two independently trained models, applying a parameter permutation that preserves the input-output behavior allows the two models to be connected by a low-loss linear path. When such a path exists, the models are said to achieve linear mode connectivity (LMC). Prior studies, including Ainsworth et al., have reported that achieving LMC requires not only an appropriate permutation search but also sufficiently wide models (e.g., a 32 $\\times$ width multiplier for ResNet-20). This is broadly believed to be because increasing the model width ensures a large enough space of candidate permutations, increasing the chance of finding one that yields LMC. In this work, we empirically demonstrate that, even without any permutations, simply widening the models is sufficient for achieving LMC when using a suitable softmax temperature calibration. We further explain why this phenomenon arises by analyzing intermediate layer outputs. Specifically, we introduce layerwise exponentially weighted connectivity (LEWC), which states that the output of each layer of the merged model can be represented as an exponentially weighted sum of the outputs of the corresponding layers of the original models. Consequently the merged model's output matches that of an ensemble of the original models, which facilitates LMC. To the best of our knowledge, this work is the first to show that widening the model not only facilitates nonlinear mode connectivity, as suggested in prior research, but also significantly increases the possibility of achieving linear mode connectivity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08023","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.234285","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":246,"author":"Akira Ito, Masanori Yamada, Daiki Chijiwa, Atsutoshi Kumagai","raw_content_length":1676,"priority":7,"update_frequency":1,"reading_time_minutes":1.23,"robust_parsing_used":true,"entities":{"organizations":["LMC","Width Expansion"],"persons":["Ainsworth","\\times$"],"locations":[],"monetary":["32 $"]},"char_count":1675,"language_detected":"en","key_concepts":{"key_phrases":["Permutations","Impact","Width Expansion","Linear Mode Connectivity","Ainsworth","LMC","arXiv251008023v1 Announce Type","new Abstract","two independently trained models","a parameter permutation"],"filter_categories":{"ai_ml":["Ainsworth"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Permutations":2.0,"Impact":2.0,"Width Expansion":2.0,"Linear Mode Connectivity":2.0,"Ainsworth":2.0,"LMC":2.0,"arXiv251008023v1 Announce Type":1.0,"new Abstract":1.0,"two independently trained models":1.0,"a parameter permutation":1.0}},"age_hours":2.7730671952777777,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6695,"joy":0.0658,"surprise":0.2121,"sadness":0.0082,"fear":0.0078,"anger":0.0243,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving linear mode connectivity in neural networks by widening the models, potentially leading to more efficient training. While it doesn't directly address climate change, more efficient AI training could reduce energy consumption. The research is supported by empirical demonstrations and analysis of intermediate layer outputs, but it is still in the basic research phase with no deployed applications.","key_impact_metrics":["32x width multiplier for ResNet-20"],"technology_tags":["neural networks","linear mode connectivity","softmax temperature calibration"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:42.211504Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2321f184a227","title":"PEAR: Phase Entropy Aware Reward for Efficient Reasoning","content":"arXiv:2510.08026v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) have achieved impressive performance on complex reasoning tasks by generating detailed chain-of-thought (CoT) explanations. However, these responses are often excessively long, containing redundant reasoning steps that inflate inference cost and reduce usability. Controlling the length of generated reasoning without sacrificing accuracy remains an open challenge. Through a systematic empirical analysis, we reveal a consistent positive correlation between model entropy and response length at different reasoning stages across diverse LRMs: the thinking phase exhibits higher entropy, reflecting exploratory behavior of longer responses, while the final answer phase shows lower entropy, indicating a more deterministic solution.This observation suggests that entropy at different reasoning stages can serve as a control knob for balancing conciseness and performance. Based on this insight, this paper introduces Phase Entropy Aware Reward (PEAR), a reward mechanism that incorporating phase-dependent entropy into the reward design. Instead of treating all tokens uniformly, PEAR penalize excessive entropy during the thinking phase and allowing moderate exploration at the final answer phase, which encourages models to generate concise reasoning traces that retain sufficient flexibility to solve the task correctly. This enables adaptive control of response length without relying on explicit length targets or rigid truncation rules. Extensive experiments across four benchmarks demonstrate that PEAR consistently reduces response length while sustaining competitive accuracy across model scales. In addition, PEAR demonstrates strong out-of-distribution (OOD) robustness beyond the training distribution. Our code is available at: https://github.com/iNLP-Lab/PEAR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08026","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.234718","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Chen Huang, Wei Lu, Wenxuan Zhang","raw_content_length":1853,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1852,"language_detected":"en","key_concepts":{"key_phrases":["PEAR","Phase Entropy Aware Reward","Efficient Reasoning","arXiv251008026v1","Announce Type","new Abstract","Large Reasoning Models","LRMs","impressive performance","complex reasoning tasks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PEAR":2.0,"Phase Entropy Aware Reward":2.0,"Efficient Reasoning":2.0,"arXiv251008026v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Large Reasoning Models":1.0,"LRMs":1.0,"impressive performance":1.0,"complex reasoning tasks":1.0}},"age_hours":2.773081383055555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8779,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8507,"joy":0.0046,"surprise":0.007,"sadness":0.0096,"fear":0.0568,"anger":0.0418,"disgust":0.0295},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a new reward mechanism (PEAR) for Large Reasoning Models (LRMs) to reduce response length and inference cost by penalizing excessive entropy during the thinking phase. The concrete action is the development and testing of this algorithm across four benchmarks, demonstrating a reduction in response length while maintaining accuracy. While promising, it's still in the research phase with no real-world deployment yet, hence the lower scores for economic viability and deployment readiness.","key_impact_metrics":["Reduced response length","Sustained competitive accuracy"],"technology_tags":["Large Language Models","Artificial Intelligence","Machine Learning","Entropy Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:37:45.245676Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bfcaabec546c","title":"AILoRA: Function","content":"arXiv:2510.08034v1 Announce Type: new Abstract: Parameter-efficient finetuning (PEFT) aims to mitigate the substantial computational and memory overhead involved in adapting large-scale pretrained models to diverse downstream tasks. Among numerous PEFT strategies, Low-Rank Adaptation (LoRA) has emerged as one of the most widely adopted approaches due to its robust empirical performance and low implementation complexity. In practical deployment, LoRA is typically applied to the $W^Q$ and $W^V$ projection matrices of self-attention modules, enabling an effective trade-off between model performance and parameter efficiency. While LoRA has achieved considerable empirical success, it still encounters challenges such as suboptimal performance and slow convergence. To address these limitations, we introduce \\textbf{AILoRA}, a novel parameter-efficient method that incorporates function-aware asymmetric low-rank priors. Our empirical analysis reveals that the projection matrices $W^Q$ and $W^V$ in the self-attention mechanism exhibit distinct parameter characteristics, stemming from their functional differences. Specifically, $W^Q$ captures task-specific semantic space knowledge essential for attention distributions computation, making its parameters highly sensitive to downstream task variations. In contrast, $W^V$ encodes token-level feature representations that tend to remain stable across tasks and layers. Leveraging these insights, AILoRA performs a function-aware initialization by injecting the principal components of $W^Q$ to retain task-adaptive capacity, and the minor components of $W^V$ to preserve generalizable feature representations. This asymmetric initialization strategy enables LoRA modules to better capture the specialized roles of attention parameters, thereby enhancing both finetuning performance and convergence efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08034","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.235131","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Xiaoshuang Ji, Zhendong Zhao, Xiaoyan Gu, Xiaojun Chen, Xin Zhao, Zeyao Liu","raw_content_length":1866,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":["LoRA"],"persons":[],"locations":[],"monetary":[]},"char_count":1865,"language_detected":"en","key_concepts":{"key_phrases":["AILoRA Function","LoRA","arXiv251008034v1","Announce Type","new Abstract","Parameter-efficient finetuning","PEFT","the substantial computational and memory overhead","large-scale pretrained models","downstream tasks"],"filter_categories":{"ai_ml":["AILoRA Function"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AILoRA Function":2.0,"LoRA":2.0,"arXiv251008034v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Parameter-efficient finetuning":1.0,"PEFT":1.0,"the substantial computational and memory overhead":1.0,"large-scale pretrained models":1.0,"downstream tasks":1.0}},"age_hours":2.773095536388889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9241,"joy":0.0207,"surprise":0.0288,"sadness":0.0053,"fear":0.0056,"anger":0.0112,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel parameter-efficient finetuning method (AILoRA) for large language models, aiming to improve performance and convergence efficiency. While the method shows promise in reducing computational overhead, it is currently in the research phase with no deployed units or real-world data. The potential climate impact is indirect, stemming from reduced energy consumption during model training and deployment, but this is not quantified.","key_impact_metrics":["Improved convergence efficiency","Reduced computational overhead"],"technology_tags":["Parameter-efficient finetuning","Low-Rank Adaptation","Large Language Models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:37:48.200806Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13853c8f2b8b","title":"Climate Knowledge in Large Language Models","content":"arXiv:2510.08043v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed for climate-related applications, where understanding internal climatological knowledge is crucial for reliability and misinformation risk assessment. Despite growing adoption, the capacity of LLMs to recall climate normals from parametric knowledge remains largely uncharacterized. We investigate the capacity of contemporary LLMs to recall climate normals without external retrieval, focusing on a prototypical query: mean July 2-m air temperature 1991-2020 at specified locations. We construct a global grid of queries at 1{\\deg} resolution land points, providing coordinates and location descriptors, and validate responses against ERA5 reanalysis. Results show that LLMs encode non-trivial climate structure, capturing latitudinal and topographic patterns, with root-mean-square errors of 3-6 {\\deg}C and biases of $\\pm$1 {\\deg}C. However, spatially coherent errors remain, particularly in mountains and high latitudes. Performance degrades sharply above 1500 m, where RMSE reaches 5-13 {\\deg}C compared to 2-4 {\\deg}C at lower elevations. We find that including geographic context (country, city, region) reduces errors by 27% on average, with larger models being most sensitive to location descriptors. While models capture the global mean magnitude of observed warming between 1950-1974 and 2000-2024, they fail to reproduce spatial patterns of temperature change, which directly relate to assessing climate change. This limitation highlights that while LLMs may capture present-day climate distributions, they struggle to represent the regional and local expression of long-term shifts in temperature essential for understanding climate dynamics. Our evaluation framework provides a reproducible benchmark for quantifying parametric climate knowledge in LLMs and complements existing climate communication assessments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08043","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.235933","language":"en","tags":["physicsao-ph","computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Ivan Kuznetsov (Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany), Jacopo Grassi (Department of Environment, Land, and Infrastructure Engineering, Politecnico di Torino, Turin, Italy), Dmitrii Pantiukhin (Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany), Boris Shapkin (Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany), Thomas Jung (Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany, Institute of Environmental Physics, University of Bremen, Bremen, Germany), Nikolay Koldunov (Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany)","raw_content_length":1931,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["\\deg}C. However"],"persons":[],"locations":[],"monetary":["\\pm$1"]},"char_count":1930,"language_detected":"en","key_concepts":{"key_phrases":["Climate Knowledge","Large Language Models","LLMs","the capacity","climate normals","arXiv251008043v1 Announce Type","new Abstract","Large language models","climate-related applications","internal climatological knowledge"],"filter_categories":{"ai_ml":["Large Language Models","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Climate Knowledge":2.0,"Large Language Models":2.0,"LLMs":2.0,"the capacity":2.0,"climate normals":2.0,"arXiv251008043v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"climate-related applications":1.0,"internal climatological knowledge":1.0}},"age_hours":2.7731222094444448,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9914999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6017,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8995,"joy":0.0046,"surprise":0.0339,"sadness":0.0061,"fear":0.0367,"anger":0.013,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research investigates the ability of LLMs to recall climate normals, comparing their output to ERA5 reanalysis data. While the models show some ability to capture climate structure, they struggle with spatial patterns of temperature change. This is currently basic research with no deployment, but the evaluation framework could be useful for future climate communication assessments.","key_impact_metrics":["RMSE of 3-6 degrees C","Bias of +/- 1 degree C"],"technology_tags":["Large Language Models","Climate Modeling"],"sdg_alignment":[4,13],"analyzed_at":"2025-10-28T20:37:54.428451Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce59aa09616f","title":"Towards Reliable LLM","content":"arXiv:2510.08044v1 Announce Type: new Abstract: Large language models (LLMs) demonstrate advanced reasoning abilities, enabling robots to understand natural language instructions and generate high-level plans with appropriate grounding. However, LLM hallucinations present a significant challenge, often leading to overconfident yet potentially misaligned or unsafe plans. While researchers have explored uncertainty estimation to improve the reliability of LLM-based planning, existing studies have not sufficiently differentiated between epistemic and intrinsic uncertainty, limiting the effectiveness of uncertainty esti- mation. In this paper, we present Combined Uncertainty estimation for Reliable Embodied planning (CURE), which decomposes the uncertainty into epistemic and intrinsic uncertainty, each estimated separately. Furthermore, epistemic uncertainty is subdivided into task clarity and task familiarity for more accurate evaluation. The overall uncertainty assessments are obtained using random network distillation and multi-layer perceptron regression heads driven by LLM features. We validated our approach in two distinct experimental settings: kitchen manipulation and tabletop rearrangement experiments. The results show that, compared to existing methods, our approach yields uncertainty estimates that are more closely aligned with the actual execution outcomes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08044","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.236325","language":"en","tags":["csro","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Shiyuan Yin, Chenjia Bai, Zihao Zhang, Junwei Jin, Xinxin Zhang, Chi Zhang, Xuelong Li","raw_content_length":1388,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Combined Uncertainty","LLM","Reliable Embodied"],"persons":[],"locations":[],"monetary":[]},"char_count":1387,"language_detected":"en","key_concepts":{"key_phrases":["Reliable LLM","arXiv251008044v1 Announce Type","new Abstract","Large language models","LLMs","advanced reasoning abilities","robots","natural language instructions","high-level plans","appropriate grounding"],"filter_categories":{"ai_ml":["Reliable LLM","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reliable LLM":2.0,"arXiv251008044v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"advanced reasoning abilities":1.0,"robots":1.0,"natural language instructions":1.0,"high-level plans":1.0,"appropriate grounding":1.0}},"age_hours":2.773135548888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6763,"joy":0.0093,"surprise":0.0145,"sadness":0.0119,"fear":0.2623,"anger":0.0186,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (CURE) to improve the reliability of LLM-based planning by decomposing uncertainty. The approach is validated in kitchen manipulation and tabletop rearrangement experiments, showing improved alignment with actual execution outcomes. However, the technology is still in the research phase, with no clear path to economic viability or large-scale deployment, limiting its immediate sustainability impact.","key_impact_metrics":["Improved uncertainty estimates aligned with actual execution outcomes"],"technology_tags":["Large Language Models","Robotics","Uncertainty Estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:37:58.389280Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fa8cac631e8f","title":"LinguaSim: Interactive Multi","content":"arXiv:2510.08046v1 Announce Type: new Abstract: The generation of testing and training scenarios for autonomous vehicles has drawn significant attention. While Large Language Models (LLMs) have enabled new scenario generation methods, current methods struggle to balance command adherence accuracy with the realism of real-world driving environments. To reduce scenario description complexity, these methods often compromise realism by limiting scenarios to 2D, or open-loop simulations where background vehicles follow predefined, non-interactive behaviors. We propose LinguaSim, an LLM-based framework that converts natural language into realistic, interactive 3D scenarios, ensuring both dynamic vehicle interactions and faithful alignment between the input descriptions and the generated scenarios. A feedback calibration module further refines the generation precision, improving fidelity to user intent. By bridging the gap between natural language and closed-loop, interactive simulations, LinguaSim constrains adversarial vehicle behaviors using both the scenario description and the autonomous driving model guiding them. This framework facilitates the creation of high-fidelity scenarios that enhance safety testing and training. Experiments show LinguaSim can generate scenarios with varying criticality aligned with different natural language descriptions (ACT: 0.072 s for dangerous vs. 3.532 s for safe descriptions; comfortability: 0.654 vs. 0.764), and its refinement module effectively reduces excessive aggressiveness in LinguaSim's initial outputs, lowering the crash rate from 46.9% to 6.3% to better match user intentions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08046","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.237137","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Qingyuan Shi, Qingwen Meng, Hao Cheng, Qing Xu, Jianqiang Wang","raw_content_length":1644,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["Interactive Multi arXiv:2510.08046v1 Announce Type: new Abstract","LLM"],"persons":["LinguaSim"],"locations":[],"monetary":[]},"char_count":1643,"language_detected":"en","key_concepts":{"key_phrases":["LinguaSim","Interactive Multi","scenarios","arXiv251008046v1 Announce Type","new Abstract","The generation","testing","autonomous vehicles","significant attention","Large Language Models"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LinguaSim":2.0,"Interactive Multi":2.0,"scenarios":2.0,"arXiv251008046v1 Announce Type":1.0,"new Abstract":1.0,"The generation":1.0,"testing":1.0,"autonomous vehicles":1.0,"significant attention":1.0,"Large Language Models":1.0}},"age_hours":2.7731610399999997,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9127,"joy":0.0092,"surprise":0.0425,"sadness":0.0097,"fear":0.0075,"anger":0.0122,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"LinguaSim is an LLM-based framework that generates realistic, interactive 3D scenarios for autonomous vehicle testing and training. It shows a reduction in crash rates from 46.9% to 6.3% by refining initial outputs. This is still in the applied research stage, with no clear path to economic viability or deployment readiness.","key_impact_metrics":["crash rate reduction from 46.9% to 6.3%","ACT: 0.072 s for dangerous vs. 3.532 s for safe descriptions"],"technology_tags":["autonomous vehicles","large language models","scenario generation","safety testing"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-28T20:38:02.548218Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
