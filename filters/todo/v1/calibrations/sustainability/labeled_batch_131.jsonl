{"id":"science_arxiv_cs_7a3589535dc8","title":"Audio Does Matter: Importance","content":"arXiv:2508.04273v2 Announce Type: replace Abstract: Video Moment Retrieval (VMR) aims to retrieve a specific moment semantically related to the given query. To tackle this task, most existing VMR methods solely focus on the visual and textual modalities while neglecting the complementary but important audio modality. Although a few recent works try to tackle the joint audio-vision-text reasoning, they treat all modalities equally and simply embed them without fine-grained interaction for moment retrieval. These designs are counter-practical as: Not all audios are helpful for video moment retrieval, and the audio of some videos may be complete noise or background sound that is meaningless to the moment determination. To this end, we propose a novel Importance-aware Multi-Granularity fusion model (IMG), which learns to dynamically and selectively aggregate the audio-vision-text contexts for VMR. Specifically, after integrating the textual guidance with vision and audio separately, we first design a pseudo-label-supervised audio importance predictor that predicts the importance score of the audio, and accordingly assigns weights to mitigate the interference caused by noisy audio. Then, we design a multi-granularity audio fusion module that adaptively fuses audio and visual modalities at local-, event-, and global-level, fully capturing their complementary contexts. We further propose a cross-modal knowledge distillation strategy to address the challenge of missing audio modality during inference. To evaluate our method, we further construct a new VMR dataset, i.e., Charades-AudioMatter, where audio-related samples are manually selected and re-organized from the original Charades-STA to validate the model's capability in utilizing audio modality. Extensive experiments validate the effectiveness of our method, achieving state-of-the-art with audio-video fusion in VMR methods. Our code is available at https://github.com/HuiGuanLab/IMG.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.04273","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.245433","language":"en","tags":["eessas","preprints","cscv","research","cssd","csmm","csir","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":268,"author":"Junan Lin, Daizong Liu, Xianke Chen, Xiaoye Qu, Xun Yang, Jixiang Zhu, Sanyuan Zhang, Jianfeng Dong","raw_content_length":1964,"priority":7,"update_frequency":1,"reading_time_minutes":1.34,"robust_parsing_used":true,"entities":{"organizations":["Multi-Granularity","VMR","Video Moment Retrieval","Importance-aware"],"persons":[],"locations":[],"monetary":[]},"char_count":1963,"language_detected":"en","key_concepts":{"key_phrases":["Audio","Announce Type","Abstract","Video Moment Retrieval","VMR","a specific moment","the given query","this task","most existing VMR methods","the visual and textual modalities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Audio":2.0,"Announce Type":1.0,"Abstract":1.0,"Video Moment Retrieval":1.0,"VMR":1.0,"a specific moment":1.0,"the given query":1.0,"this task":1.0,"most existing VMR methods":1.0,"the visual and textual modalities":1.0}},"age_hours":2.7690022561111114,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9448,"joy":0.0047,"surprise":0.019,"sadness":0.0088,"fear":0.0027,"anger":0.0106,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":1,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for video moment retrieval using audio-visual-text fusion. It focuses on improving the accuracy of the retrieval process by selectively weighting the audio modality. There are no concrete actions or measurable outcomes related to sustainability, as it is a theoretical improvement in AI algorithms.","key_impact_metrics":["State-of-the-art accuracy in VMR"],"technology_tags":["Artificial Intelligence","Video Analysis","Audio Processing"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:44:57.669604Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_efdee901568c","title":"Mediator-Guided Multi-Agent Collaboration among Open","content":"arXiv:2508.05996v2 Announce Type: replace Abstract: Complex medical decision-making involves cooperative workflows operated by different clinicians. Designing AI multi-agent systems can expedite and augment human-level clinical decision-making. Existing multi-agent researches primarily focus on language-only tasks, yet their extension to multimodal scenarios remains challenging. A blind combination of diverse vision-language models (VLMs) can amplify an erroneous outcome interpretation. VLMs in general are less capable in instruction following and importantly self-reflection, compared to large language models (LLMs) of comparable sizes. This disparity largely constrains VLMs' ability in cooperative workflows. In this study, we propose MedOrch, a mediator-guided multi-agent collaboration framework for medical multimodal decision-making. MedOrch employs an LLM-based mediator agent that enables multiple VLM-based expert agents to exchange and reflect on their outputs towards collaboration. We utilize multiple open-source general-purpose and domain-specific VLMs instead of costly GPT-series models, revealing the strength of heterogeneous models. We show that the collaboration within distinct VLM-based agents can surpass the capabilities of any individual agent. We validate our approach on five medical vision question answering benchmarks, demonstrating superior collaboration performance without model training. Our findings underscore the value of mediator-guided multi-agent collaboration in advancing medical multimodal intelligence.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.05996","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.246210","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Kaitao Chen, Mianxin Liu, Daoming Zong, Chaoyue Ding, Shaohao Rui, Yankai Jiang, Mu Zhou, Xiaosong Wang","raw_content_length":1555,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["LLM","VLM"],"persons":[],"locations":["MedOrch"],"monetary":[]},"char_count":1554,"language_detected":"en","key_concepts":{"key_phrases":["Mediator-Guided Multi-Agent Collaboration","Open","VLMs","Announce Type","Abstract","Complex medical decision-making","cooperative workflows","different clinicians","Designing AI multi-agent systems","human-level clinical decision-making"],"filter_categories":{"ai_ml":["Designing AI multi-agent systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mediator-Guided Multi-Agent Collaboration":2.0,"Open":2.0,"VLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"Complex medical decision-making":1.0,"cooperative workflows":1.0,"different clinicians":1.0,"Designing AI multi-agent systems":1.0,"human-level clinical decision-making":1.0}},"age_hours":2.7690336047222224,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8091,"joy":0.0105,"surprise":0.0142,"sadness":0.007,"fear":0.1173,"anger":0.0265,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a mediator-guided multi-agent collaboration framework (MedOrch) for medical multimodal decision-making. It utilizes open-source VLMs and demonstrates superior collaboration performance on medical vision question answering benchmarks. While promising, it is still in the applied research stage with no deployed units or operational data, hence the vaporware flag.","key_impact_metrics":["Superior collaboration performance on five medical vision question answering benchmarks"],"technology_tags":["Multi-agent systems","Vision-language models","Large language models"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:45:00.837324Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4afb97fb59cc","title":"NEP: Autoregressive Image Editing via Next Editing Token Prediction","content":"arXiv:2508.06044v2 Announce Type: replace Abstract: Text-guided image editing involves modifying a source image based on a language instruction and, typically, requires changes to only small local regions. However, existing approaches generate the entire target image rather than selectively regenerate only the intended editing areas. This results in (1) unnecessary computational costs and (2) a bias toward reconstructing non-editing regions, which compromises the quality of the intended edits. To resolve these limitations, we propose to formulate image editing as Next Editing-token Prediction (NEP) based on autoregressive image generation, where only regions that need to be edited are regenerated, thus avoiding unintended modification to the non-editing areas. To enable any-region editing, we propose to pre-train an any-order autoregressive text-to-image (T2I) model. Once trained, it is capable of zero-shot image editing and can be easily adapted to NEP for image editing, which achieves a new state-of-the-art on widely used image editing benchmarks. Moreover, our model naturally supports test-time scaling (TTS) through iteratively refining its generation in a zero-shot manner. The project page is: https://nep-bigai.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.06044","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.246604","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Huimin Wu, Xiaojian Ma, Haozhe Zhao, Yanpeng Zhao, Qing Li","raw_content_length":1246,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["NEP","Next Editing Token"],"persons":[],"locations":[],"monetary":[]},"char_count":1245,"language_detected":"en","key_concepts":{"key_phrases":["Next Editing Token","Prediction","arXiv250806044v2","Announce Type","Abstract","Text-guided image editing","a source image","a language instruction","changes","only small local regions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Next Editing Token":2.0,"Prediction":2.0,"arXiv250806044v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Text-guided image editing":1.0,"a source image":1.0,"a language instruction":1.0,"changes":1.0,"only small local regions":1.0}},"age_hours":2.769049605277778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7651,"joy":0.0052,"surprise":0.0216,"sadness":0.0692,"fear":0.0077,"anger":0.0535,"disgust":0.0779},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel image editing technique (NEP) that reduces computational costs by only regenerating necessary regions. While it achieves state-of-the-art results on benchmarks, it's still in the research phase with no deployed units or real-world impact data. The potential climate impact is indirect, stemming from reduced energy consumption during image editing, but this is not quantified.","key_impact_metrics":["Computational cost reduction","State-of-the-art benchmark performance"],"technology_tags":["Image editing","Autoregressive models","Artificial intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:45:04.566717Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c7fbba1b164","title":"Voting-Based Semi-Parallel Proof","content":"arXiv:2508.06489v2 Announce Type: replace Abstract: Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety guarantees, transaction throughput and confirmation latencies of Nakamoto consensus. In this work, we first consider the existing parallel PoW protocols and develop hard-coded incentive attack structures. Our theoretical results and simulations show that the existing parallel PoW protocols are more vulnerable to incentive attacks than the Nakamoto consensus, e.g., attacks have smaller profitability threshold and they result in higher relative rewards. Next, we introduce a voting-based semi-parallel PoW protocol that outperforms both Nakamoto consensus and the existing parallel PoW protocols from most practical perspectives such as communication overheads, throughput, transaction conflicts, incentive compatibility of the protocol as well as a fair distribution of transaction fees among the voters and the leaders. We use state-of-the-art analysis to evaluate the consistency of the protocol and consider Markov decision process (MDP) models to substantiate our claims about the resilience of our protocol against incentive attacks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.06489","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.246989","language":"en","tags":["mathpr","csdm","preprints","csdc","research","cscr","mathit","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Mustafa Doger, Sennur Ulukus","raw_content_length":1169,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["PoW"],"persons":["Nakamoto"],"locations":[],"monetary":[]},"char_count":1168,"language_detected":"en","key_concepts":{"key_phrases":["Voting-Based Semi-Parallel Proof","the existing parallel PoW protocols","arXiv250806489v2 Announce Type","Abstract","Work","the safety guarantees","transaction throughput","confirmation latencies","Nakamoto consensus","this work"],"filter_categories":{"ai_ml":["Work"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Voting-Based Semi-Parallel Proof":2.0,"the existing parallel PoW protocols":2.0,"arXiv250806489v2 Announce Type":1.0,"Abstract":1.0,"Work":1.0,"the safety guarantees":1.0,"transaction throughput":1.0,"confirmation latencies":1.0,"Nakamoto consensus":1.0,"this work":1.0}},"age_hours":2.769064183611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.079,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4158,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6778,"joy":0.0106,"surprise":0.0279,"sadness":0.0198,"fear":0.209,"anger":0.0324,"disgust":0.0226},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new voting-based semi-parallel Proof-of-Work protocol. While it claims improvements in communication overheads, throughput, and transaction conflicts, it is still in the theoretical stage with no deployed units or real-world data. The claims are substantiated by simulations and Markov decision process models, but lack independent verification or deployment data.","key_impact_metrics":["smaller profitability threshold","higher relative rewards"],"technology_tags":["Proof-of-Work","Blockchain","Consensus Protocol"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:07.844581Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_841415eee9b3","title":"FormCoach: Lift Smarter, Not Harder","content":"arXiv:2508.07501v3 Announce Type: replace Abstract: Good form is the difference between strength and strain, yet for the fast-growing community of at-home fitness enthusiasts, expert feedback is often out of reach. FormCoach transforms a simple camera into an always-on, interactive AI training partner, capable of spotting subtle form errors and delivering tailored corrections in real time, leveraging vision-language models (VLMs). We showcase this capability through a web interface and benchmark state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference video pairs spanning 22 strength and mobility exercises. To accelerate research in AI-driven coaching, we release both the dataset and an automated, rubric-based evaluation pipeline, enabling standardized comparison across models. Our benchmarks reveal substantial gaps compared to human-level coaching, underscoring both the challenges and opportunities in integrating nuanced, context-aware movement analysis into interactive AI systems. By framing form correction as a collaborative and creative process between humans and machines, FormCoach opens a new frontier in embodied AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.07501","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.247364","language":"en","tags":["computer-science","preprints","cscv","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Xiaoye Zuo, Nikos Athanasiou, Ginger Delmas, Yiming Huang, Xingyu Fu, Lingjie Liu","raw_content_length":1160,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["FormCoach"],"persons":["Lift Smarter"],"locations":[],"monetary":[]},"char_count":1159,"language_detected":"en","key_concepts":{"key_phrases":["FormCoach","Lift Smarter","Announce Type","Good form","the difference","strength","strain","the fast-growing community","home","expert feedback"],"filter_categories":{"ai_ml":["strain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FormCoach":3.0,"Lift Smarter":2.0,"Announce Type":1.0,"Good form":1.0,"the difference":1.0,"strength":1.0,"strain":1.0,"the fast-growing community":1.0,"home":1.0,"expert feedback":1.0}},"age_hours":2.7690799558333334,"is_recent":true,"quality_score":1.0,"sentiment_score":9.568,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9136,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.922,"joy":0.014,"surprise":0.0463,"sadness":0.006,"fear":0.0046,"anger":0.005,"disgust":0.0021},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a prototype AI coaching system. While it benchmarks VLMs on a dataset of 1,700 video pairs, there are no deployed units or measured outcomes related to energy consumption or reduced travel. The potential climate impact is minimal at this stage.","key_impact_metrics":["1,700 expert-annotated video pairs"],"technology_tags":["AI","Vision-Language Models","Fitness Coaching"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:45:10.955224Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e51fd59721e6","title":"Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo","content":"arXiv:2508.07631v2 Announce Type: replace Abstract: We study the problem of posterior sampling in the context of score based generative models. We have a trained score network for a prior $p(x)$, a measurement model $p(y|x)$, and are tasked with sampling from the posterior $p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case) under well-accepted computational hardness assumptions. Despite this, popular algorithms for tasks such as image super-resolution, stylization, and reconstruction enjoy empirical success. Rather than establishing distributional assumptions or restricted settings under which exact posterior sampling is tractable, we view this as a more general \"tilting\" problem of biasing a distribution towards a measurement. Under minimal assumptions, we show that one can tractably sample from a distribution that is simultaneously close to the posterior of a noised prior in KL divergence and the true posterior in Fisher divergence. Intuitively, this combination ensures that the resulting sample is consistent with both the measurement and the prior. To the best of our knowledge these are the first formal results for (approximate) posterior sampling in polynomial time.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.07631","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.247767","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Advait Parulekar, Litu Rout, Karthikeyan Shanmugam, Sanjay Shakkottai","raw_content_length":1217,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Efficient Approximate Posterior Sampling"],"persons":["Announce Type","Langevin Monte Carlo"],"locations":[],"monetary":[]},"char_count":1216,"language_detected":"en","key_concepts":{"key_phrases":["Efficient Approximate Posterior Sampling","Annealed Langevin Monte Carlo","arXiv250807631v2 Announce Type","Abstract","the problem","posterior sampling","the context","score based generative models","a trained score network","a prior px"],"filter_categories":{"ai_ml":["a trained score network"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Efficient Approximate Posterior Sampling":2.0,"Annealed Langevin Monte Carlo":2.0,"arXiv250807631v2 Announce Type":1.0,"Abstract":1.0,"the problem":1.0,"posterior sampling":1.0,"the context":1.0,"score based generative models":1.0,"a trained score network":1.0,"a prior px":1.0}},"age_hours":2.7690956119444445,"is_recent":true,"quality_score":1.0,"sentiment_score":1.153,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7694,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3328,"joy":0.0043,"surprise":0.007,"sadness":0.0248,"fear":0.0212,"anger":0.1438,"disgust":0.4662},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for approximate posterior sampling, which could potentially improve the efficiency of score-based generative models used in various applications. While the algorithm shows promise, it is currently in the basic research stage with no deployed technology or measured outcomes. The impact on climate change is indirect and speculative at this point.","key_impact_metrics":[],"technology_tags":["score-based generative models","posterior sampling","annealed Langevin Monte Carlo"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:45:14.195152Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_914b7bdb14d8","title":"Learning Satellite Attitude Dynamics with Physics","content":"arXiv:2508.07841v2 Announce Type: replace Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model Predictive Control (MPC) has emerged as a powerful strategy for these tasks, relying on accurate models of the system dynamics to optimize control actions over a prediction horizon. In scenarios where physics models are incomplete, difficult to derive, or computationally expensive, machine learning offers a flexible alternative by learning the system behavior directly from data. However, purely data-driven models often struggle with generalization and stability, especially when applied to inputs outside their training domain. To address these limitations, we investigate the benefits of incorporating Physics-Informed Neural Networks (PINNs) into the learning of spacecraft attitude dynamics, comparing their performance with that of purely data-driven approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network architecture with a self-attention mechanism, we trained several models on simulated data generated with the Basilisk simulator. Two training strategies were considered: a purely data-driven baseline and a physics-informed variant to improve robustness and stability. Our results demonstrate that the inclusion of physics-based information significantly enhances the performance in terms of the mean relative error of the best architectures found by 27.08%. These advantages are particularly evident when the learned models are integrated into an MPC framework, where PINN-based models consistently outperform their purely data-driven counterparts in terms of control accuracy and robustness, yielding improvements of up to 42.86% in performance stability error and increased robustness-to-noise.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.07841","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.248178","language":"en","tags":["cslg","eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":234,"author":"Carlo Cena, Mauro Martini, Marcello Chiaberge","raw_content_length":1761,"priority":7,"update_frequency":1,"reading_time_minutes":1.17,"robust_parsing_used":true,"entities":{"organizations":["Learning Satellite Attitude Dynamics","Physics-Informed Neural Networks","MPC","Non-Volume Preserving","Model Predictive Control"],"persons":[],"locations":[],"monetary":[]},"char_count":1760,"language_detected":"en","key_concepts":{"key_phrases":["Learning Satellite Attitude Dynamics","Physics","arXiv250807841v2","Announce Type","Abstract","Attitude control","a fundamental aspect","spacecraft operations","Model Predictive Control","MPC"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Learning Satellite Attitude Dynamics":2.0,"Physics":2.0,"arXiv250807841v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Attitude control":1.0,"a fundamental aspect":1.0,"spacecraft operations":1.0,"Model Predictive Control":1.0,"MPC":1.0}},"age_hours":2.7691101677777774,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9472,"joy":0.0071,"surprise":0.0108,"sadness":0.0062,"fear":0.0098,"anger":0.0093,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving satellite attitude control using physics-informed neural networks (PINNs). While the research shows a 27.08% improvement in mean relative error and up to 42.86% improvement in performance stability error compared to purely data-driven methods, it is based on simulated data and has not yet been deployed in real-world applications. The economic viability is uncertain as it's an early-stage concept.","key_impact_metrics":["mean relative error improvement of 27.08%","performance stability error improvement of 42.86%"],"technology_tags":["Physics-Informed Neural Networks","Model Predictive Control","Satellite Attitude Control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:17.980148Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4c2b83d1be5a","title":"PCHands: PCA","content":"arXiv:2508.07945v2 Announce Type: replace Abstract: We consider the problem of learning a common representation for dexterous manipulation across manipulators of different morphologies. To this end, we propose PCHands, a novel approach for extracting hand postural synergies from a large set of manipulators. We define a simplified and unified description format based on anchor positions for manipulators ranging from 2-finger grippers to 5-finger anthropomorphic hands. This enables learning a variable-length latent representation of the manipulator configuration and the alignment of the end-effector frame of all manipulators. We show that it is possible to extract principal components from this latent representation that is universal across manipulators of different structures and degrees of freedom. To evaluate PCHands, we use this compact representation to encode observation and action spaces of control policies for dexterous manipulation tasks learned with RL. In terms of learning efficiency and consistency, the proposed representation outperforms a baseline that learns the same tasks in joint space. We additionally show that PCHands performs robustly in RL from demonstration, when demonstrations are provided from a different manipulator. We further support our results with real-world experiments that involve a 2-finger gripper and a 4-finger anthropomorphic hand. Code and additional material are available at https://hsp-iit.github.io/PCHands/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.07945","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.248587","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"En Yen Puang, Federico Ceola, Giulia Pasquale, Lorenzo Natale","raw_content_length":1470,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["PCHands"],"persons":[],"locations":[],"monetary":[]},"char_count":1469,"language_detected":"en","key_concepts":{"key_phrases":["PCHands","manipulators","PCA","arXiv250807945v2 Announce Type","Abstract","the problem","a common representation","dexterous manipulation","different morphologies","this end"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PCHands":3.0,"manipulators":3.0,"PCA":2.0,"arXiv250807945v2 Announce Type":1.0,"Abstract":1.0,"the problem":1.0,"a common representation":1.0,"dexterous manipulation":1.0,"different morphologies":1.0,"this end":1.0}},"age_hours":2.769125100833333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8989,"joy":0.0521,"surprise":0.0259,"sadness":0.0025,"fear":0.0041,"anger":0.0115,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a novel approach (PCHands) for robotic manipulation, demonstrating improved learning efficiency and consistency compared to baseline methods. Real-world experiments with a 2-finger gripper and a 4-finger anthropomorphic hand provide some evidence of deployment readiness, but the impact on climate or other sustainability dimensions is indirect and currently theoretical. The compact representation encodes observation and action spaces of control policies for dexterous manipulation tasks learned with RL.","key_impact_metrics":["Learning efficiency improvement","Consistency improvement"],"technology_tags":["Robotics","Reinforcement Learning","Dexterous Manipulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:21.546663Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c440ad14e2b7","title":"SaraCoder: Orchestrating Semantic and Structural Cues for Resource","content":"arXiv:2508.10068v2 Announce Type: replace Abstract: Despite Retrieval-Augmented Generation improving code completion, traditional retrieval methods struggle with information redundancy and a lack of diversity within limited context windows. To solve this, we propose a resource-optimized retrieval augmentation method, SaraCoder. It maximizes information diversity and representativeness in a limited context window, significantly boosting the accuracy and reliability of repository-level code completion. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that SaraCoder outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and resource-optimized repository-level code completion systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10068","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.250094","language":"en","tags":["cspl","preprints","research","csse","cscl","csir","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Xiaohan Chen, Zhongying Pan, Quan Feng, Yu Tian, Shuqun Yang, Mengru Wang, Lina Gong, Yuxia Geng, Piji Li, Xiang Chen","raw_content_length":1375,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["Hierarchical Feature Optimization","External-Aware Identifier Disambiguator","SaraCoder"],"persons":[],"locations":[],"monetary":[]},"char_count":1374,"language_detected":"en","key_concepts":{"key_phrases":["SaraCoder","Semantic and Structural Cues","Resource","Announce Type","Abstract","Retrieval-Augmented Generation","code completion","traditional retrieval methods","information redundancy","a lack"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SaraCoder":3.0,"Semantic and Structural Cues":2.0,"Resource":2.0,"Announce Type":1.0,"Abstract":1.0,"Retrieval-Augmented Generation":1.0,"code completion":1.0,"traditional retrieval methods":1.0,"information redundancy":1.0,"a lack":1.0}},"age_hours":2.7691848019444443,"is_recent":true,"quality_score":1.0,"sentiment_score":1.6310000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6738,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8322,"joy":0.0158,"surprise":0.011,"sadness":0.0081,"fear":0.0674,"anger":0.0417,"disgust":0.0238},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"SaraCoder is a resource-optimized retrieval augmentation method for code completion that shows promise in improving accuracy and efficiency. The article mentions extensive experiments on benchmarks, indicating some level of validation. However, it is still in the research phase with no deployed units or operational data, limiting its immediate sustainability impact.","key_impact_metrics":["Accuracy improvement on CrossCodeEval","Accuracy improvement on RepoEval-Updated"],"technology_tags":["Code completion","Retrieval-Augmented Generation","Resource Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:45:24.562992Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_56b31d786275","title":"Jailbreaking Commercial Black","content":"arXiv:2508.10390v2 Announce Type: replace Abstract: Jailbreaking commercial black-box models is one of the most challenging and serious security threats today. Existing attacks achieve certain success on non-reasoning models but perform limitedly on the latest reasoning models. We discover that carefully crafted developer messages can markedly boost jailbreak effectiveness. Building on this, we propose two developer-role-based attacks: D-Attack, which enhances contextual simulation, and DH-CoT, which strengthens attacks with deceptive chain-of-thought. In experiments, we further diccover that current red-teaming datasets often contain samples unsuited for measuring attack gains: prompts that fail to trigger defenses, prompts where malicious content is not the sole valid output, and benign prompts. Such data hinders accurate measurement of the true improvement brought by an attack method. To address this, we introduce MDH, a Malicious content Detection approach combining LLM-based screening with Human verification to balance accuracy and cost, with which we clean data and build the RTA dataset series. Experiments demonstrate that MDH reliably filters low-quality samples and that developer messages significantly improve jailbreak attack success. Codes, datasets, and other results will be released in https://github.com/AlienZhang1996/DH-CoT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10390","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.251273","language":"en","tags":["computer-science","preprints","cscl","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Chiyu Zhang, Lu Zhou, Xiaogang Xu, Jiafei Wu, Liming Fang, Zhe Liu","raw_content_length":1361,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["MDH"],"persons":[],"locations":[],"monetary":[]},"char_count":1360,"language_detected":"en","key_concepts":{"key_phrases":["Jailbreaking Commercial Black","arXiv250810390v2 Announce Type","Abstract","Jailbreaking commercial black-box models","Existing attacks","certain success","non-reasoning models","the latest reasoning models","carefully crafted developer messages","jailbreak effectiveness"],"filter_categories":{"ai_ml":["Jailbreaking Commercial Black"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Jailbreaking Commercial Black":2.0,"arXiv250810390v2 Announce Type":1.0,"Abstract":1.0,"Jailbreaking commercial black-box models":1.0,"Existing attacks":1.0,"certain success":1.0,"non-reasoning models":1.0,"the latest reasoning models":1.0,"carefully crafted developer messages":1.0,"jailbreak effectiveness":1.0}},"age_hours":2.7692303208333335,"is_recent":true,"quality_score":1.0,"sentiment_score":6.6615,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3323,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7376,"joy":0.0104,"surprise":0.0216,"sadness":0.0135,"fear":0.1725,"anger":0.0385,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on jailbreaking AI models, which has an indirect and speculative link to sustainability. The concrete action is the development of new attack methods and a dataset for evaluating them. The evidence is based on experiments, and the stage is basic research.","key_impact_metrics":["Improvement in jailbreak attack success","Reliability of MDH filter"],"technology_tags":["AI security","LLM","Red-teaming"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:45:28.743672Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f3935b82f9da","title":"Holistic Evaluation of Multimodal LLMs on Spatial Intelligence","content":"arXiv:2508.13142v2 Announce Type: replace Abstract: Multimodal models have achieved remarkable progress in recent years. Nevertheless, they continue to exhibit notable limitations in spatial understanding and reasoning, the very capability that anchors artificial general intelligence in the physical world. With the recent release of GPT-5, allegedly the most powerful AI model to date, it is timely to examine where the leading models (GPT, Gemini, Grok, Seed, Qwen, and Intern) stand on the path toward spatial intelligence. We first propose a holistic taxonomy of spatial tasks that unifies existing benchmarks and a standardized protocol for the fair evaluation of state-of-the-art proprietary and open-source models across eight key benchmarks, at a cost exceeding ten billion total tokens. Our empirical study then reveals that (1) GPT-5 demonstrates unprecedented strength in spatial intelligence (SI), yet (2) still falls short of human performance significantly across a broad spectrum of SI-tasks. Moreover, we (3) show that SI-tasks expose greater model capability deficiency than non-SI tasks, to the extent that (4) proprietary models do not exhibit a decisive advantage when facing the most difficult ones. In addition, we conduct a qualitative evaluation across a diverse set of scenarios that are intuitive for humans, yet fail even the most advanced multimodal models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.13142","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.252454","language":"en","tags":["cslg","preprints","cscv","research","cscl","csmm","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang, Chen Wei, Xuanke Shi, Kewang Deng, Xiaoyang Han, Zukai Chen, Jiaqi Li, Xiangyu Fan, Hanming Deng, Lewei Lu, Bo Li, Ziwei Liu, Quan Wang, Dahua Lin, Lei Yang","raw_content_length":1387,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Intern","Holistic Evaluation of Multimodal","Spatial Intelligence arXiv:2508.13142v2 Announce Type","GPT"],"persons":["Qwen","Grok"],"locations":["Gemini"],"monetary":[]},"char_count":1386,"language_detected":"en","key_concepts":{"key_phrases":["Holistic Evaluation","Multimodal LLMs","Spatial Intelligence","arXiv250813142v2","Announce Type","Multimodal models","remarkable progress","recent years","notable limitations","spatial understanding"],"filter_categories":{"ai_ml":["Multimodal LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Holistic Evaluation":2.0,"Multimodal LLMs":2.0,"Spatial Intelligence":2.0,"arXiv250813142v2":1.0,"Announce Type":1.0,"Multimodal models":1.0,"remarkable progress":1.0,"recent years":1.0,"notable limitations":1.0,"spatial understanding":1.0}},"age_hours":2.7692740019444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.701,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8142,"joy":0.054,"surprise":0.0902,"sadness":0.0068,"fear":0.0132,"anger":0.0156,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a holistic evaluation of multimodal LLMs on spatial intelligence. While the research itself doesn't directly impact climate change, it contributes to the development of AI models, which could indirectly influence sustainability efforts in the future. The study uses a standardized protocol and benchmarks, providing some evidence for its claims, but it is still in the research phase.","key_impact_metrics":["Cost exceeding ten billion total tokens","Performance across eight key benchmarks"],"technology_tags":["Multimodal LLMs","Spatial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:31.978313Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e443a841a3e","title":"HebID: Detecting Social Identities in Hebrew","content":"arXiv:2508.15483v2 Announce Type: replace Abstract: Political language is deeply intertwined with social identities. While social identities are often shaped by specific cultural contexts and expressed through particular uses of language, existing datasets for group and identity detection are predominantly English-centric, single-label and focus on coarse identity categories. We introduce HebID, the first multilabel Hebrew corpus for social identity detection: 5,536 sentences from Israeli politicians' Facebook posts (Dec 2018-Apr 2021), manually annotated for twelve nuanced social identities (e.g. Rightist, Ultra-Orthodox, Socially-oriented) grounded by survey data. We benchmark multilabel and single-label encoders alongside 2B-9B-parameter generative LLMs, finding that Hebrew-tuned LLMs provide the best results (macro-$F_1$ = 0.74). We apply our classifier to politicians' Facebook posts and parliamentary speeches, evaluating differences in popularity, temporal trends, clustering patterns, and gender-related variations in identity expression. We utilize identity choices from a national public survey, enabling a comparison between identities portrayed in elite discourse and the public's identity priorities. HebID provides a comprehensive foundation for studying social identities in Hebrew and can serve as a model for similar research in other non-English political contexts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.15483","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.253682","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Guy Mor-Lan, Naama Rivlin-Angert, Yael R. Kaplan, Tamir Sheafer, Shaul R. Shenhav","raw_content_length":1396,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Socially"],"locations":[],"monetary":[]},"char_count":1395,"language_detected":"en","key_concepts":{"key_phrases":["HebID","Social Identities","Hebrew","social identities","arXiv250815483v2","Announce Type","Abstract","Political language","specific cultural contexts","particular uses"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"HebID":3.0,"Social Identities":2.0,"Hebrew":2.0,"social identities":2.0,"arXiv250815483v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Political language":1.0,"specific cultural contexts":1.0,"particular uses":1.0}},"age_hours":2.769319368611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9173,"joy":0.0129,"surprise":0.0265,"sadness":0.0031,"fear":0.0198,"anger":0.0124,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new dataset and methodology for detecting social identities in Hebrew text. While valuable for social science research, it has no direct or measurable impact on climate change or other sustainability dimensions. The deployment readiness is low as it's primarily a research project.","key_impact_metrics":["macro-$F_1$ = 0.74"],"technology_tags":["Natural Language Processing","Social Identity Detection"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:45:34.807998Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c9511550e4af","title":"The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech","content":"arXiv:2508.15524v2 Announce Type: replace Abstract: We present the first large-scale computational study of political delegitimization discourse (PDD), defined as symbolic attacks on the normative validity of political entities. We curate and manually annotate a novel Hebrew-language corpus of 10,410 sentences drawn from Knesset speeches (1993-2023), Facebook posts (2018-2021), and leading news outlets, of which 1,812 instances (17.4\\%) exhibit PDD and 642 carry additional annotations for intensity, incivility, target type, and affective framing. We introduce a two-stage classification pipeline combining finetuned encoder models and decoder LLMs. Our best model (DictaLM 2.0) attains an F$_1$ of 0.74 for binary PDD detection and a macro-F$_1$ of 0.67 for classification of delegitimization characteristics. Applying this classifier to longitudinal and cross-platform data, we see a marked rise in PDD over three decades, higher prevalence on social media versus parliamentary debate, greater use by male than female politicians, and stronger tendencies among right-leaning actors - with pronounced spikes during election campaigns and major political events. Our findings demonstrate the feasibility and value of automated PDD analysis for understanding democratic discourse.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.15524","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.254071","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Naama Rivlin-Angert, Guy Mor-Lan","raw_content_length":1285,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["PDD","Knesset"],"persons":[],"locations":[],"monetary":["$ of 0.67","an F$_1$ of 0.74"]},"char_count":1284,"language_detected":"en","key_concepts":{"key_phrases":["The Enemy","A Study","Political Delegitimization Discourse","Israeli Political Speech","PDD","arXiv250815524v2","Announce Type","Abstract","the first large-scale computational study","political delegitimization discourse"],"filter_categories":{"research_academic":["A Study","the first large-scale computational study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Enemy":2.0,"A Study":2.0,"Political Delegitimization Discourse":2.0,"Israeli Political Speech":2.0,"PDD":2.0,"arXiv250815524v2":1.0,"Announce Type":1.0,"Abstract":1.0,"the first large-scale computational study":1.0,"political delegitimization discourse":1.0}},"age_hours":2.76933599,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7707,"joy":0.0518,"surprise":0.0488,"sadness":0.0054,"fear":0.0427,"anger":0.0531,"disgust":0.0275},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on analyzing political discourse, specifically delegitimization, using a computational approach. While it provides insights into societal dynamics, it does not directly address climate change or environmental sustainability. The study uses a novel Hebrew-language corpus and achieves an F1 score of 0.74 for PDD detection.","key_impact_metrics":["F1 score of 0.74","10,410 sentences"],"technology_tags":["Natural Language Processing","Political Discourse Analysis"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:45:37.873648Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf149b6260cb","title":"MCPVerse: An Expansive, Real","content":"arXiv:2508.16260v2 Announce Type: replace Abstract: Large Language Models (LLMs) are evolving from text generators into reasoning agents. This transition makes their ability to use external tools a critical capability. However, evaluating this skill presents a significant challenge. Existing benchmarks are often limited by their reliance on synthetic tools and severely constrained action spaces. To address these limitations, we introduce MCPVerse, an expansive, real-world benchmark for evaluating agentic tool use. MCPVerse integrates more than 550 real-world, executable tools to create an unprecedented action space exceeding 140k tokens, and employs outcome-based evaluation with real-time ground truth for time-sensitive tasks. We benchmarked the state-of-the-art LLMs across three modes (Oracle, Standard, and Max-Scale), revealing that while most models suffer performance degradation when confronted with larger tool sets, the agentic models, such as Claude-4-Sonnet, can effectively leverage expanded exploration spaces to improve accuracy. This finding not only exposes the limitations of state-of-the-art models in complex, real-world scenarios but also establishes MCPVerse as a critical benchmark for measuring and advancing agentic tool use capabilities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16260","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.254581","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Fei Lei, Yibo Yang, Wenxiu Sun, Dahua Lin","raw_content_length":1273,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["MCPVerse"],"persons":["Max-Scale","Standard"],"locations":[],"monetary":[]},"char_count":1272,"language_detected":"en","key_concepts":{"key_phrases":["MCPVerse","An Expansive","arXiv250816260v2 Announce Type","Abstract","Large Language Models","LLMs","text generators","reasoning agents","This transition","their ability"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MCPVerse":3.0,"An Expansive":2.0,"arXiv250816260v2 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"text generators":1.0,"reasoning agents":1.0,"This transition":1.0,"their ability":1.0}},"age_hours":2.769350992777778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5305,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4939,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9255,"joy":0.0093,"surprise":0.0309,"sadness":0.0042,"fear":0.0115,"anger":0.0122,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a benchmark (MCPVerse) for evaluating AI agentic tool use. While the benchmark itself doesn't directly reduce emissions, it could indirectly contribute by improving the efficiency of AI systems used in sustainability applications. The technical credibility is high due to the use of real-world tools and outcome-based evaluation, but deployment readiness is low as it's primarily a research tool.","key_impact_metrics":["Action space exceeding 140k tokens","550+ real-world executable tools"],"technology_tags":["Large Language Models","AI Agent","Tool Use"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:41.511811Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_034d7b19529d","title":"Autonomous UAV Flight Navigation in Confined Spaces: A Reinforcement Learning Approach","content":"arXiv:2508.16807v2 Announce Type: replace Abstract: Autonomous UAV inspection of confined industrial infrastructure, such as ventilation ducts, demands robust navigation policies where collisions are unacceptable. While Deep Reinforcement Learning (DRL) offers a powerful paradigm for developing such policies, it presents a critical trade-off between on-policy and off-policy algorithms. Off-policy methods promise high sample efficiency, a vital trait for minimizing costly and unsafe real-world fine-tuning. In contrast, on-policy methods often exhibit greater training stability, which is essential for reliable convergence in hazard-dense environments. This paper directly investigates this trade-off by comparing a leading on-policy algorithm, Proximal Policy Optimization (PPO), against an off-policy counterpart, Soft Actor-Critic (SAC), for precision flight in procedurally generated ducts within a high-fidelity simulator. Our results show that PPO consistently learned a stable, collision-free policy that completed the entire course. In contrast, SAC failed to find a complete solution, converging to a suboptimal policy that navigated only the initial segments before failure. This work provides evidence that for high-precision, safety-critical navigation tasks, the reliable convergence of a well-established on-policy method can be more decisive than the nominal sample efficiency of an off-policy algorithm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16807","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.254983","language":"en","tags":["cslg","eesssy","csai","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Marco S. Tayar, Lucas K. de Oliveira, Felipe Andrade G. Tommaselli, Juliano D. Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker","raw_content_length":1425,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Deep Reinforcement Learning","Soft Actor-Critic","PPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1424,"language_detected":"en","key_concepts":{"key_phrases":["Autonomous UAV Flight Navigation","Confined Spaces","A Reinforcement Learning Approach","arXiv250816807v2 Announce Type","Abstract","Autonomous UAV inspection","confined industrial infrastructure","ventilation ducts","robust navigation policies","collisions"],"filter_categories":{"ai_ml":["A Reinforcement Learning Approach"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Autonomous UAV Flight Navigation":2.0,"Confined Spaces":2.0,"A Reinforcement Learning Approach":2.0,"arXiv250816807v2 Announce Type":1.0,"Abstract":1.0,"Autonomous UAV inspection":1.0,"confined industrial infrastructure":1.0,"ventilation ducts":1.0,"robust navigation policies":1.0,"collisions":1.0}},"age_hours":2.7693662263888887,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8115,"joy":0.0065,"surprise":0.0098,"sadness":0.0098,"fear":0.0717,"anger":0.0337,"disgust":0.057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on autonomous UAV navigation using reinforcement learning. The concrete action is the comparison of two algorithms (PPO and SAC) in a high-fidelity simulator. Evidence is provided by the simulation results showing PPO's superior performance. It is currently in the applied research stage, demonstrated in a simulator but not yet deployed in real-world applications.","key_impact_metrics":["collision-free policy completion","navigation of initial segments before failure"],"technology_tags":["autonomous UAV","reinforcement learning","confined space navigation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:47.754343Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4ebd9ac2425b","title":"Lightweight Joint Optimization of General-Purpose Vision","content":"arXiv:2508.17394v3 Announce Type: replace Abstract: Retrieving relevant visual and textual information from medical literature and hospital records can enhance diagnostic accuracy for clinical image interpretation. We develop a multimodal retrieval model jointly optimized with an LVLM for medical diagnosis, unlike standard RAG which doesn't backpropagate LVLM errors to the retriever. Using only general-purpose backbones with lightweight fine-tuning, our model achieves competitive results with medically-pretrained models on clinical classification and VQA tasks. In a novel analysis, we find that different top-retrieved images often yield different predictions for the same target, and that these cases are challenging for all models, even for non-retrieval models. Our joint retrieval optimization significantly improves these cases over standard RAG. However, oracle analysis reveals that while the correct diagnosis is frequently achievable using one of the top retrieved images, in practice there is a large performance gap from the oracle, and rerankers using frontier LVLMs do not close this gap -- leaving ample room for improvement by future methods. Code available at https://github.com/Nirmaz/JOMED.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17394","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.255363","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Nir Mazor, Tom Hope","raw_content_length":1216,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["VQA","Lightweight Joint Optimization of General-Purpose"],"persons":["RAG","Announce Type"],"locations":[],"monetary":[]},"char_count":1215,"language_detected":"en","key_concepts":{"key_phrases":["Lightweight Joint Optimization","General-Purpose Vision","arXiv250817394v3 Announce Type","Abstract","relevant visual and textual information","medical literature","hospital records","diagnostic accuracy","clinical image interpretation","a multimodal retrieval model"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lightweight Joint Optimization":2.0,"General-Purpose Vision":2.0,"arXiv250817394v3 Announce Type":1.0,"Abstract":1.0,"relevant visual and textual information":1.0,"medical literature":1.0,"hospital records":1.0,"diagnostic accuracy":1.0,"clinical image interpretation":1.0,"a multimodal retrieval model":1.0}},"age_hours":2.7693806241666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.121,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8242,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8716,"joy":0.0093,"surprise":0.0213,"sadness":0.006,"fear":0.0471,"anger":0.0289,"disgust":0.0159},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving medical diagnosis using AI, specifically by optimizing retrieval models. While it aims to improve accuracy, there's no direct connection to reducing GHG emissions or other environmental benefits. The research is in the applied research stage, with code available but no deployed units or operational data related to sustainability.","key_impact_metrics":["Competitive results on clinical classification","Improved cases over standard RAG"],"technology_tags":["AI","Machine Learning","Medical Imaging","Retrieval Model"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:45:53.679498Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce44177e3625","title":"Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco","content":"arXiv:2508.17466v2 Announce Type: replace Abstract: This paper presents a deep learning framework designed to enhance the grasping capabilities of quadrupeds equipped with arms, with a focus on improving precision and adaptability. Our approach centers on a sim-to-real methodology that minimizes reliance on physical data collection. We developed a pipeline within the Genesis simulation environment to generate a synthetic dataset of grasp attempts on common objects. By simulating thousands of interactions from various perspectives, we created pixel-wise annotated grasp-quality maps to serve as the ground truth for our model. This dataset was used to train a custom CNN with a U-Net-like architecture that processes multi-modal input from an onboard RGB and depth cameras, including RGB images, depth maps, segmentation masks, and surface normal maps. The trained model outputs a grasp-quality heatmap to identify the optimal grasp point. We validated the complete framework on a four-legged robot. The system successfully executed a full loco-manipulation task: autonomously navigating to a target object, perceiving it with its sensors, predicting the optimal grasp pose using our model, and performing a precise grasp. This work proves that leveraging simulated training with advanced sensing offers a scalable and effective solution for object handling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17466","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.255783","language":"en","tags":["cslg","eesssy","csai","cssy","preprints","cscv","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Dilermando Almeida, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker","raw_content_length":1364,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["Loco arXiv:2508.17466v2 Announce Type: replace Abstract","CNN","U-Net","RGB","Genesis"],"persons":[],"locations":[],"monetary":[]},"char_count":1363,"language_detected":"en","key_concepts":{"key_phrases":["Grasping","Legged Robots","A Deep Learning Approach","Loco","arXiv250817466v2 Announce Type","Abstract","This paper","a deep learning framework","the grasping capabilities","quadrupeds"],"filter_categories":{"ai_ml":["A Deep Learning Approach","a deep learning framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Grasping":2.0,"Legged Robots":2.0,"A Deep Learning Approach":2.0,"Loco":2.0,"arXiv250817466v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"a deep learning framework":1.0,"the grasping capabilities":1.0,"quadrupeds":1.0}},"age_hours":2.769395667222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8914,"joy":0.0282,"surprise":0.0433,"sadness":0.0043,"fear":0.0127,"anger":0.0115,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed robotic system capable of autonomous navigation and object manipulation. The system uses a deep learning model trained on simulated data and validated on a physical robot, demonstrating a degree of technical credibility. However, the climate impact is indirect and theoretical, as the application of this technology to sustainability challenges is not explicitly addressed.","key_impact_metrics":["grasp-quality heatmap","success rate of autonomous navigation and grasping"],"technology_tags":["robotics","deep learning","computer vision","loco-manipulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:45:58.929470Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_24e8857f8757","title":"Bridging Graph and State","content":"arXiv:2508.17554v2 Announce Type: replace Abstract: Predicting a patient's length of stay (LOS) in the intensive care unit (ICU) is a critical task for hospital resource management, yet remains challenging due to the heterogeneous and irregularly sampled nature of electronic health records (EHRs). In this work, we propose S$^2$G-Net, a novel neural architecture that unifies state-space sequence modeling with multi-view Graph Neural Networks (GNNs) for ICU LOS prediction. The temporal path employs Mamba state-space models (SSMs) to capture patient trajectories, while the graph path leverages an optimized GraphGPS backbone, designed to integrate heterogeneous patient similarity graphs derived from diagnostic, administrative, and semantic features. Experiments on the large-scale MIMIC-IV cohort dataset show that S$^2$G-Net consistently outperforms sequence models (BiLSTM, Mamba, Transformer), graph models (classic GNNs, GraphGPS), and hybrid approaches across all primary metrics. Extensive ablation studies and interpretability analyses highlight the complementary contributions of each component of our architecture and underscore the importance of principled graph construction. These results demonstrate that S$^2$G-Net provides an effective and scalable solution for ICU LOS prediction with multi-modal clinical data. The code can be found at https://github.com/ShuqiZi1/S2G-Net.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17554","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.256568","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Shuqi Zi, Haitz S\\'aez de Oc\\'ariz Borde, Emma Rocheteau, Pietro Lio'","raw_content_length":1396,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Mamba, Transformer","MIMIC-IV","ICU","Graph Neural Networks","Mamba"],"persons":["GraphGPS","Bridging Graph"],"locations":[],"monetary":[]},"char_count":1395,"language_detected":"en","key_concepts":{"key_phrases":["Graph","State","Announce Type","Abstract","a patients length","stay","LOS","the intensive care unit","ICU","a critical task"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Graph":2.0,"State":2.0,"Announce Type":1.0,"Abstract":1.0,"a patients length":1.0,"stay":1.0,"LOS":1.0,"the intensive care unit":1.0,"ICU":1.0,"a critical task":1.0}},"age_hours":2.7694259719444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8973,"joy":0.0082,"surprise":0.044,"sadness":0.0058,"fear":0.0214,"anger":0.0167,"disgust":0.0066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural architecture (S$^2$G-Net) for predicting ICU length of stay, demonstrating improved performance on the MIMIC-IV dataset compared to existing models. While this could indirectly improve resource allocation and potentially reduce energy consumption in hospitals, the direct climate impact is minimal and unquantified. The research is in the applied research stage, with no mention of deployment or economic viability.","key_impact_metrics":["Improved prediction accuracy on MIMIC-IV dataset","Outperforms BiLSTM, Mamba, Transformer, GraphGPS"],"technology_tags":["Neural Networks","Graph Neural Networks","State-Space Models","Machine Learning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:46:05.323115Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_56be4ea28e94","title":"Effect of Performance Feedback Timing on Motor Learning for a Surgical Training Task","content":"arXiv:2508.17830v2 Announce Type: replace Abstract: Objective: Robot-assisted minimally invasive surgery (RMIS) has become the gold standard for a variety of surgical procedures, but the optimal method of training surgeons for RMIS is unknown. We hypothesized that real-time, rather than post-task, error feedback would better increase learning speed and reduce errors. Methods: Forty-two surgical novices learned a virtual version of the ring-on-wire task, a canonical task in RMIS training. We investigated the impact of feedback timing with multi-sensory (haptic and visual) cues in three groups: (1) real-time error feedback, (2) trial replay with error feedback, and (3) no error feedback. Results: Participant performance was evaluated based on the accuracy of ring position and orientation during the task. Participants who received real-time feedback outperformed other groups in ring orientation. Additionally, participants who received feedback in replay outperformed participants who did not receive any error feedback on ring orientation during long, straight path sections. There were no significant differences between groups for ring position overall, but participants who received real-time feedback outperformed the other groups in positional accuracy on tightly curved path sections. Conclusion: The addition of real-time haptic and visual error feedback improves learning outcomes in a virtual surgical task over error feedback in replay or no error feedback at all. Significance: This work demonstrates that multi-sensory error feedback delivered in real time leads to better training outcomes as compared to the same feedback delivered after task completion. This novel method of training may enable surgical trainees to develop skills with greater speed and accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.17830","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.256984","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Mary Kate Gale, Kailana Baker-Matsuoka, Ilana Nisky, Allison Okamura","raw_content_length":1790,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["RMIS"],"persons":[],"locations":[],"monetary":[]},"char_count":1789,"language_detected":"en","key_concepts":{"key_phrases":["Effect","Performance Feedback Timing","Motor Learning","a Surgical Training Task","RMIS","arXiv250817830v2 Announce Type","Abstract","Objective","Robot-assisted minimally invasive surgery","the gold standard"],"filter_categories":{"ai_ml":["a Surgical Training Task"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Effect":2.0,"Performance Feedback Timing":2.0,"Motor Learning":2.0,"a Surgical Training Task":2.0,"RMIS":2.0,"arXiv250817830v2 Announce Type":1.0,"Abstract":1.0,"Objective":1.0,"Robot-assisted minimally invasive surgery":1.0,"the gold standard":1.0}},"age_hours":2.7694426188888888,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9206,"joy":0.0099,"surprise":0.0429,"sadness":0.0051,"fear":0.0068,"anger":0.0075,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes research on surgical training using virtual reality. While improved surgical training could indirectly reduce waste and improve healthcare outcomes, the direct climate impact is minimal. The study is peer-reviewed and provides specific metrics on ring position and orientation accuracy, increasing its technical credibility.","key_impact_metrics":["Accuracy of ring position","Accuracy of ring orientation"],"technology_tags":["Virtual Reality","Surgical Training","Robotics"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:46:08.369607Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a129227b1472","title":"FSA: An Alternative Efficient Implementation of Native Sparse Attention Kernel","content":"arXiv:2508.18224v2 Announce Type: replace Abstract: Recent advance in sparse attention mechanisms has demonstrated strong potential for reducing the computational cost of long-context training and inference in large language models (LLMs). Native Sparse Attention (NSA), one state-of-the-art approach, introduces natively trainable, hardware-aligned sparse attention that delivers substantial system-level performance boost while maintaining accuracy comparable to full attention. However, the kernel implementation of NSA forces a loop order that is only efficient with a relatively large number of query heads in each Grouped Query Attention (GQA) group, whereas existing LLMs widely adopt much smaller number of query heads in each GQA group -- such an inconsistency significantly limits the applicability of this sparse algorithmic advance. In this work, we propose Flash Sparse Attention (FSA), an alternative kernel implementation that enables efficient NSA computation across a wide range of popular LLMs with varied smaller number of heads in each GQA group on modern GPUs. Compared to vanilla NSA kernel implementation, our empirical evaluation demonstrates that FSA achieves (i) up to 3.5x and on average 1.6x kernel-level latency reduction, (ii) up to 1.25x and 1.09x on average end-to-end training speedup on state-of-the-art LLMs, and (iii) up to 1.36x and 1.11x on average for prefill-phase speedup in LLM generative inference. Github Repo at https://github.com/Relaxed-System-Lab/Flash-Sparse-Attention.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18224","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.257773","language":"en","tags":["computer-science","cslg","preprints","csdc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Ran Yan, Youhe Jiang, Zhuoming Chen, Haohui Mai, Beidi Chen, Binhang Yuan","raw_content_length":1519,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["NSA","FSA","Native Sparse Attention"],"persons":[],"locations":[],"monetary":[]},"char_count":1518,"language_detected":"en","key_concepts":{"key_phrases":["FSA","An Alternative Efficient Implementation","Native Sparse Attention Kernel","arXiv250818224v2 Announce Type","Abstract","Recent advance","sparse attention mechanisms","strong potential","the computational cost","long-context training"],"filter_categories":{"ai_ml":["long-context training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FSA":2.0,"An Alternative Efficient Implementation":2.0,"Native Sparse Attention Kernel":2.0,"arXiv250818224v2 Announce Type":1.0,"Abstract":1.0,"Recent advance":1.0,"sparse attention mechanisms":1.0,"strong potential":1.0,"the computational cost":1.0,"long-context training":1.0}},"age_hours":2.7694711502777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8625,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8721,"joy":0.0412,"surprise":0.0464,"sadness":0.0052,"fear":0.0124,"anger":0.0168,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a novel kernel implementation (FSA) for sparse attention in LLMs, demonstrating performance improvements over existing methods. The concrete actions are the kernel-level latency reduction (up to 3.5x), end-to-end training speedup (up to 1.25x), and prefill-phase speedup (up to 1.36x). While not directly related to climate impact, improved efficiency in LLM training and inference can indirectly reduce energy consumption of compute resources.","key_impact_metrics":["kernel-level latency reduction 3.5x","end-to-end training speedup 1.25x"],"technology_tags":["sparse attention","large language models","GPU optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:46:11.926898Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f76396396131","title":"Tailored Teaching with Balanced Difficulty: Elevating Reasoning in Multimodal Chain","content":"arXiv:2508.18673v2 Announce Type: replace Abstract: The effectiveness of Multimodal Chain-of-Thought (MCoT) prompting is often limited by the use of randomly or manually selected examples. These examples fail to account for both model-specific knowledge distributions and the intrinsic complexity of the tasks, resulting in suboptimal and unstable model performance. To address this, we propose a novel framework inspired by the pedagogical principle of \"tailored teaching with balanced difficulty\". We reframe prompt selection as a prompt curriculum design problem: constructing a well ordered set of training examples that align with the model's current capabilities. Our approach integrates two complementary signals: (1) model-perceived difficulty, quantified through prediction disagreement in an active learning setup, capturing what the model itself finds challenging; and (2) intrinsic sample complexity, which measures the inherent difficulty of each question-image pair independently of any model. By jointly analyzing these signals, we develop a difficulty-balanced sampling strategy that ensures the selected prompt examples are diverse across both dimensions. Extensive experiments conducted on five challenging benchmarks and multiple popular Multimodal Large Language Models (MLLMs) demonstrate that our method yields substantial and consistent improvements and greatly reduces performance discrepancies caused by random sampling, providing a principled and robust approach for enhancing multimodal reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18673","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.258175","language":"en","tags":["computer-science","csai","preprints","cscl","csmm","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Xinglong Yang, Quan Feng, Zhongying Pan, Xiang Chen, Yu Tian, Wentong Li, Shuofei Qiao, Yuxia Geng, Xingyu Zhao, Sheng-Jun Huang","raw_content_length":1525,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Chain-of-Thought"],"persons":[],"locations":[],"monetary":[]},"char_count":1524,"language_detected":"en","key_concepts":{"key_phrases":["Tailored Teaching","Balanced Difficulty","Elevating Reasoning","Multimodal Chain","arXiv250818673v2","Announce Type","Abstract","The effectiveness","Thought","MCoT"],"filter_categories":{"ai_ml":["Tailored Teaching"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tailored Teaching":2.0,"Balanced Difficulty":2.0,"Elevating Reasoning":2.0,"Multimodal Chain":2.0,"arXiv250818673v2":1.0,"Announce Type":1.0,"Abstract":1.0,"The effectiveness":1.0,"Thought":1.0,"MCoT":1.0}},"age_hours":2.7694859925000004,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8777,"joy":0.0051,"surprise":0.031,"sadness":0.01,"fear":0.0293,"anger":0.0359,"disgust":0.011},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for improving the performance of Multimodal Large Language Models (MLLMs) by optimizing prompt selection. The concrete action is the development of a difficulty-balanced sampling strategy. Evidence is provided through extensive experiments on five benchmarks, but it is still in the research phase with no real-world deployment.","key_impact_metrics":["substantial and consistent improvements","greatly reduces performance discrepancies"],"technology_tags":["Multimodal Chain-of-Thought prompting","active learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:46:18.766489Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e43676164a61","title":"Chronological Passage Assembling in RAG framework for Temporal Question Answering","content":"arXiv:2508.18748v2 Announce Type: replace Abstract: Long-context question answering over narrative tasks is challenging because correct answers often hinge on reconstructing a coherent timeline of events while preserving contextual f low in a limited context window. Retrievalaugmented generation (RAG) methods aim to address this challenge by selectively retrieving only necessary document segments. However, narrative texts possess unique characteristics that limit the effectiveness of these existing approaches. Specifically, understanding narrative texts requires more than isolated segments, as the broader context and sequential relationships between segments are crucial for comprehension. To address these limitations, we propose ChronoRAG, a novel RAG framework specialized for narrative texts. This approach focuses on two essential aspects: refining dispersed document information into coherent and structured passages and preserving narrative flow by explicitly capturing and maintaining the temporal order among retrieved passages. We empirically demonstrate the effectiveness of ChronoRAG through experiments on the NarrativeQA and GutenQAdataset, showing substantial improvements in tasks requiring both factual identification and comprehension of complex sequential relationships, underscoring that reasoning over temporal order is crucial in resolving narrative QA.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18748","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.258580","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Byeongjeong Kim, Jeonghyun Park, Joonho Yang, Hwanhee Lee","raw_content_length":1384,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["ChronoRAG","Temporal Question Answering","Chronological Passage Assembling"],"persons":["RAG"],"locations":["RAG"],"monetary":[]},"char_count":1383,"language_detected":"en","key_concepts":{"key_phrases":["Chronological Passage Assembling","RAG framework","Temporal Question Answering","arXiv250818748v2","Announce Type","Abstract","Long-context question","narrative tasks","correct answers","a coherent timeline"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chronological Passage Assembling":2.0,"RAG framework":2.0,"Temporal Question Answering":2.0,"arXiv250818748v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Long-context question":1.0,"narrative tasks":1.0,"correct answers":1.0,"a coherent timeline":1.0}},"age_hours":2.7694996744444444,"is_recent":true,"quality_score":1.0,"sentiment_score":3.721,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2558,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.909,"joy":0.0069,"surprise":0.0267,"sadness":0.0101,"fear":0.0207,"anger":0.0154,"disgust":0.0111},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving question answering for narrative texts using a novel RAG framework. While it demonstrates improvements on specific datasets, it's in the early stages of research with no clear path to directly reducing GHG emissions or addressing climate change. The impact is theoretical at this point.","key_impact_metrics":["Improvements on NarrativeQA dataset","Improvements on GutenQA dataset"],"technology_tags":["RAG framework","Temporal Question Answering"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:46:22.244794Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0a577d0adb03","title":"TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision","content":"arXiv:2508.19257v2 Announce Type: replace Abstract: Vision-Language-Action (VLA) models process visual inputs independently at each timestep, discarding valuable temporal information inherent in robotic manipulation tasks. This frame-by-frame processing makes models vulnerable to visual noise while ignoring the substantial coherence between consecutive frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a training-free approach that intelligently integrates historical and current visual representations to enhance VLA inference quality. Our method employs dual-dimension detection combining efficient grayscale pixel difference analysis with attention-based semantic relevance assessment, enabling selective temporal token fusion through hard fusion strategies and keyframe anchoring to prevent error accumulation. Comprehensive experiments across LIBERO, SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0 percentage points average on LIBERO (72.4\\% vs 68.4\\% baseline), cross-environment validation on SimplerEnv (4.8\\% relative improvement), and 8.7\\% relative improvement on real robot tasks. Our approach proves model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably, TTF reveals that selective Query matrix reuse in attention mechanisms enhances rather than compromises performance, suggesting promising directions for direct KQV matrix reuse strategies that achieve computational acceleration while improving task success rates.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.19257","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.258982","language":"en","tags":["cslg","csai","preprints","cscv","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Chenghao Liu, Jiachen Zhang, Chengxuan Li, Zhimu Zhou, Shixin Wu, Songfang Huang, Huiling Duan","raw_content_length":1507,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Pixel-Attention Integration for Vision arXiv:2508.19257v2 Announce Type:","Temporal Token Fusion","SimplerEnv","TTF","Vision-Language-Action","LIBERO"],"persons":[],"locations":[],"monetary":[]},"char_count":1506,"language_detected":"en","key_concepts":{"key_phrases":["Temporal Token Fusion","TTF-VLA","Pixel-Attention Integration","Vision","arXiv250819257v2 Announce Type","Abstract","VLA","visual inputs","each timestep","valuable temporal information"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Temporal Token Fusion":3.0,"TTF-VLA":2.0,"Pixel-Attention Integration":2.0,"Vision":2.0,"arXiv250819257v2 Announce Type":1.0,"Abstract":1.0,"VLA":1.0,"visual inputs":1.0,"each timestep":1.0,"valuable temporal information":1.0}},"age_hours":2.769514515277778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5079,"joy":0.0083,"surprise":0.0232,"sadness":0.0177,"fear":0.386,"anger":0.0308,"disgust":0.0261},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (TTF) to improve VLA model performance in robotic manipulation tasks, showing improvements in simulation and real-world robot tasks. While the research is promising, it is still in the applied research stage with no mention of commercial deployment or economic viability. The climate impact is indirect, potentially reducing energy consumption by improving robot efficiency, but this is not quantified.","key_impact_metrics":["4.0 percentage points average on LIBERO","8.7% relative improvement on real robot tasks"],"technology_tags":["Vision-Language-Action models","Temporal Token Fusion","Pixel-Attention Integration"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:46:28.375133Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_40e1c0025a96","title":"One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist","content":"arXiv:2508.21451v2 Announce Type: replace Abstract: Image captioning is fundamental for applications like video-grounded chatbot systems and navigation robots, yet deploying such models on local devices is challenging due to the high computational demands of multimodal LLMs (MLLMs). To address this, we first build lightweight captioning models using a 125M-parameter language model, 56 times smaller than LLaMA-7B, and evaluate their performance not only on single-sentence but on detailed captioning tasks. We obtain surprising results showing that our model can achieve performance comparable to MLLMs, suggesting its potential to serve as a strong captioning specialist for on-device applications. While promising, our model also exhibits a limitation: like other MLLMs, it suffers from occasional captioning errors. We investigate the underlying causes and observe that the problems stem from ineffective attention mechanisms and limited visual representations. To alleviate them, we develop a novel captioning framework, Sharp-Eyed Refinement, which enhances caption quality by refining coarse descriptions into more precise captions. At its core, DeepLens improves visual grounding by re-examining the informative regions identified in the initial glance. Experimental results demonstrate the superiority of our model over both recent lightweight captioning methods and MLLMs in detailed captioning and even in long-range video QA tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.21451","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.260141","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Junha Song, Yongsik Jo, So Yeon Min, Quanting Xie, Taehwan Kim, Yonatan Bisk, Jaegul Choo","raw_content_length":1446,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":["LLaMA-7B"],"monetary":[]},"char_count":1445,"language_detected":"en","key_concepts":{"key_phrases":["One More Glance","Sharp Eyes","Lightweight Captioning","a Practical Visual Specialist","arXiv250821451v2 Announce Type","Abstract","Image captioning","applications","video-grounded chatbot systems","navigation robots"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"One More Glance":2.0,"Sharp Eyes":2.0,"Lightweight Captioning":2.0,"a Practical Visual Specialist":2.0,"arXiv250821451v2 Announce Type":1.0,"Abstract":1.0,"Image captioning":1.0,"applications":1.0,"video-grounded chatbot systems":1.0,"navigation robots":1.0}},"age_hours":2.769560086388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9193,"joy":0.019,"surprise":0.0324,"sadness":0.0048,"fear":0.0093,"anger":0.0101,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel captioning framework that improves visual grounding. It achieves comparable performance to MLLMs using a smaller language model (125M parameters vs LLaMA-7B), suggesting potential for on-device applications. However, it's still in the applied research stage with no deployed units or customer contracts, making it vaporware at this point.","key_impact_metrics":["56 times smaller language model than LLaMA-7B"],"technology_tags":["image captioning","lightweight language model","visual grounding"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:46:34.645193Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_da2eeaf8ec3f","title":"Talk Less, Call Right: Enhancing Role","content":"arXiv:2509.00482v2 Announce Type: replace Abstract: This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this setting, dialogue agents often produce overly long in-character responses (over-speaking) while failing to use tools effectively according to the persona (under-acting), such as generating function calls that do not exist or making unnecessary tool calls before answering. We explore four prompting approaches to address these issues: 1) basic role prompting, 2) improved role prompting, 3) automatic prompt optimization (APO), and 4) rule-based role prompting. The rule-based role prompting (RRP) approach achieved the best performance through two novel techniques-character-card/scene-contract design and strict enforcement of function calling-which led to an overall score of 0.571, improving on the zero-shot baseline score of 0.519. These findings demonstrate that RRP design can substantially improve the effectiveness and reliability of role-playing dialogue agents compared with more elaborate methods such as APO. To support future efforts in developing persona prompts, we are open-sourcing all of our best-performing prompts and the APO tool Source code is available at https://github.com/scb-10x/apo","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.00482","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.260552","language":"en","tags":["computer-science","csai","preprints","cscl","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Saksorn Ruangtanusak, Pittawat Taveekitworachai, Kunat Pipatanakul","raw_content_length":1391,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["API","APO","Dialogue Challenge (CPDC","Commonsense","RRP"],"persons":[],"locations":[],"monetary":[]},"char_count":1390,"language_detected":"en","key_concepts":{"key_phrases":["Talk Less Call Right","Enhancing Role","arXiv250900482v2","Announce Type","Abstract","This report","a tool-augmented large language model","LLM","a role-playing dialogue agent","the API track"],"filter_categories":{"ai_ml":["a tool-augmented large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Talk Less Call Right":2.0,"Enhancing Role":2.0,"arXiv250900482v2":1.0,"Announce Type":1.0,"Abstract":1.0,"This report":1.0,"a tool-augmented large language model":1.0,"LLM":1.0,"a role-playing dialogue agent":1.0,"the API track":1.0}},"age_hours":2.7695762816666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8791,"joy":0.005,"surprise":0.016,"sadness":0.021,"fear":0.005,"anger":0.0344,"disgust":0.0396},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the performance of LLMs in role-playing dialogue using different prompting techniques. While the research demonstrates a performance improvement of 0.519 to 0.571 in overall score, it's still in the applied research phase with no clear link to direct environmental impact or deployment.","key_impact_metrics":["Overall score improvement: 0.052"],"technology_tags":["Large Language Models","Prompt Engineering","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:46:37.815762Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0dad17339d49","title":"VulSolver: Vulnerability Detection via LLM","content":"arXiv:2509.00882v3 Announce Type: replace Abstract: Traditional vulnerability detection methods rely heavily on predefined rule matching, which often fails to capture vulnerabilities accurately. With the rise of large language models (LLMs), leveraging their ability to understand code semantics has emerged as a promising direction for achieving more accurate and efficient vulnerability detection. However, current LLM-based approaches face significant challenges: instability in model outputs, limitations in context length, and hallucination. As a result, many existing solutions either use LLMs merely to enrich predefined rule sets, thereby keeping the detection process fundamentally rule-based, or over-rely on them, leading to poor robustness. To address these challenges, we propose a constraint-solving approach powered by LLMs named VULSOLVER. By modeling vulnerability detection as a constraint-solving problem, and by integrating static application security testing (SAST) with the semantic reasoning capabilities of LLMs, our method enables the LLM to act like a professional human security expert. We assess VULSOLVER on the OWASP Benchmark (1,023 labeled samples), achieving 96.29% accuracy, 96.55% F1-score, and 100% recall. Applied to popular GitHub repositories, VULSOLVER also identified 15 previously unknown high-severity vulnerabilities (CVSS 7.5-9.8), demonstrating its effectiveness in real-world security analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.00882","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.261743","language":"en","tags":["preprints","research","computer-science","cscr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Xiang Li, Yueci Su, Jiahao Liu, Zhiwei Lin, Yuebing Hou, Peiming Gao, Yuanchao Zhang","raw_content_length":1442,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["LLM","Vulnerability Detection via"],"persons":["VULSOLVER","Announce Type"],"locations":[],"monetary":[]},"char_count":1441,"language_detected":"en","key_concepts":{"key_phrases":["VulSolver","Vulnerability Detection","LLM","arXiv250900882v3 Announce Type","Abstract","Traditional vulnerability detection methods","predefined rule matching","which","vulnerabilities","the rise"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VulSolver":2.0,"Vulnerability Detection":2.0,"LLM":2.0,"arXiv250900882v3 Announce Type":1.0,"Abstract":1.0,"Traditional vulnerability detection methods":1.0,"predefined rule matching":1.0,"which":1.0,"vulnerabilities":1.0,"the rise":1.0}},"age_hours":2.769621298333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.324,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2648,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5626,"joy":0.0107,"surprise":0.0236,"sadness":0.0581,"fear":0.3009,"anger":0.0283,"disgust":0.0158},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel approach to vulnerability detection using LLMs. While it demonstrates high accuracy and identifies previously unknown vulnerabilities in GitHub repositories, it is still in the applied research phase with no deployed units or customer contracts. The climate impact is indirect, potentially reducing energy consumption from inefficient code if widely adopted, but this is not quantified.","key_impact_metrics":["Accuracy 96.29%","F1-score 96.55%"],"technology_tags":["Large Language Models","Vulnerability Detection","Static Application Security Testing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:46:45.030468Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d2fd7a0802e","title":"REFRAG: Rethinking RAG based Decoding","content":"arXiv:2509.01092v2 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in leveraging extensive external knowledge to enhance responses in multi-turn and agentic applications, such as retrieval-augmented generation (RAG). However, processing long-context inputs introduces significant system latency and demands substantial memory for the key-value cache, resulting in reduced throughput and a fundamental trade-off between knowledge enrichment and system efficiency. While minimizing latency for long-context inputs is a primary objective for LLMs, we contend that RAG require specialized consideration. In RAG, much of the LLM context consists of concatenated passages from retrieval, with only a small subset directly relevant to the query. These passages often exhibit low semantic similarity due to diversity or deduplication during re-ranking, leading to block-diagonal attention patterns that differ from those in standard LLM generation tasks. Based on this observation, we argue that most computations over the RAG context during decoding are unnecessary and can be eliminated with minimal impact on performance. To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG applications. By exploiting the sparsity structure, we demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to previous work) without loss in perplexity. In addition, our optimization framework for large context enables REFRAG to extend the context size of LLMs by 16. We provide rigorous validation of REFRAG across diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets. Experimental results confirm that REFRAG delivers substantial speedup with no loss in accuracy compared to LLaMA models and other state-of-the-art baselines across various context sizes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.01092","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.262572","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":267,"author":"Xiaoqiang Lin, Aritra Ghosh, Bryan Kian Hsiang Low, Anshumali Shrivastava, Vijai Mohan","raw_content_length":1963,"priority":7,"update_frequency":1,"reading_time_minutes":1.335,"robust_parsing_used":true,"entities":{"organizations":["LLM","Decoding arXiv:2509.01092v2"],"persons":["Rethinking RAG","RAG"],"locations":["RAG"],"monetary":[]},"char_count":1962,"language_detected":"en","key_concepts":{"key_phrases":["REFRAG","Rethinking RAG","Decoding","Announce Type","Large Language Models","LLMs","remarkable capabilities","extensive external knowledge","responses","turn and agentic applications"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"REFRAG":2.0,"Rethinking RAG":2.0,"Decoding":2.0,"Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable capabilities":1.0,"extensive external knowledge":1.0,"responses":1.0,"turn and agentic applications":1.0}},"age_hours":2.769651028333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8209,"joy":0.0129,"surprise":0.1123,"sadness":0.0113,"fear":0.0125,"anger":0.0212,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (REFRAG) to improve the efficiency of Retrieval-Augmented Generation (RAG) in LLMs, leading to reduced latency and increased context size. The concrete action is the development and validation of this framework, demonstrating a 30.85x acceleration in time-to-first-token. However, it is still in the applied research phase, with no mention of deployed units or commercial applications, hence the vaporware flag.","key_impact_metrics":["30.85x time-to-first-token acceleration","16x context size extension"],"technology_tags":["Large Language Models","Retrieval-Augmented Generation","Efficient Decoding"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:46:55.687664Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_61a5efeaa893","title":"Maximum entropy temporal networks","content":"arXiv:2509.02098v2 Announce Type: replace Abstract: Temporal networks consist of timestamped directed interactions that may appear continuously in time, yet few studies have directly tackled the continuous-time modeling of networks. Here, we introduce a maximum-entropy approach to temporal networks and with basic assumptions on constraints, the corresponding network ensembles admit a modular and interpretable representation: a set of global time processes and a static maximum-entropy edge, e.g. node pair, probability. This time-edge labels factorization yields closed-form log-likelihoods, degree, clustering and motif expectations, and yields a whole class of effective generative models. We provide maximum-entropy derivation of an inhomogeneous Poisson edge intensity for temporal networks via functional optimization over path entropy, connecting NHPP modeling to maximum-entropy network ensembles. NHPP consistently improve log-likelihood over generic Poisson processes, while the maximum-entropy edge labels recover strength constraints and reproduce expected unique-degree curves. We discuss the limitations of this framework and how it can be integrated with multivariate Hawkes calibration procedures, renewal theory, and neural kernel estimation in graph neural networks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.02098","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.262949","language":"en","tags":["computer-science","preprints","physicsdata-an","research","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Paolo Barucca","raw_content_length":1288,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["NHPP"],"persons":["node pair","Announce Type"],"locations":[],"monetary":[]},"char_count":1287,"language_detected":"en","key_concepts":{"key_phrases":["temporal networks","Maximum","arXiv250902098v2 Announce Type","Abstract","Temporal networks","timestamped directed interactions","time","few studies","the continuous-time modeling","networks"],"filter_categories":{"ai_ml":["networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"temporal networks":3.0,"Maximum":2.0,"arXiv250902098v2 Announce Type":1.0,"Abstract":1.0,"Temporal networks":1.0,"timestamped directed interactions":1.0,"time":1.0,"few studies":1.0,"the continuous-time modeling":1.0,"networks":1.0}},"age_hours":2.7696654872222224,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8827,"joy":0.0154,"surprise":0.0736,"sadness":0.0049,"fear":0.0048,"anger":0.0127,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for modeling temporal networks. While it shows potential for improving network analysis, it is currently in the basic research stage with no concrete deployments or quantifiable environmental benefits. The paper does mention improved log-likelihood over generic Poisson processes, which is a measurable outcome.","key_impact_metrics":["log-likelihood improvement"],"technology_tags":["temporal networks","maximum entropy modeling","inhomogeneous Poisson process"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:46:58.523218Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_33b0e9b39c89","title":"VendiRL: A Framework for Self","content":"arXiv:2509.02930v2 Announce Type: replace Abstract: In self-supervised reinforcement learning (RL), one of the key challenges is learning a diverse set of skills to prepare agents for unknown future tasks. Despite impressive advances, scalability and evaluation remain prevalent issues. Regarding scalability, the search for meaningful skills can be obscured by high-dimensional feature spaces, where relevant features may vary across downstream task domains. For evaluating skill diversity, defining what constitutes \"diversity\" typically requires a hard commitment to a specific notion of what it means for skills to be diverse, potentially leading to inconsistencies in how skill diversity is understood, making results across different approaches hard to compare, and leaving many forms of diversity unexplored. To address these issues, we adopt a measure of sample diversity that translates ideas from ecology to machine learning -- the Vendi Score -- allowing the user to specify and evaluate any desired form of diversity. We demonstrate how this metric facilitates skill evaluation and introduce VendiRL, a unified framework for learning diversely diverse sets of skills. Given distinct similarity functions, VendiRL motivates distinct forms of diversity, which could support skill-diversity pretraining in new and richly interactive environments where optimising for various forms of diversity may be desirable.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.02930","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.264507","language":"en","tags":["computer-science","cslg","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Erik M. Lintunen","raw_content_length":1421,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1420,"language_detected":"en","key_concepts":{"key_phrases":["VendiRL A Framework","Self","scalability","arXiv250902930v2","Announce Type","Abstract","self-supervised reinforcement learning","the key challenges","a diverse set","skills"],"filter_categories":{"ai_ml":["self-supervised reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VendiRL A Framework":2.0,"Self":2.0,"scalability":2.0,"arXiv250902930v2":1.0,"Announce Type":1.0,"Abstract":1.0,"self-supervised reinforcement learning":1.0,"the key challenges":1.0,"a diverse set":1.0,"skills":1.0}},"age_hours":2.7697219352777775,"is_recent":true,"quality_score":0.7,"sentiment_score":4.8685,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0263,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8431,"joy":0.004,"surprise":0.0161,"sadness":0.0067,"fear":0.0854,"anger":0.024,"disgust":0.0207},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel reinforcement learning framework (VendiRL) for skill diversity, but it is currently in the research stage with no deployed applications or measurable outcomes related to sustainability. The potential climate impact is theoretical, as the framework itself doesn't directly reduce emissions or sequester carbon. The technical credibility is moderate due to the peer-reviewed nature of the research, but the deployment readiness is very low.","key_impact_metrics":[],"technology_tags":["reinforcement learning","self-supervised learning","skill diversity"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:02.075438Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a353d76156d9","title":"SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self","content":"arXiv:2509.03937v2 Announce Type: replace Abstract: Despite the significant advancements of self-play fine-tuning (SPIN), which can transform a weak large language model (LLM) into a strong one through competitive interactions between models of varying capabilities, it still faces challenges in the Text-to-SQL task. SPIN does not generate new information, and the large number of correct SQL queries produced by the opponent model during self-play reduces the main model's ability to generate accurate SQL queries. To address this challenge, we propose a new self-play fine-tuning method tailored for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a verification-based iterative fine-tuning approach, which synthesizes high-quality fine-tuning data iteratively based on the database schema and validation feedback to enhance model performance, while building a model base with varying capabilities. During the self-play fine-tuning phase, we propose an error-driven loss method that incentivizes incorrect outputs from the opponent model, enabling the main model to distinguish between correct SQL and erroneous SQL generated by the opponent model, thereby improving its ability to generate correct SQL. Extensive experiments and in-depth analyses on six open-source LLMs and five widely used benchmarks demonstrate that our approach outperforms existing state-of-the-art (SOTA) methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.03937","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.264909","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Yuhao Zhang, Shaoming Duan, Jinhang Su, Chuanyi Liu, Peiyi Han","raw_content_length":1415,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing","SPFT-SQL","SQL"],"persons":[],"locations":[],"monetary":[]},"char_count":1414,"language_detected":"en","key_concepts":{"key_phrases":["SQL","SPFT-SQL","Large Language Model","Self","SPIN","arXiv250903937v2 Announce Type","Abstract","the significant advancements","self-play fine-tuning","which"],"filter_categories":{"ai_ml":["Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SQL":3.0,"SPFT-SQL":2.0,"Large Language Model":2.0,"Self":2.0,"SPIN":2.0,"arXiv250903937v2 Announce Type":1.0,"Abstract":1.0,"the significant advancements":1.0,"self-play fine-tuning":1.0,"which":1.0}},"age_hours":2.769738108888889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.375500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2751,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8846,"joy":0.0102,"surprise":0.0501,"sadness":0.0234,"fear":0.0149,"anger":0.0119,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the accuracy of Text-to-SQL parsing using LLMs, which could indirectly support sustainability efforts by improving data analysis and decision-making in related fields. However, there are no direct, measurable outcomes related to climate impact or other sustainability dimensions. The technology is in the applied research phase, with experiments on open-source LLMs and benchmarks, but no real-world deployment data.","key_impact_metrics":["Accuracy improvement on Text-to-SQL task","Performance on open-source LLMs"],"technology_tags":["Large Language Models","Text-to-SQL parsing","Self-play fine-tuning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:05.573687Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2c68a270df73","title":"EvoEmo: Towards Evolved Emotional Policies for Adversarial LLM Agents in Multi","content":"arXiv:2509.04310v3 Announce Type: replace Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \\textit{complex}, \\textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.04310","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.265300","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Yunbo Long, Liming Xu, Lukas Beckenbauer, Yuhan Liu, Alexandra Brintrup","raw_content_length":1358,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","CoT","LLM","EvoEmo"],"persons":[],"locations":[],"monetary":[]},"char_count":1357,"language_detected":"en","key_concepts":{"key_phrases":["EvoEmo","Evolved Emotional Policies","Adversarial LLM Agents","Multi","arXiv250904310v3 Announce Type","Abstract","Recent research","Thought","Large Language Models","LLMs"],"filter_categories":{"ai_ml":["Adversarial LLM Agents","Large Language Models"],"research_academic":["Recent research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EvoEmo":2.0,"Evolved Emotional Policies":2.0,"Adversarial LLM Agents":2.0,"Multi":2.0,"arXiv250904310v3 Announce Type":1.0,"Abstract":1.0,"Recent research":1.0,"Thought":1.0,"Large Language Models":1.0,"LLMs":1.0}},"age_hours":2.7697522825000003,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8862,"joy":0.0303,"surprise":0.0458,"sadness":0.0051,"fear":0.0063,"anger":0.0195,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an evolutionary reinforcement learning framework (EvoEmo) to optimize emotional expression in LLM negotiations. While it shows improved success rates, efficiency, and buyer savings compared to baselines, it is still in the research phase with no real-world deployment or quantifiable environmental impact. The impact is theoretical at this stage.","key_impact_metrics":["higher success rates","increased buyer savings"],"technology_tags":["Large Language Models","Reinforcement Learning","Evolutionary Algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:08.677908Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2096c8799ca5","title":"Cryo","content":"arXiv:2509.04886v2 Announce Type: replace Abstract: Cryoablation is a minimally invasive localised treatment for prostate cancer that destroys malignant tissue during de-freezing, while sparing surrounding healthy structures. Its success depends on accurate preoperative planning of cryoprobe placements to fully cover the tumour and avoid critical anatomy. This planning is currently manual, expertise-dependent, and time-consuming, leading to variability in treatment quality and limited scalability. In this work, we introduce Cryo-RL, a reinforcement learning framework that models cryoablation planning as a Markov decision process and learns an optimal policy for cryoprobe placement. Within a simulated environment that models clinical constraints and stochastic intraoperative variability, an agent sequentially selects cryoprobe positions and ice sphere diameters. Guided by a reward function based on tumour coverage, this agent learns a cryoablation strategy that leads to optimal cryoprobe placements without the need for any manually-designed plans. Evaluated on 583 retrospective prostate cancer cases, Cryo-RL achieved over 8 percentage-point Dice improvements compared with the best automated baselines, based on geometric optimisation, and matched human expert performance while requiring substantially less planning time. These results highlight the potential of reinforcement learning to deliver clinically viable, reproducible, and efficient cryoablation plans.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.04886","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.265706","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Trixia Simangan, Ahmed Nadeem Abbasi, Yipeng Hu, Shaheer U. Saeed","raw_content_length":1482,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Cryo arXiv:2509.04886v2 Announce Type:"],"persons":["Markov","Cryo-RL"],"locations":[],"monetary":[]},"char_count":1481,"language_detected":"en","key_concepts":{"key_phrases":["Cryo","arXiv250904886v2","Announce Type","Abstract","Cryoablation","a minimally invasive localised treatment","prostate cancer","malignant tissue","surrounding healthy structures","Its success"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cryo":2.0,"arXiv250904886v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Cryoablation":1.0,"a minimally invasive localised treatment":1.0,"prostate cancer":1.0,"malignant tissue":1.0,"surrounding healthy structures":1.0,"Its success":1.0}},"age_hours":2.7697660352777778,"is_recent":true,"quality_score":0.7,"sentiment_score":1.0470000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7906,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6743,"joy":0.0074,"surprise":0.0143,"sadness":0.0222,"fear":0.1931,"anger":0.0484,"disgust":0.0403},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a reinforcement learning framework (Cryo-RL) for optimizing cryoprobe placement in prostate cancer treatment. While the research shows a significant improvement in tumor coverage (8 percentage-point Dice improvements) compared to automated baselines, it is currently limited to a simulated environment. The lack of real-world deployment and economic viability data limits its immediate sustainability impact.","key_impact_metrics":["8 percentage-point Dice improvements"],"technology_tags":["Reinforcement Learning","Cryoablation","Medical Imaging"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:47:11.969010Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1300034708a0","title":"Talk Isn't Always Cheap: Understanding Failure Modes in Multi","content":"arXiv:2509.05396v2 Announce Type: replace Abstract: While multi-agent debate has been proposed as a promising strategy for improving AI reasoning ability, we find that debate can sometimes be harmful rather than helpful. Prior work has primarily focused on debates within homogeneous groups of agents, whereas we explore how diversity in model capabilities influences the dynamics and outcomes of multi-agent interactions. Through a series of experiments, we demonstrate that debate can lead to a decrease in accuracy over time - even in settings where stronger (i.e., more capable) models outnumber their weaker counterparts. Our analysis reveals that models frequently shift from correct to incorrect answers in response to peer reasoning, favoring agreement over challenging flawed reasoning. We perform additional experiments investigating various potential contributing factors to these harmful shifts - including sycophancy, social conformity, and model and task type. These results highlight important failure modes in the exchange of reasons during multi-agent debate, suggesting that naive applications of debate may cause performance degradation when agents are neither incentivised nor adequately equipped to resist persuasive but incorrect reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.05396","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.266087","language":"en","tags":["computer-science","csma","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Andrea Wynn, Harsh Satija, Gillian Hadfield","raw_content_length":1263,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1262,"language_detected":"en","key_concepts":{"key_phrases":["Talk","Understanding Failure Modes","Multi","that debate","Announce Type","Abstract","multi-agent debate","a promising strategy","AI reasoning ability","Prior work"],"filter_categories":{"ai_ml":["Understanding Failure Modes"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Talk":2.0,"Understanding Failure Modes":2.0,"Multi":2.0,"that debate":2.0,"Announce Type":1.0,"Abstract":1.0,"multi-agent debate":1.0,"a promising strategy":1.0,"AI reasoning ability":1.0,"Prior work":1.0}},"age_hours":2.7697802330555557,"is_recent":true,"quality_score":0.7,"sentiment_score":9.375,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.875,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5409,"joy":0.0171,"surprise":0.0093,"sadness":0.0469,"fear":0.0228,"anger":0.1112,"disgust":0.2518},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores failure modes in multi-agent AI debate, finding that debate can decrease accuracy. The research is based on experiments where models shift from correct to incorrect answers. There is no concrete action happening in terms of climate impact, but the research is technically credible and uses metrics to evaluate model performance.","key_impact_metrics":["Decrease in accuracy over time","Shift from correct to incorrect answers"],"technology_tags":["Multi-agent debate","AI reasoning","Machine Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:47:15.086928Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_02bd638cc969","title":"Evaluating YOLO Architectures: Implications for Real","content":"arXiv:2509.05652v2 Announce Type: replace Abstract: Vehicle detection systems trained on Non-Bangladeshi datasets struggle to accurately identify local vehicle types in Bangladesh's unique road environments, creating critical gaps in autonomous driving technology for developing regions. This study evaluates six YOLO model variants on a custom dataset featuring 29 distinct vehicle classes, including region-specific vehicles such as ``Desi Nosimon'', ``Leguna'', ``Battery Rickshaw'', and ``CNG''. The dataset comprises high-resolution images (1920x1080) captured across various Bangladeshi roads using mobile phone cameras and manually annotated using LabelImg with YOLO format bounding boxes. Performance evaluation revealed YOLOv11x as the top performer, achieving 63.7\\% mAP@0.5, 43.8\\% mAP@0.5:0.95, 61.4\\% recall, and 61.6\\% F1-score, though requiring 45.8 milliseconds per image for inference. Medium variants (YOLOv8m, YOLOv11m) struck an optimal balance, delivering robust detection performance with mAP@0.5 values of 62.5\\% and 61.8\\% respectively, while maintaining moderate inference times around 14-15 milliseconds. The study identified significant detection challenges for rare vehicle classes, with Construction Vehicles and Desi Nosimons showing near-zero accuracy due to dataset imbalances and insufficient training samples. Confusion matrices revealed frequent misclassifications between visually similar vehicles, particularly Mini Trucks versus Mini Covered Vans. This research provides a foundation for developing robust object detection systems specifically adapted to Bangladesh traffic conditions, addressing critical needs in autonomous vehicle technology advancement for developing regions where conventional generic-trained models fail to perform adequately.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.05652","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.266507","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Ha Meem Hossain, Pritam Nath, Mahitun Nesa Mahi, Imtiaz Uddin, Ishrat Jahan Eiste, Syed Nasibur Rahman Ratul, Md Naim Uddin Mozumdar, Asif Mohammed Saad, MD Tamim Hossain","raw_content_length":1788,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["LabelImg","YOLO","63.7\\% mAP@0.5","Non-Bangladeshi"],"persons":["Bangladeshi"],"locations":["Bangladesh"],"monetary":[]},"char_count":1787,"language_detected":"en","key_concepts":{"key_phrases":["YOLO Architectures","Implications","Announce Type","Abstract","Vehicle detection systems","Non-Bangladeshi datasets","local vehicle types","Bangladeshs unique road environments","critical gaps","autonomous driving technology"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"YOLO Architectures":2.0,"Implications":2.0,"Announce Type":1.0,"Abstract":1.0,"Vehicle detection systems":1.0,"Non-Bangladeshi datasets":1.0,"local vehicle types":1.0,"Bangladeshs unique road environments":1.0,"critical gaps":1.0,"autonomous driving technology":1.0}},"age_hours":2.769795685277778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.5249999999999995,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.505,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8505,"joy":0.0096,"surprise":0.0256,"sadness":0.0307,"fear":0.0346,"anger":0.0336,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on adapting object detection for autonomous vehicles in Bangladesh, which could indirectly reduce emissions by optimizing traffic flow and potentially promoting the adoption of electric vehicles in the future. The study provides concrete performance metrics (mAP, recall, F1-score) for different YOLO models on a custom dataset. However, it is still in the applied research phase with no actual deployments or economic viability demonstrated.","key_impact_metrics":["63.7% mAP@0.5","43.8% mAP@0.5:0.95"],"technology_tags":["YOLO","Object Detection","Autonomous Vehicles"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:47:18.455738Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_570a18f475d3","title":"When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection","content":"arXiv:2509.06427v2 Announce Type: replace Abstract: Muzzle patterns are among the most effective biometric traits for cattle identification. Fast and accurate detection of the muzzle region as the region of interest is critical to automatic visual cattle identification.. Earlier approaches relied on manual detection, which is labor-intensive and inconsistent. Recently, automated methods using supervised models like YOLO have become popular for muzzle detection. Although effective, these methods require extensive annotated datasets and tend to be trained data-dependent, limiting their performance on new or unseen cattle. To address these limitations, this study proposes a zero-shot muzzle detection framework based on Grounding DINO, a vision-language model capable of detecting muzzles without any task-specific training or annotated data. This approach leverages natural language prompts to guide detection, enabling scalable and flexible muzzle localization across diverse breeds and environments. Our model achieves a mean Average Precision (mAP)@0.5 of 76.8\\%, demonstrating promising performance without requiring annotated data. To our knowledge, this is the first research to provide a real-world, industry-oriented, and annotation-free solution for cattle muzzle detection. The framework offers a practical alternative to supervised methods, promising improved adaptability and ease of deployment in livestock monitoring applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.06427","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.266897","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Rabin Dulal, Lihong Zheng, Muhammad Ashad Kabir","raw_content_length":1452,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["DINO","YOLO"],"persons":["Language Model Guides"],"locations":[],"monetary":[]},"char_count":1451,"language_detected":"en","key_concepts":{"key_phrases":["When Language Model Guides Vision","DINO","Cattle Muzzle Detection","arXiv250906427v2 Announce Type","Abstract","Muzzle patterns","the most effective biometric traits","cattle identification","Fast and accurate detection","the muzzle region"],"filter_categories":{"ai_ml":["the most effective biometric traits"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"When Language Model Guides Vision":2.0,"DINO":2.0,"Cattle Muzzle Detection":2.0,"arXiv250906427v2 Announce Type":1.0,"Abstract":1.0,"Muzzle patterns":1.0,"the most effective biometric traits":1.0,"cattle identification":1.0,"Fast and accurate detection":1.0,"the muzzle region":1.0}},"age_hours":2.7698102588888887,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8867,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9022,"joy":0.0086,"surprise":0.0366,"sadness":0.0052,"fear":0.0223,"anger":0.0177,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a zero-shot muzzle detection framework for cattle identification using a vision-language model. The concrete action is the development of a model that achieves a mAP@0.5 of 76.8% without annotated data. This is still in the applied research phase, with no deployment mentioned, hence the 'vaporware' flag.","key_impact_metrics":["mAP@0.5 with 76.8%"],"technology_tags":["vision-language model","cattle identification","muzzle detection"],"sdg_alignment":[2,15],"analyzed_at":"2025-10-29T12:47:21.671470Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e54b24bc3aa","title":"VL Norm: Rethink Loss Aggregation in RLVR","content":"arXiv:2509.07558v2 Announce Type: replace Abstract: We propose VL Norm (Variance-reduced Length-dependent Normalization), a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed VL Norm not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Besides, VL Norm is easy to implement with less than 10 lines of code change. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. When integrated into the state-of-the-art RL algorithm DAPO, it achieves up to 2.67x faster convergence on the CountDown task. Our code is public at https://github.com/zerolllin/Delta-L-Normalization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.07558","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.268065","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Zhiyuan He, Xufang Luo, Yike Zhang, Yuqing Yang, Lili Qiu","raw_content_length":1487,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["DAPO","Reinforcement Learning with Verifiable Rewards","GRPO"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1486,"language_detected":"en","key_concepts":{"key_phrases":["RLVR","VL Norm","Rethink Loss Aggregation","arXiv250907558v2 Announce Type","Abstract","Variance-reduced Length-dependent Normalization","the characteristic","dynamic generation lengths","Reinforcement Learning","Verifiable Rewards"],"filter_categories":{"ai_ml":["Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RLVR":4.0,"VL Norm":3.0,"Rethink Loss Aggregation":2.0,"arXiv250907558v2 Announce Type":1.0,"Abstract":1.0,"Variance-reduced Length-dependent Normalization":1.0,"the characteristic":1.0,"dynamic generation lengths":1.0,"Reinforcement Learning":1.0,"Verifiable Rewards":1.0}},"age_hours":2.7698531925,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7235,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3447,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8926,"joy":0.025,"surprise":0.0423,"sadness":0.0061,"fear":0.0132,"anger":0.0161,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel loss aggregation method (VL Norm) for reinforcement learning with verifiable rewards (RLVR), showing a 2.67x faster convergence on the CountDown task when integrated into the DAPO algorithm. The research is supported by theoretical analysis and experimental results, with code publicly available. However, it remains at the applied research stage with no current deployment or proven economic viability, and the climate impact is indirect and theoretical.","key_impact_metrics":["2.67x faster convergence on CountDown task"],"technology_tags":["Reinforcement Learning","Loss Aggregation","Large Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:47:25.116120Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3cc7435faba","title":"Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression","content":"arXiv:2509.08093v2 Announce Type: replace Abstract: Converging evidence suggests that systems of semantic categories across human languages achieve near-optimal compression via the Information Bottleneck (IB) complexity-accuracy principle. Large language models (LLMs) are not trained for this objective, which raises the question: are LLMs capable of evolving efficient human-like semantic systems? To address this question, we focus on the domain of color as a key testbed of cognitive theories of categorization and replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two influential human behavioral studies. First, we conduct an English color-naming study, showing that Gemini aligns well with the naming patterns of native English speakers and achieves a significantly high IB-efficiency score, while Llama exhibits an efficient but lower complexity system compared to English. Second, to test whether LLMs simply mimic patterns in their training data or actually exhibit a human-like inductive bias toward IB-efficiency, we simulate cultural evolution of pseudo color-naming systems in LLMs via iterated in-context language learning. We find that akin to humans, LLMs iteratively restructure initially random systems towards greater IB-efficiency and increased alignment with patterns observed across the world's languages. These findings demonstrate that LLMs are capable of evolving perceptually grounded, human-like semantic systems, driven by the same fundamental principle that governs semantic efficiency across human languages.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.08093","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.269203","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Nathaniel Imel, Noga Zaslavsky","raw_content_length":1556,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["the Information Bottleneck","Llama"],"persons":["Gemini"],"locations":[],"monetary":[]},"char_count":1555,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Culturally transmitted color categories","a learning bias","efficient compression","arXiv250908093v2 Announce Type","Abstract","Converging evidence","systems","semantic categories","human languages"],"filter_categories":{"ai_ml":["LLMs"],"engineering":["systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Culturally transmitted color categories":2.0,"a learning bias":2.0,"efficient compression":2.0,"arXiv250908093v2 Announce Type":1.0,"Abstract":1.0,"Converging evidence":1.0,"systems":1.0,"semantic categories":1.0,"human languages":1.0}},"age_hours":2.7698955544444446,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.896,"joy":0.0034,"surprise":0.0458,"sadness":0.0068,"fear":0.0114,"anger":0.0183,"disgust":0.0184},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the capabilities of LLMs to evolve efficient semantic systems, specifically in the domain of color categorization. While the findings are interesting from a cognitive science perspective, there are no concrete actions or measurable outcomes directly related to climate change mitigation or adaptation. The research is at a very early stage and doesn't involve any deployed technology or real-world impact.","key_impact_metrics":["IB-efficiency score","Alignment with native English speakers naming patterns"],"technology_tags":["Large Language Models","Semantic Systems","Color Categorization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:47:28.330622Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_369245182d43","title":"Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation","content":"arXiv:2509.08163v2 Announce Type: replace Abstract: Ensuring equitable treatment (fairness) across protected attributes (such as gender or ethnicity) is a critical issue in machine learning. Most existing literature focuses on binary classification, but achieving fairness in regression tasks-such as insurance pricing or hiring score assessments-is equally important. Moreover, anti-discrimination laws also apply to continuous attributes, such as age, for which many existing methods are not applicable. In practice, multiple protected attributes can exist simultaneously; however, methods targeting fairness across several attributes often overlook so-called \"fairness gerrymandering\", thereby ignoring disparities among intersectional subgroups (e.g., African-American women or Hispanic men). In this paper, we propose a distance covariance regularisation framework that mitigates the association between model predictions and protected attributes, in line with the fairness definition of demographic parity, and that captures both linear and nonlinear dependencies. To enhance applicability in the presence of multiple protected attributes, we extend our framework by incorporating two multivariate dependence measures based on distance covariance: the previously proposed joint distance covariance (JdCov) and our novel concatenated distance covariance (CCdCov), which effectively address fairness gerrymandering in both regression and classification tasks involving protected attributes of various types. We discuss and illustrate how to calibrate regularisation strength, including a method based on Jensen-Shannon divergence, which quantifies dissimilarities in prediction distributions across groups. We apply our framework to the COMPAS recidivism dataset and a large motor insurance claims dataset.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.08163","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.269631","language":"en","tags":["statml","cslg","statap","preprints","research","computer-science","q-finrm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Ho Ming Lee, Katrien Antonio, Benjamin Avanzi, Lorenzo Marchi, Rui Zhou","raw_content_length":1811,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":["associatio"],"persons":["Machine Learning"],"locations":[],"monetary":[]},"char_count":1810,"language_detected":"en","key_concepts":{"key_phrases":["Machine Learning","Multitype Protected Attributes","Intersectional Fairness","Regularisation","arXiv250908163v2 Announce Type","Abstract","equitable treatment fairness","protected attributes","gender","ethnicity"],"filter_categories":{"ai_ml":["Machine Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Machine Learning":2.0,"Multitype Protected Attributes":2.0,"Intersectional Fairness":2.0,"Regularisation":2.0,"arXiv250908163v2 Announce Type":1.0,"Abstract":1.0,"equitable treatment fairness":1.0,"protected attributes":1.0,"gender":1.0,"ethnicity":1.0}},"age_hours":2.769910113888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8778,"joy":0.0596,"surprise":0.0201,"sadness":0.0043,"fear":0.0077,"anger":0.0185,"disgust":0.012},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":7,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a machine learning framework to address fairness in regression and classification tasks, aiming to mitigate bias across protected attributes. While it uses real datasets (COMPAS, motor insurance), it remains at the applied research stage with no deployed technology or measured outcomes in a real-world sustainability context. The potential climate impact is indirect, relying on fairer resource allocation, but the technical credibility is supported by the use of distance covariance regularisation and Jensen-Shannon divergence.","key_impact_metrics":["Fairness gerrymandering reduction","Dissimilarities in prediction distributions across groups"],"technology_tags":["Machine Learning","Fairness Algorithms","Regularisation"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T12:47:32.262192Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d0e4bfbbc36f","title":"\"A 6 or a 9?\": Ensemble Learning Through the Multiplicity of Performant Models and Explanations","content":"arXiv:2509.09073v2 Announce Type: replace Abstract: Creating models from past observations and ensuring their effectiveness on new data is the essence of machine learning. However, selecting models that generalize well remains a challenging task. Related to this topic, the Rashomon Effect refers to cases where multiple models perform similarly well for a given learning problem. This often occurs in real-world scenarios, like the manufacturing process or medical diagnosis, where diverse patterns in data lead to multiple high-performing solutions. We propose the Rashomon Ensemble, a method that strategically selects models from these diverse high-performing solutions to improve generalization. By grouping models based on both their performance and explanations, we construct ensembles that maximize diversity while maintaining predictive accuracy. This selection ensures that each model covers a distinct region of the solution space, making the ensemble more robust to distribution shifts and variations in unseen data. We validate our approach on both open and proprietary collaborative real-world datasets, demonstrating up to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large. Additionally, we demonstrate tangible benefits for businesses in various real-world applications, highlighting the robustness, practicality, and effectiveness of our approach.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.09073","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.270018","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Gianlucca Zuin, Adriano Veloso","raw_content_length":1387,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1386,"language_detected":"en","key_concepts":{"key_phrases":["the Multiplicity","Performant Models","Explanations","models","arXiv250909073v2 Announce Type","Abstract","past observations","their effectiveness","new data","the essence"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Multiplicity":2.0,"Performant Models":2.0,"Explanations":2.0,"models":2.0,"arXiv250909073v2 Announce Type":1.0,"Abstract":1.0,"past observations":1.0,"their effectiveness":1.0,"new data":1.0,"the essence":1.0}},"age_hours":2.7699249655555556,"is_recent":true,"quality_score":0.7,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9007,"joy":0.0123,"surprise":0.0627,"sadness":0.0042,"fear":0.0086,"anger":0.008,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel machine learning method (Rashomon Ensemble) to improve model generalization, validated on real-world datasets. The concrete action is the strategic selection of models to improve predictive accuracy, demonstrated with up to 0.20+ AUROC improvements. However, it is still in the research/pilot phase with no large-scale deployment data available, limiting its immediate sustainability impact.","key_impact_metrics":["0.20+ AUROC improvements","Rashomon ratio"],"technology_tags":["machine learning","ensemble learning","model generalization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:35.769914Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2fe21b555199","title":"Fused Lasso Improves Accuracy of Co","content":"arXiv:2509.09413v2 Announce Type: replace Abstract: Co-occurrence network inference algorithms have significantly advanced our understanding of microbiome communities. However, these algorithms typically analyze microbial associations within samples collected from a single environmental niche, often capturing only static snapshots rather than dynamic microbial processes. Previous studies have commonly grouped samples from different environmental niches together without fully considering how microbial communities adapt their associations when faced with varying ecological conditions. Our study addresses this limitation by explicitly investigating both spatial and temporal dynamics of microbial communities. We analyzed publicly available microbiome abundance data across multiple locations and time points, to evaluate algorithm performance in predicting microbial associations using our proposed Same-All Cross-validation (SAC) framework. SAC evaluates algorithms in two distinct scenarios: training and testing within the same environmental niche (Same), and training and testing on combined data from multiple environmental niches (All). To overcome the limitations of conventional algorithms, we propose fuser, an algorithm that, while not entirely new in machine learning, is novel for microbiome community network inference. It retains subsample-specific signals while simultaneously sharing relevant information across environments during training. Unlike standard approaches that infer a single generalized network from combined data, fuser generates distinct, environment-specific predictive networks. Our results demonstrate that fuser achieves comparable predictive performance to existing algorithms such as glmnet when evaluated within homogeneous environments (Same), and notably reduces test error compared to baseline algorithms in cross-environment (All) scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.09413","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.270835","language":"en","tags":["computer-science","cslg","q-biope","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Daniel Agyapong, Briana H. Beatty, Peter G. Kennedy, Toby D. Hocking","raw_content_length":1891,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["Same-All Cross","SAC"],"persons":[],"locations":[],"monetary":[]},"char_count":1890,"language_detected":"en","key_concepts":{"key_phrases":["Fused Lasso","Accuracy","samples","arXiv250909413v2 Announce Type","Abstract","Co-occurrence network inference algorithms","our understanding","microbiome communities","these algorithms","microbial associations"],"filter_categories":{"ai_ml":["Co-occurrence network inference algorithms","these algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fused Lasso":2.0,"Accuracy":2.0,"samples":2.0,"arXiv250909413v2 Announce Type":1.0,"Abstract":1.0,"Co-occurrence network inference algorithms":1.0,"our understanding":1.0,"microbiome communities":1.0,"these algorithms":1.0,"microbial associations":1.0}},"age_hours":2.7699537819444444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8655,"joy":0.0135,"surprise":0.0663,"sadness":0.0127,"fear":0.0089,"anger":0.0206,"disgust":0.0125},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm (fuser) for analyzing microbiome data to better understand microbial communities across different environments and time points. While the algorithm shows improved predictive performance compared to existing methods, it is still in the research phase and lacks concrete deployment or quantified environmental impact. The study analyzes publicly available data and demonstrates the algorithm's performance using a Same-All Cross-validation framework.","key_impact_metrics":["Reduces test error compared to baseline algorithms in cross-environment scenarios"],"technology_tags":["microbiome analysis","co-occurrence network inference","machine learning","fused lasso"],"sdg_alignment":[2,13,15],"analyzed_at":"2025-10-29T12:47:39.263829Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a51fff4c7d72","title":"Towards Secure and Explainable Smart Contract Generation with Security","content":"arXiv:2509.09942v2 Announce Type: replace Abstract: Smart contracts automate the management of high-value assets, where vulnerabilities can lead to catastrophic financial losses. This challenge is amplified in Large Language Models (LLMs) by two interconnected failures: they operate as unauditable \"black boxes\" lacking a transparent reasoning process, and consequently, generate code riddled with critical security vulnerabilities. To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a novel framework for secure and explainable smart contract generation. It begins with Continual Pre-training (CPT) to specialize the model. We then apply Long Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated reasoning-and-code samples to train the model to emulate human security analysis. Finally, to directly mitigate vulnerabilities, we employ Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement learning phase that refines the generation policy by optimizing a weighted reward signal for compilation success, security compliance, and format correctness. Evaluated against 17 baselines on a benchmark of 756 real-world functions, SmartCoder-R1 establishes a new state of the art, achieving top performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This FullRate marks a 45.79% relative improvement over the strongest baseline, DeepSeek-R1. Crucially, its generated reasoning also excels in human evaluations, achieving high-quality ratings for Functionality (82.7%), Security (85.3%), and Clarity (90.7%).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.09942","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.271240","language":"en","tags":["computer-science","csai","preprints","cscr","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Lei Yu, Jingyuan Zhang, Xin Wang, Jiajia Ma, Li Yang, Fengjun Zhang","raw_content_length":1669,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["SmartCoder-R1","Large Language Models","CPT","Security-Aware Group Relative Policy Opt","Qwen2.5-Coder-7B"],"persons":["Long Chain"],"locations":[],"monetary":[]},"char_count":1668,"language_detected":"en","key_concepts":{"key_phrases":["Secure","Explainable Smart Contract Generation","Security","Announce Type","Smart contracts","the management","high-value assets","vulnerabilities","catastrophic financial losses","This challenge"],"filter_categories":{"ai_ml":["Explainable Smart Contract Generation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Secure":2.0,"Explainable Smart Contract Generation":2.0,"Security":2.0,"Announce Type":1.0,"Smart contracts":1.0,"the management":1.0,"high-value assets":1.0,"vulnerabilities":1.0,"catastrophic financial losses":1.0,"This challenge":1.0}},"age_hours":2.769969098333333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.354,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0708,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.789,"joy":0.0046,"surprise":0.0197,"sadness":0.015,"fear":0.1342,"anger":0.0274,"disgust":0.0101},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for generating secure smart contracts, showing improved performance on key metrics like ComPass (87.70%) and VulRate (8.60%) compared to baselines. While promising, it's still in the applied research stage with no evidence of real-world deployment or economic viability. The potential climate impact is indirect, as secure smart contracts could enable more efficient and transparent climate-related transactions, but this is not directly measured.","key_impact_metrics":["ComPass 87.70%","VulRate 8.60%"],"technology_tags":["Smart Contracts","Large Language Models","Security"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:42.801213Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bc48602d2924","title":"Recovery Performance of PhaseLift for Phase Retrieval from Coded Diffraction Patterns","content":"arXiv:2509.10300v2 Announce Type: replace Abstract: The PhaseLift algorithm is an effective convex method for solving the phase retrieval problem from Fourier measurements with coded diffraction patterns (CDP). While exact reconstruction guarantees are well-established in the noiseless case, the stability of recovery under noise remains less well understood. In particular, when the measurements are corrupted by an additive noise vector $\\vw \\in \\R^m$, existing recovery bounds scale on the order of $\\norm{\\vw}$, which is conjectured to be suboptimal. More recently, Soltanolkotabi conjectured that the optimal PhaseLift recovery bound should scale with the average noise magnitude, that is, on the order of $\\norm{\\vw}/\\sqrt m$. However, establishing this theoretically is considerably more challenging and has remained an open problem. In this paper, we focus on this conjecture and prove that under adversarial noise, the recovery error of PhaseLift is bounded by $O\\xkh{ \\sqrt{\\frac{\\norm{\\vw}\\log n }{\\sqrt m}}}\\norm{\\vx_0}$. Here, $\\vx_0 \\in \\C^n$ is the signals we aim to recover. Moreover, for mean-zero sub-Gaussian noise vector $\\vw \\in \\R^m$, a upper error bound and its corresponding minimax lower bound are also provided. Our results represent a significant step toward Soltanolkotabi's conjecture, offering new insights into the stability of PhaseLift under noisy CDP measurements.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.10300","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.271769","language":"en","tags":["preprints","research","csna","mathit","mathna","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Meng Huang, Jinming Wen, Ran Zhang","raw_content_length":1400,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["\\vw \\in \\R^m$","Coded Diffraction Patterns arXiv:2509.10300v2 Announce Type:","CDP","Fourier"],"persons":[],"locations":["Soltanolkotabi"],"monetary":["\\norm{\\vw}$"]},"char_count":1399,"language_detected":"en","key_concepts":{"key_phrases":["Recovery Performance","PhaseLift","Phase Retrieval","Coded Diffraction Patterns","arXiv250910300v2 Announce Type","Abstract","The PhaseLift algorithm","an effective convex method","the phase retrieval problem","Fourier measurements"],"filter_categories":{"ai_ml":["The PhaseLift algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Recovery Performance":2.0,"PhaseLift":2.0,"Phase Retrieval":2.0,"Coded Diffraction Patterns":2.0,"arXiv250910300v2 Announce Type":1.0,"Abstract":1.0,"The PhaseLift algorithm":1.0,"an effective convex method":1.0,"the phase retrieval problem":1.0,"Fourier measurements":1.0}},"age_hours":2.769983983611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.792,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5584,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4191,"joy":0.0082,"surprise":0.0359,"sadness":0.0746,"fear":0.0941,"anger":0.1109,"disgust":0.2572},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the PhaseLift algorithm for phase retrieval from coded diffraction patterns. While the research aims to improve the stability of the algorithm under noisy conditions, it is still in the theoretical stage and lacks concrete deployment or measurable climate impact. The research is peer-reviewed, increasing its technical credibility, but its economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["Phase Retrieval","Coded Diffraction Patterns","PhaseLift Algorithm"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:46.461968Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1c0bab57f9f6","title":"CrunchLLM: Multitask LLMs for Structured Business Reasoning and Outcome Prediction","content":"arXiv:2509.10698v2 Announce Type: replace Abstract: Predicting the success of start-up companies, defined as achieving an exit through acquisition or IPO, is a critical problem in entrepreneurship and innovation research. Datasets such as Crunchbase provide both structured information (e.g., funding rounds, industries, investor networks) and unstructured text (e.g., company descriptions), but effectively leveraging this heterogeneous data for prediction remains challenging. Traditional machine learning approaches often rely only on structured features and achieve moderate accuracy, while large language models (LLMs) offer rich reasoning abilities but struggle to adapt directly to domain-specific business data. We present \\textbf{CrunchLLM}, a domain-adapted LLM framework for startup success prediction. CrunchLLM integrates structured company attributes with unstructured textual narratives and applies parameter-efficient fine-tuning strategies alongside prompt optimization to specialize foundation models for entrepreneurship data. Our approach achieves accuracy exceeding 80\\% on Crunchbase startup success prediction, significantly outperforming traditional classifiers and baseline LLMs. Beyond predictive performance, CrunchLLM provides interpretable reasoning traces that justify its predictions, enhancing transparency and trustworthiness for financial and policy decision makers. This work demonstrates how adapting LLMs with domain-aware fine-tuning and structured--unstructured data fusion can advance predictive modeling of entrepreneurial outcomes. CrunchLLM contributes a methodological framework and a practical tool for data-driven decision making in venture capital and innovation policy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.10698","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.272171","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Rabeya Tus Sadia, Qiang Cheng","raw_content_length":1718,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["IPO","Crunchbase"],"persons":[],"locations":[],"monetary":[]},"char_count":1717,"language_detected":"en","key_concepts":{"key_phrases":["CrunchLLM Multitask LLMs","Structured Business Reasoning and Outcome Prediction","Announce Type","Abstract","the success","start-up companies","an exit","acquisition","IPO","a critical problem"],"filter_categories":{"ai_ml":["CrunchLLM Multitask LLMs"],"business_innovation":["acquisition","IPO"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CrunchLLM Multitask LLMs":2.0,"Structured Business Reasoning and Outcome Prediction":2.0,"Announce Type":1.0,"Abstract":1.0,"the success":1.0,"start-up companies":1.0,"an exit":1.0,"acquisition":1.0,"IPO":1.0,"a critical problem":1.0}},"age_hours":2.769998398333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8672,"joy":0.0151,"surprise":0.0482,"sadness":0.0051,"fear":0.044,"anger":0.0158,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a domain-adapted LLM framework (CrunchLLM) for startup success prediction. While it achieves accuracy exceeding 80% on Crunchbase data, it's still in the applied research stage with no concrete deployment or real-world impact on sustainability. The potential climate impact is low as it primarily focuses on financial predictions, not direct environmental interventions.","key_impact_metrics":["Accuracy exceeding 80%"],"technology_tags":["Large Language Models","Machine Learning","Data Analytics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:47:49.867971Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f10e554113f","title":"Follow","content":"arXiv:2509.10796v3 Announce Type: replace Abstract: Robot person following (RPF) -- mobile robots that follow and assist a specific person -- has emerging applications in personal assistance, security patrols, eldercare, and logistics. To be effective, such robots must follow the target while ensuring safety and comfort for both the target and surrounding people. In this work, we present the first comprehensive study of RPF, which (i) surveys representative scenarios, motion-planning methods, and evaluation metrics with a focus on safety and comfort; (ii) introduces Follow-Bench, a unified benchmark simulating diverse scenarios, including various target trajectory patterns, crowd dynamics, and environmental layouts; and (iii) re-implements six representative RPF planners, ensuring that both safety and comfort are systematically considered. Moreover, we evaluate the two best-performing planners from our benchmark on a differential-drive robot to provide insights into the real-world deployment of RPF planners. Extensive simulation and real-world experiments provide a quantitative study of the safety-comfort trade-offs of existing planners, while revealing open challenges and future research directions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.10796","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.272568","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Hanjing Ye, Weixi Situ, Jianwei Peng, Yu Zhan, Bingyi Xia, Kuanqi Cai, Hong Zhang","raw_content_length":1220,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["RPF"],"persons":["Follow-Bench"],"locations":[],"monetary":[]},"char_count":1219,"language_detected":"en","key_concepts":{"key_phrases":["RPF","arXiv250910796v3 Announce Type","Abstract","Robot person","mobile robots","a specific person","emerging applications","personal assistance","security patrols","eldercare"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"RPF":2.0,"arXiv250910796v3 Announce Type":1.0,"Abstract":1.0,"Robot person":1.0,"mobile robots":1.0,"a specific person":1.0,"emerging applications":1.0,"personal assistance":1.0,"security patrols":1.0,"eldercare":1.0}},"age_hours":2.770013546111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9169,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9427,"joy":0.0109,"surprise":0.0177,"sadness":0.0032,"fear":0.0145,"anger":0.0084,"disgust":0.0026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a benchmark and simulation environment for robot person following (RPF). The concrete action is the development of a simulation environment and the re-implementation of existing RPF planners. Evidence is provided through extensive simulation and real-world experiments, but deployment is limited to a differential-drive robot, indicating a pilot stage. The climate impact is indirect, potentially enabling more efficient logistics or eldercare, but not directly reducing emissions.","key_impact_metrics":["Safety-comfort trade-offs (quantitative study)"],"technology_tags":["Robot Person Following","Motion Planning","Simulation"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:47:53.476152Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f22fbd7fd46","title":"Dynamic Span Interaction and Graph","content":"arXiv:2509.11604v2 Announce Type: replace Abstract: Entity-level sentiment classification involves identifying the sentiment polarity linked to specific entities within text. This task poses several challenges: effectively modeling the subtle and complex interactions between entities and their surrounding sentiment expressions; capturing dependencies that may span across sentences; and ensuring consistent sentiment predictions for multiple mentions of the same entity through coreference resolution. Additionally, linguistic phenomena such as negation, ambiguity, and overlapping opinions further complicate the analysis. These complexities make entity-level sentiment classification a difficult problem, especially in real-world, noisy textual data. To address these issues, we propose SpanEIT, a novel framework integrating dynamic span interaction and graph-aware memory mechanisms for enhanced entity-sentiment relational modeling. SpanEIT builds span-based representations for entities and candidate sentiment phrases, employs bidirectional attention for fine-grained interactions, and uses a graph attention network to capture syntactic and co-occurrence relations. A coreference-aware memory module ensures entity-level consistency across documents. Experiments on FSAD, BARU, and IMDB datasets show SpanEIT outperforms state-of-the-art transformer and hybrid baselines in accuracy and F1 scores. Ablation and interpretability analyses validate the effectiveness of our approach, underscoring its potential for fine-grained sentiment analysis in applications like social media monitoring and customer feedback analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.11604","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.273726","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Md. Mithun Hossain,  Sanjara, Md. Shakil Hossain, Sudipto Chaki","raw_content_length":1631,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1630,"language_detected":"en","key_concepts":{"key_phrases":["Dynamic Span Interaction","Graph","Announce Type","Abstract","Entity-level sentiment classification","the sentiment polarity","specific entities","text","This task","several challenges"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dynamic Span Interaction":2.0,"Graph":2.0,"Announce Type":1.0,"Abstract":1.0,"Entity-level sentiment classification":1.0,"the sentiment polarity":1.0,"specific entities":1.0,"text":1.0,"This task":1.0,"several challenges":1.0}},"age_hours":2.7700559730555554,"is_recent":true,"quality_score":0.7,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9074,"joy":0.0097,"surprise":0.0389,"sadness":0.0096,"fear":0.0211,"anger":0.0097,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (SpanEIT) for entity-level sentiment classification. While it shows improved accuracy and F1 scores on benchmark datasets, it is still in the research phase with no concrete deployment or measurable environmental outcomes. The impact on sustainability is indirect, potentially improving the accuracy of sentiment analysis in sustainability-related texts, but this is theoretical.","key_impact_metrics":["Accuracy improvement on FSAD, BARU, and IMDB datasets","F1 score improvement on FSAD, BARU, and IMDB datasets"],"technology_tags":["Natural Language Processing","Sentiment Analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:47:56.911079Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1b6f7b72bbc5","title":"Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self","content":"arXiv:2509.11645v2 Announce Type: replace Abstract: This study presents the first comprehensive evaluation of Multimodal Large Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS) self-management. We constructed a database of approximately 3,000 anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a `Divide and Conquer' framework consisting of a visual question-answering task, a domain knowledge assessment task, and a patient education counseling assessment task. Our investigation revealed limitations of MLLMs' ability in interpreting complex spinal radiographs and comprehending AIS care knowledge. To address these, we pioneered enhancing MLLMs with spinal keypoint prompting and compiled an AIS knowledge base for retrieval augmented generation (RAG), respectively. Results showed varying effectiveness of visual prompting across different architectures, while RAG substantially improved models' performances on the knowledge assessment task. Our findings indicate current MLLMs are far from capable in realizing personalized assistant in AIS care. The greatest challenge lies in their abilities to obtain accurate detections of spinal deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.11645","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.274488","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Zhaolong Wu, Pu Luo, Nan Meng, Jason Pui Yin Cheung, Teng Zhang","raw_content_length":1263,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["AIS","Multimodal Large Language Models","Adolescent Idiopathic Scoliosis"],"persons":[],"locations":[],"monetary":[]},"char_count":1262,"language_detected":"en","key_concepts":{"key_phrases":["Multimodal Large Language Models","Adolescent Idiopathic Scoliosis Self","arXiv250911645v2 Announce Type","Abstract","This study","the first comprehensive evaluation","MLLMs","AIS","a database","approximately 3000 anteroposterior X"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"],"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multimodal Large Language Models":3.0,"Adolescent Idiopathic Scoliosis Self":2.0,"arXiv250911645v2 Announce Type":1.0,"Abstract":1.0,"This study":1.0,"the first comprehensive evaluation":1.0,"MLLMs":1.0,"AIS":1.0,"a database":1.0,"approximately 3000 anteroposterior X":1.0}},"age_hours":2.770085700833333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8715,"joy":0.0346,"surprise":0.0409,"sadness":0.0082,"fear":0.017,"anger":0.0189,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the application of MLLMs for AIS self-management, focusing on improving diagnostic accuracy and patient education. The study identifies limitations in current MLLMs, particularly in spinal deformity detection (best accuracy: 0.55) and direction (best accuracy: 0.13), and proposes enhancements like spinal keypoint prompting and RAG. It is still in the applied research phase with no real-world deployment.","key_impact_metrics":["spinal deformity detection accuracy: 0.55","spinal deformity direction accuracy: 0.13"],"technology_tags":["Multimodal Large Language Models","Spinal Keypoint Prompting","Retrieval Augmented Generation"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:48:00.255434Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
