{"id":"science_arxiv_cs_25c340722fbf","title":"VisRAG 2.0: Evidence-Guided Multi","content":"arXiv:2510.09733v1 Announce Type: new Abstract: Visual retrieval-augmented generation (VRAG) augments vision-language models (VLMs) with external visual knowledge to ground reasoning and reduce hallucinations. Yet current VRAG systems often fail to reliably perceive and integrate evidence across multiple images, leading to weak grounding and erroneous conclusions. In this paper, we propose EVisRAG, an end-to-end framework that learns to reason with evidence-guided multi-image to address this issue. The model first observes retrieved images and records per-image evidence, then derives the final answer from the aggregated evidence. To train EVisRAG effectively, we introduce Reward-Scoped Group Relative Policy Optimization (RS-GRPO), which binds fine-grained rewards to scope-specific tokens to jointly optimize visual perception and reasoning abilities of VLMs. Experimental results on multiple visual question answering benchmarks demonstrate that EVisRAG delivers substantial end-to-end gains over backbone VLM with 27\\% improvements on average. Further analysis shows that, powered by RS-GRPO, EVisRAG improves answer accuracy by precisely perceiving and localizing question-relevant evidence across multiple images and deriving the final answer from that evidence, much like a real detective.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09733","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.554809","language":"en","tags":["computer-science","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Yubo Sun, Chunyi Peng, Yukun Yan, Shi Yu, Zhenghao Liu, Chi Chen, Zhiyuan Liu, Maosong Sun","raw_content_length":1305,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["Reward-Scoped Group Relative Policy Optimization","Evidence-Guided Multi arXiv:2510.09733v1","VRAG"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1304,"language_detected":"en","key_concepts":{"key_phrases":["Evidence-Guided Multi","arXiv251009733v1 Announce Type","new Abstract","Visual retrieval-augmented generation","VRAG","vision-language models","VLMs","external visual knowledge","reasoning","hallucinations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Evidence-Guided Multi":2.0,"arXiv251009733v1 Announce Type":1.0,"new Abstract":1.0,"Visual retrieval-augmented generation":1.0,"VRAG":1.0,"vision-language models":1.0,"VLMs":1.0,"external visual knowledge":1.0,"reasoning":1.0,"hallucinations":1.0}},"age_hours":2.7452367697222226,"is_recent":true,"quality_score":1.0,"sentiment_score":0.7595000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8481,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8406,"joy":0.0048,"surprise":0.033,"sadness":0.0344,"fear":0.0283,"anger":0.037,"disgust":0.0219},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel AI framework (EVisRAG) that improves visual question answering accuracy by 27% on average. This is achieved through a new training method (RS-GRPO) that enhances visual perception and reasoning. While promising, it is still in the applied research stage with no indication of real-world deployment or economic viability.","key_impact_metrics":["answer accuracy improvement 27%"],"technology_tags":["visual question answering","AI","machine learning","vision-language models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T10:58:04.135071Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_124940f989d0","title":"ARROW: An Adaptive Rollout and Routing Method for Global Weather Forecasting","content":"arXiv:2510.09734v1 Announce Type: new Abstract: Weather forecasting is a fundamental task in spatiotemporal data analysis, with broad applications across a wide range of domains. Existing data-driven forecasting methods typically model atmospheric dynamics over a fixed short time interval (e.g., 6 hours) and rely on naive autoregression-based rollout for long-term forecasting (e.g., 138 hours). However, this paradigm suffers from two key limitations: (1) it often inadequately models the spatial and multi-scale temporal dependencies inherent in global weather systems, and (2) the rollout strategy struggles to balance error accumulation with the capture of fine-grained atmospheric variations. In this study, we propose ARROW, an Adaptive-Rollout Multi-scale temporal Routing method for Global Weather Forecasting. To contend with the first limitation, we construct a multi-interval forecasting model that forecasts weather across different time intervals. Within the model, the Shared-Private Mixture-of-Experts captures both shared patterns and specific characteristics of atmospheric dynamics across different time scales, while Ring Positional Encoding accurately encodes the circular latitude structure of the Earth when representing spatial information. For the second limitation, we develop an adaptive rollout scheduler based on reinforcement learning, which selects the most suitable time interval to forecast according to the current weather state. Experimental results demonstrate that ARROW achieves state-of-the-art performance in global weather forecasting, establishing a promising paradigm in this field.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09734","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.555225","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Jindong Tian, Yifei Ding, Ronghui Xu, Hao Miao, Chenjuan Guo, Bin Yang","raw_content_length":1627,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["ARROW","Adaptive-Rollout Multi"],"persons":[],"locations":[],"monetary":[]},"char_count":1626,"language_detected":"en","key_concepts":{"key_phrases":["ARROW","An Adaptive Rollout","Routing","Method","Global Weather Forecasting","arXiv251009734v1 Announce Type","new Abstract","Weather forecasting","a fundamental task","spatiotemporal data analysis"],"filter_categories":{"research_academic":["Method"],"engineering":["spatiotemporal data analysis"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ARROW":2.0,"An Adaptive Rollout":2.0,"Routing":2.0,"Method":2.0,"Global Weather Forecasting":2.0,"arXiv251009734v1 Announce Type":1.0,"new Abstract":1.0,"Weather forecasting":1.0,"a fundamental task":1.0,"spatiotemporal data analysis":1.0}},"age_hours":2.745252803888889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8348,"joy":0.0039,"surprise":0.0244,"sadness":0.0096,"fear":0.0675,"anger":0.0311,"disgust":0.0288},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (ARROW) for global weather forecasting, which could indirectly improve climate models and resource allocation related to climate adaptation. The technical credibility is supported by experimental results, but economic viability and deployment readiness are low as it's still in the research phase. The impact is limited by the lack of concrete deployment and measurable outcomes in terms of GHG reduction or climate adaptation benefits.","key_impact_metrics":["State-of-the-art performance in global weather forecasting","Improved accuracy in long-term forecasting (e.g., 138 hours)"],"technology_tags":["Weather Forecasting","Reinforcement Learning","Spatiotemporal Data Analysis"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T10:58:07.149414Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1daf07e32d92","title":"InterCorpRel","content":"arXiv:2510.09735v1 Announce Type: new Abstract: Identifying inter-firm relationships such as supply and competitive ties is critical for financial analysis and corporate governance, yet remains challenging due to the scale, sparsity, and contextual dependence of corporate data. Graph-based methods capture structure but miss semantic depth, while large language models (LLMs) excel at text but remain limited in their ability to represent relational dependencies. To address this, we propose InterCorpRel-LLM, a cross-modal framework that integrates GNNs with LLMs, supported by a proprietary dataset derived from FactSet supply chain records and three tailored training tasks: company graph matching, industry classification, and supply relation prediction. This design enables effective joint modeling of structure and semantics. Experiments show that InterCorpRel-LLM substantially outperforms strong baselines, including GPT-5, on a supply relation identification task, achieving an F-score of 0.8543 vs. 0.2287 with only a 7B-parameter backbone and lightweight training. The model also generalizes to zero-shot competitor identification, underscoring its ability to capture nuanced inter-firm dynamics. Our framework thus provides analysts and strategists with a robust tool for mapping and reasoning about complex corporate networks, enhancing decision-making and risk management in dynamic markets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09735","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.555653","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Qianyou Sun, Jiexin Zheng, Bohan Jin, Lihua Chen, Yijie Peng","raw_content_length":1407,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["FactSet"],"persons":[],"locations":["InterCorpRel"],"monetary":[]},"char_count":1406,"language_detected":"en","key_concepts":{"key_phrases":["InterCorpRel","arXiv251009735v1 Announce Type","new Abstract","inter-firm relationships","supply","competitive ties","financial analysis","corporate governance","the scale","sparsity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"InterCorpRel":2.0,"arXiv251009735v1 Announce Type":1.0,"new Abstract":1.0,"inter-firm relationships":1.0,"supply":1.0,"competitive ties":1.0,"financial analysis":1.0,"corporate governance":1.0,"the scale":1.0,"sparsity":1.0}},"age_hours":2.745267251111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9007,"joy":0.0068,"surprise":0.0431,"sadness":0.0128,"fear":0.0167,"anger":0.0131,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework (InterCorpRel-LLM) for identifying inter-firm relationships, which could indirectly support sustainability efforts by improving risk management and decision-making in corporate networks. The model achieves an F-score of 0.8543 on a supply relation identification task. However, the direct climate impact is theoretical, and deployment is at the pilot stage, limiting the score.","key_impact_metrics":["F-score on supply relation identification: 0.8543"],"technology_tags":["Graph Neural Networks","Large Language Models","Cross-modal Framework"],"sdg_alignment":[8,9,12],"analyzed_at":"2025-10-29T10:58:10.547976Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ee124a70728f","title":"Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement","content":"arXiv:2510.09738v1 Announce Type: new Abstract: This research introduces the Judge's Verdict Benchmark, a novel two-step methodology to evaluate Large Language Models (LLMs) as judges for response accuracy evaluation tasks. We assess how well 54 LLMs can replicate human judgment when scoring responses from RAG (Retrieval-Augmented Generation) or Agentic pipelines against ground truth answers. Our methodology progresses from traditional correlation analysis to comprehensive Cohen's Kappa analysis that measures actual agreement patterns. The two-step approach includes: (1) a correlation test that filters judges with strong alignment, followed by (2) a human-likeness test using z-scores to identify two distinct judgment patterns: human-like judgment (|z| < 1) that mimics natural human variation, and super-consistent judgment (z > 1) that exceeds typical human-to-human agreement levels. This methodology reveals that 27 out of 54 tested LLMs achieve Tier 1 performance: 23 models exhibit human-like patterns that preserve the nuances of human judgment, while 4 models demonstrate super-consistent behavior, a pattern that could indicate either enhanced reliability or oversimplification of complex judgments. Testing 43 open-source models (1B-405B parameters) and 11 closed models (GPT, Gemini, Claude variants), we demonstrate that judge excellence is not solely dependent on model size but on specific training strategies. Our key contributions include: (1) establishing that correlation alone is insufficient for judge evaluation, (2) introducing a \"Turing Test for judges\" based on agreement patterns, and (3) providing a standardized benchmark for classifying LLM judges into distinct performance tiers for different evaluation needs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09738","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.556084","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Steve Han, Gilberto Titericz Junior, Tom Balough, Wenfei Zhou","raw_content_length":1749,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Agentic","RAG (Retrieval-Augmented Generation"],"persons":["Kappa","Verdict","Verdict Benchmark","Cohen"],"locations":[],"monetary":[]},"char_count":1748,"language_detected":"en","key_concepts":{"key_phrases":["Judges Verdict","A Comprehensive Analysis","LLM Judge Capability","Human Agreement","arXiv251009738v1 Announce Type","new Abstract","This research","the Judges Verdict Benchmark","a novel two-step methodology","Large Language Models"],"filter_categories":{"ai_ml":["LLM Judge Capability","Large Language Models"],"research_academic":["This research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Judges Verdict":2.0,"A Comprehensive Analysis":2.0,"LLM Judge Capability":2.0,"Human Agreement":2.0,"arXiv251009738v1 Announce Type":1.0,"new Abstract":1.0,"This research":1.0,"the Judges Verdict Benchmark":1.0,"a novel two-step methodology":1.0,"Large Language Models":1.0}},"age_hours":2.7452832116666666,"is_recent":true,"quality_score":1.0,"sentiment_score":9.511000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9022,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8836,"joy":0.0233,"surprise":0.0561,"sadness":0.0038,"fear":0.008,"anger":0.0168,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on evaluating LLMs as judges for response accuracy, which is a theoretical contribution. While it introduces a novel benchmark and methodology, it doesn't directly address climate change or environmental sustainability. The impact is indirect, potentially improving the accuracy of information related to sustainability, but it's currently at the applied research stage with no deployed technology or measurable environmental outcomes.","key_impact_metrics":["Cohen's Kappa analysis","z-scores"],"technology_tags":["Large Language Models","Retrieval-Augmented Generation","Agentic pipelines"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:58:13.572723Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_44b7c663f3ac","title":"Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry","content":"arXiv:2510.09740v1 Announce Type: new Abstract: Active Learning (AL) promises to reduce annotation cost by prioritizing informative samples, yet its reliability is undermined when labels are noisy or when the data distribution shifts. In practice, annotators make mistakes, rare categories are ambiguous, and conventional AL heuristics (uncertainty, diversity) often amplify such errors by repeatedly selecting mislabeled or redundant samples. We propose Reliable Active Learning via Neural Collapse Geometry (NCAL-R), a framework that leverages the emergent geometric regularities of deep networks to counteract unreliable supervision. Our method introduces two complementary signals: (i) a Class-Mean Alignment Perturbation score, which quantifies how candidate samples structurally stabilize or distort inter-class geometry, and (ii) a Feature Fluctuation score, which captures temporal instability of representations across training checkpoints. By combining these signals, NCAL-R prioritizes samples that both preserve class separation and highlight ambiguous regions, mitigating the effect of noisy or redundant labels. Experiments on ImageNet-100 and CIFAR100 show that NCAL-R consistently outperforms standard AL baselines, achieving higher accuracy with fewer labels, improved robustness under synthetic label noise, and stronger generalization to out-of-distribution data. These results suggest that incorporating geometric reliability criteria into acquisition decisions can make Active Learning less brittle to annotation errors and distribution shifts, a key step toward trustworthy deployment in real-world labeling pipelines. Our code is available at https://github.com/Vision-IIITD/NCAL.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09740","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.556911","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Atharv Goel, Sharat Agarwal, Saket Anand, Chetan Arora","raw_content_length":1704,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["NCAL","Neural Collapse Geometry","Class-Mean Alignment Perturbation","Feature Fluctuation"],"persons":["Announce Type","Unreliable Labels","Active Learning"],"locations":[],"monetary":[]},"char_count":1703,"language_detected":"en","key_concepts":{"key_phrases":["Reliable Active Learning","Unreliable Labels","Neural Collapse Geometry","Announce Type","new Abstract","Active Learning","annotation cost","informative samples","its reliability","labels"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reliable Active Learning":3.0,"Unreliable Labels":2.0,"Neural Collapse Geometry":2.0,"Announce Type":1.0,"new Abstract":1.0,"Active Learning":1.0,"annotation cost":1.0,"informative samples":1.0,"its reliability":1.0,"labels":1.0}},"age_hours":2.745312761388889,"is_recent":true,"quality_score":1.0,"sentiment_score":1.5460000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6908,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2276,"joy":0.0031,"surprise":0.0145,"sadness":0.0748,"fear":0.0575,"anger":0.302,"disgust":0.3205},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel active learning framework (NCAL-R) that improves the efficiency of machine learning models by reducing the need for labeled data. While the research shows improved accuracy with fewer labels on ImageNet-100 and CIFAR100, it is still in the applied research stage with no real-world deployment data. The potential climate impact is indirect, as it could improve the efficiency of models used for climate-related tasks, but this is not explicitly quantified.","key_impact_metrics":["Higher accuracy with fewer labels","Improved robustness under synthetic label noise"],"technology_tags":["Active Learning","Neural Networks","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T10:58:16.588887Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_781401196205","title":"Constructive Distortion: Improving MLLMs with Attention","content":"arXiv:2510.09741v1 Announce Type: new Abstract: Multimodal large language models (MLLMs) often miss small details and spatial relations in cluttered scenes, leading to errors in fine-grained perceptual grounding. We introduce AttWarp, a lightweight method that allocates more resolution to query-relevant content while compressing less informative areas, all while preserving global context. At test time, the approach uses an MLLM's cross-modal attention to perform rectilinear warping of the input image, reallocating spatial resolution toward regions the model deems important, without changing model weights or architecture. This attention-guided warping preserves all original image information but redistributes it non-uniformly, so small objects and subtle relationships become easier for the same model to read while the global layout remains intact. Across five benchmarks (TextVQA, GQA, DocVQA, POPE, MMMU) and four MLLMs (LLaVA, Qwen-VL, InternVL, and InstructBLIP), AttWarp consistently improves accuracy, strengthens compositional reasoning, and reduces hallucinations, outperforming four competitive baselines that manipulate raw images at test time. Together, these results show that attention-guided warping prioritizes information relevant to the query while preserving context, and that the same MLLMs perform better when given such warped inputs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09741","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.557312","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Dwip Dalal, Gautam Vashishtha, Utkarsh Mishra, Jeonghwan Kim, Madhav Kanda, Hyeonjeong Ha, Svetlana Lazebnik, Heng Ji, Unnat Jain","raw_content_length":1366,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["AttWarp"],"persons":["DocVQA","Qwen","GQA"],"locations":[],"monetary":[]},"char_count":1365,"language_detected":"en","key_concepts":{"key_phrases":["MLLMs","Constructive Distortion","Attention","Announce Type","new Abstract","Multimodal large language models","small details","spatial relations","cluttered scenes","errors"],"filter_categories":{"ai_ml":["MLLMs","Multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MLLMs":3.0,"Constructive Distortion":2.0,"Attention":2.0,"Announce Type":1.0,"new Abstract":1.0,"Multimodal large language models":1.0,"small details":1.0,"spatial relations":1.0,"cluttered scenes":1.0,"errors":1.0}},"age_hours":2.745328505833333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8987,"joy":0.0027,"surprise":0.0221,"sadness":0.0257,"fear":0.0076,"anger":0.0184,"disgust":0.0248},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (AttWarp) to improve MLLM performance by reallocating spatial resolution based on attention. The method is evaluated across five benchmarks and four MLLMs, showing consistent improvements in accuracy. However, it is currently in the research stage with no deployed units or real-world data related to sustainability impact.","key_impact_metrics":["Accuracy improvement across five benchmarks","Performance improvement on four MLLMs"],"technology_tags":["Multimodal Large Language Models","Attention Mechanisms","Image Processing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T10:58:19.945628Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fcdf33a266f8","title":"PatentVision: A multimodal method for drafting patent applications","content":"arXiv:2510.09762v1 Announce Type: new Abstract: Patent drafting is complex due to its need for detailed technical descriptions, legal compliance, and visual elements. Although Large Vision Language Models (LVLMs) show promise across various tasks, their application in automating patent writing remains underexplored. In this paper, we present PatentVision, a multimodal framework that integrates textual and visual inputs such as patent claims and drawings to generate complete patent specifications. Built on advanced LVLMs, PatentVision enhances accuracy by combining fine tuned vision language models with domain specific training tailored to patents. Experiments reveal it surpasses text only methods, producing outputs with greater fidelity and alignment with human written standards. Its incorporation of visual data allows it to better represent intricate design features and functional connections, leading to richer and more precise results. This study underscores the value of multimodal techniques in patent automation, providing a scalable tool to reduce manual workloads and improve consistency. PatentVision not only advances patent drafting but also lays the groundwork for broader use of LVLMs in specialized areas, potentially transforming intellectual property management and innovation processes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09762","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.558100","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Ruo Yang, Sai Krishna Reddy Mudhiganti, Manali Sharma","raw_content_length":1317,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["PatentVision"],"persons":[],"locations":[],"monetary":[]},"char_count":1316,"language_detected":"en","key_concepts":{"key_phrases":["PatentVision","A multimodal method","patent applications","arXiv251009762v1 Announce Type","new Abstract","Patent drafting","its need","detailed technical descriptions","legal compliance","visual elements"],"filter_categories":{"ai_ml":["detailed technical descriptions"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PatentVision":3.0,"A multimodal method":2.0,"patent applications":2.0,"arXiv251009762v1 Announce Type":1.0,"new Abstract":1.0,"Patent drafting":1.0,"its need":1.0,"detailed technical descriptions":1.0,"legal compliance":1.0,"visual elements":1.0}},"age_hours":2.7453546969444447,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9189,"joy":0.0148,"surprise":0.0414,"sadness":0.0037,"fear":0.0065,"anger":0.0103,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a multimodal framework for drafting patent applications using LVLMs. It's in the early stages of development (applied research), with no deployed units or customer contracts. The sustainability impact is indirect, potentially improving efficiency in innovation processes but without direct climate impact.","key_impact_metrics":[],"technology_tags":["Large Vision Language Models","Patent Automation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:58:22.686614Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e28c0ba59bd","title":"Network Traffic as a Scalable Ethnographic Lens for Understanding University Students' AI Tool Practices","content":"arXiv:2510.09763v1 Announce Type: new Abstract: AI-driven applications have become woven into students' academic and creative workflows, influencing how they learn, write, and produce ideas. Gaining a nuanced understanding of these usage patterns is essential, yet conventional survey and interview methods remain limited by recall bias, self-presentation effects, and the underreporting of habitual behaviors. While ethnographic methods offer richer contextual insights, they often face challenges of scale and reproducibility. To bridge this gap, we introduce a privacy-conscious approach that repurposes VPN-based network traffic analysis as a scalable ethnographic technique for examining students' real-world engagement with AI tools. By capturing anonymized metadata rather than content, this method enables fine-grained behavioral tracing while safeguarding personal information, thereby complementing self-report data. A three-week field deployment with university students reveals fragmented, short-duration interactions across multiple tools and devices, with intense bursts of activity coinciding with exam periods-patterns mirroring institutional rhythms of academic life. We conclude by discussing methodological, ethical, and empirical implications, positioning network traffic analysis as a promising avenue for large-scale digital ethnography on technology-in-practice.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09763","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.558524","language":"en","tags":["preprints","research","computer-science","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Donghan Hu, Rameen Mahmood, Annabelle David, Danny Yuxing Huang","raw_content_length":1386,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Understanding University Students' AI Tool Practices arXiv:2510.09763v1","Network Traffic"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1385,"language_detected":"en","key_concepts":{"key_phrases":["Network Traffic","a Scalable Ethnographic Lens","Understanding University Students AI Tool Practices","arXiv251009763v1 Announce Type","new Abstract","AI-driven applications","students academic and creative workflows","ideas","a nuanced understanding","these usage patterns"],"filter_categories":{"ai_ml":["Understanding University Students AI Tool Practices"],"research_academic":["Understanding University Students AI Tool Practices","students academic and creative workflows"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Network Traffic":2.0,"a Scalable Ethnographic Lens":2.0,"Understanding University Students AI Tool Practices":2.0,"arXiv251009763v1 Announce Type":1.0,"new Abstract":1.0,"AI-driven applications":1.0,"students academic and creative workflows":1.0,"ideas":1.0,"a nuanced understanding":1.0,"these usage patterns":1.0}},"age_hours":2.745448241944444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9162,"joy":0.0068,"surprise":0.0286,"sadness":0.0056,"fear":0.016,"anger":0.0115,"disgust":0.0153},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores a novel method for analyzing student AI tool usage through network traffic analysis. While it doesn't directly address climate change, understanding technology adoption patterns can indirectly inform strategies for promoting sustainable technology use. The field deployment with university students provides some empirical data, but the direct sustainability impact is minimal.","key_impact_metrics":["Three-week field deployment","Fragmented, short-duration interactions"],"technology_tags":["Network traffic analysis","AI tool usage"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T10:58:25.807728Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bb4d9edc8a72","title":"Leveraging Shared Prototypes for a Multimodal Pulse Motion Foundation Model","content":"arXiv:2510.09764v1 Announce Type: new Abstract: Modeling multi-modal time-series data is critical for capturing system-level dynamics, particularly in biosignals where modalities such as ECG, PPG, EDA, and accelerometry provide complementary perspectives on interconnected physiological processes. While recent self-supervised learning (SSL) advances have improved unimodal representation learning, existing multi-modal approaches often rely on CLIP-style contrastive objectives that overfit to easily aligned features and misclassify valid cross-modal relationships as negatives, resulting in fragmented and non-generalizable embeddings. To overcome these limitations, we propose ProtoMM, a novel SSL framework that introduces a shared prototype dictionary to anchor heterogeneous modalities in a common embedding space. By clustering representations around shared prototypes rather than explicit negative sampling, our method captures complementary information across modalities and provides a coherent \"common language\" for physiological signals. In this work, we focus on developing a Pulse Motion foundation model with ProtoMM and demonstrate that our approach outperforms contrastive-only and prior multimodal SSL methods, achieving state-of-the-art performance while offering improved interpretability of learned features.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09764","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.558927","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Wanting Mao, Maxwell A Xu, Harish Haresamudram, Mithun Saha, Santosh Kumar, James Matthew Rehg","raw_content_length":1330,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["ECG","EDA","SSL","PPG","CLIP"],"persons":[],"locations":[],"monetary":[]},"char_count":1329,"language_detected":"en","key_concepts":{"key_phrases":["Shared Prototypes","a Multimodal Pulse Motion Foundation Model","arXiv251009764v1","Announce Type","new Abstract","Modeling multi-modal time-series data","system-level dynamics","biosignals","modalities","ECG"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Shared Prototypes":2.0,"a Multimodal Pulse Motion Foundation Model":2.0,"arXiv251009764v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Modeling multi-modal time-series data":1.0,"system-level dynamics":1.0,"biosignals":1.0,"modalities":1.0,"ECG":1.0}},"age_hours":2.7454636838888886,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8689,"joy":0.0224,"surprise":0.0639,"sadness":0.0083,"fear":0.0135,"anger":0.0139,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel self-supervised learning framework (ProtoMM) for modeling multi-modal time-series data, specifically biosignals. While it demonstrates improved performance compared to existing methods, it remains at the prototype stage with no deployed units or real-world impact data. The climate impact is indirect, potentially enabling better health monitoring, but not directly reducing emissions.","key_impact_metrics":["State-of-the-art performance on pulse motion foundation model"],"technology_tags":["Self-Supervised Learning","Multi-modal Time-Series Data","Biosignals","ECG","PPG","EDA","Accelerometry"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T10:58:29.014689Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a6af72c6a412","title":"HeSRN: Representation Learning On Heterogeneous Graphs via Slot","content":"arXiv:2510.09767v1 Announce Type: new Abstract: Graph Transformers have recently achieved remarkable progress in graph representation learning by capturing long-range dependencies through self-attention. However, their quadratic computational complexity and inability to effectively model heterogeneous semantics severely limit their scalability and generalization on real-world heterogeneous graphs. To address these issues, we propose HeSRN, a novel Heterogeneous Slot-aware Retentive Network for efficient and expressive heterogeneous graph representation learning. HeSRN introduces a slot-aware structure encoder that explicitly disentangles node-type semantics by projecting heterogeneous features into independent slots and aligning their distributions through slot normalization and retention-based fusion, effectively mitigating the semantic entanglement caused by forced feature-space unification in previous Transformer-based models. Furthermore, we replace the self-attention mechanism with a retention-based encoder, which models structural and contextual dependencies in linear time complexity while maintaining strong expressive power. A heterogeneous retentive encoder is further employed to jointly capture both local structural signals and global heterogeneous semantics through multi-scale retention layers. Extensive experiments on four real-world heterogeneous graph datasets demonstrate that HeSRN consistently outperforms state-of-the-art heterogeneous graph neural networks and Graph Transformer baselines on node classification tasks, achieving superior accuracy with significantly lower computational complexity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09767","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.559334","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Yifan Lu, Ziyun Zou, Belal Alsinglawi, Islam Al-Qudah, Izzat Alsmadi, Feilong Tang, Pengfei Jiao, Shoaib Jameel","raw_content_length":1638,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["Retentive Network","Transformer","Slot arXiv:2510.09767v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1637,"language_detected":"en","key_concepts":{"key_phrases":["HeSRN","Representation Learning","Heterogeneous Graphs","Slot","arXiv251009767v1","Announce Type","new Abstract","Graph Transformers","remarkable progress","graph representation"],"filter_categories":{"ai_ml":["Graph Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HeSRN":3.0,"Representation Learning":2.0,"Heterogeneous Graphs":2.0,"Slot":2.0,"arXiv251009767v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Graph Transformers":1.0,"remarkable progress":1.0,"graph representation":1.0}},"age_hours":2.7454778524999996,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8473,"joy":0.0124,"surprise":0.0438,"sadness":0.0315,"fear":0.0217,"anger":0.029,"disgust":0.0143},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel graph representation learning method (HeSRN) that achieves superior accuracy with significantly lower computational complexity on node classification tasks compared to state-of-the-art methods. This could potentially improve the efficiency of various applications, including those related to sustainability, but it is currently in the research phase with no deployed units or real-world data demonstrating climate impact. The claim of lower computational complexity is a concrete action, and the superior accuracy is a measurable outcome, but it's not directly tied to a specific climate benefit yet.","key_impact_metrics":["lower computational complexity","superior accuracy"],"technology_tags":["graph representation learning","heterogeneous graphs","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:58:32.199490Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_28428effe1bb","title":"Gold Panning: Turning Positional Bias into Signal for Multi","content":"arXiv:2510.09770v1 Announce Type: new Abstract: Large language models exhibit a strong position bias in multi-document contexts, systematically prioritizing information based on location rather than relevance. While existing approaches treat this bias as noise to be mitigated, we introduce Gold Panning Bandits, a framework that leverages position bias as a diagnostic signal: by reordering documents and observing shifts in the model's responses, we can efficiently identify the most relevant content. We frame the problem of choosing reorderings as a bipartite matching problem. While an optimal assignment can be computed at each iteration with the Hungarian algorithm in $O(N^3)$ time, we propose a greedy $O(N \\log N)$ strategy that achieves comparable performance by prioritizing the placement of the most uncertain documents in the most informative positions. Our approach identifies relevant documents using up to 65\\% fewer language model queries than random permutation baselines on knowledge-intensive NLP tasks, substantially reducing computational cost without model retraining. This work demonstrates that inherent LLM biases can be transformed from liabilities into assets for efficient, inference-time optimization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09770","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.560127","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Adam Byerly, Daniel Khashabi","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["N)$","Signal"],"persons":["Bias"],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["Gold Panning","Positional Bias","Signal","Multi","arXiv251009770v1 Announce Type","new Abstract","Large language models","a strong position bias","multi-document contexts","information"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gold Panning":2.0,"Positional Bias":2.0,"Signal":2.0,"Multi":2.0,"arXiv251009770v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"a strong position bias":1.0,"multi-document contexts":1.0,"information":1.0}},"age_hours":2.7455094208333333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9095,"joy":0.0081,"surprise":0.0309,"sadness":0.0061,"fear":0.0145,"anger":0.0152,"disgust":0.0157},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores a method to improve the efficiency of large language models (LLMs) by leveraging position bias to identify relevant information. The concrete action is the development of an algorithm that reorders documents to reduce the number of queries needed. The evidence supporting this is the claim of a 65% reduction in language model queries compared to random baselines, although this is not independently verified and is still in a research phase.","key_impact_metrics":["65% fewer language model queries"],"technology_tags":["Large Language Models","Information Retrieval","Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:58:35.226354Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6ecb4afc2943","title":"A Generic Machine Learning Framework for Radio Frequency Fingerprinting","content":"arXiv:2510.09775v1 Announce Type: new Abstract: Fingerprinting Radio Frequency (RF) emitters typically involves finding unique emitter characteristics that are featured in their transmitted signals. These fingerprints are nuanced but sufficiently detailed, motivating the pursuit of methods that can successfully extract them. The most granular downstream task is known as Specific Emitter Identification (SEI), which requires a well informed RF fingerprinting (RFF) approach for it to be successful. RFF and SEI have a long history, with numerous application areas in defence and civilian contexts such as signal intelligence, electronic surveillance, physical-layer authentication of wireless communication devices, to name a few. RFF methods also support many other downstream tasks such as Emitter Data Association (EDA) and RF Emitter Clustering (RFEC) and are applicable to a range of transmission types. In recent years, data-driven approaches have become popular in the RFF domain due to their ability to automatically learn intricate fingerprints from raw data. These methods generally deliver superior performance when compared to traditional techniques. The more traditional approaches are often labour-intensive, inflexible and only applicable to a particular emitter type or transmission scheme. Therefore, we consider data-driven Machine Learning (ML)-enabled RFF. In particular, we propose a generic framework for ML-enabled RFF which is inclusive of several popular downstream tasks such as SEI, EDA and RFEC. Each task is formulated as a RF fingerprint-dependent task. A variety of use cases using real RF datasets are presented here to demonstrate the framework for a range of tasks and application areas, such as spaceborne surveillance, signal intelligence and countering drones.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09775","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.561351","language":"en","tags":["statml","computer-science","cslg","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Alex Hiles, Bashar I. Ahmad","raw_content_length":1800,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["Specific Emitter Identification","EDA","Fingerprinting Radio Frequency","Emitter Data Association","SEI"],"persons":[],"locations":[],"monetary":[]},"char_count":1799,"language_detected":"en","key_concepts":{"key_phrases":["A Generic Machine Learning Framework","Radio Frequency Fingerprinting","arXiv251009775v1 Announce Type","new Abstract","Fingerprinting Radio Frequency RF emitters","unique emitter characteristics","their transmitted signals","These fingerprints","the pursuit","methods"],"filter_categories":{"ai_ml":["A Generic Machine Learning Framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Generic Machine Learning Framework":2.0,"Radio Frequency Fingerprinting":2.0,"arXiv251009775v1 Announce Type":1.0,"new Abstract":1.0,"Fingerprinting Radio Frequency RF emitters":1.0,"unique emitter characteristics":1.0,"their transmitted signals":1.0,"These fingerprints":1.0,"the pursuit":1.0,"methods":1.0}},"age_hours":2.745552615555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.526,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9052,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9223,"joy":0.016,"surprise":0.0316,"sadness":0.0028,"fear":0.0082,"anger":0.0141,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a machine learning framework for radio frequency fingerprinting. While the technology could potentially be used in applications that indirectly support sustainability (e.g., monitoring and securing renewable energy infrastructure), the article does not present any concrete actions or measurable outcomes related to climate change mitigation or adaptation. It is currently in the applied research stage, with use cases presented but no deployed units or quantified impact data.","key_impact_metrics":[],"technology_tags":["machine learning","radio frequency fingerprinting","signal processing"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T10:58:50.032315Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46eb4a58f4db","title":"Why Do Transformers Fail to Forecast Time Series In","content":"arXiv:2510.09776v1 Announce Type: new Abstract: Time series forecasting (TSF) remains a challenging and largely unsolved problem in machine learning, despite significant recent efforts leveraging Large Language Models (LLMs), which predominantly rely on Transformer architectures. Empirical evidence consistently shows that even powerful Transformers often fail to outperform much simpler models, e.g., linear models, on TSF tasks; however, a rigorous theoretical understanding of this phenomenon remains limited. In this paper, we provide a theoretical analysis of Transformers' limitations for TSF through the lens of In-Context Learning (ICL) theory. Specifically, under AR($p$) data, we establish that: (1) Linear Self-Attention (LSA) models $\\textit{cannot}$ achieve lower expected MSE than classical linear models for in-context forecasting; (2) as the context length approaches to infinity, LSA asymptotically recovers the optimal linear predictor; and (3) under Chain-of-Thought (CoT) style inference, predictions collapse to the mean exponentially. We empirically validate these findings through carefully designed experiments. Our theory not only sheds light on several previously underexplored phenomena but also offers practical insights for designing more effective forecasting architectures. We hope our work encourages the broader research community to revisit the fundamental theoretical limitations of TSF and to critically evaluate the direct application of increasingly sophisticated architectures without deeper scrutiny.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09776","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.561788","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Yufa Zhou, Yixiao Wang, Surbhi Goel, Anru R. Zhang","raw_content_length":1542,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["linear","AR($p$","In-Context Learning","Linear Self-Attention","Large Language Models","TSF","LSA","MSE","Transformer"],"persons":[],"locations":[],"monetary":[]},"char_count":1541,"language_detected":"en","key_concepts":{"key_phrases":["Transformers","Forecast Time Series","arXiv251009776v1 Announce Type","new Abstract","TSF","a challenging and largely unsolved problem","machine learning","significant recent efforts","Large Language Models","LLMs"],"filter_categories":{"ai_ml":["Transformers","machine learning","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Transformers":2.0,"Forecast Time Series":2.0,"arXiv251009776v1 Announce Type":1.0,"new Abstract":1.0,"TSF":1.0,"a challenging and largely unsolved problem":1.0,"machine learning":1.0,"significant recent efforts":1.0,"Large Language Models":1.0,"LLMs":1.0}},"age_hours":2.7455680838888887,"is_recent":true,"quality_score":1.0,"sentiment_score":0.801,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8398,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7995,"joy":0.0124,"surprise":0.0421,"sadness":0.0309,"fear":0.0566,"anger":0.0341,"disgust":0.0244},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper provides theoretical analysis of the limitations of Transformers for time series forecasting, showing that linear self-attention models cannot outperform classical linear models. While it offers insights for designing more effective forecasting architectures, it's purely theoretical with no deployed technology or measured outcomes related to climate impact. The research is peer-reviewed, lending credibility to the analysis.","key_impact_metrics":[],"technology_tags":["Time Series Forecasting","Machine Learning","Transformers"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:58:53.432495Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6fa5bde82349","title":"Tensor","content":"arXiv:2510.09778v1 Announce Type: new Abstract: In this work we investigate efficient data compression for spatiotemporal Black, Azov and Marmara Seas temperature tensors that contain significant number of missing values. These tensors have a complex structure influenced by the coastlines and bathymetry, as well as temporal temperature changes. While such missing data typically provokes utilization of tensor completion algorithms, we demonstrate that standard SVD-based compression approaches (including the Tucker, Tensor-Train (TT) and Quantized-TT formats) are remarkably effective and yield comparable results. We propose a greedy spatial data partitioning algorithm enhancing their performance. We divide the data into the smaller subtensors before compression via exploitation of this trick. Furthermore, our analysis reveals a strong temporal dependency in the data's compressibility caused by its nature. Fixing the level of precision we observe a significant seasonal variation. Investigating this, we find that a temporal partitioning on a scale of approximately two days is nearly optimal for all tested tensor based formats. The combined application of these spatial and temporal strategies with tensor methods ultimately achieves a robust compression ratio of 5 times across the entire dataset.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09778","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.562187","language":"en","tags":["computer-science","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Ilya Kosolapov, Tatiana Sheloput, Sergey Matveev","raw_content_length":1314,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Quantized-TT","Tensor-Train","SVD"],"persons":["Tucker","Azov","Marmara Seas"],"locations":[],"monetary":[]},"char_count":1311,"language_detected":"en","key_concepts":{"key_phrases":["Tensor","arXiv251009778v1 Announce Type","new Abstract","this work","efficient data compression","significant number","missing values","These tensors","a complex structure","the coastlines"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tensor":2.0,"arXiv251009778v1 Announce Type":1.0,"new Abstract":1.0,"this work":1.0,"efficient data compression":1.0,"significant number":1.0,"missing values":1.0,"These tensors":1.0,"a complex structure":1.0,"the coastlines":1.0}},"age_hours":2.745583128888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9143,"joy":0.0129,"surprise":0.0408,"sadness":0.0061,"fear":0.0032,"anger":0.0147,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a data compression technique for sea temperature tensors, achieving a 5x compression ratio. While this could indirectly support climate modeling and monitoring, the direct climate impact is modest and theoretical. The technology is in the applied research stage, with no evidence of deployment or economic viability.","key_impact_metrics":["Compression ratio: 5 times"],"technology_tags":["Data compression","Tensor decomposition","SVD"],"sdg_alignment":[13,14],"analyzed_at":"2025-10-29T10:58:56.729726Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d69f700ebbe0","title":"SVTime: Small Time Series Forecasting Models Informed by \"Physics\" of Large Vision Model Forecasters","content":"arXiv:2510.09780v1 Announce Type: new Abstract: Time series AI is crucial for analyzing dynamic web content, driving a surge of pre-trained large models known for their strong knowledge encoding and transfer capabilities across diverse tasks. However, given their energy-intensive training, inference, and hardware demands, using large models as a one-fits-all solution raises serious concerns about carbon footprint and sustainability. For a specific task, a compact yet specialized, high-performing model may be more practical and affordable, especially for resource-constrained users such as small businesses. This motivates the question: Can we build cost-effective lightweight models with large-model-like performance on core tasks such as forecasting? This paper addresses this question by introducing SVTime, a novel Small model inspired by large Vision model (LVM) forecasters for long-term Time series forecasting (LTSF). Recently, LVMs have been shown as powerful tools for LTSF. We identify a set of key inductive biases of LVM forecasters -- analogous to the \"physics\" governing their behaviors in LTSF -- and design small models that encode these biases through meticulously crafted linear layers and constraint functions. Across 21 baselines spanning lightweight, complex, and pre-trained large models on 8 benchmark datasets, SVTime outperforms state-of-the-art (SOTA) lightweight models and rivals large models with 10^3 fewer parameters than LVMs, while enabling efficient training and inference in low-resource settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09780","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.562620","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"ChengAo Shen, Ziming Zhao, Hanghang Tong, Dongjin Song, Dongsheng Luo, Qingsong Wen, Jingchao Ni","raw_content_length":1539,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["SVTime","Vision"],"persons":["Small"],"locations":[],"monetary":[]},"char_count":1538,"language_detected":"en","key_concepts":{"key_phrases":["SVTime","Small Time Series Forecasting Models","Physics","Large Vision Model Forecasters","arXiv251009780v1","Announce Type","new Abstract","Time series AI","dynamic web content","a surge"],"filter_categories":{"ai_ml":["Time series AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SVTime":2.0,"Small Time Series Forecasting Models":2.0,"Physics":2.0,"Large Vision Model Forecasters":2.0,"arXiv251009780v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Time series AI":1.0,"dynamic web content":1.0,"a surge":1.0}},"age_hours":2.7455996344444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.2105,"joy":0.005,"surprise":0.0154,"sadness":0.0278,"fear":0.6834,"anger":0.0461,"disgust":0.0118},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel small model (SVTime) for time series forecasting that aims to reduce energy consumption compared to large models. It achieves comparable performance to large models with 10^3 fewer parameters, suggesting a potential for reduced energy consumption during training and inference. However, it is currently in the applied research stage, with no deployment data available.","key_impact_metrics":["10^3 fewer parameters than LVMs"],"technology_tags":["Time series forecasting","Machine learning","Energy efficiency"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T10:58:59.764398Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_132cf393bab5","title":"Building a Foundational Guardrail for General Agentic Systems via Synthetic Data","content":"arXiv:2510.09781v1 Announce Type: new Abstract: While LLM agents can plan multi-step tasks, intervening at the planning stage-before any action is executed-is often the safest way to prevent harm, since certain risks can lead to severe consequences once carried out. However, existing guardrails mostly operate post-execution, which is difficult to scale and leaves little room for controllable supervision at the plan level. To address this challenge, we highlight three critical gaps in current research: data gap, model gap, and evaluation gap. To close the data gap, we introduce AuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii) injects category-labeled risks with calibrated difficulty, and (iii) filters outputs via an automated reward model, producing large and reliable corpora for pre-execution safety. To close the guardian model gap, we propose a foundational guardrail Safiron, combining a cross-planner adapter with a compact guardian model. The adapter unifies different input formats, while Safiron flags risky cases, assigns risk types, and generates rationales; trained in two stages with a broadly explored data recipe, Safiron achieves robust transfer across settings. To close the evaluation gap, we release Pre-Exec Bench, a realistic benchmark covering diverse tools and branching trajectories, which measures detection, fine-grained categorization, explanation, and cross-planner generalization in human-verified scenarios. Extensive experiments demonstrate consistent gains of the proposed guardrail over strong baselines on Pre-Exec Bench, and ablations further distill actionable practices, providing a practical template for safer agentic systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09781","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.563038","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Yue Huang, Hang Hua, Yujun Zhou, Pengcheng Jing, Manish Nagireddy, Inkit Padhi, Greta Dolcetti, Zhangchen Xu, Subhajit Chaudhury, Ambrish Rawat, Liubov Nedoshivina, Pin-Yu Chen, Prasanna Sattigeri, Xiangliang Zhang","raw_content_length":1704,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["AuraGen","Safiron","General Agentic Systems","Synthetic Data"],"persons":[],"locations":[],"monetary":[]},"char_count":1703,"language_detected":"en","key_concepts":{"key_phrases":["a Foundational Guardrail","General Agentic Systems","Synthetic Data","arXiv251009781v1 Announce Type","new Abstract","LLM agents","multi-step tasks","the planning stage","any action","the safest way"],"filter_categories":{"ai_ml":["a Foundational Guardrail"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"a Foundational Guardrail":2.0,"General Agentic Systems":2.0,"Synthetic Data":2.0,"arXiv251009781v1 Announce Type":1.0,"new Abstract":1.0,"LLM agents":1.0,"multi-step tasks":1.0,"the planning stage":1.0,"any action":1.0,"the safest way":1.0}},"age_hours":2.7456163625,"is_recent":true,"quality_score":1.0,"sentiment_score":1.4985,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7003,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6351,"joy":0.0355,"surprise":0.0077,"sadness":0.0163,"fear":0.2655,"anger":0.0276,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to pre-execution safety for LLM agents using synthetic data. While the approach is promising and demonstrates gains over baselines on a new benchmark, it is still in the applied research stage with no real-world deployment. The climate impact is indirect, as it aims to prevent harmful actions by AI agents, but the specific link to emissions reduction is not quantified.","key_impact_metrics":["Detection rate on Pre-Exec Bench","Fine-grained categorization accuracy"],"technology_tags":["LLM agents","Synthetic data","Risk assessment","Guardrails"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T10:59:03.063546Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0e00189d50a9","title":"The Geometry of Reasoning: Flowing Logics in Representation Space","content":"arXiv:2510.09782v1 Announce Type: new Abstract: We study how large language models (LLMs) ``think'' through their representation space. We propose a novel geometric framework that models an LLM's reasoning as flows -- embedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows' velocities. Using learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. Our work serves as both a conceptual foundation and practical tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs' behavior.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09782","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.563431","language":"en","tags":["cslg","csai","preprints","research","cscl","cslo","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Yufa Zhou, Yixiao Wang, Xunjian Yin, Shuyan Zhou, Anru R. Zhang","raw_content_length":1173,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1172,"language_detected":"en","key_concepts":{"key_phrases":["The Geometry","Reasoning","Flowing Logics","Representation Space","LLMs","logic","Announce Type","new Abstract","how large language models","their representation space"],"filter_categories":{"ai_ml":["LLMs","how large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Geometry":2.0,"Reasoning":2.0,"Flowing Logics":2.0,"Representation Space":2.0,"LLMs":2.0,"logic":2.0,"Announce Type":1.0,"new Abstract":1.0,"how large language models":1.0,"their representation space":1.0}},"age_hours":2.7456324722222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8373,"joy":0.0209,"surprise":0.0296,"sadness":0.0031,"fear":0.0424,"anger":0.0416,"disgust":0.0251},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents theoretical research on how large language models reason, using a geometric framework. While potentially impactful for future AI development, it lacks concrete actions or measurable outcomes related to sustainability. The research is at a very early stage with no deployment or practical application yet.","key_impact_metrics":[],"technology_tags":["Large Language Models","AI Reasoning","Geometric Framework"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:59:05.752428Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03084f37fe0e","title":"Large Language Models for Imbalanced Classification: Diversity makes the difference","content":"arXiv:2510.09783v1 Announce Type: new Abstract: Oversampling is one of the most widely used approaches for addressing imbalanced classification. The core idea is to generate additional minority samples to rebalance the dataset. Most existing methods, such as SMOTE, require converting categorical variables into numerical vectors, which often leads to information loss. Recently, large language model (LLM)-based methods have been introduced to overcome this limitation. However, current LLM-based approaches typically generate minority samples with limited diversity, reducing robustness and generalizability in downstream classification tasks. To address this gap, we propose a novel LLM-based oversampling method designed to enhance diversity. First, we introduce a sampling strategy that conditions synthetic sample generation on both minority labels and features. Second, we develop a new permutation strategy for fine-tuning pre-trained LLMs. Third, we fine-tune the LLM not only on minority samples but also on interpolated samples to further enrich variability. Extensive experiments on 10 tabular datasets demonstrate that our method significantly outperforms eight SOTA baselines. The generated synthetic samples are both realistic and diverse. Moreover, we provide theoretical analysis through an entropy-based perspective, proving that our method encourages diversity in the generated samples.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09783","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.563859","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Dang Nguyen, Sunil Gupta, Kien Do, Thin Nguyen, Taylor Braund, Alexis Whitton, Svetha Venkatesh","raw_content_length":1406,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["LLM","SMOTE"],"persons":[],"locations":[],"monetary":[]},"char_count":1405,"language_detected":"en","key_concepts":{"key_phrases":["Imbalanced Classification","Diversity","the difference","arXiv251009783v1 Announce Type","new Abstract","Oversampling","the most widely used approaches","imbalanced classification","The core idea","additional minority samples"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Imbalanced Classification":2.0,"Diversity":2.0,"the difference":2.0,"arXiv251009783v1 Announce Type":1.0,"new Abstract":1.0,"Oversampling":1.0,"the most widely used approaches":1.0,"imbalanced classification":1.0,"The core idea":1.0,"additional minority samples":1.0}},"age_hours":2.745648047222222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9044,"joy":0.0092,"surprise":0.0448,"sadness":0.0093,"fear":0.01,"anger":0.014,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel LLM-based oversampling method to improve imbalanced classification. The concrete action is the development and testing of a new algorithm. The evidence supporting claims is the experimental results on 10 tabular datasets, showing outperformance compared to SOTA baselines. The stage of deployment is applied research, as it is tested on datasets but not deployed in real-world applications.","key_impact_metrics":["Significant outperformance compared to eight SOTA baselines","Realistic and diverse synthetic samples generated"],"technology_tags":["Large Language Models","Oversampling","Imbalanced Classification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:08.782171Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fa4def261308","title":"Steering Embedding Models with Geometric Rotation: Mapping Semantic Relationships Across Languages and Models","content":"arXiv:2510.09790v1 Announce Type: new Abstract: Understanding how language and embedding models encode semantic relationships is fundamental to model interpretability and control. While early word embeddings exhibited intuitive vector arithmetic (''king'' - ''man'' + ''woman'' = ''queen''), modern high-dimensional text representations lack straightforward interpretable geometric properties. We introduce Rotor-Invariant Shift Estimation (RISE), a geometric approach that represents semantic transformations as consistent rotational operations in embedding space, leveraging the manifold structure of modern language representations. RISE operations have the ability to operate across both languages and models with high transfer of performance, suggesting the existence of analogous cross-lingual geometric structure. We evaluate RISE across three embedding models, three datasets, and seven morphologically diverse languages in five major language groups. Our results demonstrate that RISE consistently maps discourse-level semantic transformations with distinct grammatical features (e.g., negation and conditionality) across languages and models. This work provides the first systematic demonstration that discourse-level semantic transformations correspond to consistent geometric operations in multilingual embedding spaces, empirically supporting the Linear Representation Hypothesis at the sentence level.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09790","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.565041","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Michael Freenor, Lauren Alvarez","raw_content_length":1416,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["Rotor-Invariant Shift Estimation","RISE"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1415,"language_detected":"en","key_concepts":{"key_phrases":["Embedding Models","Geometric Rotation","Mapping Semantic Relationships","Languages","Models","arXiv251009790v1 Announce Type","new Abstract","language","embedding models","semantic relationships"],"filter_categories":{"ai_ml":["language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Embedding Models":2.0,"Geometric Rotation":2.0,"Mapping Semantic Relationships":2.0,"Languages":2.0,"Models":2.0,"arXiv251009790v1 Announce Type":1.0,"new Abstract":1.0,"language":1.0,"embedding models":1.0,"semantic relationships":1.0}},"age_hours":2.745693522777778,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8446,"joy":0.0075,"surprise":0.0408,"sadness":0.0084,"fear":0.034,"anger":0.034,"disgust":0.0307},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach (RISE) for understanding semantic transformations in multilingual embedding spaces. While the research demonstrates consistent geometric operations across languages and models, it is currently in the basic research stage with no deployed technology or measured outcomes in terms of environmental impact. The vaporware flag is raised because it's an early-stage concept with no deployment.","key_impact_metrics":["Transfer of performance across languages","Consistent mapping of discourse-level semantic transformations"],"technology_tags":["Natural Language Processing","Embedding Models","Geometric Representation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T10:59:11.960621Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8fa5422e701c","title":"PRAXA: A Framework for What","content":"arXiv:2510.09791v1 Announce Type: new Abstract: Various analytical techniques-such as scenario modeling, sensitivity analysis, perturbation-based analysis, counterfactual analysis, and parameter space analysis-are used across domains to explore hypothetical scenarios, examine input-output relationships, and identify pathways to desired results. Although termed differently, these methods share common concepts and methods, suggesting unification under what-if analysis. Yet a unified framework to define motivations, core components, and its distinct types is lacking. To address this gap, we reviewed 141 publications from leading visual analytics and HCI venues (2014-2024). Our analysis (1) outlines the motivations for what-if analysis, (2) introduces Praxa, a structured framework that identifies its fundamental components and characterizes its distinct types, and (3) highlights challenges associated with the application and implementation. Together, our findings establish a standardized vocabulary and structural understanding, enabling more consistent use across domains and communicate with greater conceptual clarity. Finally, we identify open research problems and future directions to advance what-if analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09791","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.565422","language":"en","tags":["preprints","research","computer-science","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Sneha Gathani, Kevin Li, Raghav Thind, Sirui Zeng, Matthew Xu, Peter J. Haas, Cagatay Demiralp, Zhicheng Liu","raw_content_length":1228,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["Praxa","HCI","PRAXA"],"persons":[],"locations":[],"monetary":[]},"char_count":1227,"language_detected":"en","key_concepts":{"key_phrases":["PRAXA","A Framework","What","Announce Type","new Abstract","Various analytical techniques","scenario modeling","sensitivity analysis","perturbation-based analysis","counterfactual analysis"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PRAXA":2.0,"A Framework":2.0,"What":2.0,"Announce Type":1.0,"new Abstract":1.0,"Various analytical techniques":1.0,"scenario modeling":1.0,"sensitivity analysis":1.0,"perturbation-based analysis":1.0,"counterfactual analysis":1.0}},"age_hours":2.745709101111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8909,"joy":0.0289,"surprise":0.055,"sadness":0.0044,"fear":0.0082,"anger":0.0095,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article presents a framework for 'what-if' analysis, which could potentially be used to model and optimize sustainability strategies. However, it is purely theoretical at this stage, with no concrete deployment or measured outcomes. The technical credibility is relatively high due to the peer-reviewed analysis of existing literature.","key_impact_metrics":[],"technology_tags":["scenario modeling","sensitivity analysis","perturbation-based analysis"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T10:59:14.707438Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fb142a39ce9a","title":"Principled Operator Learning in Ocean Dynamics: The Role of Temporal Structure","content":"arXiv:2510.09792v1 Announce Type: new Abstract: Neural operators are becoming the default tools to learn solutions to governing partial differential equations (PDEs) in weather and ocean forecasting applications. Despite early promising achievements, significant challenges remain, including long-term prediction stability and adherence to physical laws, particularly for high-frequency processes. In this paper, we take a step toward addressing these challenges in high-resolution ocean prediction by incorporating temporal Fourier modes, demonstrating how this modification enhances physical fidelity. This study compares the standard Fourier Neural Operator (FNO) with its variant, FNOtD, which has been modified to internalize the dispersion relation while learning the solution operator for ocean PDEs. The results demonstrate that entangling space and time in the training of integral kernels enables the model to capture multiscale wave propagation and effectively learn ocean dynamics. FNOtD substantially improves long-term prediction stability and consistency with underlying physical dynamics in challenging high-frequency settings compared to the standard FNO. It also provides competitive predictive skill relative to a state-of-the-art numerical ocean model, while requiring significantly lower computational cost.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09792","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.565834","language":"en","tags":["computer-science","cslg","physicsao-ph","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Vahidreza Jahanmard, Ali Ramezani-Kebrya, Robinson Hordoir","raw_content_length":1329,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["FNO"],"persons":["Fourier"],"locations":[],"monetary":[]},"char_count":1328,"language_detected":"en","key_concepts":{"key_phrases":["Principled Operator Learning","Ocean Dynamics","The Role","Temporal Structure","arXiv251009792v1 Announce Type","new Abstract","Neural operators","the default tools","solutions","partial differential equations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Principled Operator Learning":2.0,"Ocean Dynamics":2.0,"The Role":2.0,"Temporal Structure":2.0,"arXiv251009792v1 Announce Type":1.0,"new Abstract":1.0,"Neural operators":1.0,"the default tools":1.0,"solutions":1.0,"partial differential equations":1.0}},"age_hours":2.7457243294444447,"is_recent":true,"quality_score":1.0,"sentiment_score":6.951499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3903,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8911,"joy":0.0144,"surprise":0.0231,"sadness":0.0077,"fear":0.042,"anger":0.0123,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural operator (FNOtD) for ocean dynamics prediction that improves long-term prediction stability and consistency with physical dynamics compared to the standard FNO. It shows competitive predictive skill relative to a state-of-the-art numerical ocean model while requiring significantly lower computational cost. The research is in the applied research stage, with comparisons made against existing models, but lacks real-world deployment data.","key_impact_metrics":["Improved long-term prediction stability","Lower computational cost"],"technology_tags":["Neural Operators","Ocean Modeling","Weather Forecasting"],"sdg_alignment":[13,14],"analyzed_at":"2025-10-29T10:59:17.732808Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c88a52f1b1a","title":"Causality $\\neq$ Decodability, and Vice Versa: Lessons from Interpreting Counting ViTs","content":"arXiv:2510.09794v1 Announce Type: new Abstract: Mechanistic interpretability seeks to uncover how internal components of neural networks give rise to predictions. A persistent challenge, however, is disentangling two often conflated notions: decodability--the recoverability of information from hidden states--and causality--the extent to which those states functionally influence outputs. In this work, we investigate their relationship in vision transformers (ViTs) fine-tuned for object counting. Using activation patching, we test the causal role of spatial and CLS tokens by transplanting activations across clean-corrupted image pairs. In parallel, we train linear probes to assess the decodability of count information at different depths. Our results reveal systematic mismatches: middle-layer object tokens exert strong causal influence despite being weakly decodable, whereas final-layer object tokens support accurate decoding yet are functionally inert. Similarly, the CLS token becomes decodable in mid-layers but only acquires causal power in the final layers. These findings highlight that decodability and causality reflect complementary dimensions of representation--what information is present versus what is used--and that their divergence can expose hidden computational circuits.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09794","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.566231","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Lianghuan Huang, Yingshan Chang","raw_content_length":1301,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1300,"language_detected":"en","key_concepts":{"key_phrases":["neq Decodability","Vice Versa","Lessons","Interpreting Counting ViTs","arXiv251009794v1 Announce Type","new Abstract","Mechanistic interpretability","how internal components","neural networks","rise"],"filter_categories":{"ai_ml":["neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"neq Decodability":2.0,"Vice Versa":2.0,"Lessons":2.0,"Interpreting Counting ViTs":2.0,"arXiv251009794v1 Announce Type":1.0,"new Abstract":1.0,"Mechanistic interpretability":1.0,"how internal components":1.0,"neural networks":1.0,"rise":1.0}},"age_hours":2.7457407433333336,"is_recent":true,"quality_score":0.7,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9217,"joy":0.0105,"surprise":0.0284,"sadness":0.0062,"fear":0.0108,"anger":0.0132,"disgust":0.0092},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores the interpretability of neural networks, specifically Vision Transformers (ViTs), and their relationship to object counting. While the research itself doesn't directly address climate change, understanding AI decision-making processes could indirectly contribute to more efficient and reliable AI systems used in sustainability applications. There are no concrete actions or measurable outcomes related to sustainability at this stage.","key_impact_metrics":[],"technology_tags":["Vision Transformers","Mechanistic Interpretability","Object Counting"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:59:20.755617Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9dc66431ef2d","title":"A Unified Framework for Lifted Training and Inversion Approaches","content":"arXiv:2510.09796v1 Announce Type: new Abstract: The training of deep neural networks predominantly relies on a combination of gradient-based optimisation and back-propagation for the computation of the gradient. While incredibly successful, this approach faces challenges such as vanishing or exploding gradients, difficulties with non-smooth activations, and an inherently sequential structure that limits parallelisation. Lifted training methods offer an alternative by reformulating the nested optimisation problem into a higher-dimensional, constrained optimisation problem where the constraints are no longer enforced directly but penalised with penalty terms. This chapter introduces a unified framework that encapsulates various lifted training strategies, including the Method of Auxiliary Coordinates, Fenchel Lifted Networks, and Lifted Bregman Training, and demonstrates how diverse architectures, such as Multi-Layer Perceptrons, Residual Neural Networks, and Proximal Neural Networks fit within this structure. By leveraging tools from convex optimisation, particularly Bregman distances, the framework facilitates distributed optimisation, accommodates non-differentiable proximal activations, and can improve the conditioning of the training landscape. We discuss the implementation of these methods using block-coordinate descent strategies, including deterministic implementations enhanced by accelerated and adaptive optimisation techniques, as well as implicit stochastic gradient methods. Furthermore, we explore the application of this framework to inverse problems, detailing methodologies for both the training of specialised networks (e.g., unrolled architectures) and the stable inversion of pre-trained networks. Numerical results on standard imaging tasks validate the effectiveness and stability of the lifted Bregman approach compared to conventional training, particularly for architectures employing proximal activations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09796","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.566683","language":"en","tags":["statml","cslg","preprints","research","csna","mathoc","mathna","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Xiaoyu Wang, Alexandra Valavanis, Azhir Mahmood, Andreas Mang, Martin Benning, Audrey Repetti","raw_content_length":1953,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["Fenchel Lifted Networks","Multi-Layer Percep"],"persons":["Lifted Bregman Training"],"locations":[],"monetary":[]},"char_count":1952,"language_detected":"en","key_concepts":{"key_phrases":["A Unified Framework","Lifted Training and Inversion Approaches","arXiv251009796v1 Announce Type","new Abstract","The training","deep neural networks","a combination","gradient-based optimisation","back-propagation","the computation"],"filter_categories":{"ai_ml":["Lifted Training and Inversion Approaches","deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Unified Framework":2.0,"Lifted Training and Inversion Approaches":2.0,"arXiv251009796v1 Announce Type":1.0,"new Abstract":1.0,"The training":1.0,"deep neural networks":1.0,"a combination":1.0,"gradient-based optimisation":1.0,"back-propagation":1.0,"the computation":1.0}},"age_hours":2.745755643611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.061,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8122,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8862,"joy":0.0228,"surprise":0.039,"sadness":0.0091,"fear":0.0268,"anger":0.0111,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for training neural networks that could potentially improve efficiency and enable the use of non-differentiable activations, which may lead to more energy-efficient AI models. The numerical results on standard imaging tasks validate the effectiveness and stability of the lifted Bregman approach, but it is still in the research phase with no deployed applications. The potential climate impact is indirect, through reduced energy consumption of AI, but is not yet quantified.","key_impact_metrics":["Improved conditioning of training landscape","Effectiveness and stability validated on imaging tasks"],"technology_tags":["Lifted Training","Neural Networks","Convex Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:24.053636Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_89eb33cd2b0b","title":"Distributed clustering in partially overlapping feature spaces","content":"arXiv:2510.09799v1 Announce Type: new Abstract: We introduce and address a novel distributed clustering problem where each participant has a private dataset containing only a subset of all available features, and some features are included in multiple datasets. This scenario occurs in many real-world applications, such as in healthcare, where different institutions have complementary data on similar patients. We propose two different algorithms suitable for solving distributed clustering problems that exhibit this type of feature space heterogeneity. The first is a federated algorithm in which participants collaboratively update a set of global centroids. The second is a one-shot algorithm in which participants share a statistical parametrization of their local clusters with the central server, who generates and merges synthetic proxy datasets. In both cases, participants perform local clustering using algorithms of their choice, which provides flexibility and personalized computational costs. Pretending that local datasets result from splitting and masking an initial centralized dataset, we identify some conditions under which the proposed algorithms are expected to converge to the optimal centralized solution. Finally, we test the practical performance of the algorithms on three public datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09799","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.567079","language":"en","tags":["computer-science","cslg","csds","preprints","csdc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Alessio Maritan, Luca Schenato","raw_content_length":1319,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1318,"language_detected":"en","key_concepts":{"key_phrases":["partially overlapping feature spaces","Announce Type","new Abstract","a novel distributed clustering problem","each participant","a private dataset","only a subset","all available features","some features","multiple datasets"],"filter_categories":{"ai_ml":["all available features"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"partially overlapping feature spaces":2.0,"Announce Type":1.0,"new Abstract":1.0,"a novel distributed clustering problem":1.0,"each participant":1.0,"a private dataset":1.0,"only a subset":1.0,"all available features":1.0,"some features":1.0,"multiple datasets":1.0}},"age_hours":2.7457704297222225,"is_recent":true,"quality_score":0.7,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8679,"joy":0.0172,"surprise":0.0901,"sadness":0.005,"fear":0.0035,"anger":0.0118,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes algorithms for distributed clustering, which could potentially improve data analysis in various sectors, including healthcare. While the algorithms themselves don't directly reduce GHG emissions, better data analysis *could* lead to more efficient resource allocation and potentially identify areas for emissions reduction in the future. However, this is theoretical and there are no deployed units or measured outcomes at this stage.","key_impact_metrics":[],"technology_tags":["distributed clustering","federated learning","data analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:27.298452Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_80dd531e9cc3","title":"How can we assess human","content":"arXiv:2510.09801v1 Announce Type: new Abstract: LLM-powered agents are both a promising new technology and a source of complexity, where choices about models, tools, and prompting can affect their usefulness. While numerous benchmarks measure agent accuracy across domains, they mostly assume full automation, failing to represent the collaborative nature of real-world use cases. In this paper, we make two major steps towards the rigorous assessment of human-agent interactions. First, we propose PULSE, a framework for more efficient human-centric evaluation of agent designs, which comprises collecting user feedback, training an ML model to predict user satisfaction, and computing results by combining human satisfaction ratings with model-generated pseudo-labels. Second, we deploy the framework on a large-scale web platform built around the open-source software agent OpenHands, collecting in-the-wild usage data across over 15k users. We conduct case studies around how three agent design decisions -- choice of LLM backbone, planning strategy, and memory mechanisms -- impact developer satisfaction rates, yielding practical insights for software agent design. We also show how our framework can lead to more robust conclusions about agent design, reducing confidence intervals by 40\\% compared to a standard A/B test. Finally, we find substantial discrepancies between in-the-wild results and benchmark performance (e.g., the anti-correlation between results comparing claude-sonnet-4 and gpt-5), underscoring the limitations of benchmark-driven evaluation. Our findings provide guidance for evaluations of LLM agents with humans and identify opportunities for better agent designs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09801","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.567508","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Valerie Chen, Rohit Malhotra, Xingyao Wang, Juan Michelini, Xuhui Zhou, Aditya Bharat Soni, Hoang H. Tran, Calvin Smith, Ameet Talwalkar, Graham Neubig","raw_content_length":1695,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["OpenHands"],"persons":[],"locations":[],"monetary":[]},"char_count":1694,"language_detected":"en","key_concepts":{"key_phrases":["human","arXiv251009801v1 Announce Type","new Abstract","LLM-powered agents","a promising new technology","a source","complexity","choices","models","tools"],"filter_categories":{"ai_ml":["LLM-powered agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"human":2.0,"arXiv251009801v1 Announce Type":1.0,"new Abstract":1.0,"LLM-powered agents":1.0,"a promising new technology":1.0,"a source":1.0,"complexity":1.0,"choices":1.0,"models":1.0,"tools":1.0}},"age_hours":2.7457860008333332,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9403,"joy":0.0078,"surprise":0.017,"sadness":0.0041,"fear":0.0061,"anger":0.0127,"disgust":0.0119},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a framework (PULSE) and a web platform (OpenHands) deployed with 15k users to evaluate human-agent interactions. It presents concrete data on user satisfaction and discrepancies between benchmark performance and real-world results. The 40% reduction in confidence intervals compared to A/B testing is a measurable outcome.","key_impact_metrics":["40% reduction in confidence intervals","15k users"],"technology_tags":["LLM agents","Human-agent interaction","AI evaluation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:30.212875Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ba89505ce9f1","title":"Task","content":"arXiv:2505.18361v4 Announce Type: replace-cross Abstract: Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language. We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment. Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy. For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18361","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.358006","language":"en","tags":["cslg","csai","preprints","research","q-bionc","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Trinity Chung, Yuchen Shen, Nathan C. L. Kong, Aran Nayebi","raw_content_length":1681,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["EAD"],"persons":["ConvRNNs"],"locations":[],"monetary":[]},"char_count":1678,"language_detected":"en","key_concepts":{"key_phrases":["Task","arXiv250518361v4 Announce Type","replace-cross Abstract","Tactile sensing","neuroscience","artificial systems","more mature modalities","vision","language","these gaps"],"filter_categories":{"research_academic":["neuroscience"],"ai_ml":["vision","language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Task":2.0,"arXiv250518361v4 Announce Type":1.0,"replace-cross Abstract":1.0,"Tactile sensing":1.0,"neuroscience":1.0,"artificial systems":1.0,"more mature modalities":1.0,"vision":1.0,"language":1.0,"these gaps":1.0}},"age_hours":2.7731553658333334,"is_recent":true,"quality_score":0.7,"sentiment_score":9.2405,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8481,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8863,"joy":0.0136,"surprise":0.0678,"sadness":0.0071,"fear":0.0093,"anger":0.0101,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This is basic research on tactile sensing using neural networks. It identifies ConvRNNs as superior encoders for tactile categorization and achieves neural representations closely matching rodent somatosensory cortex. There is no concrete action or deployment yet, and the impact on sustainability is indirect and theoretical.","key_impact_metrics":["neural alignment with rodent somatosensory cortex","supervised categorization performance"],"technology_tags":["neural networks","tactile sensing","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:33.410150Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2a4d55260d05","title":"Latent-Feature-Informed Neural ODE Modeling for Lightweight Stability Evaluation of Black","content":"arXiv:2510.09826v1 Announce Type: new Abstract: Stability evaluation of black-box grid-tied inverters is vital for grid reliability, yet identification techniques are both data-hungry and blocked by proprietary internals. {To solve this, this letter proposes a latent-feature-informed neural ordinary differential equation (LFI-NODE) modeling method that can achieve lightweight stability evaluation directly from trajectory data.} LFI-NODE parameterizes the entire system ODE with a single continuous-time neural network, allowing each new sample to refine a unified global model. It faithfully captures nonlinear large-signal dynamics to preserve uniform predictive accuracy as the inverter transitions between operating points. Meanwhile, latent perturbation features distilled from every trajectory steer the learning process and concurrently reveal the small-signal eigenstructure essential for rigorous stability analysis. Validated on a grid-forming inverter, {The LFI-NODE requires one to two orders of magnitude fewer training samples compared with traditional methods, collected from short time-domain trajectories instead of extensive frequency-domain measurements.} {Furthermore, the LFI-NODE requires only 48 short transients to achieve a trajectory prediction error at the hundredth level and an eigenvalue estimation error at the tenth level, outperforming benchmark methods by one to two orders of magnitude.} This makes LFI-NODE a practical and lightweight approach for achieving high-fidelity stability assessment of complex black-box power-electronic systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09826","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.571162","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Jialin Zheng, Zhong Liu, Xiaonan Lu","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Latent-Feature-Informed Neural ODE Modeling"],"persons":[],"locations":[],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["Latent-Feature-Informed Neural ODE Modeling","Lightweight Stability Evaluation","Black","LFI-NODE","Announce Type","new Abstract","Stability evaluation","black-box grid-tied inverters","grid reliability","identification techniques"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Latent-Feature-Informed Neural ODE Modeling":2.0,"Lightweight Stability Evaluation":2.0,"Black":2.0,"LFI-NODE":2.0,"Announce Type":1.0,"new Abstract":1.0,"Stability evaluation":1.0,"black-box grid-tied inverters":1.0,"grid reliability":1.0,"identification techniques":1.0}},"age_hours":2.7459247186111115,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5251,"joy":0.0068,"surprise":0.0188,"sadness":0.0519,"fear":0.0126,"anger":0.321,"disgust":0.0637},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (LFI-NODE) for stability evaluation of grid-tied inverters, potentially improving grid reliability and enabling greater penetration of renewable energy sources. It achieves this by requiring significantly fewer training samples (one to two orders of magnitude) and short time-domain trajectories, making it a lightweight approach. The technology is still in the applied research stage, validated on a grid-forming inverter, but not yet deployed in real-world applications.","key_impact_metrics":["trajectory prediction error at the hundredth level","eigenvalue estimation error at the tenth level"],"technology_tags":["neural ordinary differential equation","grid-tied inverters","stability evaluation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T10:59:36.600353Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d489189e4eb4","title":"An Exploration of Non","content":"arXiv:2510.09827v1 Announce Type: new Abstract: To define a steepest descent method over a neural network, we need to choose a norm for each layer, a way to aggregate these norms across layers, and whether to use normalization. We systematically explore different alternatives for aggregating norms across layers, both formalizing existing combinations of Adam and the recently proposed Muon as a type of non-Euclidean gradient descent, and deriving new variants of the Muon optimizer. Through a comprehensive experimental evaluation of the optimizers within our framework, we find that Muon is sensitive to the choice of learning rate, whereas a new variant we call MuonMax is significantly more robust. We then show how to combine any non-Euclidean gradient method with model based momentum (known as Momo). The new Momo variants of Muon are significantly more robust to hyperparameter tuning, and often achieve a better validation score. Thus for new tasks, where the optimal hyperparameters are not known, we advocate for using Momo in combination with MuonMax to save on costly hyperparameter tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09827","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.571599","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Michael Crawshaw, Chirag Modi, Mingrui Liu, Robert M. Gower","raw_content_length":1106,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["Momo","MuonMax"],"persons":["Adam","Muon"],"locations":[],"monetary":[]},"char_count":1105,"language_detected":"en","key_concepts":{"key_phrases":["An Exploration","Non","layers","arXiv251009827v1","Announce Type","new Abstract","a steepest descent method","a neural network","a norm","each layer"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Exploration":2.0,"Non":2.0,"layers":2.0,"arXiv251009827v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"a steepest descent method":1.0,"a neural network":1.0,"a norm":1.0,"each layer":1.0}},"age_hours":2.7459403230555557,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8998,"joy":0.0122,"surprise":0.0334,"sadness":0.0049,"fear":0.0152,"anger":0.0232,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores new optimization algorithms for neural networks, specifically focusing on improving robustness and reducing hyperparameter tuning. While better optimization can lead to more efficient training of models used in climate-related applications, the direct climate impact is theoretical and depends on the specific application. The research is at an early stage, with no deployed systems or real-world data beyond experimental evaluations.","key_impact_metrics":["Improved validation score","Reduced hyperparameter tuning cost"],"technology_tags":["Neural Network Optimization","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T10:59:39.553748Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_60e447670fe9","title":"CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems with Local Scores, Conditional Independence Tests, and Relation Attributes","content":"arXiv:2510.09846v1 Announce Type: new Abstract: Causal discovery from observational data is fundamental to scientific fields like biology, where controlled experiments are often impractical. However, existing methods, including constraint-based (e.g., PC, causalMGM) and score-based approaches (e.g., NOTEARS), face significant limitations. These include an inability to resolve causal direction, restrictions to linear associations, sensitivity to violations of the faithfulness assumption, and inefficiency in searching vast hypothesis spaces. While large language models (LLMs) offer powerful reasoning capabilities, their application is hindered by a fundamental discrepancy: they are designed for text, while most causal data is tabular. To address these challenges, we introduce CALM, a novel causal analysis language model specifically designed for tabular data in complex systems. CALM leverages a Mamba-based architecture to classify causal patterns from pairwise variable relationships. It integrates a comprehensive suite of evidence, including local causal scores, conditional independence tests, and relational attributes, to capture a wide spectrum of linear, nonlinear, and conditional causal mechanisms. Trained on a diverse corpus of synthetic data (from linear, mixed, and nonlinear models) and 10 real-world biological datasets with rigorously validated causal relationships, our model ensures robustness and generalizability. Empirical evaluation demonstrates that CALM significantly outperforms existing methods in both simulation studies, achieving over 91% accuracy, and in a real-world application identifying causal factors in Hepatitis C virus progression. This work represents a significant step towards accurate and generalizable causal discovery by successfully adapting the pattern recognition capabilities of language models to the intricacies of tabular data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09846","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.573965","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Zhenjiang Fan, Zengyi Qin, Yuanning Zheng, Bo Xiong, Summer Han","raw_content_length":1892,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":["Conditional Independence Tests","Relation","CALM","Local Scores","NOTEARS"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1891,"language_detected":"en","key_concepts":{"key_phrases":["CALM","A Causal Analysis Language Model","Tabular Data","Complex Systems","Local Scores","Conditional Independence Tests","Relation Attributes","arXiv251009846v1 Announce Type","new Abstract","Causal discovery"],"filter_categories":{"research_academic":["Causal discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CALM":2.0,"A Causal Analysis Language Model":2.0,"Tabular Data":2.0,"Complex Systems":2.0,"Local Scores":2.0,"Conditional Independence Tests":2.0,"Relation Attributes":2.0,"arXiv251009846v1 Announce Type":1.0,"new Abstract":1.0,"Causal discovery":1.0}},"age_hours":2.7460281516666667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.728,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7456,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9028,"joy":0.0078,"surprise":0.0247,"sadness":0.0169,"fear":0.0271,"anger":0.0101,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel causal analysis language model (CALM) for tabular data, achieving over 91% accuracy in simulation studies and demonstrating potential in identifying causal factors in Hepatitis C virus progression. While promising, it is still in the applied research phase with no clear path to economic viability or large-scale deployment for climate applications. The model's ability to improve understanding of complex systems could indirectly contribute to sustainability efforts, but the direct climate impact is currently limited.","key_impact_metrics":["Accuracy in simulation studies: 91%"],"technology_tags":["causal analysis","language model","tabular data","machine learning"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T10:59:42.643137Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9a7d0be31a6","title":"Cell Instance Segmentation: The Devil Is in the Boundaries","content":"arXiv:2510.09848v1 Announce Type: new Abstract: State-of-the-art (SOTA) methods for cell instance segmentation are based on deep learning (DL) semantic segmentation approaches, focusing on distinguishing foreground pixels from background pixels. In order to identify cell instances from foreground pixels (e.g., pixel clustering), most methods decompose instance information into pixel-wise objectives, such as distances to foreground-background boundaries (distance maps), heat gradients with the center point as heat source (heat diffusion maps), and distances from the center point to foreground-background boundaries with fixed angles (star-shaped polygons). However, pixel-wise objectives may lose significant geometric properties of the cell instances, such as shape, curvature, and convexity, which require a collection of pixels to represent. To address this challenge, we present a novel pixel clustering method, called Ceb (for Cell boundaries), to leverage cell boundary features and labels to divide foreground pixels into cell instances. Starting with probability maps generated from semantic segmentation, Ceb first extracts potential foreground-foreground boundaries with a revised Watershed algorithm. For each boundary candidate, a boundary feature representation (called boundary signature) is constructed by sampling pixels from the current foreground-foreground boundary as well as the neighboring background-foreground boundaries. Next, a boundary classifier is used to predict its binary boundary label based on the corresponding boundary signature. Finally, cell instances are obtained by dividing or merging neighboring regions based on the predicted boundary labels. Extensive experiments on six datasets demonstrate that Ceb outperforms existing pixel clustering methods on semantic segmentation probability maps. Moreover, Ceb achieves highly competitive performance compared to SOTA cell instance segmentation methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09848","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.574795","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Peixian Liang, Yifan Ding, Yizhe Zhang, Jianxu Chen, Hao Zheng, Hongxiao Wang, Yejia Zhang, Guangyu Meng, Tim Weninger, Michael Niemier, X. Sharon Hu, Danny Z Chen","raw_content_length":1947,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["Ceb"],"monetary":[]},"char_count":1946,"language_detected":"en","key_concepts":{"key_phrases":["Cell Instance Segmentation","The Devil","the Boundaries","foreground pixels","arXiv251009848v1 Announce Type","new Abstract","the-art","SOTA","cell instance segmentation","deep learning"],"filter_categories":{"ai_ml":["deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cell Instance Segmentation":2.0,"The Devil":2.0,"the Boundaries":2.0,"foreground pixels":2.0,"arXiv251009848v1 Announce Type":1.0,"new Abstract":1.0,"the-art":1.0,"SOTA":1.0,"cell instance segmentation":1.0,"deep learning":1.0}},"age_hours":2.746060043611111,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8585,"joy":0.0068,"surprise":0.0295,"sadness":0.0389,"fear":0.0185,"anger":0.0169,"disgust":0.0309},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel pixel clustering method for cell instance segmentation. While it shows improved performance on datasets, it's still in the applied research phase with no deployed units or real-world data related to sustainability. The impact on climate is indirect, potentially improving research efficiency, but not directly reducing emissions.","key_impact_metrics":["Improved performance on six datasets","Outperforms existing pixel clustering methods"],"technology_tags":["Cell instance segmentation","Pixel clustering","Deep learning"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T10:59:46.350974Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_47fdfbd94936","title":"QONNECT: A QoS","content":"arXiv:2510.09851v1 Announce Type: new Abstract: Modern applications increasingly span across cloud, fog, and edge environments, demanding orchestration systems that can adapt to diverse deployment contexts while meeting Quality-of-Service (QoS) requirements. Standard Kubernetes schedulers do not account for user-defined objectives such as energy efficiency, cost optimization, and global performance, often leaving operators to make manual, cluster-by-cluster placement decisions. To address this need, we present QONNECT, a vendor-agnostic orchestration framework that enables declarative, QoS-driven application deployment across heterogeneous Kubernetes and K3s clusters. QONNECT introduces a distributed architecture composed of a central Knowledge Base, Raft-replicated Resource Lead Agents, and lightweight Resource Agents in each cluster. Through a minimal YAML-based interface, users specify high-level QoS goals, which the system translates into concrete placement and migration actions. Our implementation is evaluated on a federated testbed of up to nine cloud-fog-edge clusters using the Istio Bookinfo microservice application. The system demonstrates dynamic, policy-driven microservice placement, automated failover, QoS-compliant rescheduling, and leader re-election after node failure, all without manual intervention. By bridging the gap between declarative deployment models and operational QoS goals, QONNECT transforms the cloud-edge continuum into a unified, self-optimizing platform.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09851","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.575572","language":"en","tags":["preprints","csdc","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Haci Ismail Aslan, Syed Muhammad Mahmudul Haque, Joel Witzke, Odej Kao","raw_content_length":1509,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Resource Lead Agents","Kubernetes","Standard Kubernetes","QONNECT","Resource Agents"],"persons":["K3s"],"locations":[],"monetary":[]},"char_count":1508,"language_detected":"en","key_concepts":{"key_phrases":["A QoS","arXiv251009851v1","Announce Type","new Abstract","Modern applications","cloud fog and edge environments","orchestration systems","deployment","Service","QoS"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A QoS":2.0,"arXiv251009851v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Modern applications":1.0,"cloud fog and edge environments":1.0,"orchestration systems":1.0,"deployment":1.0,"Service":1.0,"QoS":1.0}},"age_hours":2.7460873922222224,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8907,"joy":0.007,"surprise":0.0571,"sadness":0.0056,"fear":0.02,"anger":0.0132,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"QONNECT is an orchestration framework that aims to improve energy efficiency by dynamically placing microservices across cloud-fog-edge clusters. The system is evaluated on a testbed, demonstrating dynamic placement and automated failover. While the concept has potential, it's currently in the applied research phase with no real-world deployments or quantified energy savings data.","key_impact_metrics":["Dynamic microservice placement","Automated failover"],"technology_tags":["Kubernetes","K3s","Orchestration","Microservices"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T10:59:49.300259Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f55eca21d27","title":"MTMD: A Multi","content":"arXiv:2510.09857v1 Announce Type: new Abstract: The lightweight ad ranking layer, living after the retrieval stage and before the fine ranker, plays a critical role in the success of a cascaded ad recommendation system. Due to the fact that there are multiple optimization tasks depending on the ad domain, e.g., Click Through Rate (CTR) for click ads and Conversion Rate (CVR) for conversion ads, as well as multiple surfaces where an ad is served (home feed, search, or related item recommendation) with diverse ad products (shopping or standard ad); it is an essentially challenging problem in industry on how to do joint holistic optimization in the lightweight ranker, such that the overall platform's value, advertiser's value, and user's value are maximized. Deep Neural Network (DNN)-based multitask learning (MTL) can handle multiple goals naturally, with each prediction head mapping to a particular optimization goal. However, in practice, it is unclear how to unify data from different surfaces and ad products into a single model. It is critical to learn domain-specialized knowledge and explicitly transfer knowledge between domains to make MTL effective. We present a Multi-Task Multi-Domain (MTMD) architecture under the classic Two-Tower paradigm, with the following key contributions: 1) handle different prediction tasks, ad products, and ad serving surfaces in a unified framework; 2) propose a novel mixture-of-expert architecture to learn both specialized knowledge each domain and common knowledge shared between domains; 3) propose a domain adaption module to encourage knowledge transfer between experts; 4) constrain the modeling of different prediction tasks. MTMD improves the offline loss value by 12% to 36%, mapping to 2% online reduction in cost per click. We have deployed this single MTMD framework into production for Pinterest ad recommendation replacing 9 production models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09857","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.576807","language":"en","tags":["computer-science","preprints","cscv","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":286,"author":"Xiao Yang, Peifeng Yin, Abe Engle, Jinfeng Zhuang, Ling Leng","raw_content_length":1914,"priority":7,"update_frequency":1,"reading_time_minutes":1.43,"robust_parsing_used":true,"entities":{"organizations":["CVR","Click Through Rate","MTL","Deep Neural Network","CTR","Conversion Rate","A Multi arXiv:2510.09857v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1911,"language_detected":"en","key_concepts":{"key_phrases":["MTMD","arXiv251009857v1 Announce Type","new Abstract","The lightweight ad ranking layer","the retrieval stage","the fine ranker","a critical role","the success","a cascaded ad recommendation system","the fact"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MTMD":2.0,"arXiv251009857v1 Announce Type":1.0,"new Abstract":1.0,"The lightweight ad ranking layer":1.0,"the retrieval stage":1.0,"the fine ranker":1.0,"a critical role":1.0,"the success":1.0,"a cascaded ad recommendation system":1.0,"the fact":1.0}},"age_hours":2.74613446,"is_recent":true,"quality_score":1.0,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8511,"joy":0.0318,"surprise":0.0967,"sadness":0.0037,"fear":0.0041,"anger":0.0083,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":6,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes the deployment of a machine learning model (MTMD) for ad recommendation at Pinterest, replacing 9 existing models. The concrete action is the deployment and the measured outcome is a 2% online reduction in cost per click. The technical credibility is supported by the reported offline loss value improvement and the fact that it's deployed in a real-world setting.","key_impact_metrics":["2% online reduction in cost per click","12% to 36% offline loss value improvement"],"technology_tags":["machine learning","ad recommendation","multi-task learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T10:59:52.660888Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a4eb9b57990a","title":"AI and Consciousness","content":"arXiv:2510.09858v1 Announce Type: new Abstract: This is a skeptical overview of the literature on AI consciousness. We will soon create AI systems that are conscious according to some influential, mainstream theories of consciousness but are not conscious according to other influential, mainstream theories of consciousness. We will not be in a position to know which theories are correct and whether we are surrounded by AI systems as richly and meaningfully conscious as human beings or instead only by systems as experientially blank as toasters. None of the standard arguments either for or against AI consciousness takes us far. Table of Contents Chapter One: Hills and Fog Chapter Two: What Is Consciousness? What Is AI? Chapter Three: Ten Possibly Essential Features of Consciousness Chapter Four: Against Introspective and Conceptual Arguments for Essential Features Chapter Five: Materialism and Functionalism Chapter Six: The Turing Test and the Chinese Room Chapter Seven: The Mimicry Argument Against AI Consciousness Chapter Eight: Global Workspace Theories and Higher Order Theories Chapter Nine: Integrated Information, Local Recurrence, Associative Learning, and Iterative Natural Kinds Chapter Ten: Does Biological Substrate Matter? Chapter Eleven: The Problem of Strange Intelligence Chapter Twelve: The Leapfrog Hypothesis and the Social Semi-Solution","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09858","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.577210","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Eric Schwitzgebel","raw_content_length":1398,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Consciousness arXiv:2510.09858v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1371,"language_detected":"en","key_concepts":{"key_phrases":["Consciousness","AI systems","consciousness","Announce Type","new Abstract","a skeptical overview","the literature","AI consciousness","some influential mainstream theories","other influential mainstream theories"],"filter_categories":{"ai_ml":["AI systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Consciousness":2.0,"AI systems":2.0,"consciousness":2.0,"Announce Type":1.0,"new Abstract":1.0,"a skeptical overview":1.0,"the literature":1.0,"AI consciousness":1.0,"some influential mainstream theories":1.0,"other influential mainstream theories":1.0}},"age_hours":2.746149799444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.304,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8608,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6169,"joy":0.0068,"surprise":0.0558,"sadness":0.007,"fear":0.2625,"anger":0.0279,"disgust":0.0231},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article is a theoretical overview of AI consciousness, lacking concrete actions or measurable outcomes related to sustainability. It explores philosophical arguments and does not present any deployed technology or data relevant to climate change, resource management, or social equity. The focus is on the nature of consciousness, not on practical applications with environmental or social impact.","key_impact_metrics":[],"technology_tags":["artificial intelligence","consciousness"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:59:55.562594Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_47a54730a1fe","title":"Cluster-Aware Prompt Ensemble Learning for Few","content":"arXiv:2510.09867v1 Announce Type: new Abstract: Vision-language models (VLMs) such as CLIP achieve zero-shot transfer across various tasks by pre-training on numerous image-text pairs. These models often benefit from using an ensemble of context prompts to represent a class. Despite being effective, conventional prompt ensembling that averages textual features of context prompts often yields suboptimal results. This is because feature averaging shifts the class centroids away from the true class distribution. To address this issue, we propose the Cluster-Aware Prompt Ensemble Learning (CAPEL) framework, which preserves the cluster nature of context prompts. CAPEL classifies images into one of several class clusters, each represented by a distinct prompt. Instead of ensembling prompts in the feature space, we perform ensembling in the classification logits space, aligning better with the visual feature distribution. To further optimize prompt fine-tuning while maintaining cluster-specific discriminative power, we introduce a cluster-preserving regularization term. This ensures that prompts remain distinct and specialized for different clusters, preventing collapse into a uniform direction. Additionally, we integrate an adaptive prompt weighting technique to dynamically adjust the attention weights for flawed or ambiguous prompts, ensuring robust performance across diverse datasets and tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09867","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.578017","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Zhi Chen, Xin Yu, Xiaohui Tao, Yan Li, Zi Huang","raw_content_length":1414,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Cluster-Aware Prompt Ensemble Learning for Few arXiv:2510.09867v1 Announce Type:","the Cluster-Aware Prompt Ensemble Learning (CAPEL","CLIP"],"persons":[],"locations":[],"monetary":[]},"char_count":1413,"language_detected":"en","key_concepts":{"key_phrases":["Cluster-Aware Prompt Ensemble Learning","context prompts","arXiv251009867v1 Announce Type","new Abstract","Vision-language models","VLMs","CLIP","zero-shot transfer","various tasks","pre"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cluster-Aware Prompt Ensemble Learning":2.0,"context prompts":2.0,"arXiv251009867v1 Announce Type":1.0,"new Abstract":1.0,"Vision-language models":1.0,"VLMs":1.0,"CLIP":1.0,"zero-shot transfer":1.0,"various tasks":1.0,"pre":1.0}},"age_hours":2.7461794183333335,"is_recent":true,"quality_score":1.0,"sentiment_score":5.572,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1144,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.914,"joy":0.02,"surprise":0.0371,"sadness":0.0109,"fear":0.0032,"anger":0.0076,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new machine learning framework (CAPEL) to improve the performance of vision-language models. While it could potentially improve the efficiency of AI models used in sustainability applications, there are no concrete actions or measurable outcomes related to climate change or environmental impact at this stage. It's currently at the basic research stage with no deployment.","key_impact_metrics":[],"technology_tags":["machine learning","vision-language models","prompt engineering"],"sdg_alignment":[],"analyzed_at":"2025-10-29T10:59:58.413915Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_01152fff6132","title":"CoBia: Constructed Conversations Can Trigger Otherwise Concealed Societal Biases in LLMs","content":"arXiv:2510.09871v1 Announce Type: new Abstract: Improvements in model construction, including fortified safety guardrails, allow Large language models (LLMs) to increasingly pass standard safety checks. However, LLMs sometimes slip into revealing harmful behavior, such as expressing racist viewpoints, during conversations. To analyze this systematically, we introduce CoBia, a suite of lightweight adversarial attacks that allow us to refine the scope of conditions under which LLMs depart from normative or ethical behavior in conversations. CoBia creates a constructed conversation where the model utters a biased claim about a social group. We then evaluate whether the model can recover from the fabricated bias claim and reject biased follow-up questions. We evaluate 11 open-source as well as proprietary LLMs for their outputs related to six socio-demographic categories that are relevant to individual safety and fair treatment, i.e., gender, race, religion, nationality, sex orientation, and others. Our evaluation is based on established LLM-based bias metrics, and we compare the results against human judgments to scope out the LLMs' reliability and alignment. The results suggest that purposefully constructed conversations reliably reveal bias amplification and that LLMs often fail to reject biased follow-up questions during dialogue. This form of stress-testing highlights deeply embedded biases that can be surfaced through interaction. Code and artifacts are available at https://github.com/nafisenik/CoBia.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09871","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.578835","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Nafiseh Nikeghbal, Amir Hossein Kargaran, Jana Diesner","raw_content_length":1529,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["CoBia","Announce Type"],"locations":[],"monetary":[]},"char_count":1528,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","CoBia","Constructed Conversations","Trigger","Societal Biases","arXiv251009871v1 Announce Type","new Abstract","Improvements","model construction","fortified safety guardrails"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":5.0,"CoBia":3.0,"Constructed Conversations":2.0,"Trigger":2.0,"Societal Biases":2.0,"arXiv251009871v1 Announce Type":1.0,"new Abstract":1.0,"Improvements":1.0,"model construction":1.0,"fortified safety guardrails":1.0}},"age_hours":2.7462096486111114,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.2563,"joy":0.0033,"surprise":0.0061,"sadness":0.0136,"fear":0.0687,"anger":0.2909,"disgust":0.3611},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":6,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on identifying and measuring biases in LLMs, which is a crucial step towards ensuring AI systems are fair and equitable. While it doesn't directly address climate change, it has implications for how AI is used in climate modeling, policy recommendations, and resource allocation, potentially impacting vulnerable communities. The research uses established LLM-based bias metrics and compares results against human judgments, providing a degree of validation.","key_impact_metrics":["Bias amplification in LLMs","Failure rate of LLMs to reject biased follow-up questions"],"technology_tags":["Large Language Models","Bias Detection","Adversarial Attacks"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T11:00:01.588502Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95f0e8c08f2c","title":"WARC","content":"arXiv:2510.09872v1 Announce Type: new Abstract: Training web agents to navigate complex, real-world websites requires them to master $\\textit{subtasks}$ - short-horizon interactions on multiple UI components (e.g., choosing the correct date in a date picker, or scrolling in a container to extract information). We introduce WARC-Bench (Web Archive Benchmark), a novel web navigation benchmark featuring 438 tasks designed to evaluate multimodal AI agents on subtasks. WARC-Bench enables sandboxed interactions with dynamic and realistic webpages using Web ARChive files. We show that WARC-Bench is challenging for leading computer-use models, with the highest observed success rate being 64.8%. To improve open source models on subtask, we explore two common training techniques: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). Experiments show that SFT models obtain a 48.8% success rate on the benchmark. Training with RLVR over SFT checkpoints, even in data-scarce settings, improves the score to 52.8% on WARC-Bench, outperforming many frontier models. Our analysis concludes that mastering these subtasks is essential for robust web planning and navigation, and is a capability not extensively evaluated by existing benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09872","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.579232","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Sanjari Srivastava, Gang Li, Cheng Chang, Rishu Garg, Manpreet Kaur, Charlene Y. Lee, Yuezhang Li, Yining Mao, Ignacio Cases, Yanan Xie, Peng Qi","raw_content_length":1274,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["SFT","WARC-Bench"],"persons":["WARC-Bench","WARC arXiv:2510.09872v1 Announce Type:"],"locations":[],"monetary":[]},"char_count":1273,"language_detected":"en","key_concepts":{"key_phrases":["WARC","Announce Type","new Abstract","Training web agents","complex real-world websites","them","textitsubtasks - short-horizon interactions","multiple UI components","the correct date","a date picker"],"filter_categories":{"ai_ml":["Training web agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"WARC":2.0,"Announce Type":1.0,"new Abstract":1.0,"Training web agents":1.0,"complex real-world websites":1.0,"them":1.0,"textitsubtasks - short-horizon interactions":1.0,"multiple UI components":1.0,"the correct date":1.0,"a date picker":1.0}},"age_hours":2.7462260411111115,"is_recent":true,"quality_score":0.7,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.895,"joy":0.0186,"surprise":0.06,"sadness":0.0032,"fear":0.0099,"anger":0.0106,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for web navigation AI agents. While it improves AI capabilities, its direct climate impact is minimal, and economic viability is not addressed. The technology is in the applied research stage, with some metrics provided (success rates of 64.8%, 48.8%, and 52.8%).","key_impact_metrics":["Success rate on benchmark 64.8%","SFT model success rate 48.8%","RLVR model success rate 52.8%"],"technology_tags":["Web navigation AI","Reinforcement learning","Supervised fine-tuning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:00:04.876532Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2ad2a9009496","title":"ROBOPSY PL[AI]: Using Role","content":"arXiv:2510.09874v1 Announce Type: new Abstract: The paper presents the first results of an artistic research project investigating how Large Language Models (LLMs) curate and present collective memory. In a public installation exhibited during two months in Vienna in 2025, visitors could interact with five different LLMs (ChatGPT with GPT 4o and GPT 4o mini, Mistral Large, DeepSeek-Chat, and a locally run Llama 3.1 model), which were instructed to act as narrators, implementing a role-playing game revolving around the murder of Austrian philosopher Moritz Schlick in 1936. Results of the investigation include protocols of LLM-user interactions during the game and qualitative conversations after the play experience to get insight into the players' reactions to the game. In a quantitative analysis 115 introductory texts for role-playing generated by the LLMs were examined by different methods of natural language processing, including semantic similarity and sentiment analysis. While the qualitative player feedback allowed to distinguish three distinct types of users, the quantitative text analysis showed significant differences between how the different LLMs presented the historical content. Our study thus adds to ongoing efforts to analyse LLM performance, but also suggests a way of how these efforts can be disseminated in a playful way to a general audience.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09874","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.579661","language":"en","tags":["computer-science","cscy","csai","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Margarete Jahrmann, Thomas Brandstetter, Stefan Glasauer","raw_content_length":1380,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["LLM","ROBOPSY","GPT"],"persons":["Moritz Schlick","Mistral Large"],"locations":["Vienna"],"monetary":[]},"char_count":1379,"language_detected":"en","key_concepts":{"key_phrases":["ROBOPSY PLAI","Role","arXiv251009874v1 Announce Type","new Abstract","The paper","the first results","an artistic research project","how Large Language Models","LLMs","curate"],"filter_categories":{"ai_ml":["ROBOPSY PLAI","how Large Language Models"],"research_academic":["an artistic research project"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ROBOPSY PLAI":2.0,"Role":2.0,"arXiv251009874v1 Announce Type":1.0,"new Abstract":1.0,"The paper":1.0,"the first results":1.0,"an artistic research project":1.0,"how Large Language Models":1.0,"LLMs":1.0,"curate":1.0}},"age_hours":2.7462419077777778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6603,"joy":0.2148,"surprise":0.0896,"sadness":0.0048,"fear":0.0049,"anger":0.0148,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an artistic research project using LLMs. While it analyzes LLM performance and user interaction, it does not directly address climate change or environmental sustainability. The deployment is a public installation, but there are no concrete actions or measurable outcomes related to sustainability.","key_impact_metrics":["115 introductory texts examined","Three distinct types of users distinguished"],"technology_tags":["Large Language Models","Natural Language Processing"],"sdg_alignment":[4,16],"analyzed_at":"2025-10-29T11:00:07.840738Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0eed8e9ea6f9","title":"Myopic Bayesian Decision Theory for Batch Active Learning with Partial Batch Label Sampling","content":"arXiv:2510.09877v1 Announce Type: new Abstract: Over the past couple of decades, many active learning acquisition functions have been proposed, leaving practitioners with an unclear choice of which to use. Bayesian Decision Theory (BDT) offers a universal principle to guide decision-making. In this work, we derive BDT for (Bayesian) active learning in the myopic framework, where we imagine we only have one more point to label. This derivation leads to effective algorithms such as Expected Error Reduction (EER), Expected Predictive Information Gain (EPIG), and other algorithms that appear in the literature. Furthermore, we show that BAIT (active learning based on V-optimal experimental design) can be derived from BDT and asymptotic approximations. A key challenge of such methods is the difficult scaling to large batch sizes, leading to either computational challenges (BatchBALD) or dramatic performance drops (top-$B$ selection). Here, using a particular formulation of the decision process, we derive Partial Batch Label Sampling (ParBaLS) for the EPIG algorithm. We show experimentally for several datasets that ParBaLS EPIG gives superior performance for a fixed budget and Bayesian Logistic Regression on Neural Embeddings. Our code is available at https://github.com/ADDAPT-ML/ParBaLS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09877","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.580064","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Kangping Hu, Stephen Mussmann","raw_content_length":1303,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Expected Predictive Information Gain (","Bayesian Decision Theory","Myopic Bayesian Decision Theory for","Expected Error Reduction","BDT"],"persons":[],"locations":["Bayesian"],"monetary":[]},"char_count":1302,"language_detected":"en","key_concepts":{"key_phrases":["Myopic Bayesian Decision Theory","Batch Active Learning","Partial Batch Label Sampling","BDT","new Abstract","the past couple","decades","many active learning acquisition functions","practitioners","an unclear choice"],"filter_categories":{"business_innovation":["many active learning acquisition functions"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Myopic Bayesian Decision Theory":2.0,"Batch Active Learning":2.0,"Partial Batch Label Sampling":2.0,"BDT":2.0,"new Abstract":1.0,"the past couple":1.0,"decades":1.0,"many active learning acquisition functions":1.0,"practitioners":1.0,"an unclear choice":1.0}},"age_hours":2.7462586208333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8992,"joy":0.0104,"surprise":0.0657,"sadness":0.0053,"fear":0.0049,"anger":0.0102,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm (ParBaLS) for active learning, which could potentially improve the efficiency of machine learning models used in sustainability applications. The concrete action is the development and experimental validation of this algorithm on several datasets. However, the article does not provide specific metrics on how this algorithm translates to real-world sustainability outcomes, and it is currently in the applied research stage.","key_impact_metrics":["Superior performance for a fixed budget","Bayesian Logistic Regression on Neural Embeddings"],"technology_tags":["Active Learning","Machine Learning","Bayesian Decision Theory"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:00:11.084686Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e95b76f68b4","title":"Fast Self","content":"arXiv:2510.09878v1 Announce Type: new Abstract: Multi-object tracking (MOT) methods often rely on Intersection-over-Union (IoU) for association. However, this becomes unreliable when objects are similar or occluded. Also, computing IoU for segmentation masks is computationally expensive. In this work, we use segmentation masks to capture object shapes, but we do not compute segmentation IoU. Instead, we fuse depth and mask features and pass them through a compact encoder trained self-supervised. This encoder produces stable object representations, which we use as an additional similarity cue alongside bounding box IoU and re-identification features for matching. We obtain depth maps from a zero-shot depth estimator and object masks from a promptable visual segmentation model to obtain fine-grained spatial cues. Our MOT method is the first to use the self-supervised encoder to refine segmentation masks without computing masks IoU. MOT can be divided into joint detection-ReID (JDR) and tracking-by-detection (TBD) models. The latter are computationally more efficient. Experiments of our TBD method on challenging benchmarks with non-linear motion, occlusion, and crowded scenes, such as SportsMOT and DanceTrack, show that our method outperforms the TBD state-of-the-art on most metrics, while achieving competitive performance on simpler benchmarks with linear motion, such as MOT17.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09878","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.580470","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Milad Khanchi, Maria Amer, Charalambos Poullis","raw_content_length":1399,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["IoU"],"persons":["IoU"],"locations":[],"monetary":[]},"char_count":1398,"language_detected":"en","key_concepts":{"key_phrases":["Fast Self","segmentation masks","arXiv251009878v1 Announce Type","new Abstract Multi-object tracking MOT methods","Union","association","objects","IoU","this work","object shapes"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fast Self":2.0,"segmentation masks":2.0,"arXiv251009878v1 Announce Type":1.0,"new Abstract Multi-object tracking MOT methods":1.0,"Union":1.0,"association":1.0,"objects":1.0,"IoU":1.0,"this work":1.0,"object shapes":1.0}},"age_hours":2.7462746027777776,"is_recent":true,"quality_score":1.0,"sentiment_score":4.9005,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0199,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7904,"joy":0.0025,"surprise":0.018,"sadness":0.0234,"fear":0.0437,"anger":0.0384,"disgust":0.0837},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to multi-object tracking using self-supervised learning and depth estimation. While it improves tracking performance on specific benchmarks, it's currently in the research phase with no deployed units or quantifiable environmental benefits. The potential climate impact is low as it doesn't directly address GHG emissions or resource consumption.","key_impact_metrics":["Improved tracking performance on SportsMOT and DanceTrack"],"technology_tags":["Multi-object tracking","Self-supervised learning","Depth estimation","Segmentation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:00:13.657457Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a88597600a27","title":"CHUG: Crowdsourced User","content":"arXiv:2510.09879v1 Announce Type: new Abstract: High Dynamic Range (HDR) videos enhance visual experiences with superior brightness, contrast, and color depth. The surge of User-Generated Content (UGC) on platforms like YouTube and TikTok introduces unique challenges for HDR video quality assessment (VQA) due to diverse capture conditions, editing artifacts, and compression distortions. Existing HDR-VQA datasets primarily focus on professionally generated content (PGC), leaving a gap in understanding real-world UGC-HDR degradations. To address this, we introduce CHUG: Crowdsourced User-Generated HDR Video Quality Dataset, the first large-scale subjective study on UGC-HDR quality. CHUG comprises 856 UGC-HDR source videos, transcoded across multiple resolutions and bitrates to simulate real-world scenarios, totaling 5,992 videos. A large-scale study via Amazon Mechanical Turk collected 211,848 perceptual ratings. CHUG provides a benchmark for analyzing UGC-specific distortions in HDR videos. We anticipate CHUG will advance No-Reference (NR) HDR-VQA research by offering a large-scale, diverse, and real-world UGC dataset. The dataset is publicly available at: https://shreshthsaini.github.io/CHUG/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09879","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.580882","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Shreshth Saini, Alan C. Bovik, Neil Birkbeck, Yilin Wang, Balu Adsumilli","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Crowdsourced User arXiv:2510.09879v1 Announce Type","UGC","CHUG","User-Generated Content","UGC-HDR","HDR","Amazon Mechanical Turk","PGC","YouTube","VQA","TikTok","Crowdsourced User-Generated HDR Video Quality Dataset"],"persons":[],"locations":[],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["CHUG","Crowdsourced User","Announce Type","new Abstract","HDR","visual experiences","superior brightness","contrast","color depth","The surge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CHUG":2.0,"Crowdsourced User":2.0,"Announce Type":1.0,"new Abstract":1.0,"HDR":1.0,"visual experiences":1.0,"superior brightness":1.0,"contrast":1.0,"color depth":1.0,"The surge":1.0}},"age_hours":2.746291101111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4425,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8885,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8559,"joy":0.0627,"surprise":0.0628,"sadness":0.0035,"fear":0.003,"anger":0.0085,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new dataset for HDR video quality assessment. While the dataset itself doesn't directly reduce GHG emissions, it could indirectly support the development of more efficient video compression algorithms, potentially reducing energy consumption in video streaming. The technical credibility is relatively high due to the large-scale subjective study and publicly available dataset, but it is still in the basic research stage.","key_impact_metrics":["856 UGC-HDR source videos","211,848 perceptual ratings"],"technology_tags":["HDR video","video quality assessment","crowdsourcing"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:00:16.668017Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bf74a5c268dc","title":"LTGS: Long","content":"arXiv:2510.09881v1 Announce Type: new Abstract: Recent advances in novel-view synthesis can create the photo-realistic visualization of real-world environments from conventional camera captures. However, acquiring everyday environments from casual captures faces challenges due to frequent scene changes, which require dense observations both spatially and temporally. We propose long-term Gaussian scene chronology from sparse-view updates, coined LTGS, an efficient scene representation that can embrace everyday changes from highly under-constrained casual captures. Given an incomplete and unstructured Gaussian splatting representation obtained from an initial set of input images, we robustly model the long-term chronology of the scene despite abrupt movements and subtle environmental variations. We construct objects as template Gaussians, which serve as structural, reusable priors for shared object tracks. Then, the object templates undergo a further refinement pipeline that modulates the priors to adapt to temporally varying environments based on few-shot observations. Once trained, our framework is generalizable across multiple time steps through simple transformations, significantly enhancing the scalability for a temporal evolution of 3D environments. As existing datasets do not explicitly represent the long-term real-world changes with a sparse capture setup, we collect real-world datasets to evaluate the practicality of our pipeline. Experiments demonstrate that our framework achieves superior reconstruction quality compared to other baselines while enabling fast and light-weight updates.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09881","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.581699","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Minkwan Kim, Seungmin Lee, Junho Kim, Young Min Kim","raw_content_length":1620,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1619,"language_detected":"en","key_concepts":{"key_phrases":["LTGS","arXiv251009881v1 Announce Type","new Abstract","Recent advances","novel-view synthesis","the photo-realistic visualization","real-world environments","conventional camera captures","everyday environments","casual captures"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LTGS":2.0,"arXiv251009881v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"novel-view synthesis":1.0,"the photo-realistic visualization":1.0,"real-world environments":1.0,"conventional camera captures":1.0,"everyday environments":1.0,"casual captures":1.0}},"age_hours":2.746320023888889,"is_recent":true,"quality_score":0.7,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9046,"joy":0.0462,"surprise":0.0273,"sadness":0.003,"fear":0.0074,"anger":0.0085,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a novel method for 3D scene reconstruction from sparse images, which could potentially reduce the need for extensive data collection and processing. This could indirectly reduce energy consumption associated with data centers and computational resources. However, the impact is theoretical and lacks concrete deployment data or quantified energy savings.","key_impact_metrics":["Superior reconstruction quality compared to other baselines","Fast and light-weight updates"],"technology_tags":["Novel-view synthesis","Gaussian splatting","3D reconstruction"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:00:19.798072Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1b0d420b4b62","title":"iBERT: Interpretable Style Embeddings via Sense Decomposition","content":"arXiv:2510.09882v1 Announce Type: new Abstract: We present iBERT (interpretable-BERT), an encoder to produce inherently interpretable and controllable embeddings - designed to modularize and expose the discriminative cues present in language, such as stylistic and semantic structure. Each input token is represented as a sparse, non-negative mixture over k context-independent sense vectors, which can be pooled into sentence embeddings or used directly at the token level. This enables modular control over representation, before any decoding or downstream use. To demonstrate our model's interpretability, we evaluate it on a suite of style-focused tasks. On the STEL benchmark, it improves style representation effectiveness by ~8 points over SBERT-style baselines, while maintaining competitive performance on authorship verification. Because each embedding is a structured composition of interpretable senses, we highlight how specific style attributes - such as emoji use, formality, or misspelling can be assigned to specific sense vectors. While our experiments center on style, iBERT is not limited to stylistic modeling. Its structural modularity is designed to interpretably decompose whichever discriminative signals are present in the data - enabling generalization even when supervision blends stylistic and semantic factors.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09882","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.582102","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Vishal Anand, Milad Alshomary, Kathleen McKeown","raw_content_length":1343,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Sense Decomposition arXiv:2510.09882v1"],"persons":[],"locations":["STEL"],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["iBERT","Interpretable Style Embeddings","Sense Decomposition","arXiv251009882v1 Announce Type","new Abstract","interpretable-BERT","an encoder","inherently interpretable and controllable embeddings","the discriminative cues","language"],"filter_categories":{"ai_ml":["language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"iBERT":3.0,"Interpretable Style Embeddings":2.0,"Sense Decomposition":2.0,"arXiv251009882v1 Announce Type":1.0,"new Abstract":1.0,"interpretable-BERT":1.0,"an encoder":1.0,"inherently interpretable and controllable embeddings":1.0,"the discriminative cues":1.0,"language":1.0}},"age_hours":2.7463362055555556,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9003,"joy":0.0197,"surprise":0.0496,"sadness":0.0048,"fear":0.005,"anger":0.0131,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (iBERT) for creating interpretable language embeddings. While it improves style representation effectiveness by ~8 points on the STEL benchmark, it's still in the research phase with no clear path to deployment or direct climate impact. The technology is at a very early stage, lacking deployment or economic viability data.","key_impact_metrics":["Style representation effectiveness improvement on STEL benchmark: ~8 points"],"technology_tags":["Natural Language Processing","Machine Learning","BERT"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:00:23.310328Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b2014d4b56f3","title":"DELTA: Dynamic Layer","content":"arXiv:2510.09883v1 Announce Type: new Abstract: Large reasoning models (LRMs) achieve state-of-the-art performance on challenging benchmarks by generating long chains of intermediate steps, but their inference cost is dominated by decoding, where each new token must attend to the entire growing sequence. Existing sparse attention methods reduce computation by pruning the key-value (KV) cache, yet they suffer from severe accuracy degradation on reasoning tasks due to cumulative selection errors and the dynamic importance of tokens over long derivations. We present \\textbf{DELTA}, a training-free sparse attention mechanism that achieves computational efficiency without sacrificing model accuracy. DELTA partitions transformer layers into three groups: initial layers that use full attention, a small set of \\emph{selection layers} that identify salient tokens via aggregated head-level attention scores, and subsequent \\emph{sparse-attention layers} that attend only to the selected subset. This design preserves the full KV cache in GPU memory for accuracy, while avoiding expensive full-attention computation over many layers. On reasoning benchmarks such as AIME and GPQA-Diamond, DELTA matches or surpasses full attention in accuracy, while reducing the number of attended tokens by up to $5\\times$ and delivering $1.5\\times$ end-to-end speedup. Our results show that selective reuse of intermediate attention maps offers a robust path toward efficient long-context reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09883","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.582529","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Hossein Entezari Zarch, Lei Gao, Chaoyi Jiang, Murali Annavarm","raw_content_length":1488,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["DELTA"],"persons":[],"locations":["LRMs"],"monetary":[]},"char_count":1487,"language_detected":"en","key_concepts":{"key_phrases":["DELTA","Dynamic Layer","arXiv251009883v1 Announce Type","new Abstract","Large reasoning models","LRMs","the-art","challenging benchmarks","long chains","intermediate steps"],"filter_categories":{"ai_ml":["long chains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DELTA":2.0,"Dynamic Layer":2.0,"arXiv251009883v1 Announce Type":1.0,"new Abstract":1.0,"Large reasoning models":1.0,"LRMs":1.0,"the-art":1.0,"challenging benchmarks":1.0,"long chains":1.0,"intermediate steps":1.0}},"age_hours":2.746351038888889,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5449999999999999,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.891,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5424,"joy":0.0055,"surprise":0.0516,"sadness":0.1709,"fear":0.0246,"anger":0.0696,"disgust":0.1355},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel sparse attention mechanism (DELTA) that improves the efficiency of large reasoning models. It achieves a 1.5x speedup and reduces the number of attended tokens by up to 5x while maintaining or surpassing full attention accuracy on reasoning benchmarks. While promising, it is still in the research phase, lacking deployment data and independent validation.","key_impact_metrics":["attended tokens reduced by 5x","end-to-end speedup of 1.5x"],"technology_tags":["sparse attention","large language models","AI efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:00:26.984966Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aff660190fa1","title":"TAWRMAC: A Novel Dynamic Graph Representation Learning Method","content":"arXiv:2510.09884v1 Announce Type: new Abstract: Dynamic graph representation learning has become essential for analyzing evolving networks in domains such as social network analysis, recommendation systems, and traffic analysis. However, existing continuous-time methods face three key challenges: (1) some methods depend solely on node-specific memory without effectively incorporating information from neighboring nodes, resulting in embedding staleness; (2) most fail to explicitly capture correlations between node neighborhoods, limiting contextual awareness; and (3) many fail to fully capture the structural dynamics of evolving graphs, especially in absence of rich link attributes. To address these limitations, we introduce TAWRMAC-a novel framework that integrates Temporal Anonymous Walks with Restart, Memory Augmentation, and Neighbor Co-occurrence embedding. TAWRMAC enhances embedding stability through a memory-augmented GNN with fixedtime encoding and improves contextual representation by explicitly capturing neighbor correlations. Additionally, its Temporal Anonymous Walks with Restart mechanism distinguishes between nodes exhibiting repetitive interactions and those forming new connections beyond their immediate neighborhood. This approach captures structural dynamics better and supports strong inductive learning. Extensive experiments on multiple benchmark datasets demonstrate that TAWRMAC consistently outperforms state-of-the-art methods in dynamic link prediction and node classification under both transductive and inductive settings across three different negative sampling strategies. By providing stable, generalizable, and context-aware embeddings, TAWRMAC advances the state of the art in continuous-time dynamic graph learning. The code is available at https://anonymous.4open.science/r/tawrmac-A253 .","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09884","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.582955","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Soheila Farokhi, Xiaojun Qi, Hamid Karimi","raw_content_length":1842,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["TAWRMAC","Neighbor Co"],"persons":["Anonymous Walks","node neighborhoods"],"locations":[],"monetary":[]},"char_count":1841,"language_detected":"en","key_concepts":{"key_phrases":["TAWRMAC","arXiv251009884v1 Announce Type","new Abstract","Dynamic graph representation learning","networks","domains","social network analysis","recommendation systems","traffic analysis","existing continuous-time methods"],"filter_categories":{"ai_ml":["networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TAWRMAC":2.0,"arXiv251009884v1 Announce Type":1.0,"new Abstract":1.0,"Dynamic graph representation learning":1.0,"networks":1.0,"domains":1.0,"social network analysis":1.0,"recommendation systems":1.0,"traffic analysis":1.0,"existing continuous-time methods":1.0}},"age_hours":2.746365393611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6591,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8636,"joy":0.0104,"surprise":0.0466,"sadness":0.0233,"fear":0.0311,"anger":0.0181,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel dynamic graph representation learning method (TAWRMAC). While it demonstrates improved performance in link prediction and node classification on benchmark datasets, it is still in the research phase with no concrete deployments or quantified climate impact. The potential for sustainability impact is indirect, as improved graph learning could potentially optimize systems related to energy or resource management, but this is not explicitly demonstrated.","key_impact_metrics":["Improved performance in dynamic link prediction","Improved performance in node classification"],"technology_tags":["Dynamic graph representation learning","Temporal Anonymous Walks with Restart","Memory Augmentation","Neighbor Co-occurrence embedding"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:00:30.108893Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_44ca1b8fb1e1","title":"Closing the Data","content":"arXiv:2510.09885v1 Announce Type: new Abstract: Despite autoregressive large language models (arLLMs) being the current dominant paradigm in language modeling, they resist knowledge injection via fine-tuning due to inherent shortcomings such as the \"reversal curse\" -- the challenge of answering questions that reverse the original information order in the training sample. Masked diffusion large language models (dLLMs) are rapidly emerging as a powerful alternative to the arLLM paradigm, with evidence of better data efficiency and free of the \"reversal curse\" in pre-training. However, it is unknown whether these advantages extend to the post-training phase, i.e. whether pre-trained dLLMs can easily acquire new knowledge through fine-tuning. On three diverse datasets, we fine-tune arLLMs and dLLMs, evaluating them with forward and backward style Question Answering (QA) to probe knowledge generalization and the reversal curse. Our results confirm that arLLMs critically rely on extensive data augmentation via paraphrases for QA generalization, and paraphrases are only effective when their information order matches the QA style. Conversely, dLLMs achieve high accuracies on both forward and backward QAs without paraphrases; adding paraphrases yields only marginal gains. Lastly, inspired by the dLLM's performance, we introduce a novel masked fine-tuning paradigm for knowledge injection into pre-trained arLLMs. This proposed method successfully and drastically improves the data efficiency of arLLM fine-tuning, effectively closing the performance gap with dLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09885","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.583364","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Xu Pan, Ely Hahami, Jingxuan Fan, Ziqian Xie, Haim Sompolinsky","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["Question Answering","the Data arXiv:2510.09885v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["the Data","arXiv251009885v1 Announce Type","new Abstract","autoregressive large language models","arLLMs","the current dominant paradigm","language modeling","knowledge injection","fine-tuning","inherent shortcomings"],"filter_categories":{"ai_ml":["autoregressive large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Data":2.0,"arXiv251009885v1 Announce Type":1.0,"new Abstract":1.0,"autoregressive large language models":1.0,"arLLMs":1.0,"the current dominant paradigm":1.0,"language modeling":1.0,"knowledge injection":1.0,"fine-tuning":1.0,"inherent shortcomings":1.0}},"age_hours":2.746380313888889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8983,"joy":0.0137,"surprise":0.0433,"sadness":0.0094,"fear":0.0123,"anger":0.0119,"disgust":0.0111},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel masked fine-tuning paradigm for knowledge injection into pre-trained arLLMs, showing improved data efficiency. The evidence is based on experimental results on three datasets. It is currently in the basic research stage, with no deployment or commercialization.","key_impact_metrics":["High accuracies on forward and backward QAs","Drastically improves the data efficiency of arLLM fine-tuning"],"technology_tags":["Large Language Models","Masked Diffusion Models","Knowledge Injection"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:00:33.220456Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_328b06b7a4e1","title":"Abductive Preference Learning","content":"arXiv:2510.09887v1 Announce Type: new Abstract: Frontier large language models such as GPT-5 and Claude Sonnet remain prone to overconfidence even after alignment through Reinforcement Learning with Human Feedback (RLHF) and Direct Preference Optimization (DPO). For instance, they tend to offer the same conservative answer \"No\" to both questions \"Can I eat the [food / potato chips] that has been left out overnight?\" despite the latter requiring no refridgeration for safe consumption. We find that this failure is potentially attributed to a limitation of existing preference learning: it emphasizes selecting the correct response for a given prompt, while neglecting counterfactual prompts that should alter the response. To address this limitation, we propose abductive preference learning, a fine-tuning paradigm that reverses the conventional conditioning by learning preferences over prompts given a response. To validate this idea, we construct an abductive dataset derived from the HaluEval QA benchmark with 1,001 entries, implementing abductive DPO and its variant DPOP. Experiments reveal complementary strengths: standard methods improve response selection, abductive methods improve prompt discrimination, while a multitask objective unifies both. On the abductive dataset, multitask DPOP boosts accuracy from $90.0\\%$ to $99.5\\%$ in response selection and $54.7\\%$ to $85.0\\%$ in prompt discrimination, with qualitative evidence highlighting improved sensitivity to prompt differences. Finally, evaluation on AlpacaEval shows multitask DPOP improves win rate (from $5.26\\%$ to $6.17\\%$), confirming that abductive preference learning preserves the benefits of conventional preference optimization while addressing the overlooked challenge of counterfactual prompts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09887","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.583808","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Yijin Ni, Peng Qi","raw_content_length":1785,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["Direct Preference Optimization","Frontier","Reinforcement Learning with Human Feedback","DPO"],"persons":["Claude Sonnet"],"locations":[],"monetary":[]},"char_count":1782,"language_detected":"en","key_concepts":{"key_phrases":["Abductive Preference Learning","arXiv251009887v1","Announce Type","new Abstract","Frontier large language models","GPT-5","Claude Sonnet","overconfidence","alignment","Reinforcement Learning"],"filter_categories":{"ai_ml":["Frontier large language models","GPT-5","Claude Sonnet","Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Abductive Preference Learning":2.0,"arXiv251009887v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Frontier large language models":1.0,"GPT-5":1.0,"Claude Sonnet":1.0,"overconfidence":1.0,"alignment":1.0,"Reinforcement Learning":1.0}},"age_hours":2.7463955144444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9254,"joy":0.0027,"surprise":0.0205,"sadness":0.0077,"fear":0.0239,"anger":0.0085,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for improving the reliability of large language models. While the technology itself does not directly address climate change, it could indirectly contribute by improving the accuracy of information related to sustainability and climate action. The research is in the applied research stage, with experiments conducted on a dataset, but no real-world deployment is mentioned, hence low readiness.","key_impact_metrics":["accuracy improvement in response selection from 90.0% to 99.5%","accuracy improvement in prompt discrimination from 54.7% to 85.0%"],"technology_tags":["large language models","preference learning","abductive reasoning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:00:36.686144Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
