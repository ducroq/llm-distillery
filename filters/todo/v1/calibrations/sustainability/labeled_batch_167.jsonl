{"id":"science_arxiv_cs_9ccab0a3c918","title":"CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction","content":"arXiv:2510.12703v1 Announce Type: new Abstract: Autonomous driving remains a challenging task, particularly due to safety concerns. Modern vehicles are typically equipped with expensive sensors such as LiDAR, cameras, and radars to reduce the risk of accidents. However, these sensors face inherent limitations: their field of view and line of sight can be obstructed by other vehicles, thereby reducing situational awareness. In this context, vehicle-to-vehicle communication plays a crucial role, as it enables cars to share information and remain aware of each other even when sensors are occluded. One way to achieve this is through the use of Cooperative Awareness Messages (CAMs). In this paper, we investigate the use of CAM data for vehicle trajectory prediction. Specifically, we design and train a neural network, Cooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely used motion forecasting dataset. We then evaluate the model on a second dataset that we created from scratch using Cooperative Awareness Messages, in order to assess whether this type of data can be effectively exploited. Our approach demonstrates promising results, showing that CAMs can indeed support vehicle trajectory prediction. At the same time, we discuss several limitations of the approach, which highlight opportunities for future research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12703","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.430991","language":"en","tags":["preprints","csai","csni","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Mattia Grasselli, Angelo Porrello, Carlo Augusto Grazia","raw_content_length":1355,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":["Cooperative Awareness","Vehicle Trajectory Prediction arXiv:2510.12703v1 Announce Type","CAM","Graph Neural Network"],"persons":[],"locations":[],"monetary":[]},"char_count":1354,"language_detected":"en","key_concepts":{"key_phrases":["CAMNet","Cooperative Awareness Messages","Vehicle Trajectory Prediction","arXiv251012703v1 Announce Type","new Abstract","Autonomous driving","a challenging task","safety concerns","Modern vehicles","expensive sensors"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CAMNet":2.0,"Cooperative Awareness Messages":2.0,"Vehicle Trajectory Prediction":2.0,"arXiv251012703v1 Announce Type":1.0,"new Abstract":1.0,"Autonomous driving":1.0,"a challenging task":1.0,"safety concerns":1.0,"Modern vehicles":1.0,"expensive sensors":1.0}},"age_hours":2.743372888888889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.3395,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0679,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.464,"joy":0.0048,"surprise":0.0137,"sadness":0.0117,"fear":0.466,"anger":0.0276,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research into using vehicle-to-vehicle communication to improve autonomous driving safety. While safer driving could reduce accidents and potentially improve fuel efficiency, the impact on GHG emissions is indirect and not quantified. The research is in an early stage, with evaluation on a created dataset, but no real-world deployment.","key_impact_metrics":["Improved trajectory prediction accuracy","Dataset created from Cooperative Awareness Messages"],"technology_tags":["Autonomous driving","Vehicle-to-vehicle communication","Neural networks","Trajectory prediction"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:30:29.212355Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_05c115e2d47b","title":"SAIL","content":"arXiv:2510.12709v1 Announce Type: new Abstract: Multimodal embedding models aim to yield informative unified representations that empower diverse cross-modal tasks. Despite promising developments in the evolution from CLIP-based dual-tower architectures to large vision-language models, prior works still face unavoidable challenges in real-world applications and business scenarios, such as the limited modality support, unstable training mechanisms, and industrial domain gaps. In this work, we introduce SAIL-Embedding, an omni-modal embedding foundation model that addresses these issues through tailored training strategies and architectural design. In the optimization procedure, we propose a multi-stage training scheme to boost the multifaceted effectiveness of representation learning. Specifically, the content-aware progressive training aims to enhance the model's adaptability to diverse downstream tasks and master enriched cross-modal proficiency. The collaboration-aware recommendation enhancement training further adapts multimodal representations for recommendation scenarios by distilling knowledge from sequence-to-item and ID-to-item embeddings while mining user historical interests. Concurrently, we develop the stochastic specialization and dataset-driven pattern matching to strengthen model training flexibility and generalizability. Experimental results show that SAIL-Embedding achieves SOTA performance compared to other methods in different retrieval tasks. In online experiments across various real-world scenarios integrated with our model, we observe a significant increase in Lifetime (LT), which is a crucial indicator for the recommendation experience. For instance, the model delivers the 7-day LT gain of +0.158% and the 14-day LT gain of +0.144% in the Douyin-Selected scenario. For the Douyin feed rank model, the match features produced by SAIL-Embedding yield a +0.08% AUC gain.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12709","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.432268","language":"en","tags":["preprints","csir","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Lin Lin, Jiefeng Long, Zhihe Wan, Yuchi Wang, Dingkang Yang, Shuang Yang, Yueyang Yao, Xu Chen, Zirui Guo, Shengqiang Li, Weiran Li, Hanyu Li, Yaling Mou, Yan Qiu, Haiyang Yu, Xiao Liang, Hongsheng Li, Chao Feng","raw_content_length":1920,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["CLIP","SAIL arXiv:2510.12709v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1919,"language_detected":"en","key_concepts":{"key_phrases":["SAIL","arXiv251012709v1 Announce Type","new Abstract","Multimodal embedding models","informative unified representations","diverse cross-modal tasks","promising developments","the evolution","large vision-language models","prior works"],"filter_categories":{"ai_ml":["SAIL"],"engineering":["promising developments"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SAIL":2.0,"arXiv251012709v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal embedding models":1.0,"informative unified representations":1.0,"diverse cross-modal tasks":1.0,"promising developments":1.0,"the evolution":1.0,"large vision-language models":1.0,"prior works":1.0}},"age_hours":2.7434166261111113,"is_recent":true,"quality_score":0.7,"sentiment_score":4.925,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.015,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7641,"joy":0.0072,"surprise":0.0143,"sadness":0.0704,"fear":0.109,"anger":0.0143,"disgust":0.0208},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a new multimodal embedding model (SAIL-Embedding) and its application in recommendation systems. The concrete action is the deployment of this model in Douyin, resulting in a reported increase in Lifetime (LT) and AUC gain. However, the sustainability impact is indirect and relies on the assumption that improved recommendation systems can influence user behavior towards more sustainable choices, which is not explicitly addressed or quantified.","key_impact_metrics":["7-day LT gain of +0.158%","14-day LT gain of +0.144%"],"technology_tags":["multimodal embedding","recommendation system","machine learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:30:32.258659Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4b162b62e7f7","title":"Reflection","content":"arXiv:2510.12710v1 Announce Type: new Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap towards general-purpose robots, yet efficiently adapting them to novel, specific tasks in-situ remains a significant hurdle. While reinforcement learning (RL) is a promising avenue for such adaptation, the process often suffers from low efficiency, hindering rapid task mastery. We introduce Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation without human intervention. Our framework establishes a self-improving loop where the agent learns from its own experience to enhance both strategy and execution. The core of our framework is a dual-pathway architecture that addresses the full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway enables rapid learning by using the VLM's causal reasoning to automatically synthesize a targeted, dense reward function from failure analysis. This provides a focused learning signal that significantly accelerates policy exploration. However, optimizing such proxy rewards introduces a potential risk of \"reward hacking,\" where the agent masters the reward function but fails the actual task. To counteract this, our second pathway, Success-Driven Quality-Guided SFT, grounds the policy in holistic success. It identifies and selectively imitates high-quality successful trajectories, ensuring the agent remains aligned with the ultimate task goal. This pathway is strengthened by a conditional curriculum mechanism to aid initial exploration. We conduct experiments in challenging manipulation tasks. The results demonstrate that our framework achieves faster convergence and higher final success rates compared to representative baselines. Our work presents a robust solution for creating self-improving agents that can efficiently and reliably adapt to new environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12710","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.432720","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Baicheng Li, Dong Wu, Zike Yan, Xinchen Liu, Zecui Zeng, Lusong Li, Hongbin Zha","raw_content_length":1880,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":["Reflective Self-Adaptation","Vision-Language-Action","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1875,"language_detected":"en","key_concepts":{"key_phrases":["Reflection","arXiv251012710v1","Announce Type","new Abstract","Pre-trained Vision-Language-Action VLA models","a major leap","general-purpose robots","them","specific tasks","situ"],"filter_categories":{"ai_ml":["Pre-trained Vision-Language-Action VLA models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reflection":2.0,"arXiv251012710v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Pre-trained Vision-Language-Action VLA models":1.0,"a major leap":1.0,"general-purpose robots":1.0,"them":1.0,"specific tasks":1.0,"situ":1.0}},"age_hours":2.743431556388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8823,"joy":0.0067,"surprise":0.0205,"sadness":0.0152,"fear":0.0253,"anger":0.0222,"disgust":0.0277},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a novel framework for robot task adaptation using reinforcement learning. While the results demonstrate faster convergence and higher success rates compared to baselines, it is still in the research phase with no deployed units or real-world impact data. The climate impact is theoretical, as it could potentially improve efficiency in various sectors, but there are no specific metrics related to GHG emissions reduction.","key_impact_metrics":["Faster convergence","Higher final success rates"],"technology_tags":["Vision-Language-Action models","Reinforcement Learning","Robotics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:34.925536Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d6f6efe1f1ff","title":"Beyond Seeing: Evaluating Multimodal LLMs on Tool","content":"arXiv:2510.12712v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in real-world scenarios where user-provided images are often imperfect, requiring active image manipulations such as cropping, editing, or enhancement to uncover salient visual cues. Beyond static visual perception, MLLMs must also think with images: dynamically transforming visual content and integrating it with other tools to solve complex tasks. However, this shift from treating vision as passive context to a manipulable cognitive workspace remains underexplored. Most existing benchmarks still follow a think about images paradigm, where images are regarded as static inputs. To address this gap, we introduce IRIS, an Interactive Reasoning with Images and Systems that evaluates MLLMs' ability to perceive, transform, and reason across complex visual-textual tasks under the think with images paradigm. IRIS comprises 1,204 challenging, open-ended vision tasks (603 single-turn, 601 multi-turn) spanning across five diverse domains, each paired with detailed rubrics to enable systematic evaluation. Our evaluation shows that current MLLMs struggle with tasks requiring effective integration of vision and general-purpose tools. Even the strongest model (GPT-5-think) reaches only 18.68% pass rate. We further observe divergent tool-use behaviors, with OpenAI models benefiting from diverse image manipulations while Gemini-2.5-pro shows no improvement. By introducing the first benchmark centered on think with images, IRIS offers critical insights for advancing visual intelligence in MLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12712","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.433280","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Xingang Guo, Utkarsh Tyagi, Advait Gosai, Paula Vergara, Ernesto Gabriel Hern\\'andez Montoya, Chen Bo Calvin Zhang, Bin Hu, Yunzhong He, Bing Liu, Rakshith Sharma Srinivasa","raw_content_length":1617,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["IRIS","Tool arXiv:2510.12712v1 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1616,"language_detected":"en","key_concepts":{"key_phrases":["Multimodal LLMs","Tool","MLLMs","Announce Type","new Abstract","Multimodal Large Language Models","real-world scenarios","user-provided images","active image manipulations","cropping"],"filter_categories":{"ai_ml":["Multimodal LLMs","Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multimodal LLMs":2.0,"Tool":2.0,"MLLMs":2.0,"Announce Type":1.0,"new Abstract":1.0,"Multimodal Large Language Models":1.0,"real-world scenarios":1.0,"user-provided images":1.0,"active image manipulations":1.0,"cropping":1.0}},"age_hours":2.743446278611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8723,"joy":0.0073,"surprise":0.0286,"sadness":0.0091,"fear":0.0233,"anger":0.0275,"disgust":0.032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (IRIS) for evaluating multimodal LLMs on their ability to manipulate images and integrate them with tools. While it doesn't directly address climate change, improved image processing could indirectly contribute to sustainability efforts in areas like remote sensing for deforestation monitoring or optimizing energy consumption in smart buildings. The benchmark provides measurable outcomes (pass rates) for different models.","key_impact_metrics":["Pass rate of 18.68% for GPT-5-think"],"technology_tags":["Multimodal Large Language Models","Image Processing","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:38.747057Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c18f100560dd","title":"Residual MPC: Blending Reinforcement Learning with GPU","content":"arXiv:2510.12717v1 Announce Type: new Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion controllers grounded in physical models, but its robustness depends on frequent replanning and is limited by model mismatch and real-time computational constraints. Reinforcement Learning (RL), by contrast, can produce highly robust behaviors through stochastic training but often lacks interpretability, suffers from out-of-distribution failures, and requires intensive reward engineering. This work presents a GPU-parallelized residual architecture that tightly integrates MPC and RL by blending their outputs at the torque-control level. We develop a kinodynamic whole-body MPC formulation evaluated across thousands of agents in parallel at 100 Hz for RL training. The residual policy learns to make targeted corrections to the MPC outputs, combining the interpretability and constraint handling of model-based control with the adaptability of RL. The model-based control prior acts as a strong bias, initializing and guiding the policy towards desirable behavior with a simple set of rewards. Compared to standalone MPC or end-to-end RL, our approach achieves higher sample efficiency, converges to greater asymptotic rewards, expands the range of trackable velocity commands, and enables zero-shot adaptation to unseen gaits and uneven terrain.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12717","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.434110","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Se Hwan Jeon, Ho Jae Lee, Seungwoo Hong, Sangbae Kim","raw_content_length":1373,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning","Model Predictive Control","MPC","Blending Reinforcement Learning","GPU"],"persons":["GPU arXiv:2510.12717v1 Announce Type:"],"locations":[],"monetary":[]},"char_count":1372,"language_detected":"en","key_concepts":{"key_phrases":["Residual MPC","Blending Reinforcement Learning","GPU","arXiv251012717v1 Announce Type","new Abstract","Model Predictive Control","MPC","interpretable tunable locomotion controllers","physical models","its robustness"],"filter_categories":{"ai_ml":["Blending Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Residual MPC":2.0,"Blending Reinforcement Learning":2.0,"GPU":2.0,"arXiv251012717v1 Announce Type":1.0,"new Abstract":1.0,"Model Predictive Control":1.0,"MPC":1.0,"interpretable tunable locomotion controllers":1.0,"physical models":1.0,"its robustness":1.0}},"age_hours":2.7434759236111113,"is_recent":true,"quality_score":1.0,"sentiment_score":2.742,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4516,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8816,"joy":0.0042,"surprise":0.0286,"sadness":0.0297,"fear":0.0147,"anger":0.0177,"disgust":0.0236},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a GPU-parallelized residual architecture that integrates MPC and RL for improved locomotion control. While it shows promise in achieving higher sample efficiency and expanding the range of trackable velocity commands, it is still in the early stages of development with no deployed units or customer contracts. The climate impact is theoretical at this stage, depending on the application of improved locomotion control in energy-intensive industries.","key_impact_metrics":["100 Hz for RL training","thousands of agents in parallel"],"technology_tags":["Model Predictive Control","Reinforcement Learning","GPU-parallelization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:41.530636Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_30bccccacd36","title":"Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction","content":"arXiv:2510.12719v1 Announce Type: new Abstract: Chemical pretrained models, sometimes referred to as foundation models, are receiving considerable interest for drug discovery applications. The general chemical knowledge extracted from self-supervised training has the potential to improve predictions for critical drug discovery endpoints, including on-target potency and ADMET properties. Multi-task learning has previously been successfully leveraged to improve predictive models. Here, we show that enabling multitasking in finetuning of chemical pretrained graph neural network models such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the GROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT) significantly improves performance over non-pretrained graph neural network models. Surprisingly, we find that the performance improvement from finetuning KERMT in a multitask manner is most significant at larger data sizes. Additionally, we publish two multitask ADMET data splits to enable more accurate benchmarking of multitask deep learning methods for drug property prediction. Finally, we provide an accelerated implementation of the KERMT model on GitHub, unlocking large-scale pretraining, finetuning, and inference in industrial drug discovery workflows.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12719","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.434508","language":"en","tags":["preprints","computer-science","cslg","research","q-bioqm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Matthew Adrian, Yunsie Chung, Kevin Boyd, Saee Paliwal, Srimukh Prasad Veccham, Alan C. Cheng","raw_content_length":1300,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["ADMET","Graph Transformer","KERMT","Chemical","KGPT"],"persons":["GROVER"],"locations":[],"monetary":[]},"char_count":1299,"language_detected":"en","key_concepts":{"key_phrases":["Multitask finetuning","acceleration","chemical pretrained models","small molecule drug property prediction","Announce Type","new Abstract","Chemical pretrained models","foundation models","considerable interest","drug discovery applications"],"filter_categories":{"ai_ml":["chemical pretrained models"],"research_academic":["drug discovery applications"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multitask finetuning":2.0,"acceleration":2.0,"chemical pretrained models":2.0,"small molecule drug property prediction":2.0,"Announce Type":1.0,"new Abstract":1.0,"Chemical pretrained models":1.0,"foundation models":1.0,"considerable interest":1.0,"drug discovery applications":1.0}},"age_hours":2.7434900666666664,"is_recent":true,"quality_score":1.0,"sentiment_score":7.992,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5984,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7483,"joy":0.1209,"surprise":0.0973,"sadness":0.0053,"fear":0.0101,"anger":0.0137,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes improved machine learning models for drug discovery, specifically ADMET properties. While improved drug discovery could lead to more efficient development of sustainable chemicals or medicines, the direct climate impact is theoretical and unquantified. The models are in the applied research phase, with no evidence of deployment or real-world impact yet.","key_impact_metrics":["Performance improvement from finetuning KERMT at larger data sizes"],"technology_tags":["Machine Learning","Drug Discovery","Graph Neural Networks"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:30:44.438198Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6154548a226b","title":"Omni","content":"arXiv:2510.12720v1 Announce Type: new Abstract: Fine-grained perception of multimodal information is critical for advancing human-AI interaction. With recent progress in audio-visual technologies, Omni Language Models (OLMs), capable of processing audio and video signals in parallel, have emerged as a promising paradigm for achieving richer understanding and reasoning. However, their capacity to capture and describe fine-grained details remains limited explored. In this work, we present a systematic and comprehensive investigation of omni detailed perception from the perspectives of the data pipeline, models, and benchmark. We first identify an inherent \"co-growth\" between detail and hallucination in current OLMs. To address this, we propose Omni-Detective, an agentic data generation pipeline integrating tool-calling, to autonomously produce highly detailed yet minimally hallucinatory multimodal data. Based on the data generated with Omni-Detective, we train two captioning models: Audio-Captioner for audio-only detailed perception, and Omni-Captioner for audio-visual detailed perception. Under the cascade evaluation protocol, Audio-Captioner achieves the best performance on MMAU and MMAR among all open-source models, surpassing Gemini 2.5 Flash and delivering performance comparable to Gemini 2.5 Pro. On existing detailed captioning benchmarks, Omni-Captioner sets a new state-of-the-art on VDC and achieves the best trade-off between detail and hallucination on the video-SALMONN 2 testset. Given the absence of a dedicated benchmark for omni detailed perception, we design Omni-Cloze, a novel cloze-style evaluation for detailed audio, visual, and audio-visual captioning that ensures stable, efficient, and reliable assessment. Experimental results and analysis demonstrate the effectiveness of Omni-Detective in generating high-quality detailed captions, as well as the superiority of Omni-Cloze in evaluating such detailed captions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12720","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.434963","language":"en","tags":["preprints","csmm","computer-science","research","cscl","cssd","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":256,"author":"Ziyang Ma, Ruiyang Xu, Zhenghao Xing, Yunfei Chu, Yuxuan Wang, Jinzheng He, Jin Xu, Pheng-Ann Heng, Kai Yu, Junyang Lin, Eng Siong Chng, Xie Chen","raw_content_length":1959,"priority":7,"update_frequency":1,"reading_time_minutes":1.28,"robust_parsing_used":true,"entities":{"organizations":["Omni-Detective","Omni arXiv:2510.12720v1 Announce Type: new Abstract","Omni Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1958,"language_detected":"en","key_concepts":{"key_phrases":["Omni","Announce Type","new Abstract","Fine-grained perception","multimodal information","human-AI interaction","recent progress","audio-visual technologies","Omni Language Models","OLMs"],"filter_categories":{"ai_ml":["Fine-grained perception"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Omni":2.0,"Announce Type":1.0,"new Abstract":1.0,"Fine-grained perception":1.0,"multimodal information":1.0,"human-AI interaction":1.0,"recent progress":1.0,"audio-visual technologies":1.0,"Omni Language Models":1.0,"OLMs":1.0}},"age_hours":2.743505100277778,"is_recent":true,"quality_score":0.7,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8913,"joy":0.0221,"surprise":0.0542,"sadness":0.0058,"fear":0.0085,"anger":0.0107,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI model for detailed audio-visual perception. While it achieves state-of-the-art performance on specific benchmarks (MMAU, MMAR, VDC, video-SALMONN 2), its direct climate impact is minimal at this stage. It's primarily a research project with potential for future applications, but lacks concrete deployment or economic viability at present.","key_impact_metrics":["Best performance on MMAU and MMAR","State-of-the-art on VDC"],"technology_tags":["Omni Language Models","Audio-Visual Perception","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:47.387617Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b67e2e943436","title":"CARVQ: Corrective Adaptor with Group Residual Vector Quantization for LLM Embedding Compression","content":"arXiv:2510.12721v1 Announce Type: new Abstract: Large Language Models (LLMs) typically rely on a large number of parameters for token embedding, leading to substantial storage requirements and memory footprints. In particular, LLMs deployed on edge devices are memory-bound, and reducing the memory footprint by compressing the embedding layer not only frees up the memory bandwidth but also speeds up inference. To address this, we introduce CARVQ, a post-training novel Corrective Adaptor combined with group Residual Vector Quantization. CARVQ relies on the composition of both linear and non-linear maps and mimics the original model embedding to compress to approximately 1.6 bits without requiring specialized hardware to support lower-bit storage. We test our method on pre-trained LLMs such as LLaMA-3.2-1B, LLaMA-3.2-3B, LLaMA-3.2-3B-Instruct, LLaMA-3.1-8B, Qwen2.5-7B, Qwen2.5-Math-7B and Phi-4, evaluating on common generative, discriminative, math and reasoning tasks. We show that in most cases, CARVQ can achieve lower average bitwidth-per-parameter while maintaining reasonable perplexity and accuracy compared to scalar quantization. Our contributions include a novel compression technique that is compatible with state-of-the-art transformer quantization methods and can be seamlessly integrated into any hardware supporting 4-bit memory to reduce the model's memory footprint in memory-constrained devices. This work demonstrates a crucial step toward the efficient deployment of LLMs on edge devices.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12721","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.435361","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Dayin Gou, Sanghyun Byun, Nilesh Malpeddi, Gabrielle De Micheli, Prathamesh Vaste, Jacob Song, Woo Seong Chung","raw_content_length":1520,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Group Residual Vector Quantization for LLM Embedding Compression arXiv:2510.12721v1 Announce Type: new Abstract","Corrective Adaptor","Residual Vector Quantization","CARVQ"],"persons":[],"locations":[],"monetary":[]},"char_count":1519,"language_detected":"en","key_concepts":{"key_phrases":["CARVQ","Corrective Adaptor","Group Residual Vector Quantization","LLM Embedding Compression","LLMs","arXiv251012721v1 Announce Type","new Abstract","Large Language Models","a large number","parameters"],"filter_categories":{"ai_ml":["LLM Embedding Compression","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CARVQ":3.0,"Corrective Adaptor":3.0,"Group Residual Vector Quantization":2.0,"LLM Embedding Compression":2.0,"LLMs":2.0,"arXiv251012721v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"a large number":1.0,"parameters":1.0}},"age_hours":2.7435208372222224,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1370000000000005,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0274,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9353,"joy":0.0095,"surprise":0.033,"sadness":0.0036,"fear":0.0031,"anger":0.0102,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel compression technique (CARVQ) for LLMs, reducing memory footprint and potentially energy consumption during inference, especially on edge devices. The method is tested on several pre-trained LLMs, showing a reduction to approximately 1.6 bits while maintaining reasonable accuracy. However, it is still in the research phase with no real-world deployments mentioned.","key_impact_metrics":["1.6 bits per parameter","reasonable perplexity and accuracy"],"technology_tags":["LLM compression","vector quantization","edge computing"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:30:50.181164Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_96c256b65861","title":"T(R,O) Grasp: Efficient Graph Diffusion of Robot","content":"arXiv:2510.12724v1 Announce Type: new Abstract: Dexterous grasping remains a central challenge in robotics due to the complexity of its high-dimensional state and action space. We introduce T(R,O) Grasp, a diffusion-based framework that efficiently generates accurate and diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph, a unified representation that models spatial transformations between robotic hands and objects while encoding their geometric properties. A graph diffusion model, coupled with an efficient inverse kinematics solver, supports both unconditioned and conditioned grasp synthesis. Extensive experiments on a diverse set of dexterous hands show that T(R,O) Grasp achieves average success rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per second on an NVIDIA A100 40GB GPU, substantially outperforming existing baselines. In addition, our approach is robust and generalizable across embodiments while significantly reducing memory consumption. More importantly, the high inference speed enables closed-loop dexterous manipulation, underscoring the potential of T(R,O) Grasp to scale into a foundation model for dexterous grasping.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12724","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.436141","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Xin Fei, Zhixuan Xu, Huaicong Fang, Tianrui Zhang, Lin Shao","raw_content_length":1200,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["GPU"],"persons":["T(R"],"locations":[],"monetary":[]},"char_count":1199,"language_detected":"en","key_concepts":{"key_phrases":["Grasp","Efficient Graph Diffusion","Robot","arXiv251012724v1","Announce Type","new Abstract","Dexterous grasping","a central challenge","robotics","the complexity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Grasp":2.0,"Efficient Graph Diffusion":2.0,"Robot":2.0,"arXiv251012724v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Dexterous grasping":1.0,"a central challenge":1.0,"robotics":1.0,"the complexity":1.0}},"age_hours":2.7435520119444448,"is_recent":true,"quality_score":1.0,"sentiment_score":9.063,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8126,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9236,"joy":0.0116,"surprise":0.0258,"sadness":0.0028,"fear":0.0072,"anger":0.0156,"disgust":0.0134},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to robotic grasping using graph diffusion. It achieves a 94.83% success rate and an inference speed of 0.21s on an NVIDIA A100 GPU. While promising, it is still in the research phase with no deployed units or real-world applications, hence the low deployment readiness and economic viability scores.","key_impact_metrics":["success rate of 94.83%","inference speed of 0.21s"],"technology_tags":["robotics","grasping","graph diffusion","artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:53.225459Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e4b4059e048a","title":"Improving Decision Trees through the Lens of Parameterized Local Search","content":"arXiv:2510.12726v1 Announce Type: new Abstract: Algorithms for learning decision trees often include heuristic local-search operations such as (1) adjusting the threshold of a cut or (2) also exchanging the feature of that cut. We study minimizing the number of classification errors by performing a fixed number of a single type of these operations. Although we discover that the corresponding problems are NP-complete in general, we provide a comprehensive parameterized-complexity analysis with the aim of determining those properties of the problems that explain the hardness and those that make the problems tractable. For instance, we show that the problems remain hard for a small number $d$ of features or small domain size $D$ but the combination of both yields fixed-parameter tractability. That is, the problems are solvable in $(D + 1)^{2d} \\cdot |I|^{O(1)}$ time, where $|I|$ is the size of the input. We also provide a proof-of-concept implementation of this algorithm and report on empirical results.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12726","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.436517","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Juha Harviainen, Frank Sommer, Manuel Sorge","raw_content_length":1016,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["|I|^{O(1)}$"],"locations":[],"monetary":[]},"char_count":1015,"language_detected":"en","key_concepts":{"key_phrases":["Decision Trees","the Lens","Parameterized Local Search","arXiv251012726v1 Announce Type","new Abstract","Algorithms","decision trees","heuristic local-search operations","the threshold","a cut"],"filter_categories":{"ai_ml":["Algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Decision Trees":2.0,"the Lens":2.0,"Parameterized Local Search":2.0,"arXiv251012726v1 Announce Type":1.0,"new Abstract":1.0,"Algorithms":1.0,"decision trees":1.0,"heuristic local-search operations":1.0,"the threshold":1.0,"a cut":1.0}},"age_hours":2.7435675055555557,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9047,"joy":0.0127,"surprise":0.0243,"sadness":0.015,"fear":0.0059,"anger":0.019,"disgust":0.0184},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents theoretical improvements to decision tree algorithms, focusing on parameterized complexity analysis. While it includes a proof-of-concept implementation and empirical results, it lacks concrete deployment or measurable outcomes related to climate impact. The research is at an early stage, with no clear path to economic viability or deployment readiness.","key_impact_metrics":["Classification errors minimized"],"technology_tags":["Decision Trees","Machine Learning","Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:30:57.485308Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c885f3bbf361","title":"Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems","content":"arXiv:2510.12727v1 Announce Type: new Abstract: In this paper, we presents a novel hierarchical federated learning architecture specifically designed for smart agricultural production systems and crop yield prediction. Our approach introduces a seasonal subscription mechanism where farms join crop-specific clusters at the beginning of each agricultural season. The proposed three-layer architecture consists of individual smart farms at the client level, crop-specific aggregators at the middle layer, and a global model aggregator at the top level. Within each crop cluster, clients collaboratively train specialized models tailored to specific crop types, which are then aggregated to produce a higher-level global model that integrates knowledge across multiple crops. This hierarchical design enables both local specialization for individual crop types and global generalization across diverse agricultural contexts while preserving data privacy and reducing communication overhead. Experiments demonstrate the effectiveness of the proposed system, showing that local and crop-layer models closely follow actual yield patterns with consistent alignment, significantly outperforming standard machine learning models. The results validate the advantages of hierarchical federated learning in the agricultural context, particularly for scenarios involving heterogeneous farming environments and privacy-sensitive agricultural data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12727","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.436933","language":"en","tags":["preprints","csai","computer-science","cslg","research","csdc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Anas Abouaomar, Mohammed El hanjri, Abdellatif Kobbane, Anis Laouiti, Khalid Nafil","raw_content_length":1435,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Smart Agricultural Production Systems","Hierarchical Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1434,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical Federated Learning","Crop Yield Prediction","Smart Agricultural Production Systems","arXiv251012727v1 Announce Type","new Abstract","this paper","a novel hierarchical federated learning architecture","smart agricultural production systems","crop yield prediction","Our approach"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical Federated Learning":2.0,"Crop Yield Prediction":2.0,"Smart Agricultural Production Systems":2.0,"arXiv251012727v1 Announce Type":1.0,"new Abstract":1.0,"this paper":1.0,"a novel hierarchical federated learning architecture":1.0,"smart agricultural production systems":1.0,"crop yield prediction":1.0,"Our approach":1.0}},"age_hours":2.743581658333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8946,"joy":0.0235,"surprise":0.0404,"sadness":0.0049,"fear":0.0084,"anger":0.0197,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a hierarchical federated learning architecture for crop yield prediction. While it shows improved performance over standard machine learning models, it's still in the research phase with no mention of real-world deployment or economic viability. The impact on climate is indirect, through potentially optimizing resource use in agriculture, but not quantified.","key_impact_metrics":["Significantly outperforming standard machine learning models"],"technology_tags":["Federated Learning","Smart Agriculture","Crop Yield Prediction"],"sdg_alignment":[2],"analyzed_at":"2025-10-29T16:31:00.367249Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f132473bbdca","title":"Clutch Control: An Attention","content":"arXiv:2510.12732v1 Announce Type: new Abstract: JavaScript engines are widely used in web browsers, PDF readers, and server-side applications. The rise in concern over their security has led to the development of several targeted fuzzing techniques. However, existing approaches use random selection to determine where to perform mutations in JavaScript code. We postulate that the problem of selecting better mutation targets is suitable for combinatorial bandits with a volatile number of arms. Thus, we propose CLUTCH, a novel deep combinatorial bandit that can observe variable length JavaScript test case representations, using an attention mechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can dynamically adapt its exploration. We show that CLUTCH increases efficiency in JavaScript fuzzing compared to three state-of-the-art solutions by increasing the number of valid test cases and coverage-per-testcase by, respectively, 20.3% and 8.9% on average. In volatile and combinatorial settings we show that CLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1% less regret in volatile and combinatorial settings, respectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12732","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.438857","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Myles Foley, Sergio Maffeis, Muhammad Fakhrur Rozi, Takeshi Takahashi","raw_content_length":1180,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Concrete Dropout","CLUTCH","JavaScript","PDF"],"persons":["Clutch Control:"],"locations":[],"monetary":[]},"char_count":1179,"language_detected":"en","key_concepts":{"key_phrases":["Clutch Control","An Attention","arXiv251012732v1 Announce Type","new Abstract","JavaScript engines","web browsers","PDF readers","server-side applications","The rise","concern"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Clutch Control":2.0,"An Attention":2.0,"arXiv251012732v1 Announce Type":1.0,"new Abstract":1.0,"JavaScript engines":1.0,"web browsers":1.0,"PDF readers":1.0,"server-side applications":1.0,"The rise":1.0,"concern":1.0}},"age_hours":2.7436273972222223,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6572,"joy":0.007,"surprise":0.0293,"sadness":0.0157,"fear":0.2307,"anger":0.0452,"disgust":0.0149},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel deep combinatorial bandit approach (CLUTCH) for improving JavaScript fuzzing, which could indirectly contribute to sustainability by enhancing the security and efficiency of web applications. The concrete actions involve increasing the number of valid test cases and coverage-per-testcase by 20.3% and 8.9%, respectively, compared to state-of-the-art solutions. However, the direct link to climate impact is weak, and the technology is still in the applied research stage.","key_impact_metrics":["number of valid test cases increased by 20.3%","coverage-per-testcase increased by 8.9%"],"technology_tags":["fuzzing","deep learning","combinatorial bandits","JavaScript"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:03.646632Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5ab113c300c4","title":"HYPE: Hybrid Planning with Ego Proposal","content":"arXiv:2510.12733v1 Announce Type: new Abstract: Safe and interpretable motion planning in complex urban environments needs to reason about bidirectional multi-agent interactions. This reasoning requires to estimate the costs of potential ego driving maneuvers. Many existing planners generate initial trajectories with sampling-based methods and refine them by optimizing on learned predictions of future environment states, which requires a cost function that encodes the desired vehicle behavior. Designing such a cost function can be very challenging, especially if a wide range of complex urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego proposal-conditioned predictions, a planner that integrates multimodal trajectory proposals from a learned proposal model as heuristic priors into a Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions, we introduce an ego-conditioned occupancy prediction model, enabling consistent, scene-aware reasoning. Our design significantly simplifies cost function design in refinement by considering proposal-driven guidance, requiring only minimalistic grid-based cost terms. Evaluations on large-scale real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves state-of-the-art performance, especially in safety and adaptability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12733","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.439288","language":"en","tags":["preprints","csai","computer-science","cslg","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Hang Yu, Julian Jordan, Julian Schmidt, Silvan Lindner, Alessandro Canevaro, Wilhelm Stork","raw_content_length":1344,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["HYPE","Monte Carlo Tree Search"],"persons":["Ego Proposal"],"locations":[],"monetary":[]},"char_count":1343,"language_detected":"en","key_concepts":{"key_phrases":["HYPE","Hybrid Planning","Ego Proposal","arXiv251012733v1 Announce Type","new Abstract","Safe and interpretable motion planning","complex urban environments","bidirectional multi-agent interactions","This reasoning","the costs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"HYPE":2.0,"Hybrid Planning":2.0,"Ego Proposal":2.0,"arXiv251012733v1 Announce Type":1.0,"new Abstract":1.0,"Safe and interpretable motion planning":1.0,"complex urban environments":1.0,"bidirectional multi-agent interactions":1.0,"This reasoning":1.0,"the costs":1.0}},"age_hours":2.743642211944444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9036,"joy":0.0126,"surprise":0.0237,"sadness":0.0035,"fear":0.0246,"anger":0.0229,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a new motion planning algorithm (HYPE) for autonomous vehicles, which could indirectly reduce GHG emissions by optimizing traffic flow and reducing accidents. The article mentions evaluations on real-world benchmarks (nuPlan and DeepUrban), suggesting some level of validation, but it's still in the applied research phase with no deployed units. The impact is indirect and depends on the widespread adoption of autonomous vehicles and their integration into a sustainable transportation system.","key_impact_metrics":["State-of-the-art performance in safety","State-of-the-art performance in adaptability"],"technology_tags":["Autonomous vehicles","Motion planning","Monte Carlo Tree Search","Machine Learning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:31:07.577260Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06560e6d1f01","title":"Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect","content":"arXiv:2510.12734v1 Announce Type: new Abstract: Variable importance (VI) methods are often used for hypothesis generation, feature selection, and scientific validation. In the standard VI pipeline, an analyst estimates VI for a single predictive model with only the observed features. However, the importance of a feature depends heavily on which other variables are included in the model, and essential variables are often omitted from observational datasets. Moreover, the VI estimated for one model is often not the same as the VI estimated for another equally-good model - a phenomenon known as the Rashomon Effect. We address these gaps by introducing UNobservables and Inference for Variable importancE using Rashomon SEts (UNIVERSE). Our approach adapts Rashomon sets - the sets of near-optimal models in a dataset - to produce bounds on the true VI even with missing features. We theoretically guarantee the robustness of our approach, show strong performance on semi-synthetic simulations, and demonstrate its utility in a credit risk task.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12734","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.439726","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Jon Donnelly, Srikar Katta, Emanuele Borgonovo, Cynthia Rudin","raw_content_length":1050,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["UNIVERSE","UNobservables and Inference for Variable importancE","the Rashomon Effect"],"persons":["Rashomon","Rashomon SEts"],"locations":[],"monetary":[]},"char_count":1049,"language_detected":"en","key_concepts":{"key_phrases":["Doctor Rashomon","the UNIVERSE","Madness","Variable Importance","Unobserved Confounding","the Rashomon Effect","arXiv251012734v1 Announce Type","new Abstract","Variable importance VI methods","hypothesis generation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Doctor Rashomon":2.0,"the UNIVERSE":2.0,"Madness":2.0,"Variable Importance":2.0,"Unobserved Confounding":2.0,"the Rashomon Effect":2.0,"arXiv251012734v1 Announce Type":1.0,"new Abstract":1.0,"Variable importance VI methods":1.0,"hypothesis generation":1.0}},"age_hours":2.7436576227777776,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8854,"joy":0.0054,"surprise":0.0254,"sadness":0.0054,"fear":0.031,"anger":0.0274,"disgust":0.02},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a novel method (UNIVERSE) for improving variable importance estimation in predictive models, particularly when dealing with unobserved confounding variables. While the method itself doesn't directly reduce GHG emissions, it could potentially improve the accuracy of models used to predict and manage climate-related risks or optimize resource allocation in sustainable systems. It's currently in the theoretical stage with simulations, lacking real-world deployment and quantifiable impact.","key_impact_metrics":[],"technology_tags":["machine learning","variable importance","causal inference"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:11.115035Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b41e7badbcce","title":"CoNet","content":"arXiv:2510.12739v1 Announce Type: new Abstract: Deep learning (DL) based methods for orthogonal frequency division multiplexing (OFDM) radio receivers demonstrated higher signal detection performance compared to the traditional receivers. However, the existing DL-based models, usually adapted from computer vision, aren't well suited for wireless communications. These models require high computational resources and memory, and have significant inference delays, limiting their use in resource-constrained settings. Additionally, reducing network size to ease resource demands often leads to notable performance degradation. This paper introduces collaborative networks (CoNet), a novel neural network (NN) architecture designed for OFDM receivers. CoNet uses multiple small ResNet or CNN subnetworks to simultaneously process signal features from different perspectives like capturing channel correlations and interference patterns. These subnetworks fuse their outputs through interaction operations (e.g., element-wise multiplication), significantly enhancing detection performance. Simulation results show CoNet significantly outperforms traditional architectures like residual networks (ResNets) in bit error rate (BER) and reduces inference delay when both nets have the same size and the same computational complexity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12739","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.440232","language":"en","tags":["preprints","csit","computer-science","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Mohanad Obeed, Ming Jian","raw_content_length":1328,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["OFDM","CNN","CoNet"],"persons":["arXiv:2510.12739v1 Announce Type"],"locations":["CoNet"],"monetary":[]},"char_count":1327,"language_detected":"en","key_concepts":{"key_phrases":["CoNet","arXiv251012739v1 Announce Type","new Abstract","Deep learning","DL based methods","orthogonal frequency division multiplexing","OFDM","radio receivers","higher signal detection performance","the traditional receivers"],"filter_categories":{"ai_ml":["Deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CoNet":2.0,"arXiv251012739v1 Announce Type":1.0,"new Abstract":1.0,"Deep learning":1.0,"DL based methods":1.0,"orthogonal frequency division multiplexing":1.0,"OFDM":1.0,"radio receivers":1.0,"higher signal detection performance":1.0,"the traditional receivers":1.0}},"age_hours":2.7436716283333333,"is_recent":true,"quality_score":0.7,"sentiment_score":6.233499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2467,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8671,"joy":0.0098,"surprise":0.0754,"sadness":0.0246,"fear":0.0063,"anger":0.0103,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural network architecture (CoNet) for OFDM receivers, demonstrating improved bit error rate (BER) and reduced inference delay compared to traditional architectures. This could lead to more energy-efficient wireless communication, but it is currently in the simulation stage with no real-world deployment. The improved efficiency has the potential to reduce energy consumption in wireless communication systems.","key_impact_metrics":["reduced inference delay","outperforms ResNets in bit error rate (BER)"],"technology_tags":["neural network","OFDM","wireless communication","ResNet"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:15.041689Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2969766a6886","title":"Personalized Federated Fine","content":"arXiv:2510.12741v1 Announce Type: new Abstract: Foundation models open up new possibilities for the use of AI in healthcare. However, even when pre-trained on health data, they still need to be fine-tuned for specific downstream tasks. Furthermore, although foundation models reduce the amount of training data required to achieve good performance, obtaining sufficient data is still a challenge. This is due, in part, to restrictions on sharing and aggregating data from different sources to protect patients' privacy. One possible solution to this is to fine-tune foundation models via federated learning across multiple participating clients (i.e., hospitals, clinics, etc.). In this work, we propose a new personalized federated fine-tuning method that learns orthogonal LoRA adapters to disentangle general and client-specific knowledge, enabling each client to fully exploit both their own data and the data of others. Our preliminary results on real-world federated medical imaging tasks demonstrate that our approach is competitive against current federated fine-tuning methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12741","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.441042","language":"en","tags":["preprints","computer-science","research","csdc","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Adam Tupper, Christian Gagn\\'e","raw_content_length":1087,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["LoRA"],"persons":[],"locations":[],"monetary":[]},"char_count":1086,"language_detected":"en","key_concepts":{"key_phrases":["Personalized Federated Fine","arXiv251012741v1 Announce Type","new Abstract","Foundation models","new possibilities","the use","healthcare","health data","specific downstream tasks","foundation models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Personalized Federated Fine":2.0,"arXiv251012741v1 Announce Type":1.0,"new Abstract":1.0,"Foundation models":1.0,"new possibilities":1.0,"the use":1.0,"healthcare":1.0,"health data":1.0,"specific downstream tasks":1.0,"foundation models":1.0}},"age_hours":2.7437033794444443,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9435,"joy":0.0052,"surprise":0.0226,"sadness":0.0082,"fear":0.0069,"anger":0.0077,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new federated learning method for fine-tuning foundation models in healthcare. While it shows preliminary results on real-world medical imaging tasks, it is still at the research stage with no deployed units or operational data. The potential climate impact is indirect, related to improved healthcare efficiency and resource allocation, but not directly quantified.","key_impact_metrics":[],"technology_tags":["federated learning","foundation models","medical imaging"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:31:17.772127Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c005da087672","title":"CTRL","content":"arXiv:2510.12742v1 Announce Type: new Abstract: When users are dissatisfied with recommendations from a recommender system, they often lack fine-grained controls for changing them. Large language models (LLMs) offer a solution by allowing users to guide their recommendations through natural language requests (e.g., \"I want to see respectful posts with a different perspective than mine\"). We propose a method, CTRL-Rec, that allows for natural language control of traditional recommender systems in real-time with computational efficiency. Specifically, at training time, we use an LLM to simulate whether users would approve of items based on their language requests, and we train embedding models that approximate such simulated judgments. We then integrate these user-request-based predictions into the standard weighting of signals that traditional recommender systems optimize. At deployment time, we require only a single LLM embedding computation per user request, allowing for real-time control of recommendations. In experiments with the MovieLens dataset, our method consistently allows for fine-grained control across a diversity of requests. In a study with 19 Letterboxd users, we find that CTRL-Rec was positively received by users and significantly enhanced users' sense of control and satisfaction with recommendations compared to traditional controls.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12742","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.441442","language":"en","tags":["preprints","csai","csir","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Micah Carroll, Adeline Foote, Kevin Feng, Marcus Williams, Anca Dragan, W. Bradley Knox, Smitha Milli","raw_content_length":1371,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1370,"language_detected":"en","key_concepts":{"key_phrases":["CTRL","users","Announce Type","new Abstract","recommendations","a recommender system","fine-grained controls","them","Large language models","LLMs"],"filter_categories":{"ai_ml":["fine-grained controls","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CTRL":2.0,"users":2.0,"Announce Type":1.0,"new Abstract":1.0,"recommendations":1.0,"a recommender system":1.0,"fine-grained controls":1.0,"them":1.0,"Large language models":1.0,"LLMs":1.0}},"age_hours":2.743718088888889,"is_recent":true,"quality_score":0.7,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3357,"joy":0.0066,"surprise":0.0126,"sadness":0.0113,"fear":0.0047,"anger":0.5771,"disgust":0.0521},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (CTRL-Rec) to improve recommender systems using LLMs. While the method shows promise in enhancing user control and satisfaction, its direct climate impact is minimal and theoretical. The study is primarily based on simulations and a small user study, indicating it's still in the early stages of development with no deployed units.","key_impact_metrics":["Enhanced user satisfaction with recommendations","Improved sense of control"],"technology_tags":["Large Language Models","Recommender Systems","Natural Language Processing"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:31:23.675133Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7fbebf882f82","title":"FlashVSR: Towards Real-Time Diffusion","content":"arXiv:2510.12747v1 Announce Type: new Abstract: Diffusion models have recently advanced video restoration, but applying them to real-world video super-resolution (VSR) remains challenging due to high latency, prohibitive computation, and poor generalization to ultra-high resolutions. Our goal in this work is to make diffusion-based VSR practical by achieving efficiency, scalability, and real-time performance. To this end, we propose FlashVSR, the first diffusion-based one-step streaming framework towards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408 videos on a single A100 GPU by combining three complementary innovations: (i) a train-friendly three-stage distillation pipeline that enables streaming super-resolution, (ii) locality-constrained sparse attention that cuts redundant computation while bridging the train-test resolution gap, and (iii) a tiny conditional decoder that accelerates reconstruction without sacrificing quality. To support large-scale training, we also construct VSR-120K, a new dataset with 120k videos and 180k images. Extensive experiments show that FlashVSR scales reliably to ultra-high resolutions and achieves state-of-the-art performance with up to 12x speedup over prior one-step diffusion VSR models. We will release the code, pretrained models, and dataset to foster future research in efficient diffusion-based VSR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12747","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.441868","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Junhao Zhuang, Shi Guo, Xin Cai, Xiaohui Li, Yihao Liu, Chun Yuan, Tianfan Xue","raw_content_length":1381,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["VSR","GPU"],"persons":[],"locations":[],"monetary":[]},"char_count":1380,"language_detected":"en","key_concepts":{"key_phrases":["FlashVSR","Real-Time Diffusion","arXiv251012747v1 Announce Type","new Abstract","recently advanced video restoration","them","real-world video super","resolution","VSR","high latency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"FlashVSR":3.0,"Real-Time Diffusion":2.0,"arXiv251012747v1 Announce Type":1.0,"new Abstract":1.0,"recently advanced video restoration":1.0,"them":1.0,"real-world video super":1.0,"resolution":1.0,"VSR":1.0,"high latency":1.0}},"age_hours":2.7437336475,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8734,"joy":0.0169,"surprise":0.0117,"sadness":0.0052,"fear":0.0441,"anger":0.03,"disgust":0.0187},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel diffusion-based video super-resolution (VSR) framework called FlashVSR, claiming a 12x speedup over prior one-step diffusion VSR models and achieving approximately 17 FPS for 768x1408 videos on a single A100 GPU. While the technology is promising, it is still in the applied research phase with no evidence of real-world deployment or independent validation, hence the vaporware flag. The climate impact is indirect, potentially reducing energy consumption by improving efficiency of video processing, but this is not quantified.","key_impact_metrics":["12x speedup","17 FPS"],"technology_tags":["Video Super-Resolution","Diffusion Models","Sparse Attention"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:26.721847Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95bbdf6c5148","title":"SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding","content":"arXiv:2510.12749v1 Announce Type: new Abstract: The scene perception, understanding, and simulation are fundamental techniques for embodied-AI agents, while existing solutions are still prone to segmentation deficiency, dynamic objects' interference, sensor data sparsity, and view-limitation problems. This paper proposes a novel framework, named SPORTS, for holistic scene understanding via tightly integrating Video Panoptic Segmentation (VPS), Visual Odometry (VO), and Scene Rendering (SR) tasks into an iterative and unified perspective. Firstly, VPS designs an adaptive attention-based geometric fusion mechanism to align cross-frame features via enrolling the pose, depth, and optical flow modality, which automatically adjust feature maps for different decoding stages. And a post-matching strategy is integrated to improve identities tracking. In VO, panoptic segmentation results from VPS are combined with the optical flow map to improve the confidence estimation of dynamic objects, which enhances the accuracy of the camera pose estimation and completeness of the depth map generation via the learning-based paradigm. Furthermore, the point-based rendering of SR is beneficial from VO, transforming sparse point clouds into neural fields to synthesize high-fidelity RGB views and twin panoptic views. Extensive experiments on three public datasets demonstrate that our attention-based feature fusion outperforms most existing state-of-the-art methods on the odometry, tracking, segmentation, and novel view synthesis tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12749","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.442272","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Zhiliu Yang, Jinyu Dai, Jianyuan Zhang, Zhu Yang","raw_content_length":1538,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["Simultaneous Panoptic Odometry","VPS","Scene Rendering (","Video Panoptic Segmentation","Visual Odometry"],"persons":["SPORTS"],"locations":[],"monetary":[]},"char_count":1537,"language_detected":"en","key_concepts":{"key_phrases":["SPORTS","Simultaneous Panoptic Odometry","Rendering","Tracking","Segmentation","Urban Scenes Understanding","arXiv251012749v1 Announce Type","new Abstract","The scene perception","understanding"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SPORTS":3.0,"Simultaneous Panoptic Odometry":2.0,"Rendering":2.0,"Tracking":2.0,"Segmentation":2.0,"Urban Scenes Understanding":2.0,"arXiv251012749v1 Announce Type":1.0,"new Abstract":1.0,"The scene perception":1.0,"understanding":1.0}},"age_hours":2.7437488675,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9259,"joy":0.0074,"surprise":0.0309,"sadness":0.005,"fear":0.0112,"anger":0.0129,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel framework (SPORTS) for urban scene understanding, which could indirectly contribute to sustainability by improving the efficiency of embodied-AI agents in urban environments. However, the impact is theoretical and not directly linked to concrete GHG emission reductions or other measurable sustainability outcomes. The technology is still in the applied research phase, with experiments on public datasets but no real-world deployment.","key_impact_metrics":["Accuracy of camera pose estimation","Completeness of depth map generation"],"technology_tags":["Video Panoptic Segmentation","Visual Odometry","Scene Rendering"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:31:30.756523Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9274662cbde2","title":"VQArt","content":"arXiv:2510.12750v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant capabilities in joint visual and linguistic tasks. However, existing Visual Question Answering (VQA) benchmarks often fail to evaluate deep semantic understanding, particularly in complex domains like visual art analysis. Confined to simple syntactic structures and surface-level attributes, these questions fail to capture the diversity and depth of human visual inquiry. This limitation incentivizes models to exploit statistical shortcuts rather than engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a new, large-scale VQA benchmark for the cultural heritage domain. This benchmark is constructed using a novel multi-agent pipeline where specialized agents collaborate to generate nuanced, validated, and linguistically diverse questions. The resulting benchmark is structured along relevant visual understanding dimensions that probe a model's ability to interpret symbolic meaning, narratives, and complex visual relationships. Our evaluation of 14 state-of-the-art MLLMs on this benchmark reveals significant limitations in current models, including a surprising weakness in simple counting tasks and a clear performance gap between proprietary and open-source models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12750","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.442699","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"A. Alfarano (University of Zurich, Max Planck Society), L. Venturoli (University of Zurich, Max Planck Society), D. Negueruela del Castillo (University of Zurich, Max Planck Society)","raw_content_length":1320,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["VQA","VQArt-Bench"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1319,"language_detected":"en","key_concepts":{"key_phrases":["VQArt","arXiv251012750v1 Announce Type","new Abstract","Multimodal Large Language Models","MLLMs","significant capabilities","joint visual and linguistic tasks","However existing Visual Question Answering","VQA","deep semantic understanding"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VQArt":2.0,"arXiv251012750v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal Large Language Models":1.0,"MLLMs":1.0,"significant capabilities":1.0,"joint visual and linguistic tasks":1.0,"However existing Visual Question Answering":1.0,"VQA":1.0,"deep semantic understanding":1.0}},"age_hours":2.7437632144444444,"is_recent":true,"quality_score":0.7,"sentiment_score":2.1405000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5719,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7565,"joy":0.003,"surprise":0.0537,"sadness":0.083,"fear":0.015,"anger":0.0292,"disgust":0.0596},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":1,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a new benchmark for evaluating multimodal large language models in the cultural heritage domain. While it's innovative, it's at the basic research stage with no deployed technology or measurable environmental outcomes. The benchmark itself doesn't directly reduce emissions or promote sustainability, but it could indirectly support better understanding and communication of sustainability issues through art.","key_impact_metrics":["Performance gap between proprietary and open-source models","Weakness in simple counting tasks"],"technology_tags":["Multimodal Large Language Models","Visual Question Answering"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:31:33.809702Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_342a894a47b9","title":"KoALA: KL","content":"arXiv:2510.12752v1 Announce Type: new Abstract: Deep neural networks are highly susceptible to adversarial attacks, which pose significant risks to security- and safety-critical applications. We present KoALA (KL-L0 Adversarial detection via Label Agreement), a novel, semantics-free adversarial detector that requires no architectural changes or adversarial retraining. KoALA operates on a simple principle: it detects an adversarial attack when class predictions from two complementary similarity metrics disagree. These metrics-KL divergence and an L0-based similarity-are specifically chosen to detect different types of perturbations. The KL divergence metric is sensitive to dense, low-amplitude shifts, while the L0-based similarity is designed for sparse, high-impact changes. We provide a formal proof of correctness for our approach. The only training required is a simple fine-tuning step on a pre-trained image encoder using clean images to ensure the embeddings align well with both metrics. This makes KOALA a lightweight, plug-and-play solution for existing models and various data modalities. Our extensive experiments on ResNet/CIFAR-10 and CLIP/Tiny-ImageNet confirm our theoretical claims. When the theorem's conditions are met, KoALA consistently and effectively detects adversarial examples. On the full test sets, KoALA achieves a precision of 0.94 and a recall of 0.81 on ResNet/CIFAR-10, and a precision of 0.66 and a recall of 0.85 on CLIP/Tiny-ImageNet.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12752","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.443102","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Siqi Li, Yasser Shoukry","raw_content_length":1480,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["KL-L0 Adversarial"],"persons":["KoALA","Label Agreement"],"locations":[],"monetary":[]},"char_count":1479,"language_detected":"en","key_concepts":{"key_phrases":["KoALA KL","KoALA","Announce Type","new Abstract","Deep neural networks","adversarial attacks","which","significant risks","security- and safety-critical applications","KL-L0 Adversarial detection"],"filter_categories":{"ai_ml":["Deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"KoALA KL":2.0,"KoALA":2.0,"Announce Type":1.0,"new Abstract":1.0,"Deep neural networks":1.0,"adversarial attacks":1.0,"which":1.0,"significant risks":1.0,"security- and safety-critical applications":1.0,"KL-L0 Adversarial detection":1.0}},"age_hours":2.743777675,"is_recent":true,"quality_score":1.0,"sentiment_score":0.4630000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9074,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3208,"joy":0.0107,"surprise":0.0198,"sadness":0.0124,"fear":0.6011,"anger":0.0255,"disgust":0.0096},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel adversarial detector (KoALA) for deep neural networks. While the technology itself doesn't directly impact climate change, it could improve the security and reliability of AI systems used in climate modeling or renewable energy management. The paper provides precision and recall metrics on specific datasets, but it's still in the early stages of development with no real-world deployment.","key_impact_metrics":["precision of 0.94 on ResNet/CIFAR-10","recall of 0.81 on ResNet/CIFAR-10"],"technology_tags":["adversarial detection","deep neural networks","AI security"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:31:36.789346Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2d453dae8383","title":"PET Head Motion Estimation Using Supervised Deep Learning with Attention","content":"arXiv:2510.12758v1 Announce Type: new Abstract: Head movement poses a significant challenge in brain positron emission tomography (PET) imaging, resulting in image artifacts and tracer uptake quantification inaccuracies. Effective head motion estimation and correction are crucial for precise quantitative image analysis and accurate diagnosis of neurological disorders. Hardware-based motion tracking (HMT) has limited applicability in real-world clinical practice. To overcome this limitation, we propose a deep-learning head motion correction approach with cross-attention (DL-HMC++) to predict rigid head motion from one-second 3D PET raw data. DL-HMC++ is trained in a supervised manner by leveraging existing dynamic PET scans with gold-standard motion measurements from external HMT. We evaluate DL-HMC++ on two PET scanners (HRRT and mCT) and four radiotracers (18F-FDG, 18F-FPEB, 11C-UCB-J, and 11C-LSN3172176) to demonstrate the effectiveness and generalization of the approach in large cohort PET studies. Quantitative and qualitative results demonstrate that DL-HMC++ consistently outperforms state-of-the-art data-driven motion estimation methods, producing motion-free images with clear delineation of brain structures and reduced motion artifacts that are indistinguishable from gold-standard HMT. Brain region of interest standard uptake value analysis exhibits average difference ratios between DL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT and 0.5 plus-minus 0.2% for mCT. DL-HMC++ demonstrates the potential for data-driven PET head motion correction to remove the burden of HMT, making motion correction accessible to clinical populations beyond research settings. The code is available at https://github.com/maxxxxxxcai/DL-HMC-TMI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12758","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.443995","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Zhuotong Cai, Tianyi Zeng, Jiazhen Zhang, El\\'eonore V. Lieffrig, Kathryn Fontaine, Chenyu You, Enette Mae Revilla, James S. Duncan, Jingmin Xin, Yihuan Lu, John A. Onofrey","raw_content_length":1773,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["HMT","PET","18F-FDG","PET Head Motion Estimation Using Supervised Deep Learning with Attention"],"persons":[],"locations":[],"monetary":[]},"char_count":1772,"language_detected":"en","key_concepts":{"key_phrases":["PET Head Motion Estimation","Supervised Deep Learning","Attention","arXiv251012758v1 Announce Type","new Abstract","Head movement","a significant challenge","brain positron emission tomography","PET imaging","image artifacts"],"filter_categories":{"ai_ml":["Supervised Deep Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PET Head Motion Estimation":2.0,"Supervised Deep Learning":2.0,"Attention":2.0,"arXiv251012758v1 Announce Type":1.0,"new Abstract":1.0,"Head movement":1.0,"a significant challenge":1.0,"brain positron emission tomography":1.0,"PET imaging":1.0,"image artifacts":1.0}},"age_hours":2.7438080611111113,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.785,"joy":0.0045,"surprise":0.0481,"sadness":0.0397,"fear":0.0953,"anger":0.012,"disgust":0.0153},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a deep-learning approach for head motion correction in PET imaging, demonstrating improved accuracy compared to existing methods. The concrete action is the development and evaluation of the DL-HMC++ algorithm. Evidence includes quantitative results showing reduced motion artifacts and improved uptake value analysis, but it's still in the research phase, not yet deployed clinically.","key_impact_metrics":["average difference ratios between DL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT","0.5 plus-minus 0.2% for mCT"],"technology_tags":["deep learning","medical imaging","PET scan","motion correction"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:31:40.276278Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_333f4585c6e3","title":"Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark","content":"arXiv:2510.12765v1 Announce Type: new Abstract: This paper presents a comprehensive study and benchmark on Efficient Perceptual Super-Resolution (EPSR). While significant progress has been made in efficient PSNR-oriented super resolution, approaches focusing on perceptual quality metrics remain relatively inefficient. Motivated by this gap, we aim to replicate or improve the perceptual results of Real-ESRGAN while meeting strict efficiency constraints: a maximum of 5M parameters and 2000 GFLOPs, calculated for an input size of 960x540 pixels. The proposed solutions were evaluated on a novel dataset consisting of 500 test images of 4K resolution, each degraded using multiple degradation types, without providing the original high-quality counterparts. This design aims to reflect realistic deployment conditions and serves as a diverse and challenging benchmark. The top-performing approach manages to outperform Real-ESRGAN across all benchmark datasets, demonstrating the potential of efficient methods in the perceptual domain. This paper establishes the modern baselines for efficient perceptual super resolution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12765","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.444777","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Bruno Longarela, Marcos V. Conde, Alvaro Garcia, Radu Timofte","raw_content_length":1126,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Efficient Perceptual Image Super","PSNR","Efficient Perceptual Super-Resolution","AIM 2025 Study"],"persons":["Benchmark arXiv:2510.12765v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1125,"language_detected":"en","key_concepts":{"key_phrases":["Benchmark","Announce Type","new Abstract","This paper","a comprehensive study","benchmark","Efficient Perceptual Super-Resolution","EPSR","significant progress","efficient PSNR-oriented super resolution"],"filter_categories":{"research_academic":["a comprehensive study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Benchmark":2.0,"Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"a comprehensive study":1.0,"benchmark":1.0,"Efficient Perceptual Super-Resolution":1.0,"EPSR":1.0,"significant progress":1.0,"efficient PSNR-oriented super resolution":1.0}},"age_hours":2.7438365666666664,"is_recent":true,"quality_score":1.0,"sentiment_score":9.896,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9792,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8525,"joy":0.0245,"surprise":0.0269,"sadness":0.0139,"fear":0.0077,"anger":0.0477,"disgust":0.0268},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a study on efficient perceptual super-resolution, aiming to improve perceptual quality while meeting efficiency constraints (5M parameters, 2000 GFLOPs). It uses a novel dataset for evaluation and outperforms Real-ESRGAN, but lacks real-world deployment data. The vaporware flag is set because it's an early-stage concept without deployed units.","key_impact_metrics":["5M parameters","2000 GFLOPs"],"technology_tags":["Super-Resolution","Image Processing","Efficient Algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:43.285374Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06dec4f0d7a2","title":"Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction","content":"arXiv:2510.12768v1 Announce Type: new Abstract: Reconstructing dynamic 3D scenes from monocular input is fundamentally under-constrained, with ambiguities arising from occlusion and extreme novel views. While dynamic Gaussian Splatting offers an efficient representation, vanilla models optimize all Gaussian primitives uniformly, ignoring whether they are well or poorly observed. This limitation leads to motion drifts under occlusion and degraded synthesis when extrapolating to unseen views. We argue that uncertainty matters: Gaussians with recurring observations across views and time act as reliable anchors to guide motion, whereas those with limited visibility are treated as less reliable. To this end, we introduce USplat4D, a novel Uncertainty-aware dynamic Gaussian Splatting framework that propagates reliable motion cues to enhance 4D reconstruction. Our key insight is to estimate time-varying per-Gaussian uncertainty and leverages it to construct a spatio-temporal graph for uncertainty-aware optimization. Experiments on diverse real and synthetic datasets show that explicitly modeling uncertainty consistently improves dynamic Gaussian Splatting models, yielding more stable geometry under occlusion and high-quality synthesis at extreme viewpoints.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12768","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.445539","language":"en","tags":["preprints","csai","computer-science","research","csgr","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Fengzhi Guo, Chih-Chuan Hsu, Sihao Ding, Cheng Zhang","raw_content_length":1271,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["per-Gaus","Uncertainty Matters","Monocular 4D Reconstruction"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1270,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty Matters","Monocular 4D Reconstruction","occlusion","arXiv251012768v1 Announce Type","new Abstract","dynamic 3D scenes","monocular input","ambiguities","extreme novel views","dynamic Gaussian Splatting"],"filter_categories":{"ai_ml":["Uncertainty Matters"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty Matters":2.0,"Monocular 4D Reconstruction":2.0,"occlusion":2.0,"arXiv251012768v1 Announce Type":1.0,"new Abstract":1.0,"dynamic 3D scenes":1.0,"monocular input":1.0,"ambiguities":1.0,"extreme novel views":1.0,"dynamic Gaussian Splatting":1.0}},"age_hours":2.7438651605555555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.374,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8748,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7843,"joy":0.0038,"surprise":0.017,"sadness":0.0247,"fear":0.106,"anger":0.02,"disgust":0.0442},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to 4D reconstruction using uncertainty-aware Gaussian Splatting. While the research demonstrates improved stability and synthesis quality, it is currently in the early stages of development with no deployed units or concrete metrics related to sustainability. The potential climate impact is indirect, as improved 3D reconstruction could potentially optimize resource use in various applications, but this is not quantified.","key_impact_metrics":[],"technology_tags":["Gaussian Splatting","4D Reconstruction","Uncertainty Estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:31:46.616340Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ab6ff6e2896d","title":"Sample","content":"arXiv:2510.12769v1 Announce Type: new Abstract: We consider the problem of constructing probabilistic predictions that lead to accurate decisions when employed by downstream users to inform actions. For a single decision maker, designing an optimal predictor is equivalent to minimizing a proper loss function corresponding to the negative utility of that individual. For multiple decision makers, our problem can be viewed as a variant of omniprediction in which the goal is to design a single predictor that simultaneously minimizes multiple losses. Existing algorithms for achieving omniprediction broadly fall into two categories: 1) boosting methods that optimize other auxiliary targets such as multicalibration and obtain omniprediction as a corollary, and 2) adversarial two-player game based approaches that estimate and respond to the ``worst-case\" loss in an online fashion. We give lower bounds demonstrating that multicalibration is a strictly more difficult problem than omniprediction and thus the former approach must incur suboptimal sample complexity. For the latter approach, we discuss how these ideas can be used to obtain a sample-efficient algorithm through an online-to-batch conversion. This conversion has the downside of returning a complex, randomized predictor. We improve on this method by designing a more direct, unrandomized algorithm that exploits structural elements of the set of proper losses.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12769","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.445973","language":"en","tags":["preprints","computer-science","cslg","research","statme","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Isaac Gibbs, Ryan J. Tibshirani","raw_content_length":1431,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1430,"language_detected":"en","key_concepts":{"key_phrases":["Sample","new Abstract","the problem","probabilistic predictions","accurate decisions","downstream users","actions","a single decision maker","an optimal predictor","a proper loss function"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sample":2.0,"new Abstract":1.0,"the problem":1.0,"probabilistic predictions":1.0,"accurate decisions":1.0,"downstream users":1.0,"actions":1.0,"a single decision maker":1.0,"an optimal predictor":1.0,"a proper loss function":1.0}},"age_hours":2.7438792191666668,"is_recent":true,"quality_score":0.7,"sentiment_score":0.8200000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.836,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8985,"joy":0.0199,"surprise":0.0455,"sadness":0.0053,"fear":0.0062,"anger":0.0161,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving probabilistic predictions for decision-making, which could potentially lead to more efficient resource allocation and reduced waste in various sectors, including those relevant to sustainability. However, the paper is theoretical and does not present any concrete deployments or measurable outcomes related to climate change or other sustainability dimensions. The research is at a basic research stage with peer review, but lacks real-world validation.","key_impact_metrics":[],"technology_tags":["probabilistic prediction","omniprediction","machine learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:31:49.937805Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c4aaf5c6540","title":"Dr.LLM: Dynamic Layer Routing in LLMs","content":"arXiv:2510.12773v1 Announce Type: new Abstract: Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inference-time search, architectural changes, or large-scale retraining, and in practice often degrade accuracy despite efficiency gains. We introduce Dr.LLM, Dynamic routing of Layers for LLMs, a retrofittable framework that equips pretrained models with lightweight per-layer routers deciding to skip, execute, or repeat a block. Routers are trained with explicit supervision: using Monte Carlo Tree Search (MCTS), we derive high-quality layer configurations that preserve or improve accuracy under a compute budget. Our design, windowed pooling for stable routing, focal loss with class balancing, and bottleneck MLP routers, ensures robustness under class imbalance and long sequences. On ARC (logic) and DART (math), Dr.LLM improves accuracy by up to +3.4%p while saving 5 layers per example on average. Routers generalize to out-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA, AGIEval) with only 0.85% accuracy drop while retaining efficiency, and outperform prior routing methods by up to +7.7%p. Overall, Dr.LLM shows that explicitly supervised routers retrofit frozen LLMs for budget-aware, accuracy-driven inference without altering base weights.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12773","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.446381","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Ahmed Heakl, Martin Gubri, Salman Khan, Sangdoo Yun, Seong Joon Oh","raw_content_length":1519,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Monte Carlo Tree Search","LLM"],"locations":[],"monetary":[]},"char_count":1518,"language_detected":"en","key_concepts":{"key_phrases":["DrLLM","LLMs","Dynamic Layer Routing","arXiv251012773v1 Announce Type","new Abstract","every","all layers","a transformer stack","wasted computation","simple queries"],"filter_categories":{"ai_ml":["DrLLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DrLLM":3.0,"LLMs":3.0,"Dynamic Layer Routing":2.0,"arXiv251012773v1 Announce Type":1.0,"new Abstract":1.0,"every":1.0,"all layers":1.0,"a transformer stack":1.0,"wasted computation":1.0,"simple queries":1.0}},"age_hours":2.7438948677777777,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9285,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6143,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4585,"joy":0.0033,"surprise":0.031,"sadness":0.1897,"fear":0.0095,"anger":0.1322,"disgust":0.1758},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"Dr.LLM improves LLM efficiency by dynamically routing layers, saving computation. It achieves up to +3.4%p accuracy improvement while saving 5 layers per example on ARC and DART datasets. This is currently at the applied research stage, with potential for reducing energy consumption in LLM inference.","key_impact_metrics":["accuracy improvement +3.4%p","5 layers saved per example"],"technology_tags":["Large Language Models","Dynamic Layer Routing","Monte Carlo Tree Search"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:31:53.312904Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a71d618359aa","title":"What If : Understanding Motion Through Sparse Interactions","content":"arXiv:2510.12777v1 Announce Type: new Abstract: Understanding the dynamics of a physical scene involves reasoning about the diverse ways it can potentially change, especially as a result of local interactions. We present the Flow Poke Transformer (FPT), a novel framework for directly predicting the distribution of local motion, conditioned on sparse interactions termed \"pokes\". Unlike traditional methods that typically only enable dense sampling of a single realization of scene dynamics, FPT provides an interpretable directly accessible representation of multi-modal scene motion, its dependency on physical interactions and the inherent uncertainties of scene dynamics. We also evaluate our model on several downstream tasks to enable comparisons with prior methods and highlight the flexibility of our approach. On dense face motion generation, our generic pre-trained model surpasses specialized baselines. FPT can be fine-tuned in strongly out-of-distribution tasks such as synthetic datasets to enable significant improvements over in-domain methods in articulated object motion estimation. Additionally, predicting explicit motion distributions directly enables our method to achieve competitive performance on tasks like moving part segmentation from pokes which further demonstrates the versatility of our FPT. Code and models are publicly available at https://compvis.github.io/flow-poke-transformer.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12777","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.446798","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Stefan Andreas Baumann, Nick Stracke, Timy Phan, Bj\\\"orn Ommer","raw_content_length":1416,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["the Flow Poke Transformer","FPT"],"persons":[],"locations":[],"monetary":[]},"char_count":1415,"language_detected":"en","key_concepts":{"key_phrases":["What","Motion","Sparse","arXiv251012777v1 Announce Type","new Abstract","the dynamics","a physical scene","the diverse ways","a result","local interactions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Motion":2.0,"Sparse":2.0,"arXiv251012777v1 Announce Type":1.0,"new Abstract":1.0,"the dynamics":1.0,"a physical scene":1.0,"the diverse ways":1.0,"a result":1.0,"local interactions":1.0}},"age_hours":2.743909619722222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7829,"joy":0.0189,"surprise":0.1398,"sadness":0.0052,"fear":0.0225,"anger":0.0225,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (Flow Poke Transformer) for predicting local motion based on sparse interactions. While the model shows promise in tasks like motion generation and segmentation, it is currently in the research phase with no concrete deployment or measured environmental outcomes. The potential climate impact is low as it's a fundamental research project with no direct link to emissions reduction or climate adaptation at this stage.","key_impact_metrics":[],"technology_tags":["machine learning","motion prediction","transformer networks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:31:56.762204Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2293a6795ab7","title":"Content Anonymization for Privacy in Long","content":"arXiv:2510.12780v1 Announce Type: new Abstract: Voice anonymization techniques have been found to successfully obscure a speaker's acoustic identity in short, isolated utterances in benchmarks such as the VoicePrivacy Challenge. In practice, however, utterances seldom occur in isolation: long-form audio is commonplace in domains such as interviews, phone calls, and meetings. In these cases, many utterances from the same speaker are available, which pose a significantly greater privacy risk: given multiple utterances from the same speaker, an attacker could exploit an individual's vocabulary, syntax, and turns of phrase to re-identify them, even when their voice is completely disguised. To address this risk, we propose new content anonymization approaches. Our approach performs a contextual rewriting of the transcripts in an ASR-TTS pipeline to eliminate speaker-specific style while preserving meaning. We present results in a long-form telephone conversation setting demonstrating the effectiveness of a content-based attack on voice-anonymized speech. Then we show how the proposed content-based anonymization methods can mitigate this risk while preserving speech utility. Overall, we find that paraphrasing is an effective defense against content-based attacks and recommend that stakeholders adopt this step to ensure anonymity in long-form audio.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12780","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.447201","language":"en","tags":["preprints","computer-science","research","cscl","cssd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Cristina Aggazzotti, Ashi Garg, Zexin Cai, Nicholas Andrews","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["ASR","Content Anonymization for Privacy in Long arXiv:2510.12780v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["Content Anonymization","Privacy","Long","arXiv251012780v1 Announce Type","new Abstract","Voice anonymization techniques","a speakers acoustic identity","short isolated utterances","benchmarks","the VoicePrivacy Challenge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Content Anonymization":2.0,"Privacy":2.0,"Long":2.0,"arXiv251012780v1 Announce Type":1.0,"new Abstract":1.0,"Voice anonymization techniques":1.0,"a speakers acoustic identity":1.0,"short isolated utterances":1.0,"benchmarks":1.0,"the VoicePrivacy Challenge":1.0}},"age_hours":2.743925081111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.679,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5358,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9438,"joy":0.0072,"surprise":0.0253,"sadness":0.0034,"fear":0.0052,"anger":0.007,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new content anonymization approach to protect speaker identity in long-form audio. While it demonstrates the effectiveness of the approach in a telephone conversation setting, it's still in the applied research stage with no deployed units or customer contracts. The climate impact is indirect, potentially reducing the need for travel or physical meetings if it enables more secure remote communication.","key_impact_metrics":["Effectiveness of content-based attack on voice-anonymized speech","Mitigation of re-identification risk"],"technology_tags":["Voice anonymization","Content anonymization","ASR-TTS pipeline"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:32:00.421852Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ff4c59de2f85","title":"SRUM: Fine","content":"arXiv:2510.12784v1 Announce Type: new Abstract: Recently, remarkable progress has been made in Unified Multimodal Models (UMMs), which integrate vision-language generation and understanding capabilities within a single framework. However, a significant gap exists where a model's strong visual understanding often fails to transfer to its visual generation. A model might correctly understand an image based on user instructions, yet be unable to generate a faithful image from text prompts. This phenomenon directly raises a compelling question: Can a model achieve self-improvement by using its understanding module to reward its generation module? To bridge this gap and achieve self-improvement, we introduce SRUM, a self-rewarding post-training framework that can be directly applied to existing UMMs of various designs. SRUM creates a feedback loop where the model's own understanding module acts as an internal ``evaluator'', providing corrective signals to improve its generation module, without requiring additional human-labeled data. To ensure this feedback is comprehensive, we designed a global-local dual reward system. To tackle the inherent structural complexity of images, this system offers multi-scale guidance: a \\textbf{global reward} ensures the correctness of the overall visual semantics and layout, while a \\textbf{local reward} refines fine-grained, object-level fidelity. SRUM leads to powerful capabilities and shows strong generalization, boosting performance on T2I-CompBench from 82.18 to \\textbf{88.37} and on T2I-ReasonBench from 43.82 to \\textbf{46.75}. Overall, our work establishes a powerful new paradigm for enabling a UMMs' understanding module to guide and enhance its own generation via self-rewarding.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12784","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.448016","language":"en","tags":["preprints","computer-science","research","cscl","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":238,"author":"Weiyang Jin, Yuwei Niu, Jiaqi Liao, Chengqi Duan, Aoxue Li, Shenghua Gao, Xihui Liu","raw_content_length":1744,"priority":7,"update_frequency":1,"reading_time_minutes":1.19,"robust_parsing_used":true,"entities":{"organizations":["Unified Multimodal Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1743,"language_detected":"en","key_concepts":{"key_phrases":["SRUM","Announce Type","new Abstract","remarkable progress","Unified Multimodal Models","UMMs","which","vision-language generation","capabilities","a single framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SRUM":2.0,"Announce Type":1.0,"new Abstract":1.0,"remarkable progress":1.0,"Unified Multimodal Models":1.0,"UMMs":1.0,"which":1.0,"vision-language generation":1.0,"capabilities":1.0,"a single framework":1.0}},"age_hours":2.7439547247222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.662500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9325,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.733,"joy":0.0092,"surprise":0.1414,"sadness":0.0261,"fear":0.0183,"anger":0.029,"disgust":0.0429},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel self-rewarding framework (SRUM) for improving unified multimodal models. While it shows performance gains on benchmarks (T2I-CompBench from 82.18 to 88.37 and on T2I-ReasonBench from 43.82 to 46.75), it is still in the research phase and lacks concrete actions related to direct environmental sustainability. The potential climate impact is indirect and currently unquantifiable.","key_impact_metrics":["T2I-CompBench improvement: 6.19","T2I-ReasonBench improvement: 2.93"],"technology_tags":["Unified Multimodal Models","Self-Rewarding Learning","Text-to-Image Generation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:32:04.632304Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a427c380e9f5","title":"MVP4D: Multi","content":"arXiv:2510.12785v1 Announce Type: new Abstract: Digital human avatars aim to simulate the dynamic appearance of humans in virtual environments, enabling immersive experiences across gaming, film, virtual reality, and more. However, the conventional process for creating and animating photorealistic human avatars is expensive and time-consuming, requiring large camera capture rigs and significant manual effort from professional 3D artists. With the advent of capable image and video generation models, recent methods enable automatic rendering of realistic animated avatars from a single casually captured reference image of a target subject. While these techniques significantly lower barriers to avatar creation and offer compelling realism, they lack constraints provided by multi-view information or an explicit 3D representation. So, image quality and realism degrade when rendered from viewpoints that deviate strongly from the reference image. Here, we build a video model that generates animatable multi-view videos of digital humans based on a single reference image and target expressions. Our model, MVP4D, is based on a state-of-the-art pre-trained video diffusion model and generates hundreds of frames simultaneously from viewpoints varying by up to 360 degrees around a target subject. We show how to distill the outputs of this model into a 4D avatar that can be rendered in real-time. Our approach significantly improves the realism, temporal consistency, and 3D consistency of generated avatars compared to previous methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12785","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.448429","language":"en","tags":["preprints","csai","computer-science","research","csgr","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Felix Taubner, Ruihang Zhang, Mathieu Tuli, Sherwin Bahmani, David B. Lindell","raw_content_length":1545,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["Multi arXiv:2510.12785v1 Announce Type: new Abstract","Digital"],"persons":[],"locations":[],"monetary":[]},"char_count":1544,"language_detected":"en","key_concepts":{"key_phrases":["MVP4D","Multi","Announce Type","new Abstract","Digital human avatars","the dynamic appearance","humans","virtual environments","immersive experiences","gaming"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MVP4D":2.0,"Multi":2.0,"Announce Type":1.0,"new Abstract":1.0,"Digital human avatars":1.0,"the dynamic appearance":1.0,"humans":1.0,"virtual environments":1.0,"immersive experiences":1.0,"gaming":1.0}},"age_hours":2.7439690069444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8739,"joy":0.0265,"surprise":0.0467,"sadness":0.0209,"fear":0.0116,"anger":0.013,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method for generating realistic digital human avatars. While innovative, it's currently in the applied research stage with no deployed units or measured outcomes related to sustainability. The potential climate impact is minimal as it primarily addresses virtual environment applications, and the economic viability is uncertain at this stage.","key_impact_metrics":[],"technology_tags":["digital avatars","video diffusion models","4D avatar rendering"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:32:07.417210Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c1c5655f027","title":"UniFusion: Vision","content":"arXiv:2510.12789v1 Announce Type: new Abstract: Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often use the last layer information from VLM, employ multiple visual encoders, or train large unified models jointly for text and image generation, which demands substantial computational resources and large-scale data, limiting its accessibility.We present UniFusion, a diffusion-based generative model conditioned on a frozen large vision-language model (VLM) that serves as a unified multimodal encoder. At the core of UniFusion is the Layerwise Attention Pooling (LAP) mechanism that extracts both high level semantics and low level details from text and visual tokens of a frozen VLM to condition a diffusion generative model. We demonstrate that LAP outperforms other shallow fusion architectures on text-image alignment for generation and faithful transfer of visual information from VLM to the diffusion model which is key for editing. We propose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI), which conditions a diffusion transformer (DiT) only on the text tokens generated by the VLM during in-model prompt rewriting. VERIFI combines the alignment of the conditioning distribution with the VLM's reasoning capabilities for increased capabilities and flexibility at inference. In addition, finetuning on editing task not only improves text-image alignment for generation, indicative of cross-modality knowledge transfer, but also exhibits tremendous generalization capabilities. Our model when trained on single image editing, zero-shot generalizes to multiple image references further motivating the unified encoder design of UniFusion.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12789","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.451125","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":262,"author":"Kevin Li, Manuel Brack, Sudeep Katakol, Hareesh Ravi, Ajinkya Kale","raw_content_length":1911,"priority":7,"update_frequency":1,"reading_time_minutes":1.31,"robust_parsing_used":true,"entities":{"organizations":["LAP","VLM","UniFusion","the Layerwise Attention Pooling"],"persons":[],"locations":[],"monetary":[]},"char_count":1910,"language_detected":"en","key_concepts":{"key_phrases":["UniFusion","Vision","arXiv251012789v1 Announce Type","new Abstract","recent advances","visual generation","most existing architectures","distinct encoders","images","text"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"UniFusion":2.0,"Vision":2.0,"arXiv251012789v1 Announce Type":1.0,"new Abstract":1.0,"recent advances":1.0,"visual generation":1.0,"most existing architectures":1.0,"distinct encoders":1.0,"images":1.0,"text":1.0}},"age_hours":2.7440127566666668,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8591,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8446,"joy":0.0111,"surprise":0.1013,"sadness":0.007,"fear":0.0165,"anger":0.0125,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to visual generation using a unified multimodal encoder. While the research demonstrates improved text-image alignment and generalization capabilities, it is currently in the basic research stage with no deployed units or measured outcomes. The potential climate impact is low as it's unclear how this technology directly reduces GHG emissions or contributes to climate adaptation.","key_impact_metrics":[],"technology_tags":["diffusion models","vision-language models","multimodal learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:10.647403Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_15323aaf322b","title":"ViCO: A Training Strategy towards Semantic Aware Dynamic High","content":"arXiv:2510.12793v1 Announce Type: new Abstract: Existing Multimodal Large Language Models (MLLMs) suffer from increased inference costs due to the additional vision tokens introduced by image inputs. In this work, we propose Visual Consistency Learning (ViCO), a novel training algorithm that enables the model to represent images of varying semantic complexities using different numbers of vision tokens. The key idea behind our method is to employ multiple MLP connectors, each with a different image compression ratio, to downsample the vision tokens based on the semantic complexity of the image. During training, we minimize the KL divergence between the responses conditioned on different MLP connectors. At inference time, we introduce an image router, termed Visual Resolution Router (ViR), that automatically selects the appropriate compression rate for each image patch. Compared with existing dynamic high-resolution strategies, which adjust the number of visual tokens based on image resolutions, our method dynamically adapts the number of visual tokens according to semantic complexity. Experimental results demonstrate that our method can reduce the number of vision tokens by up to 50% while maintaining the model's perception, reasoning, and OCR capabilities. We hope this work will contribute to the development of more efficient MLLMs. The code and models will be released to facilitate future research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12793","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.451531","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Long Cui, Weiyun Wang, Jie Shao, Zichen Wen, Gen Luo, Linfeng Zhang, Yanting Zhang, Yu Qiao, Wenhai Wang","raw_content_length":1423,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["Semantic Aware","ViR"],"persons":["ViCO"],"locations":[],"monetary":[]},"char_count":1422,"language_detected":"en","key_concepts":{"key_phrases":["ViCO","A Training Strategy","Semantic Aware Dynamic High","arXiv251012793v1 Announce Type","new Abstract","Existing Multimodal Large Language Models","MLLMs","increased inference costs","the additional vision tokens","image inputs"],"filter_categories":{"ai_ml":["A Training Strategy","Existing Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ViCO":3.0,"A Training Strategy":2.0,"Semantic Aware Dynamic High":2.0,"arXiv251012793v1 Announce Type":1.0,"new Abstract":1.0,"Existing Multimodal Large Language Models":1.0,"MLLMs":1.0,"increased inference costs":1.0,"the additional vision tokens":1.0,"image inputs":1.0}},"age_hours":2.744027676111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.757,"joy":0.0176,"surprise":0.0341,"sadness":0.0884,"fear":0.0442,"anger":0.0277,"disgust":0.0311},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a method to reduce the computational cost of MLLMs by dynamically adjusting the number of vision tokens based on semantic complexity. The concrete action is the development of a new training algorithm (ViCO) and an image router (ViR). The evidence supporting the claim is experimental results showing a 50% reduction in vision tokens while maintaining model performance. This is currently at the basic research stage.","key_impact_metrics":["reduction in vision tokens by up to 50%"],"technology_tags":["Multimodal Large Language Models","Image Compression","Artificial Intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:32:13.827751Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_072760206b16","title":"CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations","content":"arXiv:2510.12795v1 Announce Type: new Abstract: We present CuMPerLay, a novel differentiable vectorization layer that enables the integration of Cubical Multiparameter Persistence (CMP) into deep learning pipelines. While CMP presents a natural and powerful way to topologically work with images, its use is hindered by the complexity of multifiltration structures as well as the vectorization of CMP. In face of these challenges, we introduce a new algorithm for vectorizing MP homologies of cubical complexes. Our CuMPerLay decomposes the CMP into a combination of individual, learnable single-parameter persistence, where the bifiltration functions are jointly learned. Thanks to the differentiability, its robust topological feature vectors can be seamlessly used within state-of-the-art architectures such as Swin Transformers. We establish theoretical guarantees for the stability of our vectorization under generalized Wasserstein metrics. Our experiments on benchmark medical imaging and computer vision datasets show the benefit CuMPerLay on classification and segmentation performance, particularly in limited-data scenarios. Overall, CuMPerLay offers a promising direction for integrating global structural information into deep networks for structured image analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12795","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.451952","language":"en","tags":["preprints","mathat","csai","statml","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Caner Korkmaz, Brighton Nuwagira, Bar{\\i}\\c{s} Co\\c{s}kunuzer, Tolga Birdal","raw_content_length":1280,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Cubical Multiparameter Persistence","Swin Transformers","CMP"],"persons":[],"locations":[],"monetary":[]},"char_count":1279,"language_detected":"en","key_concepts":{"key_phrases":["CuMPerLay","CMP","Learning Cubical Multiparameter Persistence Vectorizations","arXiv251012795v1 Announce Type","new Abstract","a novel differentiable vectorization layer","the integration","Cubical Multiparameter Persistence","deep learning pipelines","a natural and powerful way"],"filter_categories":{"ai_ml":["deep learning pipelines"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CuMPerLay":3.0,"CMP":3.0,"Learning Cubical Multiparameter Persistence Vectorizations":2.0,"arXiv251012795v1 Announce Type":1.0,"new Abstract":1.0,"a novel differentiable vectorization layer":1.0,"the integration":1.0,"Cubical Multiparameter Persistence":1.0,"deep learning pipelines":1.0,"a natural and powerful way":1.0}},"age_hours":2.744042077777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.200999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8687,"joy":0.0173,"surprise":0.0213,"sadness":0.0194,"fear":0.0407,"anger":0.0198,"disgust":0.0127},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (CuMPerLay) for vectorizing MP homologies of cubical complexes, improving classification and segmentation performance in medical imaging and computer vision datasets. While the algorithm shows promise in limited-data scenarios, it is currently in the basic research stage with no deployed units or customer contracts. The climate impact is indirect, potentially improving resource efficiency in medical imaging but without quantified GHG reductions.","key_impact_metrics":["Classification performance improvement","Segmentation performance improvement"],"technology_tags":["Cubical Multiparameter Persistence","Deep Learning","Medical Imaging","Computer Vision"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:32:16.768160Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fe3931f67895","title":"DriveVLA","content":"arXiv:2510.12796v1 Announce Type: new Abstract: Scaling Vision-Language-Action (VLA) models on large-scale data offers a promising path to achieving a more generalized driving intelligence. However, VLA models are limited by a ``supervision deficit'': the vast model capacity is supervised by sparse, low-dimensional actions, leaving much of their representational power underutilized. To remedy this, we propose \\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to predict future images. This task generates a dense, self-supervised signal that compels the model to learn the underlying dynamics of the driving environment. We showcase the paradigm's versatility by instantiating it for two dominant VLA archetypes: an autoregressive world model for VLAs that use discrete visual tokens, and a diffusion world model for those operating on continuous visual features. Building on the rich representations learned from world modeling, we introduce a lightweight action expert to address the inference latency for real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a 680x larger in-house dataset demonstrate that DriveVLA-W0 significantly outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling law, showing that performance gains accelerate as the training dataset size increases.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12796","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.452349","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Yingyan Li, Shuyao Shang, Weisong Liu, Bing Zhan, Haochen Wang, Yuqi Wang, Yuntao Chen, Xiaoman Wang, Yasong An, Chufeng Tang, Lu Hou, Lue Fan, Zhaoxiang Zhang","raw_content_length":1347,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["VLA"],"persons":[],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["DriveVLA","arXiv251012796v1 Announce Type","new Abstract","VLA","large-scale data","a promising path","a more generalized driving intelligence","VLA models","a supervision deficit","the vast model capacity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DriveVLA":2.0,"arXiv251012796v1 Announce Type":1.0,"new Abstract":1.0,"VLA":1.0,"large-scale data":1.0,"a promising path":1.0,"a more generalized driving intelligence":1.0,"VLA models":1.0,"a supervision deficit":1.0,"the vast model capacity":1.0}},"age_hours":2.7440573833333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7675,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3535,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8597,"joy":0.0088,"surprise":0.0338,"sadness":0.047,"fear":0.015,"anger":0.0221,"disgust":0.0135},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel training paradigm (DriveVLA-W0) for vision-language-action models in autonomous driving, aiming to improve driving intelligence. It shows significant outperformance on benchmarks (NAVSIM v1/v2) and a larger in-house dataset, but it is still in the research phase with no deployed units or real-world operational data. The potential climate impact is indirect, relying on the eventual deployment of more efficient autonomous driving systems, but is not quantified.","key_impact_metrics":["680x larger in-house dataset","Outperforms BEV and VLA baselines"],"technology_tags":["Vision-Language-Action Models","Autonomous Driving","World Modeling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:20.248231Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a6606d215900","title":"Detect Anything via Next Point Prediction","content":"arXiv:2510.12798v1 Announce Type: new Abstract: Object detection has long been dominated by traditional coordinate regression-based models, such as YOLO, DETR, and Grounding DINO. Although recent efforts have attempted to leverage MLLMs to tackle this task, they face challenges like low recall rate, duplicate predictions, coordinate misalignment, etc. In this work, we bridge this gap and propose Rex-Omni, a 3B-scale MLLM that achieves state-of-the-art object perception performance. On benchmarks like COCO and LVIS, Rex-Omni attains performance comparable to or exceeding regression-based models (e.g., DINO, Grounding DINO) in a zero-shot setting. This is enabled by three key designs: 1) Task Formulation: we use special tokens to represent quantized coordinates from 0 to 999, reducing the model's learning difficulty and improving token efficiency for coordinate prediction; 2) Data Engines: we construct multiple data engines to generate high-quality grounding, referring, and pointing data, providing semantically rich supervision for training; \\3) Training Pipelines: we employ a two-stage training process, combining supervised fine-tuning on 22 million data with GRPO-based reinforcement post-training. This RL post-training leverages geometry-aware rewards to effectively bridge the discrete-to-continuous coordinate prediction gap, improve box accuracy, and mitigate undesirable behaviors like duplicate predictions that stem from the teacher-guided nature of the initial SFT stage. Beyond conventional detection, Rex-Omni's inherent language understanding enables versatile capabilities such as object referring, pointing, visual prompting, GUI grounding, spatial referring, OCR and key-pointing, all systematically evaluated on dedicated benchmarks. We believe that Rex-Omni paves the way for more versatile and language-aware visual perception systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12798","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.452787","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Qing Jiang, Junan Huo, Xingyu Chen, Yuda Xiong, Zhaoyang Zeng, Yihao Chen, Tianhe Ren, Junzhi Yu, Lei Zhang","raw_content_length":1872,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["DINO","Data Engines","Detect Anything","COCO","Rex-Omni","DETR","YOLO","Next Point Prediction arXiv:2510.12798v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1871,"language_detected":"en","key_concepts":{"key_phrases":["Anything","Next Point Prediction","arXiv251012798v1 Announce Type","new Abstract","Object detection","traditional coordinate regression-based models","YOLO","DETR","DINO","recent efforts"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Anything":2.0,"Next Point Prediction":2.0,"arXiv251012798v1 Announce Type":1.0,"new Abstract":1.0,"Object detection":1.0,"traditional coordinate regression-based models":1.0,"YOLO":1.0,"DETR":1.0,"DINO":1.0,"recent efforts":1.0}},"age_hours":2.7440737213888893,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7364999999999995,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5473,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9391,"joy":0.004,"surprise":0.0162,"sadness":0.0108,"fear":0.0156,"anger":0.0093,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel MLLM for object detection. While it achieves state-of-the-art performance on benchmarks, it is still in the research phase with no deployed units or customer contracts. The climate impact is indirect, potentially enabling more efficient resource management in the future, but currently theoretical.","key_impact_metrics":["Comparable performance to DINO on COCO and LVIS","3B-scale MLLM"],"technology_tags":["MLLM","Object Detection","Computer Vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:23.177015Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0ab7adbb9943","title":"DeepMMSearch","content":"arXiv:2510.12801v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) in real-world applications require access to external knowledge sources and must remain responsive to the dynamic and ever-changing real-world information in order to address information-seeking and knowledge-intensive user queries. Existing approaches, such as retrieval augmented generation (RAG) methods, search agents, and search equipped MLLMs, often suffer from rigid pipelines, excessive search calls, and poorly constructed search queries, which result in inefficiencies and suboptimal outcomes. To address these limitations, we present DeepMMSearch-R1, the first multimodal LLM capable of performing on-demand, multi-turn web searches and dynamically crafting queries for both image and text search tools. Specifically, DeepMMSearch-R1 can initiate web searches based on relevant crops of the input image making the image search more effective, and can iteratively adapt text search queries based on retrieved information, thereby enabling self-reflection and self-correction. Our approach relies on a two-stage training pipeline: a cold start supervised finetuning phase followed by an online reinforcement learning optimization. For training, we introduce DeepMMSearchVQA, a novel multimodal VQA dataset created through an automated pipeline intermixed with real-world information from web search tools. This dataset contains diverse, multi-hop queries that integrate textual and visual information, teaching the model when to search, what to search for, which search tool to use and how to reason over the retrieved information. We conduct extensive experiments across a range of knowledge-intensive benchmarks to demonstrate the superiority of our approach. Finally, we analyze the results and provide insights that are valuable for advancing multimodal web-search.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12801","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.453213","language":"en","tags":["preprints","csir","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Kartik Narayan, Yang Xu, Tian Cao, Kavya Nerella, Vishal M. Patel, Navid Shiee, Peter Grasch, Chao Jia, Yinfei Yang, Zhe Gan","raw_content_length":1868,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["DeepMMSearch-R1"],"persons":[],"locations":[],"monetary":[]},"char_count":1867,"language_detected":"en","key_concepts":{"key_phrases":["DeepMMSearch","arXiv251012801v1 Announce Type","new Abstract","Multimodal Large Language Models","MLLMs","real-world applications","access","external knowledge sources","the dynamic and ever-changing real-world information","order"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepMMSearch":2.0,"arXiv251012801v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal Large Language Models":1.0,"MLLMs":1.0,"real-world applications":1.0,"access":1.0,"external knowledge sources":1.0,"the dynamic and ever-changing real-world information":1.0,"order":1.0}},"age_hours":2.744088199444444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6079,"joy":0.0023,"surprise":0.0119,"sadness":0.0444,"fear":0.1178,"anger":0.1019,"disgust":0.1138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel multimodal search algorithm (DeepMMSearch-R1) and its training dataset (DeepMMSearchVQA). While it aims to improve information retrieval, there are no concrete deployments or measured outcomes related to sustainability. It is currently in the applied research stage, with potential for future impact if it can be used to improve access to information about sustainable technologies or climate change.","key_impact_metrics":[],"technology_tags":["Multimodal Search","Large Language Models","Information Retrieval"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:26.506564Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9b62ab685bc6","title":"Replicable Learning of Large","content":"arXiv:2402.13857v2 Announce Type: cross Abstract: We provide efficient replicable algorithms for the problem of learning large-margin halfspaces. Our results improve upon the algorithms provided by Impagliazzo, Lei, Pitassi, and Sorrell [STOC, 2022]. We design the first dimension-independent replicable algorithms for this task which runs in polynomial time, is proper, and has strictly improved sample complexity compared to the one achieved by Impagliazzo et al. [2022] with respect to all the relevant parameters. Moreover, our first algorithm has sample complexity that is optimal with respect to the accuracy parameter $\\epsilon$. We also design an SGD-based replicable algorithm that, in some parameters' regimes, achieves better sample and time complexity than our first algorithm. Departing from the requirement of polynomial time algorithms, using the DP-to-Replicability reduction of Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sorrell, and Sivakumar [STOC, 2023], we show how to obtain a replicable algorithm for large-margin halfspaces with improved sample complexity with respect to the margin parameter $\\tau$, but running time doubly exponential in $1/\\tau^2$ and worse sample complexity dependence on $\\epsilon$ than one of our previous algorithms. We then design an improved algorithm with better sample complexity than all three of our previous algorithms and running time exponential in $1/\\tau^{2}$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2402.13857","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.454438","language":"en","tags":["preprints","statml","computer-science","cslg","research","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Alkis Kalavasis, Amin Karbasi, Kasper Green Larsen, Grigoris Velegkas, Felix Zhou","raw_content_length":1428,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["SGD","STOC","Bun","Sorrell"],"persons":["Pitassi","Lei","Impagliazzo","Sivakumar","Impagliazzo et al"],"locations":["Gaboardi"],"monetary":[]},"char_count":1427,"language_detected":"en","key_concepts":{"key_phrases":["Replicable Learning","arXiv240213857v2 Announce Type","cross","efficient replicable algorithms","the problem","large-margin halfspaces","Our results","the algorithms","Impagliazzo","Lei"],"filter_categories":{"ai_ml":["efficient replicable algorithms","the algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Replicable Learning":2.0,"arXiv240213857v2 Announce Type":1.0,"cross":1.0,"efficient replicable algorithms":1.0,"the problem":1.0,"large-margin halfspaces":1.0,"Our results":1.0,"the algorithms":1.0,"Impagliazzo":1.0,"Lei":1.0}},"age_hours":2.7441299352777775,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8721,"joy":0.0542,"surprise":0.047,"sadness":0.0049,"fear":0.0028,"anger":0.0144,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the efficiency of machine learning algorithms for large-margin halfspaces. While more efficient algorithms can reduce the energy consumption of computation, the impact on climate is indirect and difficult to quantify without knowing the specific applications and scale of deployment. The research is at a basic research stage, with no deployed technology or measured outcomes.","key_impact_metrics":["Sample complexity with respect to the accuracy parameter $\\epsilon$"],"technology_tags":["Machine Learning","Algorithms","Large-Margin Halfspaces"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:29.767167Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_15d8745bcc20","title":"Differentially Private Matchings","content":"arXiv:2501.00926v2 Announce Type: cross Abstract: Computing matchings in general graphs plays a central role in graph algorithms. However, despite the recent interest in differentially private graph algorithms, there has been limited work on private matchings. Moreover, almost all existing work focuses on estimating the size of the maximum matching, whereas in many applications, the matching itself is the object of interest. There is currently only a single work on private algorithms for computing matching solutions by [HHRRW STOC'14]. Moreover, their work focuses on allocation problems and hence is limited to bipartite graphs. Motivated by the importance of computing matchings in sensitive graph data, we initiate the study of differentially private algorithms for computing maximal and maximum matchings in general graphs. We provide a number of algorithms and lower bounds for this problem in different models and settings. We first prove a lower bound showing that computing explicit solutions necessarily incurs large error, even if we try to obtain privacy by allowing ourselves to output non-edges. We then consider implicit solutions, where at the end of the computation there is an ($\\varepsilon$-differentially private) billboard and each node can determine its matched edge(s) based on what is written on this publicly visible billboard. For this solution concept, we provide tight upper and lower (bicriteria) bounds, where the degree bound is violated by a logarithmic factor (which we show is necessary). We further show that our algorithm can be made distributed in the local edge DP (LEDP) model, and can even be done in a logarithmic number of rounds if we further relax the degree bounds by logarithmic factors. Our edge-DP matching algorithms give rise to new matching algorithms in the node-DP setting by combining our edge-DP algorithms with a novel use of arboricity sparsifiers. [...]","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2501.00926","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.454907","language":"en","tags":["preprints","computer-science","cscr","research","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":293,"author":"Michael Dinitz, George Z. Li, Quanquan C. Liu, Felix Zhou","raw_content_length":1919,"priority":7,"update_frequency":1,"reading_time_minutes":1.465,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1916,"language_detected":"en","key_concepts":{"key_phrases":["Differentially Private Matchings","Announce Type","cross","Abstract","Computing matchings","general graphs","a central role","graph algorithms","the recent interest","differentially private graph algorithms"],"filter_categories":{"ai_ml":["graph algorithms","differentially private graph algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Differentially Private Matchings":2.0,"Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Computing matchings":1.0,"general graphs":1.0,"a central role":1.0,"graph algorithms":1.0,"the recent interest":1.0,"differentially private graph algorithms":1.0}},"age_hours":2.744144117222222,"is_recent":true,"quality_score":0.7,"sentiment_score":5.7905,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1581,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9198,"joy":0.0051,"surprise":0.017,"sadness":0.0096,"fear":0.0154,"anger":0.0188,"disgust":0.0143},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents algorithms for differentially private matchings in graphs. While the research is technically sound and peer-reviewed, it is at a very early stage (basic research) and does not have any concrete deployments or measurable outcomes related to sustainability. The potential climate impact is minimal at this stage.","key_impact_metrics":[],"technology_tags":["differential privacy","graph algorithms","matching algorithms"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:32:35.453748Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_45e5f7900bbe","title":"Leveraging LLMs, IDEs, and Semantic Embeddings for Automated Move Method Refactoring","content":"arXiv:2503.20934v1 Announce Type: cross Abstract: MOVEMETHOD is a hallmark refactoring. Despite a plethora of research tools that recommend which methods to move and where, these recommendations do not align with how expert developers perform MOVEMETHOD. Given the extensive training of Large Language Models and their reliance upon naturalness of code, they should expertly recommend which methods are misplaced in a given class and which classes are better hosts. Our formative study of 2016 LLM recommendations revealed that LLMs give expert suggestions, yet they are unreliable: up to 80% of the suggestions are hallucinations. We introduce the first LLM fully powered assistant for MOVEMETHOD refactoring that automates its whole end-to-end lifecycle, from recommendation to execution. We designed novel solutions that automatically filter LLM hallucinations using static analysis from IDEs and a novel workflow that requires LLMs to be self-consistent, critique, and rank refactoring suggestions. As MOVEMETHOD refactoring requires global, projectlevel reasoning, we solved the limited context size of LLMs by employing refactoring-aware retrieval augment generation (RAG). Our approach, MM-assist, synergistically combines the strengths of the LLM, IDE, static analysis, and semantic relevance. In our thorough, multi-methodology empirical evaluation, we compare MM-assist with the previous state-of-the-art approaches. MM-assist significantly outperforms them: (i) on a benchmark widely used by other researchers, our Recall@1 and Recall@3 show a 1.7x improvement; (ii) on a corpus of 210 recent refactorings from Open-source software, our Recall rates improve by at least 2.4x. Lastly, we conducted a user study with 30 experienced participants who used MM-assist to refactor their own code for one week. They rated 82.8% of MM-assist recommendations positively. This shows that MM-assist is both effective and useful.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.20934","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.456183","language":"en","tags":["preprints","csai","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":272,"author":"Fraol Batole, Abhiram Bellur, Malinda Dilhara, Mohammed Raihan Ullah, Yaroslav Zharov, Timofey Bryksin, Kai Ishikawa, Haifeng Chen, Masaharu Morimoto, Shota Motoura, Takeo Hosomi, Tien N. Nguyen, Hridesh Rajan, Nikolaos Tsantalis, Danny Dig","raw_content_length":1928,"priority":7,"update_frequency":1,"reading_time_minutes":1.36,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","MOVEMETHOD","Automated Move Method Refactoring arXiv:2503.20934v1","Semantic Embeddings"],"persons":[],"locations":[],"monetary":[]},"char_count":1927,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","IDEs","Semantic Embeddings","Automated Move Method Refactoring","MOVEMETHOD","which methods","arXiv250320934v1 Announce Type","cross","a hallmark refactoring","a plethora"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":2.0,"IDEs":2.0,"Semantic Embeddings":2.0,"Automated Move Method Refactoring":2.0,"MOVEMETHOD":2.0,"which methods":2.0,"arXiv250320934v1 Announce Type":1.0,"cross":1.0,"a hallmark refactoring":1.0,"a plethora":1.0}},"age_hours":2.744159013611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9484,"joy":0.0018,"surprise":0.0098,"sadness":0.0063,"fear":0.0048,"anger":0.0155,"disgust":0.0134},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving software refactoring using LLMs, IDEs, and semantic embeddings. While it demonstrates improved recall rates (1.7x and 2.4x improvements) and positive user feedback (82.8%), it's still in the applied research stage with no clear path to economic viability or large-scale deployment. The impact on climate is indirect, as it improves software development efficiency, which *could* lead to more efficient resource use in other sectors, but this is not directly measured or quantified.","key_impact_metrics":["Recall@1 and Recall@3 show a 1.7x improvement","Recall rates improve by at least 2.4x"],"technology_tags":["Large Language Models","Software Refactoring"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:32:39.597968Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_025da9f454de","title":"Mixture of Inverse Gaussians for Hemodynamic Transport (MIGHT) in Vascular Networks","content":"arXiv:2510.11743v1 Announce Type: cross Abstract: Synthetic molecular communication (MC) in the cardiovascular system (CVS) is a key enabler for many envisioned medical applications in the human body, such as targeted drug delivery, early cancer detection, and continuous health monitoring. The design of MC systems for such applications requires suitable models for the signaling molecule propagation through complex vessel networks (VNs). Existing theoretical models offer limited analytical tractability and lack closed-form solutions, making the analysis of large-scale VNs either infeasible or not insightful. To overcome these limitations, in this paper, we propose a novel closed-form physical model, termed MIGHT, for advection-diffusion-driven transport of signaling molecules through complex VNs. The model represents the received molecule flux as a weighted sum of inverse Gaussian (IG) distributions, parameterized by physical properties of the network. The proposed model is validated by comparison with an existing convolution-based model and finite-element simulations. Further, we show that the model can be applied for the reduction of large VNs to simplified representations preserving the essential transport dynamics and for estimating representative VN based on received signals from unknown VNs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11743","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.459149","language":"en","tags":["preprints","computer-science","research","q-bioqm","cset","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Timo Jakumeit, Bastian Heinlein, Leonie Richter, Sebastian Lotter, Robert Schober, Maximilian Sch\\\"afer","raw_content_length":1318,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["Vascular Networks"],"persons":["Hemodynamic Transport","Gaussian"],"locations":[],"monetary":[]},"char_count":1317,"language_detected":"en","key_concepts":{"key_phrases":["Mixture","Inverse Gaussians","Hemodynamic Transport","MIGHT","Vascular Networks","arXiv251011743v1 Announce Type","cross","Synthetic molecular communication","the cardiovascular system","CVS"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mixture":2.0,"Inverse Gaussians":2.0,"Hemodynamic Transport":2.0,"MIGHT":2.0,"Vascular Networks":2.0,"arXiv251011743v1 Announce Type":1.0,"cross":1.0,"Synthetic molecular communication":1.0,"the cardiovascular system":1.0,"CVS":1.0}},"age_hours":2.744262828333333,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.899,"joy":0.0117,"surprise":0.0455,"sadness":0.0095,"fear":0.0148,"anger":0.0109,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel model for molecular communication in the cardiovascular system, which could potentially enable targeted drug delivery and early cancer detection. The model is validated by comparison with existing models and simulations, increasing technical credibility. However, it is still in the early stages of research and lacks concrete deployment or economic viability data.","key_impact_metrics":["Reduction of large VNs to simplified representations","Estimation of representative VN based on received signals"],"technology_tags":["Molecular Communication","Vascular Network Modeling","Advection-Diffusion"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:32:42.764251Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e1fa59bc6fe","title":"PRISM: Enhancing Protein Inverse Folding through Fine","content":"arXiv:2510.11750v1 Announce Type: cross Abstract: Designing protein sequences that fold into a target three-dimensional structure, known as the inverse folding problem, is central to protein engineering but remains challenging due to the vast sequence space and the importance of local structural constraints. Existing deep learning approaches achieve strong recovery rates, yet they lack explicit mechanisms to reuse fine-grained structure-sequence patterns that are conserved across natural proteins. We present PRISM, a multimodal retrieval-augmented generation framework for inverse folding that retrieves fine-grained representations of potential motifs from known proteins and integrates them with a hybrid self-cross attention decoder. PRISM is formulated as a latent-variable probabilistic model and implemented with an efficient approximation, combining theoretical grounding with practical scalability. Across five benchmarks (CATH-4.2, TS50, TS500, CAMEO 2022, and the PDB date split), PRISM establishes new state of the art in both perplexity and amino acid recovery, while also improving foldability metrics (RMSD, TM-score, pLDDT), demonstrating that fine-grained multimodal retrieval is a powerful and efficient paradigm for protein sequence design.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11750","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.459963","language":"en","tags":["preprints","computer-science","cslg","research","q-bioqm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Sazan Mahbub, Souvik Kundu, Eric P. Xing","raw_content_length":1265,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["CATH-4.2"],"persons":[],"locations":[],"monetary":[]},"char_count":1264,"language_detected":"en","key_concepts":{"key_phrases":["PRISM","Protein Inverse","Fine","Announce Type","cross","Abstract","Designing protein sequences","a target three-dimensional structure","the inverse folding problem","the vast sequence space"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PRISM":2.0,"Protein Inverse":2.0,"Fine":2.0,"Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Designing protein sequences":1.0,"a target three-dimensional structure":1.0,"the inverse folding problem":1.0,"the vast sequence space":1.0}},"age_hours":2.74429196,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9211,"joy":0.0059,"surprise":0.034,"sadness":0.012,"fear":0.0088,"anger":0.011,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (PRISM) for protein inverse folding, achieving state-of-the-art results in amino acid recovery and foldability metrics (RMSD, TM-score, pLDDT) across multiple benchmarks. While the technology is still in the research phase, its potential lies in designing proteins for various applications, including potentially creating more efficient enzymes for industrial processes or biofuels, but this is theoretical. The paper is peer-reviewed and provides specific metrics, increasing its credibility.","key_impact_metrics":["Amino acid recovery rate","RMSD"],"technology_tags":["Protein Engineering","Inverse Folding","Deep Learning","AI","Multimodal Retrieval"],"sdg_alignment":[2,9],"analyzed_at":"2025-10-29T16:32:46.414043Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_df1c2bc22469","title":"Fast and Interpretable Protein Substructure Alignment via Optimal Transport","content":"arXiv:2510.11752v1 Announce Type: cross Abstract: Proteins are essential biological macromolecules that execute life functions. Local motifs within protein structures, such as active sites, are the most critical components for linking structure to function and are key to understanding protein evolution and enabling protein engineering. Existing computational methods struggle to identify and compare these local structures, which leaves a significant gap in understanding protein structures and harnessing their functions. This study presents PLASMA, the first deep learning framework for efficient and interpretable residue-level protein substructure alignment. We reformulate the problem as a regularized optimal transport task and leverage differentiable Sinkhorn iterations. For a pair of input protein structures, PLASMA outputs a clear alignment matrix with an interpretable overall similarity score. Through extensive quantitative evaluations and three biological case studies, we demonstrate that PLASMA achieves accurate, lightweight, and interpretable residue-level alignment. Additionally, we introduce PLASMA-PF, a training-free variant that provides a practical alternative when training data are unavailable. Our method addresses a critical gap in protein structure analysis tools and offers new opportunities for functional annotation, evolutionary studies, and structure-based drug design. Reproducibility is ensured via our official implementation at https://github.com/ZW471/PLASMA-Protein-Local-Alignment.git.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11752","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.460371","language":"en","tags":["preprints","csai","computer-science","cslg","research","q-bioqm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Zhiyu Wang, Bingxin Zhou, Jing Wang, Yang Tan, Weishu Zhao, Pietro Li\\`o, Liang Hong","raw_content_length":1531,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["PLASMA","Optimal Transport arXiv:2510.11752v1 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1530,"language_detected":"en","key_concepts":{"key_phrases":["Fast and Interpretable Protein Substructure Alignment","Optimal Transport","protein structures","arXiv251011752v1","Announce Type","Proteins","essential biological macromolecules","life functions","Local motifs","active sites"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fast and Interpretable Protein Substructure Alignment":2.0,"Optimal Transport":2.0,"protein structures":2.0,"arXiv251011752v1":1.0,"Announce Type":1.0,"Proteins":1.0,"essential biological macromolecules":1.0,"life functions":1.0,"Local motifs":1.0,"active sites":1.0}},"age_hours":2.744305836944444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.395,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.079,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9156,"joy":0.0045,"surprise":0.0285,"sadness":0.0114,"fear":0.0135,"anger":0.0175,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel deep learning framework (PLASMA) for protein substructure alignment. While it has potential for applications in drug design and understanding protein evolution, its direct climate impact is currently theoretical. The method is validated through quantitative evaluations and biological case studies, but deployment is limited to research settings.","key_impact_metrics":["Accurate residue-level alignment","Interpretable similarity score"],"technology_tags":["Deep Learning","Protein Substructure Alignment","Optimal Transport"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:32:49.378113Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e14af9a0422","title":"An Effective Method for Solving a Class of Transcendental Diophantine Equations","content":"arXiv:2510.11753v1 Announce Type: cross Abstract: This paper investigates the exponential Diophantine equation of the form $a^x+b=c^y$, where $a, b, c$ are given positive integers with $a,c \\ge 2$, and $x,y$ are positive integer unknowns. We define this form as a \"Type-I transcendental diophantine equation.\" A general solution to this problem remains an open question; however, the ABC conjecture implies that the number of solutions for any such equation is finite. This work introduces and implements an effective algorithm designed to solve these equations. The method first computes a strict upper bound for potential solutions given the parameters $(a, b, c)$ and then identifies all solutions via finite enumeration. While the universal termination of this algorithm is not theoretically guaranteed, its heuristic-based design has proven effective and reliable in large-scale numerical experiments. Crucially, for each instance it successfully solves, the algorithm is capable of generating a rigorous mathematical proof of the solution's completeness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11753","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.460784","language":"en","tags":["preprints","computer-science","mathnt","research","csms","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Zeyu Cai","raw_content_length":1061,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["ABC","c)$"],"persons":[],"locations":[],"monetary":[]},"char_count":1060,"language_detected":"en","key_concepts":{"key_phrases":["An Effective Method","a Class","Transcendental Diophantine Equations","arXiv251011753v1 Announce Type","cross","This paper","the exponential Diophantine equation","the form","axb","positive integers"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Effective Method":2.0,"a Class":2.0,"Transcendental Diophantine Equations":2.0,"arXiv251011753v1 Announce Type":1.0,"cross":1.0,"This paper":1.0,"the exponential Diophantine equation":1.0,"the form":1.0,"axb":1.0,"positive integers":1.0}},"age_hours":2.7443224341666665,"is_recent":true,"quality_score":1.0,"sentiment_score":9.559,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9118,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7615,"joy":0.0836,"surprise":0.1177,"sadness":0.0138,"fear":0.0086,"anger":0.0111,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for solving a specific type of Diophantine equation. While the algorithm's termination is not theoretically guaranteed, it has shown effectiveness in numerical experiments and can generate rigorous mathematical proofs for solved instances. The connection to sustainability is indirect, as the algorithm itself doesn't directly address environmental issues, but could potentially be used to optimize resource allocation or model complex systems.","key_impact_metrics":[],"technology_tags":["algorithm","mathematical optimization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:32:55.182027Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e1ad24d447a","title":"On Thompson Sampling and Bilateral Uncertainty in Additive Bayesian Optimization","content":"arXiv:2510.11792v1 Announce Type: cross Abstract: In Bayesian Optimization (BO), additive assumptions can mitigate the twin difficulties of modeling and searching a complex function in high dimension. However, common acquisition functions, like the Additive Lower Confidence Bound, ignore pairwise covariances between dimensions, which we'll call \\textit{bilateral uncertainty} (BU), imposing a second layer of approximations. While theoretical results indicate that asymptotically not much is lost in doing so, little is known about the practical effects of this assumption in small budgets. In this article, we show that by exploiting conditional independence, Thompson Sampling respecting BU can be efficiently conducted. We use this fact to execute an empirical investigation into the loss incurred by ignoring BU, finding that the additive approximation to Thompson Sampling does indeed have, on balance, worse performance than the exact method, but that this difference is of little practical significance. This buttresses the theoretical understanding and suggests that the BU-ignoring approximation is sufficient for BO in practice, even in the non-asymptotic regime.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11792","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.462103","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Nathan Wycoff","raw_content_length":1176,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Bilateral Uncertainty in Additive Bayesian Optimization arXiv:2510.11792v1 Announce Type:","the Additive Lower Confidence Bound","Thompson Sampling","Thompson Sampling and"],"persons":[],"locations":[],"monetary":[]},"char_count":1175,"language_detected":"en","key_concepts":{"key_phrases":["Thompson Sampling","Bilateral Uncertainty","Additive Bayesian Optimization","Announce Type","cross","Bayesian Optimization BO","additive assumptions","the twin difficulties","modeling","a complex function"],"filter_categories":{"ai_ml":["Bilateral Uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Thompson Sampling":2.0,"Bilateral Uncertainty":2.0,"Additive Bayesian Optimization":2.0,"Announce Type":1.0,"cross":1.0,"Bayesian Optimization BO":1.0,"additive assumptions":1.0,"the twin difficulties":1.0,"modeling":1.0,"a complex function":1.0}},"age_hours":2.7443632508333335,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9305,"joy":0.0055,"surprise":0.0207,"sadness":0.0065,"fear":0.0174,"anger":0.0117,"disgust":0.0076},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on improving Bayesian Optimization algorithms, specifically Thompson Sampling, for additive functions. While the research finds that a simplified approximation performs nearly as well as the exact method, the impact on sustainability is indirect, as it could potentially improve the efficiency of optimization in various fields, including climate tech. The research is theoretical and has not been deployed in a real-world application.","key_impact_metrics":["performance difference between methods"],"technology_tags":["Bayesian Optimization","Thompson Sampling","Additive Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:32:58.952879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_904315ef349c","title":"Mean","content":"arXiv:2510.11843v1 Announce Type: cross Abstract: This paper introduces a framework of Constrained Mean-Field Games (CMFGs), where each agent solves a constrained Markov decision process (CMDP). This formulation captures scenarios in which agents' strategies are subject to feasibility, safety, or regulatory restrictions, thereby extending the scope of classical mean field game (MFG) models. We first establish the existence of CMFG equilibria under a strict feasibility assumption, and we further show uniqueness under a classical monotonicity condition. To compute equilibria, we develop Constrained Mean-Field Occupation Measure Optimization (CMFOMO), an optimization-based scheme that parameterizes occupation measures and shows that finding CMFG equilibria is equivalent to solving a single optimization problem with convex constraints and bounded variables. CMFOMO does not rely on uniqueness of the equilibria and can approximate all equilibria with arbitrary accuracy. We further prove that CMFG equilibria induce $O(1 / \\sqrt{N})$-Nash equilibria in the associated constrained $N$-player games, thereby extending the classical justification of MFGs as approximations for large but finite systems. Numerical experiments on a modified Susceptible-Infected-Susceptible (SIS) epidemic model with various constraints illustrate the effectiveness and flexibility of the framework.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11843","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.462508","language":"en","tags":["preprints","computer-science","mathoc","research","mathpr","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Anran Hu, Zijiu Lyu","raw_content_length":1386,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Constrained Mean-Field Occupation Measure Optimization","CMFOMO","CMFG","Constrained Mean-Field Games","MFG"],"persons":["Markov","Announce Type"],"locations":[],"monetary":[]},"char_count":1385,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011843v1 Announce Type","cross","Abstract","This paper","a framework","Constrained Mean-Field Games","CMFGs","each agent","a constrained Markov decision process","CMDP"],"filter_categories":{"ai_ml":["Constrained Mean-Field Games"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011843v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"This paper":1.0,"a framework":1.0,"Constrained Mean-Field Games":1.0,"CMFGs":1.0,"each agent":1.0,"a constrained Markov decision process":1.0,"CMDP":1.0}},"age_hours":2.7443776808333333,"is_recent":true,"quality_score":0.7,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8839,"joy":0.0577,"surprise":0.025,"sadness":0.0029,"fear":0.0073,"anger":0.0154,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework (CMFGs) and an optimization-based scheme (CMFOMO) for computing equilibria in constrained mean-field games. The numerical experiments on a modified SIS epidemic model demonstrate the framework's effectiveness and flexibility, but there's no real-world deployment or quantified environmental impact yet. The framework could potentially be used to model and optimize systems with environmental constraints, but this is still in the research phase.","key_impact_metrics":["O(1 / sqrt(N))-Nash equilibria"],"technology_tags":["Mean-Field Games","Constrained Markov Decision Processes","Optimization"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:33:03.985603Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e465451e76e","title":"Enhancing Diffusion","content":"arXiv:2510.11923v1 Announce Type: cross Abstract: Diffusion-based samplers learn to sample complex, high-dimensional distributions using energies or log densities alone, without training data. Yet, they remain impractical for molecular sampling because they are often slower than molecular dynamics and miss thermodynamically relevant modes. Inspired by enhanced sampling, we encourage exploration by introducing a sequential bias along bespoke, information-rich, low-dimensional projections of atomic coordinates known as collective variables (CVs). We introduce a repulsive potential centered on the CVs from recent samples, which pushes future samples towards novel CV regions and effectively increases the temperature in the projected space. Our resulting method improves efficiency, mode discovery, enables the estimation of free energy differences, and retains independent sampling from the approximate Boltzmann distribution via reweighting by the bias. On standard peptide conformational sampling benchmarks, the method recovers diverse conformational states and accurate free energy profiles. We are the first to demonstrate reactive sampling using a diffusion-based sampler, capturing bond breaking and formation with universal interatomic potentials at near-first-principles accuracy. The approach resolves reactive energy landscapes at a fraction of the wall-clock time of standard sampling methods, advancing diffusion-based sampling towards practical use in molecular sciences.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11923","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.464090","language":"en","tags":["preprints","statml","computer-science","cslg","research","physicschem-ph","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Juno Nam, B\\'alint M\\'at\\'e, Artur P. Toshev, Manasa Kaniselvan, Rafael G\\'omez-Bombarelli, Ricky T. Q. Chen, Brandon Wood, Guan-Horng Liu, Benjamin Kurt Miller","raw_content_length":1492,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Enhancing Diffusion arXiv:2510.11923v1 Announce Type:"],"persons":["Boltzmann"],"locations":[],"monetary":[]},"char_count":1491,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion","arXiv251011923v1 Announce Type","cross","Diffusion-based samplers","complex high-dimensional distributions","energies","densities","training data","molecular sampling","molecular dynamics"],"filter_categories":{"ai_ml":["training data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion":2.0,"arXiv251011923v1 Announce Type":1.0,"cross":1.0,"Diffusion-based samplers":1.0,"complex high-dimensional distributions":1.0,"energies":1.0,"densities":1.0,"training data":1.0,"molecular sampling":1.0,"molecular dynamics":1.0}},"age_hours":2.744431409444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.063,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8126,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9145,"joy":0.0073,"surprise":0.0291,"sadness":0.0114,"fear":0.0084,"anger":0.0137,"disgust":0.0156},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method for molecular sampling using diffusion models, improving efficiency and mode discovery. It demonstrates reactive sampling with near-first-principles accuracy, resolving reactive energy landscapes faster than standard methods. While promising, it's still in the applied research stage with no deployed units or independent verification.","key_impact_metrics":["Fraction of wall-clock time reduction","Accuracy of free energy profiles"],"technology_tags":["Diffusion-based sampling","Molecular dynamics","Enhanced sampling"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:33:09.241946Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ddfec6ce3341","title":"On the Walsh spectra of quadratic APN functions","content":"arXiv:2510.12008v1 Announce Type: cross Abstract: APN functions play a central role as building blocks in the design of many block ciphers, serving as optimal functions to resist differential attacks. One of the most important properties of APN functions is their linearity, which is directly related to the Walsh spectrum of the function. In this paper, we establish two novel connections that allow us to derive strong conditions on the Walsh spectra of quadratic APN functions. We prove that the Walsh transform of a quadratic APN function $F$ operating on $n=2k$ bits is uniquely associated with a vector space partition of $\\mathbb{F}_2^n$ and a specific blocking set in the corresponding projective space $PG(n-1,2)$. These connections allow us to prove a variety of results on the Walsh spectrum of $F$. We prove for instance that $F$ can have at most one component function of amplitude larger than $2^{\\frac{3}{4}n}$. We also find the first nontrivial upper bound on the number of bent component functions of a quadratic APN function, and and provide conditions for a function to be CCZ-equivalent to a permutation, based on its number of bent components.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12008","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.464483","language":"en","tags":["preprints","mathco","csit","computer-science","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Sophie Hannah B\\'en\\'eteau, Nicolas Goluboff, Lukas K\\\"olsch, Divyesh Vaghasiya","raw_content_length":1165,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["APN"],"persons":["Walsh"],"locations":[],"monetary":["PG(n-1,2)$.","larger than $2^{\\frac{3}{4}n}$.","\\mathbb{F}_2^n$"]},"char_count":1164,"language_detected":"en","key_concepts":{"key_phrases":["the Walsh spectra","quadratic APN functions","APN functions","arXiv251012008v1 Announce Type","cross","a central role","blocks","the design","many block ciphers","optimal functions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Walsh spectra":3.0,"quadratic APN functions":3.0,"APN functions":2.0,"arXiv251012008v1 Announce Type":1.0,"cross":1.0,"a central role":1.0,"blocks":1.0,"the design":1.0,"many block ciphers":1.0,"optimal functions":1.0}},"age_hours":2.744446455277778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6997,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.872,"joy":0.0273,"surprise":0.0635,"sadness":0.0047,"fear":0.0118,"anger":0.0149,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on improving the security of block ciphers, which indirectly supports sustainability by protecting data used in climate modeling, renewable energy management, and other sustainability-related applications. The research is theoretical, establishing mathematical connections and proving bounds on the Walsh spectrum of APN functions, but does not have immediate deployment or measurable impact on emissions. The technical credibility is high due to the mathematical proofs and potential for peer review.","key_impact_metrics":["at most one component function of amplitude larger than 2^(3/4)n","first nontrivial upper bound on the number of bent component functions"],"technology_tags":["cryptography","block ciphers","APN functions"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:33:12.763911Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bf3440507b0d","title":"Statistical Guarantees for High","content":"arXiv:2510.12013v1 Announce Type: cross Abstract: Stochastic Gradient Descent (SGD) and its Ruppert-Polyak averaged variant (ASGD) lie at the heart of modern large-scale learning, yet their theoretical properties in high-dimensional settings are rarely understood. In this paper, we provide rigorous statistical guarantees for constant learning-rate SGD and ASGD in high-dimensional regimes. Our key innovation is to transfer powerful tools from high-dimensional time series to online learning. Specifically, by viewing SGD as a nonlinear autoregressive process and adapting existing coupling techniques, we prove the geometric-moment contraction of high-dimensional SGD for constant learning rates, thereby establishing asymptotic stationarity of the iterates. Building on this, we derive the $q$-th moment convergence of SGD and ASGD for any $q\\ge2$ in general $\\ell^s$-norms, and, in particular, the $\\ell^{\\infty}$-norm that is frequently adopted in high-dimensional sparse or structured models. Furthermore, we provide sharp high-probability concentration analysis which entails the probabilistic bound of high-dimensional ASGD. Beyond closing a critical gap in SGD theory, our proposed framework offers a novel toolkit for analyzing a broad class of high-dimensional learning algorithms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12013","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.464896","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Jiaqi Li, Zhipeng Lou, Johannes Schmidt-Hieber, Wei Biao Wu","raw_content_length":1294,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["SGD"],"persons":["ASGD"],"locations":[],"monetary":["$q\\ge2$","$q$-th moment"]},"char_count":1293,"language_detected":"en","key_concepts":{"key_phrases":["Statistical Guarantees","ASGD","arXiv251012013v1 Announce Type","cross","Abstract","Stochastic Gradient Descent","SGD","its Ruppert-Polyak","the heart","modern large-scale learning"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Statistical Guarantees":2.0,"ASGD":2.0,"arXiv251012013v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Stochastic Gradient Descent":1.0,"SGD":1.0,"its Ruppert-Polyak":1.0,"the heart":1.0,"modern large-scale learning":1.0}},"age_hours":2.7444620872222223,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9188,"joy":0.0241,"surprise":0.0263,"sadness":0.0042,"fear":0.009,"anger":0.0129,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on improving the theoretical understanding of Stochastic Gradient Descent (SGD) algorithms, which are used in machine learning. While machine learning can be applied to various sustainability-related problems, the paper itself doesn't present concrete actions or measurable outcomes related to climate change or other sustainability dimensions. It's basic research with potential applications, but no direct impact is demonstrated.","key_impact_metrics":[],"technology_tags":["Stochastic Gradient Descent","Machine Learning","Optimization Algorithms"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:33:16.946559Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_779a12bf51d7","title":"Generative AI and Firm Productivity: Field Experiments in Online Retail","content":"arXiv:2510.12049v1 Announce Type: cross Abstract: We quantify the impact of Generative Artificial Intelligence (GenAI) on firm productivity through a series of large-scale randomized field experiments involving millions of users and products at a leading cross-border online retail platform. Over six months in 2023-2024, GenAI-based enhancements were integrated into seven consumer-facing business workflows. We find that GenAI adoption significantly increases sales, with treatment effects ranging from 0\\% to 16.3\\%, depending on GenAI's marginal contribution relative to existing firm practices. Because inputs and prices were held constant across experimental arms, these gains map directly into total factor productivity improvements. Across the four GenAI applications with positive effects, the implied annual incremental value is approximately \\$5 per consumer-an economically meaningful impact given the retailer's scale and the early stage of GenAI adoption. The primary mechanism operates through higher conversion rates, consistent with GenAI reducing frictions in the marketplace and improving consumer experience. We also document substantial heterogeneity: smaller and newer sellers, as well as less experienced consumers, exhibit disproportionately larger gains. Our findings provide novel, large-scale causal evidence on the productivity effects of GenAI in online retail, highlighting both its immediate value and broader potential.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12049","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.465692","language":"en","tags":["preprints","csai","computer-science","research","q-finec","econgn","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Lu Fang, Zhe Yuan, Kaifu Zhang, Dante Donati, Miklos Sarvary","raw_content_length":1452,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Generative Artificial Intelligence (GenAI","Firm Productivity: Field Experiments","GenAI"],"persons":["Generative AI"],"locations":[],"monetary":[]},"char_count":1451,"language_detected":"en","key_concepts":{"key_phrases":["Generative AI and Firm Productivity","Field Experiments","Online Retail","arXiv251012049v1 Announce Type","cross","Abstract","the impact","Generative Artificial Intelligence","GenAI","firm productivity"],"filter_categories":{"ai_ml":["Generative AI and Firm Productivity","Generative Artificial Intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative AI and Firm Productivity":2.0,"Field Experiments":2.0,"Online Retail":2.0,"arXiv251012049v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"the impact":1.0,"Generative Artificial Intelligence":1.0,"GenAI":1.0,"firm productivity":1.0}},"age_hours":2.7444916830555557,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7329,"joy":0.0918,"surprise":0.1322,"sadness":0.0073,"fear":0.0082,"anger":0.0206,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":2,"technical_credibility":7,"economic_viability":7,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes the deployment of GenAI in a large-scale online retail platform, resulting in increased sales and productivity. The study involves millions of users and products over six months, providing substantial data. The impact is quantified with specific metrics like sales increases and implied annual incremental value per consumer.","key_impact_metrics":["Sales increase 0-16.3%","Annual incremental value $5 per consumer"],"technology_tags":["Generative AI","Online Retail","E-commerce"],"sdg_alignment":[8,9,12],"analyzed_at":"2025-10-29T16:33:23.353852Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
