{"id":"science_arxiv_cs_da6e785fa670","title":"Part II: ROLL Flash -","content":"arXiv:2510.11345v1 Announce Type: new Abstract: Synchronous Reinforcement Learning (RL) post-training has emerged as a crucial step for enhancing Large Language Models (LLMs) with diverse capabilities. However, many systems designed to accelerate RL post-training still suffer from low resource utilization and limited scalability. We present ROLL Flash, a system that extends ROLL with native support for asynchronous RL post-training. ROLL Flash is built upon two core design principles: fine-grained parallelism and rollout-train decoupling. Guided by these principles, ROLL Flash provides flexible programming interfaces that enable a fully asynchronous training architecture and support efficient rollout mechanisms, including queue scheduling and environment-level asynchronous execution. Through comprehensive theoretical analysis and extensive experiments, we demonstrate that ROLL Flash significantly improves resource utilization and scalability over synchronous RL post-training. ROLL Flash achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using the same GPU budget as synchronous baselines. Furthermore, we implement several popular off-policy algorithms and verify that asynchronous training can achieve performance on par with synchronous training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11345","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.946546","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Han Lu, Zichen Liu, Shaopan Xiong, Yancheng He, Wei Gao, Yanan Wu, Weixun Wang, Jiashun Liu, Yang Li, Haizhou Zhao, Ju Huang, Siran Yang, Xiaoyang Li, Yijia Luo, Zihe Liu, Ling Pan, Junchi Yan, Wei Wang, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng","raw_content_length":1285,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models"],"persons":["ROLL Flash"],"locations":[],"monetary":[]},"char_count":1284,"language_detected":"en","key_concepts":{"key_phrases":["ROLL","Part II","Flash","ROLL Flash","arXiv251011345v1","Announce Type","new Abstract","Synchronous Reinforcement Learning","post-training","a crucial step"],"filter_categories":{"engineering":["ROLL"],"ai_ml":["Synchronous Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ROLL":3.0,"Part II":2.0,"Flash":2.0,"ROLL Flash":2.0,"arXiv251011345v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Synchronous Reinforcement Learning":1.0,"post-training":1.0,"a crucial step":1.0}},"age_hours":2.758457960277778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9078,"joy":0.0087,"surprise":0.0302,"sadness":0.0279,"fear":0.0076,"anger":0.0086,"disgust":0.0092},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a system (ROLL Flash) for improving the efficiency of Reinforcement Learning post-training for Large Language Models. While it demonstrates speedups (up to 2.72x on agentic tasks) and improved resource utilization, it is still in the research phase with no deployed units or real-world impact on emissions. The theoretical analysis and experimental results provide technical credibility, but economic viability and deployment readiness are low at this stage.","key_impact_metrics":["2.24x speedup on RLVR tasks","2.72x speedup on agentic tasks"],"technology_tags":["Reinforcement Learning","Large Language Models","Asynchronous Training"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:59:10.038294Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_518515e8605a","title":"Understanding the Generalization of Stochastic Gradient Adam in Learning Neural Networks","content":"arXiv:2510.11354v1 Announce Type: new Abstract: Adam is a popular and widely used adaptive gradient method in deep learning, which has also received tremendous focus in theoretical research. However, most existing theoretical work primarily analyzes its full-batch version, which differs fundamentally from the stochastic variant used in practice. Unlike SGD, stochastic Adam does not converge to its full-batch counterpart even with infinitesimal learning rates. We present the first theoretical characterization of how batch size affects Adam's generalization, analyzing two-layer over-parameterized CNNs on image data. Our results reveal that while both Adam and AdamW with proper weight decay $\\lambda$ converge to poor test error solutions, their mini-batch variants can achieve near-zero test error. We further prove Adam has a strictly smaller effective weight decay bound than AdamW, theoretically explaining why Adam requires more sensitive $\\lambda$ tuning. Extensive experiments validate our findings, demonstrating the critical role of batch size and weight decay in Adam's generalization performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11354","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.947868","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Xuan Tang, Han Zhang, Yuan Cao, Difan Zou","raw_content_length":1114,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["Learning Neural Networks","SGD","the Generalization of Stochastic Gradient Adam"],"persons":["Adam","AdamW"],"locations":[],"monetary":[]},"char_count":1113,"language_detected":"en","key_concepts":{"key_phrases":["the Generalization","Stochastic Gradient Adam","Learning Neural Networks","which","arXiv251011354v1","Announce Type","new Abstract","Adam","deep learning","tremendous focus"],"filter_categories":{"ai_ml":["Learning Neural Networks","deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Generalization":2.0,"Stochastic Gradient Adam":2.0,"Learning Neural Networks":2.0,"which":2.0,"arXiv251011354v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Adam":1.0,"deep learning":1.0,"tremendous focus":1.0}},"age_hours":2.758500578888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8804,"joy":0.0147,"surprise":0.0685,"sadness":0.0082,"fear":0.0064,"anger":0.0125,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research analyzes the generalization of the Adam optimization algorithm in neural networks, specifically CNNs for image data. The concrete action is the theoretical characterization of how batch size affects Adam's generalization, with experimental validation. The evidence supporting the claims comes from theoretical proofs and extensive experiments, but it is still in the basic research stage.","key_impact_metrics":["near-zero test error","smaller effective weight decay bound"],"technology_tags":["Adam optimization","CNN","Deep Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:59:13.370043Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d8b87c694ceb","title":"A mathematical model for pricing perishable goods for quick","content":"arXiv:2510.11360v1 Announce Type: new Abstract: Quick commerce (q-commerce) is one of the fastest growing sectors in India. It provides informal employment to approximately 4,50,000 workers, and it is estimated to become a USD 200 Billion industry by 2026. A significant portion of this industry deals with perishable goods. (e.g. milk, dosa batter etc.) These are food items which are consumed relatively fresh by the consumers and therefore their order volume is high and repetitive even when the average basket size is relatively small. The fundamental challenge for the retailer is that, increasing selling price would hamper sales and would lead to unsold inventory. On the other hand setting a price less, would lead to forgoing of potential revenue. This paper attempts to propose a mathematical model which formalizes this dilemma. The problem statement is not only important for improving the unit economics of the perennially loss making quick commerce firms, but also would lead to a trickle-down effect in improving the conditions of the gig workers as observed in [4]. The sections below describe the mathematical formulation. The results from the simulation would be published in a follow-up study.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11360","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.948701","language":"en","tags":["computer-science","econem","csce","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Milon Bhattacharya","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":["India"],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["perishable goods","A mathematical model","arXiv251011360v1","Announce Type","new Abstract","Quick commerce","q-commerce","the fastest growing sectors","India","informal employment"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"perishable goods":3.0,"A mathematical model":2.0,"arXiv251011360v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Quick commerce":1.0,"q-commerce":1.0,"the fastest growing sectors":1.0,"India":1.0,"informal employment":1.0}},"age_hours":2.758530910833333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7754,"joy":0.1282,"surprise":0.0635,"sadness":0.0046,"fear":0.0065,"anger":0.0124,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":4,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a mathematical model for pricing perishable goods in quick commerce. While addressing food waste could have a positive environmental impact, the article focuses primarily on economic optimization and does not present any concrete actions or measurable outcomes related to sustainability. The model's impact on reducing food waste or emissions is theoretical at this stage.","key_impact_metrics":[],"technology_tags":["mathematical modeling","pricing optimization"],"sdg_alignment":[2,12],"analyzed_at":"2025-10-29T11:59:16.380220Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2cf3ba8a1879","title":"Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment","content":"arXiv:2510.11369v1 Announce Type: new Abstract: Reasoning-based image quality assessment (IQA) models trained through reinforcement learning (RL) exhibit exceptional generalization, yet the underlying mechanisms and critical factors driving this capability remain underexplored in current research. Moreover, despite their superior performance, these models incur inference energy usage and latency orders of magnitude higher than their earlier counterparts, restricting their deployment in specific scenarios. Through extensive experiments, this paper verifies and elaborates that through RL training, MLLMs leverage their reasoning capability to convert redundant visual representations into compact, cross-domain aligned text representations. This conversion is precisely the source of the generalization exhibited by these reasoning-based IQA models. Building on this fundamental insight, we propose a novel algorithm, RALI, which employs contrastive learning to directly align images with these generalizable text representations learned by RL. This approach eliminates the reliance on reasoning processes and even obviates the need to load an LLM. For the quality scoring task, this framework achieves generalization performance comparable to reasoning-based models while requiring less than 5% of their model parameters and inference time.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11369","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.949832","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Shijie Zhao, Xuanyu Zhang, Weiqi Li, Junlin Li, Li Zhang, Tianfan Xue, Jian Zhang","raw_content_length":1347,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["IQA"],"persons":[],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["Representation","Visual Reinforcement Learning","Image Quality Assessment","Announce Type","IQA","reinforcement learning","exceptional generalization","the underlying mechanisms","critical factors","this capability"],"filter_categories":{"ai_ml":["Visual Reinforcement Learning","reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Representation":2.0,"Visual Reinforcement Learning":2.0,"Image Quality Assessment":2.0,"Announce Type":1.0,"IQA":1.0,"reinforcement learning":1.0,"exceptional generalization":1.0,"the underlying mechanisms":1.0,"critical factors":1.0,"this capability":1.0}},"age_hours":2.758570393333333,"is_recent":true,"quality_score":1.0,"sentiment_score":2.661,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4678,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7502,"joy":0.005,"surprise":0.0516,"sadness":0.0628,"fear":0.0106,"anger":0.0519,"disgust":0.068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel algorithm (RALI) that reduces the energy consumption and parameter size of image quality assessment models. It achieves comparable performance to reasoning-based models while requiring less than 5% of their model parameters and inference time. This is currently in the applied research stage, with no mention of deployment.","key_impact_metrics":["less than 5% of model parameters","less than 5% of inference time"],"technology_tags":["image quality assessment","reinforcement learning","contrastive learning","MLLMs"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:59:19.758603Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_718d074197ac","title":"Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers","content":"arXiv:2510.11370v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as a crucial approach for enhancing the capabilities of large language models. However, in Mixture-of-Experts (MoE) models, the routing mechanism often introduces instability, even leading to catastrophic RL training collapse. We analyze the training-inference consistency of MoE models and identify a notable discrepancy in routing behaviors between the two phases. Moreover, even under identical conditions, the routing framework can yield divergent expert selections across repeated forward passes. To address this foundational inconsistency, we propose Rollout Routing Replay (R3), a method that records routing distributions from the inference engine and replays them during training. R3 significantly reduces training-inference policy KL divergence and mitigates extreme discrepancies without compromising training speed. Extensive experiments on various settings confirm that R3 succeeds in stabilizing RL training, preventing collapse and outperforming methods such as GSPO and TIS. We believe this work can offer a new solution for stabilizing RL in MoE models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11370","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.950224","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Wenhan Ma, Hailin Zhang, Liang Zhao, Yifan Song, Yudong Wang, Zhifang Sui, Fuli Luo","raw_content_length":1159,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Rollout Routing Replay","Inference","Stabilizing MoE Reinforcement Learning"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1158,"language_detected":"en","key_concepts":{"key_phrases":["MoE Reinforcement Learning","Aligning Training and Inference Routers","Announce Type","new Abstract","Reinforcement learning","a crucial approach","the capabilities","large language models","Experts","the routing mechanism"],"filter_categories":{"ai_ml":["MoE Reinforcement Learning","Reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MoE Reinforcement Learning":2.0,"Aligning Training and Inference Routers":2.0,"Announce Type":1.0,"new Abstract":1.0,"Reinforcement learning":1.0,"a crucial approach":1.0,"the capabilities":1.0,"large language models":1.0,"Experts":1.0,"the routing mechanism":1.0}},"age_hours":2.7585854552777773,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2469999999999999,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7506,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7891,"joy":0.0047,"surprise":0.0286,"sadness":0.0144,"fear":0.1144,"anger":0.0338,"disgust":0.0149},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the stability of reinforcement learning in Mixture-of-Experts models, which could indirectly improve the efficiency of large language models used in various applications, including those related to sustainability. The concrete action is the proposal of the R3 method and its experimental validation. However, the impact on climate is indirect and not quantified, and the technology is at an early stage of development.","key_impact_metrics":["training-inference policy KL divergence reduction","stabilizing RL training preventing collapse"],"technology_tags":["reinforcement learning","mixture-of-experts models","large language models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:59:22.811604Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8bc984f0be46","title":"Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning","content":"arXiv:2510.11372v1 Announce Type: new Abstract: Although large language models excel across many tasks, they can memorise training data and thereby expose private or copyrighted text. Most defences target the pre-training stage, leaving memorisation during fine-tuning, especially for domain adaptation and instruction tuning, poorly understood. We fine-tune Pythia, Llama3, and Mistral models spanning 1.4B-70B parameters on common evaluation datasets and track verbatim memorisation throughout training. We find that memorisation increases dramatically in the first few epochs, often significantly before either validation perplexity or evaluation performance is optimised. We use a simple but effective n-gram memorisation score which reliably precedes verbatim memorisation; using it as an early-stopping criterion mitigates memorisation with minimal performance loss. Further, we introduce an n-gram-aware loss regulariser and show that it reduces memorisation across all model families tested by up to 40% while minimising evaluation performance trade-offs when compared to an existing memorisation mitigation strategy. These results yield practical, scalable insights into memorisation dynamics during language model fine-tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11372","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.956032","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Dean L. Slack, Noura Al Moubayed","raw_content_length":1237,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["Mistral"],"persons":[],"locations":["Pythia"],"monetary":[]},"char_count":1236,"language_detected":"en","key_concepts":{"key_phrases":["Early Detection","Reduction","Memorisation","Domain Adaptation","Instruction Tuning","arXiv251011372v1 Announce Type","new Abstract","large language models","many tasks","training data"],"filter_categories":{"ai_ml":["Domain Adaptation","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Early Detection":2.0,"Reduction":2.0,"Memorisation":2.0,"Domain Adaptation":2.0,"Instruction Tuning":2.0,"arXiv251011372v1 Announce Type":1.0,"new Abstract":1.0,"large language models":1.0,"many tasks":1.0,"training data":1.0}},"age_hours":2.7585998891666668,"is_recent":true,"quality_score":1.0,"sentiment_score":6.14,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.228,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7896,"joy":0.0029,"surprise":0.0192,"sadness":0.0369,"fear":0.0141,"anger":0.053,"disgust":0.0842},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on mitigating memorization in large language models during fine-tuning, which could indirectly reduce energy consumption by allowing for smaller, more efficient models. The study uses n-gram memorization scores and loss regularizers to reduce memorization by up to 40% with minimal performance loss. This is currently in the applied research phase, with no deployed technology or customer contracts.","key_impact_metrics":["Memorisation reduction by up to 40%"],"technology_tags":["Large Language Models","Fine-tuning","Memorisation Mitigation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:59:29.656370Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6752565d571a","title":"MaterialRefGS: Reflective Gaussian Splatting with Multi","content":"arXiv:2510.11387v1 Announce Type: new Abstract: Modeling reflections from 2D images is essential for photorealistic rendering and novel view synthesis. Recent approaches enhance Gaussian primitives with reflection-related material attributes to enable physically based rendering (PBR) with Gaussian Splatting. However, the material inference often lacks sufficient constraints, especially under limited environment modeling, resulting in illumination aliasing and reduced generalization. In this work, we revisit the problem from a multi-view perspective and show that multi-view consistent material inference with more physically-based environment modeling is key to learning accurate reflections with Gaussian Splatting. To this end, we enforce 2D Gaussians to produce multi-view consistent material maps during deferred shading. We also track photometric variations across views to identify highly reflective regions, which serve as strong priors for reflection strength terms. To handle indirect illumination caused by inter-object occlusions, we further introduce an environment modeling strategy through ray tracing with 2DGS, enabling photorealistic rendering of indirect radiance. Experiments on widely used benchmarks show that our method faithfully recovers both illumination and geometry, achieving state-of-the-art rendering quality in novel views synthesis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11387","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.957745","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Wenyuan Zhang, Jimin Tang, Weiqi Zhang, Yi Fang, Yu-Shen Liu, Zhizhong Han","raw_content_length":1371,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Multi arXiv:2510.11387v1 Announce Type","PBR"],"persons":["Gaussian","Gaussian Splatting"],"locations":[],"monetary":[]},"char_count":1370,"language_detected":"en","key_concepts":{"key_phrases":["MaterialRefGS","Multi","arXiv251011387v1 Announce Type","new Abstract","Modeling reflections","2D images","photorealistic rendering","novel view synthesis","Recent approaches","Gaussian primitives"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MaterialRefGS":2.0,"Multi":2.0,"arXiv251011387v1 Announce Type":1.0,"new Abstract":1.0,"Modeling reflections":1.0,"2D images":1.0,"photorealistic rendering":1.0,"novel view synthesis":1.0,"Recent approaches":1.0,"Gaussian primitives":1.0}},"age_hours":2.758656459444444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.157,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0314,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8687,"joy":0.029,"surprise":0.0631,"sadness":0.0102,"fear":0.007,"anger":0.0136,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for rendering reflections in 3D models, potentially leading to more efficient design and visualization. However, it's currently in the research phase with no deployed applications or quantified environmental benefits. The technical credibility is moderate due to the peer-reviewed nature of the publication, but economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["Gaussian Splatting","Photorealistic Rendering","Novel View Synthesis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:59:44.989085Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_133cb72157ed","title":"Beyond Survival: Evaluating LLMs in Social Deduction Games with Human","content":"arXiv:2510.11389v1 Announce Type: new Abstract: Social deduction games like Werewolf combine language, reasoning, and strategy, providing a testbed for studying natural language and social intelligence. However, most studies reduce the game to LLM-based self-play, yielding templated utterances and anecdotal cases that overlook the richness of social gameplay. Evaluation further relies on coarse metrics such as survival time or subjective scoring due to the lack of quality reference data. To address these gaps, we curate a high-quality, human-verified multimodal Werewolf dataset containing over 100 hours of video, 32.4M utterance tokens, and 15 rule variants. Based on this dataset, we propose a novel strategy-alignment evaluation that leverages the winning faction's strategies as ground truth in two stages: 1) Speech evaluation, formulated as multiple-choice-style tasks that assess whether the model can adopt appropriate stances across five dimensions of social ability; and 2) Decision evaluation, which assesses the model's voting choices and opponent-role inferences. This framework enables a fine-grained evaluation of models' linguistic and reasoning capabilities, while capturing their ability to generate strategically coherent gameplay. Our experiments show that state-of-the-art LLMs show diverse performance, with roughly half remain below 0.50, revealing clear gaps in deception and counterfactual reasoning. We hope our dataset further inspires research on language, reasoning, and strategy in multi-agent interaction.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11389","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.958569","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Zirui Song, Yuan Huang, Junchang Liu, Haozhe Luo, Chenxi Wang, Lang Gao, Zixiang Xu, Mingfei Han, Xiaojun Chang, Xiuying Chen","raw_content_length":1544,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Social Deduction Games","LLM"],"persons":[],"locations":["Werewolf"],"monetary":[]},"char_count":1543,"language_detected":"en","key_concepts":{"key_phrases":["Survival","LLMs","Social Deduction Games","Human","arXiv251011389v1 Announce Type","new Abstract","Social deduction games","Werewolf","language","reasoning"],"filter_categories":{"ai_ml":["LLMs","language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Survival":2.0,"LLMs":2.0,"Social Deduction Games":2.0,"Human":2.0,"arXiv251011389v1 Announce Type":1.0,"new Abstract":1.0,"Social deduction games":1.0,"Werewolf":1.0,"language":1.0,"reasoning":1.0}},"age_hours":2.7586855666666668,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9433,"joy":0.0067,"surprise":0.0194,"sadness":0.0059,"fear":0.0049,"anger":0.0078,"disgust":0.012},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on evaluating LLMs using a curated dataset. While it doesn't directly address climate change, the development of AI for social interaction could potentially be applied to sustainability challenges in the future, but this is highly speculative. The article presents a dataset and evaluation framework, but no deployed technology or measured outcomes related to sustainability are presented.","key_impact_metrics":["32.4M utterance tokens","100 hours of video"],"technology_tags":["Large Language Models","Social Deduction Games","AI Evaluation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:59:50.243861Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_713f033bee87","title":"Medical Interpretability and Knowledge Maps of Large Language Models","content":"arXiv:2510.11390v1 Announce Type: new Abstract: We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama3.3-70B, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11390","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.958980","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Razvan Marinescu, Victoria-Elisabeth Gruber, Diego Fajardo","raw_content_length":1438,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Medical Interpretability"],"persons":[],"locations":[],"monetary":[]},"char_count":1437,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Medical Interpretability","Knowledge Maps","Announce Type","new Abstract","a systematic study","medical-domain interpretability","LLMs","the LLMs","medical knowledge"],"filter_categories":{"ai_ml":["Large Language Models"],"research_academic":["a systematic study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"Medical Interpretability":2.0,"Knowledge Maps":2.0,"Announce Type":1.0,"new Abstract":1.0,"a systematic study":1.0,"medical-domain interpretability":1.0,"LLMs":1.0,"the LLMs":1.0,"medical knowledge":1.0}},"age_hours":2.758701578611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8755,"joy":0.0449,"surprise":0.0306,"sadness":0.0075,"fear":0.0101,"anger":0.0199,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the interpretability of LLMs in the medical domain. While it doesn't directly address climate change, it could indirectly contribute by improving the efficiency and accuracy of medical AI, potentially leading to better resource allocation in healthcare, but this is highly speculative and indirect. The research is at a basic research stage with no deployment or measurable outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Large Language Models","Medical AI","Interpretability"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:59:56.979942Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_898e048b6f03","title":"DocReward: A Document Reward Model for Structuring and Stylizing","content":"arXiv:2510.11391v1 Announce Type: new Abstract: Recent advances in agentic workflows have enabled the automation of tasks such as professional document generation. However, they primarily focus on textual quality, neglecting visual structure and style, which are crucial for readability and engagement. This gap arises mainly from the absence of suitable reward models to guide agentic workflows toward producing documents with stronger structural and stylistic quality. To address this, we propose DocReward, a document reward model that evaluates documents based on their structure and style. We construct a multi-domain dataset DocPair of 117K paired documents, covering 32 domains and 267 document types, each including a high- and low-professionalism document with identical content but different structure and style. This enables the model to evaluate professionalism comprehensively, and in a textual-quality-agnostic way. DocReward is trained using the Bradley-Terry loss to score documents, penalizing predictions that contradict the annotated ranking. To assess the performance of reward models, we create a test dataset containing document bundles ranked by well-educated human evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6 and 19.4 percentage points, respectively, demonstrating its superiority over baselines. In an extrinsic evaluation of document generation, DocReward achieves a significantly higher win rate of 60.8%, compared to GPT-5's 37.7% win rate, demonstrating its utility in guiding generation agents toward producing human-preferred documents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11391","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.959393","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Junpeng Liu, Yuzhong Zhao, Bowen Cao, Jiayu Ding, Yilin Jia, Tengchao Lv, Yupan Huang, Shaohan Huang, Nan Yang, Li Dong, Lei Cui, Tao Ge, Xun Wang, Huitian Jiao, Sun Mao, FNU Kartik, Si-Qing Chen, Wai Lam, Furu Wei","raw_content_length":1604,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["DocReward","DocPair"],"persons":[],"locations":[],"monetary":[]},"char_count":1603,"language_detected":"en","key_concepts":{"key_phrases":["DocReward","A Document Reward Model","Structuring","Stylizing","agentic workflows","arXiv251011391v1 Announce Type","new Abstract","Recent advances","the automation","tasks"],"filter_categories":{"engineering":["the automation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DocReward":2.0,"A Document Reward Model":2.0,"Structuring":2.0,"Stylizing":2.0,"agentic workflows":2.0,"arXiv251011391v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"the automation":1.0,"tasks":1.0}},"age_hours":2.758716058888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8725,"joy":0.0157,"surprise":0.0587,"sadness":0.014,"fear":0.0081,"anger":0.0208,"disgust":0.0101},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel reward model (DocReward) for improving the structure and style of automatically generated documents. While it demonstrates improved performance over GPT models (30.6% and 19.4% accuracy improvement over GPT-4o and GPT-5 respectively), it is still in the research phase with no real-world deployment or quantifiable environmental impact. The dataset creation and model training are concrete actions, but the overall impact on sustainability is indirect and theoretical at this stage.","key_impact_metrics":["30.6% accuracy improvement over GPT-4o","19.4% accuracy improvement over GPT-5"],"technology_tags":["Reward Model","Document Generation","AI"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:02.729626Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1816d4c3c36f","title":"VeriCite: Towards Reliable Citations in Retrieval","content":"arXiv:2510.11394v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for enhancing the responses of large language models (LLMs) with external knowledge sources. Despite the impressive performance in complex question-answering tasks, RAG still struggles with hallucinations. Attributing RAG-generated content through in-line citations has demonstrated potential in reducing hallucinations and facilitating human verification. Existing citation generation methods primarily rely on either fine-tuning the generator or employing post-processing approaches for citation matching. However, the former approach demands substantial annotated data and computational resources, while the latter often encounters difficulties in managing multiple citations and frequently produces suboptimal results. In this paper, we introduce a novel framework, called VeriCite, designed to rigorously validate supporting evidence and enhance answer attribution. Specifically, VeriCite breaks down into a three-stage generation: 1) The initial answer generation first generates a response based on all available contexts and has its claims verified through the NLI model; 2) the supporting evidence selection assesses the utility of each document and extracts useful supporting evidences; 3) the final answer refinement integrates the initial response and collected evidences to produce the final, refined answer.We conduct experiments across five open-source LLMs and four datasets, demonstrating that VeriCite can significantly improve citation quality while maintaining the correctness of the answers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11394","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.960216","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Haosheng Qian, Yixing Fan, Jiafeng Guo, Ruqing Zhang, Qi Chen, Dawei Yin, Xueqi Cheng","raw_content_length":1632,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Retrieval-Augmented Generation (RAG"],"persons":["RAG","RAG-"],"locations":[],"monetary":[]},"char_count":1631,"language_detected":"en","key_concepts":{"key_phrases":["VeriCite","Reliable Citations","Retrieval","RAG","hallucinations","arXiv251011394v1 Announce Type","new Abstract","Retrieval-Augmented Generation","a crucial approach","the responses"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VeriCite":2.0,"Reliable Citations":2.0,"Retrieval":2.0,"RAG":2.0,"hallucinations":2.0,"arXiv251011394v1 Announce Type":1.0,"new Abstract":1.0,"Retrieval-Augmented Generation":1.0,"a crucial approach":1.0,"the responses":1.0}},"age_hours":2.7587433,"is_recent":true,"quality_score":1.0,"sentiment_score":1.814,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6372,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9011,"joy":0.0231,"surprise":0.0319,"sadness":0.0061,"fear":0.0157,"anger":0.013,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (VeriCite) to improve citation quality in Retrieval-Augmented Generation (RAG) systems. The concrete action is the development of a three-stage generation process to validate supporting evidence and enhance answer attribution. The claims are supported by experiments across five open-source LLMs and four datasets, but it is still in the applied research stage with no real-world deployment.","key_impact_metrics":["Improved citation quality","Maintained answer correctness"],"technology_tags":["Large Language Models","Retrieval-Augmented Generation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:06.561247Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_515fb519009c","title":"FedHybrid: Breaking the Memory Wall of Federated Learning via Hybrid Tensor Management","content":"arXiv:2510.11400v1 Announce Type: new Abstract: Federated Learning (FL) emerges as a new learning paradigm that enables multiple devices to collaboratively train a shared model while preserving data privacy. However, one fundamental and prevailing challenge that hinders the deployment of FL on mobile devices is the memory limitation. This paper proposes \\textit{FedHybrid}, a novel framework that effectively reduces the memory footprint during the training process while guaranteeing the model accuracy and the overall training progress. Specifically, \\textit{FedHybrid} first selects the participating devices for each training round by jointly evaluating their memory budget, computing capability, and data diversity. After that, it judiciously analyzes the computational graph and generates an execution plan for each selected client in order to meet the corresponding memory budget while minimizing the training delay through employing a hybrid of recomputation and compression techniques according to the characteristic of each tensor. During the local training process, \\textit{FedHybrid} carries out the execution plan with a well-designed activation compression technique to effectively achieve memory reduction with minimum accuracy loss. We conduct extensive experiments to evaluate \\textit{FedHybrid} on both simulation and off-the-shelf mobile devices. The experiment results demonstrate that \\textit{FedHybrid} achieves up to a 39.1\\% increase in model accuracy and a 15.5$\\times$ reduction in wall clock time under various memory budgets compared with the baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11400","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.965819","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Kahou Tam, Chunlin Tian, Li Li, Haikai Zhao, ChengZhong Xu","raw_content_length":1584,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["FedHybrid","Hybrid Tensor Management","Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1583,"language_detected":"en","key_concepts":{"key_phrases":["Federated Learning","FedHybrid","the Memory Wall","Hybrid Tensor Management","arXiv251011400v1 Announce Type","new Abstract","a new learning paradigm","multiple devices","a shared model","data privacy"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Federated Learning":3.0,"FedHybrid":2.0,"the Memory Wall":2.0,"Hybrid Tensor Management":2.0,"arXiv251011400v1 Announce Type":1.0,"new Abstract":1.0,"a new learning paradigm":1.0,"multiple devices":1.0,"a shared model":1.0,"data privacy":1.0}},"age_hours":2.7587681925,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8726,"joy":0.015,"surprise":0.0389,"sadness":0.012,"fear":0.0211,"anger":0.0275,"disgust":0.0128},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework, FedHybrid, to reduce the memory footprint of federated learning on mobile devices. While it shows promising results in simulations and on off-the-shelf mobile devices, achieving up to a 39.1% increase in model accuracy and a 15.5x reduction in wall clock time, it remains in the applied research stage with no real-world deployments. The reduction in energy consumption from more efficient training is the primary climate impact, but it is not directly quantified in terms of GHG emissions reduction.","key_impact_metrics":["39.1% increase in model accuracy","15.5x reduction in wall clock time"],"technology_tags":["Federated Learning","Memory Optimization","Edge Computing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:12.243036Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a4e7a26defab","title":"On Inherited Popularity Bias in Cold","content":"arXiv:2510.11402v1 Announce Type: new Abstract: Collaborative filtering (CF) recommender systems struggle with making predictions on unseen, or 'cold', items. Systems designed to address this challenge are often trained with supervision from warm CF models in order to leverage collaborative and content information from the available interaction data. However, since they learn to replicate the behavior of CF methods, cold-start models may therefore also learn to imitate their predictive biases. In this paper, we show that cold-start systems can inherit popularity bias, a common cause of recommender system unfairness arising when CF models overfit to more popular items, thereby maximizing user-oriented accuracy but neglecting rarer items. We demonstrate that cold-start recommenders not only mirror the popularity biases of warm models, but are in fact affected more severely: because they cannot infer popularity from interaction data, they instead attempt to estimate it based solely on content features. This leads to significant over-prediction of certain cold items with similar content to popular warm items, even if their ground truth popularity is very low. Through experiments on three multimedia datasets, we analyze the impact of this behavior on three generative cold-start methods. We then describe a simple post-processing bias mitigation method that, by using embedding magnitude as a proxy for predicted popularity, can produce more balanced recommendations with limited harm to user-oriented cold-start accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11402","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.966706","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Gregor Meehan, Johan Pauwels","raw_content_length":1538,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1537,"language_detected":"en","key_concepts":{"key_phrases":["Inherited Popularity Bias","Cold","arXiv251011402v1 Announce Type","new Abstract","Collaborative filtering","CF recommender systems","predictions","Systems","this challenge","supervision"],"filter_categories":{"engineering":["Systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Inherited Popularity Bias":2.0,"Cold":2.0,"arXiv251011402v1 Announce Type":1.0,"new Abstract":1.0,"Collaborative filtering":1.0,"CF recommender systems":1.0,"predictions":1.0,"Systems":1.0,"this challenge":1.0,"supervision":1.0}},"age_hours":2.758797222777778,"is_recent":true,"quality_score":0.7,"sentiment_score":6.985,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.397,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8357,"joy":0.0057,"surprise":0.0085,"sadness":0.01,"fear":0.0849,"anger":0.0331,"disgust":0.0222},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper identifies and analyzes popularity bias in cold-start recommender systems, demonstrating that these systems can exacerbate existing biases. The research uses experiments on three multimedia datasets and proposes a post-processing bias mitigation method. While it doesn't directly address climate change, it highlights fairness issues within AI systems that could indirectly impact resource allocation or access to information related to sustainability.","key_impact_metrics":["Over-prediction of certain cold items with similar content to popular warm items","Impact on user-oriented cold-start accuracy"],"technology_tags":["Collaborative filtering","Recommender systems","Bias mitigation","Machine Learning"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T12:00:16.119652Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6aac0dc26cae","title":"KnowRL: Teaching Language Models to Know What They Know","content":"arXiv:2510.11407v1 Announce Type: new Abstract: Truly reliable AI requires more than simply scaling up knowledge; it demands the ability to know what it knows and when it does not. Yet recent research shows that even the best LLMs misjudge their own competence in more than one in five cases, making any response born of such internal uncertainty impossible to fully trust. Inspired by self-improvement reinforcement learning techniques that require minimal data, we present a simple but powerful framework KnowRL that strengthens a model's internal understanding of its own feasibility boundaries, enabling safer and more responsible behaviour. Our framework combines two components: (i) introspection, where the model generates and classifies tasks it judges feasible or infeasible, and (ii) consensus-based rewarding, where stability of self-knowledge assessment is reinforced through internal agreement. By using internally generated data, this design strengthens consistency in self-knowledge and entirely avoids costly external supervision. In experiments on LLaMA-3.1-8B and Qwen-2.5-7B, KnowRL steadily improved self-knowledge, validated by both intrinsic self-consistency and extrinsic benchmarking. With nothing more than a small seed set and no external supervision, our method drove gains as high as 28% in accuracy and 12% in F1, outperforming baselines in just a few iterations. Our framework essentially unlocks the untapped capacity of LLMs to self-improve their knowledge awareness, opening the door to reliable, more accountable AI and safer deployment in critical applications. Owing to its simplicity and independence from external effort, we encourage applying this reliability-enhancing process to all future models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11407","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.967555","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Sahil Kale, Devendra Singh Dhami","raw_content_length":1739,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1738,"language_detected":"en","key_concepts":{"key_phrases":["KnowRL","Language Models","What","arXiv251011407v1 Announce Type","new Abstract","knowledge","the ability","what","recent research","even the best LLMs"],"filter_categories":{"research_academic":["recent research"],"ai_ml":["even the best LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"KnowRL":2.0,"Language Models":2.0,"What":2.0,"arXiv251011407v1 Announce Type":1.0,"new Abstract":1.0,"knowledge":1.0,"the ability":1.0,"what":1.0,"recent research":1.0,"even the best LLMs":1.0}},"age_hours":2.758826749166667,"is_recent":true,"quality_score":0.7,"sentiment_score":9.667,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9334,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6772,"joy":0.0047,"surprise":0.0495,"sadness":0.0118,"fear":0.203,"anger":0.0376,"disgust":0.0162},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (KnowRL) to improve LLM self-knowledge, validated by intrinsic self-consistency and extrinsic benchmarking. The concrete action is the development and testing of this framework on LLaMA-3.1-8B and Qwen-2.5-7B. Evidence includes accuracy gains as high as 28% and F1 score improvements of 12%. It's in the applied research stage, with no indication of real-world deployment.","key_impact_metrics":["accuracy gains 28%","F1 score improvements 12%"],"technology_tags":["LLM","Reinforcement Learning","AI Safety"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:19.752168Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_297c9cfbac86","title":"Leveraging LLMs for Semi","content":"arXiv:2510.11409v1 Announce Type: new Abstract: The creation of systematic literature reviews (SLR) is critical for analyzing the landscape of a research field and guiding future research directions. However, retrieving and filtering the literature corpus for an SLR is highly time-consuming and requires extensive manual effort, as keyword-based searches in digital libraries often return numerous irrelevant publications. In this work, we propose a pipeline leveraging multiple large language models (LLMs), classifying papers based on descriptive prompts and deciding jointly using a consensus scheme. The entire process is human-supervised and interactively controlled via our open-source visual analytics web interface, LLMSurver, which enables real-time inspection and modification of model outputs. We evaluate our approach using ground-truth data from a recent SLR comprising over 8,000 candidate papers, benchmarking both open and commercial state-of-the-art LLMs from mid-2024 and fall 2025. Results demonstrate that our pipeline significantly reduces manual effort while achieving lower error rates than single human annotators. Furthermore, modern open-source models prove sufficient for this task, making the method accessible and cost-effective. Overall, our work demonstrates how responsible human-AI collaboration can accelerate and enhance systematic literature reviews within academic workflows.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11409","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.968369","language":"en","tags":["computer-science","cslg","csdl","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Lucas Joos, Daniel A. Keim, Maximilian T. Fischer","raw_content_length":1414,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["SLR","LLMSurver"],"persons":[],"locations":[],"monetary":[]},"char_count":1413,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Semi","Announce Type","new Abstract","The creation","systematic literature reviews","SLR","the landscape","a research field","future research directions"],"filter_categories":{"ai_ml":["LLMs"],"research_academic":["a research field","future research directions"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":2.0,"Semi":2.0,"Announce Type":1.0,"new Abstract":1.0,"The creation":1.0,"systematic literature reviews":1.0,"SLR":1.0,"the landscape":1.0,"a research field":1.0,"future research directions":1.0}},"age_hours":2.758857365,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8934,"joy":0.006,"surprise":0.0123,"sadness":0.0067,"fear":0.0349,"anger":0.0307,"disgust":0.016},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a pipeline using LLMs to improve the efficiency of systematic literature reviews. While this doesn't directly reduce GHG emissions, it has the potential to accelerate research in climate-related fields by reducing manual effort and improving accuracy. The pipeline is evaluated using ground-truth data and benchmarks LLMs, providing some evidence of its effectiveness, but it is still in the early stages of deployment.","key_impact_metrics":["Error rates lower than single human annotators","Reduction in manual effort"],"technology_tags":["Large Language Models","Literature Review Automation","AI-assisted research"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:22.860239Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e3dca9665234","title":"Autonomous vehicles need social awareness to find optima in multi","content":"arXiv:2510.11410v1 Announce Type: new Abstract: Previous work has shown that when multiple selfish Autonomous Vehicles (AVs) are introduced to future cities and start learning optimal routing strategies using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic systems, as they would require a significant amount of time to converge to the optimal solution, equivalent to years of real-world commuting. We demonstrate that moving beyond the selfish component in the reward significantly relieves this issue. If each AV, apart from minimizing its own travel time, aims to reduce its impact on the system, this will be beneficial not only for the system-wide performance but also for each individual player in this routing game. By introducing an intrinsic reward signal based on the marginal cost matrix, we significantly reduce training time and achieve convergence more reliably. Marginal cost quantifies the impact of each individual action (route-choice) on the system (total travel time). Including it as one of the components of the reward can reduce the degree of non-stationarity by aligning agents' objectives. Notably, the proposed counterfactual formulation preserves the system's equilibria and avoids oscillations. Our experiments show that training MARL algorithms with our novel reward formulation enables the agents to converge to the optimal solution, whereas the baseline algorithms fail to do so. We show these effects in both a toy network and the real-world network of Saint-Arnoult. Our results optimistically indicate that social awareness (i.e., including marginal costs in routing decisions) improves both the system-wide and individual performance of future urban systems with AVs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11410","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.968819","language":"en","tags":["csma","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Anastasia Psarou, {\\L}ukasz Gorczyca, Dominik Gawe{\\l}, Rafa{\\l} Kucharski","raw_content_length":1733,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Autonomous Vehicles","Multi-Agent Reinforcement Learning"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1726,"language_detected":"en","key_concepts":{"key_phrases":["Autonomous vehicles","social awareness","optima","multi","arXiv251011410v1 Announce Type","new Abstract","Previous work","multiple selfish Autonomous Vehicles","AVs","future cities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Autonomous vehicles":2.0,"social awareness":2.0,"optima":2.0,"multi":2.0,"arXiv251011410v1 Announce Type":1.0,"new Abstract":1.0,"Previous work":1.0,"multiple selfish Autonomous Vehicles":1.0,"AVs":1.0,"future cities":1.0}},"age_hours":2.7588726805555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5307,"joy":0.0265,"surprise":0.047,"sadness":0.0208,"fear":0.2326,"anger":0.1162,"disgust":0.0262},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel reward formulation for multi-agent reinforcement learning in autonomous vehicles that reduces training time and improves system-wide performance. The research is validated through experiments on a toy network and a real-world network, showing convergence to optimal solutions. However, it is still in the applied research stage with no deployed units or customer contracts.","key_impact_metrics":["Reduced training time","Convergence to optimal solution"],"technology_tags":["Autonomous Vehicles","Multi-Agent Reinforcement Learning","Traffic Optimization"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:00:27.931732Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_96ead5e2f99f","title":"Robust Ego","content":"arXiv:2510.11417v1 Announce Type: new Abstract: Establishing object-level correspondence between egocentric and exocentric views is essential for intelligent assistants to deliver precise and intuitive visual guidance. However, this task faces numerous challenges, including extreme viewpoint variations, occlusions, and the presence of small objects. Existing approaches usually borrow solutions from video object segmentation models, but still suffer from the aforementioned challenges. Recently, the Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities and excellent performance in video object segmentation. Yet, when simply applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe difficulties due to ineffective ego-exo feature fusion and limited long-term memory capacity, especially for long videos. Addressing these problems, we propose a novel EEC framework based on SAM 2 with long-term memories by presenting a dual-memory architecture and an adaptive feature routing module inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features (i) a Memory-View MoE module which consists of a dual-branch routing mechanism to adaptively assign contribution weights to each expert feature along both channel and spatial dimensions, and (ii) a dual-memory bank system with a simple yet effective compression strategy to retain critical long-term information while eliminating redundancy. In the extensive experiments on the challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new state-of-the-art results and significantly outperforms existing methods and the SAM 2 baseline, showcasing its strong generalization across diverse scenarios. Our code and model are available at https://github.com/juneyeeHu/LM-EEC.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11417","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.970926","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Yijun Hu, Bing Fan, Xin Gu, Haiqing Ren, Dongfang Liu, Heng Fan, Libo Zhang","raw_content_length":1790,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["EEC"],"persons":["SAM 2"],"locations":[],"monetary":[]},"char_count":1789,"language_detected":"en","key_concepts":{"key_phrases":["Robust Ego","arXiv251011417v1 Announce Type","new Abstract","object-level correspondence","egocentric and exocentric views","intelligent assistants","precise and intuitive visual guidance","this task","numerous challenges","extreme viewpoint variations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Ego":2.0,"arXiv251011417v1 Announce Type":1.0,"new Abstract":1.0,"object-level correspondence":1.0,"egocentric and exocentric views":1.0,"intelligent assistants":1.0,"precise and intuitive visual guidance":1.0,"this task":1.0,"numerous challenges":1.0,"extreme viewpoint variations":1.0}},"age_hours":2.7589401925,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7747,"joy":0.0098,"surprise":0.0315,"sadness":0.1083,"fear":0.0488,"anger":0.0147,"disgust":0.0122},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (LM-EEC) for improving object-level correspondence between egocentric and exocentric views using SAM 2. The concrete action is the development of a dual-memory architecture and adaptive feature routing module. The evidence supporting the claims is the reported state-of-the-art results on the EgoExo4D benchmark, but it is still in the applied research stage with no real-world deployments.","key_impact_metrics":["State-of-the-art results on EgoExo4D benchmark","Significant outperformance of SAM 2 baseline"],"technology_tags":["Computer Vision","Ego-Exo Correspondence","Segment Anything Model","Long-Term Memory Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:00:31.135543Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90891de3c350","title":"Forward","content":"arXiv:2510.11418v1 Announce Type: new Abstract: The application of deep learning to the area of communications systems has been a growing field of interest in recent years. Forward-forward (FF) learning is an efficient alternative to the backpropagation (BP) algorithm, which is the typically used training procedure for neural networks. Among its several advantages, FF learning does not require the communication channel to be differentiable and does not rely on the global availability of partial derivatives, allowing for an energy-efficient implementation. In this work, we design end-to-end learned autoencoders using the FF algorithm and numerically evaluate their performance for the additive white Gaussian noise and Rayleigh block fading channels. We demonstrate their competitiveness with BP-trained systems in the case of joint coding and modulation, and in a scenario where a fixed, non-differentiable modulation stage is applied. Moreover, we provide further insights into the design principles of the FF network, its training convergence behavior, and significant memory and processing time savings compared to BP-based approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11418","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.971441","language":"en","tags":["computer-science","cslg","preprints","mathit","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Daniel Seifert, Onur G\\\"unl\\\"u, Rafael F. Schaefer","raw_content_length":1147,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Rayleigh"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1146,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011418v1 Announce Type","new Abstract","The application","deep learning","the area","communications systems","a growing field","interest","recent years","Forward-forward FF learning"],"filter_categories":{"ai_ml":["deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011418v1 Announce Type":1.0,"new Abstract":1.0,"The application":1.0,"deep learning":1.0,"the area":1.0,"communications systems":1.0,"a growing field":1.0,"interest":1.0,"recent years":1.0,"Forward-forward FF learning":1.0}},"age_hours":2.758954829722222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.553,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8963,"joy":0.0229,"surprise":0.0509,"sadness":0.0038,"fear":0.0054,"anger":0.0139,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel deep learning approach (Forward-Forward learning) for communication systems that claims to be more energy-efficient than backpropagation. While it demonstrates competitiveness with existing systems and provides insights into design principles and performance, it's still in the numerical evaluation stage, lacking real-world deployment and validation. The potential for energy savings in communication systems could have a modest climate impact, but this is theoretical at this stage.","key_impact_metrics":["Memory savings compared to BP","Processing time savings compared to BP"],"technology_tags":["Deep Learning","Forward-Forward Learning","Autoencoders","Communication Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:00:34.563475Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_14f87c2761b1","title":"A Modular AIoT Framework for Low","content":"arXiv:2510.11421v1 Announce Type: new Abstract: This paper presents an AI-driven IoT robotic teleoperation system designed for real-time remote manipulation and intelligent visual monitoring, tailored for smart city applications. The architecture integrates a Flutter-based cross-platform mobile interface with MQTT-based control signaling and WebRTC video streaming via the LiveKit framework. A YOLOv11-nano model is deployed for lightweight object detection, enabling real-time perception with annotated visual overlays delivered to the user interface. Control commands are transmitted via MQTT to an ESP8266-based actuator node, which coordinates multi-axis robotic arm motion through an Arduino Mega2560 controller. The backend infrastructure is hosted on DigitalOcean, ensuring scalable cloud orchestration and stable global communication. Latency evaluations conducted under both local and international VPN scenarios (including Hong Kong, Japan, and Belgium) demonstrate actuator response times as low as 0.2 seconds and total video latency under 1.2 seconds, even across high-latency networks. This low-latency dual-protocol design ensures responsive closed-loop interaction and robust performance in distributed environments. Unlike conventional teleoperation platforms, the proposed system emphasizes modular deployment, real-time AI sensing, and adaptable communication strategies, making it well-suited for smart city scenarios such as remote infrastructure inspection, public equipment servicing, and urban automation. Future enhancements will focus on edge-device deployment, adaptive routing, and integration with city-scale IoT networks to enhance resilience and scalability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11421","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.972668","language":"en","tags":["computer-science","preprints","cshc","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Shih-Chieh Sun, Yun-Cheng Tsai","raw_content_length":1692,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["MQTT","Arduino","node","LiveKit","IoT"],"persons":[],"locations":["Hong Kong","WebRTC","Japan","Belgium"],"monetary":[]},"char_count":1691,"language_detected":"en","key_concepts":{"key_phrases":["A Modular AIoT Framework","Low","arXiv251011421v1 Announce Type","new Abstract","This paper","an AI-driven IoT robotic teleoperation system","real-time remote manipulation","intelligent visual monitoring","smart city applications","The architecture"],"filter_categories":{"ai_ml":["A Modular AIoT Framework"],"engineering":["A Modular AIoT Framework","an AI-driven IoT robotic teleoperation system"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Modular AIoT Framework":2.0,"Low":2.0,"arXiv251011421v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"an AI-driven IoT robotic teleoperation system":1.0,"real-time remote manipulation":1.0,"intelligent visual monitoring":1.0,"smart city applications":1.0,"The architecture":1.0}},"age_hours":2.758998685,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9008,"joy":0.0269,"surprise":0.0512,"sadness":0.005,"fear":0.0051,"anger":0.0076,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":5,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AIoT robotic teleoperation system with measured latency under local and international VPN scenarios. This demonstrates a functional prototype, but lacks information on broader impact or economic viability. The system could contribute to smart city applications, but the scale of impact is unclear.","key_impact_metrics":["Actuator response times as low as 0.2 seconds","Total video latency under 1.2 seconds"],"technology_tags":["AIoT","Robotics","Teleoperation"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:00:37.401922Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_529db5bd687c","title":"Beyond the Crowd: LLM","content":"arXiv:2510.11423v1 Announce Type: new Abstract: Community Notes, the crowd-sourced misinformation governance system on X (formerly Twitter), enables users to flag misleading posts, attach contextual notes, and vote on their helpfulness. However, our analysis of 30.8K health-related notes reveals significant latency, with a median delay of 17.6 hours before the first note receives a helpfulness status. To improve responsiveness during real-world misinformation surges, we propose CrowdNotes+, a unified framework that leverages large language models (LLMs) to augment Community Notes for faster and more reliable health misinformation governance. CrowdNotes+ integrates two complementary modes: (1) evidence-grounded note augmentation and (2) utility-guided note automation, along with a hierarchical three-step evaluation that progressively assesses relevance, correctness, and helpfulness. We instantiate the framework through HealthNotes, a benchmark of 1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness judge. Experiments on fifteen LLMs reveal an overlooked loophole in current helpfulness evaluation, where stylistic fluency is mistaken for factual accuracy, and demonstrate that our hierarchical evaluation and LLM-augmented generation jointly enhance factual precision and evidence utility. These results point toward a hybrid human-AI governance model that improves both the rigor and timeliness of crowd-sourced fact-checking.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11423","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.973062","language":"en","tags":["computer-science","preprints","cscl","research","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Jiaying Wu, Zihang Fu, Haonan Wang, Fanxiao Li, Min-Yen Kan","raw_content_length":1467,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["CrowdNotes+","HealthNotes"],"persons":["CrowdNotes+","Twitter"],"locations":[],"monetary":[]},"char_count":1466,"language_detected":"en","key_concepts":{"key_phrases":["the Crowd","arXiv251011423v1 Announce Type","new Abstract","Community Notes","the crowd-sourced misinformation governance system","formerly Twitter","users","misleading posts","contextual notes","their helpfulness"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Crowd":2.0,"arXiv251011423v1 Announce Type":1.0,"new Abstract":1.0,"Community Notes":1.0,"the crowd-sourced misinformation governance system":1.0,"formerly Twitter":1.0,"users":1.0,"misleading posts":1.0,"contextual notes":1.0,"their helpfulness":1.0}},"age_hours":2.759014007222222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9395,"joy":0.0019,"surprise":0.0264,"sadness":0.0099,"fear":0.0063,"anger":0.011,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a framework (CrowdNotes+) to improve misinformation governance using LLMs. While it presents a benchmark (HealthNotes) and experimental results, it's still in the research stage with no real-world deployment. The impact on climate is indirect, potentially reducing the spread of misinformation about climate solutions, but this is theoretical.","key_impact_metrics":["Median delay reduction of 17.6 hours","1.2K helpfulness-annotated health notes"],"technology_tags":["Large Language Models","Misinformation Governance"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:00:40.405781Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be7f4a84101b","title":"Who are you, ChatGPT? Personality and Demographic Style in LLM","content":"arXiv:2510.11434v1 Announce Type: new Abstract: Generative large language models (LLMs) have become central to everyday life, producing human-like text across diverse domains. A growing body of research investigates whether these models also exhibit personality- and demographic-like characteristics in their language. In this work, we introduce a novel, data-driven methodology for assessing LLM personality without relying on self-report questionnaires, applying instead automatic personality and gender classifiers to model replies on open-ended questions collected from Reddit. Comparing six widely used models to human-authored responses, we find that LLMs systematically express higher Agreeableness and lower Neuroticism, reflecting cooperative and stable conversational tendencies. Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation, echoing prior findings on automated agents. We contribute a new dataset of human and model responses, along with large-scale comparative analyses, shedding new light on the topic of personality and demographic patterns of generative AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11434","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.973436","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Dana Sotto Porat, Ella Rabinovich","raw_content_length":1140,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Agreeableness"],"persons":["Announce Type"],"locations":["Reddit"],"monetary":[]},"char_count":1139,"language_detected":"en","key_concepts":{"key_phrases":["Who","you","Personality and Demographic Style","LLM","arXiv251011434v1 Announce Type","new Abstract","Generative large language models","LLMs","everyday life","human-like text"],"filter_categories":{"ai_ml":["LLM","Generative large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Who":2.0,"you":2.0,"Personality and Demographic Style":2.0,"LLM":2.0,"arXiv251011434v1 Announce Type":1.0,"new Abstract":1.0,"Generative large language models":1.0,"LLMs":1.0,"everyday life":1.0,"human-like text":1.0}},"age_hours":2.7590287502777775,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8336,"joy":0.0154,"surprise":0.1312,"sadness":0.0029,"fear":0.0057,"anger":0.0083,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research analyzes LLM personality traits, finding that LLMs systematically express higher Agreeableness and lower Neuroticism. While the research is technically credible with a novel methodology and dataset, it's in the early stages and has minimal direct climate impact potential. The study provides metrics related to personality and gender classification of LLMs.","key_impact_metrics":["Higher Agreeableness","Lower Neuroticism"],"technology_tags":["Large Language Models","AI Personality Analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:00:43.404722Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13dee9697303","title":"What Generative Search Engines Like and How to Optimize Web Content Cooperatively","content":"arXiv:2510.11438v1 Announce Type: new Abstract: By employing large language models (LLMs) to retrieve documents and generate natural language responses, Generative Engines, such as Google AI overview and ChatGPT, provide significantly enhanced user experiences and have rapidly become the new form of search. Their rapid adoption also drives the needs of Generative Engine Optimization (GEO), as content providers are eager to gain more traction from them. In this paper, we introduce AutoGEO, a framework to automatically learn generative engine preferences when using retrieved contents for response generation, and rewrite web contents for more such traction. AutoGEO first prompts frontier LLMs to explain generative engine preferences and extract meaningful preference rules from these explanations. Then it uses preference rules as context engineering for AutoGEO$_\\text{API}$, a prompt-based GEO system, and as rule-based rewards to train AutoGEO$_\\text{Mini}$, a cost-effective GEO model. Experiments on the standard GEO-Bench and two newly constructed benchmarks using real user queries demonstrate the effectiveness of AutoGEO in enhancing content traction while preserving search utility. Analyses confirm the learned rules' robustness and abilities to capture unique preferences in variant domains, and AutoGEO systems' ability to embed them in content optimization. The code is released at https://github.com/cxcscmu/AutoGEO.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11438","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.973865","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Yujiang Wu, Shanshan Zhong, Yubin Kim, Chenyan Xiong","raw_content_length":1439,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Generative Engine Optimization","GEO","Google AI"],"persons":["AutoGEO$_\\text{API}$","Generative Engines"],"locations":[],"monetary":[]},"char_count":1438,"language_detected":"en","key_concepts":{"key_phrases":["What","Generative Search Engines","How to Optimize Web Content","arXiv251011438v1 Announce Type","new Abstract","large language models","LLMs","documents","natural language responses","Generative Engines"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Generative Search Engines":2.0,"How to Optimize Web Content":2.0,"arXiv251011438v1 Announce Type":1.0,"new Abstract":1.0,"large language models":1.0,"LLMs":1.0,"documents":1.0,"natural language responses":1.0,"Generative Engines":1.0}},"age_hours":2.759043828888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.531,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9062,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8411,"joy":0.0545,"surprise":0.0703,"sadness":0.0025,"fear":0.0098,"anger":0.0162,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (AutoGEO) for optimizing web content for generative search engines. While the framework is tested on benchmarks and shows effectiveness in enhancing content traction, it's still in the research phase with no real-world deployment or quantified environmental impact. The code is released, which increases transparency, but there are no specific metrics related to reduced energy consumption or other direct environmental benefits.","key_impact_metrics":["Content traction enhancement","Preference rule robustness"],"technology_tags":["Large Language Models","Generative Engine Optimization","Content Rewriting"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:00:46.844834Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2840e18fd212","title":"Reconstructing 12","content":"arXiv:2510.11442v1 Announce Type: new Abstract: Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for cardiac diagnosis, providing comprehensive spatial coverage of the heart necessary to detect conditions such as myocardial infarction (MI). However, their lack of portability limits continuous and large-scale use. Three-lead ECG systems are widely used in wearable devices due to their simplicity and mobility, but they often fail to capture pathologies in unmeasured regions. To address this, we propose WearECG, a Variational Autoencoder (VAE) method that reconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model includes architectural improvements to better capture temporal and spatial dependencies in ECG signals. We evaluate generation quality using MSE, MAE, and Frechet Inception Distance (FID), and assess clinical validity via a Turing test with expert cardiologists. To further validate diagnostic utility, we fine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label classification task involving over 40 cardiac conditions, including six different myocardial infarction locations, using both real and generated signals. Experiments on the MIMIC dataset show that our method produces physiologically realistic and diagnostically informative signals, with robust performance in downstream tasks. This work demonstrates the potential of generative modeling for ECG reconstruction and its implications for scalable, low-cost cardiac screening.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11442","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.974271","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Xinyan Guan, Yongfan Lai, Jiarui Jin, Jun Li, Haoyu Wang, Qinghao Zhao, Deyun Zhang, Shijia Geng, Shenda Hong","raw_content_length":1508,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["MAE","Turing","ECG","MSE","VAE","Frechet Inception Distance"],"persons":["a Variational Autoencoder"],"locations":[],"monetary":[]},"char_count":1507,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011442v1 Announce Type","new Abstract","Twelve-lead electrocardiograms","ECGs","the clinical gold standard","cardiac diagnosis","comprehensive spatial coverage","the heart","conditions","myocardial infarction"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011442v1 Announce Type":1.0,"new Abstract":1.0,"Twelve-lead electrocardiograms":1.0,"ECGs":1.0,"the clinical gold standard":1.0,"cardiac diagnosis":1.0,"comprehensive spatial coverage":1.0,"the heart":1.0,"conditions":1.0,"myocardial infarction":1.0}},"age_hours":2.7590593799999996,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8337,"joy":0.0053,"surprise":0.0418,"sadness":0.0623,"fear":0.0228,"anger":0.0175,"disgust":0.0165},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on reconstructing 12-lead ECGs from 3-lead ECGs using a VAE model. While the potential for scalable, low-cost cardiac screening exists, the current stage is applied research with validation on the MIMIC dataset. There are no deployed units or customer contracts, making it vaporware.","key_impact_metrics":["MSE","MAE","FID"],"technology_tags":["Variational Autoencoder","ECG reconstruction","Wearable devices"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:00:49.724284Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5a0866975ec0","title":"GenCNER: A Generative Framework for Continual Named Entity Recognition","content":"arXiv:2510.11444v1 Announce Type: new Abstract: Traditional named entity recognition (NER) aims to identify text mentions into pre-defined entity types. Continual Named Entity Recognition (CNER) is introduced since entity categories are continuously increasing in various real-world scenarios. However, existing continual learning (CL) methods for NER face challenges of catastrophic forgetting and semantic shift of non-entity type. In this paper, we propose GenCNER, a simple but effective Generative framework for CNER to mitigate the above drawbacks. Specifically, we skillfully convert the CNER task into sustained entity triplet sequence generation problem and utilize a powerful pre-trained seq2seq model to solve it. Additionally, we design a type-specific confidence-based pseudo labeling strategy along with knowledge distillation (KD) to preserve learned knowledge and alleviate the impact of label noise at the triplet level. Experimental results on two benchmark datasets show that our framework outperforms previous state-of-the-art methods in multiple CNER settings, and achieves the smallest gap compared with non-CL results.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11444","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.974674","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Yawen Yang, Fukun Ma, Shiao Meng, Aiwei Liu, Lijie Wen","raw_content_length":1142,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["NER"],"persons":["Entity Recognition"],"locations":["GenCNER"],"monetary":[]},"char_count":1141,"language_detected":"en","key_concepts":{"key_phrases":["GenCNER","Continual Named Entity Recognition","A Generative Framework","NER","arXiv251011444v1 Announce Type","new Abstract","Traditional","entity recognition","text mentions","pre-defined entity types"],"filter_categories":{"hydrogen_energy":["NER"],"renewable_energy":["NER"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GenCNER":3.0,"Continual Named Entity Recognition":3.0,"A Generative Framework":2.0,"NER":2.0,"arXiv251011444v1 Announce Type":1.0,"new Abstract":1.0,"Traditional":1.0,"entity recognition":1.0,"text mentions":1.0,"pre-defined entity types":1.0}},"age_hours":2.759074538611111,"is_recent":true,"quality_score":1.0,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4196,"joy":0.0105,"surprise":0.0288,"sadness":0.0192,"fear":0.492,"anger":0.0237,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for continual named entity recognition (CNER). The concrete action is the development of a new algorithm, GenCNER, and its evaluation on benchmark datasets. While the experimental results show improved performance, there's no direct link to sustainability or environmental impact. The technology is at an early stage of development with no deployment.","key_impact_metrics":["Smallest gap compared with non-CL results","Outperforms previous state-of-the-art methods"],"technology_tags":["Natural Language Processing","Continual Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:00:53.200166Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_55c3734b2639","title":"Repeated-and-Offset QPSK for DFT","content":"arXiv:2510.11445v1 Announce Type: new Abstract: Motivated by the convergence of terrestrial cellular networks with satellite networks, we consider an adaptation of offset quadrature phase shift keying (OQPSK), used with single-carrier waveform in traditional satellite systems, to discrete Fourier transform spread (DFT-s-) orthogonal frequency-division multiplexed (OFDM) waveform employed in the uplink of terrestrial systems. We introduce a new order-one constellation modulation, termed repeated-and-offset QPSK (RO-QPSK), derive its basic properties, and compare it with pi/2-BPSK with frequency-domain spectral shaping (FDSS), as supported in 5G. RO-QPSK naturally produces a Hann-window-shaped spectrum, resulting in a very low maximum peak-to-average power ratio (PAPR) on the order of 2 dB. Moreover, with single-tap equalization and symbol combining at the receiver, RO-QSPK can improve the signal-to-interference-plus-noise (SINR) compared to pi/2-BPSK with FDSS, in narrowband and/or moderately frequency-selective channels, as encountered in satellite communications. A moderate FDSS can also be combined with RO-QSPK to further reduce the PAPR while providing similar performance. Of independent interest, general SINR expressions for DFT-s-OFDM are also provided.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11445","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.975076","language":"en","tags":["eesssp","preprints","research","mathit","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Renaud-Alexandre Pitaval","raw_content_length":1279,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["DFT","QPSK","DFT arXiv:2510.11445v1 Announce Type","OFDM","RO-QPSK"],"persons":["Fourier"],"locations":[],"monetary":[]},"char_count":1278,"language_detected":"en","key_concepts":{"key_phrases":["Repeated-and-Offset QPSK","DFT","new Abstract","the convergence","terrestrial cellular networks","satellite networks","an adaptation","offset quadrature phase shift keying","OQPSK","single-carrier waveform"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Repeated-and-Offset QPSK":2.0,"DFT":2.0,"new Abstract":1.0,"the convergence":1.0,"terrestrial cellular networks":1.0,"satellite networks":1.0,"an adaptation":1.0,"offset quadrature phase shift keying":1.0,"OQPSK":1.0,"single-carrier waveform":1.0}},"age_hours":2.759091216666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8341,"joy":0.0384,"surprise":0.0937,"sadness":0.0048,"fear":0.0082,"anger":0.0163,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new modulation technique (RO-QPSK) for satellite and terrestrial networks, aiming to improve SINR and reduce PAPR. While it mentions a PAPR on the order of 2 dB, it's still in the research phase with no deployed units or real-world data to demonstrate concrete climate impact. The potential climate impact is indirect, through potentially more efficient data transmission, but is not quantified.","key_impact_metrics":["PAPR reduction of 2 dB"],"technology_tags":["RO-QPSK","DFT-s-OFDM","OQPSK"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:00:56.692767Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c02c1a2a093b","title":"Building and Evaluating a Realistic Virtual World for Large Scale Urban Exploration from 360{\\deg} Videos","content":"arXiv:2510.11447v1 Announce Type: new Abstract: We propose to build realistic virtual worlds, called 360RVW, for large urban environments directly from 360{\\deg} videos. We provide an interface for interactive exploration, where users can freely navigate via their own avatars. 360{\\deg} videos record the entire environment of the shooting location simultaneously leading to highly realistic and immersive representations. Our system uses 360{\\deg} videos recorded along streets and builds a 360RVW through four main operations: video segmentation by intersection detection, video completion to remove the videographer, semantic segmentation for virtual collision detection with the avatar, and projection onto a distorted sphere that moves along the camera trajectory following the avatar's movements. Our interface allows users to explore large urban environments by changing their walking direction at intersections or choosing a new location by clicking on a map. Even without a 3D model, the users can experience collision with buildings using metadata produced by semantic segmentation. Furthermore, we stream the 360{\\deg} videos so users can directly access 360RVW via their web browser. We fully evaluate our system, including a perceptual experiment comparing our approach to previous exploratory interfaces. The results confirm the quality of our system, especially regarding the presence of users and the interactive exploration, making it most suitable for a virtual tour of urban environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11447","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.975499","language":"en","tags":["preprints","research","computer-science","csmm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Mizuki Takenawa, Naoki Sugimoto, Leslie W\\\"ohler, Satoshi Ikehata, Kiyoharu Aizawa","raw_content_length":1509,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["360RVW","Evaluating a Realistic Virtual World","Videos arXiv:2510.11447v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1508,"language_detected":"en","key_concepts":{"key_phrases":["Building","a Realistic Virtual World","Large Scale Urban Exploration","Videos","arXiv251011447v1","Announce Type","new Abstract","realistic virtual worlds","large urban environments","videos"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Building":2.0,"a Realistic Virtual World":2.0,"Large Scale Urban Exploration":2.0,"Videos":2.0,"arXiv251011447v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"realistic virtual worlds":1.0,"large urban environments":1.0,"videos":1.0}},"age_hours":2.7591063583333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8503,"joy":0.074,"surprise":0.0521,"sadness":0.0031,"fear":0.0049,"anger":0.0116,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a system for creating virtual urban environments from 360 videos. While it could potentially reduce the need for physical travel and thus emissions, this is theoretical and not quantified. The system is in the early stages of development, with a perceptual experiment conducted, but no real-world deployment.","key_impact_metrics":["Perceptual experiment results"],"technology_tags":["360 video","virtual reality","semantic segmentation"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:00:59.245004Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d04f895ed5ad","title":"A Faster and More Reliable Middleware for Autonomous Driving Systems","content":"arXiv:2510.11448v1 Announce Type: new Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control loops and tightly bounded delays from perception to actuation. Many open-source autonomy systems rely on ROS 2 middleware; when multiple sensor and control nodes share one compute unit, ROS 2 and its DDS transports add significant (de)serialization, copying, and discovery overheads, shrinking the available time budget. We present Sensor-in-Memory (SIM), a shared-memory transport designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double buffers that overwrite old data to prioritize freshness, and integrates into ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM operates beside ROS 2 and is optimized for applications where data freshness and minimal latency outweigh guaranteed completeness. SIM provides sequence numbers, a writer heartbeat, and optional checksums to ensure ordering, liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces data-transport latency by up to 98% compared to ROS 2 zero-copy transports such as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows 95th/99th-percentile tail latencies by around 96%. In tests on a production-ready Level 4 vehicle running Autoware.Universe, SIM increased localization frequency from 7.5 Hz to 9.5 Hz. Applied across all latency-critical modules, SIM cut average perception-to-decision latency from 521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h) on dry concrete by 13.6 ft (4.14 m).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11448","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.975995","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Yuankai He, Hanlin Chen, Weisong Shi","raw_content_length":1656,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["DDS","PCL","ROS","ROS 2","SIM"],"persons":[],"locations":[],"monetary":[]},"char_count":1655,"language_detected":"en","key_concepts":{"key_phrases":["A Faster and More Reliable Middleware","Autonomous Driving Systems","arXiv251011448v1 Announce Type","new Abstract","safety","high-speed autonomous vehicles","rapid control loops","tightly bounded delays","perception","actuation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Faster and More Reliable Middleware":2.0,"Autonomous Driving Systems":2.0,"arXiv251011448v1 Announce Type":1.0,"new Abstract":1.0,"safety":1.0,"high-speed autonomous vehicles":1.0,"rapid control loops":1.0,"tightly bounded delays":1.0,"perception":1.0,"actuation":1.0}},"age_hours":2.759122639722222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7845,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7887,"joy":0.009,"surprise":0.029,"sadness":0.0061,"fear":0.097,"anger":0.0462,"disgust":0.0239},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research presents a new middleware (SIM) for autonomous driving systems, demonstrating concrete improvements in latency and braking distance on a Level 4 vehicle. The evidence includes measured reductions in data transport latency and perception-to-decision latency, leading to a shorter emergency braking distance. While promising, it's still in the applied research stage, requiring further deployment and validation to assess its broader economic viability and systemic impact.","key_impact_metrics":["Localization frequency increased from 7.5 Hz to 9.5 Hz","Emergency braking distance reduced by 13.6 ft (4.14 m)"],"technology_tags":["autonomous driving","middleware","shared-memory transport","ROS 2"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:02.353305Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d1e2bc51ba6b","title":"Enhancing Maritime Domain Awareness on Inland Waterways: A YOLO","content":"arXiv:2510.11449v1 Announce Type: new Abstract: Maritime Domain Awareness (MDA) for inland waterways remains challenged by cooperative system vulnerabilities. This paper presents a novel framework that fuses high-resolution satellite imagery with vessel trajectory data from the Automatic Identification System (AIS). This work addresses the limitations of AIS-based monitoring by leveraging non-cooperative satellite imagery and implementing a fusion approach that links visual detections with AIS data to identify dark vessels, validate cooperative traffic, and support advanced MDA. The You Only Look Once (YOLO) v11 object detection model is used to detect and characterize vessels and barges by vessel type, barge cover, operational status, barge count, and direction of travel. An annotated data set of 4,550 instances was developed from $5{,}973~\\mathrm{mi}^2$ of Lower Mississippi River imagery. Evaluation on a held-out test set demonstrated vessel classification (tugboat, crane barge, bulk carrier, cargo ship, and hopper barge) with an F1 score of 95.8\\%; barge cover (covered or uncovered) detection yielded an F1 score of 91.6\\%; operational status (staged or in motion) classification reached an F1 score of 99.4\\%. Directionality (upstream, downstream) yielded 93.8\\% accuracy. The barge count estimation resulted in a mean absolute error (MAE) of 2.4 barges. Spatial transferability analysis across geographically disjoint river segments showed accuracy was maintained as high as 98\\%. These results underscore the viability of integrating non-cooperative satellite sensing with AIS fusion. This approach enables near-real-time fleet inventories, supports anomaly detection, and generates high-quality data for inland waterway surveillance. Future work will expand annotated datasets, incorporate temporal tracking, and explore multi-modal deep learning to further enhance operational scalability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11449","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.976459","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":258,"author":"Geoffery Agorku, Sarah Hernandez, Hayley Hames, Cade Wagner","raw_content_length":1915,"priority":7,"update_frequency":1,"reading_time_minutes":1.29,"robust_parsing_used":true,"entities":{"organizations":["AIS","YOLO","the Automatic Identification System","MDA"],"persons":[],"locations":["Lower Mississippi River"],"monetary":["$5{,}973~\\mathrm{mi}^2$"]},"char_count":1914,"language_detected":"en","key_concepts":{"key_phrases":["Maritime Domain Awareness","Inland Waterways","A YOLO","AIS","arXiv251011449v1 Announce Type","new Abstract","MDA","inland waterways","cooperative system vulnerabilities","This paper"],"filter_categories":{"ai_ml":["Maritime Domain Awareness"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Maritime Domain Awareness":3.0,"Inland Waterways":2.0,"A YOLO":2.0,"AIS":2.0,"arXiv251011449v1 Announce Type":1.0,"new Abstract":1.0,"MDA":1.0,"inland waterways":1.0,"cooperative system vulnerabilities":1.0,"This paper":1.0}},"age_hours":2.7591381305555553,"is_recent":true,"quality_score":1.0,"sentiment_score":3.1245000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3751,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8438,"joy":0.0234,"surprise":0.0396,"sadness":0.0059,"fear":0.0548,"anger":0.0254,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for maritime domain awareness using YOLO v11. It demonstrates vessel classification with an F1 score of 95.8% and barge cover detection with an F1 score of 91.6%. The technology is at the applied research stage, with potential for deployment in inland waterway surveillance, but lacks real-world deployment data and economic viability assessment.","key_impact_metrics":["vessel classification F1 score 95.8%","barge cover detection F1 score 91.6%"],"technology_tags":["YOLO v11","satellite imagery","AIS fusion","object detection"],"sdg_alignment":[9,14],"analyzed_at":"2025-10-29T12:01:05.526548Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_594d51b1efdd","title":"List Decoding Reed-","content":"arXiv:2510.11453v1 Announce Type: new Abstract: Reed--Solomon error-correcting codes are ubiquitous across computer science and information theory, with applications in cryptography, computational complexity, communication and storage systems, and more. Most works on efficient error correction for these codes, like the celebrated Berlekamp--Welch unique decoder and the (Guruswami--)Sudan list decoders, are focused on measuring error in the Hamming metric, which simply counts the number of corrupted codeword symbols. However, for some applications, other metrics that depend on the specific values of the errors may be more appropriate. This work gives a polynomial-time algorithm that list decodes (generalized) Reed--Solomon codes over prime fields in $\\ell_p$ (semi)metrics, for any $0 < p \\leq 2$. Compared to prior algorithms for the Lee ($\\ell_1$) and Euclidean ($\\ell_2$) metrics, ours decodes to arbitrarily large distances (for correspondingly small rates), and has better distance-rate tradeoffs for all decoding distances above some moderate thresholds. We also prove lower bounds on the $\\ell_{1}$ and $\\ell_{2}$ minimum distances of a certain natural subclass of GRS codes, which establishes that our list decoder is actually a unique decoder for many parameters of interest. Finally, we analyze our algorithm's performance under random Laplacian and Gaussian errors, and show that it supports even larger rates than for corresponding amounts of worst-case error in $\\ell_{1}$ and $\\ell_{2}$ (respectively).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11453","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.976920","language":"en","tags":["computer-science","csds","preprints","mathit","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Chris Peikert, Alexandra Veliche Hostetler","raw_content_length":1528,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["Hamming"],"persons":["Solomon","Lee","Euclidean"],"locations":[],"monetary":["$\\ell_1$","$\\ell_2$"]},"char_count":1525,"language_detected":"en","key_concepts":{"key_phrases":["List Decoding Reed-","arXiv251011453v1 Announce Type","new Abstract","Reed","Solomon error-correcting codes","computer science","information theory","applications","cryptography","computational complexity"],"filter_categories":{"research_academic":["computer science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"List Decoding Reed-":2.0,"arXiv251011453v1 Announce Type":1.0,"new Abstract":1.0,"Reed":1.0,"Solomon error-correcting codes":1.0,"computer science":1.0,"information theory":1.0,"applications":1.0,"cryptography":1.0,"computational complexity":1.0}},"age_hours":2.7591538930555553,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8795,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7759,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9014,"joy":0.0106,"surprise":0.0267,"sadness":0.0047,"fear":0.0213,"anger":0.022,"disgust":0.0133},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for error correction in Reed-Solomon codes, potentially improving data storage and communication efficiency. While the algorithm itself doesn't directly reduce GHG emissions, more efficient data handling could lead to reduced energy consumption in data centers and communication networks. The research is peer-reviewed and provides specific performance metrics, but it's still in the early stages of development with no deployed units.","key_impact_metrics":["Arbitrarily large decoding distances","Better distance-rate tradeoffs"],"technology_tags":["Error Correction","Reed-Solomon Codes","Data Storage","Communication"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:08.585231Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7540674fc786","title":"From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization","content":"arXiv:2510.11457v1 Announce Type: new Abstract: Improving the multi-step reasoning ability of Large Language Models (LLMs) is a critical yet challenging task. The dominant paradigm, outcome-supervised reinforcement learning (RLVR), rewards only correct final answers, often propagating flawed reasoning and suffering from sparse reward signals. While process-level reward models (PRMs) provide denser, step-by-step feedback, they lack generalizability and interpretability, requiring task-specific segmentation of the reasoning process. To this end, we propose the Dimension-level Reward Model (DRM), a new supervision framework that bridges the gap between these two approaches. DRM evaluates the quality of a reasoning process along three fundamental, complementary, and interpretable dimensions: Confidence for uncertainty calibration, Relevance for semantic alignment, and Coherence for logical consistency. Together, these dimensions capture aspects beyond final answer correctness and enable interpretable assessment without requiring ground truth answers. Experimental results show that DRM provides effective supervision signals, guides the optimization of LLMs and enhances their reasoning ability. In particular, DRM-supervised training achieves consistent gains on both in-distribution and out-of-distribution open-domain tasks, including mathematics, question answering, code execution, and puzzles. Our findings demonstrate that multidimensional supervision of the reasoning process can improve the generalized reasoning ability of LLMs beyond the training distribution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11457","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.978105","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Beining Wang, Weihang Su, Hongtao Tian, Tao Yang, Yujia Zhou, Ting Yao, Qingyao Ai, Yiqun Liu","raw_content_length":1584,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Coherence","DRM"],"persons":[],"locations":[],"monetary":[]},"char_count":1583,"language_detected":"en","key_concepts":{"key_phrases":["Multidimensional Supervision","Reasoning Process","LLM Optimization","arXiv251011457v1 Announce Type","new Abstract","the multi-step reasoning ability","Large Language Models","LLMs","a critical yet challenging task","The dominant paradigm"],"filter_categories":{"ai_ml":["LLM Optimization","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multidimensional Supervision":2.0,"Reasoning Process":2.0,"LLM Optimization":2.0,"arXiv251011457v1 Announce Type":1.0,"new Abstract":1.0,"the multi-step reasoning ability":1.0,"Large Language Models":1.0,"LLMs":1.0,"a critical yet challenging task":1.0,"The dominant paradigm":1.0}},"age_hours":2.759200434166667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9431,"joy":0.0063,"surprise":0.0197,"sadness":0.0087,"fear":0.0071,"anger":0.0081,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new method (DRM) for improving LLM reasoning, which could indirectly impact sustainability by optimizing resource use in AI. However, the article is primarily theoretical, lacking concrete deployments or quantified environmental benefits. The research is in the early stages, with no clear path to economic viability or deployment readiness.","key_impact_metrics":["Confidence for uncertainty calibration","Relevance for semantic alignment"],"technology_tags":["Large Language Models","Reinforcement Learning","AI Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:11.695891Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9de42d1207f8","title":"Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model","content":"arXiv:2510.11462v1 Announce Type: new Abstract: Deductive and abductive reasoning are two critical paradigms for analyzing knowledge graphs, enabling applications from financial query answering to scientific discovery. Deductive reasoning on knowledge graphs usually involves retrieving entities that satisfy a complex logical query, while abductive reasoning generates plausible logical hypotheses from observations. Despite their clear synergistic potential, where deduction can validate hypotheses and abduction can uncover deeper logical patterns, existing methods address them in isolation. To bridge this gap, we propose DARK, a unified framework for Deductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion model capable of capturing the bidirectional relationship between queries and conclusions, DARK has two key innovations. First, to better leverage deduction for hypothesis refinement during abductive reasoning, we introduce a self-reflective denoising process that iteratively generates and validates candidate hypotheses against the observed conclusion. Second, to discover richer logical associations, we propose a logic-exploration reinforcement learning approach that simultaneously masks queries and conclusions, enabling the model to explore novel reasoning compositions. Extensive experiments on multiple benchmark knowledge graphs show that DARK achieves state-of-the-art performance on both deductive and abductive reasoning tasks, demonstrating the significant benefits of our unified approach.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11462","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.978514","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Yisen Gao, Jiaxin Bai, Yi Huang, Xingcheng Fu, Qingyun Sun, Yangqiu Song","raw_content_length":1539,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["ref","DARK","Masked Diffusion Model arXiv:2510.11462v1 Announce Type"],"persons":[],"locations":["Knowledge Graphs"],"monetary":[]},"char_count":1538,"language_detected":"en","key_concepts":{"key_phrases":["Deductive and Abductive Reasoning","Knowledge Graphs","Masked Diffusion Model","knowledge graphs","arXiv251011462v1 Announce Type","new Abstract","Deductive and abductive reasoning","two critical paradigms","enabling applications","financial query"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deductive and Abductive Reasoning":2.0,"Knowledge Graphs":2.0,"Masked Diffusion Model":2.0,"knowledge graphs":2.0,"arXiv251011462v1 Announce Type":1.0,"new Abstract":1.0,"Deductive and abductive reasoning":1.0,"two critical paradigms":1.0,"enabling applications":1.0,"financial query":1.0}},"age_hours":2.7592142733333334,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8454,"joy":0.0225,"surprise":0.0266,"sadness":0.0073,"fear":0.0463,"anger":0.03,"disgust":0.0219},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel framework (DARK) for deductive and abductive reasoning in knowledge graphs. While the research shows state-of-the-art performance on benchmark datasets, it remains in the basic research phase with no deployed technology or measured outcomes in a real-world sustainability context. The potential climate impact is indirect, relying on future applications of improved knowledge graph reasoning.","key_impact_metrics":["State-of-the-art performance on deductive and abductive reasoning tasks"],"technology_tags":["knowledge graphs","masked diffusion model","reinforcement learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:15.676777Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0af8531392a","title":"Iterative Amortized Inference: Unifying In","content":"arXiv:2510.11471v1 Announce Type: new Abstract: Modern learning systems increasingly rely on amortized learning - the idea of reusing computation or inductive biases shared across tasks to enable rapid generalization to novel problems. This principle spans a range of approaches, including meta-learning, in-context learning, prompt tuning, learned optimizers and more. While motivated by similar goals, these approaches differ in how they encode and leverage task-specific information, often provided as in-context examples. In this work, we propose a unified framework which describes how such methods differ primarily in the aspects of learning they amortize - such as initializations, learned updates, or predictive mappings - and how they incorporate task data at inference. We introduce a taxonomy that categorizes amortized models into parametric, implicit, and explicit regimes, based on whether task adaptation is externalized, internalized, or jointly modeled. Building on this view, we identify a key limitation in current approaches: most methods struggle to scale to large datasets because their capacity to process task data at inference (e.g., context length) is often limited. To address this, we propose iterative amortized inference, a class of models that refine solutions step-by-step over mini-batches, drawing inspiration from stochastic optimization. Our formulation bridges optimization-based meta-learning with forward-pass amortization in models like LLMs, offering a scalable and extensible foundation for general-purpose task adaptation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11471","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.978935","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Sarthak Mittal, Divyat Mahajan, Guillaume Lajoie, Mohammad Pezeshki","raw_content_length":1566,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Iterative Amortized Inference: Unifying In arXiv:2510.11471v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1565,"language_detected":"en","key_concepts":{"key_phrases":["Iterative Amortized Inference","arXiv251011471v1 Announce Type","new Abstract","Modern learning systems","amortized learning","the idea","computation","inductive biases","tasks","rapid generalization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Iterative Amortized Inference":2.0,"arXiv251011471v1 Announce Type":1.0,"new Abstract":1.0,"Modern learning systems":1.0,"amortized learning":1.0,"the idea":1.0,"computation":1.0,"inductive biases":1.0,"tasks":1.0,"rapid generalization":1.0}},"age_hours":2.759229348333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.372,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8744,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8818,"joy":0.0192,"surprise":0.0631,"sadness":0.005,"fear":0.0114,"anger":0.0131,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel machine learning framework (iterative amortized inference) to improve the scalability of task adaptation in AI models. While the framework could potentially improve the efficiency of AI models used in climate-related applications, there are no concrete deployments or measured outcomes related to sustainability. The research is at a very early stage, focusing on theoretical improvements rather than practical applications.","key_impact_metrics":[],"technology_tags":["machine learning","meta-learning","artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:20.639803Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_97c56f66162a","title":"Differentiable Fast Top","content":"arXiv:2510.11472v1 Announce Type: new Abstract: Cascade ranking is a widely adopted paradigm in large-scale information retrieval systems for Top-K item selection. However, the Top-K operator is non-differentiable, hindering end-to-end training. Existing methods include Learning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics like NDCG and suffer from objective misalignment, and differentiable sorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for direct Top-K optimization but introduce gradient conflicts through matrix aggregation. A promising alternative is to directly construct a differentiable approximation of the Top-K selection operator, bypassing the use of soft permutation matrices. However, even state-of-the-art differentiable Top-K operator (e.g., LapSum) require $O(n \\log n)$ complexity due to their dependence on sorting for solving the threshold. Thus, we propose DFTopK, a novel differentiable Top-K operator achieving optimal $O(n)$ time complexity. By relaxing normalization constraints, DFTopK admits a closed-form solution and avoids sorting. DFTopK also avoids the gradient conflicts inherent in differentiable sorting-based methods. We evaluate DFTopK on both the public benchmark RecFLow and an industrial system. Experimental results show that DFTopK significantly improves training efficiency while achieving superior performance, which enables us to scale up training samples more efficiently. In the online A/B test, DFTopK yielded a +1.77\\% revenue lift with the same computational budget compared to the baseline. To the best of our knowledge, this work is the first to introduce differentiable Top-K operators into recommendation systems and the first to achieve theoretically optimal linear-time complexity for Top-K selection. We have open-sourced our implementation to facilitate future research in both academia and industry.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11472","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.979575","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Yanjie Zhu, Zhen Zhang, Yunli Wang, Zhiqiang Wang, Yu Li, Rufan Zhou, Shiyang Wen, Peng Jiang, Chenhao Lin, Jian Yang","raw_content_length":1915,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["LapSum","n)$ complexity","the Top-K","NDCG","LambdaLoss","ARF","Top-K"],"persons":["Cascade","Top-K"],"locations":[],"monetary":[]},"char_count":1914,"language_detected":"en","key_concepts":{"key_phrases":["Differentiable Fast Top","which","arXiv251011472v1 Announce Type","new Abstract","Cascade ranking","a widely adopted paradigm","large-scale information retrieval systems","Top-K item selection","the Top-K operator","end"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Differentiable Fast Top":2.0,"which":2.0,"arXiv251011472v1 Announce Type":1.0,"new Abstract":1.0,"Cascade ranking":1.0,"a widely adopted paradigm":1.0,"large-scale information retrieval systems":1.0,"Top-K item selection":1.0,"the Top-K operator":1.0,"end":1.0}},"age_hours":2.7592457486111113,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8309,"joy":0.0053,"surprise":0.0224,"sadness":0.0454,"fear":0.0179,"anger":0.0249,"disgust":0.0532},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a novel differentiable Top-K operator (DFTopK) that improves training efficiency and performance in recommendation systems. It has been tested on a public benchmark and an industrial system, yielding a +1.77% revenue lift in an online A/B test. While it improves efficiency, the direct climate impact is indirect, related to potential energy savings in computation.","key_impact_metrics":["+1.77% revenue lift","O(n) time complexity"],"technology_tags":["differentiable Top-K operator","recommendation systems"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:01:23.635338Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_888f10776b61","title":"An adaptive time","content":"arXiv:2510.11475v1 Announce Type: new Abstract: This paper develops three linear and energy-stable schemes for a modified phase field crystal model with a strong nonlinear vacancy potential (VMPFC model). This sixth-order phase-field model enables realistic crystal growth simulation. Starting from a Crank-Nicolson scheme based on the stabilized-SAV (S-SAV) method, we optimize it via the generalized positive auxiliary variable (GPAV) and modified exponential scalar auxiliary variable (ESAV) methods, thereby reducing computational complexity or eliminating the requirement for the nonlinear free energy potential to be bounded from below. The newly developed Energy-Variation Moving Average (EV-MA) adaptive time-stepping strategy resolves numerical instabilities and mitigates the high parameter sensitivity of the conventional adaptive time algorithm during rapid energy decay in the strongly nonlinear system. Unlike conventional instantaneous energy-derivative monitors, the EV-MA technique incorporates a moving average of the energy variation. Additionally, the rate of change between adjacent time steps is constrained by a maximum change factor. This design effectively dampens spurious oscillations and enhances the robustness of time step selection. Extensive numerical experiments are conducted to validate the accuracy and energy stability of the proposed schemes. The EV-MA strategy is also demonstrated to perform robustly across a wide range of parameters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11475","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.980803","language":"en","tags":["preprints","mathmp","research","csna","math-ph","mathna","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Wanrong Hao, Yunqing Huang","raw_content_length":1476,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["Crank-Nicolson","Energy-Variation Moving Average"],"persons":[],"locations":[],"monetary":[]},"char_count":1475,"language_detected":"en","key_concepts":{"key_phrases":["An adaptive time","arXiv251011475v1 Announce Type","new Abstract","This paper","three linear and energy-stable schemes","a modified phase field crystal model","a strong nonlinear vacancy potential","VMPFC model","This sixth-order phase-field model","realistic crystal growth simulation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An adaptive time":2.0,"arXiv251011475v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"three linear and energy-stable schemes":1.0,"a modified phase field crystal model":1.0,"a strong nonlinear vacancy potential":1.0,"VMPFC model":1.0,"This sixth-order phase-field model":1.0,"realistic crystal growth simulation":1.0}},"age_hours":2.7592901555555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.568,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9136,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8532,"joy":0.0554,"surprise":0.069,"sadness":0.0053,"fear":0.0031,"anger":0.0108,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the computational efficiency and stability of crystal growth simulations. While improved simulations can potentially lead to better materials design for sustainable technologies, the direct climate impact is theoretical at this stage. The research is at a basic research level, with no deployed technology or measured outcomes in a real-world setting.","key_impact_metrics":["Computational complexity reduction","Energy stability"],"technology_tags":["Phase field crystal model","Crystal growth simulation","Adaptive time-stepping"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:28.089490Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f87f76165922","title":"Investigating Large Language Models' Linguistic Abilities for Text Preprocessing","content":"arXiv:2510.11482v1 Announce Type: new Abstract: Text preprocessing is a fundamental component of Natural Language Processing, involving techniques such as stopword removal, stemming, and lemmatization to prepare text as input for further processing and analysis. Despite the context-dependent nature of the above techniques, traditional methods usually ignore contextual information. In this paper, we investigate the idea of using Large Language Models (LLMs) to perform various preprocessing tasks, due to their ability to take context into account without requiring extensive language-specific annotated resources. Through a comprehensive evaluation on web-sourced data, we compare LLM-based preprocessing (specifically stopword removal, lemmatization and stemming) to traditional algorithms across multiple text classification tasks in six European languages. Our analysis indicates that LLMs are capable of replicating traditional stopword removal, lemmatization, and stemming methods with accuracies reaching 97%, 82%, and 74%, respectively. Additionally, we show that ML algorithms trained on texts preprocessed by LLMs achieve an improvement of up to 6% with respect to the $F_1$ measure compared to traditional techniques. Our code, prompts, and results are publicly available at https://github.com/GianCarloMilanese/llm_pipeline_wi-iat.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11482","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.981955","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Marco Braga, Gian Carlo Milanese, Gabriella Pasi","raw_content_length":1347,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Natural Language Processing","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models Linguistic Abilities","Text Preprocessing","Announce Type","new Abstract","Text preprocessing","a fundamental component","Natural Language Processing","techniques","stopword removal","stemming"],"filter_categories":{"ai_ml":["Large Language Models Linguistic Abilities","Natural Language Processing"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models Linguistic Abilities":2.0,"Text Preprocessing":2.0,"Announce Type":1.0,"new Abstract":1.0,"Text preprocessing":1.0,"a fundamental component":1.0,"Natural Language Processing":1.0,"techniques":1.0,"stopword removal":1.0,"stemming":1.0}},"age_hours":2.7593313408333335,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.892,"joy":0.0147,"surprise":0.0391,"sadness":0.0056,"fear":0.0177,"anger":0.0207,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research investigates using LLMs for text preprocessing, showing up to 6% improvement in F1 measure for text classification. While promising, it's still in the research phase with no deployed technology or economic viability demonstrated. The impact on climate is indirect, potentially improving efficiency in processing climate-related text data, but this is theoretical.","key_impact_metrics":["Accuracy of stopword removal with LLMs: 97%","Improvement of F1 measure: up to 6%"],"technology_tags":["Large Language Models","Natural Language Processing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:01:30.879741Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1bf6c389d1f1","title":"Uncertainty Quantification for Retrieval","content":"arXiv:2510.11483v1 Announce Type: new Abstract: Retrieval-augmented reasoning (RAR) is a recent evolution of retrieval-augmented generation (RAG) that employs multiple reasoning steps for retrieval and generation. While effective for some complex queries, RAR remains vulnerable to errors and misleading outputs. Uncertainty quantification (UQ) offers methods to estimate the confidence of systems' outputs. These methods, however, often handle simple queries with no retrieval or single-step retrieval, without properly handling RAR setup. Accurate estimation of UQ for RAR requires accounting for all sources of uncertainty, including those arising from retrieval and generation. In this paper, we account for all these sources and introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ method for RAR. The core idea of R2C is to perturb the multi-step reasoning process by applying various actions to reasoning steps. These perturbations alter the retriever's input, which shifts its output and consequently modifies the generator's input at the next step. Through this iterative feedback loop, the retriever and generator continuously reshape one another's inputs, enabling us to capture uncertainty arising from both components. Experiments on five popular RAR systems across diverse QA datasets show that R2C improves AUROC by over 5% on average compared to the state-of-the-art UQ baselines. Extrinsic evaluations using R2C as an external signal further confirm its effectiveness for two downstream tasks: in Abstention, it achieves ~5% gains in both F1Abstain and AccAbstain; in Model Selection, it improves the exact match by ~7% over single models and ~3% over selection methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11483","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.982372","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Heydar Soudani, Hamed Zamani, Faegheh Hasibi","raw_content_length":1705,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["Retrieval-Augmented Reasoning Consistency","RAR"],"persons":[],"locations":[],"monetary":[]},"char_count":1704,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty Quantification","Retrieval","RAR","arXiv251011483v1 Announce Type","new Abstract","Retrieval-augmented reasoning","a recent evolution","retrieval-augmented generation","RAG","multiple reasoning steps"],"filter_categories":{"ai_ml":["Uncertainty Quantification"],"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty Quantification":2.0,"Retrieval":2.0,"RAR":2.0,"arXiv251011483v1 Announce Type":1.0,"new Abstract":1.0,"Retrieval-augmented reasoning":1.0,"a recent evolution":1.0,"retrieval-augmented generation":1.0,"RAG":1.0,"multiple reasoning steps":1.0}},"age_hours":2.75934609,"is_recent":true,"quality_score":1.0,"sentiment_score":1.596,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6808,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4327,"joy":0.0044,"surprise":0.0179,"sadness":0.0183,"fear":0.4721,"anger":0.0258,"disgust":0.0287},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (R2C) for uncertainty quantification in retrieval-augmented reasoning systems. It achieves a 5% improvement in AUROC compared to existing methods and shows gains in downstream tasks like abstention and model selection. However, it's still in the research phase with no deployed applications or economic viability demonstrated, hence the low scores.","key_impact_metrics":["AUROC improved by over 5%","F1Abstain gains of ~5%"],"technology_tags":["Uncertainty Quantification","Retrieval-Augmented Reasoning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:34.102548Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cfc09251bbf5","title":"Constraint","content":"arXiv:2510.11491v1 Announce Type: new Abstract: Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that arise from exploration during training by reducing constraint violations while maintaining task performance. Existing approaches typically rely on a single policy to jointly optimize reward and safety, which can cause instability due to conflicting objectives, or they use external safety filters that override actions and require prior system knowledge. In this paper, we propose a modular cost-aware regulator that scales the agent's actions based on predicted constraint violations, preserving exploration through smooth action modulation rather than overriding the policy. The regulator is trained to minimize constraint violations while avoiding degenerate suppression of actions. Our approach integrates seamlessly with off-policy RL methods such as SAC and TD3, and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion tasks with sparse costs, reducing constraint violations by up to 126 times while increasing returns by over an order of magnitude compared to prior methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11491","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.983157","language":"en","tags":["cslg","eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Murad Dawood, Usama Ahmed Siddiquie, Shahram Khorshidi, Maren Bennewitz","raw_content_length":1124,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["TD3","SAC"],"persons":[],"locations":[],"monetary":[]},"char_count":1123,"language_detected":"en","key_concepts":{"key_phrases":["Constraint","arXiv251011491v1 Announce Type","new Abstract","Safe reinforcement learning","unsafe behaviors","exploration","training","constraint violations","task performance","Existing approaches"],"filter_categories":{"ai_ml":["Constraint","Safe reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Constraint":2.0,"arXiv251011491v1 Announce Type":1.0,"new Abstract":1.0,"Safe reinforcement learning":1.0,"unsafe behaviors":1.0,"exploration":1.0,"training":1.0,"constraint violations":1.0,"task performance":1.0,"Existing approaches":1.0}},"age_hours":2.7593740644444447,"is_recent":true,"quality_score":1.0,"sentiment_score":9.403500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8807,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6997,"joy":0.0083,"surprise":0.01,"sadness":0.0135,"fear":0.2072,"anger":0.0402,"disgust":0.0212},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to safe reinforcement learning, showing a reduction in constraint violations by up to 126 times and increased returns in Safety Gym locomotion tasks. This is a promising development, but it's still in the research phase with no real-world deployments or economic viability demonstrated. The metrics are based on simulations, not real-world data.","key_impact_metrics":["constraint violations reduced by 126 times","returns increased by over an order of magnitude"],"technology_tags":["reinforcement learning","safe RL","cost-aware regulator"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:38.094346Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f145f29618d","title":"How Reinforcement Learning After Next","content":"arXiv:2510.11495v1 Announce Type: new Abstract: Recent advances in reasoning domains with neural networks have primarily been enabled by a training recipe that optimizes Large Language Models, previously trained to predict the next-token in a sequence, with reinforcement learning algorithms. We introduce a framework to study the success of this paradigm, and we theoretically expose the optimization mechanisms by which reinforcement learning improves over next-token prediction in this setting. We study learning from mixture distributions of short and long ``chain-of-thought'' sequences encoding a single task. In particular, when the task consists of predicting the parity of $d$ bits and long sequences are rare, we show how reinforcement learning after next-token prediction enables autoregressive transformers to generalize, whereas mere next-token prediction requires extreme statistical or computational resources to do so. We further explain how reinforcement learning leverages increased test-time computation, manifested in longer responses, to facilitate this learning process. In a simplified setting, we theoretically prove that autoregressive linear models following this training recipe can efficiently learn to predict the parity of $d$ bits as long as the proportion of long demonstrations in the data mix is not exponentially small in the input dimension $d$. Finally, we demonstrate these same phenomena in other settings, including the post-training of Llama-series models on mixture variations of common mathematical reasoning benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11495","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.983589","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Nikolaos Tsilivis, Eran Malach, Karen Ullrich, Julia Kempe","raw_content_length":1564,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1563,"language_detected":"en","key_concepts":{"key_phrases":["How Reinforcement Learning","reinforcement learning","arXiv251011495v1 Announce Type","new Abstract","Recent advances","reasoning domains","neural networks","a training recipe","Large Language Models","a sequence"],"filter_categories":{"ai_ml":["How Reinforcement Learning","reinforcement learning","neural networks","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"How Reinforcement Learning":2.0,"reinforcement learning":2.0,"arXiv251011495v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"reasoning domains":1.0,"neural networks":1.0,"a training recipe":1.0,"Large Language Models":1.0,"a sequence":1.0}},"age_hours":2.7593887552777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8304,"joy":0.0486,"surprise":0.0728,"sadness":0.0039,"fear":0.0121,"anger":0.0212,"disgust":0.0109},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical research on improving reinforcement learning algorithms for large language models. The concrete action is the development of a framework to study the optimization mechanisms of reinforcement learning. The evidence is based on theoretical proofs and demonstrations on mathematical reasoning benchmarks, but there are no deployed systems or real-world data. It is at the basic research stage.","key_impact_metrics":["parity of d bits"],"technology_tags":["reinforcement learning","large language models","autoregressive transformers"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:01:41.062029Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7693287f076c","title":"ReLook: Vision","content":"arXiv:2510.11498v1 Announce Type: new Abstract: While Large Language Models (LLMs) excel at algorithmic code generation, they struggle with front-end development, where correctness is judged on rendered pixels and interaction. We present ReLook, an agentic, vision-grounded reinforcement learning framework that empowers an agent to close a robust generate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool. During training, the agent uses the MLLM-in-the-loop both as a visual critic--scoring code with screenshots--and as a source of actionable, vision-grounded feedback; a strict zero-reward rule for invalid renders anchors renderability and prevents reward hacking. To prevent behavioral collapse, we introduce Forced Optimization, a strict acceptance rule that admits only improving revisions, yielding monotonically better trajectories. At inference, we decouple the critic and run a lightweight, critic-free self-edit cycle, keeping latency comparable to base decoding while retaining most of the gains. Across three widely used benchmarks, ReLook consistently outperforms strong baselines in vision-grounded front-end code generation, highlighting the benefits of agentic perception, visual rewards, and training-inference decoupling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11498","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.984369","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Yuhang Li, Chenchen Zhang, Ruilin Lv, Ao Liu, Ken Deng, Yuanxing Zhang, Jiaheng Liu, Wiggin Zhou, Bo Zhou","raw_content_length":1263,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["ReLook","Forced Optimization"],"persons":[],"locations":[],"monetary":[]},"char_count":1262,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011498v1 Announce Type","new Abstract","Large Language Models","LLMs","algorithmic code generation","front-end development","correctness","rendered pixels","interaction","ReLook"],"filter_categories":{"ai_ml":["Large Language Models","algorithmic code generation"],"engineering":["front-end development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011498v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"algorithmic code generation":1.0,"front-end development":1.0,"correctness":1.0,"rendered pixels":1.0,"interaction":1.0,"ReLook":1.0}},"age_hours":2.7594201752777776,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9074,"joy":0.0121,"surprise":0.0286,"sadness":0.0065,"fear":0.0156,"anger":0.0167,"disgust":0.0131},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework (ReLook) for improving front-end code generation, but its sustainability impact is indirect. While more efficient code generation could potentially reduce energy consumption in software development, this is theoretical at this stage. The research is peer-reviewed, lending technical credibility, but it is still in the applied research phase with no deployment data.","key_impact_metrics":["Latency comparable to base decoding","Outperforms strong baselines in vision-grounded front-end code generation"],"technology_tags":["Large Language Models","Reinforcement Learning","Vision-Grounded AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:44.513424Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_363959142322","title":"Offline Reinforcement Learning with Generative Trajectory Policies","content":"arXiv:2510.11499v1 Announce Type: new Abstract: Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors. However, existing methods face a stark trade-off: slow, iterative models like diffusion policies are computationally expensive, while fast, single-step models like consistency policies often suffer from degraded performance. In this paper, we demonstrate that it is possible to bridge this gap. The key to moving beyond the limitations of individual methods, we argue, lies in a unifying perspective that views modern generative models, including diffusion, flow matching, and consistency models, as specific instances of learning a continuous-time generative trajectory governed by an Ordinary Differential Equation (ODE). This principled foundation provides a clearer design space for generative policies in RL and allows us to propose Generative Trajectory Policies (GTPs), a new and more general policy paradigm that learns the entire solution map of the underlying ODE. To make this paradigm practical for offline RL, we further introduce two key theoretically principled adaptations. Empirical results demonstrate that GTP achieves state-of-the-art performance on D4RL benchmarks - it significantly outperforms prior generative policies, achieving perfect scores on several notoriously hard AntMaze tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11499","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.984793","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Xinsong Feng, Leshu Tang, Chenan Wang, Haipeng Chen","raw_content_length":1427,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["an Ordinary Differential Equation"],"persons":[],"locations":[],"monetary":[]},"char_count":1426,"language_detected":"en","key_concepts":{"key_phrases":["Offline Reinforcement Learning","Generative Trajectory Policies","arXiv251011499v1 Announce Type","new Abstract","Generative models","a powerful class","policies","offline reinforcement learning","their ability","complex multi-modal behaviors"],"filter_categories":{"ai_ml":["Offline Reinforcement Learning","offline reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Offline Reinforcement Learning":2.0,"Generative Trajectory Policies":2.0,"arXiv251011499v1 Announce Type":1.0,"new Abstract":1.0,"Generative models":1.0,"a powerful class":1.0,"policies":1.0,"offline reinforcement learning":1.0,"their ability":1.0,"complex multi-modal behaviors":1.0}},"age_hours":2.759435241111111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5724,"joy":0.0032,"surprise":0.0168,"sadness":0.1286,"fear":0.0266,"anger":0.0826,"disgust":0.1699},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm (Generative Trajectory Policies) for offline reinforcement learning. While the algorithm achieves state-of-the-art performance on benchmarks, there's no concrete deployment or measurable impact on real-world sustainability challenges. The research is at an early stage, focusing on algorithmic improvements rather than practical applications.","key_impact_metrics":["Perfect scores on AntMaze tasks"],"technology_tags":["Reinforcement Learning","Generative Models","Offline RL"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:01:47.521843Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_91c040c2fc2a","title":"Context","content":"arXiv:2510.11501v1 Announce Type: new Abstract: Autonomous vehicles have shown promising potential to be a groundbreaking technology for improving the safety of road users. For these vehicles, as well as many other safety-critical robotic technologies, to be deployed in real-world applications, we require algorithms that can generalize well to unseen scenarios and data. Model-based reinforcement learning algorithms (MBRL) have demonstrated state-of-the-art performance and data efficiency across a diverse set of domains. However, these algorithms have also shown susceptibility to changes in the environment and its transition dynamics. In this work, we explore the performance and generalization capabilities of MBRL algorithms for autonomous driving, specifically in the simulated autonomous racing environment, Roboracer (formerly F1Tenth). We frame the head-to-head racing task as a learning problem using contextual Markov decision processes and parameterize the driving behavior of the adversaries using the context of the episode, thereby also parameterizing the transition and reward dynamics. We benchmark the behavior of MBRL algorithms in this environment and propose a novel context-aware extension of the existing literature, cMask. We demonstrate that context-aware MBRL algorithms generalize better to out-of-distribution adversary behaviors relative to context-free approaches. We also demonstrate that cMask displays strong generalization capabilities, as well as further performance improvement relative to other context-aware MBRL approaches when racing against adversaries with in-distribution behaviors.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11501","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.985588","language":"en","tags":["computer-science","cslg","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Emran Yasser Moustafa, Ivana Dusparic","raw_content_length":1632,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["MBRL"],"persons":["Markov","Roboracer"],"locations":[],"monetary":[]},"char_count":1629,"language_detected":"en","key_concepts":{"key_phrases":["Context","arXiv251011501v1 Announce Type","new Abstract","Autonomous vehicles","promising potential","a groundbreaking technology","the safety","road users","these vehicles","real-world applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Context":2.0,"arXiv251011501v1 Announce Type":1.0,"new Abstract":1.0,"Autonomous vehicles":1.0,"promising potential":1.0,"a groundbreaking technology":1.0,"the safety":1.0,"road users":1.0,"these vehicles":1.0,"real-world applications":1.0}},"age_hours":2.7594619686111113,"is_recent":true,"quality_score":1.0,"sentiment_score":9.593,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9186,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9109,"joy":0.0138,"surprise":0.0478,"sadness":0.0031,"fear":0.0124,"anger":0.0084,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores model-based reinforcement learning for autonomous driving in a simulated environment. While improved autonomous driving *could* lead to more efficient transportation and reduced emissions, this is currently in the applied research stage with no concrete deployment or measured emissions reductions. The article demonstrates performance improvements in simulation, but lacks real-world validation.","key_impact_metrics":["Generalization capabilities against out-of-distribution adversary behaviors","Performance improvement relative to other context-aware MBRL approaches"],"technology_tags":["Model-based reinforcement learning","Autonomous driving","Contextual Markov decision processes"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:50.598239Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_626b83dd2bf6","title":"Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors","content":"arXiv:2510.11502v1 Announce Type: new Abstract: Research on reasoning in language models (LMs) predominantly focuses on improving the correctness of their outputs. But some important applications require modeling reasoning patterns that are incorrect. For example, automated systems that can reason about and simulate student errors are useful for providing real-time feedback in the classroom or offline practice for educators-in-training. This paper presents a new method, MISTAKE, that (1) constructs high-quality synthetic examples of reasoning errors by leveraging cycle consistency between incorrect answers and latent misconceptions; and (2) uses the generated data to learn models for student simulation, misconception classification, and answer generation. We evaluate MISTAKE on three educational tasks and find that it results in (1) higher accuracy when simulating incorrect student answers based on specific misconceptions, (2) increased performance inferring latent misconceptions from observed incorrect answers, and (3) higher alignment with expert-written distractor answers when generating incorrect answers (e.g., for multiple-choice tests).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11502","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.985977","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Alexis Ross, Jacob Andreas","raw_content_length":1161,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["MISTAKE"],"locations":[],"monetary":[]},"char_count":1160,"language_detected":"en","key_concepts":{"key_phrases":["MISTAKEs","Key Errors","arXiv251011502v1 Announce Type","new Abstract","Research","reasoning","language models","LMs","the correctness","their outputs"],"filter_categories":{"healthcare_tech":["Research"],"research_academic":["Research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MISTAKEs":2.0,"Key Errors":2.0,"arXiv251011502v1 Announce Type":1.0,"new Abstract":1.0,"Research":1.0,"reasoning":1.0,"language models":1.0,"LMs":1.0,"the correctness":1.0,"their outputs":1.0}},"age_hours":2.7594771822222226,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8275,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1655,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9438,"joy":0.0027,"surprise":0.0087,"sadness":0.0057,"fear":0.0043,"anger":0.0174,"disgust":0.0173},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method, MISTAKE, for modeling student errors in language models. While the research is innovative and shows promise for improving educational tools, it is currently in the basic research stage with no deployed technology or measured outcomes related to sustainability. The impact on climate change is minimal, as it primarily focuses on improving educational software.","key_impact_metrics":["higher accuracy when simulating incorrect student answers based on specific misconceptions","increased performance inferring latent misconceptions from observed incorrect answers"],"technology_tags":["AI","machine learning","education"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:01:53.660069Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06f712a581b5","title":"Towards Fast and Scalable Normal Integration using Continuous Components","content":"arXiv:2510.11508v1 Announce Type: new Abstract: Surface normal integration is a fundamental problem in computer vision, dealing with the objective of reconstructing a surface from its corresponding normal map. Existing approaches require an iterative global optimization to jointly estimate the depth of each pixel, which scales poorly to larger normal maps. In this paper, we address this problem by recasting normal integration as the estimation of relative scales of continuous components. By constraining pixels belonging to the same component to jointly vary their scale, we drastically reduce the number of optimization variables. Our framework includes a heuristic to accurately estimate continuous components from the start, a strategy to rebalance optimization terms, and a technique to iteratively merge components to further reduce the size of the problem. Our method achieves state-of-the-art results on the standard normal integration benchmark in as little as a few seconds and achieves one-order-of-magnitude speedup over pixel-level approaches on large-resolution normal maps.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11508","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.987181","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Francesco Milano, Jen Jen Chung, Lionel Ott, Roland Siegwart","raw_content_length":1093,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["Continuous Components arXiv:2510.11508v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1092,"language_detected":"en","key_concepts":{"key_phrases":["Fast and Scalable Normal Integration","Continuous Components","arXiv251011508v1 Announce Type","new Abstract","Surface normal integration","a fundamental problem","computer vision","the objective","a surface","its corresponding normal map"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fast and Scalable Normal Integration":2.0,"Continuous Components":2.0,"arXiv251011508v1 Announce Type":1.0,"new Abstract":1.0,"Surface normal integration":1.0,"a fundamental problem":1.0,"computer vision":1.0,"the objective":1.0,"a surface":1.0,"its corresponding normal map":1.0}},"age_hours":2.759522689722222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.492,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3016,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.907,"joy":0.0078,"surprise":0.0193,"sadness":0.0161,"fear":0.0205,"anger":0.0156,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm for surface normal integration, achieving a one-order-of-magnitude speedup on large-resolution normal maps compared to pixel-level approaches. This could potentially reduce the energy consumption of computer vision tasks, but the actual impact is difficult to quantify without knowing the specific applications and energy profiles of those applications. The research is at an early stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["one-order-of-magnitude speedup"],"technology_tags":["surface normal integration","computer vision","optimization algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:01:56.953752Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6bdf73f81d3e","title":"Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model","content":"arXiv:2510.11509v1 Announce Type: new Abstract: Physical environments and circumstances are fundamentally dynamic, yet current 3D datasets and evaluation benchmarks tend to concentrate on either dynamic scenarios or dynamic situations in isolation, resulting in incomplete comprehension. To overcome these constraints, we introduce Situat3DChange, an extensive dataset supporting three situation-aware change understanding tasks following the perception-action model: 121K question-answer pairs, 36K change descriptions for perception tasks, and 17K rearrangement instructions for the action task. To construct this large-scale dataset, Situat3DChange leverages 11K human observations of environmental changes to establish shared mental models and shared situational awareness for human-AI collaboration. These observations, enriched with egocentric and allocentric perspectives as well as categorical and coordinate spatial relations, are integrated using an LLM to support understanding of situated changes. To address the challenge of comparing pairs of point clouds from the same scene with minor changes, we propose SCReasoner, an efficient 3D MLLM approach that enables effective point cloud comparison with minimal parameter overhead and no additional tokens required for the language decoder. Comprehensive evaluation on Situat3DChange tasks highlights both the progress and limitations of MLLMs in dynamic scene and situation understanding. Additional experiments on data scaling and cross-domain transfer demonstrate the task-agnostic effectiveness of using Situat3DChange as a training dataset for MLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11509","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.987601","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Ruiping Liu, Junwei Zheng, Yufan Chen, Zirui Wang, Kunyu Peng, Kailun Yang, Jiaming Zhang, Marc Pollefeys, Rainer Stiefelhagen","raw_content_length":1616,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1615,"language_detected":"en","key_concepts":{"key_phrases":["Situat3DChange","Situated 3D Change Understanding Dataset","Multimodal Large Language Model","arXiv251011509v1 Announce Type","new Abstract","Physical environments","circumstances","current 3D datasets","evaluation benchmarks","either dynamic scenarios"],"filter_categories":{"ai_ml":["Multimodal Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Situat3DChange":3.0,"Situated 3D Change Understanding Dataset":2.0,"Multimodal Large Language Model":2.0,"arXiv251011509v1 Announce Type":1.0,"new Abstract":1.0,"Physical environments":1.0,"circumstances":1.0,"current 3D datasets":1.0,"evaluation benchmarks":1.0,"either dynamic scenarios":1.0}},"age_hours":2.759537063888889,"is_recent":true,"quality_score":0.7,"sentiment_score":8.953,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7906,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8808,"joy":0.0076,"surprise":0.071,"sadness":0.0061,"fear":0.0136,"anger":0.0133,"disgust":0.0076},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a new dataset (Situat3DChange) and a 3D MLLM approach (SCReasoner) for understanding dynamic scenes. While the dataset is large-scale (121K question-answer pairs), it is still in the research phase. The impact on climate is indirect, potentially enabling better AI for environmental monitoring or robotics, but there are no concrete actions or measured outcomes yet.","key_impact_metrics":["121K question-answer pairs","36K change descriptions"],"technology_tags":["3D scene understanding","Multimodal Large Language Model","Point cloud comparison"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:02:00.417340Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6edbe807898d","title":"LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference","content":"arXiv:2510.11512v1 Announce Type: new Abstract: Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11512","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.987997","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Jianhao Yuan, Fabio Pizzati, Francesco Pinto, Lars Kunze, Ivan Laptev, Paul Newman, Philip Torr, Daniele De Martini","raw_content_length":1410,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["Plausibility Preference Error","PPE","Video Diffusion Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1409,"language_detected":"en","key_concepts":{"key_phrases":["LikePhys","Intuitive Physics Understanding","Video Diffusion Models","Likelihood Preference","video diffusion models","arXiv251011512v1 Announce Type","new Abstract","Intuitive physics understanding","an essential role","general-purpose physically plausible world simulators"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LikePhys":3.0,"Intuitive Physics Understanding":2.0,"Video Diffusion Models":2.0,"Likelihood Preference":2.0,"video diffusion models":2.0,"arXiv251011512v1 Announce Type":1.0,"new Abstract":1.0,"Intuitive physics understanding":1.0,"an essential role":1.0,"general-purpose physically plausible world simulators":1.0}},"age_hours":2.759552321111111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9079,"joy":0.0202,"surprise":0.0174,"sadness":0.0035,"fear":0.032,"anger":0.0093,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the evaluation of intuitive physics understanding in video diffusion models. While it could indirectly contribute to more efficient simulations of physical systems relevant to climate modeling, it is currently in the basic research phase with no immediate deployment or quantified climate impact. The technical credibility is supported by the use of a curated dataset and a novel evaluation metric (PPE), but it lacks deployment and economic viability at this stage.","key_impact_metrics":["Plausibility Preference Error (PPE)","Alignment with human preference"],"technology_tags":["Video Diffusion Models","Intuitive Physics","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:02:03.480776Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d288b61914bd","title":"mmWalk: Towards Multi","content":"arXiv:2510.11520v1 Announce Type: new Abstract: Walking assistance in extreme or complex environments remains a significant challenge for people with blindness or low vision (BLV), largely due to the lack of a holistic scene understanding. Motivated by the real-world needs of the BLV community, we build mmWalk, a simulated multi-modal dataset that integrates multi-view sensor and accessibility-oriented features for outdoor safe navigation. Our dataset comprises 120 manually controlled, scenario-categorized walking trajectories with 62k synchronized frames. It contains over 559k panoramic images across RGB, depth, and semantic modalities. Furthermore, to emphasize real-world relevance, each trajectory involves outdoor corner cases and accessibility-specific landmarks for BLV users. Additionally, we generate mmWalkVQA, a VQA benchmark with over 69k visual question-answer triplets across 9 categories tailored for safe and informed walking assistance. We evaluate state-of-the-art Vision-Language Models (VLMs) using zero- and few-shot settings and found they struggle with our risk assessment and navigational tasks. We validate our mmWalk-finetuned model on real-world datasets and show the effectiveness of our dataset for advancing multi-modal walking assistance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11520","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.989573","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Kedi Ying, Ruiping Liu, Chongyan Chen, Mingzhe Tao, Hao Shi, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen","raw_content_length":1278,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["BLV","Towards Multi arXiv:2510.11520v1 Announce Type: new Abstract","VQA","RGB"],"persons":[],"locations":[],"monetary":[]},"char_count":1277,"language_detected":"en","key_concepts":{"key_phrases":["Announce Type","new Abstract","Walking assistance","extreme or complex environments","a significant challenge","people","blindness","low vision","BLV","the lack"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Announce Type":1.0,"new Abstract":1.0,"Walking assistance":1.0,"extreme or complex environments":1.0,"a significant challenge":1.0,"people":1.0,"blindness":1.0,"low vision":1.0,"BLV":1.0,"the lack":1.0}},"age_hours":2.7596103558333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8882,"joy":0.0113,"surprise":0.0396,"sadness":0.0071,"fear":0.0409,"anger":0.0096,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":7,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes the creation of a multi-modal dataset (mmWalk) for training AI to assist people with blindness or low vision in navigating outdoor environments. While it addresses accessibility and safety, the direct climate impact is minimal. The research is in the applied research stage, with a dataset created and models being evaluated, but no real-world deployment yet.","key_impact_metrics":["62k synchronized frames","559k panoramic images"],"technology_tags":["Computer Vision","Accessibility Technology"],"sdg_alignment":[3,10,11],"analyzed_at":"2025-10-29T12:02:06.811456Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
