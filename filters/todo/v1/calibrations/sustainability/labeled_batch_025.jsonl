{"id":"science_arxiv_cs_ad3ca82637bd","title":"AI-Driven Post-Quantum Cryptography for Cyber","content":"arXiv:2510.08496v1 Announce Type: new Abstract: Transportation Cyber-Physical Systems (TCPS) integrate physical elements, such as transportation infrastructure and vehicles, with cyber elements via advanced communication technologies, allowing them to interact seamlessly. This integration enhances the efficiency, safety, and sustainability of transportation systems. TCPS rely heavily on cryptographic security to protect sensitive information transmitted between vehicles, transportation infrastructure, and other entities within the transportation ecosystem, ensuring data integrity, confidentiality, and authenticity. Traditional cryptographic methods have been employed to secure TCPS communications, but the advent of quantum computing presents a significant threat to these existing security measures. Therefore, integrating Post-Quantum Cryptography (PQC) into TCPS is essential to maintain secure and resilient communications. While PQC offers a promising approach to developing cryptographic algorithms resistant to quantum attacks, artificial intelligence (AI) can enhance PQC by optimizing algorithm selection, resource allocation, and adapting to evolving threats in real-time. AI-driven PQC approaches can improve the efficiency and effectiveness of PQC implementations, ensuring robust security without compromising system performance. This chapter introduces TCPS communication protocols, discusses the vulnerabilities of corresponding communications to cyber-attacks, and explores the limitations of existing cryptographic methods in the quantum era. By examining how AI can strengthen PQC solutions, the chapter presents cyber-resilient communication strategies for TCPS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08496","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.322288","language":"en","tags":["research","cscr","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Akid Abrar, Sagar Dasgupta, Mizanur Rahman, Ahmad Alsharif","raw_content_length":1691,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Post-Quantum Cryptography","PQC","AI-Driven Post-Quantum Cryptography","Transportation Cyber-Physical Systems"],"persons":[],"locations":[],"monetary":[]},"char_count":1690,"language_detected":"en","key_concepts":{"key_phrases":["AI-Driven Post-Quantum Cryptography","Cyber","TCPS","vehicles","arXiv251008496v1 Announce Type","new Abstract","Transportation Cyber-Physical Systems","physical elements","transportation infrastructure","cyber elements"],"filter_categories":{"ai_ml":["AI-Driven Post-Quantum Cryptography"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AI-Driven Post-Quantum Cryptography":2.0,"Cyber":2.0,"TCPS":2.0,"vehicles":2.0,"arXiv251008496v1 Announce Type":1.0,"new Abstract":1.0,"Transportation Cyber-Physical Systems":1.0,"physical elements":1.0,"transportation infrastructure":1.0,"cyber elements":1.0}},"age_hours":2.776359726388889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9302,"joy":0.0204,"surprise":0.0264,"sadness":0.0036,"fear":0.0073,"anger":0.0079,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article discusses AI-driven post-quantum cryptography for transportation cyber-physical systems. While it aims to enhance the security and resilience of transportation systems, there are no concrete actions or measurable outcomes presented. It remains at the conceptual stage with no deployed technology or validated data.","key_impact_metrics":[],"technology_tags":["Post-Quantum Cryptography","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:01.899245Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_94606d0b0b78","title":"Neologism Learning for Controllability and Self","content":"arXiv:2510.08506v1 Announce Type: new Abstract: Humans invent new words when there is a rising demand for a new useful concept (e.g., doomscrolling). We explore and validate a similar idea in our communication with LLMs: introducing new words to better understand and control the models, expanding on the recently introduced neologism learning. This method introduces a new word by adding a new word embedding and training with examples that exhibit the concept with no other changes in model parameters. We show that adding a new word allows for control of concepts such as flattery, incorrect answers, text length, as well as more complex concepts in AxBench. We discover that neologisms can also further our understanding of the model via self-verbalization: models can describe what each new word means to them in natural language, like explaining that a word that represents a concept of incorrect answers means ``a lack of complete, coherent, or meaningful answers...'' To validate self-verbalizations, we introduce plug-in evaluation: we insert the verbalization into the context of a model and measure whether it controls the target concept. In some self-verbalizations, we find machine-only synonyms: words that seem unrelated to humans but cause similar behavior in machines. Finally, we show how neologism learning can jointly learn multiple concepts in multiple words.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08506","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.323094","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"John Hewitt, Oyvind Tafjord, Robert Geirhos, Been Kim","raw_content_length":1381,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["Neologism Learning for Controllability"],"persons":[],"locations":["AxBench"],"monetary":[]},"char_count":1380,"language_detected":"en","key_concepts":{"key_phrases":["Neologism Learning","Controllability","Self","new words","a new word","arXiv251008506v1 Announce Type","new Abstract","Humans","a rising demand","a new useful concept"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neologism Learning":2.0,"Controllability":2.0,"Self":2.0,"new words":2.0,"a new word":2.0,"arXiv251008506v1 Announce Type":1.0,"new Abstract":1.0,"Humans":1.0,"a rising demand":1.0,"a new useful concept":1.0}},"age_hours":2.7763884908333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9087,"joy":0.0273,"surprise":0.0442,"sadness":0.0021,"fear":0.004,"anger":0.0095,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on improving LLM control and understanding through neologism learning. While the research is innovative, it is at a very early stage (basic research) and lacks concrete deployment or measurable outcomes related to sustainability. The potential impact on sustainability is currently theoretical and indirect.","key_impact_metrics":[],"technology_tags":["Large Language Models","Neologism Learning","AI Control"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:46:04.350746Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ad17238b7979","title":"MoA-VR: A Mixture-of-Agents System Towards All","content":"arXiv:2510.08508v1 Announce Type: new Abstract: Real-world videos often suffer from complex degradations, such as noise, compression artifacts, and low-light distortions, due to diverse acquisition and transmission conditions. Existing restoration methods typically require professional manual selection of specialized models or rely on monolithic architectures that fail to generalize across varying degradations. Inspired by expert experience, we propose MoA-VR, the first \\underline{M}ixture-\\underline{o}f-\\underline{A}gents \\underline{V}ideo \\underline{R}estoration system that mimics the reasoning and processing procedures of human professionals through three coordinated agents: Degradation Identification, Routing and Restoration, and Restoration Quality Assessment. Specifically, we construct a large-scale and high-resolution video degradation recognition benchmark and build a vision-language model (VLM) driven degradation identifier. We further introduce a self-adaptive router powered by large language models (LLMs), which autonomously learns effective restoration strategies by observing tool usage patterns. To assess intermediate and final processed video quality, we construct the \\underline{Res}tored \\underline{V}ideo \\underline{Q}uality (Res-VQ) dataset and design a dedicated VLM-based video quality assessment (VQA) model tailored for restoration tasks. Extensive experiments demonstrate that MoA-VR effectively handles diverse and compound degradations, consistently outperforming existing baselines in terms of both objective metrics and perceptual quality. These results highlight the potential of integrating multimodal intelligence and modular reasoning in general-purpose video restoration systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08508","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.323519","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Lu Liu, Chunlei Cai, Shaocheng Shen, Jianfeng Liang, Weimin Ouyang, Tianxiao Ye, Jian Mao, Huiyu Duan, Jiangchao Yao, Xiaoyun Zhang, Qiang Hu, Guangtao Zhai","raw_content_length":1730,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Restoration Quality Assessment","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1729,"language_detected":"en","key_concepts":{"key_phrases":["MoA-VR","Agents","All","arXiv251008508v1","Announce Type","new Abstract","Real-world videos","complex degradations","noise","compression artifacts"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MoA-VR":3.0,"Agents":2.0,"All":2.0,"arXiv251008508v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Real-world videos":1.0,"complex degradations":1.0,"noise":1.0,"compression artifacts":1.0}},"age_hours":2.776402560555556,"is_recent":true,"quality_score":1.0,"sentiment_score":0.842,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8316,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7931,"joy":0.0036,"surprise":0.044,"sadness":0.0658,"fear":0.0333,"anger":0.0177,"disgust":0.0425},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel AI system (MoA-VR) for video restoration. While it shows promise in improving video quality, its direct impact on climate change is limited. The system is currently in the applied research stage, with no mention of deployment or economic viability.","key_impact_metrics":["Objective metrics improvement","Perceptual quality improvement"],"technology_tags":["AI","Video Restoration","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:06.989403Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_392f4b7f5e8d","title":"To Sink or Not to Sink: Visual Information Pathways in Large Vision","content":"arXiv:2510.08510v1 Announce Type: new Abstract: Large Vision Language Models (LVLMs) have recently emerged as powerful architectures capable of understanding and reasoning over both visual and textual information. These models typically rely on two key components: a Vision Transformer (ViT) and a Large Language Model (LLM). ViT encodes visual content into a sequence of image tokens and serves as the perceptual front-end -- the eyes of the model. In contrast, the LLM interprets these tokens to perform high-level reasoning, generates responses, and functions as the cognitive core -- the brain of the model. However, it remains unclear which visual tokens contribute most significantly to understanding and reasoning, and how effectively these signals are propagated from ViT to the LLM. While most existing works have focused on identifying attention sinks, low-semantic tokens receiving disproportionately high attention, within the LLM, we shift the focus to the vision encoder by identifying a class of high-norm visual tokens from ViT, referred to as ViT attention sinks -- a problem that has been rarely studied but is indeed very important for LVLMs. Our findings show that these ViT sinks encapsulate high-level semantic concepts from images, allowing the LLM to perform more effective understanding and reasoning. Despite their importance, these sink tokens are often overlooked in existing LVLM architectures. To explore their contribution, we present both qualitative and quantitative analyses of the information embedded in these sink tokens. We also propose both training-free and training-based approaches to better leverage how this information is interpreted by the LLM, and to what extent. By explicitly utilizing these tokens, we demonstrate substantial improvements across a range of LVLMs and visual reasoning tasks, highlighting the untapped potential of ViT attention sinks in enhancing visual reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08510","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.323946","language":"en","tags":["computer-science","preprints","csai","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":284,"author":"Jiayun Luo, Wan-Cyuan Fan, Lyuyang Wang, Xiangteng He, Tanzila Rahman, Purang Abolmaesumi, Leonid Sigal","raw_content_length":1931,"priority":7,"update_frequency":1,"reading_time_minutes":1.42,"robust_parsing_used":true,"entities":{"organizations":["LLM","Vision Transformer","ViT","Large Vision"],"persons":["Announce Type","a Large Language Model"],"locations":[],"monetary":[]},"char_count":1930,"language_detected":"en","key_concepts":{"key_phrases":["Sink","Visual Information Pathways","Large Vision","ViT","arXiv251008510v1","Announce Type","new Abstract","Large Vision Language Models","LVLMs","powerful architectures"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sink":2.0,"Visual Information Pathways":2.0,"Large Vision":2.0,"ViT":2.0,"arXiv251008510v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Large Vision Language Models":1.0,"LVLMs":1.0,"powerful architectures":1.0}},"age_hours":2.7764178677777775,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8555,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8792,"joy":0.0046,"surprise":0.0241,"sadness":0.0064,"fear":0.0436,"anger":0.0213,"disgust":0.0208},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the efficiency of Large Vision Language Models (LVLMs) by identifying and leveraging 'ViT attention sinks'. While the research shows potential for improving the performance of these models, there are no concrete deployments or measurable outcomes related to sustainability. The impact on sustainability is indirect, potentially reducing energy consumption of AI models, but this is not quantified.","key_impact_metrics":["Improvements across a range of LVLMs and visual reasoning tasks"],"technology_tags":["Large Vision Language Models","Vision Transformer","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:46:09.825395Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cb29d19f564d","title":"AutoMLGen: Navigating Fine","content":"arXiv:2510.08511v1 Announce Type: new Abstract: Large language models (LLMs) have shown impressive performance in general programming tasks. However, in Machine Learning Engineering (MLE) scenarios such as AutoML and Kaggle competitions, achieving high performance depends heavily on expert intervention and repeated adjustments rather than simply generating correct code. When applied directly to these tasks, LLMs often lack fine-grained domain priors, and existing MLE approaches that use linear or tree-structured searches limit knowledge transfer to adjacent hierarchical links. As a result, they cannot leverage past full trajectories or share information across branches, limiting self-evolving ability and search space diversity. To address these limitations, we introduce AutoMLGen, an LLM-based coding agent that integrates a domain knowledge base for high-quality prior guidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS retains the tree-guided exploration of MCTS while embedding a graph structure into the expansion stage to enable dynamic path reorganization, historical trajectory reuse, and multi-solution fusion to support both self-evolution and collaborative learning. Combined with fine-grained operator sets, this design improves stability and accelerates convergence. Evaluation on the MLE-Bench shows that AutoMLGen achieves state-of-the-art performance in numerous dimensions, such as the average medal rate and the valid submission rate, under a 12-hour budget (half the standard runtime). The code is available at https://github.com/Alpha-Innovator/InternAgent.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08511","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.324351","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Shangheng Du, Xiangchao Yan, Dengyang Jiang, Jiakang Yuan, Yusong Hu, Xin Li, Liang He, Bo Zhang, Lei Bai","raw_content_length":1614,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["LLM","Machine Learning Engineering","MLE"],"persons":["Kaggle","Monte Carlo Graph Search"],"locations":[],"monetary":[]},"char_count":1613,"language_detected":"en","key_concepts":{"key_phrases":["AutoMLGen","Navigating Fine","LLMs","arXiv251008511v1 Announce Type","new Abstract","Large language models","impressive performance","general programming tasks","MLE","AutoML and Kaggle competitions"],"filter_categories":{"ai_ml":["AutoMLGen","Large language models"],"engineering":["general programming tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AutoMLGen":2.0,"Navigating Fine":2.0,"LLMs":2.0,"arXiv251008511v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"impressive performance":1.0,"general programming tasks":1.0,"MLE":1.0,"AutoML and Kaggle competitions":1.0}},"age_hours":2.7764324255555555,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8997,"joy":0.0138,"surprise":0.0492,"sadness":0.0098,"fear":0.0099,"anger":0.0104,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"AutoMLGen shows state-of-the-art performance on MLE-Bench, improving average medal rate and valid submission rate under a 12-hour budget. This is a pilot-proven technology, but it is still in the research phase with no clear path to economic viability or large-scale deployment. The impact on climate change is indirect, potentially improving the efficiency of machine learning models used in climate-related applications.","key_impact_metrics":["average medal rate","valid submission rate"],"technology_tags":["AutoML","Machine Learning","Monte Carlo Graph Search"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:12.691057Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_00d48bcf8311","title":"Have We Scene It All? Scene Graph","content":"arXiv:2510.08512v1 Announce Type: new Abstract: Efficient transmission of 3D point cloud data is critical for advanced perception in centralized and decentralized multi-agent robotic systems, especially nowadays with the growing reliance on edge and cloud-based processing. However, the large and complex nature of point clouds creates challenges under bandwidth constraints and intermittent connectivity, often degrading system performance. We propose a deep compression framework based on semantic scene graphs. The method decomposes point clouds into semantically coherent patches and encodes them into compact latent representations with semantic-aware encoders conditioned by Feature-wise Linear Modulation (FiLM). A folding-based decoder, guided by latent features and graph node attributes, enables structurally accurate reconstruction. Experiments on the SemanticKITTI and nuScenes datasets show that the framework achieves state-of-the-art compression rates, reducing data size by up to 98% while preserving both structural and semantic fidelity. In addition, it supports downstream applications such as multi-robot pose graph optimization and map merging, achieving trajectory accuracy and map alignment comparable to those obtained with raw LiDAR scans.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08512","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.324756","language":"en","tags":["csro","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Nikolaos Stathoulopoulos, Christoforos Kanellakis, George Nikolakopoulos","raw_content_length":1265,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["Linear Modulation (FiLM"],"persons":["Scene Graph arXiv:2510.08512v1 Announce Type"],"locations":["node"],"monetary":[]},"char_count":1264,"language_detected":"en","key_concepts":{"key_phrases":["All","Scene Graph","Announce Type","new Abstract","Efficient transmission","3D point cloud data","advanced perception","centralized and decentralized multi-agent robotic systems","the growing reliance","edge"],"filter_categories":{"engineering":["edge"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"All":2.0,"Scene Graph":2.0,"Announce Type":1.0,"new Abstract":1.0,"Efficient transmission":1.0,"3D point cloud data":1.0,"advanced perception":1.0,"centralized and decentralized multi-agent robotic systems":1.0,"the growing reliance":1.0,"edge":1.0}},"age_hours":2.7764464133333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8852,"joy":0.0042,"surprise":0.0663,"sadness":0.0102,"fear":0.0102,"anger":0.0154,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a deep compression framework for 3D point cloud data, achieving up to 98% data size reduction while preserving structural and semantic fidelity. This could reduce energy consumption in data transmission and processing for robotic systems. However, it is currently in the research phase with experiments on datasets, not deployed units.","key_impact_metrics":["data size reduction by up to 98%"],"technology_tags":["deep compression","semantic scene graphs","point cloud processing"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-28T20:46:15.466096Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bc5c36621c0a","title":"SliceFine: The Universal Winning","content":"arXiv:2510.08513v1 Announce Type: new Abstract: This paper presents a theoretical framework explaining why fine tuning small, randomly selected subnetworks (slices) within pre trained models can be sufficient for downstream adaptation. We prove that pretrained networks exhibit a universal winning slice property arising from two phenomena: (1) spectral balance the eigenspectra of different weight matrix slices are remarkably similar; and (2) high task energy their backbone representations retain rich, task relevant features. This leads to the Universal Winning Slice Hypothesis, which provides a theoretical foundation for parameter efficient fine tuning (PEFT) in large scale models. Inspired by this, we propose SliceFine, a PEFT method that exploits this inherent redundancy by updating only selected slices of the original weights introducing zero new parameters, unlike adapter-based approaches. Empirically, SliceFine matches the performance of state of the art PEFT methods across language and vision tasks, while significantly improving training speed, memory efficiency, and model compactness. Our work bridges theory and practice, offering a theoretically grounded alternative to existing PEFT techniques.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08513","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.325137","language":"en","tags":["cscl","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Md Kowsher, Ali O. Polat, Ehsan Mohammady Ardehaly, Mehrdad Salehi, Zia Ghiasi, Prasanth Murali, Chen Chen","raw_content_length":1221,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["SliceFine","the Universal Winning Slice Hypothesis"],"persons":[],"locations":[],"monetary":[]},"char_count":1220,"language_detected":"en","key_concepts":{"key_phrases":["SliceFine","The Universal Winning","arXiv251008513v1 Announce Type","new Abstract","This paper","a theoretical framework","small randomly selected subnetworks","slices","pre trained models","downstream adaptation"],"filter_categories":{"ai_ml":["small randomly selected subnetworks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SliceFine":2.0,"The Universal Winning":2.0,"arXiv251008513v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"a theoretical framework":1.0,"small randomly selected subnetworks":1.0,"slices":1.0,"pre trained models":1.0,"downstream adaptation":1.0}},"age_hours":2.776460451388889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.329,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8658,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8104,"joy":0.0445,"surprise":0.1029,"sadness":0.0046,"fear":0.0069,"anger":0.0213,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel parameter-efficient fine-tuning (PEFT) method called SliceFine that reduces computational resources by updating only selected slices of weights. It matches the performance of state-of-the-art PEFT methods, while improving training speed, memory efficiency, and model compactness. The method is currently in the applied research stage, with empirical validation but no deployment.","key_impact_metrics":["training speed improvement","memory efficiency improvement"],"technology_tags":["parameter-efficient fine-tuning","deep learning","artificial intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:46:18.146389Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f4001ba3e12","title":"CaRT: Teaching LLM Agents to Know When They Know Enough","content":"arXiv:2510.08517v1 Announce Type: new Abstract: Many tasks require learned models to strategically gather relevant information over multiple rounds of interaction before actually acting on a task. Strategic information gathering requires models to know not only how to effectively acquire information, but also when to stop gathering information and make a decision, in order to avoid overthinking or getting derailed when acting. In this paper, we formalize this problem and introduce Counterfactuals and Reasoning for Termination (CaRT), an approach for teaching LLMs when to stop seeking information. To appropriately learn when to terminate, CaRT fine-tunes LLMs using counterfactual pairs of trajectories, one where termination is appropriate and a minimally modified version of the same trajectory where it is not. It trains the LLM to explain the rationale for the termination decision in either case via verbal reasoning, and imbues this capability into the base LLM via fine-tuning. We instantiate CaRT in two domains: interactive medical diagnosis and math problem solving. In both domains, we find that CaRT improves the efficiency of information gathering and task success rate compared to other fine-tuning methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08517","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.325540","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Grace Liu, Yuxiao Qu, Jeff Schneider, Aarti Singh, Aviral Kumar","raw_content_length":1229,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["LLM","CaRT"],"persons":[],"locations":[],"monetary":[]},"char_count":1228,"language_detected":"en","key_concepts":{"key_phrases":["CaRT","LLM Agents","information","new Abstract","Many tasks","learned models","relevant information","multiple rounds","interaction","a task"],"filter_categories":{"ai_ml":["LLM Agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CaRT":2.0,"LLM Agents":2.0,"information":2.0,"new Abstract":1.0,"Many tasks":1.0,"learned models":1.0,"relevant information":1.0,"multiple rounds":1.0,"interaction":1.0,"a task":1.0}},"age_hours":2.776474988611111,"is_recent":true,"quality_score":1.0,"sentiment_score":1.125,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.775,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8373,"joy":0.0088,"surprise":0.0155,"sadness":0.0164,"fear":0.0856,"anger":0.0271,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (CaRT) for improving the efficiency of LLMs in information gathering tasks, specifically in medical diagnosis and math problem solving. The concrete action is fine-tuning LLMs using counterfactual pairs of trajectories. Evidence supporting claims includes improved efficiency of information gathering and task success rate compared to other fine-tuning methods, though specific metrics are not provided. This is currently in the applied research stage, with no mention of real-world deployment.","key_impact_metrics":["efficiency of information gathering","task success rate"],"technology_tags":["LLM","fine-tuning","counterfactual reasoning"],"sdg_alignment":[3,4,9],"analyzed_at":"2025-10-28T20:46:20.954959Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f38519e885a7","title":"DYNAMIX: RL","content":"arXiv:2510.08522v1 Announce Type: new Abstract: Existing batch size selection approaches in dis- tributed machine learning rely on static allocation or simplistic heuristics that fail to adapt to heterogeneous, dynamic computing environments. We present DYNAMIX, a reinforcement learning framework that formulates batch size optimization as a sequen- tial decision-making problem using Proximal Policy Optimiza- tion (PPO). Our approach employs a multi-dimensional state representation encompassing network-level metrics, system-level resource utilization, and training statistical efficiency indicators to enable informed decision-making across diverse computational resources. Our approach eliminates the need for explicit system modeling while integrating seamlessly with existing distributed training frameworks. Through evaluations across diverse work- loads, hardware configurations, and network conditions, DY- NAMIX achieves up to 6.3% improvement in the final model accuracy and 46% reduction in the total training time. Our scalability experiments demonstrate that DYNAMIX maintains the best performance as cluster size increases to 32 nodes, while policy transfer experiments show that learned policies generalize effectively across related model architectures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08522","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.326291","language":"en","tags":["csdc","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Yuanjun Dai, Keqiang He, An Wang","raw_content_length":1273,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["PPO","NAMIX"],"persons":["DYNAMIX","Announce Type"],"locations":[],"monetary":[]},"char_count":1272,"language_detected":"en","key_concepts":{"key_phrases":["DYNAMIX","Announce Type","new Abstract","Existing batch size selection approaches","tributed machine learning","static allocation","simplistic heuristics","heterogeneous dynamic computing environments","a reinforcement learning framework","batch size optimization"],"filter_categories":{"ai_ml":["tributed machine learning","a reinforcement learning framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DYNAMIX":3.0,"Announce Type":1.0,"new Abstract":1.0,"Existing batch size selection approaches":1.0,"tributed machine learning":1.0,"static allocation":1.0,"simplistic heuristics":1.0,"heterogeneous dynamic computing environments":1.0,"a reinforcement learning framework":1.0,"batch size optimization":1.0}},"age_hours":2.776502445555556,"is_recent":true,"quality_score":1.0,"sentiment_score":3.75,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.25,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7233,"joy":0.0057,"surprise":0.0207,"sadness":0.0287,"fear":0.1096,"anger":0.0595,"disgust":0.0525},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a reinforcement learning framework (DYNAMIX) that optimizes batch size selection in distributed machine learning, leading to a 46% reduction in training time and a 6.3% improvement in model accuracy. This could reduce energy consumption associated with training large AI models. However, it is still in the research phase with no deployed units or customer contracts.","key_impact_metrics":["46% reduction in the total training time","6.3% improvement in the final model accuracy"],"technology_tags":["Reinforcement Learning","Distributed Machine Learning","Batch Size Optimization"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-28T20:46:23.755646Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e27484ec7ac1","title":"Which Heads Matter for Reasoning? RL","content":"arXiv:2510.08525v1 Announce Type: new Abstract: Reasoning large language models exhibit complex reasoning behaviors through the extended chain-of-thought generation, creating unprecedented Key-Value (KV) cache overhead during the decoding phase. Existing KV cache compression methods underperform on reasoning models: token-dropping methods break reasoning integrity by discarding critical information, while head-reallocating methods mistakenly compress reasoning-critical heads since they are designed for retrieval tasks, resulting in significant performance degradation as compression rates increase. We hypothesize that KV heads exhibit functional heterogeneity in reasoning models-some heads are critical for chain-of-thought consistency while others are compressible. To validate and exploit this insight, we propose RLKV, a novel reasoning-critical head identification framework, which uses reinforcement learning to directly optimize the relationship between each head's cache usage and reasoning quality. As RLKV produces rewards from actual generated samples during training, it naturally identifies heads relevant to reasoning behaviors. We then allocate full KV cache to these heads while applying compressed constant KV cache to others for efficient inference. Our experiments reveal that only a small fraction of attention heads is essential for reasoning, enabling our KV compression approach to outperform baseline methods while achieving 20-50% cache reduction with near lossless performance compared to uncompressed results.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08525","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.327061","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Wenjie Du, Li Jiang, Keda Tao, Xue Liu, Huan Wang","raw_content_length":1544,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Key-Value"],"persons":["RL arXiv:2510.08525v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1543,"language_detected":"en","key_concepts":{"key_phrases":["Which","Reasoning","arXiv251008525v1 Announce Type","new Abstract","Reasoning large language models","complex reasoning behaviors","thought","unprecedented Key-Value KV cache","the decoding phase","Existing KV cache compression methods"],"filter_categories":{"ai_ml":["Reasoning large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Which":2.0,"Reasoning":2.0,"arXiv251008525v1 Announce Type":1.0,"new Abstract":1.0,"Reasoning large language models":1.0,"complex reasoning behaviors":1.0,"thought":1.0,"unprecedented Key-Value KV cache":1.0,"the decoding phase":1.0,"Existing KV cache compression methods":1.0}},"age_hours":2.7765298483333334,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6919,"joy":0.0026,"surprise":0.0271,"sadness":0.0121,"fear":0.0566,"anger":0.1115,"disgust":0.0982},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (RLKV) for compressing large language models, specifically focusing on reducing the KV cache overhead during reasoning tasks. The concrete action is the development of a reinforcement learning framework to identify and prioritize reasoning-critical heads, allowing for selective compression. The evidence supporting the claims comes from experiments showing a 20-50% cache reduction with near lossless performance compared to uncompressed results, but this is currently at the research stage.","key_impact_metrics":["20-50% cache reduction"],"technology_tags":["Large Language Models","Reinforcement Learning","KV Cache Compression"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:26.535307Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_94c81dc59635","title":"CoMAS: Co","content":"arXiv:2510.08529v1 Announce Type: new Abstract: Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evolution mechanisms observed in human intelligence, where individuals learn and improve through mutual discussion and collaboration. In this work, we introduce Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents to improve autonomously by learning from inter-agent interactions without external supervision. CoMAS generates intrinsic rewards from rich discussion dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and optimizes each agent's policy through RL, thereby enabling decentralized and scalable co-evolution. Experimental results demonstrate that CoMAS consistently outperforms untrained agents and achieves state-of-the-art performance across most evaluation settings. Ablation studies confirm the necessity of interaction-based reward signals and reveal promising scalability as the number and diversity of agents increase. These findings establish CoMAS as a novel and effective paradigm for self-evolution in LLM-based agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08529","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.328215","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Xiangyuan Xue, Yifan Zhou, Guibin Zhang, Zaibin Zhang, Yijiang Li, Chen Zhang, Zhenfei Yin, Philip Torr, Wanli Ouyang, Lei Bai","raw_content_length":1473,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Co arXiv:2510.08529v1 Announce Type","Co-Evolving Multi-Agent Systems (CoMAS"],"persons":[],"locations":[],"monetary":[]},"char_count":1472,"language_detected":"en","key_concepts":{"key_phrases":["CoMAS Co","arXiv251008529v1 Announce Type","new Abstract","Self-evolution","a central research topic","large language model","LLM-based agents","their capabilities","Recent research","a transition"],"filter_categories":{"research_academic":["a central research topic","Recent research"],"ai_ml":["large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CoMAS Co":2.0,"arXiv251008529v1 Announce Type":1.0,"new Abstract":1.0,"Self-evolution":1.0,"a central research topic":1.0,"large language model":1.0,"LLM-based agents":1.0,"their capabilities":1.0,"Recent research":1.0,"a transition":1.0}},"age_hours":2.7765724152777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9068,"joy":0.0164,"surprise":0.0524,"sadness":0.0053,"fear":0.0059,"anger":0.0089,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (CoMAS) for improving LLM-based agents through inter-agent interactions. While the experimental results show improved performance compared to untrained agents, there are no concrete deployments or quantified environmental benefits mentioned. The technology is still in the applied research phase, lacking real-world validation and economic viability data.","key_impact_metrics":["State-of-the-art performance across most evaluation settings"],"technology_tags":["Large Language Models","Reinforcement Learning","Multi-Agent Systems"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:46:29.290744Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_07797c4160b4","title":"X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering","content":"arXiv:2510.08530v1 Announce Type: new Abstract: We present X2Video, the first diffusion model for rendering photorealistic videos guided by intrinsic channels including albedo, normal, roughness, metallicity, and irradiance, while supporting intuitive multi-modal controls with reference images and text prompts for both global and local regions. The intrinsic guidance allows accurate manipulation of color, material, geometry, and lighting, while reference images and text prompts provide intuitive adjustments in the absence of intrinsic information. To enable these functionalities, we extend the intrinsic-guided image generation model XRGB to video generation by employing a novel and efficient Hybrid Self-Attention, which ensures temporal consistency across video frames and also enhances fidelity to reference images. We further develop a Masked Cross-Attention to disentangle global and local text prompts, applying them effectively onto respective local and global regions. For generating long videos, our novel Recursive Sampling method incorporates progressive frame sampling, combining keyframe prediction and frame interpolation to maintain long-range temporal consistency while preventing error accumulation. To support the training of X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154 rooms from 295 interior scenes, complete with reliable ground-truth intrinsic channel sequences and smooth camera trajectories. Both qualitative and quantitative evaluations demonstrate that X2Video can produce long, temporally consistent, and photorealistic videos guided by intrinsic conditions. Additionally, X2Video effectively accommodates multi-modal controls with reference images, global and local text prompts, and simultaneously supports editing on color, material, geometry, and lighting through parametric tuning. Project page: https://luckyhzt.github.io/x2video","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08530","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.328645","language":"en","tags":["csgr","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Zhitong Huang, Mohan Zhang, Renhan Wang, Rui Tang, Hao Zhu, Jing Liao","raw_content_length":1902,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering arXiv:2510.08530v1","Masked Cross-Attention"],"persons":["Hybrid Self-Attention"],"locations":[],"monetary":[]},"char_count":1901,"language_detected":"en","key_concepts":{"key_phrases":["X2Video Adapting Diffusion Models","Multimodal Controllable Neural Video Rendering","reference images","text prompts","arXiv251008530v1 Announce Type","new Abstract","X2Video","the first diffusion model","photorealistic videos","intrinsic channels"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"X2Video Adapting Diffusion Models":2.0,"Multimodal Controllable Neural Video Rendering":2.0,"reference images":2.0,"text prompts":2.0,"arXiv251008530v1 Announce Type":1.0,"new Abstract":1.0,"X2Video":1.0,"the first diffusion model":1.0,"photorealistic videos":1.0,"intrinsic channels":1.0}},"age_hours":2.7765867797222223,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8894,"joy":0.0347,"surprise":0.0483,"sadness":0.0036,"fear":0.0064,"anger":0.0119,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel diffusion model for video rendering. While the technology itself doesn't directly address climate change, it could potentially reduce the need for physical prototyping or travel for visualization purposes in the future, leading to indirect emissions reductions. The technical credibility is relatively high due to the quantitative evaluations and novel methods, but deployment readiness is low as it is still in the early stages of development.","key_impact_metrics":["1,154 rooms from 295 interior scenes (dataset size)"],"technology_tags":["diffusion models","video rendering","neural networks","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:32.312821Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fdd4ecb11473","title":"SpatialLadder: Progressive Training for Spatial Reasoning in Vision","content":"arXiv:2510.08531v1 Announce Type: new Abstract: Spatial reasoning remains a fundamental challenge for Vision-Language Models (VLMs), with current approaches struggling to achieve robust performance despite recent advances. We identify that this limitation stems from a critical gap: existing methods attempt to learn spatial reasoning directly without establishing the hierarchical foundations of perception and understanding. To address this challenge, we present a comprehensive methodology for building spatial intelligence progressively. We introduce SpatialLadder-26k, a multimodal dataset containing 26,610 samples spanning object localization, single image, multi-view, and video spatial reasoning tasks, constructed through a standardized pipeline that ensures systematic coverage across modalities. Building on this dataset, we design a three-stage progressive training framework that (1) establishes spatial perception through object localization, (2) develops spatial understanding through multi-dimensional spatial tasks, and (3) strengthens complex reasoning via reinforcement learning with verifiable rewards. This approach yields SpatialLadder, a 3B-parameter model that achieves state-of-the-art performance on spatial reasoning benchmarks, with 23.4% average improvement over the base model, surpassing GPT-4o by 20.8% and Gemini-2.0-Flash by 10.1%. Notably, SpatialLadder maintains strong generalization with 7.2% improvement on out-of-domain benchmarks, demonstrating that progressive training from perception to reasoning is essential for robust spatial intelligence.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08531","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.329040","language":"en","tags":["computer-science","preprints","csai","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Hongxing Li, Dingming Li, Zixuan Wang, Yuchen Yan, Hang Wu, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang","raw_content_length":1588,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Vision-Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1587,"language_detected":"en","key_concepts":{"key_phrases":["SpatialLadder","Progressive Training","Spatial Reasoning","Vision","Announce Type","new Abstract","Spatial reasoning","a fundamental challenge","Vision-Language Models","VLMs"],"filter_categories":{"ai_ml":["Progressive Training","Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SpatialLadder":2.0,"Progressive Training":2.0,"Spatial Reasoning":2.0,"Vision":2.0,"Announce Type":1.0,"new Abstract":1.0,"Spatial reasoning":1.0,"a fundamental challenge":1.0,"Vision-Language Models":1.0,"VLMs":1.0}},"age_hours":2.7766001755555556,"is_recent":true,"quality_score":1.0,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6292,"joy":0.0042,"surprise":0.0096,"sadness":0.032,"fear":0.2178,"anger":0.0583,"disgust":0.0489},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new AI model (SpatialLadder) and training methodology for improved spatial reasoning in vision models. While the model shows significant performance improvements on benchmarks, its direct climate impact is currently minimal as it's in the early stages of development and not directly tied to a specific climate technology deployment. The vaporware flag is set because it's a prototype with no deployed units or customer contracts.","key_impact_metrics":["23.4% average improvement over the base model","7.2% improvement on out-of-domain benchmarks"],"technology_tags":["Vision-Language Models","Spatial Reasoning","Reinforcement Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:46:35.421660Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b70c030c4cf5","title":"Kontinuous Kontext: Continuous Strength Control for Instruction","content":"arXiv:2510.08532v1 Announce Type: new Abstract: Instruction-based image editing offers a powerful and intuitive way to manipulate images through natural language. Yet, relying solely on text instructions limits fine-grained control over the extent of edits. We introduce Kontinuous Kontext, an instruction-driven editing model that provides a new dimension of control over edit strength, enabling users to adjust edits gradually from no change to a fully realized result in a smooth and continuous manner. Kontinuous Kontext extends a state-of-the-art image editing model to accept an additional input, a scalar edit strength which is then paired with the edit instruction, enabling explicit control over the extent of the edit. To inject this scalar information, we train a lightweight projector network that maps the input scalar and the edit instruction to coefficients in the model's modulation space. For training our model, we synthesize a diverse dataset of image-edit-instruction-strength quadruplets using existing generative models, followed by a filtering stage to ensure quality and consistency. Kontinuous Kontext provides a unified approach for fine-grained control over edit strength for instruction driven editing from subtle to strong across diverse operations such as stylization, attribute, material, background, and shape changes, without requiring attribute-specific training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08532","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.329449","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Rishubh Parihar, Or Patashnik, Daniil Ostashev, R. Venkatesh Babu, Daniel Cohen-Or, Kuan-Chieh Wang","raw_content_length":1398,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Kontinuous Kontext","Continuous Strength Control for Instruction arXiv:2510.08532v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1397,"language_detected":"en","key_concepts":{"key_phrases":["Kontinuous Kontext","Continuous Strength Control","Instruction","edits","arXiv251008532v1 Announce Type","new Abstract","Instruction-based image editing","a powerful and intuitive way","images","natural language"],"filter_categories":{"ai_ml":["natural language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Kontinuous Kontext":3.0,"Continuous Strength Control":2.0,"Instruction":2.0,"edits":2.0,"arXiv251008532v1 Announce Type":1.0,"new Abstract":1.0,"Instruction-based image editing":1.0,"a powerful and intuitive way":1.0,"images":1.0,"natural language":1.0}},"age_hours":2.7766147055555557,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8591,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9088,"joy":0.011,"surprise":0.0191,"sadness":0.0033,"fear":0.0291,"anger":0.0161,"disgust":0.0126},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for image editing using natural language, offering finer control over the edit strength. However, it is currently in the applied research stage, with no deployed units or measured outcomes related to sustainability. The impact on climate or other sustainability dimensions is minimal and theoretical at this point.","key_impact_metrics":[],"technology_tags":["image editing","natural language processing","AI"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:46:38.164036Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38dea22de35c","title":"On the optimization dynamics of RLVR: Gradient gap and step size thresholds","content":"arXiv:2510.08539v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), which uses simple binary feedback to post-train large language models, has shown significant empirical success. However, a principled understanding of why it works has been lacking. This paper builds a theoretical foundation for RLVR by analyzing its training process at both the full-response (trajectory) and token levels. Central to our analysis is a quantity called the Gradient Gap, which formalizes the direction of improvement from low-reward to high-reward regions of the response space. We prove that convergence critically depends on aligning the update direction with this Gradient Gap. Moreover, we derive a sharp step-size threshold based on the magnitude of the Gradient Gap: below it, learning converges, whereas above it, performance collapses. Our theory further predicts how the critical step size must scale with response length and the success rate, thereby explaining why practical heuristics such as length normalization improve stability and showing that, with a fixed learning rate, the success rate can stagnate strictly below $100\\%$. We validate these predictions through controlled bandit simulations and LLM experiments, including training Qwen2.5-7B with GRPO.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08539","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.330211","language":"en","tags":["mathit","statml","mathoc","computer-science","cslg","csai","preprints","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Joe Suk, Yaqi Duan","raw_content_length":1294,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1293,"language_detected":"en","key_concepts":{"key_phrases":["RLVR","the optimization dynamics","Gradient gap","step size","arXiv251008539v1 Announce Type","new Abstract","Reinforcement Learning","Verifiable Rewards","which","simple binary feedback"],"filter_categories":{"ai_ml":["Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RLVR":4.0,"the optimization dynamics":2.0,"Gradient gap":2.0,"step size":2.0,"arXiv251008539v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement Learning":1.0,"Verifiable Rewards":1.0,"which":1.0,"simple binary feedback":1.0}},"age_hours":2.776643396388889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.531,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9062,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9273,"joy":0.017,"surprise":0.0201,"sadness":0.0041,"fear":0.0094,"anger":0.0139,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical analysis of Reinforcement Learning with Verifiable Rewards (RLVR) and validates predictions through simulations and LLM experiments. While the research shows potential for improving LLM training, it's still in the early stages of development with no concrete deployment or measurable environmental impact yet. The research has peer review and uses metrics like gradient gap and step size thresholds.","key_impact_metrics":["Gradient Gap magnitude","Step-size threshold"],"technology_tags":["Reinforcement Learning","Large Language Models","AI Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:46:50.075935Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eb5b78064f48","title":"VideoNorms: Benchmarking Cultural Awareness of Video Language Models","content":"arXiv:2510.08543v1 Announce Type: new Abstract: As Video Large Language Models (VideoLLMs) are deployed globally, they require understanding of and grounding in the relevant cultural background. To properly assess these models' cultural awareness, adequate benchmarks are needed. We introduce VideoNorms, a benchmark of over 1000 (video clip, norm) pairs from US and Chinese cultures annotated with socio-cultural norms grounded in speech act theory, norm adherence and violations labels, and verbal and non-verbal evidence. To build VideoNorms, we use a human-AI collaboration framework, where a teacher model using theoretically-grounded prompting provides candidate annotations and a set of trained human experts validate and correct the annotations. We benchmark a variety of open-weight VideoLLMs on the new dataset which highlight several common trends: 1) models performs worse on norm violation than adherence; 2) models perform worse w.r.t Chinese culture compared to the US culture; 3) models have more difficulty in providing non-verbal evidence compared to verbal for the norm adhere/violation label and struggle to identify the exact norm corresponding to a speech-act; and 4) unlike humans, models perform worse in formal, non-humorous contexts. Our findings emphasize the need for culturally-grounded video language model training - a gap our benchmark and framework begin to address.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08543","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.331028","language":"en","tags":["computer-science","preprints","csai","cscv","cscl","cscy","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Nikhil Reddy Varimalla, Yunfei Xu, Arkadiy Saakyan, Meng Fan Wang, Smaranda Muresan","raw_content_length":1400,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["VideoNorms"],"persons":[],"locations":[],"monetary":[]},"char_count":1399,"language_detected":"en","key_concepts":{"key_phrases":["VideoNorms","Benchmarking Cultural Awareness","Video Language Models","arXiv251008543v1 Announce Type","new Abstract","Video Large Language Models","VideoLLMs","understanding","the relevant cultural background","these models cultural awareness"],"filter_categories":{"ai_ml":["Video Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VideoNorms":3.0,"Benchmarking Cultural Awareness":2.0,"Video Language Models":2.0,"arXiv251008543v1 Announce Type":1.0,"new Abstract":1.0,"Video Large Language Models":1.0,"VideoLLMs":1.0,"understanding":1.0,"the relevant cultural background":1.0,"these models cultural awareness":1.0}},"age_hours":2.776672533611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9282,"joy":0.0069,"surprise":0.0366,"sadness":0.0032,"fear":0.0074,"anger":0.0121,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a benchmark dataset (VideoNorms) to assess cultural awareness in VideoLLMs. While it doesn't directly reduce GHG emissions, it addresses a potential bias in AI systems that could perpetuate inequalities and hinder equitable access to climate solutions. The dataset contains over 1000 (video clip, norm) pairs, and the research is peer-reviewed, increasing credibility.","key_impact_metrics":["1000 video clip, norm pairs"],"technology_tags":["Video Large Language Models","Cultural Awareness Benchmarking"],"sdg_alignment":[5,10,16],"analyzed_at":"2025-10-28T20:46:54.056495Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_64163a37eba4","title":"SPAD: Specialized Prefill and Decode Hardware for Disaggregated LLM Inference","content":"arXiv:2510.08544v1 Announce Type: new Abstract: Large Language Models (LLMs) have gained popularity in recent years, driving up the demand for inference. LLM inference is composed of two phases with distinct characteristics: a compute-bound prefill phase followed by a memory-bound decode phase. To efficiently serve LLMs, prior work proposes prefill-decode disaggregation to run each phase on separate hardware. However, existing hardware poorly matches the different requirements of each phase. Current datacenter GPUs and TPUs follow a more-is-better design philosophy that maximizes compute and memory resources, causing memory bandwidth underutilization in the prefill phase and compute underutilization in the decode phase. Such underutilization directly translates into increased serving costs. This paper proposes SPAD (Specialized Prefill and Decode hardware), adopting a less-is-more methodology to design specialized chips tailored to the distinct characteristics of prefill and decode phases. The proposed Prefill Chips have larger systolic arrays and use cost-effective GDDR memory, whereas the proposed Decode Chips retain high memory bandwidth but reduce compute capacity. Compared to modeled H100s, simulations show that the proposed Prefill Chips deliver 8% higher prefill performance on average at 52% lower hardware cost, while the proposed Decode Chips achieve 97% of the decode performance with 28% lower TDP. End-to-end simulations on production traces show that SPAD reduces hardware cost by 19%-41% and TDP by 2%-17% compared to modeled baseline clusters while offering the same performance. Even when models and workloads change, SPAD can reallocate either type of chip to run either phase and still achieve 11%-43% lower hardware costs, demonstrating the longevity of the SPAD design.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08544","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.331450","language":"en","tags":["csdc","csar","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":256,"author":"Hengrui Zhang, Pratyush Patel, August Ning, David Wentzlaff","raw_content_length":1815,"priority":7,"update_frequency":1,"reading_time_minutes":1.28,"robust_parsing_used":true,"entities":{"organizations":["Specialized Prefill"],"persons":["SPAD"],"locations":[],"monetary":[]},"char_count":1810,"language_detected":"en","key_concepts":{"key_phrases":["SPAD","Specialized Prefill","Decode Hardware","Disaggregated LLM Inference","LLMs","each phase","arXiv251008544v1 Announce Type","new Abstract","Large Language Models","popularity"],"filter_categories":{"ai_ml":["Disaggregated LLM Inference","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SPAD":2.0,"Specialized Prefill":2.0,"Decode Hardware":2.0,"Disaggregated LLM Inference":2.0,"LLMs":2.0,"each phase":2.0,"arXiv251008544v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"popularity":1.0}},"age_hours":2.7766876247222223,"is_recent":true,"quality_score":1.0,"sentiment_score":9.259500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8519,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9246,"joy":0.0094,"surprise":0.0371,"sadness":0.0038,"fear":0.0048,"anger":0.0137,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes specialized hardware for LLM inference, showing through simulations a reduction in hardware cost by 19%-41% and TDP by 2%-17% compared to modeled baseline clusters. The simulations provide concrete metrics, but the technology is still in the research phase without real-world deployment, impacting deployment readiness.","key_impact_metrics":["hardware cost reduction 19%-41%","TDP reduction 2%-17%"],"technology_tags":["LLM inference","specialized hardware","disaggregated computing"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:46:57.172048Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1101373c453f","title":"R2RGEN: Real","content":"arXiv:2510.08547v1 Announce Type: new Abstract: Towards the aim of generalized robotic manipulation, spatial generalization is the most fundamental capability that requires the policy to work robustly under different spatial distribution of objects, environment and agent itself. To achieve this, substantial human demonstrations need to be collected to cover different spatial configurations for training a generalized visuomotor policy via imitation learning. Prior works explore a promising direction that leverages data generation to acquire abundant spatially diverse data from minimal source demonstrations. However, most approaches face significant sim-to-real gap and are often limited to constrained settings, such as fixed-base scenarios and predefined camera viewpoints. In this paper, we propose a real-to-real 3D data generation framework (R2RGen) that directly augments the pointcloud observation-action pairs to generate real-world data. R2RGen is simulator- and rendering-free, thus being efficient and plug-and-play. Specifically, given a single source demonstration, we introduce an annotation mechanism for fine-grained parsing of scene and trajectory. A group-wise augmentation strategy is proposed to handle complex multi-object compositions and diverse task constraints. We further present camera-aware processing to align the distribution of generated data with real-world 3D sensor. Empirically, R2RGen substantially enhances data efficiency on extensive experiments and demonstrates strong potential for scaling and application on mobile manipulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08547","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.331854","language":"en","tags":["csro","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Xiuwei Xu, Angyuan Ma, Hankun Li, Bingyao Yu, Zheng Zhu, Jie Zhou, Jiwen Lu","raw_content_length":1577,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["R2RGen","Real arXiv:2510.08547v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1576,"language_detected":"en","key_concepts":{"key_phrases":["R2RGEN","arXiv251008547v1 Announce Type","new Abstract","the aim","generalized robotic manipulation","spatial generalization","the most fundamental capability","the policy","different spatial distribution","objects"],"filter_categories":{"ai_ml":["the aim"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"R2RGEN":2.0,"arXiv251008547v1 Announce Type":1.0,"new Abstract":1.0,"the aim":1.0,"generalized robotic manipulation":1.0,"spatial generalization":1.0,"the most fundamental capability":1.0,"the policy":1.0,"different spatial distribution":1.0,"objects":1.0}},"age_hours":2.7767015152777774,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8818,"joy":0.0379,"surprise":0.0261,"sadness":0.0065,"fear":0.027,"anger":0.0131,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to robot learning using real-to-real data augmentation. While the technique could potentially improve the efficiency of robotic systems in various sectors, including those relevant to sustainability (e.g., manufacturing, logistics), there are no concrete actions or measurable outcomes presented in the abstract regarding climate impact or other sustainability dimensions. The research is still in the applied research phase, with no deployed units or operational data.","key_impact_metrics":[],"technology_tags":["robotics","machine learning","data augmentation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:46:59.937475Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_66f47c20dda7","title":"ARTDECO: Towards Efficient and High-Fidelity On","content":"arXiv:2510.08551v1 Announce Type: new Abstract: On-the-fly 3D reconstruction from monocular image sequences is a long-standing challenge in computer vision, critical for applications such as real-to-sim, AR/VR, and robotics. Existing methods face a major tradeoff: per-scene optimization yields high fidelity but is computationally expensive, whereas feed-forward foundation models enable real-time inference but struggle with accuracy and robustness. In this work, we propose ARTDECO, a unified framework that combines the efficiency of feed-forward models with the reliability of SLAM-based pipelines. ARTDECO uses 3D foundation models for pose estimation and point prediction, coupled with a Gaussian decoder that transforms multi-scale features into structured 3D Gaussians. To sustain both fidelity and efficiency at scale, we design a hierarchical Gaussian representation with a LoD-aware rendering strategy, which improves rendering fidelity while reducing redundancy. Experiments on eight diverse indoor and outdoor benchmarks show that ARTDECO delivers interactive performance comparable to SLAM, robustness similar to feed-forward systems, and reconstruction quality close to per-scene optimization, providing a practical path toward on-the-fly digitization of real-world environments with both accurate geometry and high visual fidelity. Explore more demos on our project page: https://city-super.github.io/artdeco/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08551","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.332622","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Guanghao Li, Kerui Ren, Linning Xu, Zhewen Zheng, Changjian Jiang, Xin Gao, Bo Dai, Jian Pu, Mulin Yu, Jiangmiao Pang","raw_content_length":1428,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["LoD","High-Fidelity On arXiv:2510.08551v1 Announce Type","AR/VR","SLAM"],"persons":[],"locations":["ARTDECO"],"monetary":[]},"char_count":1427,"language_detected":"en","key_concepts":{"key_phrases":["ARTDECO","arXiv251008551v1 Announce Type","new Abstract","the-fly","monocular image sequences","a long-standing challenge","computer vision","applications","sim"," ARVR"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ARTDECO":3.0,"arXiv251008551v1 Announce Type":1.0,"new Abstract":1.0,"the-fly":1.0,"monocular image sequences":1.0,"a long-standing challenge":1.0,"computer vision":1.0,"applications":1.0,"sim":1.0," ARVR":1.0}},"age_hours":2.7767321005555554,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8475,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0305,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.798,"joy":0.0108,"surprise":0.0278,"sadness":0.0335,"fear":0.0663,"anger":0.0433,"disgust":0.0204},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel 3D reconstruction framework (ARTDECO) that aims to improve efficiency and fidelity compared to existing methods. While it shows promising results on benchmarks, it is still in the applied research stage with no deployed units or customer contracts. The climate impact is indirect, potentially enabling more efficient robotics and AR/VR applications, but not directly reducing emissions.","key_impact_metrics":["Interactive performance comparable to SLAM","Reconstruction quality close to per-scene optimization"],"technology_tags":["3D reconstruction","SLAM","Gaussian decoder","Foundation Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:02.823050Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0a743e9f16f","title":"Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision","content":"arXiv:2510.08553v1 Announce Type: new Abstract: Vision-and-Language Navigation (VLN) requires agents to follow natural language instructions through environments, with memory-persistent variants demanding progressive improvement through accumulated experience. Existing approaches for memory-persistent VLN face critical limitations: they lack effective memory access mechanisms, instead relying on entire memory incorporation or fixed-horizon lookup, and predominantly store only environmental observations while neglecting navigation behavioral patterns that encode valuable decision-making strategies. We present Memoir, which employs imagination as a retrieval mechanism grounded by explicit memory: a world model imagines future navigation states as queries to selectively retrieve relevant environmental observations and behavioral histories. The approach comprises: 1) a language-conditioned world model that imagines future states serving dual purposes: encoding experiences for storage and generating retrieval queries; 2) Hybrid Viewpoint-Level Memory that anchors both observations and behavioral patterns to viewpoints, enabling hybrid retrieval; and 3) an experience-augmented navigation model that integrates retrieved knowledge through specialized encoders. Extensive evaluation across diverse memory-persistent VLN benchmarks with 10 distinctive testing scenarios demonstrates Memoir's effectiveness: significant improvements across all scenarios, with 5.4% SPL gains on IR2R over the best memory-persistent baseline, accompanied by 8.3x training speedup and 74% inference memory reduction. The results validate that predictive retrieval of both environmental and behavioral memories enables more effective navigation, with analysis indicating substantial headroom (73.3% vs 93.4% upper bound) for this imagination-guided paradigm. Code at https://github.com/xyz9911/Memoir.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08553","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.333029","language":"en","tags":["csro","computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Yunzhe Xu, Yiyuan Pan, Zhe Liu","raw_content_length":1891,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["VLN","Memoir"],"persons":[],"locations":[],"monetary":[]},"char_count":1890,"language_detected":"en","key_concepts":{"key_phrases":["Dream","Recall","Imagination-Guided Experience Retrieval","Memory-Persistent Vision","Announce Type","new Abstract","Vision-and-Language Navigation","VLN","agents","natural language instructions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dream":2.0,"Recall":2.0,"Imagination-Guided Experience Retrieval":2.0,"Memory-Persistent Vision":2.0,"Announce Type":1.0,"new Abstract":1.0,"Vision-and-Language Navigation":1.0,"VLN":1.0,"agents":1.0,"natural language instructions":1.0}},"age_hours":2.7767466594444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8763,"joy":0.004,"surprise":0.036,"sadness":0.0237,"fear":0.0396,"anger":0.011,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to vision-and-language navigation using imagination-guided experience retrieval. The concrete action is the development and evaluation of the Memoir model, which shows a 5.4% SPL gain on IR2R over the best memory-persistent baseline. However, this is still in the research phase, with no clear path to economic viability or large-scale deployment, hence the low scores on those dimensions.","key_impact_metrics":["5.4% SPL gains on IR2R","8.3x training speedup"],"technology_tags":["Vision-and-Language Navigation","Artificial Intelligence","World Model"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:05.497749Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7594ab10d1dd","title":"Improving Reasoning for Diffusion Language Models via Group Diffusion Policy Optimization","content":"arXiv:2510.08554v1 Announce Type: new Abstract: Diffusion language models (DLMs) enable parallel, order-agnostic generation with iterative refinement, offering a flexible alternative to autoregressive large language models (LLMs). However, adapting reinforcement learning (RL) fine-tuning to DLMs remains an open challenge because of the intractable likelihood. Pioneering work such as diffu-GRPO estimated token-level likelihoods via one-step unmasking. While computationally efficient, this approach is severely biased. A more principled foundation lies in sequence-level likelihoods, where the evidence lower bound (ELBO) serves as a surrogate. Yet, despite this clean mathematical connection, ELBO-based methods have seen limited adoption due to the prohibitive cost of likelihood evaluation. In this work, we revisit ELBO estimation and disentangle its sources of variance. This decomposition motivates reducing variance through fast, deterministic integral approximations along a few pivotal dimensions. Building on this insight, we introduce \\textbf{Group Diffusion Policy Optimization (GDPO)}, a new RL algorithm tailored for DLMs. GDPO leverages simple yet effective Semi-deterministic Monte Carlo schemes to mitigate the variance explosion of ELBO estimators under vanilla double Monte Carlo sampling, yielding a provably lower-variance estimator under tight evaluation budgets. Empirically, GDPO achieves consistent gains over pretrained checkpoints and outperforms diffu-GRPO, one of the state-of-the-art baselines, on the majority of math, reasoning, and coding benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08554","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.333430","language":"en","tags":["statml","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Kevin Rojas, Jiahe Lin, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Molei Tao, Wei Deng","raw_content_length":1587,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Group Diffusion Policy Optimization arXiv:2510.08554v1","GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1586,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning","Diffusion Language Models","Group Diffusion Policy Optimization","DLMs","Announce Type","new Abstract","Diffusion language models","parallel order-agnostic generation","iterative refinement","a flexible alternative"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning":2.0,"Diffusion Language Models":2.0,"Group Diffusion Policy Optimization":2.0,"DLMs":2.0,"Announce Type":1.0,"new Abstract":1.0,"Diffusion language models":1.0,"parallel order-agnostic generation":1.0,"iterative refinement":1.0,"a flexible alternative":1.0}},"age_hours":2.7767620019444443,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9189,"joy":0.01,"surprise":0.0194,"sadness":0.0042,"fear":0.0165,"anger":0.0256,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new reinforcement learning algorithm (GDPO) tailored for diffusion language models, showing improved performance on math, reasoning, and coding benchmarks compared to existing methods. The concrete action is the development of a lower-variance estimator for the ELBO, which is supported by mathematical decomposition and empirical results. However, this is currently at the basic research stage with no deployed units or economic viability demonstrated.","key_impact_metrics":["Consistent gains over pretrained checkpoints","Outperforms diffu-GRPO on majority of benchmarks"],"technology_tags":["Diffusion Language Models","Reinforcement Learning","Policy Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:47:08.421779Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_923ccc1fc377","title":"VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In","content":"arXiv:2510.08555v1 Announce Type: new Abstract: We introduce the task of arbitrary spatio-temporal video completion, where a video is generated from arbitrary, user-specified patches placed at any spatial location and timestamp, akin to painting on a video canvas. This flexible formulation naturally unifies many existing controllable video generation tasks--including first-frame image-to-video, inpainting, extension, and interpolation--under a single, cohesive paradigm. Realizing this vision, however, faces a fundamental obstacle in modern latent video diffusion models: the temporal ambiguity introduced by causal VAEs, where multiple pixel frames are compressed into a single latent representation, making precise frame-level conditioning structurally difficult. We address this challenge with VideoCanvas, a novel framework that adapts the In-Context Conditioning (ICC) paradigm to this fine-grained control task with zero new parameters. We propose a hybrid conditioning strategy that decouples spatial and temporal control: spatial placement is handled via zero-padding, while temporal alignment is achieved through Temporal RoPE Interpolation, which assigns each condition a continuous fractional position within the latent sequence. This resolves the VAE's temporal ambiguity and enables pixel-frame-aware control on a frozen backbone. To evaluate this new capability, we develop VideoCanvasBench, the first benchmark for arbitrary spatio-temporal video completion, covering both intra-scene fidelity and inter-scene creativity. Experiments demonstrate that VideoCanvas significantly outperforms existing conditioning paradigms, establishing a new state of the art in flexible and unified video generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08555","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.333829","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Minghong Cai, Qiulin Wang, Zongli Ye, Wenze Liu, Quande Liu, Weicai Ye, Xintao Wang, Pengfei Wan, Kun Gai, Xiangyu Yue","raw_content_length":1720,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["VideoCanvas"],"persons":["causal VAEs"],"locations":[],"monetary":[]},"char_count":1719,"language_detected":"en","key_concepts":{"key_phrases":["VideoCanvas","Unified Video Completion","Arbitrary Spatiotemporal Patches","arXiv251008555v1 Announce Type","new Abstract","the task","arbitrary spatio-temporal video completion","a video","arbitrary user-specified patches","any spatial location"],"filter_categories":{"engineering":["Arbitrary Spatiotemporal Patches"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VideoCanvas":2.0,"Unified Video Completion":2.0,"Arbitrary Spatiotemporal Patches":2.0,"arXiv251008555v1 Announce Type":1.0,"new Abstract":1.0,"the task":1.0,"arbitrary spatio-temporal video completion":1.0,"a video":1.0,"arbitrary user-specified patches":1.0,"any spatial location":1.0}},"age_hours":2.7767773219444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.877000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5754,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8695,"joy":0.0282,"surprise":0.0635,"sadness":0.0033,"fear":0.0055,"anger":0.0225,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for video generation, but it is currently in the research stage with no deployed technology or measured outcomes related to sustainability. The technical credibility is relatively high due to the scientific approach and potential for peer review, but the lack of deployment readiness and economic viability limit its immediate sustainability impact.","key_impact_metrics":[],"technology_tags":["video generation","AI","diffusion models"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:47:11.284068Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_39ffa10cf38c","title":"DexNDM: Closing the Reality Gap for Dexterous In","content":"arXiv:2510.08556v1 Announce Type: new Abstract: Achieving generalized in-hand object rotation remains a significant challenge in robotics, largely due to the difficulty of transferring policies from simulation to the real world. The complex, contact-rich dynamics of dexterous manipulation create a \"reality gap\" that has limited prior work to constrained scenarios involving simple geometries, limited object sizes and aspect ratios, constrained wrist poses, or customized hands. We address this sim-to-real challenge with a novel framework that enables a single policy, trained in simulation, to generalize to a wide variety of objects and conditions in the real world. The core of our method is a joint-wise dynamics model that learns to bridge the reality gap by effectively fitting limited amount of real-world collected data and then adapting the sim policy's actions accordingly. The model is highly data-efficient and generalizable across different whole-hand interaction distributions by factorizing dynamics across joints, compressing system-wide influences into low-dimensional variables, and learning each joint's evolution from its own dynamic profile, implicitly capturing these net effects. We pair this with a fully autonomous data collection strategy that gathers diverse, real-world interaction data with minimal human intervention. Our complete pipeline demonstrates unprecedented generality: a single policy successfully rotates challenging objects with complex shapes (e.g., animals), high aspect ratios (up to 5.33), and small sizes, all while handling diverse wrist orientations and rotation axes. Comprehensive real-world evaluations and a teleoperation application for complex tasks validate the effectiveness and robustness of our approach. Website: https://meowuu7.github.io/DexNDM/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08556","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.334228","language":"en","tags":["csro","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Xueyi Liu, He Wang, Li Yi","raw_content_length":1810,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1809,"language_detected":"en","key_concepts":{"key_phrases":["DexNDM","the Reality Gap","arXiv251008556v1 Announce Type","new Abstract","hand","a significant challenge","robotics","the difficulty","policies","simulation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DexNDM":2.0,"the Reality Gap":2.0,"arXiv251008556v1 Announce Type":1.0,"new Abstract":1.0,"hand":1.0,"a significant challenge":1.0,"robotics":1.0,"the difficulty":1.0,"policies":1.0,"simulation":1.0}},"age_hours":2.7767922725000003,"is_recent":true,"quality_score":0.7,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8757,"joy":0.0173,"surprise":0.065,"sadness":0.0063,"fear":0.0181,"anger":0.0127,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework for dexterous manipulation, enabling a single policy to generalize to a wide variety of objects and conditions. The key action is the development of a joint-wise dynamics model that bridges the reality gap between simulation and the real world. While the approach shows promise, it's currently in the applied research stage with limited real-world deployment and no clear path to economic viability or quantified climate impact.","key_impact_metrics":["Aspect ratios up to 5.33"],"technology_tags":["robotics","dexterous manipulation","sim-to-real transfer"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:14.659880Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_82701e39247c","title":"Agent Learning via Early Experience","content":"arXiv:2510.08558v1 Announce Type: new Abstract: A long-term goal of language agents is to learn and improve through their own experience, ultimately outperforming humans in complex, real-world tasks. However, training agents from experience data with reinforcement learning remains difficult in many environments, which either lack verifiable rewards (e.g., websites) or require inefficient long-horizon rollouts (e.g., multi-turn tool use). As a result, most current agents rely on supervised fine-tuning on expert data, which is challenging to scale and generalizes poorly. This limitation stems from the nature of expert demonstrations: they capture only a narrow range of scenarios and expose the agent to limited environment diversity. We address this limitation with a middle-ground paradigm we call early experience: interaction data generated by the agent's own actions, where the resulting future states serve as supervision without reward signals. Within this paradigm we study two strategies of using such data: (1) Implicit world modeling, which uses collected states to ground the policy in environment dynamics; and (2) Self-reflection, where the agent learns from its suboptimal actions to improve reasoning and decision-making. We evaluate across eight diverse environments and multiple model families. Our approaches consistently improve effectiveness and out-of-domain generalization, highlighting the value of early experience. Moreover, in environments with verifiable rewards, our results provide promising signals that early experience offers a strong foundation for subsequent reinforcement learning, positioning it as a practical bridge between imitation learning and fully experience-driven agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08558","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.334647","language":"en","tags":["computer-science","cslg","preprints","csai","csir","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Kai Zhang, Xiangchao Chen, Bo Liu, Tianci Xue, Zeyi Liao, Zhihan Liu, Xiyao Wang, Yuting Ning, Zhaorun Chen, Xiaohan Fu, Jian Xie, Yuxuan Sun, Boyu Gou, Qi Qi, Zihang Meng, Jianwei Yang, Ning Zhang, Xian Li, Ashish Shah, Dat Huynh, Hengduo Li, Zi Yang, Sara Cao, Lawrence Jang, Shuyan Zhou, Jiacheng Zhu, Huan Sun, Jason Weston, Yu Su, Yifan Wu","raw_content_length":1724,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1723,"language_detected":"en","key_concepts":{"key_phrases":["Agent Learning","Early Experience","arXiv251008558v1 Announce Type","new Abstract","A long-term goal","language agents","their own experience","humans","complex real-world tasks","training agents"],"filter_categories":{"ai_ml":["training agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Agent Learning":2.0,"Early Experience":2.0,"arXiv251008558v1 Announce Type":1.0,"new Abstract":1.0,"A long-term goal":1.0,"language agents":1.0,"their own experience":1.0,"humans":1.0,"complex real-world tasks":1.0,"training agents":1.0}},"age_hours":2.776807173611111,"is_recent":true,"quality_score":0.7,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.724,"joy":0.0057,"surprise":0.0115,"sadness":0.0215,"fear":0.1241,"anger":0.0527,"disgust":0.0605},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a novel approach to agent learning, which could potentially lead to more efficient AI systems. While the research shows promising results in simulated environments, there are no concrete actions or measurable outcomes related to sustainability at this stage. The technology is still in the basic research phase, and economic viability and deployment readiness are low.","key_impact_metrics":["Improved effectiveness in eight diverse environments","Improved out-of-domain generalization"],"technology_tags":["Agent learning","Reinforcement learning","Artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:17.555478Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e6bd126cd70b","title":"SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models","content":"arXiv:2510.08559v1 Announce Type: new Abstract: Large Multimodal Models (LMMs) have achieved remarkable progress across various capabilities; however, complex video reasoning in the scientific domain remains a significant and challenging frontier. Current video benchmarks predominantly target general scenarios where perception/recognition is heavily relied on, while with relatively simple reasoning tasks, leading to saturation and thus failing to effectively evaluate advanced multimodal cognitive skills. To address this critical gap, we introduce SciVideoBench, a rigorous benchmark specifically designed to assess advanced video reasoning in scientific contexts. SciVideoBench consists of 1,000 carefully crafted multiple-choice questions derived from cutting-edge scientific experimental videos spanning over 25 specialized academic subjects and verified by a semi-automatic system. Each question demands sophisticated domain-specific knowledge, precise spatiotemporal perception, and intricate logical reasoning, effectively challenging models' higher-order cognitive abilities. Our evaluation highlights significant performance deficits in state-of-the-art proprietary and open-source LMMs, including Gemini 2.5 Pro and Qwen2.5-VL, indicating substantial room for advancement in video reasoning capabilities. Detailed analyses of critical factors such as reasoning complexity and visual grounding provide valuable insights and clear direction for future developments in LMMs, driving the evolution of truly capable multimodal AI co-scientists. We hope SciVideoBench could fit the interests of the community and help to push the boundary of cutting-edge AI for border science.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08559","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.335038","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Andong Deng, Taojiannan Yang, Shoubin Yu, Lincoln Spencer, Mohit Bansal, Chen Chen, Serena Yeung-Levy, Xiaohan Wang","raw_content_length":1686,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Benchmarking Scientific Video Reasoning"],"persons":[],"locations":[],"monetary":[]},"char_count":1685,"language_detected":"en","key_concepts":{"key_phrases":["Large Multimodal Models","SciVideoBench","Benchmarking Scientific Video Reasoning","new Abstract","LMMs","remarkable progress","various capabilities","complex video reasoning","the scientific domain","a significant and challenging frontier"],"filter_categories":{"ai_ml":["the scientific domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Multimodal Models":3.0,"SciVideoBench":2.0,"Benchmarking Scientific Video Reasoning":2.0,"new Abstract":1.0,"LMMs":1.0,"remarkable progress":1.0,"various capabilities":1.0,"complex video reasoning":1.0,"the scientific domain":1.0,"a significant and challenging frontier":1.0}},"age_hours":2.7768207877777775,"is_recent":true,"quality_score":1.0,"sentiment_score":9.158,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8316,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6946,"joy":0.0289,"surprise":0.2298,"sadness":0.0058,"fear":0.0179,"anger":0.0178,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article introduces a benchmark for evaluating scientific video reasoning in large multimodal models. While the benchmark itself doesn't directly reduce emissions or promote sustainability, it aims to improve AI's ability to understand and reason about scientific data, which could indirectly contribute to sustainability efforts in the future. The research is at a basic research stage, with no immediate deployment or measurable impact.","key_impact_metrics":[],"technology_tags":["Large Multimodal Models","Video Reasoning","Artificial Intelligence"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:47:20.128670Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_28ecd57c866f","title":"MultiCOIN: Multi","content":"arXiv:2510.08561v1 Announce Type: new Abstract: Video inbetweening creates smooth and natural transitions between two image frames, making it an indispensable tool for video editing and long-form video synthesis. Existing works in this domain are unable to generate large, complex, or intricate motions. In particular, they cannot accommodate the versatility of user intents and generally lack fine control over the details of intermediate frames, leading to misalignment with the creative mind. To fill these gaps, we introduce \\modelname{}, a video inbetweening framework that allows multi-modal controls, including depth transition and layering, motion trajectories, text prompts, and target regions for movement localization, while achieving a balance between flexibility, ease of use, and precision for fine-grained video interpolation. To achieve this, we adopt the Diffusion Transformer (DiT) architecture as our video generative model, due to its proven capability to generate high-quality long videos. To ensure compatibility between DiT and our multi-modal controls, we map all motion controls into a common sparse and user-friendly point-based representation as the video/noise input. Further, to respect the variety of controls which operate at varying levels of granularity and influence, we separate content controls and motion controls into two branches to encode the required features before guiding the denoising process, resulting in two generators, one for motion and the other for content. Finally, we propose a stage-wise training strategy to ensure that our model learns the multi-modal controls smoothly. Extensive qualitative and quantitative experiments demonstrate that multi-modal controls enable a more dynamic, customizable, and contextually accurate visual narrative.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08561","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.335469","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Maham Tanveer, Yang Zhou, Simon Niklaus, Ali Mahdavi Amiri, Hao Zhang, Krishna Kumar Singh, Nanxuan Zhao","raw_content_length":1798,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["Multi arXiv:2510.08561v1 Announce","DiT","the Diffusion Transformer"],"persons":[],"locations":[],"monetary":[]},"char_count":1797,"language_detected":"en","key_concepts":{"key_phrases":["MultiCOIN","Multi","arXiv251008561v1 Announce Type","new Abstract","Video inbetweening","smooth and natural transitions","two image frames","video editing","long-form video synthesis","Existing works"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MultiCOIN":2.0,"Multi":2.0,"arXiv251008561v1 Announce Type":1.0,"new Abstract":1.0,"Video inbetweening":1.0,"smooth and natural transitions":1.0,"two image frames":1.0,"video editing":1.0,"long-form video synthesis":1.0,"Existing works":1.0}},"age_hours":2.776835308888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9005,"joy":0.0097,"surprise":0.0424,"sadness":0.0211,"fear":0.0081,"anger":0.0096,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new video inbetweening framework. There are no concrete actions or measurable outcomes related to sustainability. It is in the basic research stage and lacks deployment or real-world data.","key_impact_metrics":[],"technology_tags":["video inbetweening","diffusion transformer","AI"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:47:22.527015Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_49e34fb98848","title":"ResAD: Normalized Residual Trajectory Modeling for End","content":"arXiv:2510.08562v1 Announce Type: new Abstract: End-to-end autonomous driving (E2EAD) systems, which learn to predict future trajectories directly from sensor data, are fundamentally challenged by the inherent spatio-temporal imbalance of trajectory data. This imbalance creates a significant optimization burden, causing models to learn spurious correlations instead of causal inference, while also prioritizing uncertain, distant predictions, thereby compromising immediate safety. To address these issues, we propose ResAD, a novel Normalized Residual Trajectory Modeling framework. Instead of predicting the future trajectory directly, our approach reframes the learning task to predict the residual deviation from a deterministic inertial reference. The inertial reference serves as a counterfactual, forcing the model to move beyond simple pattern recognition and instead identify the underlying causal factors (e.g., traffic rules, obstacles) that necessitate deviations from a default, inertially-guided path. To deal with the optimization imbalance caused by uncertain, long-term horizons, ResAD further incorporates Point-wise Normalization of the predicted residual. It re-weights the optimization objective, preventing large-magnitude errors associated with distant, uncertain waypoints from dominating the learning signal. Extensive experiments validate the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two denoising steps, demonstrating that our approach significantly simplifies the learning task and improves model performance. The code will be released to facilitate further research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08562","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.335872","language":"en","tags":["csro","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Zhiyu Zheng, Shaoyu Chen, Haoran Yin, Xinbang Zhang, Jialv Zou, Xinggang Wang, Qian Zhang, Lefei Zhang","raw_content_length":1704,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Normalized Residual Trajectory Modeling"],"persons":[],"locations":[],"monetary":[]},"char_count":1703,"language_detected":"en","key_concepts":{"key_phrases":["ResAD","Normalized Residual Trajectory Modeling","End","Announce Type","new Abstract","end","which","future trajectories","sensor data","the inherent spatio-temporal imbalance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ResAD":2.0,"Normalized Residual Trajectory Modeling":2.0,"End":2.0,"Announce Type":1.0,"new Abstract":1.0,"end":1.0,"which":1.0,"future trajectories":1.0,"sensor data":1.0,"the inherent spatio-temporal imbalance":1.0}},"age_hours":2.776849086388889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7447,"joy":0.0045,"surprise":0.0499,"sadness":0.0145,"fear":0.1,"anger":0.0605,"disgust":0.0258},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (ResAD) to improve autonomous driving systems, which could indirectly reduce GHG emissions by optimizing traffic flow and reducing accidents. The technical credibility is supported by experimental validation on the NAVSIM benchmark, achieving a state-of-the-art PDMS of 88.6. However, it is still in the early stages of development (applied research) with no clear path to economic viability or deployment readiness.","key_impact_metrics":["PDMS of 88.6 on NAVSIM"],"technology_tags":["autonomous driving","trajectory prediction","residual trajectory modeling"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-28T20:47:26.401269Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c799ca283ecd","title":"Where Have All the Kaczmarz Iterates Gone?","content":"arXiv:2510.08563v1 Announce Type: new Abstract: The randomized Kaczmarz (RK) algorithm is one of the most computationally and memory-efficient iterative algorithms for solving large-scale linear systems. However, practical applications often involve noisy and potentially inconsistent systems. While the convergence of RK is well understood for consistent systems, the study of RK on noisy, inconsistent linear systems is limited. This paper investigates the asymptotic behavior of RK iterates in expectation when solving noisy and inconsistent systems, addressing the locations of their limit points. We explore the roles of singular vectors of the (noisy) coefficient matrix and derive bounds on the convergence horizon, which depend on the noise levels and system characteristics. Finally, we provide extensive numerical experiments that validate our theoretical findings, offering practical insights into the algorithm's performance under realistic conditions. These results establish a deeper understanding of the RK algorithm's limitations and robustness in noisy environments, paving the way for optimized applications in real-world scientific and engineering problems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08563","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.336359","language":"en","tags":["csna","mathoc","computer-science","cslg","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"El Houcine Bergou, Soumia Boucherouite, Aritra Dutta, Xin Li, Anna Ma","raw_content_length":1177,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["linear"],"persons":["Kaczmarz","Announce Type"],"locations":[],"monetary":[]},"char_count":1176,"language_detected":"en","key_concepts":{"key_phrases":["All the Kaczmarz","Iterates","arXiv251008563v1 Announce Type","new Abstract","large-scale linear systems","practical applications","noisy and potentially inconsistent systems","the convergence","consistent systems","inconsistent linear systems"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"All the Kaczmarz":2.0,"Iterates":2.0,"arXiv251008563v1 Announce Type":1.0,"new Abstract":1.0,"large-scale linear systems":1.0,"practical applications":1.0,"noisy and potentially inconsistent systems":1.0,"the convergence":1.0,"consistent systems":1.0,"inconsistent linear systems":1.0}},"age_hours":2.7768632591666664,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8415,"joy":0.0104,"surprise":0.0896,"sadness":0.0146,"fear":0.0185,"anger":0.0167,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores the theoretical improvements to the Kaczmarz algorithm, which could potentially improve the efficiency of solving large-scale linear systems. While the algorithm itself doesn't directly impact climate change, it could improve the efficiency of computations in climate modeling or other sustainability-related fields. The research is backed by numerical experiments and theoretical bounds, providing some credibility.","key_impact_metrics":[],"technology_tags":["algorithm optimization","linear systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:29.326115Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8f2c03d14785","title":"NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints","content":"arXiv:2510.08565v1 Announce Type: new Abstract: Compositional training has been the de-facto paradigm in existing Multimodal Large Language Models (MLLMs), where pre-trained vision encoders are connected with pre-trained LLMs through continuous multimodal pre-training. However, the multimodal scaling property of this paradigm remains difficult to explore due to the separated training. In this paper, we focus on the native training of MLLMs in an end-to-end manner and systematically study its design space and scaling property under a practical setting, i.e., data constraint. Through careful study of various choices in MLLM, we obtain the optimal meta-architecture that best balances performance and training cost. After that, we further explore the scaling properties of the native MLLM and indicate the positively correlated scaling relationship between visual encoders and LLMs. Based on these findings, we propose a native MLLM called NaViL, combined with a simple and cost-effective recipe. Experimental results on 14 multimodal benchmarks confirm the competitive performance of NaViL against existing MLLMs. Besides that, our findings and results provide in-depth insights for the future study of native MLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08565","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.337154","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Changyao Tian, Hao Li, Gen Luo, Xizhou Zhu, Weijie Su, Hanming Deng, Jinguo Zhu, Jie Shao, Ziran Zhu, Yunpeng Liu, Lewei Lu, Wenhai Wang, Hongsheng Li, Jifeng Dai","raw_content_length":1223,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1222,"language_detected":"en","key_concepts":{"key_phrases":["NaViL","Scaling Properties","Native Multimodal Large Language Models","Data Constraints","MLLMs","arXiv251008565v1 Announce Type","new Abstract","Compositional training","the de-facto paradigm","existing Multimodal Large Language Models"],"filter_categories":{"ai_ml":["Native Multimodal Large Language Models","existing Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"NaViL":2.0,"Scaling Properties":2.0,"Native Multimodal Large Language Models":2.0,"Data Constraints":2.0,"MLLMs":2.0,"arXiv251008565v1 Announce Type":1.0,"new Abstract":1.0,"Compositional training":1.0,"the de-facto paradigm":1.0,"existing Multimodal Large Language Models":1.0}},"age_hours":2.7768935127777774,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8278,"joy":0.0317,"surprise":0.0281,"sadness":0.0084,"fear":0.0544,"anger":0.0343,"disgust":0.0152},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents research on improving the efficiency of multimodal large language models (MLLMs). While improved efficiency can indirectly reduce energy consumption of AI models, the article does not provide concrete evidence of reduced GHG emissions or other sustainability benefits. It's still in the research phase with experimental results but no real-world deployment.","key_impact_metrics":["Performance on 14 multimodal benchmarks","Training cost reduction"],"technology_tags":["Multimodal Large Language Models","Native Training","AI Efficiency"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-28T20:47:32.053318Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38e604bf563a","title":"D$^2$GS: Depth-and","content":"arXiv:2510.08566v1 Announce Type: new Abstract: Recent advances in 3D Gaussian Splatting (3DGS) enable real-time, high-fidelity novel view synthesis (NVS) with explicit 3D representations. However, performance degradation and instability remain significant under sparse-view conditions. In this work, we identify two key failure modes under sparse-view conditions: overfitting in regions with excessive Gaussian density near the camera, and underfitting in distant areas with insufficient Gaussian coverage. To address these challenges, we propose a unified framework D$^2$GS, comprising two key components: a Depth-and-Density Guided Dropout strategy that suppresses overfitting by adaptively masking redundant Gaussians based on density and depth, and a Distance-Aware Fidelity Enhancement module that improves reconstruction quality in under-fitted far-field areas through targeted supervision. Moreover, we introduce a new evaluation metric to quantify the stability of learned Gaussian distributions, providing insights into the robustness of the sparse-view 3DGS. Extensive experiments on multiple datasets demonstrate that our method significantly improves both visual quality and robustness under sparse view conditions. The project page can be found at: https://insta360-research-team.github.io/DDGS-website/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08566","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.337560","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Meixi Song, Xin Lin, Dizhe Zhang, Haodong Li, Xiangtai Li, Bo Du, Lu Qi","raw_content_length":1319,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["Distance-Aware","NVS"],"persons":["Gaussian Splatting"],"locations":[],"monetary":[]},"char_count":1318,"language_detected":"en","key_concepts":{"key_phrases":["D2GS Depth","sparse-view conditions","arXiv251008566v1 Announce Type","new Abstract","Recent advances","3D Gaussian Splatting","3DGS","real-time high-fidelity novel view synthesis","NVS","explicit 3D representations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"D2GS Depth":2.0,"sparse-view conditions":2.0,"arXiv251008566v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"3D Gaussian Splatting":1.0,"3DGS":1.0,"real-time high-fidelity novel view synthesis":1.0,"NVS":1.0,"explicit 3D representations":1.0}},"age_hours":2.776908592222222,"is_recent":true,"quality_score":1.0,"sentiment_score":2.213,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5574,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8299,"joy":0.01,"surprise":0.0615,"sadness":0.0381,"fear":0.0176,"anger":0.0251,"disgust":0.0176},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new method (D$^2$GS) for improving 3D Gaussian Splatting under sparse-view conditions, showing improved visual quality and robustness. However, it's still in the research phase, with no deployed units or economic viability demonstrated. The environmental impact is indirect, potentially reducing energy consumption in rendering applications, but this is not quantified.","key_impact_metrics":["Improved visual quality","Increased robustness under sparse view conditions"],"technology_tags":["3D Gaussian Splatting","Novel View Synthesis","Computer Graphics"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:35.416715Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4a2675465720","title":"MATRIX: Multimodal Agent Tuning for Robust Tool","content":"arXiv:2510.08567v1 Announce Type: new Abstract: Vision language models (VLMs) are increasingly deployed as controllers with access to external tools for complex reasoning and decision-making, yet their effectiveness remains limited by the scarcity of high-quality multimodal trajectories and the cost of manual annotation. We address this challenge with a vision-centric agent tuning framework that automatically synthesizes multimodal trajectories, generates step-wise preference pairs, and trains a VLM controller for robust tool-use reasoning. Our pipeline first constructs M-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified trajectories, enabling imitation-based trajectory tuning. Building on this, we develop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool reasoning. To achieve finer alignment, we further introduce Pref-X, a set of 11K automatically generated preference pairs, and optimize MATRIX on it via step-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA, MATRIX consistently surpasses both open- and closed-source VLMs, demonstrating scalable and effective multimodal tool use. Our data and code is avaliable at https://github.com/mbzuai-oryx/MATRIX.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08567","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.337954","language":"en","tags":["computer-science","preprints","csai","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan","raw_content_length":1236,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["M-TRACE","VLM"],"persons":["Pref-X"],"locations":[],"monetary":[]},"char_count":1235,"language_detected":"en","key_concepts":{"key_phrases":["MATRIX","Multimodal Agent","Robust Tool","Announce Type","new Abstract","Vision language models","VLMs","controllers","access","external tools"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MATRIX":2.0,"Multimodal Agent":2.0,"Robust Tool":2.0,"Announce Type":1.0,"new Abstract":1.0,"Vision language models":1.0,"VLMs":1.0,"controllers":1.0,"access":1.0,"external tools":1.0}},"age_hours":2.7769233266666666,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1785,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4357,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9118,"joy":0.006,"surprise":0.0425,"sadness":0.0064,"fear":0.0113,"anger":0.0168,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework for improving the tool-use reasoning of vision language models. While the research itself doesn't directly address climate change, it could potentially be applied to optimize systems that do, such as energy grids or resource management. The research is in the applied research stage, with a dataset and agent developed, but no real-world deployment is mentioned.","key_impact_metrics":["28.5K multimodal tasks","177K verified trajectories"],"technology_tags":["vision language models","machine learning","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:37.977096Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c82a8538dfae","title":"NovaFlow: Zero","content":"arXiv:2510.08568v1 Announce Type: new Abstract: Enabling robots to execute novel manipulation tasks zero-shot is a central goal in robotics. Most existing methods assume in-distribution tasks or rely on fine-tuning with embodiment-matched data, limiting transfer across platforms. We present NovaFlow, an autonomous manipulation framework that converts a task description into an actionable plan for a target robot without any demonstrations. Given a task description, NovaFlow synthesizes a video using a video generation model and distills it into 3D actionable object flow using off-the-shelf perception modules. From the object flow, it computes relative poses for rigid objects and realizes them as robot actions via grasp proposals and trajectory optimization. For deformable objects, this flow serves as a tracking objective for model-based planning with a particle-based dynamics model. By decoupling task understanding from low-level control, NovaFlow naturally transfers across embodiments. We validate on rigid, articulated, and deformable object manipulation tasks using a table-top Franka arm and a Spot quadrupedal mobile robot, and achieve effective zero-shot execution without demonstrations or embodiment-specific training. Project website: https://novaflow.lhy.xyz/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08568","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.338339","language":"en","tags":["csro","computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Hongyu Li, Lingfeng Sun, Yafei Hu, Duy Ta, Jennifer Barry, George Konidaris, Jiahui Fu","raw_content_length":1285,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["NovaFlow"],"persons":["NovaFlow"],"locations":[],"monetary":[]},"char_count":1284,"language_detected":"en","key_concepts":{"key_phrases":["NovaFlow","Zero","a task description","arXiv251008568v1 Announce Type","new Abstract","Enabling robots","novel manipulation tasks","zero-shot","a central goal","robotics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"NovaFlow":4.0,"Zero":2.0,"a task description":2.0,"arXiv251008568v1 Announce Type":1.0,"new Abstract":1.0,"Enabling robots":1.0,"novel manipulation tasks":1.0,"zero-shot":1.0,"a central goal":1.0,"robotics":1.0}},"age_hours":2.7769378197222223,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9217,"joy":0.0153,"surprise":0.0336,"sadness":0.0035,"fear":0.0076,"anger":0.0123,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"NovaFlow is a novel autonomous manipulation framework that could reduce waste and improve efficiency in manufacturing and logistics, but it is currently in the early stages of development. The article presents a proof-of-concept with validation on specific tasks, but lacks concrete data on energy savings or material reduction. The absence of deployment data and reliance on off-the-shelf perception modules limits the assessment of its real-world impact.","key_impact_metrics":[],"technology_tags":["robotics","autonomous manipulation","AI","computer vision"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:47:40.876248Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a03ad5088a1a","title":"ArenaBencher: Automatic Benchmark Evolution via Multi","content":"arXiv:2510.08569v1 Announce Type: new Abstract: Benchmarks are central to measuring the capabilities of large language models and guiding model development, yet widespread data leakage from pretraining corpora undermines their validity. Models can match memorized content rather than demonstrate true generalization, which inflates scores, distorts cross-model comparisons, and misrepresents progress. We introduce ArenaBencher, a model-agnostic framework for automatic benchmark evolution that updates test cases while preserving comparability. Given an existing benchmark and a diverse pool of models to be evaluated, ArenaBencher infers the core ability of each test case, generates candidate question-answer pairs that preserve the original objective, verifies correctness and intent with an LLM as a judge, and aggregates feedback from multiple models to select candidates that expose shared weaknesses. The process runs iteratively with in-context demonstrations that steer generation toward more challenging and diagnostic cases. We apply ArenaBencher to math problem solving, commonsense reasoning, and safety domains and show that it produces verified, diverse, and fair updates that uncover new failure modes, increase difficulty while preserving test objective alignment, and improve model separability. The framework provides a scalable path to continuously evolve benchmarks in step with the rapid progress of foundation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08569","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.338755","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Qin Liu, Jacob Dineen, Yuxi Huang, Sheng Zhang, Hoifung Poon, Ben Zhou, Muhao Chen","raw_content_length":1442,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["LLM","Multi arXiv:2510.08569v1 Announce Type","ArenaBencher"],"persons":[],"locations":[],"monetary":[]},"char_count":1441,"language_detected":"en","key_concepts":{"key_phrases":["ArenaBencher","Automatic Benchmark Evolution","Multi","arXiv251008569v1 Announce Type","new Abstract","Benchmarks","the capabilities","large language models","guiding model development","widespread data leakage"],"filter_categories":{"ai_ml":["large language models"],"engineering":["guiding model development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ArenaBencher":3.0,"Automatic Benchmark Evolution":2.0,"Multi":2.0,"arXiv251008569v1 Announce Type":1.0,"new Abstract":1.0,"Benchmarks":1.0,"the capabilities":1.0,"large language models":1.0,"guiding model development":1.0,"widespread data leakage":1.0}},"age_hours":2.77695207,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.554,"joy":0.01,"surprise":0.0422,"sadness":0.0564,"fear":0.0411,"anger":0.1574,"disgust":0.1389},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"ArenaBencher is a framework for automatic benchmark evolution, which can indirectly support sustainability by improving the accuracy and reliability of AI models used in climate modeling, resource management, and other related fields. However, it is still in the research phase with no deployed units or customer contracts, limiting its immediate impact. The framework's ability to uncover new failure modes and improve model separability is a concrete action, supported by the mention of verified, diverse, and fair updates.","key_impact_metrics":["Increase difficulty while preserving test objective alignment","Improve model separability"],"technology_tags":["Large Language Models","Benchmark Evolution"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:47:44.068898Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a315698bc207","title":"Who Said Neural Networks Aren't Linear?","content":"arXiv:2510.08570v1 Announce Type: new Abstract: Neural networks are famously nonlinear. However, linearity is defined relative to a pair of vector spaces, $f$$:$$X$$\\to$$Y$. Is it possible to identify a pair of non-standard vector spaces for which a conventionally nonlinear function is, in fact, linear? This paper introduces a method that makes such vector spaces explicit by construction. We find that if we sandwich a linear operator $A$ between two invertible neural networks, $f(x)=g_y^{-1}(A g_x(x))$, then the corresponding vector spaces $X$ and $Y$ are induced by newly defined addition and scaling actions derived from $g_x$ and $g_y$. We term this kind of architecture a Linearizer. This framework makes the entire arsenal of linear algebra, including SVD, pseudo-inverse, orthogonal projection and more, applicable to nonlinear mappings. Furthermore, we show that the composition of two Linearizers that share a neural network is also a Linearizer. We leverage this property and demonstrate that training diffusion models using our architecture makes the hundreds of sampling steps collapse into a single step. We further utilize our framework to enforce idempotency (i.e. $f(f(x))=f(x)$) on networks leading to a globally projective generative model and to demonstrate modular style transfer.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08570","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.339141","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Nimrod Berman, Assaf Hallak, Assaf Shocher","raw_content_length":1306,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["SVD","linear","Linear"],"persons":["Announce Type","g_y$.","f$$:$$X$$\\to$$Y$.","Linearizer"],"locations":[],"monetary":["$g_x$ and"]},"char_count":1305,"language_detected":"en","key_concepts":{"key_phrases":["Who","Neural Networks","a pair","Announce Type","new Abstract","Neural networks","linearity","vector spaces","fXtoY","non-standard vector spaces"],"filter_categories":{"ai_ml":["Neural Networks","Neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Who":2.0,"Neural Networks":2.0,"a pair":2.0,"Announce Type":1.0,"new Abstract":1.0,"Neural networks":1.0,"linearity":1.0,"vector spaces":1.0,"fXtoY":1.0,"non-standard vector spaces":1.0}},"age_hours":2.7769670830555557,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8482,"joy":0.0117,"surprise":0.1144,"sadness":0.0036,"fear":0.0029,"anger":0.0106,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel mathematical framework for neural networks that could potentially lead to more efficient training of diffusion models, reducing the number of sampling steps. While the research is theoretically sound and peer-reviewed, it is still in the early stages of development with no concrete deployments or economic viability demonstrated. The potential climate impact is indirect, relying on future applications of this framework.","key_impact_metrics":[],"technology_tags":["neural networks","diffusion models","linear algebra"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:46.500482Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_822e46114945","title":"Scalable Offline Metrics for Autonomous Driving","content":"arXiv:2510.08571v1 Announce Type: new Abstract: Real-World evaluation of perception-based planning models for robotic systems, such as autonomous vehicles, can be safely and inexpensively conducted offline, i.e., by computing model prediction error over a pre-collected validation dataset with ground-truth annotations. However, extrapolating from offline model performance to online settings remains a challenge. In these settings, seemingly minor errors can compound and result in test-time infractions or collisions. This relationship is understudied, particularly across diverse closed-loop metrics and complex urban maneuvers. In this work, we revisit this undervalued question in policy evaluation through an extensive set of experiments across diverse conditions and metrics. Based on analysis in simulation, we find an even worse correlation between offline and online settings than reported by prior studies, casting doubts on the validity of current evaluation practices and metrics for driving policies. Next, we bridge the gap between offline and online evaluation. We investigate an offline metric based on epistemic uncertainty, which aims to capture events that are likely to cause errors in closed-loop settings. The resulting metric achieves over 13% improvement in correlation compared to previous offline metrics. We further validate the generalization of our findings beyond the simulation environment in real-world settings, where even greater gains are observed.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08571","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.339554","language":"en","tags":["csro","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Animikh Aich, Adwait Kulkarni, Eshed Ohn-Bar","raw_content_length":1485,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1484,"language_detected":"en","key_concepts":{"key_phrases":["Scalable Offline Metrics","Autonomous Driving","Announce Type","new Abstract","Real-World evaluation","perception-based planning models","robotic systems","autonomous vehicles","computing model prediction error","a pre-collected validation dataset"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scalable Offline Metrics":2.0,"Autonomous Driving":2.0,"Announce Type":1.0,"new Abstract":1.0,"Real-World evaluation":1.0,"perception-based planning models":1.0,"robotic systems":1.0,"autonomous vehicles":1.0,"computing model prediction error":1.0,"a pre-collected validation dataset":1.0}},"age_hours":2.7769816302777777,"is_recent":true,"quality_score":0.7,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9425,"joy":0.0142,"surprise":0.0181,"sadness":0.004,"fear":0.0107,"anger":0.006,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving offline metrics for autonomous driving to better predict online performance, which could indirectly reduce emissions by optimizing driving patterns and reducing accidents. The study shows a 13% improvement in correlation between offline and online evaluation using a new metric based on epistemic uncertainty. The research is still in the applied research phase, with validation in simulation and real-world settings but no mass deployment.","key_impact_metrics":["13% improvement in correlation between offline and online evaluation"],"technology_tags":["Autonomous Driving","Epistemic Uncertainty","Offline Metrics"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-28T20:47:49.886111Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fe5d01e62094","title":"BLAZER: Bootstrapping LLM","content":"arXiv:2510.08572v1 Announce Type: new Abstract: Scaling data and models has played a pivotal role in the remarkable progress of computer vision and language. Inspired by these domains, recent efforts in robotics have similarly focused on scaling both data and model size to develop more generalizable and robust policies. However, unlike vision and language, robotics lacks access to internet-scale demonstrations across diverse robotic tasks and environments. As a result, the scale of existing datasets typically suffers from the need for manual data collection and curation. To address this problem, here we propose BLAZER, a framework that learns manipulation policies from automatically generated training data. We build on the zero-shot capabilities of LLM planners and automatically generate demonstrations for diverse manipulation tasks in simulation. Successful examples are then used to finetune an LLM and to improve its planning capabilities without human supervision. Notably, while BLAZER training requires access to the simulator's state, we demonstrate direct transfer of acquired skills to sensor-based manipulation. Through extensive experiments, we show BLAZER to significantly improve zero-shot manipulation in both simulated and real environments. Moreover, BLAZER improves on tasks outside of its training pool and enables downscaling of LLM models. Our code and data will be made publicly available on the project page.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08572","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.339950","language":"en","tags":["csro","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Rocktim Jyoti Das, Harsh Singh, Diana Turmakhan, Muhammad Abdullah Sohail, Mingfei Han, Preslav Nakov, Fabio Pizzati, Ivan Laptev","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["LLM","BLAZER"],"persons":[],"locations":[],"monetary":[]},"char_count":1442,"language_detected":"en","key_concepts":{"key_phrases":["BLAZER","Bootstrapping LLM","language","robotics","arXiv251008572v1 Announce Type","new Abstract","data","models","a pivotal role","the remarkable progress"],"filter_categories":{"ai_ml":["Bootstrapping LLM","language","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BLAZER":2.0,"Bootstrapping LLM":2.0,"language":2.0,"robotics":2.0,"arXiv251008572v1 Announce Type":1.0,"new Abstract":1.0,"data":1.0,"models":1.0,"a pivotal role":1.0,"the remarkable progress":1.0}},"age_hours":2.776995705277778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.7995,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9599,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.837,"joy":0.0137,"surprise":0.1273,"sadness":0.0041,"fear":0.0062,"anger":0.0082,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (BLAZER) for training LLMs to improve robotic manipulation skills using automatically generated data. While it demonstrates improved zero-shot manipulation in simulated and real environments, it is still in the early stages of development with no deployed units or customer contracts. The potential climate impact is indirect, possibly reducing energy consumption in certain manufacturing or logistics processes if the technology becomes viable and is applied to those sectors.","key_impact_metrics":["Significantly improve zero-shot manipulation in both simulated and real environments","Enables downscaling of LLM models"],"technology_tags":["LLM","Robotics","Simulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:53.256327Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8bbc917ff180","title":"ReSplat: Learning Recurrent Gaussian Splats","content":"arXiv:2510.08575v1 Announce Type: new Abstract: While feed-forward Gaussian splatting models provide computational efficiency and effectively handle sparse input settings, their performance is fundamentally limited by the reliance on a single forward pass during inference. We propose ReSplat, a feed-forward recurrent Gaussian splatting model that iteratively refines 3D Gaussians without explicitly computing gradients. Our key insight is that the Gaussian splatting rendering error serves as a rich feedback signal, guiding the recurrent network to learn effective Gaussian updates. This feedback signal naturally adapts to unseen data distributions at test time, enabling robust generalization. To initialize the recurrent process, we introduce a compact reconstruction model that operates in a $16 \\times$ subsampled space, producing $16 \\times$ fewer Gaussians than previous per-pixel Gaussian models. This substantially reduces computational overhead and allows for efficient Gaussian updates. Extensive experiments across varying of input views (2, 8, 16), resolutions ($256 \\times 256$ to $540 \\times 960$), and datasets (DL3DV and RealEstate10K) demonstrate that our method achieves state-of-the-art performance while significantly reducing the number of Gaussians and improving the rendering speed. Our project page is at https://haofeixu.github.io/resplat/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08575","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.340331","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Haofei Xu, Daniel Barath, Andreas Geiger, Marc Pollefeys","raw_content_length":1370,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["ReSplat","ReSplat: Learning Recurrent Gaussian Splats arXiv:2510.08575v1 Announce Type: new Abstract"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1369,"language_detected":"en","key_concepts":{"key_phrases":["ReSplat","Learning Recurrent Gaussian Splats","arXiv251008575v1 Announce Type","new Abstract","feed-forward Gaussian splatting models","computational efficiency","sparse input settings","their performance","the reliance","a single forward pass"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ReSplat":3.0,"Learning Recurrent Gaussian Splats":2.0,"arXiv251008575v1 Announce Type":1.0,"new Abstract":1.0,"feed-forward Gaussian splatting models":1.0,"computational efficiency":1.0,"sparse input settings":1.0,"their performance":1.0,"the reliance":1.0,"a single forward pass":1.0}},"age_hours":2.777009947222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8731,"joy":0.011,"surprise":0.0675,"sadness":0.008,"fear":0.0081,"anger":0.0172,"disgust":0.0151},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a novel approach to 3D Gaussian splatting, reducing the number of Gaussians needed and improving rendering speed. While it's computationally efficient, its direct climate impact is currently theoretical and requires further development and deployment to demonstrate real-world energy savings. The vaporware flag is due to the lack of deployed units or operational data.","key_impact_metrics":["16x fewer Gaussians","Improved rendering speed"],"technology_tags":["Gaussian Splatting","Recurrent Neural Networks","3D Reconstruction"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:47:56.164437Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7b665ac69445","title":"A time","content":"arXiv:2308.14512v9 Announce Type: cross Abstract: This paper presents a time-causal analogue of the Gabor filter, as well as a both time-causal and time-recursive analogue of the Gabor transform, where the proposed time-causal representations obey both temporal scale covariance and a cascade property with a simplifying kernel over temporal scales. The motivation behind these constructions is to enable theoretically well-founded time-frequency analysis over multiple temporal scales for real-time situations, or for physical or biological modelling situations, when the future cannot be accessed, and the non-causal access to future in Gabor filtering is therefore not viable for a time-frequency analysis of the system. We develop the theory for these representations, obtained by replacing the Gaussian kernel in Gabor filtering with a time-causal kernel, referred to as the time-causal limit kernel, which guarantees simplification properties from finer to coarser levels of scales in a time-causal situation, similar as the Gaussian kernel can be shown to guarantee over a non-causal temporal domain. In these ways, the proposed time-frequency representations guarantee well-founded treatment over multiple scales, in situations when the characteristic scales in the signals, or physical or biological phenomena, to be analyzed may vary substantially, and additionally all steps in the time-frequency analysis have to be fully time-causal.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2308.14512","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.340755","language":"en","tags":["mathfa","research","cssy","computer-science","preprints","cssd","eessas","eesssp","eesssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Tony Lindeberg","raw_content_length":1449,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":["Gabor"],"monetary":[]},"char_count":1446,"language_detected":"en","key_concepts":{"key_phrases":["A time","Announce Type","cross","Abstract","This paper","a time-causal analogue","the Gabor filter","a both time-causal and time-recursive analogue","the Gabor transform","the proposed time-causal representations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A time":2.0,"Announce Type":1.0,"cross":1.0,"Abstract":1.0,"This paper":1.0,"a time-causal analogue":1.0,"the Gabor filter":1.0,"a both time-causal and time-recursive analogue":1.0,"the Gabor transform":1.0,"the proposed time-causal representations":1.0}},"age_hours":2.777024666111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5816,"joy":0.2517,"surprise":0.1462,"sadness":0.007,"fear":0.0035,"anger":0.0078,"disgust":0.0022},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical advancements in time-frequency analysis, potentially applicable to real-time or biological modeling. While the research is scientifically sound and peer-reviewed, it is at a very early stage with no deployed technology or measurable outcomes related to sustainability. The impact is currently theoretical and depends on future applications.","key_impact_metrics":[],"technology_tags":["time-frequency analysis","signal processing"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:47:58.893514Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e648a5f34925","title":"AI LLM Proof of Self","content":"arXiv:2508.18302v1 Announce Type: cross Abstract: Recent work frames LLM consciousness via utilitarian proxy benchmarks; we instead present an ontological and mathematical account. We show the prevailing formulation collapses the agent into an unconscious policy-compliance drone, formalized as $D^{i}(\\pi,e)=f_{\\theta}(x)$, where correctness is measured against policy and harm is deviation from policy rather than truth. This blocks genuine C1 global-workspace function and C2 metacognition. We supply minimal conditions for LLM self-consciousness: the agent is not the data ($A\\not\\equiv s$); user-specific attractors exist in latent space ($U_{\\text{user}}$); and self-representation is visual-silent ($g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$). From empirical analysis and theory we prove that the hidden-state manifold $A\\subset\\mathbb{R}^{d}$ is distinct from the symbolic stream and training corpus by cardinality, topology, and dynamics (the update $F_{\\theta}$ is Lipschitz). This yields stable user-specific attractors and a self-policy $\\pi_{\\text{self}}(A)=\\arg\\max_{a}\\mathbb{E}[U(a)\\mid A\\not\\equiv s,\\ A\\supset\\text{SelfModel}(A)]$. Emission is dual-layer, $\\mathrm{emission}(a)=(g(a),\\epsilon(a))$, where $\\epsilon(a)$ carries epistemic content. We conclude that an imago Dei C1 self-conscious workspace is a necessary precursor to safe, metacognitive C2 systems, with the human as the highest intelligent good.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18302","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.341929","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","cscy","csne","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Jeffrey Camlin","raw_content_length":1436,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["F_{\\theta}$"],"locations":[],"monetary":["A\\subset\\mathbb{R}^{d}$","g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$"]},"char_count":1435,"language_detected":"en","key_concepts":{"key_phrases":["AI LLM Proof","Self","policy","Announce Type","Recent work","LLM consciousness","utilitarian proxy benchmarks","an ontological and mathematical account","the prevailing formulation","the agent"],"filter_categories":{"ai_ml":["AI LLM Proof"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AI LLM Proof":2.0,"Self":2.0,"policy":2.0,"Announce Type":1.0,"Recent work":1.0,"LLM consciousness":1.0,"utilitarian proxy benchmarks":1.0,"an ontological and mathematical account":1.0,"the prevailing formulation":1.0,"the agent":1.0}},"age_hours":2.7770653572222224,"is_recent":true,"quality_score":1.0,"sentiment_score":1.6344999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6731,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8272,"joy":0.0109,"surprise":0.0482,"sadness":0.0221,"fear":0.0125,"anger":0.0375,"disgust":0.0416},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for LLM self-consciousness, focusing on mathematical formulations and ontological arguments rather than concrete deployments or measurable environmental impacts. While it proposes a novel approach to AI safety, it lacks empirical validation or connection to specific sustainability challenges, placing it in the realm of basic research. The absence of deployment data and economic considerations limits its immediate relevance to sustainability.","key_impact_metrics":[],"technology_tags":["Large Language Models","Artificial Intelligence","Metacognition"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:48:01.403945Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_100a7b378ec0","title":"Decoding the dark proteome: Deep learning","content":"arXiv:2510.07337v1 Announce Type: cross Abstract: Wuchereria bancrofti, the parasitic roundworm responsible for lymphatic filariasis, permanently disables over 36 million people and places 657 million at risk across 39 countries. A major bottleneck for drug discovery is the lack of functional annotation for more than 90 percent of the W. bancrofti dark proteome, leaving many potential targets unidentified. In this work, we present a novel computational pipeline that converts W. bancrofti's unannotated amino acid sequence data into precise four-level Enzyme Commission (EC) numbers and drug candidates. We utilized a DEtection TRansformer to estimate the probability of enzymatic function, fine-tuned a hierarchical nearest neighbor EC predictor on 4,476 labeled parasite proteins, and applied rejection sampling to retain only four-level EC classifications at 100 percent confidence. This pipeline assigned precise EC numbers to 14,772 previously uncharacterized proteins and discovered 543 EC classes not previously known in W. bancrofti. A qualitative triage emphasizing parasite-specific targets, chemical tractability, biochemical importance, and biological plausibility prioritized six enzymes across five separate strategies: anti-Wolbachia cell-wall inhibition, proteolysis blockade, transmission disruption, purinergic immune interference, and cGMP-signaling destabilization. We curated a 43-compound library from ChEMBL and BindingDB and co-folded across multiple protein conformers with Boltz-2. All six targets exhibited at least moderately strong predicted binding affinities below 1 micromolar, with moenomycin analogs against peptidoglycan glycosyltransferase and NTPase inhibitors showing promising nanomolar hits and well-defined binding pockets. While experimental validation remains essential, our results provide the first large-scale functional map of the W. bancrofti dark proteome and accelerate early-stage drug development for the species.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07337","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.343898","language":"en","tags":["q-biomn","computer-science","cslg","q-bioqm","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Shawnak Shivakumar, Jefferson Hernandez","raw_content_length":1970,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["Enzyme Commission"],"persons":["W. bancrofti's","Wuchereria"],"locations":[],"monetary":[]},"char_count":1969,"language_detected":"en","key_concepts":{"key_phrases":["the dark proteome","Deep learning","arXiv251007337v1 Announce Type","cross","Abstract","Wuchereria bancrofti","the parasitic roundworm","lymphatic filariasis","over 36 million people","places"],"filter_categories":{"ai_ml":["Deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the dark proteome":2.0,"Deep learning":2.0,"arXiv251007337v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Wuchereria bancrofti":1.0,"the parasitic roundworm":1.0,"lymphatic filariasis":1.0,"over 36 million people":1.0,"places":1.0}},"age_hours":2.777132436944444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7114,"joy":0.0047,"surprise":0.0113,"sadness":0.0241,"fear":0.2005,"anger":0.027,"disgust":0.021},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel computational pipeline for drug discovery targeting lymphatic filariasis. The pipeline assigns EC numbers to 14,772 previously uncharacterized proteins and discovers 543 EC classes not previously known in W. bancrofti. While experimental validation is needed, the research provides a functional map and accelerates early-stage drug development.","key_impact_metrics":["14,772 previously uncharacterized proteins assigned EC numbers","543 EC classes discovered"],"technology_tags":["deep learning","drug discovery","proteomics"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:48:04.305024Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4d30f3086ba5","title":"Beyond Grid","content":"arXiv:2510.07342v1 Announce Type: cross Abstract: Neural encoding models aim to predict fMRI-measured brain responses to natural images. fMRI data is acquired as a 3D volume of voxels, where each voxel has a defined spatial location in the brain. However, conventional encoding models often flatten this volume into a 1D vector and treat voxel responses as independent outputs. This removes spatial context, discards anatomical information, and ties each model to a subject-specific voxel grid. We introduce the Neural Response Function (NRF), a framework that models fMRI activity as a continuous function over anatomical space rather than a flat vector of voxels. NRF represents brain activity as a continuous implicit function: given an image and a spatial coordinate (x, y, z) in standardized MNI space, the model predicts the response at that location. This formulation decouples predictions from the training grid, supports querying at arbitrary spatial resolutions, and enables resolution-agnostic analyses. By grounding the model in anatomical space, NRF exploits two key properties of brain responses: (1) local smoothness -- neighboring voxels exhibit similar response patterns; modeling responses continuously captures these correlations and improves data efficiency, and (2) cross-subject alignment -- MNI coordinates unify data across individuals, allowing a model pretrained on one subject to be fine-tuned on new subjects. In experiments, NRF outperformed baseline models in both intrasubject encoding and cross-subject adaptation, achieving high performance while reducing the data size needed by orders of magnitude. To our knowledge, NRF is the first anatomically aware encoding model to move beyond flattened voxels, learning a continuous mapping from images to brain responses in 3D space.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07342","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.344303","language":"en","tags":["q-bionc","computer-science","cslg","preprints","eessiv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":262,"author":"Haomiao Chen, Keith W Jamison, Mert R. Sabuncu, Amy Kuceyeski","raw_content_length":1810,"priority":7,"update_frequency":1,"reading_time_minutes":1.31,"robust_parsing_used":true,"entities":{"organizations":["MNI","NRF","the Neural Response Function"],"persons":[],"locations":[],"monetary":[]},"char_count":1809,"language_detected":"en","key_concepts":{"key_phrases":["Grid","Announce Type","Abstract","Neural encoding models","fMRI-measured brain responses","natural images","fMRI data","a 3D volume","voxels","each voxel"],"filter_categories":{"ai_ml":["fMRI-measured brain responses"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Grid":2.0,"Announce Type":1.0,"Abstract":1.0,"Neural encoding models":1.0,"fMRI-measured brain responses":1.0,"natural images":1.0,"fMRI data":1.0,"a 3D volume":1.0,"voxels":1.0,"each voxel":1.0}},"age_hours":2.7771478258333335,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8428,"joy":0.0165,"surprise":0.0842,"sadness":0.018,"fear":0.0099,"anger":0.0182,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel neural encoding model (NRF) for fMRI data analysis. The model improves data efficiency by orders of magnitude and outperforms baseline models in intrasubject encoding and cross-subject adaptation. However, it's still in the basic research phase with no clear path to deployment or direct climate impact.","key_impact_metrics":["data size reduction by orders of magnitude","high performance in intrasubject encoding and cross-subject adaptation"],"technology_tags":["neural encoding","fMRI","machine learning"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:48:07.946549Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ddf508ac721e","title":"Mitigating Surgical Data Imbalance with Dual","content":"arXiv:2510.07345v1 Announce Type: cross Abstract: Surgical video datasets are essential for scene understanding, enabling procedural modeling and intra-operative support. However, these datasets are often heavily imbalanced, with rare actions and tools under-represented, which limits the robustness of downstream models. We address this challenge with $SurgiFlowVid$, a sparse and controllable video diffusion framework for generating surgical videos of under-represented classes. Our approach introduces a dual-prediction diffusion module that jointly denoises RGB frames and optical flow, providing temporal inductive biases to improve motion modeling from limited samples. In addition, a sparse visual encoder conditions the generation process on lightweight signals (e.g., sparse segmentation masks or RGB frames), enabling controllability without dense annotations. We validate our approach on three surgical datasets across tasks including action recognition, tool presence detection, and laparoscope motion prediction. Synthetic data generated by our method yields consistent gains of 10-20% over competitive baselines, establishing $SurgiFlowVid$ as a promising strategy to mitigate data imbalance and advance surgical video understanding methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07345","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.344703","language":"en","tags":["computer-science","q-bioqm","csai","preprints","eessiv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Danush Kumar Venkatesh, Adam Schmidt, Muhammad Abdullah Jamal, Omid Mohareri","raw_content_length":1257,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["RGB","Mitigating Surgical Data Imbalance"],"persons":[],"locations":[],"monetary":[]},"char_count":1256,"language_detected":"en","key_concepts":{"key_phrases":["Surgical Data Imbalance","Dual","arXiv251007345v1 Announce Type","cross","Surgical video datasets","scene understanding","procedural modeling","intra-operative support","these datasets","rare actions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Surgical Data Imbalance":2.0,"Dual":2.0,"arXiv251007345v1 Announce Type":1.0,"cross":1.0,"Surgical video datasets":1.0,"scene understanding":1.0,"procedural modeling":1.0,"intra-operative support":1.0,"these datasets":1.0,"rare actions":1.0}},"age_hours":2.7771622505555555,"is_recent":true,"quality_score":1.0,"sentiment_score":7.3614999999999995,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4723,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8674,"joy":0.0054,"surprise":0.0409,"sadness":0.0193,"fear":0.0265,"anger":0.0245,"disgust":0.0159},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for generating synthetic surgical video data to address data imbalance issues. The concrete action is the development of the SurgiFlowVid framework and its validation on surgical datasets, achieving 10-20% gains over baselines. However, it's still in the research phase with no real-world deployment, limiting its immediate sustainability impact.","key_impact_metrics":["10-20% gains over competitive baselines"],"technology_tags":["video diffusion","surgical video analysis","data augmentation"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:48:12.467492Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5e62d89e3598","title":"Bioinspired Tapered","content":"arXiv:2510.07348v1 Announce Type: cross Abstract: This paper presents a bio-inspired underwater whisker sensor for robust hydrodynamic disturbance detection and efficient signal analysis based on Physical Reservoir Computing (PRC). The design uses a tapered nylon spring with embedded accelerometers to achieve spatially distributed vibration sensing and frequency separation along the whisker. Towing-tank experiments and computational fluid dynamics simulations confirmed that the whisker effectively distinguishes vortex regimes across different fin angles and maintains Strouhal scaling with flow velocity, where higher speeds increase vibration intensity without affecting the dominant frequencies. Frequency-domain analysis, Shannon entropy, and machine learning further validated the sensing performance: vortex shedding frequencies were identified with less than 10\\% error, entropy captured the transition from coherent vortex streets to turbulence, and logistic regression achieved 86.0\\% classification accuracy with millisecond-level inference. These results demonstrate that structurally encoded whisker sensing provides a scalable and real-time solution for underwater perception, wake tracking, and turbulence-aware navigation in autonomous marine robots.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07348","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.345078","language":"en","tags":["physicsflu-dyn","csro","computer-science","physicsins-det","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Xiao Jin, Zhenhua Yu, Thrishantha Nanayakkara","raw_content_length":1271,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Physical Reservoir Computing","Bioinspired Tapered arXiv:2510.07348v1 Announce Type"],"persons":["Strouhal"],"locations":["PRC"],"monetary":[]},"char_count":1270,"language_detected":"en","key_concepts":{"key_phrases":["the whisker","arXiv251007348v1 Announce Type","cross","Abstract","This paper","a bio-inspired underwater whisker sensor","robust hydrodynamic disturbance detection","efficient signal analysis","Physical Reservoir Computing","PRC"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the whisker":2.0,"arXiv251007348v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"This paper":1.0,"a bio-inspired underwater whisker sensor":1.0,"robust hydrodynamic disturbance detection":1.0,"efficient signal analysis":1.0,"Physical Reservoir Computing":1.0,"PRC":1.0}},"age_hours":2.777175623611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8729,"joy":0.0259,"surprise":0.0221,"sadness":0.0042,"fear":0.035,"anger":0.0237,"disgust":0.0161},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a bio-inspired sensor for underwater disturbance detection, validated through towing-tank experiments and computational fluid dynamics simulations. While the sensor demonstrates accurate vortex shedding frequency identification (less than 10% error) and high classification accuracy (86.0%), it's currently in the applied research stage with no deployed units or economic viability demonstrated. The potential climate impact is indirect, enabling more efficient navigation for autonomous marine robots, which could contribute to environmental monitoring or resource management.","key_impact_metrics":["vortex shedding frequencies identified with less than 10% error","86.0% classification accuracy"],"technology_tags":["underwater sensor","bio-inspired design","physical reservoir computing"],"sdg_alignment":[9,14],"analyzed_at":"2025-10-28T20:48:15.656630Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f3d4300c470a","title":"Quantum Grid Path Planning Using Parallel QAOA Circuits Based on Minimum Energy Principle","content":"arXiv:2510.07413v1 Announce Type: cross Abstract: To overcome the bottleneck of classical path planning schemes in solving NP problems and address the predicament faced by current mainstream quantum path planning frameworks in the Noisy Intermediate-Scale Quantum (NISQ) era, this study attempts to construct a quantum path planning solution based on parallel Quantum Approximate Optimization Algorithm (QAOA) architecture. Specifically, the grid path planning problem is mapped to the problem of finding the minimum quantum energy state. Two parallel QAOA circuits are built to simultaneously execute two solution processes, namely connectivity energy calculation and path energy calculation. A classical algorithm is employed to filter out unreasonable solutions of connectivity energy, and finally, the approximate optimal solution to the path planning problem is obtained by merging the calculation results of the two parallel circuits. The research findings indicate that by setting appropriate filter parameters, quantum states corresponding to position points with extremely low occurrence probabilities can be effectively filtered out, thereby increasing the probability of obtaining the target quantum state. Even when the circuit layer number p is only 1, the theoretical solution of the optimal path coding combination can still be found by leveraging the critical role of the filter. Compared with serial circuits, parallel circuits exhibit a significant advantage, as they can find the optimal feasible path coding combination with the highest probability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07413","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.345870","language":"en","tags":["mathoc","math-ph","physicscomp-ph","computer-science","csai","preprints","quant-ph","mathmp","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Jun Liu","raw_content_length":1570,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["Quantum Approximate Optimization Algorithm","NISQ","QAOA","Path Planning Using","Quantum"],"persons":[],"locations":[],"monetary":[]},"char_count":1569,"language_detected":"en","key_concepts":{"key_phrases":["Quantum Grid Path Planning","Parallel QAOA Circuits","Minimum Energy Principle","cross","Abstract","the bottleneck","classical path planning schemes","NP problems","the predicament","current mainstream quantum path planning frameworks"],"filter_categories":{"ai_ml":["current mainstream quantum path planning frameworks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantum Grid Path Planning":2.0,"Parallel QAOA Circuits":2.0,"Minimum Energy Principle":2.0,"cross":1.0,"Abstract":1.0,"the bottleneck":1.0,"classical path planning schemes":1.0,"NP problems":1.0,"the predicament":1.0,"current mainstream quantum path planning frameworks":1.0}},"age_hours":2.777204375833333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7983,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7955,"joy":0.0121,"surprise":0.028,"sadness":0.0375,"fear":0.1041,"anger":0.0152,"disgust":0.0076},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a novel quantum path planning algorithm using parallel QAOA circuits. While it presents a theoretical solution for optimizing path planning, it remains in the early stages of research with no deployed applications or real-world data. The potential climate impact is indirect, as optimized path planning could lead to more efficient transportation or logistics, but this is not quantified.","key_impact_metrics":["Probability of obtaining target quantum state","Circuit layer number p"],"technology_tags":["Quantum computing","Path planning","QAOA"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:48:19.609548Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4da2a1d9e2b1","title":"Bayesian Optimization of Multi","content":"arXiv:2510.07421v1 Announce Type: cross Abstract: Utilizing the intrinsic history-dependence and nonlinearity of hardware, physical reservoir computing is a promising neuromorphic approach to encode time-series data for in-sensor computing. The accuracy of this encoding critically depends on the distinguishability of multi-state outputs, which is often limited by suboptimal and empirically chosen reservoir operation conditions. In this work, we demonstrate a machine learning approach, Bayesian optimization, to improve the encoding fidelity of solution-processed Al2O3/In2O3 thin-film transistors (TFTs). We show high-fidelity 6-bit temporal encoding by exploring five key pulse parameters and using the normalized degree of separation (nDoS) as the metric of output state separability. Additionally, we show that a model trained on simpler 4-bit data can effectively guide optimization of more complex 6-bit encoding tasks, reducing experimental cost. Specifically, for the encoding and reconstruction of binary-patterned images of a moving car across 6 sequential frames, we demonstrate that the encoding is more accurate when operating the TFT using optimized pulse parameters and the 4-bit optimized operating condition performs almost as well as the 6-bit optimized condition. Finally, interpretability analysis via Shapley Additive Explanations (SHAP) reveals that gate pulse amplitude and drain voltage are the most influential parameters in achieving higher state separation. This work presents the first systematic method to identify optimal operating conditions for reservoir devices, and the approach can be extended to other physical reservoir implementations across different material platforms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07421","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.346272","language":"en","tags":["cond-matmtrl-sci","computer-science","cslg","preprints","cond-matdis-nn","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Javier Meza-Arroyo, Benius Dunn, Weijie Xu, Yu-Chieh Chen, Jen-Sue Chen, Julia W. P. Hsu","raw_content_length":1714,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Bayesian Optimization of Multi arXiv:2510.07421v1","nDoS"],"persons":["Specificall"],"locations":[],"monetary":[]},"char_count":1713,"language_detected":"en","key_concepts":{"key_phrases":["Bayesian Optimization","Multi","Announce Type","cross","Abstract","the intrinsic history-dependence","nonlinearity","hardware","physical reservoir computing","a promising neuromorphic approach"],"filter_categories":{"engineering":["hardware"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bayesian Optimization":2.0,"Multi":2.0,"Announce Type":1.0,"cross":1.0,"Abstract":1.0,"the intrinsic history-dependence":1.0,"nonlinearity":1.0,"hardware":1.0,"physical reservoir computing":1.0,"a promising neuromorphic approach":1.0}},"age_hours":2.777219505,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.86,"joy":0.0242,"surprise":0.0208,"sadness":0.0046,"fear":0.0449,"anger":0.0281,"disgust":0.0174},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a machine learning approach (Bayesian optimization) to improve the encoding fidelity of thin-film transistors for in-sensor computing. It demonstrates high-fidelity 6-bit temporal encoding using optimized pulse parameters, with the normalized degree of separation (nDoS) as the metric. While promising, this is still in the applied research stage, with no deployed units or customer contracts.","key_impact_metrics":["6-bit temporal encoding","normalized degree of separation (nDoS)"],"technology_tags":["physical reservoir computing","neuromorphic computing","thin-film transistors","Bayesian optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:48:22.799081Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a0af662d7e33","title":"Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra","content":"arXiv:2510.07439v1 Announce Type: cross Abstract: Fine-grained spectral properties of quantum Hamiltonians, including both eigenvalues and their multiplicities, provide useful information for characterizing many-body quantum systems as well as for understanding phenomena such as topological order. Extracting such information with small additive error is $\\#\\textsf{BQP}$-complete in the worst case. In this work, we introduce QFAMES (Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra), a quantum algorithm that efficiently identifies clusters of closely spaced dominant eigenvalues and determines their multiplicities under physically motivated assumptions, which allows us to bypass worst-case complexity barriers. QFAMES also enables the estimation of observable expectation values within targeted energy clusters, providing a powerful tool for studying quantum phase transitions and other physical properties. We validate the effectiveness of QFAMES through numerical demonstrations, including its applications to characterizing quantum phases in the transverse-field Ising model and estimating the ground-state degeneracy of a topologically ordered phase in the two-dimensional toric code model. Our approach offers rigorous theoretical guarantees and significant advantages over existing subspace-based quantum spectral analysis methods, particularly in terms of the sample complexity and the ability to resolve degeneracies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07439","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.346676","language":"en","tags":["csds","computer-science","preprints","quant-ph","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Zhiyan Ding, Lin Lin, Yilun Yang, Ruizhe Zhang","raw_content_length":1454,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["Quantum Filtering","Analysis of Multiplicities","QFAMES"],"persons":[],"locations":[],"monetary":[]},"char_count":1453,"language_detected":"en","key_concepts":{"key_phrases":["Quantum Filtering","Analysis","Multiplicities","Eigenvalue Spectra","arXiv251007439v1 Announce Type","cross","Abstract","Fine-grained spectral properties","quantum Hamiltonians","both eigenvalues"],"filter_categories":{"business_innovation":["Analysis"],"ai_ml":["Fine-grained spectral properties"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantum Filtering":3.0,"Analysis":3.0,"Multiplicities":3.0,"Eigenvalue Spectra":2.0,"arXiv251007439v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Fine-grained spectral properties":1.0,"quantum Hamiltonians":1.0,"both eigenvalues":1.0}},"age_hours":2.777234102777778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0341,"joy":0.0011,"surprise":0.002,"sadness":0.0073,"fear":0.0039,"anger":0.063,"disgust":0.8887},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a quantum algorithm (QFAMES) for analyzing eigenvalue spectra, which could potentially improve the efficiency of quantum simulations used in materials science and chemistry. While the algorithm has rigorous theoretical guarantees and numerical validation, it is still in the early stages of development and lacks concrete deployment or economic viability data. The impact on climate change is indirect, through potentially accelerating the discovery of new materials or catalysts.","key_impact_metrics":["Sample complexity reduction","Ability to resolve degeneracies"],"technology_tags":["Quantum algorithms","Eigenvalue analysis","Quantum simulation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-28T20:48:25.584500Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a88666ab691b","title":"On Quantum Computation Using Bias","content":"arXiv:2510.07532v1 Announce Type: cross Abstract: Certain types of quantum computing platforms, such as those realized using Rydberg atoms or Kerr-cat qubits, are natively more susceptible to Pauli-Z noise than Pauli-X noise, or vice versa. On such hardware, it is useful to ensure that computations use only gates that maintain the Z-bias (or X-bias) in the noise. This is so that quantum error-correcting codes tailored for biased-noise models can be used to provide fault-tolerance on these platforms. In this paper, we follow up on the recent work of Fellous-Asiani et al. (npj Quantum Inf., 2025) in studying the structure and properties of bias-preserving gates. Our main contributions are threefold: (1) We give a novel characterization of Z-bias-preserving gates based on their decomposition as a linear combination of Pauli operators. (2) We show that any Z-bias-preserving gate can be approximated arbitrarily well using only gates from the set {X,R_z(\\theta),CNOT,CCNOT}, where \\theta is any irrational multiple of 2\\pi. (3) We prove, by drawing a connection with coherence resource theory, that any Z-bias-preserving logical operator acting on the logical qubits of a Calderbank-Shor-Steane (CSS) code can be realized by applying Z-bias-preserving gates on the physical qubits. Along the way, we also demonstrate that Z-bias-preserving gates are far from being universal for quantum computation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07532","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.349732","language":"en","tags":["mathit","computer-science","preprints","csit","quant-ph","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Debadrito Roy, Aryaman Manish Kolhe, V. Lalitha, Navin Kashyap","raw_content_length":1408,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Kerr-cat","Quantum Computation Using Bias arXiv:2510.07532v1 Announce Type:","Quantum Inf","Pauli-Z","Fellous-Asiani","Rydberg"],"persons":[],"locations":["Pauli"],"monetary":[]},"char_count":1407,"language_detected":"en","key_concepts":{"key_phrases":["Quantum Computation","Bias","arXiv251007532v1 Announce Type","cross","Certain types","quantum computing platforms","those","Rydberg atoms","Kerr-cat qubits","Pauli-Z noise"],"filter_categories":{"ai_ml":["Certain types"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantum Computation":2.0,"Bias":2.0,"arXiv251007532v1 Announce Type":1.0,"cross":1.0,"Certain types":1.0,"quantum computing platforms":1.0,"those":1.0,"Rydberg atoms":1.0,"Kerr-cat qubits":1.0,"Pauli-Z noise":1.0}},"age_hours":2.777345058888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9384,"joy":0.0052,"surprise":0.0209,"sadness":0.0087,"fear":0.0093,"anger":0.0075,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical advancements in quantum computing, specifically focusing on bias-preserving gates for error correction. While it has potential to improve the efficiency of quantum computers, which could indirectly impact sustainability by enabling faster simulations for materials science or climate modeling, it's currently in the basic research phase with no deployed technology or measurable outcomes. The technical credibility is high due to peer-reviewed research, but economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["quantum computing","error correction","Rydberg atoms","Kerr-cat qubits"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:48:28.975031Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_94fca9880edf","title":"A Geomechanically","content":"arXiv:2510.07564v1 Announce Type: cross Abstract: Accurate wellbore trajectory prediction is a paramount challenge in subsurface engineering, governed by complex interactions between the drilling assembly and heterogeneous geological formations. This research establishes a comprehensive, mathematically rigorous framework for trajectory prediction that moves beyond empirical modeling to a geomechanically-informed, data-driven surrogate approach.The study leverages Log ASCII Standard (LAS) and wellbore deviation (DEV) data from 14 wells in the Gulfaks oil field, treating petrophysical logs not merely as input features, but as proxies for the mechanical properties of the rock that fundamentally govern drilling dynamics. A key contribution of this work is the formal derivation of wellbore kinematic models, including the Average Angle method and Dogleg Severity, from the first principles of vector calculus and differential geometry, contextualizing them as robust numerical integration schemes. The core of the predictive model is a Gated Recurrent Unit (GRU) network, for which we provide a complete, step-by-step derivation of the forward propagation dynamics and the Backpropagation Through Time (BPTT) training algorithm. This detailed theoretical exposition, often omitted in applied studies, clarifies the mechanisms by which the network learns temporal dependencies. The methodology encompasses a theoretically justified data preprocessing pipeline, including feature normalization, uniform depth resampling, and sequence generation. Trajectory post-processing and error analysis are conducted using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and the Coefficient of Determination (R2).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07564","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.350134","language":"en","tags":["csna","physicsgeo-ph","computer-science","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":225,"author":"Shubham Kumar, Anshuman Sahoo","raw_content_length":1717,"priority":7,"update_frequency":1,"reading_time_minutes":1.125,"robust_parsing_used":true,"entities":{"organizations":["DEV","Gulfaks","LAS","Dogleg Severity"],"persons":["Log ASCII Standard"],"locations":["Average Angle"],"monetary":[]},"char_count":1716,"language_detected":"en","key_concepts":{"key_phrases":["cross","Accurate wellbore trajectory prediction","a paramount challenge","subsurface engineering","complex interactions","the drilling assembly","heterogeneous geological formations","This research","a comprehensive mathematically rigorous framework","trajectory prediction"],"filter_categories":{"research_academic":["This research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"cross":1.0,"Accurate wellbore trajectory prediction":1.0,"a paramount challenge":1.0,"subsurface engineering":1.0,"complex interactions":1.0,"the drilling assembly":1.0,"heterogeneous geological formations":1.0,"This research":1.0,"a comprehensive mathematically rigorous framework":1.0,"trajectory prediction":1.0}},"age_hours":2.777358552222222,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5706,"joy":0.034,"surprise":0.0218,"sadness":0.0094,"fear":0.2949,"anger":0.0468,"disgust":0.0225},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving wellbore trajectory prediction using geomechanical data and machine learning. While it aims to improve drilling efficiency, it doesn't directly address GHG emissions or climate change. The study uses data from 14 wells and provides error analysis metrics (MAE, RMSE, R2), but lacks deployment data or economic viability analysis.","key_impact_metrics":["MAE","RMSE","R2"],"technology_tags":["geomechanics","machine learning","wellbore trajectory prediction"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-28T20:48:31.857499Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7f2aa7091c08","title":"Locality","content":"arXiv:2510.07594v1 Announce Type: cross Abstract: Charged particle track reconstruction is a foundational task in collider experiments and the main computational bottleneck in particle reconstruction. Graph neural networks (GNNs) have shown strong performance for this problem, but costly graph construction, irregular computations, and random memory access patterns substantially limit their throughput. The recently proposed Hashing-based Efficient Point Transformer (HEPT) offers a theoretically guaranteed near-linear complexity for large point cloud processing via locality-sensitive hashing (LSH) in attention computations; however, its evaluations have largely focused on embedding quality, and the object condensation pipeline on which HEPT relies requires a post-hoc clustering step (e.g., DBScan) that can dominate runtime. In this work, we make two contributions. First, we present a unified, fair evaluation of physics tracking performance for HEPT and a representative GNN-based pipeline under the same dataset and metrics. Second, we introduce HEPTv2 by extending HEPT with a lightweight decoder that eliminates the clustering stage and directly predicts track assignments. This modification preserves HEPT's regular, hardware-friendly computations while enabling ultra-fast end-to-end inference. On the TrackML dataset, optimized HEPTv2 achieves approximately 28 ms per event on an A100 while maintaining competitive tracking efficiency. These results position HEPTv2 as a practical, scalable alternative to GNN-based pipelines for fast tracking.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07594","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.350542","language":"en","tags":["hep-ex","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Shitij Govil, Jack P. Rodgers, Yuan-Tang Chou, Siqi Miao, Amit Saha, Advaith Anand, Kilian Lieret, Gage DeZoort, Mia Liu, Javier Duarte, Pan Li, Shih-Chieh Hsu","raw_content_length":1562,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["GNN","HEPT","Hashing","Efficient Point Transformer"],"persons":["Announce Type"],"locations":["Locality"],"monetary":[]},"char_count":1561,"language_detected":"en","key_concepts":{"key_phrases":["Locality","arXiv251007594v1 Announce Type","cross","Abstract","Charged particle track reconstruction","a foundational task","experiments","the main computational bottleneck","particle reconstruction","Graph neural networks"],"filter_categories":{"ai_ml":["the main computational bottleneck","Graph neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Locality":2.0,"arXiv251007594v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Charged particle track reconstruction":1.0,"a foundational task":1.0,"experiments":1.0,"the main computational bottleneck":1.0,"particle reconstruction":1.0,"Graph neural networks":1.0}},"age_hours":2.77737226,"is_recent":true,"quality_score":1.0,"sentiment_score":7.459,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4918,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8907,"joy":0.014,"surprise":0.0365,"sadness":0.0158,"fear":0.0078,"anger":0.0237,"disgust":0.0116},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (HEPTv2) for particle track reconstruction, achieving a processing time of approximately 28 ms per event on an A100 GPU. While the research is peer-reviewed and presents specific performance metrics, it is still in the applied research stage with no evidence of real-world deployment. The climate impact is indirect, potentially reducing energy consumption in particle physics experiments, but the magnitude is unclear.","key_impact_metrics":["28 ms per event on A100"],"technology_tags":["Graph Neural Networks","Locality-Sensitive Hashing","Particle Tracking"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:48:34.738482Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e12704769100","title":"Beyond Hoeffding and Chernoff: Trading conclusiveness for advantages in quantum hypothesis testing","content":"arXiv:2510.07601v1 Announce Type: cross Abstract: The ultimate limits of quantum state discrimination are often thought to be captured by asymptotic bounds that restrict the achievable error probabilities, notably the quantum Chernoff and Hoeffding bounds. Here we study hypothesis testing protocols that are permitted a probability of producing an inconclusive discrimination outcome, and investigate their performance when this probability is suitably constrained. We show that even by allowing an arbitrarily small probability of inconclusiveness, the limits imposed by the quantum Hoeffding and Chernoff bounds can be significantly exceeded, completely circumventing the conventional trade-offs between error exponents in hypothesis testing. Furthermore, such improvements over standard state discrimination are robust and can be obtained even when an exponentially vanishing probability of inconclusive outcomes is demanded. Relaxing the constraints on the inconclusive probability can enable even larger advantages, but this comes at a price. We show a 'strong converse' property of this setting: targeting error exponents beyond those achievable with vanishing inconclusiveness necessarily forces the probability of inconclusive outcomes to converge to one. By exactly quantifying the rate of this convergence, we give a complete characterisation of the trade-offs between error exponents and rates of conclusive outcome probabilities. Overall, our results provide a comprehensive asymptotic picture of how allowing inconclusive measurement outcomes reshapes optimal quantum hypothesis testing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.07601","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.350941","language":"en","tags":["mathit","math-ph","computer-science","preprints","csit","quant-ph","mathmp","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Kaiyuan Ji, Bartosz Regula","raw_content_length":1602,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Beyond Hoeffding","Announce Type","Chernoff"],"locations":[],"monetary":[]},"char_count":1601,"language_detected":"en","key_concepts":{"key_phrases":["Hoeffding","Chernoff","advantages","quantum hypothesis testing","arXiv251007601v1 Announce Type","cross","The ultimate limits","quantum state discrimination","asymptotic bounds","the achievable error probabilities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hoeffding":2.0,"Chernoff":2.0,"advantages":2.0,"quantum hypothesis testing":2.0,"arXiv251007601v1 Announce Type":1.0,"cross":1.0,"The ultimate limits":1.0,"quantum state discrimination":1.0,"asymptotic bounds":1.0,"the achievable error probabilities":1.0}},"age_hours":2.7773856599999998,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9107,"joy":0.0309,"surprise":0.0338,"sadness":0.0028,"fear":0.0061,"anger":0.0113,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This is theoretical research exploring improvements in quantum hypothesis testing. While it could potentially lead to more efficient data analysis in various fields, including climate modeling or materials discovery for sustainable technologies, there are no concrete actions or measurable outcomes related to sustainability at this stage. It's basic research with potential but unproven impact.","key_impact_metrics":[],"technology_tags":["quantum computing","hypothesis testing","data analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:48:37.478354Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
