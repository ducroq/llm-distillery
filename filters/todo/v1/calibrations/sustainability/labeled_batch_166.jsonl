{"id":"science_arxiv_cs_0d051fbf73de","title":"Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi","content":"arXiv:2510.12555v1 Announce Type: new Abstract: The competitive and cooperative forces of natural selection have driven the evolution of intelligence for millions of years, culminating in nature's vast biodiversity and the complexity of human minds. Inspired by this process, we propose a novel multi-agent reinforcement learning framework where each agent is assigned a genotype and where reward functions are modelled after the concept of inclusive fitness. An agent's genetic material may be shared with other agents, and our inclusive reward function naturally accounts for this. We study the resulting social dynamics in two types of network games with prisoner's dilemmas and find that our results align with well-established principles from biology, such as Hamilton's rule. Furthermore, we outline how this framework can extend to more open-ended environments with spatial and temporal structure, finite resources, and evolving populations. We hypothesize the emergence of an arms race of strategies, where each new strategy is a gradual improvement over earlier adaptations of other agents, effectively producing a multi-agent autocurriculum analogous to biological evolution. In contrast to the binary team-based structures prevalent in earlier research, our gene-based reward structure introduces a spectrum of cooperation ranging from full adversity to full cooperativeness based on genetic similarity, enabling unique non team-based social dynamics. For example, one agent having a mutual cooperative relationship with two other agents, while the two other agents behave adversarially towards each other. We argue that incorporating inclusive fitness in agents provides a foundation for the emergence of more strategically advanced and socially intelligent agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12555","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.398683","language":"en","tags":["preprints","csai","cssi","computer-science","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Andries Rosseau, Rapha\\\"el Avalos, Ann Now\\'e","raw_content_length":1778,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":["Inclusive Fitness"],"persons":["Hamilton"],"locations":[],"monetary":[]},"char_count":1777,"language_detected":"en","key_concepts":{"key_phrases":["Inclusive Fitness","a Key Step","More Advanced Social Behaviors","Multi","arXiv251012555v1 Announce Type","new Abstract","The competitive and cooperative forces","natural selection","the evolution","intelligence"],"filter_categories":{"ai_ml":["intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Inclusive Fitness":2.0,"a Key Step":2.0,"More Advanced Social Behaviors":2.0,"Multi":2.0,"arXiv251012555v1 Announce Type":1.0,"new Abstract":1.0,"The competitive and cooperative forces":1.0,"natural selection":1.0,"the evolution":1.0,"intelligence":1.0}},"age_hours":2.7423963083333334,"is_recent":true,"quality_score":1.0,"sentiment_score":9.788499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9577,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7678,"joy":0.0983,"surprise":0.0821,"sadness":0.0048,"fear":0.0119,"anger":0.0278,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article proposes a novel multi-agent reinforcement learning framework inspired by inclusive fitness. While the concept is interesting and aligns with biological principles, it's currently in the early stages of development with no concrete deployment or measurable outcomes related to sustainability. The framework is being tested in network games, but there's no evidence of real-world impact on climate or other sustainability dimensions.","key_impact_metrics":[],"technology_tags":["multi-agent reinforcement learning","inclusive fitness","network games"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T16:27:32.248176Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_56d1d5d4de4b","title":"Timeliness, Consensus, and Composition of the Crowd: Community Notes on X","content":"arXiv:2510.12559v1 Announce Type: new Abstract: This study presents the first large-scale quantitative analysis of the efficiency of X's Community Notes, a crowdsourced moderation system for identifying and contextualising potentially misleading content. Drawing on over 1.8 million notes, we examine three key dimensions of crowdsourced moderation: participation inequality, consensus formation, and timeliness. Despite the system's goal of collective moderation, we find substantial concentration effect, with the top 10% of contributors producing 58% of all notes (Gini Coefficient = 0.68). The observed consensus is rare-only 11.5% of notes reach agreement on publication, while 69% of posts receive conflicting classifications. A majority of noted posts (approximately 68%) are annotated as \"Note Not Needed\", reflecting the repurposing of the platform for debate rather than moderation. We found that such posts are paradoxically more likely to yield published notes (OR = 3.12). Temporal analyses show that the notes, on average, are published 65.7 hours after the original post, with longer delays significantly reducing the likelihood of consensus. These results portray Community Notes as a stratified, deliberative system dominated by a small contributor elite, marked by persistent dissensus, and constrained by timeliness. We conclude this study by outlining design strategies to promote equity, faster consensus, and epistemic reliability in community-based moderation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12559","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.399095","language":"en","tags":["preprints","cssi","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Olesya Razuvayevskaya, Adel Tayebi, Ulrikke Dybdal S{\\o}rensen, Kalina Bontcheva, Richard Rogers","raw_content_length":1484,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["X's Community Notes"],"persons":[],"locations":[],"monetary":[]},"char_count":1483,"language_detected":"en","key_concepts":{"key_phrases":["Timeliness","Consensus","Composition","the Crowd","Community Notes","arXiv251012559v1 Announce Type","new Abstract","This study","the first large-scale quantitative analysis","the efficiency"],"filter_categories":{"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Timeliness":2.0,"Consensus":2.0,"Composition":2.0,"the Crowd":2.0,"Community Notes":2.0,"arXiv251012559v1 Announce Type":1.0,"new Abstract":1.0,"This study":1.0,"the first large-scale quantitative analysis":1.0,"the efficiency":1.0}},"age_hours":2.742411513611111,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8917,"joy":0.018,"surprise":0.0346,"sadness":0.0039,"fear":0.006,"anger":0.0251,"disgust":0.0206},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research analyzes the effectiveness of a crowdsourced moderation system on X. While it doesn't directly impact climate change, it examines the dynamics of online information, which can indirectly influence public perception and action on sustainability issues. The study uses quantitative analysis of a large dataset and presents specific metrics related to participation, consensus, and timeliness.","key_impact_metrics":["Top 10% contributors produce 58% of notes","Notes published 65.7 hours after original post"],"technology_tags":["Crowdsourced moderation","Online information systems"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:27:35.258678Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3ae818e66d41","title":"HardcoreLogic: Challenging Large Reasoning Models with Long","content":"arXiv:2510.12563v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance on complex tasks, including logical puzzle games that require deriving solutions satisfying all constraints. However, whether they can flexibly apply appropriate rules to varying conditions, particularly when faced with non-canonical game variants, remains an open question. Existing corpora focus on popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats and memorization of solution patterns, which can mask deficiencies in understanding novel rules or adapting strategies to new variants. To address this, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles across 10 games, designed to test the robustness of LRMs on the \"long-tail\" of logical games. HardcoreLogic systematically transforms canonical puzzles through three dimensions: Increased Complexity (IC), Uncommon Elements (UE), and Unsolvable Puzzles (UP), reducing reliance on shortcut memorization. Evaluations on a diverse set of LRMs reveal significant performance drops, even for models achieving top scores on existing benchmarks, indicating heavy reliance on memorized stereotypes. While increased complexity is the dominant source of difficulty, models also struggle with subtle rule variations that do not necessarily increase puzzle difficulty. Our systematic error analysis on solvable and unsolvable puzzles further highlights gaps in genuine reasoning. Overall, HardcoreLogic exposes the limitations of current LRMs and establishes a benchmark for advancing high-level logical reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12563","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.399901","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Jingcong Liang, Shijun Wan, Xuehai Wu, Siyuan Wang, Yitong Li, Qianglong Chen, Duyu Tang, Zhongyu Wei","raw_content_length":1623,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Uncommon Eleme","HardcoreLogic"],"persons":[],"locations":["LRMs"],"monetary":[]},"char_count":1622,"language_detected":"en","key_concepts":{"key_phrases":["Large Reasoning Models","HardcoreLogic","Long","arXiv251012563v1 Announce Type","new Abstract","LRMs","impressive performance","complex tasks","logical puzzle games","deriving solutions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Reasoning Models":3.0,"HardcoreLogic":2.0,"Long":2.0,"arXiv251012563v1 Announce Type":1.0,"new Abstract":1.0,"LRMs":1.0,"impressive performance":1.0,"complex tasks":1.0,"logical puzzle games":1.0,"deriving solutions":1.0}},"age_hours":2.742440650833333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.674499999999998,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9349,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8495,"joy":0.0394,"surprise":0.0711,"sadness":0.0043,"fear":0.0136,"anger":0.0174,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (HardcoreLogic) to test the reasoning capabilities of Large Reasoning Models (LRMs). While the research itself doesn't directly impact climate change, it could indirectly contribute by improving AI's ability to solve complex problems related to sustainability. The benchmark is tested on existing LRMs, revealing performance drops, but there are no deployed applications or measurable outcomes related to climate change at this stage.","key_impact_metrics":["Performance drops on HardcoreLogic benchmark","5000 puzzles across 10 games"],"technology_tags":["Large Reasoning Models","Artificial Intelligence","Benchmark"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:27:38.155928Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0005e28491a3","title":"MMOT: The First Challenging Benchmark for Drone","content":"arXiv:2510.12565v1 Announce Type: new Abstract: Drone-based multi-object tracking is essential yet highly challenging due to small targets, severe occlusions, and cluttered backgrounds. Existing RGB-based tracking algorithms heavily depend on spatial appearance cues such as color and texture, which often degrade in aerial views, compromising reliability. Multispectral imagery, capturing pixel-level spectral reflectance, provides crucial cues that enhance object discriminability under degraded spatial conditions. However, the lack of dedicated multispectral UAV datasets has hindered progress in this domain. To bridge this gap, we introduce MMOT, the first challenging benchmark for drone-based multispectral multi-object tracking. It features three key characteristics: (i) Large Scale - 125 video sequences with over 488.8K annotations across eight categories; (ii) Comprehensive Challenges - covering diverse conditions such as extreme small targets, high-density scenarios, severe occlusions, and complex motion; and (iii) Precise Oriented Annotations - enabling accurate localization and reduced ambiguity under aerial perspectives. To better extract spectral features and leverage oriented annotations, we further present a multispectral and orientation-aware MOT scheme adapting existing methods, featuring: (i) a lightweight Spectral 3D-Stem integrating spectral features while preserving compatibility with RGB pretraining; (ii) an orientation-aware Kalman filter for precise state estimation; and (iii) an end-to-end orientation-adaptive transformer. Extensive experiments across representative trackers consistently show that multispectral input markedly improves tracking performance over RGB baselines, particularly for small and densely packed objects. We believe our work will advance drone-based multispectral multi-object tracking research. Our MMOT, code, and benchmarks are publicly available at https://github.com/Annzstbl/MMOT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12565","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.400323","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Tianhao Li, Tingfa Xu, Ying Wang, Haolin Qin, Xu Lin, Jianan Li","raw_content_length":1955,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["UAV"],"persons":["Large Scale - 125"],"locations":[],"monetary":[]},"char_count":1954,"language_detected":"en","key_concepts":{"key_phrases":["MMOT","The First Challenging Benchmark","Drone","arXiv251012565v1 Announce Type","new Abstract","Drone-based multi-object tracking","small targets","severe occlusions","cluttered backgrounds","Existing RGB-based tracking algorithms"],"filter_categories":{"ai_ml":["Existing RGB-based tracking algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MMOT":2.0,"The First Challenging Benchmark":2.0,"Drone":2.0,"arXiv251012565v1 Announce Type":1.0,"new Abstract":1.0,"Drone-based multi-object tracking":1.0,"small targets":1.0,"severe occlusions":1.0,"cluttered backgrounds":1.0,"Existing RGB-based tracking algorithms":1.0}},"age_hours":2.7424552575,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6995000000000005,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4601,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8861,"joy":0.0064,"surprise":0.021,"sadness":0.0129,"fear":0.027,"anger":0.0249,"disgust":0.0218},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel benchmark dataset (MMOT) for drone-based multispectral multi-object tracking. While the research itself doesn't directly reduce emissions, it could indirectly contribute to sustainability by improving drone applications in areas like environmental monitoring or precision agriculture. The dataset includes 488.8K annotations across eight categories, providing a basis for further research, but it is still in the applied research stage with no deployed units.","key_impact_metrics":["488.8K annotations","125 video sequences"],"technology_tags":["multispectral imaging","drone technology","object tracking"],"sdg_alignment":[2,9,11,13,15],"analyzed_at":"2025-10-29T16:27:41.713320Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9a500605fc38","title":"LayerSync: Self","content":"arXiv:2510.12581v1 Announce Type: new Abstract: We propose LayerSync, a domain-agnostic approach for improving the generation quality and the training efficiency of diffusion models. Prior studies have highlighted the connection between the quality of generation and the representations learned by diffusion models, showing that external guidance on model intermediate representations accelerates training. We reconceptualize this paradigm by regularizing diffusion models with their own intermediate representations. Building on the observation that representation quality varies across diffusion model layers, we show that the most semantically rich representations can act as an intrinsic guidance for weaker ones, reducing the need for external supervision. Our approach, LayerSync, is a self-sufficient, plug-and-play regularizer term with no overhead on diffusion model training and generalizes beyond the visual domain to other modalities. LayerSync requires no pretrained models nor additional data. We extensively evaluate the method on image generation and demonstrate its applicability to other domains such as audio, video, and motion generation. We show that it consistently improves the generation quality and the training efficiency. For example, we speed up the training of flow-based transformer by over 8.75x on ImageNet dataset and improved the generation quality by 23.6%. The code is available at https://github.com/vita-epfl/LayerSync.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12581","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.401894","language":"en","tags":["preprints","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Yasaman Haghighi, Bastien van Delft, Mariam Hassan, Alexandre Alahi","raw_content_length":1458,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["LayerSync"],"persons":[],"locations":[],"monetary":[]},"char_count":1457,"language_detected":"en","key_concepts":{"key_phrases":["LayerSync","diffusion models","Self","arXiv251012581v1 Announce Type","new Abstract","a domain-agnostic approach","the generation quality","the training efficiency","Prior studies","the connection"],"filter_categories":{"ai_ml":["a domain-agnostic approach"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LayerSync":3.0,"diffusion models":3.0,"Self":2.0,"arXiv251012581v1 Announce Type":1.0,"new Abstract":1.0,"a domain-agnostic approach":1.0,"the generation quality":1.0,"the training efficiency":1.0,"Prior studies":1.0,"the connection":1.0}},"age_hours":2.742511415,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8397,"joy":0.0527,"surprise":0.0798,"sadness":0.0044,"fear":0.0079,"anger":0.0119,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (LayerSync) to improve the training efficiency and generation quality of diffusion models, potentially leading to reduced energy consumption during AI model training. The method is evaluated on image generation and other domains, showing a speedup of 8.75x on ImageNet and a 23.6% improvement in generation quality. However, it remains in the applied research stage with no deployed units or commercial applications.","key_impact_metrics":["8.75x speed up on ImageNet","23.6% improvement in generation quality"],"technology_tags":["diffusion models","machine learning","AI training efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:27:45.483292Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b8040d7a536","title":"Easy-to","content":"arXiv:2510.12583v1 Announce Type: new Abstract: Convenient, easy to implement stochastic integration methods are developed on the basis of abstract one-step deterministic order $p$ integration techniques. The abstraction as an arbitrary one step map allows the inspection of easy to implement stochastic exponential time differencing Runge-Kutta (SETDRK), stochastic integrating factor Runge-Kutta (SIFRK) and stochastic RK (SRK) schemes. Such schemes require minimal modifications to existing deterministic schemes and converging to the Stratonovich SDE, whilst inheriting many of their desirable properties. These schemes capture all symmetric terms in the Stratonovich-Taylor expansion, are order $p$ in the limit of vanishing noise, can attain at least strong order $p/2$ or $p/2-1/2$ (parity dependent) for drift commutative noise, strong order $1$ for commutative noise, and strong order $1/2$ for multidimensional non-commutative noise. Numerical convergence is demonstrated using different bases of noise for 2nd, 3rd and 4th order SETDRK, SIFRK and SRK schemes for a stochastic KdV equation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12583","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.402632","language":"en","tags":["preprints","mathna","csna","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"J. Woodfield, A. Lobbe","raw_content_length":1103,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Runge-Kutta"],"persons":["Announce Type","Stratonovich"],"locations":[],"monetary":["$1/2$","$1$","$p/2$"]},"char_count":1100,"language_detected":"en","key_concepts":{"key_phrases":["Easy","arXiv251012583v1 Announce Type","new Abstract","stochastic integration methods","the basis","abstract one-step deterministic order","p integration techniques","The abstraction","an arbitrary one step map","the inspection"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Easy":2.0,"arXiv251012583v1 Announce Type":1.0,"new Abstract":1.0,"stochastic integration methods":1.0,"the basis":1.0,"abstract one-step deterministic order":1.0,"p integration techniques":1.0,"The abstraction":1.0,"an arbitrary one step map":1.0,"the inspection":1.0}},"age_hours":2.742534986111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8311,"joy":0.1131,"surprise":0.0372,"sadness":0.0029,"fear":0.0028,"anger":0.0075,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents new stochastic integration methods, which could potentially improve the accuracy and efficiency of simulations used in climate modeling or other energy-related fields. The impact potential is low because it is theoretical research with no immediate deployment or quantifiable impact on GHG emissions. The technical credibility is high due to the mathematical rigor and demonstration of numerical convergence.","key_impact_metrics":["strong order 1/2 for multidimensional non-commutative noise","order $p$ in the limit of vanishing noise"],"technology_tags":["stochastic integration","numerical methods","Runge-Kutta schemes"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:27:48.670135Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8ee06092ecf6","title":"Advancing End-to-End Pixel Space Generative Modeling via Self","content":"arXiv:2510.12586v1 Announce Type: new Abstract: Pixel-space generative models are often more difficult to train and generally underperform compared to their latent-space counterparts, leaving a persistent performance and efficiency gap. In this paper, we introduce a novel two-stage training framework that closes this gap for pixel-space diffusion and consistency models. In the first stage, we pre-train encoders to capture meaningful semantics from clean images while aligning them with points along the same deterministic sampling trajectory, which evolves points from the prior to the data distribution. In the second stage, we integrate the encoder with a randomly initialized decoder and fine-tune the complete model end-to-end for both diffusion and consistency models. Our training framework demonstrates strong empirical performance on ImageNet dataset. Specifically, our diffusion model reaches an FID of 2.04 on ImageNet-256 and 2.35 on ImageNet-512 with 75 number of function evaluations (NFE), surpassing prior pixel-space methods by a large margin in both generation quality and efficiency while rivaling leading VAE-based models at comparable training cost. Furthermore, on ImageNet-256, our consistency model achieves an impressive FID of 8.82 in a single sampling step, significantly surpassing its latent-space counterpart. To the best of our knowledge, this marks the first successful training of a consistency model directly on high-resolution images without relying on pre-trained VAEs or diffusion models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12586","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.403036","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Jiachen Lei, Keli Liu, Julius Berner, Haiming Yu, Hongkai Zheng, Jiahong Wu, Xiangxiang Chu","raw_content_length":1529,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["ImageNet"],"persons":[],"locations":[],"monetary":[]},"char_count":1528,"language_detected":"en","key_concepts":{"key_phrases":["End","Self","arXiv251012586v1 Announce Type","new Abstract","Pixel-space generative models","their latent-space counterparts","a persistent performance and efficiency gap","this paper","a novel two-stage training framework","this gap"],"filter_categories":{"ai_ml":["a novel two-stage training framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"End":2.0,"Self":2.0,"arXiv251012586v1 Announce Type":1.0,"new Abstract":1.0,"Pixel-space generative models":1.0,"their latent-space counterparts":1.0,"a persistent performance and efficiency gap":1.0,"this paper":1.0,"a novel two-stage training framework":1.0,"this gap":1.0}},"age_hours":2.7425499422222224,"is_recent":true,"quality_score":1.0,"sentiment_score":7.559,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5118,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9315,"joy":0.0089,"surprise":0.0196,"sadness":0.003,"fear":0.0148,"anger":0.0134,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel two-stage training framework for pixel-space generative models, demonstrating improved performance on the ImageNet dataset. While the improved efficiency in image generation could indirectly reduce energy consumption in related applications, the direct climate impact is minimal at this stage. The research is in its early stages and lacks deployment or economic viability data.","key_impact_metrics":["FID of 2.04 on ImageNet-256","FID of 2.35 on ImageNet-512"],"technology_tags":["Generative Modeling","Diffusion Models","Consistency Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:27:52.042161Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e2321d0bfa3","title":"Teaching Language Models to Faithfully Express their Uncertainty","content":"arXiv:2510.12587v1 Announce Type: new Abstract: Large language models (LLMs) often miscommunicate their uncertainty: repeated queries can produce divergent answers, yet generated responses are typically unhedged or hedged in ways that do not reflect this variability. This conveys unfaithful information about the uncertain state of the LLMs' knowledge, creating a faithfulness gap that affects even strong LLMs. We introduce Faithful Uncertainty Tuning (FUT): a fine-tuning approach that teaches instruction-tuned LLMs to express uncertainty faithfully without altering their underlying answer distribution. We construct training data by augmenting model samples with uncertainty hedges (i.e. verbal cues such as 'possibly' or 'likely') aligned with sample consistency, requiring no supervision beyond the model and a set of prompts. We evaluate FUT on open-domain question answering (QA) across multiple models and datasets. Our results show that FUT substantially reduces the faithfulness gap, while preserving QA accuracy and introducing minimal semantic distribution shift. Further analyses demonstrate robustness across decoding strategies, choice of hedgers, and other forms of uncertainty expression (i.e. numerical). These findings establish FUT as a simple and effective way to teach LLMs to communicate uncertainty faithfully.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12587","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.405074","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Bryan Eikema, Evgenia Ilia, Jos\\'e G. C. de Souza, Chrysoula Zerva, Wilker Aziz","raw_content_length":1338,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Faithfully Express"],"persons":[],"locations":[],"monetary":[]},"char_count":1337,"language_detected":"en","key_concepts":{"key_phrases":["Language Models","their Uncertainty","arXiv251012587v1 Announce Type","new Abstract","Large language models","LLMs","their uncertainty","repeated queries","divergent answers","generated responses"],"filter_categories":{"ai_ml":["their Uncertainty","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Language Models":2.0,"their Uncertainty":2.0,"arXiv251012587v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"their uncertainty":1.0,"repeated queries":1.0,"divergent answers":1.0,"generated responses":1.0}},"age_hours":2.7425647211111115,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7112,"joy":0.0111,"surprise":0.0076,"sadness":0.036,"fear":0.1689,"anger":0.0346,"disgust":0.0306},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a fine-tuning approach (FUT) to improve the faithfulness of LLMs in expressing uncertainty. While the approach is technically sound and shows promise in reducing the faithfulness gap, it is still in the applied research stage with no real-world deployment or quantified climate impact. The impact on sustainability is indirect, as more reliable information from LLMs could potentially improve decision-making in climate-related fields, but this is speculative.","key_impact_metrics":["Reduced faithfulness gap","Preserved QA accuracy"],"technology_tags":["Large Language Models","Uncertainty Quantification","Fine-tuning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:27:55.175762Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_04ee87f0bf48","title":"Enhancing Robust Multi","content":"arXiv:2510.12589v1 Announce Type: new Abstract: In the transition toward a sustainable power system, renewable-based Virtual Power Plants (RVPPs) have emerged as a promising solution to the challenges of integrating renewable energy sources into electricity markets. Their viability, however, depends on effective market participation strategies and the ability to manage uncertainties while leveraging flexible resources. This paper analyzes the impact of different flexible resources - such as concentrated solar power plants, hydro plants, biomass plants, and flexible demand - on the participation of RVPPs in energy and reserve markets. Multiple sources of uncertainty in generation, consumption, and electricity prices are addressed using a two-stage robust optimization approach. The contribution of different technologies to RVPP profitability is evaluated through a marginal contribution method, ensuring fair allocation of profits among them according to their actual role in energy and reserve provision across markets. Simulations for an RVPP in southern Spain demonstrate how strategic decisions and the availability of flexible resources influence viability, market participation, and unit scheduling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12589","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.405487","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Hadi Nemati, \\'Alvaro Ortega, Pedro S\\'anchez-Mart\\'in, Lukas Sigrist, Luis Rouco, Ignacio Egido","raw_content_length":1216,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Virtual Power Plants"],"persons":[],"locations":[],"monetary":[]},"char_count":1215,"language_detected":"en","key_concepts":{"key_phrases":["Robust Multi","arXiv251012589v1","Announce Type","new Abstract","the transition","a sustainable power system","renewable-based Virtual Power Plants","RVPPs","a promising solution","the challenges"],"filter_categories":{"ai_ml":["a sustainable power system"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Multi":2.0,"arXiv251012589v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"the transition":1.0,"a sustainable power system":1.0,"renewable-based Virtual Power Plants":1.0,"RVPPs":1.0,"a promising solution":1.0,"the challenges":1.0}},"age_hours":2.742578935277778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.637,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9274,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7819,"joy":0.0313,"surprise":0.0138,"sadness":0.0059,"fear":0.1056,"anger":0.0376,"disgust":0.0239},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":6,"economic_viability":5,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper analyzes the impact of flexible resources on RVPP participation in energy and reserve markets using a two-stage robust optimization approach. Simulations are performed for an RVPP in southern Spain, providing some evidence. However, it's still in the simulation stage, not a deployed technology with measured real-world outcomes.","key_impact_metrics":["profitability contribution","market participation"],"technology_tags":["Virtual Power Plants","Renewable Energy","Robust Optimization"],"sdg_alignment":[7,13],"analyzed_at":"2025-10-29T16:27:58.339573Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_396e779f68a0","title":"Research in Collaborative Learning Does Not Serve Cross","content":"arXiv:2510.12595v1 Announce Type: new Abstract: Cross-silo federated learning (FL) is a promising approach to enable cross-organization collaboration in machine learning model development without directly sharing private data. Despite growing organizational interest driven by data protection regulations such as GDPR and HIPAA, the adoption of cross-silo FL remains limited in practice. In this paper, we conduct an interview study to understand the practical challenges associated with cross-silo FL adoption. With interviews spanning a diverse set of stakeholders such as user organizations, software providers, and academic researchers, we uncover various barriers, from concerns about model performance to questions of incentives and trust between participating organizations. Our study shows that cross-silo FL faces a set of challenges that have yet to be well-captured by existing research in the area and are quite distinct from other forms of federated learning such as cross-device FL. We end with a discussion on future research directions that can help overcome these challenges.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12595","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.406316","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Kevin Kuo, Chhavi Yadav, Virginia Smith","raw_content_length":1093,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["GDPR","Collaborative Learning Does Not Serve","HIPAA"],"persons":[],"locations":[],"monetary":[]},"char_count":1092,"language_detected":"en","key_concepts":{"key_phrases":["Research","Collaborative Learning","Cross","arXiv251012595v1 Announce Type","new Abstract","Cross-silo federated learning","a promising approach","cross-organization collaboration","machine learning model development","private data"],"filter_categories":{"healthcare_tech":["Research"],"research_academic":["Research"],"ai_ml":["machine learning model development"],"engineering":["machine learning model development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Research":2.0,"Collaborative Learning":2.0,"Cross":2.0,"arXiv251012595v1 Announce Type":1.0,"new Abstract":1.0,"Cross-silo federated learning":1.0,"a promising approach":1.0,"cross-organization collaboration":1.0,"machine learning model development":1.0,"private data":1.0}},"age_hours":2.742608609166667,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2655,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5469,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8971,"joy":0.0166,"surprise":0.0316,"sadness":0.0076,"fear":0.0199,"anger":0.0158,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies challenges in cross-silo federated learning, which could indirectly support sustainability by enabling data sharing for climate modeling or resource management. However, it's in the early stages (interview study) with no deployed technology or measured outcomes. The impact is theoretical and depends on future applications.","key_impact_metrics":[],"technology_tags":["federated learning","machine learning"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T16:28:01.604670Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f14cae2dd35","title":"Low Latency, High Bandwidth Streaming of Experimental Data with EJFAT","content":"arXiv:2510.12597v1 Announce Type: new Abstract: Thomas Jefferson National Accelerator Facility (JLab) has partnered with Energy Sciences Network (ESnet) to define and implement an edge to compute cluster computational load balancing acceleration architecture. The ESnet-JLab FPGA Accelerated Transport (EJFAT) architecture focuses on FPGA acceleration to address compression, fragmentation, UDP packet destination redirection (Network Address Translation (NAT)) and decompression and reassembly. EJFAT seamlessly integrates edge and cluster computing to support direct processing of streamed experimental data. This will directly benefit the JLab science program as well as data centers of the future that require high throughput and low latency for both time-critical data acquisition systems and data center workflows. The EJFAT project will be presented along with how it is synergistic with other DOE activities such as an Integrated Research Infrastructure (IRI), and recent results using data sources at JLab, an EJFAT LB at ESnet, and computational cluster resources at Lawrence Berkeley National Laboratory (LBNL).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12597","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.406737","language":"en","tags":["preprints","computer-science","csdc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Ilya Baldin, Michael Goodrich, Vardan Gyurjyan, Graham Heyes, Derek Howard, Yatish Kumar, David Lawrence, Brad Sawatzky, Stacey Sheldon, Carl Timmer","raw_content_length":1127,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["EJFAT","Energy Sciences Network","Network Address Translation","DOE","UDP","NAT","Experimental Data","EJFAT arXiv:2510.12597v1 Announce Type","FPGA"],"persons":["Thomas Jefferson National","JLab","Bandwidth Streaming"],"locations":[],"monetary":[]},"char_count":1122,"language_detected":"en","key_concepts":{"key_phrases":["EJFAT","Low Latency","High Bandwidth Streaming","Experimental Data","arXiv251012597v1 Announce Type","new Abstract","Thomas Jefferson National Accelerator Facility","JLab","Energy Sciences Network","ESnet"],"filter_categories":{"research_academic":["Energy Sciences Network"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EJFAT":3.0,"Low Latency":2.0,"High Bandwidth Streaming":2.0,"Experimental Data":2.0,"arXiv251012597v1 Announce Type":1.0,"new Abstract":1.0,"Thomas Jefferson National Accelerator Facility":1.0,"JLab":1.0,"Energy Sciences Network":1.0,"ESnet":1.0}},"age_hours":2.7426229680555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9161,"joy":0.0118,"surprise":0.0418,"sadness":0.0061,"fear":0.0051,"anger":0.0129,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":4,"technical_credibility":6,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed architecture (EJFAT) for accelerating data processing between edge and cluster computing, with a focus on FPGA acceleration. It mentions results using data sources at JLab, an EJFAT LB at ESnet, and computational cluster resources at LBNL, indicating a pilot deployment. The sustainability impact is indirect, potentially reducing energy consumption in data centers by optimizing data flow, but lacks specific metrics.","key_impact_metrics":[],"technology_tags":["FPGA","Edge Computing","Data Compression","Network Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:05.051629Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_70bb65b400d7","title":"Lossless Derandomization for Undirected Single","content":"arXiv:2510.12598v1 Announce Type: new Abstract: A common step in algorithms related to shortest paths in undirected graphs is that, we select a subset of vertices as centers, then grow a ball around each vertex until a center is reached. We want the balls to be as small as possible. A randomized algorithm can uniformly sample $r$ centers to achieve the optimal (expected) ball size of $\\Theta(n/r)$. A folklore derandomization is to use the $O(\\log n)$ approximation for the set cover problem in the hitting set version where we want to hit all the balls with the centers. However, the extra $O(\\log n)$ factor is sometimes too expensive. For example, the recent $O(m\\sqrt{\\log n\\log\\log n})$ undirected single-source shortest path algorithm [DMSY23] beats Dijkstra's algorithm in sparse graphs, but the folklore derandomization would make it dominated by Dijkstra's. In this paper, we exploit the fact that the sizes of these balls can be adaptively chosen by the algorithm instead of fixed by the input. We propose a simple deterministic algorithm achieving the optimal ball size of $\\Theta(n/r)$ on average. Furthermore, given any polynomially large cost function of the ball size, we can still achieve the optimal cost on average. It allows us to derandomize [DMSY23], resulting in a deterministic $O(m\\sqrt{\\log n\\log\\log n})$ algorithm for undirected single-source shortest path. In addition, we show that the same technique can also be used to derandomize the seminal Thorup-Zwick approximate distance oracle [TZ05], also without any loss in the time/space complexity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12598","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.407151","language":"en","tags":["preprints","csds","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Shuyi Yan","raw_content_length":1584,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["n})$","Dijkstra"],"persons":[],"locations":[],"monetary":[]},"char_count":1577,"language_detected":"en","key_concepts":{"key_phrases":["Lossless Derandomization","Undirected Single","arXiv251012598v1 Announce Type","new Abstract","A common step","algorithms","shortest paths","undirected graphs","a subset","vertices"],"filter_categories":{"ai_ml":["algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lossless Derandomization":2.0,"Undirected Single":2.0,"arXiv251012598v1 Announce Type":1.0,"new Abstract":1.0,"A common step":1.0,"algorithms":1.0,"shortest paths":1.0,"undirected graphs":1.0,"a subset":1.0,"vertices":1.0}},"age_hours":2.742638716388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8988,"joy":0.0143,"surprise":0.0537,"sadness":0.006,"fear":0.0043,"anger":0.0139,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new deterministic algorithm for shortest path problems. While the algorithm itself doesn't directly reduce GHG emissions, it improves the efficiency of algorithms used in infrastructure planning and resource allocation, which could indirectly contribute to sustainability by optimizing resource use. The technical credibility is high due to the mathematical nature of the work and potential for peer review, but it's still in the research phase with no deployed applications.","key_impact_metrics":[],"technology_tags":["algorithm optimization","shortest path algorithms","derandomization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:08.547378Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_229020940480","title":"Reasoning in the Dark: Interleaved Vision","content":"arXiv:2510.12603v1 Announce Type: new Abstract: Multimodal reasoning aims to enhance the capabilities of MLLMs by incorporating intermediate reasoning steps before reaching the final answer. It has evolved from text-only reasoning to the integration of visual information, enabling the thought process to be conveyed through both images and text. Despite its effectiveness, current multimodal reasoning methods depend on explicit reasoning steps that require labor-intensive vision-text annotations and inherently introduce significant inference latency. To address these issues, we introduce multimodal latent reasoning with the advantages of multimodal representation, reduced annotation, and inference efficiency. To facilicate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR), which injects both visual and textual information in the reasoning process within the latent space. Specifically, IVT-LR represents each reasoning step by combining two implicit parts: latent text (the hidden states from the previous step) and latent vision (a set of selected image embeddings). We further introduce a progressive multi-stage training strategy to enable MLLMs to perform the above multimodal latent reasoning steps. Experiments on M3CoT and ScienceQA demonstrate that our IVT-LR method achieves an average performance increase of 5.45% in accuracy, while simultaneously achieving a speed increase of over 5 times compared to existing approaches. Code available at https://github.com/FYYDCC/IVT-LR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12603","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.407583","language":"en","tags":["preprints","csai","computer-science","research","cscl","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Chao Chen, Zhixin Ma, Yongqi Li, Yupeng Hu, Yinwei Wei, Wenjie Li, Liqiang Nie","raw_content_length":1512,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["IVT-LR"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1511,"language_detected":"en","key_concepts":{"key_phrases":["the Dark","arXiv251012603v1 Announce Type","new Abstract","Multimodal reasoning","the capabilities","MLLMs","intermediate reasoning steps","the final answer","text-only reasoning","the integration"],"filter_categories":{"ai_ml":["MLLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Dark":2.0,"arXiv251012603v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal reasoning":1.0,"the capabilities":1.0,"MLLMs":1.0,"intermediate reasoning steps":1.0,"the final answer":1.0,"text-only reasoning":1.0,"the integration":1.0}},"age_hours":2.7426529975,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9191,"joy":0.0157,"surprise":0.0306,"sadness":0.0099,"fear":0.0113,"anger":0.0071,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (IVT-LR) for improving the efficiency of multimodal reasoning in MLLMs, achieving a 5.45% accuracy increase and a 5x speed increase compared to existing approaches. While the research is promising, it is currently in the basic research stage with no deployed units or operational data, limiting its immediate sustainability impact. The potential climate impact is indirect, as improved AI efficiency could reduce energy consumption of AI models, but this is not explicitly quantified.","key_impact_metrics":["5.45% accuracy increase","5 times speed increase"],"technology_tags":["Multimodal Learning","Latent Reasoning","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:11.439878Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6291859fc117","title":"SMILE: SeMantic Ids Enhanced CoLd Item Representation for Click","content":"arXiv:2510.12604v1 Announce Type: new Abstract: With the rise of modern search and recommendation platforms, insufficient collaborative information of cold-start items exacerbates the Matthew effect of existing platform items, challenging platform diversity and becoming a longstanding issue. Existing methods align items' side content with collaborative information to transfer collaborative signals from high-popularity items to cold-start items. However, these methods fail to account for the asymmetry between collaboration and content, nor the fine-grained differences among items. To address these issues, we propose SMILE, an item representation enhancement approach based on fused alignment of semantic IDs. Specifically, we use RQ-OPQ encoding to quantize item content and collaborative information, followed by a two-step alignment: RQ encoding transfers shared collaborative signals across items, while OPQ encoding learns differentiated information of items. Comprehensive offline experiments on large-scale industrial datasets demonstrate superiority of SMILE, and rigorous online A/B tests confirm statistically significant improvements: item CTR +1.66%, buyers +1.57%, and order volume +2.17%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12604","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.407983","language":"en","tags":["preprints","csai","csir","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Qihang Zhao, Zhongbo Sun, Xiaoyang Zheng, Xian Guo, Siyuan Wang, Zihan Liang, Mingcan Peng, Ben Chen, Chenyi Lei","raw_content_length":1209,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["SMILE","OPQ","SeMantic Ids Enhanced CoLd Item Representation for Click arXiv:2510.12604v1 Announce Type"],"persons":["Matthew"],"locations":[],"monetary":[]},"char_count":1208,"language_detected":"en","key_concepts":{"key_phrases":["SMILE","SeMantic Ids Enhanced CoLd Item Representation","Click","cold-start items","arXiv251012604v1","Announce Type","new Abstract","the rise","modern search and recommendation platforms","insufficient collaborative information"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SMILE":2.0,"SeMantic Ids Enhanced CoLd Item Representation":2.0,"Click":2.0,"cold-start items":2.0,"arXiv251012604v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"the rise":1.0,"modern search and recommendation platforms":1.0,"insufficient collaborative information":1.0}},"age_hours":2.742667511666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.952,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5904,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8508,"joy":0.0118,"surprise":0.048,"sadness":0.0139,"fear":0.009,"anger":0.0519,"disgust":0.0145},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (SMILE) to improve click-through rates (CTR) in recommendation systems. While the online A/B tests show statistically significant improvements (+1.66% item CTR, +1.57% buyers, +2.17% order volume), the impact on sustainability is indirect and theoretical. The research is still in the applied research phase, with no large-scale deployment yet.","key_impact_metrics":["item CTR +1.66%","order volume +2.17%"],"technology_tags":["recommendation systems","machine learning","semantic IDs"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:28:14.230888Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3ea671732659","title":"StyleDecipher: Robust and Explainable Detection of LLM","content":"arXiv:2510.12608v1 Announce Type: new Abstract: With the increasing integration of large language models (LLMs) into open-domain writing, detecting machine-generated text has become a critical task for ensuring content authenticity and trust. Existing approaches rely on statistical discrepancies or model-specific heuristics to distinguish between LLM-generated and human-written text. However, these methods struggle in real-world scenarios due to limited generalization, vulnerability to paraphrasing, and lack of explainability, particularly when facing stylistic diversity or hybrid human-AI authorship. In this work, we propose StyleDecipher, a robust and explainable detection framework that revisits LLM-generated text detection using combined feature extractors to quantify stylistic differences. By jointly modeling discrete stylistic indicators and continuous stylistic representations derived from semantic embeddings, StyleDecipher captures distinctive style-level divergences between human and LLM outputs within a unified representation space. This framework enables accurate, explainable, and domain-agnostic detection without requiring access to model internals or labeled segments. Extensive experiments across five diverse domains, including news, code, essays, reviews, and academic abstracts, demonstrate that StyleDecipher consistently achieves state-of-the-art in-domain accuracy. Moreover, in cross-domain evaluations, it surpasses existing baselines by up to 36.30%, while maintaining robustness against adversarial perturbations and mixed human-AI content. Further qualitative and quantitative analysis confirms that stylistic signals provide explainable evidence for distinguishing machine-generated text. Our source code can be accessed at https://github.com/SiyuanLi00/StyleDecipher.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12608","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.408784","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Siyuan Li, Aodu Wulianghai, Xi Lin, Guangyan Li, Xiang Chen, Jun Wu, Jianhua Li","raw_content_length":1813,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["StyleDecipher"],"persons":[],"locations":[],"monetary":[]},"char_count":1812,"language_detected":"en","key_concepts":{"key_phrases":["StyleDecipher","Robust and Explainable Detection","LLM","arXiv251012608v1 Announce Type","new Abstract","the increasing integration","large language models","LLMs","open-domain writing","machine-generated text"],"filter_categories":{"ai_ml":["Robust and Explainable Detection","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"StyleDecipher":2.0,"Robust and Explainable Detection":2.0,"LLM":2.0,"arXiv251012608v1 Announce Type":1.0,"new Abstract":1.0,"the increasing integration":1.0,"large language models":1.0,"LLMs":1.0,"open-domain writing":1.0,"machine-generated text":1.0}},"age_hours":2.742695014166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9291,"joy":0.0105,"surprise":0.0232,"sadness":0.0038,"fear":0.014,"anger":0.0112,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (StyleDecipher) for detecting LLM-generated text, achieving state-of-the-art in-domain accuracy and surpassing existing baselines by up to 36.30% in cross-domain evaluations. While the research is promising, it is still in the applied research stage with no clear path to economic viability or deployment readiness. The climate impact is indirect, as it helps ensure content authenticity, which could indirectly support informed decision-making related to climate change.","key_impact_metrics":["accuracy improvement 36.30%"],"technology_tags":["LLM detection","stylometric analysis","AI ethics"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:28:17.500204Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_972e45ae9c3c","title":"Learning Robust Agile Flight Control with Stability Guarantees","content":"arXiv:2510.12611v1 Announce Type: new Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving precise trajectory tracking at the platform's operational limits is paramount. Controllers must handle actuator constraints, exhibit robustness to disturbances, and remain computationally efficient for safety-critical applications. In this work, we present a novel neural-augmented feedback controller for agile flight control. The controller addresses individual limitations of existing state-of-the-art control paradigms and unifies their strengths. We demonstrate the controller's capabilities, including the accurate tracking of highly aggressive trajectories that surpass the feasibility of the actuators. Notably, the controller provides universal stability guarantees, enhancing its robustness and tracking performance even in exceedingly disturbance-prone settings. Its nonlinear feedback structure is highly efficient enabling fast computation at high update rates. Moreover, the learning process in simulation is both fast and stable, and the controller's inherent robustness allows direct deployment to real-world platforms without the need for training augmentations or fine-tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12611","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.409186","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Lukas Pries, Markus Ryll","raw_content_length":1217,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1216,"language_detected":"en","key_concepts":{"key_phrases":["Learning","Robust Agile Flight Control","Stability Guarantees","arXiv251012611v1 Announce Type","new Abstract","the evolving landscape","high-speed agile quadrotor flight","precise trajectory tracking","the platforms operational limits","Controllers"],"filter_categories":{"ai_ml":["Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Learning":2.0,"Robust Agile Flight Control":2.0,"Stability Guarantees":2.0,"arXiv251012611v1 Announce Type":1.0,"new Abstract":1.0,"the evolving landscape":1.0,"high-speed agile quadrotor flight":1.0,"precise trajectory tracking":1.0,"the platforms operational limits":1.0,"Controllers":1.0}},"age_hours":2.742708676388889,"is_recent":true,"quality_score":0.7,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9237,"joy":0.0207,"surprise":0.0236,"sadness":0.0029,"fear":0.011,"anger":0.0137,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel neural-augmented feedback controller for agile flight control, demonstrating accurate tracking of aggressive trajectories in simulation. The controller offers universal stability guarantees and efficient computation. However, it is currently in the applied research stage, with no evidence of real-world deployment or quantified climate impact.","key_impact_metrics":[],"technology_tags":["agile flight control","neural-augmented feedback controller","quadrotor"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:20.342859Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_84c6adb31a24","title":"Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff","content":"arXiv:2510.12615v1 Announce Type: new Abstract: Knowledge distillation is often considered a compression mechanism when judged on the resulting student's accuracy and loss, yet its functional impact is poorly understood. In this work, we quantify the compression capacity of knowledge distillation and the resulting knowledge transfer from a functional perspective, decoupling compression from architectural reduction, which provides an improved understanding of knowledge distillation. We employ hypothesis testing, controls, and random control distillation to understand knowledge transfer mechanisms across data modalities. To rigorously test the breadth and limits of our analyses, we explore multiple distillation variants and analyse distillation scaling laws across model sizes. Our findings demonstrate that, while there is statistically significant knowledge transfer in some modalities and architectures, the extent of this transfer is less pronounced than anticipated, even under conditions designed to maximise knowledge sharing. Notably, in cases of significant knowledge transfer, we identify a consistent and severe asymmetric transfer of negative knowledge to the student, raising safety concerns in knowledge distillation applications. Across 12 experimental setups, 9 architectures, and 7 datasets, our findings show that knowledge distillation functions less as a compression mechanism and more as a data-dependent regulariser with a negative asymmetric payoff.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12615","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.409602","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Israel Mason-Williams, Gabryel Mason-Williams, Helen Yannakoudakis","raw_content_length":1481,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1480,"language_detected":"en","key_concepts":{"key_phrases":["Knowledge Distillation","A Data Dependent Regulariser","a Negative Asymmetric Payoff","knowledge distillation","new Abstract","Knowledge distillation","a compression mechanism","the resulting students accuracy","loss","its functional impact"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Knowledge Distillation":2.0,"A Data Dependent Regulariser":2.0,"a Negative Asymmetric Payoff":2.0,"knowledge distillation":2.0,"new Abstract":1.0,"Knowledge distillation":1.0,"a compression mechanism":1.0,"the resulting students accuracy":1.0,"loss":1.0,"its functional impact":1.0}},"age_hours":2.742722008888889,"is_recent":true,"quality_score":0.7,"sentiment_score":1.408,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7184,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7768,"joy":0.016,"surprise":0.0653,"sadness":0.0157,"fear":0.026,"anger":0.0386,"disgust":0.0617},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper analyzes knowledge distillation in machine learning, finding that it functions more as a data-dependent regularizer with a negative asymmetric payoff. While there is statistically significant knowledge transfer in some modalities and architectures, the extent of this transfer is less pronounced than anticipated. The work uses hypothesis testing, controls, and random control distillation to understand knowledge transfer mechanisms, but it is still in the research phase with no clear path to deployment or direct climate impact.","key_impact_metrics":["Asymmetric transfer of negative knowledge","Knowledge transfer in some modalities"],"technology_tags":["Knowledge distillation","Machine learning","Data regularization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:28:23.231044Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c2de3737c248","title":"Runtime Composition in Dynamic System of Systems: A Systematic Review of Challenges, Solutions, Tools, and Evaluation Methods","content":"arXiv:2510.12616v1 Announce Type: new Abstract: Context: Modern Systems of Systems (SoSs) increasingly operate in dynamic environments (e.g., smart cities, autonomous vehicles) where runtime composition -- the on-the-fly discovery, integration, and coordination of constituent systems (CSs)--is crucial for adaptability. Despite growing interest, the literature lacks a cohesive synthesis of runtime composition in dynamic SoSs. Objective: This study synthesizes research on runtime composition in dynamic SoSs and identifies core challenges, solution strategies, supporting tools, and evaluation methods. Methods: We conducted a Systematic Literature Review (SLR), screening 1,774 studies published between 2019 and 2024 and selecting 80 primary studies for thematic analysis (TA). Results: Challenges fall into four categories: modeling and analysis, resilient operations, system orchestration, and heterogeneity of CSs. Solutions span seven areas: co-simulation and digital twins, semantic ontologies, integration frameworks, adaptive architectures, middleware, formal methods, and AI-driven resilience. Service-oriented frameworks for composition and integration dominate tooling, while simulation platforms support evaluation. Interoperability across tools, limited cross-toolchain workflows, and the absence of standardized benchmarks remain key gaps. Evaluation approaches include simulation-based, implementation-driven, and human-centered studies, which have been applied in domains such as smart cities, healthcare, defense, and industrial automation. Conclusions: The synthesis reveals tensions, including autonomy versus coordination, the modeling-reality gap, and socio-technical integration. It calls for standardized evaluation metrics, scalable decentralized architectures, and cross-domain frameworks. The analysis aims to guide researchers and practitioners in developing and implementing dynamically composable SoSs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12616","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.410067","language":"en","tags":["preprints","computer-science","csse","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Muhammad Ashfaq, Ahmed R. Sadik, Teerath Das, Muhammad Waseem, Niko Makitalo, Tommi Mikkonen","raw_content_length":1936,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["a Systematic Literature Review","Modern Systems of Systems","SLR","A Systematic Review of Challenges, Solutions","SoSs"],"persons":["SoSs"],"locations":[],"monetary":[]},"char_count":1935,"language_detected":"en","key_concepts":{"key_phrases":["Systems","Runtime Composition","Dynamic System","A Systematic Review","Challenges","Solutions","Tools","Evaluation Methods","runtime composition","arXiv251012616v1"],"filter_categories":{"engineering":["Systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Systems":3.0,"Runtime Composition":2.0,"Dynamic System":2.0,"A Systematic Review":2.0,"Challenges":2.0,"Solutions":2.0,"Tools":2.0,"Evaluation Methods":2.0,"runtime composition":2.0,"arXiv251012616v1":1.0}},"age_hours":2.7427374105555553,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5485,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7097,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9186,"joy":0.008,"surprise":0.0359,"sadness":0.0059,"fear":0.0107,"anger":0.0122,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This systematic review analyzes existing research on runtime composition in dynamic systems of systems, identifying challenges and solutions. While it covers domains like smart cities and autonomous vehicles, it primarily focuses on theoretical frameworks and simulation-based evaluations, lacking concrete deployment data or quantified environmental impact. The vaporware flag is raised because the article discusses prototypes and pilot programs without mentioning deployed units or operational data.","key_impact_metrics":[],"technology_tags":["System of Systems","Runtime Composition","Dynamic Systems"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:28:26.466769Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9162d5c2b7b9","title":"Towards Fast Coarse","content":"arXiv:2510.12618v1 Announce Type: new Abstract: High-dimensional recordings of dynamical processes are often characterized by a much smaller set of effective variables, evolving on low-dimensional manifolds. Identifying these latent dynamics requires solving two intertwined problems: discovering appropriate coarse-grained variables and simultaneously fitting the governing equations. Most machine learning approaches tackle these tasks jointly by training autoencoders together with models that enforce dynamical consistency. We propose to decouple the two problems by leveraging the recently introduced Foundation Inference Models (FIMs). FIMs are pretrained models that estimate the infinitesimal generators of dynamical systems (e.g., the drift and diffusion of a stochastic differential equation) in zero-shot mode. By amortizing the inference of the dynamics through a FIM with frozen weights, and training only the encoder-decoder map, we define a simple, simulation-consistent loss that stabilizes representation learning. A proof of concept on a stochastic double-well system with semicircle diffusion, embedded into synthetic video data, illustrates the potential of this approach for fast and reusable coarse-graining pipelines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12618","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.410578","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Manuel Hinz, Maximilian Mauel, Patrick Seifner, David Berghaus, Kostadin Cvejoski, Ramses J. Sanchez","raw_content_length":1241,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Foundation Inference Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1240,"language_detected":"en","key_concepts":{"key_phrases":["Fast Coarse","new Abstract","High-dimensional recordings","dynamical processes","a much smaller set","effective variables","low-dimensional manifolds","these latent dynamics","two intertwined problems","appropriate coarse-grained variables"],"filter_categories":{"ai_ml":["appropriate coarse-grained variables"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fast Coarse":2.0,"new Abstract":1.0,"High-dimensional recordings":1.0,"dynamical processes":1.0,"a much smaller set":1.0,"effective variables":1.0,"low-dimensional manifolds":1.0,"these latent dynamics":1.0,"two intertwined problems":1.0,"appropriate coarse-grained variables":1.0}},"age_hours":2.7427515827777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9497,"joy":0.0068,"surprise":0.0211,"sadness":0.0039,"fear":0.0051,"anger":0.0088,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning approach for identifying latent dynamics in high-dimensional data, which could potentially be applied to climate modeling and optimization of energy systems. However, it is currently at the proof-of-concept stage with no real-world deployments or quantified impact on GHG emissions. The vaporware flag is raised due to the lack of deployed units or operational data.","key_impact_metrics":[],"technology_tags":["machine learning","dynamical systems","coarse-graining"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:29.093098Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_76eaefceca40","title":"Vizing's Theorem in Deterministic Almost","content":"arXiv:2510.12619v1 Announce Type: new Abstract: Vizing's theorem states that any $n$-vertex $m$-edge graph of maximum degree $\\Delta$ can be edge colored using at most $\\Delta + 1$ different colors. Vizing's original proof is easily translated into a deterministic $O(mn)$ time algorithm. This deterministic time bound was subsequently improved to $\\tilde O(m \\sqrt n)$ time, independently by [Arjomandi, 1982] and by [Gabow et al., 1985]. A series of recent papers improved the time bound of $\\tilde O(m\\sqrt{n})$ using randomization, culminating in the randomized near-linear time $(\\Delta+1)$-coloring algorithm by [Assadi, Behnezhad, Bhattacharya, Costa, Solomon, and Zhang, 2025]. At the heart of all of these recent improvements, there is some form of a sublinear time algorithm. Unfortunately, sublinear time algorithms as a whole almost always require randomization. This raises a natural question: can the deterministic time complexity of the problem be reduced below the $\\tilde O(m\\sqrt{n})$ barrier? In this paper, we answer this question in the affirmative. We present a deterministic almost-linear time $(\\Delta+1)$-coloring algorithm, namely, an algorithm running in $m \\cdot 2^{O(\\sqrt{\\log \\Delta})} \\cdot \\log n = m^{1+o(1)}$ time. Our main technical contribution is to entirely forego sublinear time algorithms. We do so by presenting a new deterministic color-type sparsification approach that runs in almost-linear (instead of sublinear) time, but can be used to color a much larger set of edges.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12619","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.411006","language":"en","tags":["preprints","csds","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Sepehr Assadi, Soheil Behnezhad, Sayan Bhattacharya, Mart\\'in Costa, Shay Solomon, Tianyi Zhang","raw_content_length":1522,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Vizing","Gabow et al.","Theorem in Deterministic Almost"],"persons":["Zhang","Assadi","Behnezhad","Arjomandi","Solomon"],"locations":["Costa"],"monetary":["$n$-vertex $"]},"char_count":1517,"language_detected":"en","key_concepts":{"key_phrases":["Vizings Theorem","Deterministic","arXiv251012619v1 Announce Type","new Abstract","Vizings theorem states","maximum degree","edge","at most Delta","1 different colors","Vizings original proof"],"filter_categories":{"engineering":["edge"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vizings Theorem":2.0,"Deterministic":2.0,"arXiv251012619v1 Announce Type":1.0,"new Abstract":1.0,"Vizings theorem states":1.0,"maximum degree":1.0,"edge":1.0,"at most Delta":1.0,"1 different colors":1.0,"Vizings original proof":1.0}},"age_hours":2.7427682597222223,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7341,"joy":0.1186,"surprise":0.1254,"sadness":0.0053,"fear":0.0033,"anger":0.0093,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical improvement in graph coloring algorithms, reducing the time complexity of a specific problem. While it's a significant theoretical advance, it's currently in the basic research stage and has no direct, measurable impact on sustainability. The potential impact is indirect, as more efficient algorithms could potentially be used in various optimization problems related to sustainability.","key_impact_metrics":[],"technology_tags":["graph coloring algorithms","deterministic algorithms"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:28:31.994378Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cc3917e08ac3","title":"ACADATA: Parallel Dataset of Academic Data for Machine Translation","content":"arXiv:2510.12621v1 Announce Type: new Abstract: We present ACADATA, a high-quality parallel dataset for academic translation, that consists of two subsets: ACAD-TRAIN, which contains approximately 1.5 million author-generated paragraph pairs across 96 language directions and ACAD-BENCH, a curated evaluation set of almost 6,000 translations covering 12 directions. To validate its utility, we fine-tune two Large Language Models (LLMs) on ACAD-TRAIN and benchmark them on ACAD-BENCH against specialized machine-translation systems, general-purpose, open-weight LLMs, and several large-scale proprietary models. Experimental results demonstrate that fine-tuning on ACAD-TRAIN leads to improvements in academic translation quality by +6.1 and +12.4 d-BLEU points on average for 7B and 2B models respectively, while also improving long-context translation in a general domain by up to 24.9% when translating out of English. The fine-tuned top-performing model surpasses the best propietary and open-weight models on academic translation domain. By releasing ACAD-TRAIN, ACAD-BENCH and the fine-tuned models, we provide the community with a valuable resource to advance research in academic domain and long-context translation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12621","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.411406","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"I\\~naki Lacunza, Javier Garcia Gilabert, Francesca De Luca Fornaciari, Javier Aula-Blasco, Aitor Gonzalez-Agirre, Maite Melero, Marta Villegas","raw_content_length":1225,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["ACAD-TRAIN","ACAD-BENCH","Parallel Dataset of Academic Data for Machine Translation arXiv:2510.12621v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1224,"language_detected":"en","key_concepts":{"key_phrases":["ACADATA","Parallel Dataset","Academic Data","Machine Translation","ACAD-TRAIN","ACAD-BENCH","arXiv251012621v1 Announce Type","new Abstract","a high-quality parallel dataset","academic translation"],"filter_categories":{"research_academic":["Academic Data","academic translation"],"ai_ml":["ACAD-TRAIN"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ACADATA":2.0,"Parallel Dataset":2.0,"Academic Data":2.0,"Machine Translation":2.0,"ACAD-TRAIN":2.0,"ACAD-BENCH":2.0,"arXiv251012621v1 Announce Type":1.0,"new Abstract":1.0,"a high-quality parallel dataset":1.0,"academic translation":1.0}},"age_hours":2.7427843305555557,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8142,"joy":0.0771,"surprise":0.0901,"sadness":0.0041,"fear":0.0027,"anger":0.0094,"disgust":0.0024},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a new dataset and fine-tuned models for academic translation. While the improvements in translation quality are measurable (+6.1 and +12.4 d-BLEU points), the direct climate impact is limited. The research is at the applied research stage, with no indication of deployment beyond benchmarking.","key_impact_metrics":["+6.1 d-BLEU points","+12.4 d-BLEU points"],"technology_tags":["Machine Translation","Large Language Models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:28:35.097522Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_26ea54e44257","title":"Learning-To","content":"arXiv:2510.12624v1 Announce Type: new Abstract: Active feature acquisition (AFA) is a sequential decision-making problem where the goal is to improve model performance for test instances by adaptively selecting which features to acquire. In practice, AFA methods often learn from retrospective data with systematic missingness in the features and limited task-specific labels. Most prior work addresses acquisition for a single predetermined task, limiting scalability. To address this limitation, we formalize the meta-AFA problem, where the goal is to learn acquisition policies across various tasks. We introduce Learning-to-Measure (L2M), which consists of i) reliable uncertainty quantification over unseen tasks, and ii) an uncertainty-guided greedy feature acquisition agent that maximizes conditional mutual information. We demonstrate a sequence-modeling or autoregressive pre-training approach that underpins reliable uncertainty quantification for tasks with arbitrary missingness. L2M operates directly on datasets with retrospective missingness and performs the meta-AFA task in-context, eliminating per-task retraining. Across synthetic and real-world tabular benchmarks, L2M matches or surpasses task-specific baselines, particularly under scarce labels and high missingness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12624","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.411825","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Yuta Kobayashi, Zilin Jing, Jiayu Yao, Hongseok Namkoong, Shalmali Joshi","raw_content_length":1291,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["maximizes conditional"],"persons":[],"locations":[],"monetary":[]},"char_count":1290,"language_detected":"en","key_concepts":{"key_phrases":["Learning-To","arXiv251012624v1","Announce Type","new Abstract","Active feature acquisition","AFA","a sequential decision-making problem","the goal","model performance","test instances"],"filter_categories":{"business_innovation":["Active feature acquisition"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Learning-To":2.0,"arXiv251012624v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Active feature acquisition":1.0,"AFA":1.0,"a sequential decision-making problem":1.0,"the goal":1.0,"model performance":1.0,"test instances":1.0}},"age_hours":2.742799306666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9107,"joy":0.0046,"surprise":0.0256,"sadness":0.016,"fear":0.0153,"anger":0.0138,"disgust":0.014},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel machine learning approach (Learning-to-Measure) for active feature acquisition. While it shows promise in improving model performance with limited data, particularly in scenarios with missing data, it is still in the early stages of development and lacks concrete deployment or quantified environmental impact. The technology is at the applied research stage, with potential for future applications but no current real-world deployment.","key_impact_metrics":["Matches or surpasses task-specific baselines","Improved model performance"],"technology_tags":["Active Feature Acquisition","Meta-Learning","Uncertainty Quantification"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:28:39.754258Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_69a990e98a7a","title":"Noisy Neighbor: Exploiting RDMA for Resource Exhaustion Attacks in Containerized Clouds","content":"arXiv:2510.12629v1 Announce Type: new Abstract: In modern containerized cloud environments, the adoption of RDMA (Remote Direct Memory Access) has expanded to reduce CPU overhead and enable high-performance data exchange. Achieving this requires strong performance isolation to ensure that one container's RDMA workload does not degrade the performance of others, thereby maintaining critical security assurances. However, existing isolation techniques are difficult to apply effectively due to the complexity of microarchitectural resource management within RDMA NICs (RNICs). This paper experimentally analyzes two types of resource exhaustion attacks on NVIDIA BlueField-3: (i) state saturation attacks and (ii) pipeline saturation attacks. Our results show that state saturation attacks can cause up to a 93.9% loss in bandwidth, a 1,117x increase in latency, and a 115% rise in cache misses for victim containers, while pipeline saturation attacks lead to severe link-level congestion and significant amplification, where small verb requests result in disproportionately high resource consumption. To mitigate these threats and restore predictable security assurances, we propose HT-Verbs, a threshold-driven framework based on real-time per-container RDMA verb telemetry and adaptive resource classification that partitions RNIC resources into hot, warm, and cold tiers and throttles abusive workloads without requiring hardware modifications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12629","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.412231","language":"en","tags":["preprints","computer-science","csni","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Gunwoo Kim, Taejune Park, Jinwoo Kim","raw_content_length":1450,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Noisy Neighbor: Exploiting RDMA for Resource Exhaustion Attacks","CPU"],"persons":[],"locations":[],"monetary":[]},"char_count":1449,"language_detected":"en","key_concepts":{"key_phrases":["RDMA","Noisy Neighbor","Resource Exhaustion Attacks","Containerized Clouds","arXiv251012629v1 Announce Type","new Abstract","modern containerized cloud environments","the adoption","Remote Direct Memory Access","CPU"],"filter_categories":{"ai_ml":["Containerized Clouds"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RDMA":3.0,"Noisy Neighbor":2.0,"Resource Exhaustion Attacks":2.0,"Containerized Clouds":2.0,"arXiv251012629v1 Announce Type":1.0,"new Abstract":1.0,"modern containerized cloud environments":1.0,"the adoption":1.0,"Remote Direct Memory Access":1.0,"CPU":1.0}},"age_hours":2.7428152055555555,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8755,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2249,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.757,"joy":0.0064,"surprise":0.0102,"sadness":0.0075,"fear":0.1319,"anger":0.0525,"disgust":0.0346},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on resource exhaustion attacks in containerized cloud environments using RDMA. While it doesn't directly address climate change, improving resource utilization in data centers can indirectly reduce energy consumption. The research is in the applied research stage, demonstrating a proof of concept with measured outcomes in a controlled environment.","key_impact_metrics":["93.9% loss in bandwidth","1,117x increase in latency"],"technology_tags":["RDMA","Containerization","Resource Management"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:43.295826Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_94e0c273660b","title":"Designing Tools with Control Confidence","content":"arXiv:2510.12630v1 Announce Type: new Abstract: Prehistoric humans invented stone tools for specialized tasks by not just maximizing the tool's immediate goal-completion accuracy, but also increasing their confidence in the tool for later use under similar settings. This factor contributed to the increased robustness of the tool, i.e., the least performance deviations under environmental uncertainties. However, the current autonomous tool design frameworks solely rely on performance optimization, without considering the agent's confidence in tool use for repeated use. Here, we take a step towards filling this gap by i) defining an optimization framework for task-conditioned autonomous hand tool design for robots, where ii) we introduce a neuro-inspired control confidence term into the optimization routine that helps the agent to design tools with higher robustness. Through rigorous simulations using a robotic arm, we show that tools designed with control confidence as the objective function are more robust to environmental uncertainties during tool use than a pure accuracy-driven objective. We further show that adding control confidence to the objective function for tool design provides a balance between the robustness and goal accuracy of the designed tools under control perturbations. Finally, we show that our CMAES-based evolutionary optimization strategy for autonomous tool design outperforms other state-of-the-art optimizers by designing the optimal tool within the fewest iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12630","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.412656","language":"en","tags":["preprints","csai","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Ajith Anil Meera, Abian Torres, Pablo Lanillos","raw_content_length":1582,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Control Confidence arXiv:2510.12630v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1581,"language_detected":"en","key_concepts":{"key_phrases":["Designing Tools","Control Confidence","the tool","Announce Type","new Abstract","Prehistoric humans","stone tools","specialized tasks","the tools immediate goal-completion accuracy","their confidence"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Designing Tools":2.0,"Control Confidence":2.0,"the tool":2.0,"Announce Type":1.0,"new Abstract":1.0,"Prehistoric humans":1.0,"stone tools":1.0,"specialized tasks":1.0,"the tools immediate goal-completion accuracy":1.0,"their confidence":1.0}},"age_hours":2.7428296625,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6555,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7311,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.897,"joy":0.0465,"surprise":0.0253,"sadness":0.0037,"fear":0.0129,"anger":0.0088,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel approach to tool design for robots, incorporating control confidence to enhance robustness under environmental uncertainties. The research is supported by simulations and an evolutionary optimization strategy, showing improved performance compared to state-of-the-art optimizers. However, it remains in the early stages of development with no deployed units or real-world validation, limiting its immediate sustainability impact.","key_impact_metrics":["Robustness to environmental uncertainties","Performance deviations under environmental uncertainties"],"technology_tags":["Robotics","Autonomous tool design","Evolutionary optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:46.575928Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f2c41edbc329","title":"Laminar: A Scalable Asynchronous RL Post","content":"arXiv:2510.12633v1 Announce Type: new Abstract: Reinforcement learning (RL) post-training for Large Language Models (LLMs) is now scaling to large clusters and running for extended durations to enhance model reasoning performance. However, the scalability of existing RL frameworks is limited, as extreme long-tail skewness in RL trajectory generation causes severe GPU underutilization. Current asynchronous RL systems attempt to mitigate this, but they rely on global weight synchronization between the actor and all rollouts, which creates a rigid model update schedule. This global synchronization is ill-suited for the highly skewed and evolving distribution of trajectory generation latency in RL training, crippling training efficiency. Our key insight is that efficient scaling requires breaking this lockstep through trajectory-level asynchrony, which generates and consumes each trajectory independently. We propose Laminar, a scalable and robust RL post-training system built on a fully decoupled architecture. First, we replace global updates with a tier of relay workers acting as a distributed parameter service. This enables asynchronous and fine-grained weight synchronization, allowing rollouts to pull the latest weight anytime without stalling the actor's training loop. Second, a dynamic repack mechanism consolidates long-tail trajectories onto a few dedicated rollouts, maximizing generation throughput. The fully decoupled design also isolates failures, ensuring robustness for long-running jobs. Our evaluation on a 1024-GPU cluster shows that Laminar achieves up to 5.48$\\times$ training throughput speedup over state-of-the-art systems, while reducing model convergence time.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12633","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.413455","language":"en","tags":["preprints","csai","computer-science","cslg","research","csdc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Guangming Sheng, Yuxuan Tong, Borui Wan, Wang Zhang, Chaobo Jia, Xibin Wu, Yuqi Wu, Xiang Li, Chi Zhang, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu","raw_content_length":1702,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","GPU"],"persons":["Laminar"],"locations":[],"monetary":[]},"char_count":1701,"language_detected":"en","key_concepts":{"key_phrases":["Laminar","A Scalable Asynchronous RL Post","arXiv251012633v1 Announce Type","new Abstract","Reinforcement learning","post","training","Large Language Models","LLMs","large clusters"],"filter_categories":{"ai_ml":["Reinforcement learning","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Laminar":2.0,"A Scalable Asynchronous RL Post":2.0,"arXiv251012633v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement learning":1.0,"post":1.0,"training":1.0,"Large Language Models":1.0,"LLMs":1.0,"large clusters":1.0}},"age_hours":2.742858394166667,"is_recent":true,"quality_score":1.0,"sentiment_score":3.4645,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3071,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.712,"joy":0.0065,"surprise":0.0147,"sadness":0.0278,"fear":0.1397,"anger":0.0618,"disgust":0.0375},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a system (Laminar) that improves the efficiency of reinforcement learning (RL) for large language models (LLMs). While LLMs themselves can have indirect impacts on sustainability (e.g., optimizing energy use), the direct impact of this system is primarily on reducing the computational resources required for training LLMs, potentially leading to lower energy consumption. The system achieves up to 5.48x training throughput speedup on a 1024-GPU cluster, but this is a research result, not a deployed technology.","key_impact_metrics":["5.48x training throughput speedup"],"technology_tags":["Reinforcement Learning","Large Language Models","Distributed Computing"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T16:28:50.113341Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_70dbd3e64391","title":"Memory as Action: Autonomous Context Curation for Long","content":"arXiv:2510.12635v1 Announce Type: new Abstract: Large Language Models face challenges in long-horizon agentic tasks as their constrained memory is easily overwhelmed by distracting or irrelevant context. Existing working memory methods typically rely on external, heuristic mechanisms that are decoupled from the agent's core policy. In this work, we reframe working memory management as a learnable, intrinsic capability. We propose a novel framework, Memory-as-Action, where an agent actively manages its working memory by executing explicit editing operations as part of a unified policy. This formulation allows an agent, trained via reinforcement learning, to balance memory curation against long-term task objectives under given resource constraints. However, such memory editing actions break the standard assumption of a continuously growing prefix in LLM interactions, leading to what we call trajectory fractures. These non-prefix changes disrupt the causal continuity required by standard policy gradient methods, making those methods inapplicable. To address this, we propose a new algorithm, Dynamic Context Policy Optimization, which enables stable end-to-end reinforcement learning by segmenting trajectories at memory action points and applying trajectory-level advantages to the resulting action segments. Our results demonstrate that jointly optimizing for task reasoning and memory management in an end-to-end fashion not only reduces overall computational consumption but also improves task performance, driven by adaptive context curation strategies tailored to the model's intrinsic capabilities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12635","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.413893","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Yuxiang Zhang, Jiangming Shu, Ye Ma, Xueyuan Lin, Shangxi Wu, Jitao Sang","raw_content_length":1619,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1618,"language_detected":"en","key_concepts":{"key_phrases":["Memory","Action","Autonomous Context Curation","arXiv251012635v1 Announce Type","new Abstract","Large Language Models","challenges","long-horizon agentic tasks","their constrained memory","irrelevant context"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Memory":3.0,"Action":3.0,"Autonomous Context Curation":2.0,"arXiv251012635v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"challenges":1.0,"long-horizon agentic tasks":1.0,"their constrained memory":1.0,"irrelevant context":1.0}},"age_hours":2.7428736286111115,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.2911,"joy":0.0055,"surprise":0.1034,"sadness":0.009,"fear":0.5382,"anger":0.0434,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of Large Language Models by optimizing memory management, which can reduce computational consumption. The article presents a novel algorithm and demonstrates improved task performance, suggesting potential energy savings. However, it is still in the basic research phase with no deployed units or economic viability data.","key_impact_metrics":["reduced overall computational consumption","improved task performance"],"technology_tags":["Large Language Models","Reinforcement Learning","Memory Management"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:28:53.828857Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a2e7be19aa1","title":"COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point","content":"arXiv:2510.12637v1 Announce Type: new Abstract: Large Language Models (LLMs) are highly sensitive to prompt design, and making optimized prompting techniques is crucial for generating consistent, high-quality outputs. In this study, we introduce COSTAR-A, a novel prompt engineering framework that enhances the existing COSTAR method, which stands for Context, Objective, Style, Tone, Audience, and Response, by adding the 'Answer' component at the end. We demonstrate that while the original COSTAR framework improves prompt clarity and aligns outputs for larger LLMs, its performance is less consistent with smaller, locally optimized models, particularly in tasks that require more directive or constrained outputs. Through a series of controlled prompt-output assessments with smaller (at most 8 billion parameters), fine-tuned models, we found that COSTAR-A can enhance the output structure and decisiveness of localized LLMs for certain tasks, although its effectiveness varies across models and use cases. Notably, the Llama 3.1-8B model exhibited performance improvements when prompted with COSTAR-A compared to COSTAR alone. These findings emphasize the adaptability and scalability of COSTAR-A as a prompting framework, particularly in computationally efficient AI deployments on resource-constrained hardware.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12637","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.414296","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Nzubechukwu C. Ohalete (School of Data Science and Analytics, Kennesaw State University, GA, USA), Kevin B. Gittner (School of Data Science and Analytics, Kennesaw State University, GA, USA), Lauren M. Matheny (School of Data Science and Analytics, Kennesaw State University, GA, USA)","raw_content_length":1321,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Response","Point arXiv:2510.12637v1 Announce Type","Answer"],"persons":["Large Language Model","Context"],"locations":[],"monetary":[]},"char_count":1320,"language_detected":"en","key_concepts":{"key_phrases":["COSTAR-A","A prompting framework","Large Language Model performance","Point","arXiv251012637v1 Announce Type","new Abstract","Large Language Models","LLMs","prompt design","optimized prompting techniques"],"filter_categories":{"ai_ml":["Large Language Model performance","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"COSTAR-A":3.0,"A prompting framework":2.0,"Large Language Model performance":2.0,"Point":2.0,"arXiv251012637v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"prompt design":1.0,"optimized prompting techniques":1.0}},"age_hours":2.742889899444444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8954,"joy":0.015,"surprise":0.0204,"sadness":0.0032,"fear":0.0273,"anger":0.0278,"disgust":0.0109},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of LLMs, specifically in resource-constrained environments. While it doesn't directly address climate change, the improved efficiency could lead to reduced energy consumption for AI applications. The study provides some metrics on performance improvements with the COSTAR-A framework, but it is still in the applied research phase with no deployed units.","key_impact_metrics":["Performance improvements with Llama 3.1-8B model"],"technology_tags":["Large Language Models","Prompt Engineering","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:28:57.807430Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b6bd0fa9a2e2","title":"Expert or not? assessing data quality in offline reinforcement learning","content":"arXiv:2510.12638v1 Announce Type: new Abstract: Offline reinforcement learning (RL) learns exclusively from static datasets, without further interaction with the environment. In practice, such datasets vary widely in quality, often mixing expert, suboptimal, and even random trajectories. The choice of algorithm therefore depends on dataset fidelity. Behavior cloning can suffice on high-quality data, whereas mixed- or low-quality data typically benefits from offline RL methods that stitch useful behavior across trajectories. Yet in the wild it is difficult to assess dataset quality a priori because the data's provenance and skill composition are unknown. We address the problem of estimating offline dataset quality without training an agent. We study a spectrum of proxies from simple cumulative rewards to learned value based estimators, and introduce the Bellman Wasserstein distance (BWD), a value aware optimal transport score that measures how dissimilar a dataset's behavioral policy is from a random reference policy. BWD is computed from a behavioral critic and a state conditional OT formulation, requiring no environment interaction or full policy optimization. Across D4RL MuJoCo tasks, BWD strongly correlates with an oracle performance score that aggregates multiple offline RL algorithms, enabling efficient prediction of how well standard agents will perform on a given dataset. Beyond prediction, integrating BWD as a regularizer during policy optimization explicitly pushes the learned policy away from random behavior and improves returns. These results indicate that value aware, distributional signals such as BWD are practical tools for triaging offline RL datasets and policy optimization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12638","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.414736","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Arip Asadulaev, Fakhri Karray, Martin Takac","raw_content_length":1720,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["Bellman Wasserstein","BWD"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1719,"language_detected":"en","key_concepts":{"key_phrases":["Expert","data quality","offline reinforcement learning","arXiv251012638v1 Announce Type","new Abstract","Offline reinforcement learning","static datasets","further interaction","the environment","practice"],"filter_categories":{"ai_ml":["offline reinforcement learning","Offline reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Expert":2.0,"data quality":2.0,"offline reinforcement learning":2.0,"arXiv251012638v1 Announce Type":1.0,"new Abstract":1.0,"Offline reinforcement learning":1.0,"static datasets":1.0,"further interaction":1.0,"the environment":1.0,"practice":1.0}},"age_hours":2.7429049419444445,"is_recent":true,"quality_score":1.0,"sentiment_score":3.75,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.25,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9428,"joy":0.0075,"surprise":0.021,"sadness":0.0044,"fear":0.0041,"anger":0.0101,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method (BWD) for assessing the quality of offline reinforcement learning datasets, which could indirectly improve the efficiency of RL algorithms used in climate-related applications. The research is at an early stage (basic research) and lacks direct deployment or economic viability data, but it has technical credibility due to the use of value-aware optimal transport and validation on D4RL MuJoCo tasks. The impact on climate is indirect and depends on the application of RL algorithms to climate problems.","key_impact_metrics":["Correlation with oracle performance score"],"technology_tags":["Reinforcement Learning","Offline Reinforcement Learning","Bellman Wasserstein Distance"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:29:01.032053Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f849591704e1","title":"Single","content":"arXiv:2510.12641v1 Announce Type: new Abstract: We study stability in additively separable hedonic games when coalition sizes have to respect fixed size bounds. We consider four classic notions of stability based on single-agent deviations, namely, Nash stability, individual stability, contractual Nash stability, and contractual individual stability. For each stability notion, we consider two variants: in one, the coalition left behind by a deviator must still be of a valid size, and in the other there is no such constraint. We provide a full picture of the existence of stable outcomes with respect to given size parameters. Additionally, when there are only upper bounds, we fully characterize the computational complexity of the associated existence problem. In particular, we obtain polynomial-time algorithms for contractual individual stability and contractual Nash stability, where the latter requires an upper bound of 2. We obtain further results for Nash stability and contractual individual stability, when the lower bound is at least 2.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12641","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.416703","language":"en","tags":["preprints","csgt","computer-science","research","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Martin Bullinger, Adam Dunajski, Edith Elkind, Matan Gilboa","raw_content_length":1055,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Nash"],"persons":[],"locations":["Nash"],"monetary":[]},"char_count":1054,"language_detected":"en","key_concepts":{"key_phrases":["stability","arXiv251012641v1 Announce Type","new Abstract","additively separable hedonic games","coalition sizes","fixed size bounds","four classic notions","single-agent deviations","Nash stability","individual stability"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"stability":2.0,"arXiv251012641v1 Announce Type":1.0,"new Abstract":1.0,"additively separable hedonic games":1.0,"coalition sizes":1.0,"fixed size bounds":1.0,"four classic notions":1.0,"single-agent deviations":1.0,"Nash stability":1.0,"individual stability":1.0}},"age_hours":2.742934542777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.914,"joy":0.0099,"surprise":0.0216,"sadness":0.0055,"fear":0.0097,"anger":0.0209,"disgust":0.0184},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores the theoretical stability of hedonic games with size constraints, which is a mathematical model. While it doesn't directly address climate change, it could potentially inform the design of incentive structures for cooperative climate action, though this is highly theoretical at this stage. The technical credibility is high due to its basis in mathematical theory and potential for peer review.","key_impact_metrics":[],"technology_tags":[],"sdg_alignment":[17],"analyzed_at":"2025-10-29T16:29:03.872106Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_88d72ee0faea","title":"Aixel: A Unified, Adaptive and Extensible System for AI","content":"arXiv:2510.12642v1 Announce Type: new Abstract: A growing trend in modern data analysis is the integration of data management with learning, guided by accuracy, latency, and cost requirements. In practice, applications draw data of different formats from many sources. In the meanwhile, the objectives and budgets change over time. Existing systems handle these applications across databases, analysis libraries, and tuning services. Such fragmentation leads to complex user interaction, limited adaptability, suboptimal performance, and poor extensibility across components. To address these challenges, we present Aixel, a unified, adaptive, and extensible system for AI-powered data analysis. The system organizes work across four layers: application, task, model, and data. The task layer provides a declarative interface to capture user intent, which is parsed into an executable operator plan. An optimizer compiles and schedules this plan to meet specified goals in accuracy, latency, and cost. The task layer coordinates the execution of data and model operators, with built-in support for reuse and caching to improve efficiency. The model layer offers versioned storage for index, metadata, tensors, and model artifacts. It supports adaptive construction, task-aligned drift detection, and safe updates that reuse shared components. The data layer provides unified data management capabilities, including indexing, constraint-aware discovery, task-aligned selection, and comprehensive feature management. With the above designed layers, Aixel delivers a user friendly, adaptive, efficient, and extensible system.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12642","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.417133","language":"en","tags":["preprints","csai","computer-science","research","csdb","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Meihui Zhang, Liming Wang, Chi Zhang, Zhaojing Luo","raw_content_length":1623,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Aixel"],"locations":[],"monetary":[]},"char_count":1622,"language_detected":"en","key_concepts":{"key_phrases":["Aixel","Adaptive","Extensible System","arXiv251012642v1 Announce Type","new Abstract","A growing trend","modern data analysis","the integration","data management","learning"],"filter_categories":{"ai_ml":["Aixel","learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Aixel":2.0,"Adaptive":2.0,"Extensible System":2.0,"arXiv251012642v1 Announce Type":1.0,"new Abstract":1.0,"A growing trend":1.0,"modern data analysis":1.0,"the integration":1.0,"data management":1.0,"learning":1.0}},"age_hours":2.7429502055555557,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8718,"joy":0.0116,"surprise":0.074,"sadness":0.0079,"fear":0.0072,"anger":0.0182,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"Aixel is a new AI system designed for data analysis, aiming for efficiency and adaptability. While it could potentially improve resource utilization in various sectors, leading to indirect climate benefits, the article lacks concrete actions or measurable outcomes related to GHG emissions reduction or carbon sequestration. It's currently in the early research stage, with no deployment data available.","key_impact_metrics":[],"technology_tags":["AI","Data Analysis","Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:29:08.346772Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90495573279f","title":"Reasoning Pattern Matters: Learning to Reason without Human Rationales","content":"arXiv:2510.12643v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities under the widely adopted SFT+RLVR paradigm, which first performs Supervised Fine-Tuning (SFT) on human-annotated reasoning trajectories (rationales) to establish initial reasoning behaviors, then applies Reinforcement Learning with Verifiable Rewards (RLVR) to optimize the model using verifiable signals without golden rationales. However, annotating high-quality rationales for the SFT stage remains prohibitively expensive. This paper investigates when and how rationale annotation costs can be substantially reduced without compromising reasoning performance. We identify a broad class of problems, termed patterned reasoning tasks, where reasoning follows a fixed, procedural strategy consistent across instances. Although instances vary in content such as domain knowledge, factual information, or numeric values, the solution derives from applying a shared reasoning pattern. We argue that the success of SFT+RLVR on such tasks primarily stems from its ability to enable models to internalize these reasoning patterns. Using numerical semantic matching as a representative task, we provide both causal and behavioral evidence showing that reasoning patterns rather than the quantity or quality of rationales are the key determinant of performance. Building on these insights, we propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet effective framework that enables LLMs to generate rationales aligned with task-specific reasoning patterns without requiring human rationale annotations. Experiments show that PARO-generated rationales achieve comparable SFT+RLVR performance to human rationales that are 10 times larger. These results suggest that large-scale human rationale annotations can be replaced with LLM-based automatic annotations requiring only limited human supervision over reasoning patterns.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12643","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.417580","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Chaoxu Pang, Yixuan Cao, Ping Luo","raw_content_length":1961,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning","SFT"],"persons":[],"locations":[],"monetary":[]},"char_count":1960,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning Pattern Matters","Reason","Human Rationales","Announce Type","new Abstract","Large Language Models","LLMs","remarkable reasoning capabilities","the widely adopted SFTRLVR paradigm","which"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning Pattern Matters":2.0,"Reason":2.0,"Human Rationales":2.0,"Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable reasoning capabilities":1.0,"the widely adopted SFTRLVR paradigm":1.0,"which":1.0}},"age_hours":2.742964648888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.375,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.875,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7992,"joy":0.0281,"surprise":0.1252,"sadness":0.0047,"fear":0.0124,"anger":0.0248,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method (PARO) to reduce the cost of training LLMs for reasoning tasks, potentially making them more accessible. The concrete action is the development and testing of the PARO framework. Evidence includes experimental results showing comparable performance to human-annotated rationales, but it is still in the applied research stage with no real-world deployment.","key_impact_metrics":["10 times larger (human rationales)","comparable SFT+RLVR performance"],"technology_tags":["Large Language Models","Reinforcement Learning","Supervised Fine-Tuning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:29:12.210747Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_319066cb5d6f","title":"Zero-Shot CFC: Fast Real","content":"arXiv:2510.12646v1 Announce Type: new Abstract: Zero-shot denoisers address the dataset dependency of deep-learning-based denoisers, enabling the denoising of unseen single images. Nonetheless, existing zero-shot methods suffer from long training times and rely on the assumption of noise independence and a zero-mean property, limiting their effectiveness in real-world denoising scenarios where noise characteristics are more complicated. This paper proposes an efficient and effective method for real-world denoising, the Zero-Shot denoiser based on Cross-Frequency Consistency (ZSCFC), which enables training and denoising with a single noisy image and does not rely on assumptions about noise distribution. Specifically, image textures exhibit position similarity and content consistency across different frequency bands, while noise does not. Based on this property, we developed cross-frequency consistency loss and an ultralight network to realize image denoising. Experiments on various real-world image datasets demonstrate that our ZSCFC outperforms other state-of-the-art zero-shot methods in terms of computational efficiency and denoising performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12646","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.417971","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Yanlin Jiang, Yuchen Liu, Mingren Liu","raw_content_length":1166,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Cross-Frequency Consistency"],"persons":[],"locations":[],"monetary":[]},"char_count":1165,"language_detected":"en","key_concepts":{"key_phrases":["Zero-Shot CFC","Fast Real","arXiv251012646v1","Announce Type","new Abstract","Zero-shot denoisers","the dataset dependency","deep-learning-based denoisers","the denoising","unseen single images"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Zero-Shot CFC":2.0,"Fast Real":2.0,"arXiv251012646v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Zero-shot denoisers":1.0,"the dataset dependency":1.0,"deep-learning-based denoisers":1.0,"the denoising":1.0,"unseen single images":1.0}},"age_hours":2.742979982222222,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9073,"joy":0.0233,"surprise":0.0226,"sadness":0.0245,"fear":0.0048,"anger":0.0092,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper proposes a new denoising method (ZSCFC) that improves computational efficiency and denoising performance compared to existing zero-shot methods. The concrete action is the development and testing of the ZSCFC method on real-world image datasets, demonstrating its superior performance. However, it is still in the early stages of development and lacks real-world deployment data.","key_impact_metrics":["Computational efficiency improvement","Denoising performance improvement"],"technology_tags":["Image denoising","Zero-shot learning","Cross-frequency consistency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:29:15.814859Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_726dfa5704c1","title":"PromoGuardian: Detecting Promotion Abuse Fraud with Multi","content":"arXiv:2510.12652v1 Announce Type: new Abstract: As e-commerce platforms develop, fraudulent activities are increasingly emerging, posing significant threats to the security and stability of these platforms. Promotion abuse is one of the fastest-growing types of fraud in recent years and is characterized by users exploiting promotional activities to gain financial benefits from the platform. To investigate this issue, we conduct the first study on promotion abuse fraud in e-commerce platforms MEITUAN. We find that promotion abuse fraud is a group-based fraudulent activity with two types of fraudulent activities: Stocking Up and Cashback Abuse. Unlike traditional fraudulent activities such as fake reviews, promotion abuse fraud typically involves ordinary customers conducting legitimate transactions and these two types of fraudulent activities are often intertwined. To address this issue, we propose leveraging additional information from the spatial and temporal perspectives to detect promotion abuse fraud. In this paper, we introduce PROMOGUARDIAN, a novel multi-relation fused graph neural network that integrates the spatial and temporal information of transaction data into a homogeneous graph to detect promotion abuse fraud. We conduct extensive experiments on real-world data from MEITUAN, and the results demonstrate that our proposed model outperforms state-of-the-art methods in promotion abuse fraud detection, achieving 93.15% precision, detecting 2.1 to 5.0 times more fraudsters, and preventing 1.5 to 8.8 times more financial losses in production environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12652","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.418765","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Shaofei Li, Xiao Han, Ziqi Zhang, Minyao Hua, Shuli Gao, Zhenkai Liang, Yao Guo, Xiangqun Chen, Ding Li","raw_content_length":1590,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Cashback Abuse"],"persons":[],"locations":[],"monetary":[]},"char_count":1589,"language_detected":"en","key_concepts":{"key_phrases":["PromoGuardian","Detecting Promotion Abuse Fraud","Multi","e-commerce platforms","arXiv251012652v1","Announce Type","new Abstract","fraudulent activities","significant threats","the security"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PromoGuardian":2.0,"Detecting Promotion Abuse Fraud":2.0,"Multi":2.0,"e-commerce platforms":2.0,"arXiv251012652v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"fraudulent activities":1.0,"significant threats":1.0,"the security":1.0}},"age_hours":2.743009666666667,"is_recent":true,"quality_score":1.0,"sentiment_score":0.25349999999999984,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9493,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0835,"joy":0.0042,"surprise":0.0077,"sadness":0.0176,"fear":0.7931,"anger":0.0803,"disgust":0.0137},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (PROMOGUARDIAN) for detecting promotion abuse fraud on e-commerce platforms. While it demonstrates improved fraud detection (93.15% precision, detecting 2.1 to 5.0 times more fraudsters, and preventing 1.5 to 8.8 times more financial losses), its direct climate impact is minimal. The technology is in the applied research phase, with experiments conducted on real-world data from MEITUAN, but no deployment is mentioned.","key_impact_metrics":["93.15% precision","2.1 to 5.0 times more fraudsters detected"],"technology_tags":["Graph Neural Network","Fraud Detection"],"sdg_alignment":[8,9,12],"analyzed_at":"2025-10-29T16:29:18.867315Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b9129aa62984","title":"SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross","content":"arXiv:2510.12659v1 Announce Type: new Abstract: We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning), a novel framework designed for supervised learning on tabular data. At its core, SG-XDEAT employs a dual-stream encoder that decomposes each input feature into two parallel representations: a raw value stream and a target-conditioned (label-aware) stream. These dual representations are then propagated through a hierarchical stack of attention-based modules. SG-XDEAT integrates three key components: (i) Cross-Dimensional self-attention, which captures intra-view dependencies among features within each stream; (ii) Cross-Encoding self-attention, which enables bidirectional interaction between raw and target-aware representations; and (iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically suppresses low-utility tokens by driving their attention weights toward zero--thereby mitigating the impact of noise. Empirical results on multiple public benchmarks show consistent gains over strong baselines, confirming that jointly modeling raw and target-aware views--while adaptively filtering noise--yields a more robust deep tabular learner.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12659","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.419160","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Chih-Chuan Cheng, Yi-Ju Tseng","raw_content_length":1230,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["ASSA","Cross-Encoding","Sparsity-Guided Cross-Dimensional and Cross","Cross-Encoding Attention","Sparsity-Guided Cross Dimensional","SG-XDEAT"],"persons":[],"locations":[],"monetary":[]},"char_count":1229,"language_detected":"en","key_concepts":{"key_phrases":["SG-XDEAT","Sparsity-Guided Cross","Sparsity-Guided Cross Dimensional","Cross-Encoding Attention","Target Aware Conditioning","a novel framework","supervised learning","tabular data","its core","a dual-stream encoder"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SG-XDEAT":4.0,"Sparsity-Guided Cross":2.0,"Sparsity-Guided Cross Dimensional":1.0,"Cross-Encoding Attention":1.0,"Target Aware Conditioning":1.0,"a novel framework":1.0,"supervised learning":1.0,"tabular data":1.0,"its core":1.0,"a dual-stream encoder":1.0}},"age_hours":2.743026925,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8868,"joy":0.0151,"surprise":0.0231,"sadness":0.0035,"fear":0.0302,"anger":0.028,"disgust":0.0133},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel machine learning framework for tabular data. While it shows gains over baselines on public benchmarks, it's still in the research phase with no deployed applications or quantified environmental benefits. Therefore, the impact is theoretical at this stage.","key_impact_metrics":[],"technology_tags":["machine learning","attention mechanisms","tabular data"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:29:21.698681Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8dff8f0c2d3f","title":"On the Use of Hierarchical Vision Foundation Models for Low","content":"arXiv:2510.12660v1 Announce Type: new Abstract: In this work, we aim to develop simple and efficient models for human mesh recovery (HMR) and its predecessor task, human pose estimation (HPE). State-of-the-art HMR methods, such as HMR2.0 and its successors, rely on large, non-hierarchical vision transformers as encoders, which are inherited from the corresponding HPE models like ViTPose. To establish baselines across varying computational budgets, we first construct three lightweight HMR2.0 variants by adapting the corresponding ViTPose models. In addition, we propose leveraging the early stages of hierarchical vision foundation models (VFMs), including Swin Transformer, GroupMixFormer, and VMamba, as encoders. This design is motivated by the observation that intermediate stages of hierarchical VFMs produce feature maps with resolutions comparable to or higher than those of non-hierarchical counterparts. We conduct a comprehensive evaluation of 27 hierarchical-VFM-based HMR and HPE models, demonstrating that using only the first two or three stages achieves performance on par with full-stage models. Moreover, we show that the resulting truncated models exhibit better trade-offs between accuracy and computational efficiency compared to existing lightweight alternatives.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12660","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.419563","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Shuhei Tarashima, Yushan Wang, Norio Tagawa","raw_content_length":1290,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["VMamba","ViTPose","HMR2.0","HPE","Hierarchical Vision Foundation Models"],"persons":["Swin Transformer"],"locations":[],"monetary":[]},"char_count":1289,"language_detected":"en","key_concepts":{"key_phrases":["the Use","Hierarchical Vision Foundation Models","Low","arXiv251012660v1","Announce Type","new Abstract","this work","simple and efficient models","human mesh recovery","HMR"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Use":2.0,"Hierarchical Vision Foundation Models":2.0,"Low":2.0,"arXiv251012660v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"this work":1.0,"simple and efficient models":1.0,"human mesh recovery":1.0,"HMR":1.0}},"age_hours":2.7430428875,"is_recent":true,"quality_score":1.0,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9134,"joy":0.0211,"surprise":0.0358,"sadness":0.0054,"fear":0.0062,"anger":0.0129,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research into more computationally efficient models for human mesh recovery. While not directly climate-related, improved efficiency in AI models can reduce energy consumption. The research is in the applied research stage, with performance metrics reported but no deployment data.","key_impact_metrics":["Computational efficiency improvement","Accuracy on par with full-stage models"],"technology_tags":["AI","Machine Learning","Vision Models","Efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:29:24.256540Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1bcb12620ca2","title":"Structured Sparsity and Weight","content":"arXiv:2510.12666v1 Announce Type: new Abstract: Whisper models have achieved remarkable progress in speech recognition; yet their large size remains a bottleneck for deployment on resource-constrained edge devices. This paper proposes a framework to design fine-tuned variants of Whisper which address the above problem. Structured sparsity is enforced via the Sparse Group LASSO penalty as a loss regularizer, to reduce the number of FLOating Point operations (FLOPs). Further, a weight statistics aware pruning algorithm is proposed. We also design our custom text normalizer for WER evaluation. On Common Voice 11.0 Hindi dataset, we obtain, without degrading WER, (a) 35.4% reduction in model parameters, 14.25% lower memory consumption and 18.5% fewer FLOPs on Whisper-small, and (b) 31% reduction in model parameters, 15.29% lower memory consumption and 16.95% fewer FLOPs on Whisper-medium; and, (c) substantially outperform the state-of-the-art Iterative Magnitude Pruning based method by pruning 18.7% more parameters along with a 12.31 reduction in WER.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12666","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.420722","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Prasenjit K Mudi, Anshi Sachan, Dahlia Devapriya, Sheetal Kalyani","raw_content_length":1064,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["WER","Common Voice","the Sparse Group"],"persons":["Whisper"],"locations":[],"monetary":[]},"char_count":1063,"language_detected":"en","key_concepts":{"key_phrases":["Structured Sparsity","Weight","arXiv251012666v1 Announce Type","new Abstract","Whisper models","remarkable progress","speech recognition","their large size","a bottleneck","deployment"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Structured Sparsity":2.0,"Weight":2.0,"arXiv251012666v1 Announce Type":1.0,"new Abstract":1.0,"Whisper models":1.0,"remarkable progress":1.0,"speech recognition":1.0,"their large size":1.0,"a bottleneck":1.0,"deployment":1.0}},"age_hours":2.7430864744444445,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9122,"joy":0.011,"surprise":0.0168,"sadness":0.0104,"fear":0.009,"anger":0.0265,"disgust":0.0141},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a method for reducing the size and computational cost of speech recognition models, which could lead to lower energy consumption during inference on edge devices. The claims are supported by specific metrics on the Common Voice 11.0 Hindi dataset, including reductions in model parameters, memory consumption, and FLOPs. However, it is still in the research phase, with no deployed units mentioned.","key_impact_metrics":["35.4% reduction in model parameters","18.5% fewer FLOPs"],"technology_tags":["structured sparsity","model pruning","speech recognition"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:29:28.868727Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f4653a756f43","title":"The Role of Parametric Injection","content":"arXiv:2510.12668v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving external documents. As an emerging form of RAG, parametric retrieval-augmented generation (PRAG) encodes documents as model parameters (i.e., LoRA modules) and injects these representations into the model during inference, enabling interaction between the LLM and documents at parametric level. Compared with directly placing documents in the input context, PRAG is more efficient and has the potential to offer deeper model-document interaction. Despite its growing attention, the mechanism underlying parametric injection remains poorly understood. In this work, we present a systematic study of PRAG to clarify the role of parametric injection, showing that parameterized documents capture only partial semantic information of documents, and relying on them alone yields inferior performance compared to interaction at text level. However, these parametric representations encode high-level document information that can enhance the model's understanding of documents within the input context. When combined parameterized documents with textual documents, the model can leverage relevant information more effectively and become more robust to noisy inputs, achieving better performance than either source alone. We recommend jointly using parameterized and textual documents and advocate for increasing the information content of parametric representations to advance PRAG.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12668","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.422693","language":"en","tags":["preprints","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Minghao Tang, Shiyu Ni, Jingtong Wu, Zengxin Han, Keping Bi","raw_content_length":1514,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["LoRA","RAG","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1513,"language_detected":"en","key_concepts":{"key_phrases":["documents","The Role","Parametric Injection","RAG","arXiv251012668v1 Announce Type","new Abstract","Retrieval-augmented generation","large language models","LLMs","external documents"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"documents":3.0,"The Role":2.0,"Parametric Injection":2.0,"RAG":2.0,"arXiv251012668v1 Announce Type":1.0,"new Abstract":1.0,"Retrieval-augmented generation":1.0,"large language models":1.0,"LLMs":1.0,"external documents":1.0}},"age_hours":2.7431010469444446,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8814,"joy":0.0223,"surprise":0.0434,"sadness":0.0043,"fear":0.0064,"anger":0.0232,"disgust":0.019},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a novel method (PRAG) for improving LLMs, but its direct climate impact is minimal. The research is at a basic stage, with no deployed technology or measured outcomes related to sustainability. The technical credibility is relatively high due to the scientific study, but economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["parametric retrieval-augmented generation","large language models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:29:32.653927Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cebb25e942bd","title":"TerraCodec: Compressing Earth Observations","content":"arXiv:2510.12670v1 Announce Type: new Abstract: Earth observation (EO) satellites produce massive streams of multispectral image time series, posing pressing challenges for storage and transmission. Yet, learned EO compression remains fragmented, lacking publicly available pretrained models and misaligned with advances in compression for natural imagery. Image codecs overlook temporal redundancy, while video codecs rely on motion priors that fail to capture the radiometric evolution of largely static scenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to EO. TEC includes efficient image-based variants adapted to multispectral inputs, as well as a Temporal Transformer model (TEC-TT) that leverages dependencies across time. To overcome the fixed-rate setting of today's neural codecs, we present Latent Repacking, a novel method for training flexible-rate transformer models that operate on varying rate-distortion settings. Trained on Sentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x stronger compression at equivalent image quality. Beyond compression, TEC-TT enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the AllClear benchmark. Our results establish bespoke, learned compression algorithms as a promising direction for Earth observation. Code and model weights will be released under a permissive license.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12670","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.423670","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Julen Costa-Watanabe, Isabelle Wittmann, Benedikt Blumenstiel, Konrad Schindler","raw_content_length":1395,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["TEC-TT","TEC","Temporal Transformer","TerraCodec"],"persons":["Latent Repacking"],"locations":[],"monetary":[]},"char_count":1394,"language_detected":"en","key_concepts":{"key_phrases":["TerraCodec","Compressing Earth Observations","arXiv251012670v1 Announce Type","new Abstract","Earth observation","EO satellites","massive streams","multispectral image time series","challenges","storage"],"filter_categories":{"hydrogen_energy":["storage"],"renewable_energy":["storage"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TerraCodec":2.0,"Compressing Earth Observations":2.0,"arXiv251012670v1 Announce Type":1.0,"new Abstract":1.0,"Earth observation":1.0,"EO satellites":1.0,"massive streams":1.0,"multispectral image time series":1.0,"challenges":1.0,"storage":1.0}},"age_hours":2.743130378333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7679,"joy":0.0034,"surprise":0.0436,"sadness":0.0758,"fear":0.0206,"anger":0.0475,"disgust":0.0413},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"TerraCodec achieves 3-10x stronger compression of Earth observation data at equivalent image quality compared to classical codecs. This reduces storage and transmission needs, potentially lowering the energy footprint of satellite data management. The technology is at the applied research stage, with code and model weights to be released.","key_impact_metrics":["3-10x stronger compression","Equivalent image quality"],"technology_tags":["Data compression","Earth observation","Machine learning"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T16:29:36.338788Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6e7f43a2032c","title":"MCOP: Multi","content":"arXiv:2510.12679v1 Announce Type: new Abstract: Unmanned Aerial Vehicle (UAV) swarm systems necessitate efficient collaborative perception mechanisms for diverse operational scenarios. Current Bird's Eye View (BEV)-based approaches exhibit two main limitations: bounding-box representations fail to capture complete semantic and geometric information of the scene, and their performance significantly degrades when encountering undefined or occluded objects. To address these limitations, we propose a novel multi-UAV collaborative occupancy prediction framework. Our framework effectively preserves 3D spatial structures and semantics through integrating a Spatial-Aware Feature Encoder and Cross-Agent Feature Integration. To enhance efficiency, we further introduce Altitude-Aware Feature Reduction to compactly represent scene information, along with a Dual-Mask Perceptual Guidance mechanism to adaptively select features and reduce communication overhead. Due to the absence of suitable benchmark datasets, we extend three datasets for evaluation: two virtual datasets (Air-to-Pred-Occ and UAV3D-Occ) and one real-world dataset (GauUScene-Occ). Experiments results demonstrate that our method achieves state-of-the-art accuracy, significantly outperforming existing collaborative methods while reducing communication overhead to only a fraction of previous approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12679","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.424468","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Zefu Lin, Wenbo Chen, Xiaojuan Jin, Yuran Yang, Lue Fan, Yixin Zhang, Yufeng Zhang, Zhaoxiang Zhang","raw_content_length":1375,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["Altitude-Aware Feature Reduction","UAV","Spatial-Aware Feature Encoder"],"persons":[],"locations":[],"monetary":[]},"char_count":1374,"language_detected":"en","key_concepts":{"key_phrases":["MCOP","Multi","arXiv251012679v1 Announce Type","new Abstract","UAV","necessitate efficient collaborative perception mechanisms","diverse operational scenarios","Current Birds Eye View","BEV-based approaches","two main limitations"],"filter_categories":{"ai_ml":["two main limitations"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MCOP":2.0,"Multi":2.0,"arXiv251012679v1 Announce Type":1.0,"new Abstract":1.0,"UAV":1.0,"necessitate efficient collaborative perception mechanisms":1.0,"diverse operational scenarios":1.0,"Current Birds Eye View":1.0,"BEV-based approaches":1.0,"two main limitations":1.0}},"age_hours":2.7431580597222225,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8574,"joy":0.0063,"surprise":0.0396,"sadness":0.0188,"fear":0.0151,"anger":0.036,"disgust":0.0268},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel multi-UAV collaborative occupancy prediction framework, demonstrating state-of-the-art accuracy and reduced communication overhead compared to existing methods. While the framework shows promise, it is currently evaluated on extended datasets, including virtual and one real-world dataset, indicating it is in the applied research phase with limited real-world deployment. The climate impact is indirect, potentially improving efficiency in applications like environmental monitoring or precision agriculture, but not directly reducing emissions.","key_impact_metrics":["reduced communication overhead","state-of-the-art accuracy"],"technology_tags":["UAV","collaborative perception","occupancy prediction"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T16:29:40.388677Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_20a1bf18744e","title":"Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No","content":"arXiv:2510.12680v1 Announce Type: new Abstract: Hybrid thinking enables LLMs to switch between reasoning and direct answering, offering a balance between efficiency and reasoning capability. Yet our experiments reveal that current hybrid thinking LLMs only achieve partial mode separation: reasoning behaviors often leak into the no-think mode. To understand and mitigate this, we analyze the factors influencing controllability and identify four that matter most: (1) larger data scale, (2) using think and no-think answers from different questions rather than the same question, (3) a moderate increase in no-think data number, and (4) a two-phase strategy that first trains reasoning ability and then applies hybrid think training. Building on these findings, we propose a practical recipe that, compared to standard training, can maintain accuracy in both modes while significantly reducing no-think output length (from $1085$ to $585$ on MATH500) and occurrences of reasoning-supportive tokens such as ``\\texttt{wait}'' (from $5917$ to $522$ on MATH500). Our findings highlight the limitations of current hybrid thinking and offer directions for strengthening its controllability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12680","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.424913","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Shouren Wang, Wang Yang, Xianxuan Long, Qifan Wang, Vipin Chaudhary, Xiaotian Han","raw_content_length":1186,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1185,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Hybrid Thinking","Think","arXiv251012680v1","Announce Type","new Abstract","Hybrid thinking","reasoning","direct answering","a balance"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Hybrid Thinking":2.0,"Think":2.0,"arXiv251012680v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Hybrid thinking":1.0,"reasoning":1.0,"direct answering":1.0,"a balance":1.0}},"age_hours":2.7431734525,"is_recent":true,"quality_score":0.7,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8888,"joy":0.0036,"surprise":0.027,"sadness":0.0104,"fear":0.0343,"anger":0.023,"disgust":0.013},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores improving the controllability of LLMs to switch between reasoning and direct answering. The concrete action is analyzing factors influencing controllability and proposing a training recipe to reduce no-think output length and reasoning-supportive tokens. The evidence is based on experiments on MATH500, showing a reduction in no-think output length from 1085 to 585 and a decrease in reasoning-supportive tokens from 5917 to 522. This is currently at the basic research stage.","key_impact_metrics":["no-think output length reduction from 1085 to 585","reasoning-supportive tokens reduction from 5917 to 522"],"technology_tags":["Large Language Models","Hybrid Thinking","AI Controllability"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:29:44.160704Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95863b43520a","title":"CoRA: Covariate","content":"arXiv:2510.12681v1 Announce Type: new Abstract: Time Series Foundation Models (TSFMs) have shown significant impact through their model capacity, scalability, and zero-shot generalization. However, due to the heterogeneity of inter-variate dependencies and the backbone scalability on large-scale multivariate datasets, most TSFMs are typically pre-trained on univariate time series. This limitation renders them oblivious to crucial information from diverse covariates in real-world forecasting tasks. To further enhance the performance of TSFMs, we propose a general covariate-aware adaptation (CoRA) framework for TSFMs. It leverages pre-trained backbones of foundation models while effectively incorporating exogenous covariates from various modalities, including time series, language, and images, to improve the quality of predictions. Technically, CoRA maintains the equivalence of initialization and parameter consistency during adaptation. With preserved backbones of foundation models as frozen feature extractors, the outcome embeddings from foundation models are empirically demonstrated more informative than raw data. Further, CoRA employs a novel Granger Causality Embedding (GCE) to automatically evaluate covariates regarding their causal predictability with respect to the target variate. We incorporate these weighted embeddings with a zero-initialized condition-injection mechanism, avoiding catastrophic forgetting of pre-trained foundation models and gradually integrates exogenous information. Extensive experiments show that CoRA of TSFMs surpasses state-of-the-art covariate-aware deep forecasters with full or few-shot training samples, achieving 31.1% MSE reduction on covariate-aware forecasting. Compared to other adaptation methods, CoRA exhibits strong compatibility with various advanced TSFMs and extends the scope of covariates to other modalities, presenting a practical paradigm for the application of TSFMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12681","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.425336","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Guo Qin, Zhi Chen, Yong Liu, Zhiyuan Shi, Haixuan Liu, Xiangdong Huang, Jianmin Wang, Mingsheng Long","raw_content_length":1945,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["CoRA","Time Series Foundation Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1944,"language_detected":"en","key_concepts":{"key_phrases":["CoRA Covariate","Announce Type","new Abstract","Time Series Foundation Models","TSFMs","significant impact","their model capacity","scalability","zero-shot generalization","the heterogeneity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CoRA Covariate":2.0,"Announce Type":1.0,"new Abstract":1.0,"Time Series Foundation Models":1.0,"TSFMs":1.0,"significant impact":1.0,"their model capacity":1.0,"scalability":1.0,"zero-shot generalization":1.0,"the heterogeneity":1.0}},"age_hours":2.7431880452777775,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9101,"joy":0.0077,"surprise":0.0476,"sadness":0.0097,"fear":0.0058,"anger":0.0127,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (CoRA) for improving time series forecasting by incorporating covariates, leading to a reported 31.1% MSE reduction. While the research shows promise, it is still in the early stages of development with no deployed units or real-world operational data. The lack of third-party verification and deployment readiness limits its current sustainability impact.","key_impact_metrics":["31.1% MSE reduction on covariate-aware forecasting"],"technology_tags":["Time Series Foundation Models","Covariate-aware adaptation","Granger Causality Embedding"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T16:29:47.393112Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5ff57cdc202f","title":"Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning","content":"arXiv:2510.12684v1 Announce Type: new Abstract: Robotics plays a pivotal role in planetary science and exploration, where autonomous and reliable systems are crucial due to the risks and challenges inherent to space environments. The establishment of permanent lunar bases demands robotic platforms capable of navigating and manipulating in the harsh lunar terrain. While wheeled rovers have been the mainstay for planetary exploration, their limitations in unstructured and steep terrains motivate the adoption of legged robots, which offer superior mobility and adaptability. This paper introduces a constrained reinforcement learning framework designed for autonomous quadrupedal mobile manipulators operating in lunar environments. The proposed framework integrates whole-body locomotion and manipulation capabilities while explicitly addressing critical safety constraints, including collision avoidance, dynamic stability, and power efficiency, in order to ensure robust performance under lunar-specific conditions, such as reduced gravity and irregular terrain. Experimental results demonstrate the framework's effectiveness in achieving precise 6D task-space end-effector pose tracking, achieving an average positional accuracy of 4 cm and orientation accuracy of 8.1 degrees. The system consistently respects both soft and hard constraints, exhibiting adaptive behaviors optimized for lunar gravity conditions. This work effectively bridges adaptive learning with essential mission-critical safety requirements, paving the way for advanced autonomous robotic explorers for future lunar missions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12684","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.425778","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Alvaro Belmonte-Baeza, Miguel Cazorla, Gabriel J. Garc\\'ia, Carlos J. P\\'erez-Del-Pulgar, Jorge Pomares","raw_content_length":1605,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Constrained Reinforcement Learning arXiv:2510.12684v1","Lunar Surface Operations"],"persons":[],"locations":[],"monetary":[]},"char_count":1604,"language_detected":"en","key_concepts":{"key_phrases":["Autonomous Legged Mobile Manipulation","Lunar Surface Operations","Constrained Reinforcement Learning","arXiv251012684v1","new Abstract","Robotics","a pivotal role","planetary science","exploration","autonomous and reliable systems"],"filter_categories":{"ai_ml":["Constrained Reinforcement Learning"],"research_academic":["planetary science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Autonomous Legged Mobile Manipulation":2.0,"Lunar Surface Operations":2.0,"Constrained Reinforcement Learning":2.0,"arXiv251012684v1":1.0,"new Abstract":1.0,"Robotics":1.0,"a pivotal role":1.0,"planetary science":1.0,"exploration":1.0,"autonomous and reliable systems":1.0}},"age_hours":2.743201918888889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.482,"joy":0.0097,"surprise":0.0143,"sadness":0.0651,"fear":0.2582,"anger":0.0786,"disgust":0.0921},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a constrained reinforcement learning framework for autonomous quadrupedal mobile manipulators in lunar environments. While the technology is promising, it is still in the early stages of development, with experimental results demonstrating the framework's effectiveness in achieving precise 6D task-space end-effector pose tracking, achieving an average positional accuracy of 4 cm and orientation accuracy of 8.1 degrees. The vaporware risk is flagged because it's a prototype with no deployed units.","key_impact_metrics":["positional accuracy of 4 cm","orientation accuracy of 8.1 degrees"],"technology_tags":["autonomous robotics","reinforcement learning","quadrupedal robots"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:29:50.632114Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fcfd86821488","title":"Few Shot Semi","content":"arXiv:2510.12686v1 Announce Type: new Abstract: Abnormal stop detection (ASD) in intercity coach transportation is critical for ensuring passenger safety, operational reliability, and regulatory compliance. However, two key challenges hinder ASD effectiveness: sparse GPS trajectories, which obscure short or unauthorized stops, and limited labeled data, which restricts supervised learning. Existing methods often assume dense sampling or regular movement patterns, limiting their applicability. To address data sparsity, we propose a Sparsity-Aware Segmentation (SAS) method that adaptively defines segment boundaries based on local spatial-temporal density. Building upon these segments, we introduce three domain-specific indicators to capture abnormal stop behaviors. To further mitigate the impact of sparsity, we develop Locally Temporal-Indicator Guided Adjustment (LTIGA), which smooths these indicators via local similarity graphs. To overcome label scarcity, we construct a spatial-temporal graph where each segment is a node with LTIGA-refined features. We apply label propagation to expand weak supervision across the graph, followed by a GCN to learn relational patterns. A final self-training module incorporates high-confidence pseudo-labels to iteratively improve predictions. Experiments on real-world coach data show an AUC of 0.854 and AP of 0.866 using only 10 labeled instances, outperforming prior methods. The code and dataset are publicly available at \\href{https://github.com/pangjunbiao/Abnormal-Stop-Detection-SSL.git}","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12686","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.426185","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Muhammad Ayub Sabir, Junbiao Pang, Jiaqi Wu, Fatima Ashraf","raw_content_length":1547,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["SAS","LTIGA","Locally Temporal-Indicator Guided Adjustment","Sparsity-Aware Segmentation","ASD"],"persons":[],"locations":[],"monetary":[]},"char_count":1546,"language_detected":"en","key_concepts":{"key_phrases":["Few Shot Semi","which","arXiv251012686v1 Announce Type","new Abstract","Abnormal stop detection","ASD","intercity coach transportation","passenger safety","operational reliability","regulatory compliance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Few Shot Semi":2.0,"which":2.0,"arXiv251012686v1 Announce Type":1.0,"new Abstract":1.0,"Abnormal stop detection":1.0,"ASD":1.0,"intercity coach transportation":1.0,"passenger safety":1.0,"operational reliability":1.0,"regulatory compliance":1.0}},"age_hours":2.7432159616666665,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8316,"joy":0.0041,"surprise":0.0119,"sadness":0.0189,"fear":0.0568,"anger":0.0396,"disgust":0.037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for abnormal stop detection in intercity coach transportation, which could lead to optimized routes and reduced fuel consumption. The method is evaluated on real-world data, achieving an AUC of 0.854 and AP of 0.866. However, it is still in the research phase with no current deployment.","key_impact_metrics":["AUC of 0.854","AP of 0.866"],"technology_tags":["Abnormal Stop Detection","Sparsity-Aware Segmentation","Graph Convolutional Networks"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:29:53.628704Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be3820a32efc","title":"EReLiFM: Evidential Reliability-Aware Residual Flow Meta","content":"arXiv:2510.12687v1 Announce Type: new Abstract: Open-Set Domain Generalization (OSDG) aims to enable deep learning models to recognize unseen categories in new domains, which is crucial for real-world applications. Label noise hinders open-set domain generalization by corrupting source-domain knowledge, making it harder to recognize known classes and reject unseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL) using hyperbolic prototype-guided meta-learning, they struggle to bridge domain gaps, especially with limited clean labeled data. In this paper, we propose Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first introduce an unsupervised two-stage evidential loss clustering method to promote label reliability awareness. Then, we propose a residual flow matching mechanism that models structured domain- and category-conditioned residuals, enabling diverse and uncertainty-aware transfer paths beyond interpolation-based augmentation. During this meta-learning process, the model is optimized such that the update direction on the clean set maximizes the loss decrease on the noisy set, using pseudo labels derived from the most confident predicted class for supervision. Experimental results show that EReLiFM outperforms existing methods on OSDG-NL, achieving state-of-the-art performance. The source code is available at https://github.com/KPeng9510/ERELIFM.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12687","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.426610","language":"en","tags":["preprints","computer-science","cslg","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Kunyu Peng, Di Wen, Kailun Yang, Jia Fu, Yufan Chen, Ruiping Liu, Jiamin Wu, Junwei Zheng, M. Saquib Sarfraz, Luc Van Gool, Danda Pani Paudel, Rainer Stiefelhagen","raw_content_length":1422,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Evidential Reliability-Aware Residual Flow Meta-Learning","Evidential Reliability-Aware Residual Flow Meta arXiv:2510.12687v1 Announce Type"],"persons":["Noisy Labels"],"locations":[],"monetary":[]},"char_count":1421,"language_detected":"en","key_concepts":{"key_phrases":["EReLiFM","Evidential Reliability-Aware Residual Flow Meta","arXiv251012687v1 Announce Type","new Abstract","Open-Set Domain Generalization","OSDG","deep learning models","unseen categories","new domains","which"],"filter_categories":{"ai_ml":["Open-Set Domain Generalization","deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EReLiFM":2.0,"Evidential Reliability-Aware Residual Flow Meta":2.0,"arXiv251012687v1 Announce Type":1.0,"new Abstract":1.0,"Open-Set Domain Generalization":1.0,"OSDG":1.0,"deep learning models":1.0,"unseen categories":1.0,"new domains":1.0,"which":1.0}},"age_hours":2.743231280555556,"is_recent":true,"quality_score":1.0,"sentiment_score":2.3665000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5267,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8184,"joy":0.0057,"surprise":0.0245,"sadness":0.0127,"fear":0.0214,"anger":0.0485,"disgust":0.0689},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning method (EReLiFM) to improve open-set domain generalization, which could indirectly support sustainability by improving the reliability of AI systems used in various sectors. However, the paper does not provide any concrete actions or measurable outcomes related to climate change or other sustainability goals. The research is at a basic research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":[],"technology_tags":["machine learning","domain generalization","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:29:56.909685Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e9544f05dc04","title":"From Delegates to Trustees: How Optimizing for Long","content":"arXiv:2510.12689v1 Announce Type: new Abstract: Large language models (LLMs) have shown promising accuracy in predicting survey responses and policy preferences, which has increased interest in their potential to represent human interests in various domains. Most existing research has focused on behavioral cloning, effectively evaluating how well models reproduce individuals' expressed preferences. Drawing on theories of political representation, we highlight an underexplored design trade-off: whether AI systems should act as delegates, mirroring expressed preferences, or as trustees, exercising judgment about what best serves an individual's interests. This trade-off is closely related to issues of LLM sycophancy, where models can encourage behavior or validate beliefs that may be aligned with a user's short-term preferences, but is detrimental to their long-term interests. Through a series of experiments simulating votes on various policy issues in the U.S. context, we apply a temporal utility framework that weighs short and long-term interests (simulating a trustee role) and compare voting outcomes to behavior-cloning models (simulating a delegate). We find that trustee-style predictions weighted toward long-term interests produce policy decisions that align more closely with expert consensus on well-understood issues, but also show greater bias toward models' default stances on topics lacking clear agreement. These findings reveal a fundamental trade-off in designing AI systems to represent human interests. Delegate models better preserve user autonomy but may diverge from well-supported policy positions, while trustee models can promote welfare on well-understood issues yet risk paternalism and bias on subjective topics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12689","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.427040","language":"en","tags":["preprints","csai","computer-science","research","cscy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Suyash Fulay, Jocelyn Zhu, Michiel Bakker","raw_content_length":1756,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1755,"language_detected":"en","key_concepts":{"key_phrases":["Delegates","Trustees","arXiv251012689v1 Announce Type","new Abstract","Large language models","LLMs","promising accuracy","survey responses","policy preferences","which"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Delegates":2.0,"Trustees":2.0,"arXiv251012689v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"promising accuracy":1.0,"survey responses":1.0,"policy preferences":1.0,"which":1.0}},"age_hours":2.7432461455555557,"is_recent":true,"quality_score":1.0,"sentiment_score":9.7825,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9565,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.75,"joy":0.1376,"surprise":0.0791,"sadness":0.0056,"fear":0.0109,"anger":0.0134,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the trade-offs between AI delegate and trustee models in policy decisions, using simulations to compare voting outcomes. While it doesn't directly reduce GHG emissions, it explores how AI could influence policy decisions related to sustainability. The technical credibility is relatively high due to the use of experiments and a temporal utility framework, but deployment readiness is low as it is still in the research phase.","key_impact_metrics":["Alignment with expert consensus on well-understood issues","Bias toward models' default stances on topics lacking clear agreement"],"technology_tags":["Large Language Models","AI Policy Modeling"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:29:59.689832Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e525fb72b2d9","title":"Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High","content":"arXiv:2510.12692v1 Announce Type: new Abstract: There is growing interest in applying artificial intelligence (AI) to automate and support complex decision-making tasks. However, it remains unclear how algorithms compare to human judgment in contexts requiring semantic understanding and domain expertise. We examine this in the context of the judge assignment problem, matching submissions to suitably qualified judges. Specifically, we tackled this problem at the Harvard President's Innovation Challenge, the university's premier venture competition awarding over \\$500,000 to student and alumni startups. This represents a real-world environment where high-quality judge assignment is essential. We developed an AI-based judge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE), and deployed it at the competition. We then evaluated its performance against human expert assignments using blinded match-quality scores from judges on $309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we found no statistically significant difference in assignment quality between the two approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated $3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an excellent match. Furthermore, manual assignments that previously required a full week could be automated in several hours by the algorithm during deployment. These results demonstrate that HLSE achieves human-expert-level matching quality while offering greater scalability and efficiency, underscoring the potential of AI-driven solutions to support and enhance human decision-making for judge assignment in high-stakes settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12692","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.428062","language":"en","tags":["preprints","cshc","csai","computer-science","cslg","research","cscl","cscy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Sarina Xi, Orelia Pi, Miaomiao Zhang, Becca Xiong, Jacqueline Ng Lane, Nihar B. Shah","raw_content_length":1697,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["Hybrid Lexical-Semantic Similarity Ensemble","Innovation Challenge","Harvard"],"persons":[],"locations":[],"monetary":[]},"char_count":1696,"language_detected":"en","key_concepts":{"key_phrases":["Who","a Better Matchmaker","Human vs Algorithmic Judge Assignment","arXiv251012692v1 Announce Type","new Abstract","There is growing interest","artificial intelligence","complex decision-making tasks","algorithms","human judgment"],"filter_categories":{"ai_ml":["Human vs Algorithmic Judge Assignment","artificial intelligence","algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Who":2.0,"a Better Matchmaker":2.0,"Human vs Algorithmic Judge Assignment":2.0,"arXiv251012692v1 Announce Type":1.0,"new Abstract":1.0,"There is growing interest":1.0,"artificial intelligence":1.0,"complex decision-making tasks":1.0,"algorithms":1.0,"human judgment":1.0}},"age_hours":2.7432748452777775,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1355,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8271,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8807,"joy":0.0101,"surprise":0.0744,"sadness":0.0037,"fear":0.0094,"anger":0.0138,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":1,"technical_credibility":6,"economic_viability":3,"deployment_readiness":5,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes the deployment of an AI algorithm for judge assignment in a real-world venture competition. The algorithm's performance was evaluated against human experts using match-quality scores, showing no statistically significant difference. While this improves efficiency, it has minimal direct climate or sustainability impact.","key_impact_metrics":["algorithmic matches rated 3.90 on a 5-point scale","manual matches rated 3.94 on a 5-point scale"],"technology_tags":["AI","algorithm","judge assignment"],"sdg_alignment":[4,8,9,17],"analyzed_at":"2025-10-29T16:30:03.120616Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be4312b573a3","title":"ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning","content":"arXiv:2510.12693v1 Announce Type: new Abstract: Recent advances in embodied AI highlight the potential of vision language models (VLMs) as agents capable of perception, reasoning, and interaction in complex environments. However, top-performing systems rely on large-scale models that are costly to deploy, while smaller VLMs lack the necessary knowledge and skills to succeed. To bridge this gap, we present \\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates prior knowledge learning and online reinforcement learning (RL). The first stage, \\textit{Embodied Prior Learning}, distills foundational knowledge from three types of data: (1) Trajectory-Augmented Priors, which enrich existing trajectory data with structured reasoning generated by stronger models; (2) Environment-Anchored Priors, which provide in-environment knowledge and grounding supervision; and (3) External Knowledge Priors, which transfer general knowledge from out-of-environment datasets. In the second stage, we develop an online RL pipeline that builds on these priors to further enhance agent performance. To overcome the inherent challenges in agent RL, including long horizons, sparse rewards, and training instability, we introduce three key designs: self-summarization for context management, dense reward shaping, and turn-level policy optimization. Extensive experiments on both high-level planning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate that ERA-3B surpasses both prompting-based large models and previous training-based baselines. Specifically, it achieves overall improvements of 8.4\\% on EB-ALFRED and 19.4\\% on EB-Manipulation over GPT-4o, and exhibits strong generalization to unseen tasks. Overall, ERA offers a practical path toward scalable embodied intelligence, providing methodological insights for future embodied AI systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12693","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.428492","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Hanyang Chen, Mark Zhao, Rui Yang, Qinwei Ma, Ke Yang, Jiarui Yao, Kangrui Wang, Hao Bai, Zhenhailong Wang, Rui Pan, Mengchao Zhang, Jose Barreiros, Aykut Onol, ChengXiang Zhai, Heng Ji, Manling Li, Huan Zhang, Tong Zhang","raw_content_length":1880,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["Embodied Prior Learning and Online Reinforcement Learning arXiv:2510.12693v1 Announce Type","Embodied Agents","Prior Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1879,"language_detected":"en","key_concepts":{"key_phrases":["ERA","VLMs","Embodied Agents","Embodied Prior Learning","Online Reinforcement Learning","arXiv251012693v1 Announce Type","new Abstract","Recent advances","embodied AI","the potential"],"filter_categories":{"ai_ml":["Online Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ERA":3.0,"VLMs":3.0,"Embodied Agents":2.0,"Embodied Prior Learning":2.0,"Online Reinforcement Learning":2.0,"arXiv251012693v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"embodied AI":1.0,"the potential":1.0}},"age_hours":2.743290396111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7579,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8034,"joy":0.0184,"surprise":0.0312,"sadness":0.0389,"fear":0.0313,"anger":0.0535,"disgust":0.0234},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel AI framework (ERA) for embodied agents, demonstrating improved performance on specific tasks (EB-ALFRED and EB-Manipulation) compared to GPT-4o. The concrete action is the development and testing of this AI model. The evidence supporting the claims comes from experiments showing improvements of 8.4% and 19.4% respectively. It is currently in the applied research stage, with no indication of real-world deployment.","key_impact_metrics":["8.4% improvement on EB-ALFRED","19.4% improvement on EB-Manipulation"],"technology_tags":["Embodied AI","Reinforcement Learning","Vision Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:06.180014Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6933c49e2e60","title":"Generation Space Size: Understanding and Calibrating Open","content":"arXiv:2510.12699v1 Announce Type: new Abstract: Different open-ended generation tasks require different degrees of output diversity. However, current LLMs are often miscalibrated. They collapse to overly homogeneous outputs for creative tasks and hallucinate diverse but incorrect responses for factual tasks. We argue that these two failure modes are unified by, and can both be addressed by, the notion of effective generation space size (GSS) -- the set of semantically distinct outputs a model considers for a prompt. We present GSSBench, a task suite of prompt pairs with ground-truth GSS relationships to assess different metrics and understand where models diverge from desired behavior. We find that hallucination detection metrics, particularly EigenScore, consistently outperform standard diversity and uncertainty quantification metrics, while using only model internals, providing interpretable insights into a model's internal task representations. We demonstrate three applications of GSS: (1) detecting prompt ambiguity and predicting clarification questions for better grounding, (2) interpreting overthinking and underthinking in reasoning models, and (3) steering models to expand their generation space to yield high-quality and diverse outputs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12699","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.429742","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Sunny Yu, Ahmad Jabbar, Robert Hawkins, Dan Jurafsky, Myra Cheng","raw_content_length":1265,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["GSSBench","EigenScore","GSS"],"persons":[],"locations":[],"monetary":[]},"char_count":1264,"language_detected":"en","key_concepts":{"key_phrases":["Generation Space Size","Understanding","Calibrating Open","arXiv251012699v1 Announce Type","new Abstract","Different open-ended generation tasks","different degrees","output diversity","current LLMs","overly homogeneous outputs"],"filter_categories":{"ai_ml":["current LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generation Space Size":2.0,"Understanding":2.0,"Calibrating Open":2.0,"arXiv251012699v1 Announce Type":1.0,"new Abstract":1.0,"Different open-ended generation tasks":1.0,"different degrees":1.0,"output diversity":1.0,"current LLMs":1.0,"overly homogeneous outputs":1.0}},"age_hours":2.743330058333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8065,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0387,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9065,"joy":0.0041,"surprise":0.0084,"sadness":0.0065,"fear":0.0275,"anger":0.0249,"disgust":0.022},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (GSSBench) for evaluating and improving the diversity and accuracy of LLM outputs, which could indirectly support sustainability efforts by improving the quality of information and decision-making. The paper focuses on theoretical improvements and presents a task suite for evaluation, but lacks concrete deployment or measured environmental outcomes. The technical credibility is high due to the focus on metrics and internal model analysis.","key_impact_metrics":["EigenScore","Generation Space Size"],"technology_tags":["Large Language Models","Hallucination Detection","Prompt Engineering"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:30:09.948677Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f774cf8b339","title":"Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?","content":"arXiv:2510.12702v1 Announce Type: new Abstract: Automatic software verifiers have become increasingly effective at the task of checking software against (formal) specifications. Yet, their adoption in practice has been hampered by the lack of such specifications in real world code. Large Language Models (LLMs) have shown promise in inferring formal postconditions from natural language hints embedded in code such as function names, comments or documentation. Using the generated postconditions as specifications in a subsequent verification, however, often leads verifiers to suggest invalid inputs, hinting at potential issues that ultimately turn out to be false alarms. To address this, we revisit the problem of specification inference from natural language in the context of automatic software verification. In the process, we introduce NL2Contract, the task of employing LLMs to translate informal natural language into formal functional contracts, consisting of postconditions as well as preconditions. We introduce metrics to validate and compare different NL2Contract approaches, using soundness, bug discriminative power of the generated contracts and their usability in the context of automatic software verification as key metrics. We evaluate NL2Contract with different LLMs and compare it to the task of postcondition generation nl2postcond. Our evaluation shows that (1) LLMs are generally effective at generating functional contracts sound for all possible inputs, (2) the generated contracts are sufficiently expressive for discriminating buggy from correct behavior, and (3) verifiers supplied with LLM inferred functional contracts produce fewer false alarms than when provided with postconditions alone. Further investigations show that LLM inferred preconditions generally align well with developers intentions which allows us to use automatic software verifiers to catch real-world bugs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12702","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.430568","language":"en","tags":["preprints","csai","computer-science","csse","research","cspl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":264,"author":"Cedric Richter, Heike Wehrheim","raw_content_length":1915,"priority":7,"update_frequency":1,"reading_time_minutes":1.32,"robust_parsing_used":true,"entities":{"organizations":["Formal Contracts for Automatic Software Verification"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1912,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Postconditions","Formal Contracts","Automatic Software Verification","Announce Type","new Abstract","Automatic software verifiers","the task","software","formal specifications"],"filter_categories":{"ai_ml":["Large Language Models"],"engineering":["software"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"Postconditions":2.0,"Formal Contracts":2.0,"Automatic Software Verification":2.0,"Announce Type":1.0,"new Abstract":1.0,"Automatic software verifiers":1.0,"the task":1.0,"software":1.0,"formal specifications":1.0}},"age_hours":2.7433571944444446,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9137,"joy":0.0054,"surprise":0.0351,"sadness":0.0094,"fear":0.0174,"anger":0.0091,"disgust":0.0099},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on using LLMs to improve software verification, potentially leading to more reliable and efficient software. The concrete action is the development and evaluation of the NL2Contract approach. The evidence supporting claims comes from evaluations showing the effectiveness of LLMs in generating functional contracts and reducing false alarms in software verification.","key_impact_metrics":["Fewer false alarms produced by verifiers","Soundness of generated functional contracts"],"technology_tags":["Large Language Models","Software Verification","Formal Contracts"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:30:13.054893Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
