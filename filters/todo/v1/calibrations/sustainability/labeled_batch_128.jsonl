{"id":"science_arxiv_cs_b8307a47e5db","title":"Policy Contrastive Decoding for Robotic Foundation Models","content":"arXiv:2505.13255v3 Announce Type: replace Abstract: Robotic foundation models, or generalist robot policies, hold immense potential to enable flexible, general-purpose and dexterous robotic systems. Despite their advancements, our empirical experiments reveal that existing robot policies are prone to learning spurious correlations from pre-training trajectories, adversely affecting their generalization capabilities beyond the training data. To tackle this, we propose a novel Policy Contrastive Decoding (PCD) approach, which redirects the robot policy's focus toward object-relevant visual clues by contrasting action probability distributions derived from original and object-masked visual inputs. As a training-free method, our PCD can be used as a plugin to improve different types of robot policies without needing to finetune or access model weights. We conduct extensive experiments on top of three open-source robot policies, including the autoregressive policy OpenVLA and the diffusion-based policies Octo and $\\pi_0$. The obtained results in both simulation and real-world environments prove PCD's flexibility and effectiveness, e.g., PCD enhances the state-of-the-art policy $\\pi_0$ by 8.9% in the simulation environment and by 108% in the real-world environment. Code and demos are publicly available at: https://Koorye.github.io/proj/PCD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13255","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.174332","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Shihan Wu, Ji Zhang, Xu Luo, Junlin Xie, Jingkuan Song, Heng Tao Shen, Lianli Gao","raw_content_length":1357,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1356,"language_detected":"en","key_concepts":{"key_phrases":["Robotic Foundation Models","arXiv250513255v3","Announce Type","Abstract","Robotic foundation models","generalist robot policies","immense potential","flexible general-purpose and dexterous robotic systems","their advancements","our empirical experiments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robotic Foundation Models":2.0,"arXiv250513255v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Robotic foundation models":1.0,"generalist robot policies":1.0,"immense potential":1.0,"flexible general-purpose and dexterous robotic systems":1.0,"their advancements":1.0,"our empirical experiments":1.0}},"age_hours":2.7663915991666665,"is_recent":true,"quality_score":0.7,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.822,"joy":0.0041,"surprise":0.0208,"sadness":0.0346,"fear":0.0298,"anger":0.0344,"disgust":0.0544},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (PCD) to improve robot policy generalization. While the results show a performance increase in simulation and real-world environments (e.g., 108% improvement on pi_0), the impact on sustainability is indirect and difficult to quantify. The technology is at an early stage of deployment, demonstrated in research settings.","key_impact_metrics":["8.9% enhancement in simulation","108% enhancement in real-world environment"],"technology_tags":["Robotics","Machine Learning","Policy Contrastive Decoding"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:29:20.155247Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_431324369a97","title":"Transparent and Robust RAG: Adaptive","content":"arXiv:2505.13258v2 Announce Type: replace Abstract: Retrieval-Augmented Generation (RAG) delivers substantial value in knowledge-intensive applications. Many recent works use reinforcement learning (RL) to elicit strong reasoning in RAG generators. However, two key challenges remain unresolved: (1) Transparency: most prior methods do not explicitly indicate which references are actually used during the reasoning that leads to the final answer, limiting interpretability and visibility; (2) Stability: the KL divergence estimator used in existing RL-based approaches may cause gradient spikes, leading to unstable training. To address these challenges, we propose Adaptive-Rewarded Evidence Navigation Agent (ARENA), a transparent and robust RAG generator framework trained via RL with designed rewards. Based on our structured protocol, KL divergence stabilization, and adaptive reward calculation modules, ARENA enables the RAG generator to identify key evidence, perform structured reasoning, and generate answers with interpretable decision traces. Applied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, extensive experiments across multiple baselines show 10-30% accuracy improvements on three multi-hop QA datasets, comparable to advanced closed-source LLMs (e.g., OpenAI o1, DeepSeek R1). Further analyses show that ARENA generalizes well to unseen datasets and tasks. Our models and codes are publicly released.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13258","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.174738","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu","raw_content_length":1425,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Adaptive-Rewarded Evidence Navigation","Retrieval-Augmented Generation"],"persons":[],"locations":["RAG"],"monetary":[]},"char_count":1424,"language_detected":"en","key_concepts":{"key_phrases":["Transparent and Robust RAG","Adaptive","arXiv250513258v2 Announce Type","Retrieval-Augmented Generation","RAG","substantial value","knowledge-intensive applications","Many recent works","reinforcement learning","strong reasoning"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Transparent and Robust RAG":2.0,"Adaptive":2.0,"arXiv250513258v2 Announce Type":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0,"substantial value":1.0,"knowledge-intensive applications":1.0,"Many recent works":1.0,"reinforcement learning":1.0,"strong reasoning":1.0}},"age_hours":2.7664067691666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2405,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8481,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8627,"joy":0.0043,"surprise":0.0074,"sadness":0.0096,"fear":0.0239,"anger":0.0374,"disgust":0.0547},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new RAG generator framework (ARENA) that improves accuracy on multi-hop QA datasets by 10-30% compared to baselines. While the research is promising, it is still in the applied research stage with no deployed units or operational data related to sustainability. The potential climate impact is indirect, as improved AI reasoning could potentially be applied to climate modeling or optimization, but this is speculative.","key_impact_metrics":["Accuracy improvements on multi-hop QA datasets: 10-30%"],"technology_tags":["Retrieval-Augmented Generation","Reinforcement Learning","Large Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:29:25.192708Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7b54fbfffce4","title":"Breaking the Compression Ceiling: Data","content":"arXiv:2505.13563v3 Announce Type: replace Abstract: With the rise of the fine-tuned-pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 50x compression, (b) general NLP models (RoBERTa-base, T5-base) with up to 224x compression, (c) vision models (ViT-B/32, ViT-L/14) with up to 132x compression, and (d) multi-modal models (BEiT-3) with 18x compression, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression. Code is available at https://github.com/xiaohuiwang000/UltraDelta.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13563","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.175564","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Xiaohui Wang, Peng Ye, Chenyu Huang, Shenghe Zheng, Bo Zhang, Lei Bai, Wanli Ouyang, Tao Chen","raw_content_length":1825,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Delta","UltraDelta"],"persons":["Variance-Based"],"locations":[],"monetary":[]},"char_count":1824,"language_detected":"en","key_concepts":{"key_phrases":["the Compression Ceiling","arXiv250513563v3","Announce Type","Abstract","the rise","the fine-tuned-pretrained paradigm","numerous fine-tuned models","multi-tasking","significant storage","Delta compression"],"filter_categories":{"ai_ml":["the fine-tuned-pretrained paradigm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Compression Ceiling":2.0,"arXiv250513563v3":1.0,"Announce Type":1.0,"Abstract":1.0,"the rise":1.0,"the fine-tuned-pretrained paradigm":1.0,"numerous fine-tuned models":1.0,"multi-tasking":1.0,"significant storage":1.0,"Delta compression":1.0}},"age_hours":2.7664380461111113,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8231,"joy":0.0036,"surprise":0.028,"sadness":0.0781,"fear":0.0105,"anger":0.0287,"disgust":0.0281},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a data-free delta compression pipeline (UltraDelta) that achieves ultra-high compression and strong performance for large language models, NLP models, vision models, and multi-modal models. The concrete action is the development and testing of a new compression algorithm. The evidence supporting claims comes from extensive experiments across various models, demonstrating up to 224x compression. However, it is still in the applied research stage with no mention of real-world deployment.","key_impact_metrics":["up to 50x compression on LLaMA-2 7B and 13B","up to 224x compression on RoBERTa-base, T5-base"],"technology_tags":["data compression","machine learning","model optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:29:29.012681Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1ba031b665b7","title":"Personalized Bayesian Federated Learning with Wasserstein Barycenter Aggregation","content":"arXiv:2505.14161v2 Announce Type: replace Abstract: Personalized Bayesian federated learning (PBFL) handles non-i.i.d. client data and quantifies uncertainty by combining personalization with Bayesian inference. However, existing PBFL methods face two limitations: restrictive parametric assumptions in client posterior inference and naive parameter averaging for server aggregation. To overcome these issues, we propose FedWBA, a novel PBFL method that enhances both local inference and global aggregation. At the client level, we use particle-based variational inference for nonparametric posterior representation. At the server level, we introduce particle-based Wasserstein barycenter aggregation, offering a more geometrically meaningful approach. Theoretically, we provide local and global convergence guarantees for FedWBA. Locally, we prove a KL divergence decrease lower bound per iteration for variational inference convergence. Globally, we show that the Wasserstein barycenter converges to the true parameter as the client data size increases. Empirically, experiments show that FedWBA outperforms baselines in prediction accuracy, uncertainty calibration, and convergence rate, with ablation studies confirming its robustness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.14161","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.175950","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Ting Wei, Biao Mei, Junliang Lyu, Renquan Zhang, Feng Zhou, Yifan Sun","raw_content_length":1240,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["FedWBA","Personalized Bayesian Federated Learning"],"persons":["Wasserstein"],"locations":[],"monetary":[]},"char_count":1239,"language_detected":"en","key_concepts":{"key_phrases":["Personalized Bayesian Federated Learning","Wasserstein Barycenter Aggregation","arXiv250514161v2 Announce Type","Abstract","quantifies","uncertainty","personalization","Bayesian inference","existing PBFL methods","two limitations"],"filter_categories":{"ai_ml":["uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Personalized Bayesian Federated Learning":2.0,"Wasserstein Barycenter Aggregation":2.0,"arXiv250514161v2 Announce Type":1.0,"Abstract":1.0,"quantifies":1.0,"uncertainty":1.0,"personalization":1.0,"Bayesian inference":1.0,"existing PBFL methods":1.0,"two limitations":1.0}},"age_hours":2.7664524544444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9099,"joy":0.0086,"surprise":0.017,"sadness":0.0076,"fear":0.0391,"anger":0.0117,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (FedWBA) for personalized Bayesian federated learning. While the method shows promise in improving prediction accuracy, uncertainty calibration, and convergence rate, it is currently in the basic research phase with no deployed units or real-world data. The climate impact is theoretical, as the application to specific climate-related problems is not discussed, but the potential for more efficient machine learning could reduce energy consumption in some applications.","key_impact_metrics":["KL divergence decrease lower bound per iteration","Wasserstein barycenter converges to the true parameter as the client data size increases"],"technology_tags":["federated learning","bayesian inference","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:29:32.949571Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bb22ab111ca8","title":"\"Haet Bhasha aur Diskrimineshun\": Phonetic Perturbations in Code","content":"arXiv:2505.14226v3 Announce Type: replace Abstract: Recently released LLMs have strong multilingual \\& multimodal capabilities. Model vulnerabilities are exposed using audits and red-teaming efforts. Existing efforts have focused primarily on the English language; thus, models continue to be susceptible to multilingual jailbreaking strategies, especially for multimodal contexts. In this study, we introduce a novel strategy that leverages code-mixing and phonetic perturbations to jailbreak LLMs for both text and image generation tasks. We also present an extension to a current jailbreak-template-based strategy and propose a novel template, showing higher effectiveness than baselines. Our work presents a method to effectively bypass safety filters in LLMs while maintaining interpretability by applying phonetic misspellings to sensitive words in code-mixed prompts. We achieve a 99\\% Attack Success Rate for text generation and 78\\% for image generation, with Attack Relevance Rate of 100\\% for text generation and 96\\% for image generation for the phonetically perturbed code-mixed prompts. Our interpretability experiments reveal that phonetic perturbations impact word tokenization, leading to jailbreak success. Our study motivates increasing the focus towards more generalizable safety alignment for multilingual multimodal models, especially in real-world settings wherein prompts can have misspelt words. \\textit{\\textbf{Warning: This paper contains examples of potentially harmful and offensive content.}}","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.14226","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.176359","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Darpan Aswal, Siddharth D Jaiswal","raw_content_length":1523,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Phonetic Perturbations"],"persons":[],"locations":[],"monetary":[]},"char_count":1522,"language_detected":"en","key_concepts":{"key_phrases":["Haet Bhasha aur Diskrimineshun","Phonetic Perturbations","Code","LLMs","arXiv250514226v3 Announce Type","Abstract","strong multilingual ","multimodal capabilities","Model vulnerabilities","audits"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Haet Bhasha aur Diskrimineshun":2.0,"Phonetic Perturbations":2.0,"Code":2.0,"LLMs":2.0,"arXiv250514226v3 Announce Type":1.0,"Abstract":1.0,"strong multilingual ":1.0,"multimodal capabilities":1.0,"Model vulnerabilities":1.0,"audits":1.0}},"age_hours":2.766467718611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.891,"joy":0.006,"surprise":0.0431,"sadness":0.0108,"fear":0.0218,"anger":0.0164,"disgust":0.0109},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method to jailbreak LLMs, highlighting vulnerabilities in safety filters. While the research is technically sound and demonstrates a high attack success rate (99% for text, 78% for image), it doesn't directly contribute to climate change mitigation or adaptation. The work is in the basic research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["Attack Success Rate 99%","Attack Success Rate 78%"],"technology_tags":["LLMs","jailbreaking","code-mixing","phonetic perturbations"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:29:36.917327Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_855282c7e5bf","title":"Communication-Efficient Diffusion Denoising Parallelization via Reuse","content":"arXiv:2505.14741v2 Announce Type: replace Abstract: Diffusion models have emerged as a powerful class of generative models across various modalities, including image, video, and audio synthesis. However, their deployment is often limited by significant inference latency, primarily due to the inherently sequential nature of the denoising process. While existing parallelization strategies attempt to accelerate inference by distributing computation across multiple devices, they typically incur high communication overhead, hindering deployment on commercial hardware. To address this challenge, we propose \\textbf{ParaStep}, a novel parallelization method based on a reuse-then-predict mechanism that parallelizes diffusion inference by exploiting similarity between adjacent denoising steps. Unlike prior approaches that rely on layer-wise or stage-wise communication, ParaStep employs lightweight, step-wise communication, substantially reducing overhead. ParaStep achieves end-to-end speedups of up to \\textbf{3.88}$\\times$ on SVD, \\textbf{2.43}$\\times$ on CogVideoX-2b, and \\textbf{6.56}$\\times$ on AudioLDM2-large, while maintaining generation quality. These results highlight ParaStep as a scalable and communication-efficient solution for accelerating diffusion inference, particularly in bandwidth-constrained environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.14741","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.177133","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Kunyun Wang, Bohan Li, Kai Yu, Minyi Guo, Jieru Zhao","raw_content_length":1334,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Reuse arXiv:2505.14741v2","Communication-Efficient Diffusion Denoising Parallelization"],"persons":[],"locations":[],"monetary":[]},"char_count":1333,"language_detected":"en","key_concepts":{"key_phrases":["Communication-Efficient Diffusion Denoising Parallelization","Reuse","arXiv250514741v2","Announce Type","Abstract","Diffusion models","a powerful class","generative models","various modalities","image"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Communication-Efficient Diffusion Denoising Parallelization":2.0,"Reuse":2.0,"arXiv250514741v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Diffusion models":1.0,"a powerful class":1.0,"generative models":1.0,"various modalities":1.0,"image":1.0}},"age_hours":2.766495806111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.921,"joy":0.0073,"surprise":0.0394,"sadness":0.0082,"fear":0.007,"anger":0.0106,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel parallelization method (ParaStep) to accelerate diffusion inference, which could potentially reduce the energy consumption of AI model training and deployment. The method achieves speedups of up to 6.56x on AudioLDM2-large. However, it is still in the applied research stage, with no evidence of real-world deployment or cost analysis.","key_impact_metrics":["speedups of up to 3.88x on SVD","speedups of up to 2.43x on CogVideoX-2b","speedups of up to 6.56x on AudioLDM2-large"],"technology_tags":["diffusion models","parallelization","machine learning"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:29:41.765049Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ea92be63dbb6","title":"LLMSynthor: Macro","content":"arXiv:2505.14752v2 Announce Type: replace Abstract: Macro-aligned micro-records are crucial for credible simulations in social science and urban studies. For example, epidemic models are only reliable when individual-level mobility and contacts mirror real behavior, while aggregates match real-world statistics like case counts or travel flows. However, collecting such fine-grained data at scale is impractical, leaving researchers with only macro-level data. LLMSynthor addresses this by turning a pretrained LLM into a macro-aware simulator that generates realistic micro-records consistent with target macro-statistics. It iteratively builds synthetic datasets: in each step, the LLM generates batches of records to minimize discrepancies between synthetic and target aggregates. Treating the LLM as a nonparametric copula allows the model to capture realistic joint dependencies among variables. To improve efficiency, LLM Proposal Sampling guides the LLM to propose targeted record batches, specifying variable ranges and counts, to efficiently correct discrepancies while preserving realism grounded in the model's priors. Evaluations across domains (mobility, e-commerce, population) show that LLMSynthor achieves strong realism, statistical fidelity, and practical utility, making it broadly applicable to economics, social science, and urban studies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.14752","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.177540","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Yihong Tang, Menglin Kong, Junlin He, Tong Nie, Lijun Sun","raw_content_length":1362,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":["LLMSynthor"],"monetary":[]},"char_count":1361,"language_detected":"en","key_concepts":{"key_phrases":["LLMSynthor","Macro","arXiv250514752v2 Announce Type","Abstract","Macro-aligned micro","records","credible simulations","social science","urban studies","example"],"filter_categories":{"ai_ml":["LLMSynthor"],"research_academic":["social science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMSynthor":3.0,"Macro":2.0,"arXiv250514752v2 Announce Type":1.0,"Abstract":1.0,"Macro-aligned micro":1.0,"records":1.0,"credible simulations":1.0,"social science":1.0,"urban studies":1.0,"example":1.0}},"age_hours":2.7665104741666666,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9377,"joy":0.0044,"surprise":0.0257,"sadness":0.0108,"fear":0.0066,"anger":0.0085,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"LLMSynthor is a novel approach to generating realistic micro-records for simulations, which could indirectly support sustainability efforts by improving the accuracy of models used to predict the impact of various interventions (e.g., urban planning, epidemic control). The article demonstrates statistical fidelity across domains, but it is still in the applied research stage with no deployments. The impact on climate is indirect and not quantified.","key_impact_metrics":["Discrepancies between synthetic and target aggregates","Realism of generated micro-records"],"technology_tags":["LLM","Simulation","Data Generation"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:29:45.952732Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c31a0bc128c8","title":"Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization","content":"arXiv:2505.15291v2 Announce Type: replace Abstract: Large Language Models (LLMs) have significantly advanced text generation capabilities, including tasks like summarization, often producing coherent and fluent outputs. However, faithfulness to source material remains a significant challenge due to the generation of hallucinations. While extensive research focuses on detecting and reducing these inaccuracies, less attention has been paid to the positional distribution of hallucination within generated text, particularly in long outputs. In this work, we investigate where hallucinations occur in LLM-based long response generation, using long document summarization as a key case study. Focusing on the challenging setting of long context-aware long response generation, we find a consistent and concerning phenomenon: hallucinations tend to concentrate disproportionately in the latter parts of the generated long response. To understand this bias, we explore potential contributing factors related to the dynamics of attention and decoding over long sequences. Furthermore, we investigate methods to mitigate this positional hallucination, aiming to improve faithfulness specifically in the concluding segments of long outputs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15291","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.178299","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Joonho Yang, Seunghyun Yoon, Hwan Chang, Byeongjeong Kim, Hwanhee Lee","raw_content_length":1236,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Hallucinate"],"locations":[],"monetary":[]},"char_count":1235,"language_detected":"en","key_concepts":{"key_phrases":["Hallucinate","Long Response Generation"," A Case Study","Long Document Summarization","Announce Type","Abstract","Large Language Models","LLMs","significantly advanced text generation capabilities","tasks"],"filter_categories":{"research_academic":[" A Case Study"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hallucinate":2.0,"Long Response Generation":2.0," A Case Study":2.0,"Long Document Summarization":2.0,"Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"significantly advanced text generation capabilities":1.0,"tasks":1.0}},"age_hours":2.766540521111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4425,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8885,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9027,"joy":0.005,"surprise":0.0207,"sadness":0.012,"fear":0.0453,"anger":0.0068,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the accuracy of long document summarization by addressing the issue of hallucinations in large language models. While improved summarization could indirectly contribute to sustainability by making information more accessible, there are no concrete actions or measurable outcomes related to climate impact or other sustainability dimensions at this stage. The research is in the early stages, focusing on identifying and mitigating the problem of hallucination.","key_impact_metrics":["Hallucination rate in concluding segments"],"technology_tags":["Large Language Models","Document Summarization","Attention Mechanisms"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:29:49.296096Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c39c11b576bc","title":"TemplateRL: Structured Template","content":"arXiv:2505.15692v3 Announce Type: replace Abstract: Reinforcement learning (RL) has emerged as an effective paradigm for enhancing model reasoning. However, existing RL methods like GRPO often rely on unstructured self-sampling to fit scalar rewards, often producing inefficient rollouts that fail to capture transferable problem-solving strategies. To address these limitations, we propose **TemplateRL**, a structured template-guided RL framework that augments policy optimization with explicit template guidance. Our approach first constructs a problem-solving template library via MCTS on a small seed set, then seamlessly integrates this high-level structured guidance into RL training. By guiding rollout generation to align with proven template structures, TemplateRL significantly improves high-quality trajectory hit rates while reducing ineffective exploration. This structure-guided design steers the policy toward validated strategic patterns, stabilizing training dynamics, and enhancing RL sampling efficiency. Notably, the explicit template library is interpretable, editable, and supports online updates-enabling continuous updates during both training and inference. Extensive experiments demonstrate that TemplateRL outperforms GRPO by 99% on AIME and 41% on AMC, with superior stability on weak models and remarkable cross-domain generalization, highlighting its potential for broader tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15692","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.179085","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Jinyang Wu, Chonghua Liao, Mingkuan Feng, Shuai Zhang, Zhengqi Wen, Haoran Luo, Ling Yang, Huazhe Xu, Jianhua Tao","raw_content_length":1411,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1410,"language_detected":"en","key_concepts":{"key_phrases":["TemplateRL Structured Template","arXiv250515692v3 Announce Type","Abstract","Reinforcement learning","an effective paradigm","model reasoning","existing RL methods","GRPO","unstructured self-sampling","scalar rewards"],"filter_categories":{"ai_ml":["Reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TemplateRL Structured Template":2.0,"arXiv250515692v3 Announce Type":1.0,"Abstract":1.0,"Reinforcement learning":1.0,"an effective paradigm":1.0,"model reasoning":1.0,"existing RL methods":1.0,"GRPO":1.0,"unstructured self-sampling":1.0,"scalar rewards":1.0}},"age_hours":2.766569285277778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9063,"joy":0.0043,"surprise":0.0229,"sadness":0.0214,"fear":0.0058,"anger":0.0223,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"TemplateRL improves reinforcement learning efficiency, potentially reducing the computational resources needed for model training. The article presents performance improvements of 99% on AIME and 41% on AMC compared to GRPO, but this is still in the research phase with no deployed applications or real-world energy savings demonstrated. The vaporware flag is set because it is an early-stage concept with no deployed units.","key_impact_metrics":["99% improvement on AIME","41% improvement on AMC"],"technology_tags":["Reinforcement Learning","Template-Guided RL","Policy Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:29:52.850838Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_57df2a009a2a","title":"InstructSAM: A Training","content":"arXiv:2505.15818v2 Announce Type: replace Abstract: Language-Guided object recognition in remote sensing imagery is crucial for large-scale mapping and automated data annotation. However, existing open-vocabulary and visual grounding methods rely on explicit category cues, limiting their ability to handle complex or implicit queries that require advanced reasoning. To address this issue, we introduce a new suite of tasks, including Instruction-Oriented Object Counting, Detection, and Segmentation (InstructCDS), covering open-vocabulary, open-ended, and open-subclass scenarios. We further present EarthInstruct, the first InstructCDS benchmark for earth observation. It is constructed from two diverse remote sensing datasets with varying spatial resolutions and annotation rules across 20 categories, necessitating models to interpret dataset-specific instructions. Given the scarcity of semantically rich labeled data in remote sensing, we propose InstructSAM, a training-free framework for instruction-driven object recognition. InstructSAM leverages large vision-language models to interpret user instructions and estimate object counts, employs SAM2 for mask proposal, and formulates mask-label assignment as a binary integer programming problem. By integrating semantic similarity with counting constraints, InstructSAM efficiently assigns categories to predicted masks without relying on confidence thresholds. Experiments demonstrate that InstructSAM matches or surpasses specialized baselines across multiple tasks while maintaining near-constant inference time regardless of object count, reducing output tokens by 89% and overall runtime by over 32% compared to direct generation approaches. We believe the contributions of the proposed tasks, benchmark, and effective approach will advance future research in developing versatile object recognition systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.15818","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.179509","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":234,"author":"Yijie Zheng, Weijie Wu, Qingyun Li, Xuehui Wang, Xu Zhou, Aiai Ren, Jun Shen, Long Zhao, Guoqing Li, Xue Yang","raw_content_length":1876,"priority":7,"update_frequency":1,"reading_time_minutes":1.17,"robust_parsing_used":true,"entities":{"organizations":["Instruction-Oriented Object Counting, Detection","Language-Guided"],"persons":["EarthInstruct"],"locations":[],"monetary":[]},"char_count":1875,"language_detected":"en","key_concepts":{"key_phrases":["InstructSAM A Training","arXiv250515818v2 Announce Type","Abstract","Language-Guided object recognition","remote sensing imagery","large-scale mapping","automated data annotation","existing open-vocabulary and visual grounding methods","explicit category cues","their ability"],"filter_categories":{"ai_ml":["InstructSAM A Training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"InstructSAM A Training":2.0,"arXiv250515818v2 Announce Type":1.0,"Abstract":1.0,"Language-Guided object recognition":1.0,"remote sensing imagery":1.0,"large-scale mapping":1.0,"automated data annotation":1.0,"existing open-vocabulary and visual grounding methods":1.0,"explicit category cues":1.0,"their ability":1.0}},"age_hours":2.766584027777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9173,"joy":0.0054,"surprise":0.0218,"sadness":0.0106,"fear":0.0269,"anger":0.0112,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a training-free framework (InstructSAM) that improves object recognition in remote sensing imagery, potentially enabling more efficient large-scale mapping and automated data annotation. The framework reduces output tokens by 89% and overall runtime by over 32% compared to direct generation approaches. While promising, it is still in the applied research stage with no mention of deployed units or real-world applications.","key_impact_metrics":["output tokens reduction by 89%","runtime reduction by over 32%"],"technology_tags":["object recognition","remote sensing","vision-language models","image segmentation"],"sdg_alignment":[9,11,13,15],"analyzed_at":"2025-10-29T12:29:56.409224Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7661fac276fe","title":"How Memory Management Impacts LLM Agents: An Empirical Study of Experience","content":"arXiv:2505.16067v2 Announce Type: replace Abstract: Memory is a critical component in large language model (LLM)-based agents, enabling them to store and retrieve past executions to improve task performance over time. In this paper, we conduct an empirical study on how memory management choices impact the LLM agents' behavior, especially their long-term performance. Specifically, we focus on two fundamental memory management operations that are widely used by many agent frameworks-memory addition and deletion-to systematically study their impact on the agent behavior. Through our quantitative analysis, we find that LLM agents display an experience-following property: high similarity between a task input and the input in a retrieved memory record often results in highly similar agent outputs. Our analysis further reveals two significant challenges associated with this property: error propagation, where inaccuracies in past experiences compound and degrade future performance, and misaligned experience replay, where some seemingly correct executions can provide limited or even misleading value as experiences. Through controlled experiments, we demonstrate the importance of regulating experience quality within the memory bank and show that future task evaluations can serve as free quality labels for stored memory. Our findings offer insights into the behavioral dynamics of LLM agent memory systems and provide practical guidance for designing memory components that support robust, long-term agent performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16067","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.179914","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Zirui Liu, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang","raw_content_length":1530,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1529,"language_detected":"en","key_concepts":{"key_phrases":["How Memory Management Impacts LLM Agents","An Empirical Study","Experience","arXiv250516067v2 Announce Type","Abstract","Memory","a critical component","large language model","LLM-based agents","them"],"filter_categories":{"ai_ml":["How Memory Management Impacts LLM Agents","large language model"],"research_academic":["An Empirical Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"How Memory Management Impacts LLM Agents":2.0,"An Empirical Study":2.0,"Experience":2.0,"arXiv250516067v2 Announce Type":1.0,"Abstract":1.0,"Memory":1.0,"a critical component":1.0,"large language model":1.0,"LLM-based agents":1.0,"them":1.0}},"age_hours":2.7665992413888887,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8126,"joy":0.0465,"surprise":0.0344,"sadness":0.0151,"fear":0.0521,"anger":0.0163,"disgust":0.0231},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an empirical study on memory management in LLM agents and its impact on long-term performance. While the research identifies challenges like error propagation and misaligned experience replay, it remains at a basic research stage with no concrete deployment or measurable outcomes related to sustainability. The study uses quantitative analysis to demonstrate the importance of regulating experience quality, but the impact on real-world climate or environmental issues is theoretical.","key_impact_metrics":["Similarity between task input and retrieved memory input","Similarity between agent outputs"],"technology_tags":["LLM","Memory Management","AI Agent"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:29:59.844907Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4149b5730ef2","title":"Explain Less, Understand More: Jargon Detection via Personalized Parameter","content":"arXiv:2505.16227v3 Announce Type: replace Abstract: Personalizing jargon detection and explanation is essential for making technical documents accessible to readers with diverse disciplinary backgrounds. However, tailoring models to individual users typically requires substantial annotation efforts and computational resources due to user-specific finetuning. To address this, we present a systematic study of personalized jargon detection, focusing on methods that are both efficient and scalable for real-world deployment. We explore two personalization strategies: (1) lightweight finetuning using Low-Rank Adaptation (LoRA) on open-source models, and (2) personalized prompting, which tailors model behavior at inference time without retaining. To reflect realistic constraints, we also investigate semi-supervised approaches that combine limited annotated data with self-supervised learning from users' publications. Our personalized LoRA model outperforms GPT-4 with contextual prompting by 21.4% in F1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably, our method achieves comparable performance using only 10% of the annotated training data, demonstrating its practicality for resource-constrained settings. Our study offers the first work to systematically explore efficient, low-resource personalization of jargon detection using open-source language models, offering a practical path toward scalable, user-adaptive NLP system.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16227","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.180311","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Bohao Wu, Qingyun Wang, Yue Guo","raw_content_length":1463,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["jargon","LoRA","Jargon Detection","Personalized Parameter"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1462,"language_detected":"en","key_concepts":{"key_phrases":["Jargon Detection","Personalized Parameter","Announce Type","Abstract","Personalizing jargon detection","explanation","technical documents","readers","diverse disciplinary backgrounds","tailoring models"],"filter_categories":{"ai_ml":["tailoring models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Jargon Detection":2.0,"Personalized Parameter":2.0,"Announce Type":1.0,"Abstract":1.0,"Personalizing jargon detection":1.0,"explanation":1.0,"technical documents":1.0,"readers":1.0,"diverse disciplinary backgrounds":1.0,"tailoring models":1.0}},"age_hours":2.7666143475,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9535,"joy":0.0076,"surprise":0.0104,"sadness":0.0048,"fear":0.007,"anger":0.0087,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method for personalized jargon detection, improving accessibility of technical documents. While it shows a 21.4% improvement in F1 score compared to GPT-4, the direct climate impact is indirect, relying on improved understanding of climate-related documents. It is still in the applied research phase, with no deployed units or customer contracts.","key_impact_metrics":["F1 score improvement 21.4%","Data reduction 90%"],"technology_tags":["Natural Language Processing","Machine Learning","Jargon Detection"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:30:03.243994Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1cb86db1efc0","title":"Attributing Response to Context: A Jensen","content":"arXiv:2505.16415v4 Announce Type: replace Abstract: Retrieval-Augmented Generation (RAG) leverages large language models (LLMs) combined with external contexts to enhance the accuracy and reliability of generated responses. However, reliably attributing generated content to specific context segments, context attribution, remains challenging due to the computationally intensive nature of current methods, which often require extensive fine-tuning or human annotation. In this work, we introduce a novel Jensen-Shannon Divergence driven method to Attribute Response to Context (ARC-JSD), enabling efficient and accurate identification of essential context sentences without additional fine-tuning, gradient-calculation or surrogate modelling. Evaluations on a wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using instruction-tuned LLMs in different scales demonstrate superior accuracy and significant computational efficiency improvements compared to the previous surrogate-based method. Furthermore, our mechanistic analysis reveals specific attention heads and multilayer perceptron (MLP) layers responsible for context attribution, providing valuable insights into the internal workings of RAG models and how they affect RAG behaviours. Our code is available at https://github.com/ruizheliUOA/ARC_JSD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16415","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.180725","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Ruizhe Li, Chen Chen, Yuchen Hu, Yanjun Gao, Xi Wang, Emine Yilmaz","raw_content_length":1331,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["TyDi QA","Attribute Response","ARC-JSD","Jensen-Shannon Divergence","Musique","Retrieval-Augmented Generation"],"persons":["Context","RAG"],"locations":[],"monetary":[]},"char_count":1330,"language_detected":"en","key_concepts":{"key_phrases":["Response","Context","A Jensen","Announce Type","RAG","large language models","LLMs","external contexts","the accuracy","reliability"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Response":2.0,"Context":2.0,"A Jensen":2.0,"Announce Type":1.0,"RAG":1.0,"large language models":1.0,"LLMs":1.0,"external contexts":1.0,"the accuracy":1.0,"reliability":1.0}},"age_hours":2.7666291230555555,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9335,"joy":0.0092,"surprise":0.0346,"sadness":0.005,"fear":0.0055,"anger":0.0076,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (ARC-JSD) for improving the efficiency and accuracy of context attribution in Retrieval-Augmented Generation (RAG) models. While it demonstrates superior accuracy and computational efficiency compared to previous methods on benchmarks, it remains in the applied research stage with no real-world deployment data. The impact on sustainability is indirect, potentially enabling more reliable and efficient use of LLMs in sustainability-related applications, but not directly reducing emissions or addressing climate change.","key_impact_metrics":["Superior accuracy compared to surrogate-based method","Significant computational efficiency improvements"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","Jensen-Shannon Divergence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:06.890941Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e576f105052","title":"SMART: Self-Generating and Self","content":"arXiv:2505.16646v4 Announce Type: replace Abstract: Large Language Models (LLMs) have achieved remarkable results on a variety of mathematical benchmarks. However, concerns remain as to whether these successes reflect genuine reasoning or superficial pattern recognition. Common evaluation methods, which focus on the either the final answer or the reasoning process, fail to assess the entire problem-solving procedure. To address these limitations, we introduce SMART: a Self-Generating and Self-Validating Multi-Dimensional Assessment Framework, together with its corresponding benchmark, SMART-Bench. SMART decomposes the entire problem solving process into four distinct cognitive dimensions: Understanding, Reasoning, Arithmetic, and Reflection \\& Refinement. Each dimension is evaluated independently through tailored tasks, enabling interpretable and fine-grained analysis of LLM behavior. We apply SMART to 21 state-of-the-art open- and closed-source LLMs, uncovering significant discrepancies in their abilities across different dimensions. Our findings reveal genuine weaknesses in current LLMs and motivate a new metric, the All-Pass Score, to better capture true problem-solving capabilities. Code and benchmarks will be released upon acceptance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16646","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.181112","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hua Huang","raw_content_length":1260,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["LLM","SMART","SMART-Bench","Reflection \\& Refinement"],"persons":[],"locations":[],"monetary":[]},"char_count":1259,"language_detected":"en","key_concepts":{"key_phrases":["SMART","Self-Generating","Self","Announce Type","Abstract","Large Language Models","LLMs","remarkable results","a variety","mathematical benchmarks"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SMART":3.0,"Self-Generating":2.0,"Self":2.0,"Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable results":1.0,"a variety":1.0,"mathematical benchmarks":1.0}},"age_hours":2.7666464122222223,"is_recent":true,"quality_score":1.0,"sentiment_score":9.451,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8902,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8244,"joy":0.0044,"surprise":0.0732,"sadness":0.0261,"fear":0.0353,"anger":0.0229,"disgust":0.0137},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a new framework (SMART) for evaluating LLMs, which could indirectly support sustainability efforts by improving the accuracy and reliability of AI models used in climate modeling or resource management. However, the framework itself is in the research stage and has no direct, measurable impact on GHG emissions or other sustainability metrics. The code and benchmarks are slated for release upon acceptance, indicating a lack of current deployment.","key_impact_metrics":[],"technology_tags":["Large Language Models","AI","Benchmarking"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:30:11.081365Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_966a8a2520cc","title":"Your Pre","content":"arXiv:2505.16690v2 Announce Type: replace Abstract: Post-training of large language models is essential for adapting pre-trained language models (PLMs) to align with human preferences and downstream tasks. While PLMs typically exhibit well-calibrated confidence, post-trained language models (PoLMs) often suffer from over-confidence, assigning high confidence to both correct and incorrect outputs, which can undermine reliability in critical applications. A major obstacle in calibrating PoLMs is the scarcity of labeled data for individual downstream tasks. To address this, we propose Disagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to optimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence calibration. Our method is motivated by the under-confidence issue caused by prediction disagreement between the PLM and PoLM while aligning their confidence via temperature scaling. Theoretically, the PLM's confidence underestimates PoLM's prediction accuracy on disagreement examples, causing a larger $\\tau$ and producing under-confident predictions. DACA mitigates this by selectively using only agreement examples for calibration, effectively decoupling the influence of disagreement. In this manner, our method avoids an overly large $\\tau$ in temperature scaling caused by disagreement examples, improving calibration performance. Extensive experiments demonstrate the effectiveness of our method, improving the average ECE of open-sourced and API-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16690","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.181523","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei","raw_content_length":1563,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["PLM","Disagreement-Aware Confidence Alignment","PoLM","PoLMs"],"persons":["PoLMs"],"locations":[],"monetary":[]},"char_count":1562,"language_detected":"en","key_concepts":{"key_phrases":["Your Pre","PLMs","PoLMs","arXiv250516690v2 Announce Type","Abstract","Post","training","large language models","pre-trained language models","human preferences"],"filter_categories":{"ai_ml":["training","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Your Pre":2.0,"PLMs":2.0,"PoLMs":2.0,"arXiv250516690v2 Announce Type":1.0,"Abstract":1.0,"Post":1.0,"training":1.0,"large language models":1.0,"pre-trained language models":1.0,"human preferences":1.0}},"age_hours":2.766661487222222,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5364999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4927,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8118,"joy":0.0041,"surprise":0.0146,"sadness":0.0465,"fear":0.0753,"anger":0.0206,"disgust":0.027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel unsupervised method (DACA) to improve the calibration of post-trained language models, potentially leading to more reliable AI systems. The method improves the average ECE of LLMs by up to 15.08% on benchmarks. However, it remains in the research stage with no deployed units or real-world data demonstrating a direct impact on GHG emissions or other sustainability metrics.","key_impact_metrics":["ECE improvement 15.08%"],"technology_tags":["Language Model Calibration","Unsupervised Learning","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:14.400633Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2d5f345f1e06","title":"MCP","content":"arXiv:2505.16700v2 Announce Type: replace Abstract: As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of interacting with external tools, the Model Context Protocol (MCP) has emerged as a key standardized framework for dynamic tool discovery and orchestration. Despite its widespread industry adoption, existing evaluation methods do not adequately assess tool utilization capabilities under this new paradigm. To address this gap, this paper introduces MCP-RADAR, the first comprehensive benchmark specifically designed to evaluate LLM performance within the MCP framework. MCP-RADAR features a challenging dataset of 507 tasks spanning six domains: mathematical reasoning, web search, email, calendar, file management, and terminal operations. It quantifies performance based on two primary criteria: answer correctness and operational accuracy. To closely emulate real-world usage, our evaluation employs both authentic MCP tools and high-fidelity simulations of official tools. Unlike traditional benchmarks that rely on subjective human evaluation or binary success metrics, MCP-RADAR adopts objective, quantifiable measurements across multiple task domains, including computational resource efficiency and the number of successful tool-invocation rounds. Our evaluation of leading closed-source and open-source LLMs reveals distinct capability profiles and highlights a significant trade-off between accuracy and efficiency. Our findings provide actionable insights for both LLM developers and tool creators, establishing a standardized methodology applicable to the broader LLM agent ecosystem. All implementations, configurations, and datasets are publicly available at https://anonymous.4open.science/r/MCPRadar-B143.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16700","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.181941","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Xuanqi Gao, Siyi Xie, Juan Zhai, Shiqing Ma, Chao Shen","raw_content_length":1780,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["LLM","MCP-RADAR","MCP"],"persons":[],"locations":[],"monetary":[]},"char_count":1779,"language_detected":"en","key_concepts":{"key_phrases":["MCP","arXiv250516700v2 Announce Type","Abstract","Large Language Models","LLMs","passive text generators","active reasoning agents","external tools","the Model Context Protocol","a key standardized framework"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MCP":3.0,"arXiv250516700v2 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"passive text generators":1.0,"active reasoning agents":1.0,"external tools":1.0,"the Model Context Protocol":1.0,"a key standardized framework":1.0}},"age_hours":2.7666760666666668,"is_recent":true,"quality_score":0.7,"sentiment_score":9.1355,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8271,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7715,"joy":0.0064,"surprise":0.0137,"sadness":0.0113,"fear":0.1229,"anger":0.0416,"disgust":0.0326},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (MCP-RADAR) for evaluating LLM performance in tool utilization. While it doesn't directly reduce GHG emissions, it aims to improve the efficiency of LLMs, which could indirectly contribute to sustainability by optimizing resource usage. The benchmark uses quantifiable measurements like computational resource efficiency and successful tool-invocation rounds.","key_impact_metrics":["computational resource efficiency","number of successful tool-invocation rounds"],"technology_tags":["Large Language Models","AI","Tool Orchestration"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:30:18.003608Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0e643b381e5e","title":"TRIM: Achieving Extreme Sparsity with Targeted Row","content":"arXiv:2505.16743v2 Announce Type: replace Abstract: Large Language Models (LLMs) present significant computational and memory challenges due to their extensive size, making pruning essential for their efficient deployment. Existing one-shot pruning methods often apply uniform sparsity constraints across layers or within each layer, resulting in suboptimal performance, especially at high sparsity ratios. This work introduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel approach that applies varying sparsity ratios to individual output dimensions (rows) within each layer. TRIM employs an iterative adjustment process guided by quality metrics to optimize dimension-wise sparsity allocation, focusing on reducing variance in quality retention across outputs to preserve critical information. TRIM can be seamlessly integrated with existing layer-wise pruning strategies. Our evaluations on perplexity and zero-shot tasks across diverse LLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that TRIM achieves new state-of-the-art results and enhances stability. For instance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and over 90% for OPT-13B compared to baseline methods. We conclude that fine-grained, dimension-wise sparsity adaptation is crucial for pushing the limits of extreme LLM compression. Code available at: https://github.com/flobk/TRIM","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16743","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.182333","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Florentin Beck, William Rudman, Carsten Eickhoff","raw_content_length":1416,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Iterative Metric-driven"],"persons":[],"locations":[],"monetary":[]},"char_count":1415,"language_detected":"en","key_concepts":{"key_phrases":["TRIM","Extreme Sparsity","Targeted Row","arXiv250516743v2 Announce Type","Large Language Models","LLMs","significant computational and memory challenges","their extensive size","their efficient deployment","Existing one-shot pruning methods"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TRIM":3.0,"Extreme Sparsity":2.0,"Targeted Row":2.0,"arXiv250516743v2 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"significant computational and memory challenges":1.0,"their extensive size":1.0,"their efficient deployment":1.0,"Existing one-shot pruning methods":1.0}},"age_hours":2.7666911525,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9002,"joy":0.017,"surprise":0.0551,"sadness":0.0054,"fear":0.0075,"anger":0.0114,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":8,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel pruning method (TRIM) for LLMs, achieving significant reductions in perplexity (48% for Qwen2.5-14B and over 90% for OPT-13B at 80% sparsity). This can lead to reduced energy consumption for training and inference of LLMs. However, it's still in the applied research phase, with no deployment data available.","key_impact_metrics":["Perplexity reduction 48%","Sparsity level 80%"],"technology_tags":["Large Language Models","Model Pruning","Sparsity"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:30:21.442251Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_24be852ce752","title":"DetailMaster: Can Your Text","content":"arXiv:2505.16915v2 Announce Type: replace Abstract: While recent text-to-image (T2I) models show impressive capabilities in synthesizing images from brief descriptions, their performance significantly degrades when confronted with long, detail-intensive prompts required in professional applications. We present DetailMaster, the first comprehensive benchmark specifically designed to evaluate T2I models' systematic abilities to handle extended textual inputs that contain complex compositional requirements. Our benchmark introduces four critical evaluation dimensions: Character Attributes, Structured Character Locations, Multi-Dimensional Scene Attributes, and Spatial/Interactive Relationships. The benchmark comprises long and detail-rich prompts averaging 284.89 tokens, with high quality validated by expert annotators. Evaluation on 7 general-purpose and 5 long-prompt-optimized T2I models reveals critical performance limitations: state-of-the-art models achieve merely $\\sim$50\\% accuracy in key dimensions like attribute binding and spatial reasoning, while all models showing progressive performance degradation as prompt length increases. Our analysis reveals fundamental limitations in compositional reasoning, demonstrating that current encoders flatten complex grammatical structures and that diffusion models suffer from attribute leakage under detail-intensive conditions. We open-source our dataset, data curation code, and evaluation tools to advance detail-rich T2I generation and enable applications previously hindered by the lack of a dedicated benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16915","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.182756","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Qirui Jiao, Daoyuan Chen, Yilun Huang, Xika Lin, Ying Shen, Yaliang Li","raw_content_length":1582,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Structured Character Locations","Multi-Dimensional Scene Attributes","Spatial/Interactive Relationships"],"persons":["Character Attributes","DetailMaster"],"locations":[],"monetary":[]},"char_count":1581,"language_detected":"en","key_concepts":{"key_phrases":["DetailMaster","Can Your Text","arXiv250516915v2","Announce Type","image","T2I","impressive capabilities","images","brief descriptions","their performance"],"filter_categories":{"ai_ml":["DetailMaster"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DetailMaster":3.0,"Can Your Text":2.0,"arXiv250516915v2":1.0,"Announce Type":1.0,"image":1.0,"T2I":1.0,"impressive capabilities":1.0,"images":1.0,"brief descriptions":1.0,"their performance":1.0}},"age_hours":2.7667058850000004,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8731,"joy":0.0064,"surprise":0.0642,"sadness":0.0075,"fear":0.0224,"anger":0.0192,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for text-to-image models, highlighting their limitations in handling detail-rich prompts. While it identifies areas for improvement in AI models, it's at a very early stage (benchmark creation) and doesn't directly translate to concrete climate action or measurable environmental outcomes. The research is credible due to the expert validation of the benchmark and the use of metrics to evaluate model performance.","key_impact_metrics":["Accuracy in key dimensions ~50%","Prompt length averaging 284.89 tokens"],"technology_tags":["Text-to-Image Models","AI","Benchmark"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:25.364411Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_db0fcb3de275","title":"FRIREN: Beyond Trajectories -","content":"arXiv:2505.17370v4 Announce Type: replace Abstract: Long-term time-series forecasting (LTSF) models are often presented as general-purpose solutions that can be applied across domains, implicitly assuming that all data is pointwise predictable. Using chaotic systems such as Lorenz-63 as a case study, we argue that geometric structure - not pointwise prediction - is the right abstraction for a dynamic-agnostic foundational model. Minimizing the Wasserstein-2 distance (W2), which captures geometric changes, and providing a spectral view of dynamics are essential for long-horizon forecasting. Our model, FRIREN (Flow-inspired Representations via Interpretable Eigen-networks), implements an augmented normalizing-flow block that embeds data into a normally distributed latent representation. It then generates a W2-efficient optimal path that can be decomposed into rotation, scaling, inverse rotation, and translation. This architecture yields locally generated, geometry-preserving predictions that are independent of the underlying dynamics, and a global spectral representation that functions as a finite Koopman operator with a small modification. This enables practitioners to identify which modes grow, decay, or oscillate, both locally and system-wide. FRIREN achieves an MSE of 11.4, MAE of 1.6, and SWD of 0.96 on Lorenz-63 in a 336-in, 336-out, dt=0.01 setting, surpassing TimeMixer (MSE 27.3, MAE 2.8, SWD 2.1). The model maintains effective prediction for 274 out of 336 steps, approximately 2.5 Lyapunov times. On Rossler (96-in, 336-out), FRIREN achieves an MSE of 0.0349, MAE of 0.0953, and SWD of 0.0170, outperforming TimeMixer's MSE of 4.3988, MAE of 0.886, and SWD of 3.2065. FRIREN is also competitive on standard LTSF datasets such as ETT and Weather. By connecting modern generative flows with classical spectral analysis, FRIREN makes long-term forecasting both accurate and interpretable, setting a new benchmark for LTSF model design.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.17370","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.183182","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":276,"author":"Qilin Wang","raw_content_length":1965,"priority":7,"update_frequency":1,"reading_time_minutes":1.38,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["FRIREN"],"locations":[],"monetary":[]},"char_count":1964,"language_detected":"en","key_concepts":{"key_phrases":["FRIREN","Trajectories","arXiv250517370v4 Announce Type","Abstract","Long-term time-series forecasting LTSF models","general-purpose solutions","domains","all data","chaotic systems","Lorenz-63"],"filter_categories":{"ai_ml":["domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FRIREN":2.0,"Trajectories":2.0,"arXiv250517370v4 Announce Type":1.0,"Abstract":1.0,"Long-term time-series forecasting LTSF models":1.0,"general-purpose solutions":1.0,"domains":1.0,"all data":1.0,"chaotic systems":1.0,"Lorenz-63":1.0}},"age_hours":2.76672134,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7831,"joy":0.028,"surprise":0.0844,"sadness":0.0069,"fear":0.0399,"anger":0.0491,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel time-series forecasting model (FRIREN) that improves accuracy in predicting chaotic systems. While the model itself doesn't directly impact climate change, improved forecasting could potentially contribute to better climate modeling and resource management in the future. The research is in the early stages, with no deployment or economic viability demonstrated.","key_impact_metrics":["MSE of 11.4 on Lorenz-63","MAE of 1.6 on Lorenz-63"],"technology_tags":["time-series forecasting","machine learning","normalizing flows"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:35.884226Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_18522546d5d6","title":"Evolving Machine Learning: A Survey","content":"arXiv:2505.17902v2 Announce Type: replace Abstract: In an era defined by rapid data evolution, traditional Machine Learning (ML) models often fall short in adapting to dynamic environments. Evolving Machine Learning (EML) has emerged as a critical paradigm, enabling continuous learning and adaptation in real-time data streams. This survey presents a comprehensive analysis of EML, focusing on five core challenges: data drift, concept drift, catastrophic forgetting, skewed learning, and network adaptation. We systematically review over 100 studies, categorizing state-of-the-art methods across supervised, unsupervised, and semi-supervised approaches. The survey explores diverse evaluation metrics, benchmark datasets, and real-world applications, offering a comparative lens on the effectiveness and limitations of current techniques. Additionally, we highlight the growing role of adaptive neural architectures, meta-learning, and ensemble strategies in addressing evolving data complexities. By synthesizing insights from recent literature, this work not only maps the current landscape of EML but also identifies critical gaps and opportunities for future research. Our findings aim to guide researchers and practitioners in developing robust, ethical, and scalable EML systems for real-world deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.17902","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.183583","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Ignacio Cabrera Martin, Subhaditya Mukherjee, Almas Baimagambetov, Joaquin Vanschoren, Nikolaos Polatidis","raw_content_length":1314,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Evolving Machine Learning","Machine Learning","EML"],"persons":[],"locations":[],"monetary":[]},"char_count":1313,"language_detected":"en","key_concepts":{"key_phrases":["Evolving Machine Learning","A Survey","EML","Announce Type","Abstract","an era","rapid data evolution","traditional Machine Learning ML models","dynamic environments","a critical paradigm"],"filter_categories":{"ai_ml":["Evolving Machine Learning","traditional Machine Learning ML models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Evolving Machine Learning":3.0,"A Survey":2.0,"EML":2.0,"Announce Type":1.0,"Abstract":1.0,"an era":1.0,"rapid data evolution":1.0,"traditional Machine Learning ML models":1.0,"dynamic environments":1.0,"a critical paradigm":1.0}},"age_hours":2.7667372891666666,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8568,"joy":0.007,"surprise":0.0455,"sadness":0.0184,"fear":0.0462,"anger":0.016,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article is a survey of Evolving Machine Learning (EML) techniques. While EML has the potential to improve the efficiency and adaptability of various systems, including those related to climate and sustainability, the article itself does not present any concrete deployments or measurable outcomes. It focuses on reviewing existing research and identifying future opportunities, placing it in the basic research stage.","key_impact_metrics":[],"technology_tags":["Machine Learning","Data Analysis","Adaptive Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:39.055604Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90e68dbbcb67","title":"VORTA: Efficient Video Diffusion via Routing Sparse Attention","content":"arXiv:2505.18809v2 Announce Type: replace Abstract: Video diffusion transformers have achieved remarkable progress in high-quality video generation, but remain computationally expensive due to the quadratic complexity of attention over high-dimensional video sequences. Recent acceleration methods enhance the efficiency by exploiting the local sparsity of attention scores; yet they often struggle with accelerating the long-range computation. To address this problem, we propose VORTA, an acceleration framework with two novel components: 1) a sparse attention mechanism that efficiently captures long-range dependencies, and 2) a routing strategy that adaptively replaces full 3D attention with specialized sparse attention variants. VORTA achieves an end-to-end speedup $1.76\\times$ without loss of quality on VBench. Furthermore, it can seamlessly integrate with various other acceleration methods, such as model caching and step distillation, reaching up to speedup $14.41\\times$ with negligible performance degradation. VORTA demonstrates its efficiency and enhances the practicality of video diffusion transformers in real-world settings. Codes and weights are available at https://github.com/wenhao728/VORTA.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18809","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.183976","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Wenhao Sun, Rong-Cheng Tu, Yifu Ding, Zhao Jin, Jingyi Liao, Shunyu Liu, Dacheng Tao","raw_content_length":1218,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["Efficient Video Diffusion","VBench"],"persons":[],"locations":[],"monetary":[]},"char_count":1217,"language_detected":"en","key_concepts":{"key_phrases":["VORTA","Efficient Video Diffusion","Routing Sparse Attention","arXiv250518809v2 Announce Type","Abstract","Video diffusion transformers","remarkable progress","high-quality video generation","the quadratic complexity","attention"],"filter_categories":{"ai_ml":["Video diffusion transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VORTA":3.0,"Efficient Video Diffusion":2.0,"Routing Sparse Attention":2.0,"arXiv250518809v2 Announce Type":1.0,"Abstract":1.0,"Video diffusion transformers":1.0,"remarkable progress":1.0,"high-quality video generation":1.0,"the quadratic complexity":1.0,"attention":1.0}},"age_hours":2.766752042222222,"is_recent":true,"quality_score":1.0,"sentiment_score":5.703,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1406,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7966,"joy":0.013,"surprise":0.0721,"sadness":0.0545,"fear":0.0112,"anger":0.0309,"disgust":0.0217},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel algorithm (VORTA) to improve the efficiency of video diffusion transformers, achieving a 1.76x speedup on VBench and up to 14.41x with other methods. While this could reduce energy consumption in AI training and deployment, it's still in the research phase with no deployed units or real-world impact data. The vaporware flag is raised due to the lack of deployment data.","key_impact_metrics":["speedup 1.76x","speedup 14.41x"],"technology_tags":["video diffusion","sparse attention","AI efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:30:42.439371Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_acf7adc6d12a","title":"CrosGrpsABS: Cross-Attention over Syntactic and Semantic Graphs for Aspect","content":"arXiv:2505.19018v2 Announce Type: replace Abstract: Aspect-Based Sentiment Analysis (ABSA) is a fundamental task in natural language processing, offering fine-grained insights into opinions expressed in text. While existing research has largely focused on resource-rich languages like English which leveraging large annotated datasets, pre-trained models, and language-specific tools. These resources are often unavailable for low-resource languages such as Bengali. The ABSA task in Bengali remains poorly explored and is further complicated by its unique linguistic characteristics and a lack of annotated data, pre-trained models, and optimized hyperparameters. To address these challenges, this research propose CrosGrpsABS, a novel hybrid framework that leverages bidirectional cross-attention between syntactic and semantic graphs to enhance aspect-level sentiment classification. The CrosGrpsABS combines transformerbased contextual embeddings with graph convolutional networks, built upon rule-based syntactic dependency parsing and semantic similarity computations. By employing bidirectional crossattention, the model effectively fuses local syntactic structure with global semantic context, resulting in improved sentiment classification performance across both low- and high-resource settings. We evaluate CrosGrpsABS on four low-resource Bengali ABSA datasets and the high-resource English SemEval 2014 Task 4 dataset. The CrosGrpsABS consistently outperforms existing approaches, achieving notable improvements, including a 0.93% F1-score increase for the Restaurant domain and a 1.06% gain for the Laptop domain in the SemEval 2014 Task 4 benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19018","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.184371","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, Md. Rajib Hossain","raw_content_length":1665,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["ABSA","Cross-Attention"],"persons":[],"locations":[],"monetary":[]},"char_count":1664,"language_detected":"en","key_concepts":{"key_phrases":["CrosGrpsABS","Cross","Syntactic and Semantic Graphs","Aspect","Bengali","arXiv250519018v2 Announce Type","Abstract","Aspect-Based Sentiment Analysis","ABSA","a fundamental task"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CrosGrpsABS":2.0,"Cross":2.0,"Syntactic and Semantic Graphs":2.0,"Aspect":2.0,"Bengali":2.0,"arXiv250519018v2 Announce Type":1.0,"Abstract":1.0,"Aspect-Based Sentiment Analysis":1.0,"ABSA":1.0,"a fundamental task":1.0}},"age_hours":2.766767259166667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8839,"joy":0.0073,"surprise":0.0501,"sadness":0.028,"fear":0.0116,"anger":0.0107,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research paper presents a novel approach to aspect-based sentiment analysis, showing improved F1-scores on benchmark datasets. While the research is promising and shows concrete improvements in performance metrics, it is still in the applied research phase and lacks deployment or clear pathways to economic viability or climate impact. The improvement in sentiment analysis could potentially be used to analyze public opinion on climate change or other sustainability issues, but this is not directly addressed in the paper.","key_impact_metrics":["0.93% F1-score increase for Restaurant domain","1.06% gain for Laptop domain"],"technology_tags":["natural language processing","aspect-based sentiment analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:30:46.438370Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fbbedce94ae1","title":"Shifting AI Efficiency From Model","content":"arXiv:2505.19147v3 Announce Type: replace Abstract: The advancement of large language models (LLMs) and multi-modal LLMs (MLLMs) has historically relied on scaling model parameters. However, as hardware limits constrain further model growth, the primary computational bottleneck has shifted to the quadratic cost of self-attention over increasingly long sequences by ultra-long text contexts, high-resolution images, and extended videos. In this position paper, \\textbf{we argue that the focus of research for efficient artificial intelligence (AI) is shifting from model-centric compression to data-centric compression}. We position data-centric compression as the emerging paradigm, which improves AI efficiency by directly compressing the volume of data processed during model training or inference. To formalize this shift, we establish a unified framework for existing efficiency strategies and demonstrate why it constitutes a crucial paradigm change for long-context AI. We then systematically review the landscape of data-centric compression methods, analyzing their benefits across diverse scenarios. Finally, we outline key challenges and promising future research directions. Our work aims to provide a novel perspective on AI efficiency, synthesize existing efforts, and catalyze innovation to address the challenges posed by ever-increasing context lengths.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19147","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.184782","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Xuyang Liu, Zichen Wen, Shaobo Wang, Junjie Chen, Zhishan Tao, Yubo Wang, Tailai Chen, Xiangqi Jin, Chang Zou, Yiyu Wang, Chenfei Liao, Xu Zheng, Honggang Chen, Weijia Li, Xuming Hu, Conghui He, Linfeng Zhang","raw_content_length":1371,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1370,"language_detected":"en","key_concepts":{"key_phrases":["AI Efficiency","Model","arXiv250519147v3","Announce Type","Abstract","The advancement","large language models","LLMs","multi-modal LLMs","MLLMs"],"filter_categories":{"ai_ml":["AI Efficiency","Model","large language models"],"business_innovation":["Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AI Efficiency":2.0,"Model":2.0,"arXiv250519147v3":1.0,"Announce Type":1.0,"Abstract":1.0,"The advancement":1.0,"large language models":1.0,"LLMs":1.0,"multi-modal LLMs":1.0,"MLLMs":1.0}},"age_hours":2.7667836305555555,"is_recent":true,"quality_score":0.7,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8365,"joy":0.0213,"surprise":0.0942,"sadness":0.0168,"fear":0.0086,"anger":0.0161,"disgust":0.0066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a shift to data-centric compression for AI efficiency, which could potentially reduce computational energy consumption. However, it's a position paper outlining a research direction, not a deployed technology with measurable outcomes. The claims are supported by a unified framework and review of existing methods, but lack concrete deployment data.","key_impact_metrics":[],"technology_tags":["data compression","artificial intelligence","large language models"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T12:30:50.085528Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c78119332232","title":"LLaDA 1.5: Variance","content":"arXiv:2505.19223v2 Announce Type: replace Abstract: While Masked Diffusion Models (MDMs), such as LLaDA, present a promising paradigm for language modeling, there has been relatively little effort in aligning these models with human preferences via reinforcement learning. The challenge primarily arises from the high variance in Evidence Lower Bound (ELBO)-based likelihood estimates required for preference optimization. To address this issue, we propose Variance-Reduced Preference Optimization (VRPO), a framework that formally analyzes the variance of ELBO estimators and derives bounds on both the bias and variance of preference optimization gradients. Building on this theoretical foundation, we introduce unbiased variance reduction strategies, including optimal Monte Carlo budget allocation and antithetic sampling, that significantly improve the performance of MDM alignment. We demonstrate the effectiveness of VRPO by applying it to LLaDA, and the resulting model, LLaDA 1.5, outperforms its SFT-only predecessor consistently and significantly across mathematical (GSM8K +4.7), code (HumanEval +3.0, MBPP +1.8), and alignment benchmarks (IFEval +4.0, Arena-Hard +4.3). Furthermore, LLaDA 1.5 demonstrates a highly competitive mathematical performance compared to strong language MDMs and ARMs. Project page: https://ml-gsai.github.io/LLaDA-1.5-Demo/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19223","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.185165","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Fengqi Zhu, Rongzhen Wang, Shen Nie, Xiaolu Zhang, Chunwei Wu, Jun Hu, Jun Zhou, Jianfei Chen, Yankai Lin, Ji-Rong Wen, Chongxuan Li","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["VRPO","Variance-Reduced Preference Optimization","Variance arXiv:2505.19223v2 Announce Type","MDM"],"persons":[],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["LLaDA","Variance","arXiv250519223v2","Announce Type","Abstract","Masked Diffusion Models","a promising paradigm","language modeling","relatively little effort","these models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLaDA":3.0,"Variance":2.0,"arXiv250519223v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Masked Diffusion Models":1.0,"a promising paradigm":1.0,"language modeling":1.0,"relatively little effort":1.0,"these models":1.0}},"age_hours":2.766797835,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8933,"joy":0.0157,"surprise":0.0416,"sadness":0.0103,"fear":0.0191,"anger":0.0151,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents research on improving the efficiency of language models, specifically LLaDA, using a variance-reduced preference optimization framework. While improved AI efficiency could indirectly reduce energy consumption, the article does not provide concrete actions or measurable outcomes related to environmental sustainability. The research is in the applied research stage, with demonstrations on benchmarks but no real-world deployment data.","key_impact_metrics":["GSM8K +4.7","HumanEval +3.0"],"technology_tags":["Masked Diffusion Models","Reinforcement Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:30:53.514858Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f27be6de26e","title":"SpikeStereoNet: A Brain","content":"arXiv:2505.19487v2 Announce Type: replace Abstract: Conventional frame-based cameras often struggle with stereo depth estimation in rapidly changing scenes. In contrast, bio-inspired spike cameras emit asynchronous events at microsecond-level resolution, providing an alternative sensing modality. However, existing methods lack specialized stereo algorithms and benchmarks tailored to the spike data. To address this gap, we propose SpikeStereoNet, a brain-inspired framework and the first to estimate stereo depth directly from raw spike streams. The model fuses raw spike streams from two viewpoints and iteratively refines depth estimation through a recurrent spiking neural network (RSNN) update module. To benchmark our approach, we introduce a large-scale synthetic spike stream dataset and a real-world stereo spike dataset with dense depth annotations. SpikeStereoNet outperforms existing methods on both datasets by leveraging spike streams' ability to capture subtle edges and intensity shifts in challenging regions such as textureless surfaces and extreme lighting conditions. Furthermore, our framework exhibits strong data efficiency, maintaining high accuracy even with substantially reduced training data. The source code and datasets will be publicly available.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19487","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.185569","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Zhuoheng Gao, Yihao Li, Jiyao Zhang, Rui Zhao, Tong Wu, Hao Tang, Zhaofei Yu, Hao Dong, Guozhang Chen, Tiejun Huang","raw_content_length":1280,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1279,"language_detected":"en","key_concepts":{"key_phrases":["SpikeStereoNet","A Brain","arXiv250519487v2 Announce Type","Abstract","Conventional frame-based cameras","stereo depth estimation","rapidly changing scenes","contrast","bio-inspired spike cameras","asynchronous events"],"filter_categories":{"ai_ml":["A Brain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SpikeStereoNet":3.0,"A Brain":2.0,"arXiv250519487v2 Announce Type":1.0,"Abstract":1.0,"Conventional frame-based cameras":1.0,"stereo depth estimation":1.0,"rapidly changing scenes":1.0,"contrast":1.0,"bio-inspired spike cameras":1.0,"asynchronous events":1.0}},"age_hours":2.766812405555555,"is_recent":true,"quality_score":0.7,"sentiment_score":2.213,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5574,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.894,"joy":0.0069,"surprise":0.0566,"sadness":0.0112,"fear":0.009,"anger":0.0115,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel brain-inspired framework for stereo depth estimation using spike cameras. While the framework outperforms existing methods on synthetic and real-world datasets, it is still in the early stages of development with no deployed units or customer contracts. The impact on climate is indirect, potentially enabling more efficient sensing in various applications, but not directly reducing emissions.","key_impact_metrics":["High accuracy with reduced training data","Outperforms existing methods on datasets"],"technology_tags":["Spike cameras","Spiking neural networks","Stereo depth estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:30:56.731325Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_45565c292b1b","title":"Rolling Ball Optimizer: Learning by ironing out loss landscape wrinkles","content":"arXiv:2505.19527v2 Announce Type: replace Abstract: Training large neural networks (NNs) requires optimizing high-dimensional data-dependent loss functions. The optimization landscape of these functions is often highly complex and textured, even fractal-like, with many spurious local minima, ill-conditioned valleys, degenerate points, and saddle points. Complicating things further is the fact that these landscape characteristics are a function of the data, meaning that noise in the training data can propagate forward and give rise to unrepresentative small-scale geometry. This poses a difficulty for gradient-based optimization methods, which rely on local geometry to compute updates and are, therefore, vulnerable to being derailed by noisy data. In practice,this translates to a strong dependence of the optimization dynamics on the noise in the data, i.e., poor generalization performance. To remediate this problem, we propose a new optimization procedure: Rolling Ball Optimizer (RBO), that breaks this spatial locality by incorporating information from a larger region of the loss landscape in its updates. We achieve this by simulating the motion of a rigid sphere of finite radius rolling on the loss landscape, a straightforward generalization of Gradient Descent (GD) that simplifies into it in the infinitesimal limit. The radius serves as a hyperparameter that determines the scale at which RBO sees the loss landscape, allowing control over the granularity of its interaction therewith. We are motivated by the intuition that the large-scale geometry of the loss landscape is less data-specific than its fine-grained structure, and that it is easier to optimize. We support this intuition by proving that our algorithm has a smoothing effect on the loss function. Evaluation against SGD, SAM, and Entropy-SGD, on MNIST and CIFAR-10/100 demonstrates promising results in terms of convergence speed, training accuracy, and generalization performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19527","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.186113","language":"en","tags":["computer-science","cslg","csai","preprints","mathoc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":283,"author":"Mohammed D. Belgoumri, Mohamed Reda Bouadjenek, Hakim Hacid, Imran Razzak, Sunil Aryal","raw_content_length":1970,"priority":7,"update_frequency":1,"reading_time_minutes":1.415,"robust_parsing_used":true,"entities":{"organizations":["noisy data"],"persons":["Ball Optimizer:","Announce Type"],"locations":[],"monetary":[]},"char_count":1969,"language_detected":"en","key_concepts":{"key_phrases":["Rolling Ball Optimizer","loss landscape wrinkles","arXiv250519527v2 Announce Type","Abstract","large neural networks","NNs","high-dimensional data-dependent loss functions","The optimization landscape","these functions","many spurious local minima ill-conditioned valleys"],"filter_categories":{"ai_ml":["large neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Rolling Ball Optimizer":2.0,"loss landscape wrinkles":2.0,"arXiv250519527v2 Announce Type":1.0,"Abstract":1.0,"large neural networks":1.0,"NNs":1.0,"high-dimensional data-dependent loss functions":1.0,"The optimization landscape":1.0,"these functions":1.0,"many spurious local minima ill-conditioned valleys":1.0}},"age_hours":2.766828233611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8687,"joy":0.0033,"surprise":0.0122,"sadness":0.0115,"fear":0.0254,"anger":0.0416,"disgust":0.0373},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new optimization algorithm (RBO) that could potentially improve the training of large neural networks, leading to better generalization performance. While the algorithm shows promising results on MNIST and CIFAR datasets, it is still in the early stages of research and lacks real-world deployment. The impact on climate change is indirect, as it could improve the efficiency of AI models used in climate-related applications, but this is theoretical at this stage.","key_impact_metrics":["Convergence speed on MNIST and CIFAR-10/100","Training accuracy on MNIST and CIFAR-10/100"],"technology_tags":["Optimization algorithm","Neural networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:31:00.005901Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_983fff487833","title":"STRAP: Spatio-Temporal Pattern Retrieval for Out","content":"arXiv:2505.19547v3 Announce Type: replace Abstract: Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerful tool for modeling dynamic graph-structured data across diverse domains. However, they often fail to generalize in Spatio-Temporal Out-of-Distribution (STOOD) scenarios, where both temporal dynamics and spatial structures evolve beyond the training distribution. To address this problem, we propose an innovative Spatio-Temporal Retrieval-Augmented Pattern Learning framework,STRAP, which enhances model generalization by integrating retrieval-augmented learning into the STGNN continue learning pipeline. The core of STRAP is a compact and expressive pattern library that stores representative spatio-temporal patterns enriched with historical, structural, and semantic information, which is obtained and optimized during the training phase. During inference, STRAP retrieves relevant patterns from this library based on similarity to the current input and injects them into the model via a plug-and-play prompting mechanism. This not only strengthens spatio-temporal representations but also mitigates catastrophic forgetting. Moreover, STRAP introduces a knowledge-balancing objective to harmonize new information with retrieved knowledge. Extensive experiments across multiple real-world streaming graph datasets show that STRAP consistently outperforms state-of-the-art STGNN baselines on STOOD tasks, demonstrating its robustness, adaptability, and strong generalization capability without task-specific fine-tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19547","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.186535","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Haoyu Zhang, Wentao Zhang, Hao Miao, Xinke Jiang, Yuchen Fang, Yifan Zhang","raw_content_length":1548,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Spatio-Temporal Out-of-Distribution","simi","Spatio-Temporal Pattern Retrieval for Out arXiv:2505.19547v3 Announce Type:","Spatio-Temporal Retrieval-Augmented Pattern Learning"],"persons":["STGNN"],"locations":[],"monetary":[]},"char_count":1547,"language_detected":"en","key_concepts":{"key_phrases":["STRAP","Spatio-Temporal Pattern Retrieval","arXiv250519547v3 Announce Type","Abstract","Spatio-Temporal Graph Neural Networks","STGNNs","a powerful tool","modeling dynamic graph-structured data","diverse domains","Distribution"],"filter_categories":{"ai_ml":["Spatio-Temporal Graph Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"STRAP":2.0,"Spatio-Temporal Pattern Retrieval":2.0,"arXiv250519547v3 Announce Type":1.0,"Abstract":1.0,"Spatio-Temporal Graph Neural Networks":1.0,"STGNNs":1.0,"a powerful tool":1.0,"modeling dynamic graph-structured data":1.0,"diverse domains":1.0,"Distribution":1.0}},"age_hours":2.7668435474999997,"is_recent":true,"quality_score":1.0,"sentiment_score":7.083,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4166,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9052,"joy":0.0045,"surprise":0.0419,"sadness":0.0159,"fear":0.0111,"anger":0.014,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (STRAP) for improving the generalization of Spatio-Temporal Graph Neural Networks (STGNNs) in out-of-distribution scenarios. While the research shows promise in enhancing model robustness and adaptability, it is currently at the applied research stage with no mention of real-world deployments or quantified environmental benefits. The claim of outperforming state-of-the-art baselines is supported by 'extensive experiments' but lacks specific details on the datasets used and the magnitude of improvement.","key_impact_metrics":["Outperforms state-of-the-art STGNN baselines"],"technology_tags":["Spatio-Temporal Graph Neural Networks","Retrieval-Augmented Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:31:03.539442Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_26f608d43405","title":"TCP: a Benchmark for Temporal Constraint","content":"arXiv:2505.19927v2 Announce Type: replace Abstract: Temporal reasoning and planning are essential capabilities for large language models (LLMs), yet most existing benchmarks evaluate them in isolation and under limited forms of complexity. To address this gap, we introduce the Temporal Constraint-based Planning (TCP) benchmark that jointly assesses both capabilities. Each instance in TCP features a naturalistic dialogue around a collaborative project, where diverse and interdependent temporal constraints are explicitly or implicitly expressed, and models must infer an optimal schedule that satisfies all constraints. To construct TCP, we generate abstract problem prototypes that are then paired with realistic scenarios from various domains and enriched into dialogues using an LLM. A human quality check is performed on a sampled subset to confirm the reliability of our benchmark. We evaluate state-of-the-art LLMs and find that even the strongest models may struggle with TCP, highlighting its difficulty and revealing limitations in LLMs' temporal constraint-based planning abilities. We analyze underlying failure cases, open source our benchmark, and hope our findings can inspire future research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19927","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.186925","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Zifeng Ding, Sikuan Yan, Zhangdie Yuan, Xianglong Hu, Fangru Lin, Andreas Vlachos","raw_content_length":1212,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["LLM","Planning (TCP","Temporal Constraint","TCP"],"persons":[],"locations":[],"monetary":[]},"char_count":1211,"language_detected":"en","key_concepts":{"key_phrases":["TCP","a Benchmark","Temporal Constraint","arXiv250519927v2 Announce Type","Abstract","Temporal reasoning","planning","essential capabilities","large language models","LLMs"],"filter_categories":{"ai_ml":["Temporal Constraint","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TCP":4.0,"a Benchmark":2.0,"Temporal Constraint":2.0,"arXiv250519927v2 Announce Type":1.0,"Abstract":1.0,"Temporal reasoning":1.0,"planning":1.0,"essential capabilities":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7668584619444445,"is_recent":true,"quality_score":1.0,"sentiment_score":2.213,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5574,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9106,"joy":0.005,"surprise":0.0151,"sadness":0.0045,"fear":0.0259,"anger":0.0213,"disgust":0.0175},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for temporal reasoning in LLMs. While improved LLMs could indirectly support sustainability efforts (e.g., optimizing supply chains), there are no concrete actions or measurable outcomes related to climate impact at this stage. It's currently in the basic research phase with no deployed technology.","key_impact_metrics":[],"technology_tags":["Large Language Models","Temporal Reasoning","AI Planning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:31:06.916808Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_abd64d307915","title":"MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain","content":"arXiv:2505.20096v2 Announce Type: replace Abstract: We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, each responsible for a distinct stage of the RAG pipeline. By decomposing tasks into subtasks such as query disambiguation, evidence extraction, and answer synthesis, and enabling agents to communicate intermediate reasoning via chain-of-thought prompting, MA-RAG progressively refines retrieval and synthesis while maintaining modular interpretability. Extensive experiments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms standalone LLMs and existing RAG methods across all model scales. Notably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger standalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new state-of-the-art results on challenging multi-hop datasets. Ablation studies reveal that both the planner and extractor agents are critical for multi-hop reasoning, and that high-capacity models are especially important for the QA agent to synthesize answers effectively. Beyond general-domain QA, MA-RAG generalizes to specialized domains such as medical QA, achieving competitive performance against domain-specific models without any domain-specific fine-tuning. Our results highlight the effectiveness of collaborative, modular reasoning in retrieval-augmented systems: MA-RAG not only improves answer accuracy and robustness but also provides interpretable intermediate reasoning steps, establishing a new paradigm for efficient and reliable multi-agent RAG.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20096","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.187342","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Thang Nguyen, Peter Chin, Yu-Wing Tai","raw_content_length":1956,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["Collaborative Chain arXiv:2505.20096v2","QA Agents","MA-RAG","TriviaQA","Retrieval-Augmented Generation (RAG"],"persons":["RAG","Extractor","MA-RAG"],"locations":["Multi"],"monetary":[]},"char_count":1955,"language_detected":"en","key_concepts":{"key_phrases":["MA-RAG Multi-Agent Retrieval-Augmented Generation","Collaborative Chain","MA-RAG","Announce Type","Abstract","a Multi-Agent framework","Retrieval-Augmented Generation","RAG","the inherent ambiguities","reasoning challenges"],"filter_categories":{"ai_ml":["Collaborative Chain"],"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MA-RAG Multi-Agent Retrieval-Augmented Generation":2.0,"Collaborative Chain":2.0,"MA-RAG":2.0,"Announce Type":1.0,"Abstract":1.0,"a Multi-Agent framework":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0,"the inherent ambiguities":1.0,"reasoning challenges":1.0}},"age_hours":2.7668749866666666,"is_recent":true,"quality_score":1.0,"sentiment_score":3.75,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.25,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8881,"joy":0.0452,"surprise":0.0401,"sadness":0.0043,"fear":0.0069,"anger":0.0123,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (MA-RAG) that improves the accuracy and interpretability of information retrieval and question answering. While the technology itself doesn't directly reduce GHG emissions, it could potentially improve the efficiency of research and development in climate-related fields. The vaporware flag is raised because it's currently in the applied research stage with no real-world deployments yet.","key_impact_metrics":["significantly outperforms standalone LLMs and existing RAG methods across all model scales","competitive performance against domain-specific models without any domain-specific fine-tuning"],"technology_tags":["Multi-Agent Systems","Retrieval-Augmented Generation","Large Language Models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:31:12.641271Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d9c3a8c79307","title":"ARM: Adaptive Reasoning Model","content":"arXiv:2505.20258v2 Announce Type: replace Abstract: While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on task difficulty. This often leads to the \"overthinking\" problem -- excessive and unnecessary reasoning -- which, although potentially mitigated by human intervention to control the token budget, still fundamentally contradicts the goal of achieving fully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a reasoning model capable of adaptively selecting appropriate reasoning formats based on the task at hand. These formats include three efficient ones -- Direct Answer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To train ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy Optimization (GRPO), which addresses the format collapse issue in traditional GRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by an average of 30%, and up to 70%, while maintaining performance comparable to the model that relies solely on Long CoT. Furthermore, not only does it improve inference efficiency through reduced token generation, but it also brings a 2x speedup in training. In addition to the default Adaptive Mode, ARM supports two additional reasoning modes: 1) Instruction-Guided Mode, which allows users to explicitly specify the reasoning format via special tokens -- ideal when the appropriate format is known for a batch of tasks. 2) Consensus-Guided Mode, which aggregates the outputs of the three efficient formats and resorts to Long CoT in case of disagreement, prioritizing performance with higher token usage.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20258","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.187773","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Siye Wu, Jian Xie, Yikai Zhang, Aili Chen, Kai Zhang, Yu Su, Yanghua Xiao","raw_content_length":1698,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["Direct Answer","Group Relative Policy Optimization","Ada-GRPO","GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1697,"language_detected":"en","key_concepts":{"key_phrases":["ARM","Adaptive Reasoning Model","Announce Type","Abstract","large reasoning models","strong performance","complex tasks","the ability","token usage","task difficulty"],"filter_categories":{"healthcare_tech":["ARM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ARM":2.0,"Adaptive Reasoning Model":2.0,"Announce Type":1.0,"Abstract":1.0,"large reasoning models":1.0,"strong performance":1.0,"complex tasks":1.0,"the ability":1.0,"token usage":1.0,"task difficulty":1.0}},"age_hours":2.766890076666667,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5305,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4939,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5929,"joy":0.0059,"surprise":0.0524,"sadness":0.0442,"fear":0.0575,"anger":0.1879,"disgust":0.0593},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new AI model (ARM) that reduces token usage in reasoning tasks, leading to a 30-70% reduction in tokens and a 2x speedup in training. This improved efficiency could reduce the energy consumption associated with training and running large language models. However, it's still in the applied research stage and lacks deployment data to confirm real-world energy savings.","key_impact_metrics":["Tokens reduced by 30-70%","2x speedup in training"],"technology_tags":["Artificial Intelligence","Large Language Models","Energy Efficiency"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:31:17.961438Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13a41e8d287c","title":"Empirical Investigation of Latent Representational Dynamics in Large Language Models: A Manifold Evolution Perspective","content":"arXiv:2505.20340v2 Announce Type: replace Abstract: This paper introduces the Dynamical Manifold Evolution Theory (DMET), a conceptual framework that models large language model (LLM) generation as a continuous trajectory evolving on a low-dimensional semantic manifold. The theory characterizes latent dynamics through three interpretable metrics-state continuity ($C$), attractor compactness ($Q$), and topological persistence ($P$)-which jointly capture the smoothness, stability, and structure of representation evolution. Empirical analyses across multiple Transformer architectures reveal consistent links between these latent dynamics and text quality: smoother trajectories correspond to greater fluency, and richer topological organization correlates with enhanced coherence. Different models exhibit distinct dynamical regimes, reflecting diverse strategies of semantic organization in latent space. Moreover, decoding parameters such as temperature and top-$p$ shape these trajectories in predictable ways, defining a balanced region that harmonizes fluency and creativity. As a phenomenological rather than first-principles framework, DMET provides a unified and testable perspective for interpreting, monitoring, and guiding LLM behavior, offering new insights into the interplay between internal representation dynamics and external text generation quality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20340","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.188553","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Yukun Zhang, Qi Dong","raw_content_length":1372,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["DMET","attractor compactness","Transformer","the Dynamical Manifold Evolution Theory"],"persons":[],"locations":[],"monetary":[]},"char_count":1371,"language_detected":"en","key_concepts":{"key_phrases":["Empirical Investigation","Latent Representational Dynamics","Large Language Models","A Manifold Evolution Perspective","arXiv250520340v2 Announce Type","Abstract","This paper","the Dynamical Manifold Evolution Theory","DMET","a conceptual framework"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Empirical Investigation":2.0,"Latent Representational Dynamics":2.0,"Large Language Models":2.0,"A Manifold Evolution Perspective":2.0,"arXiv250520340v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"the Dynamical Manifold Evolution Theory":1.0,"DMET":1.0,"a conceptual framework":1.0}},"age_hours":2.7669189605555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7708,"joy":0.0956,"surprise":0.0941,"sadness":0.0063,"fear":0.012,"anger":0.0156,"disgust":0.0055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework (DMET) for understanding LLM behavior. While it identifies interpretable metrics (state continuity, attractor compactness, topological persistence) and links them to text quality, there are no concrete actions or deployments described that directly impact sustainability. It's basic research with potential for future applications but currently lacks measurable environmental outcomes.","key_impact_metrics":["state continuity","attractor compactness","topological persistence"],"technology_tags":["large language models","transformer architectures","latent dynamics"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:31:21.082749Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bcb605521ee9","title":"TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data","content":"arXiv:2505.21027v2 Announce Type: replace Abstract: Adversarial attacks pose a significant threat to machine learning models by inducing incorrect predictions through imperceptible perturbations to input data. While these attacks are well studied in unstructured domains such as images, their behaviour on tabular data remains underexplored due to mixed feature types and complex inter-feature dependencies. This study introduces a comprehensive benchmark that evaluates adversarial attacks on tabular datasets with respect to both effectiveness and imperceptibility. We assess five white-box attack algorithms (FGSM, BIM, PGD, DeepFool, and C\\&W) across four representative models (LR, MLP, TabTransformer and FT-Transformer) using eleven datasets spanning finance, energy, and healthcare domains. The benchmark employs four quantitative imperceptibility metrics (proximity, sparsity, deviation, and sensitivity) to characterise perturbation realism. The analysis quantifies the trade-off between these two aspects and reveals consistent differences between attack types, with $\\ell_\\infty$-based attacks achieving higher success but lower subtlety, and $\\ell_2$-based attacks offering more realistic perturbations. The benchmark findings offer actionable insights for designing more imperceptible adversarial attacks, advancing the understanding of adversarial vulnerability in tabular machine learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21027","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.188959","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Zhipeng He, Chun Ouyang, Lijie Wen, Cong Liu, Catarina Moreira","raw_content_length":1410,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["TabTransformer","C\\&W","DeepFool","FGSM","PGD","FT-Transformer"],"persons":[],"locations":["BIM"],"monetary":[]},"char_count":1405,"language_detected":"en","key_concepts":{"key_phrases":["TabAttackBench","A Benchmark","Adversarial Attacks","Tabular Data","arXiv250521027v2 Announce Type","Abstract","Adversarial attacks","a significant threat","machine learning models","incorrect predictions"],"filter_categories":{"ai_ml":["machine learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TabAttackBench":2.0,"A Benchmark":2.0,"Adversarial Attacks":2.0,"Tabular Data":2.0,"arXiv250521027v2 Announce Type":1.0,"Abstract":1.0,"Adversarial attacks":1.0,"a significant threat":1.0,"machine learning models":1.0,"incorrect predictions":1.0}},"age_hours":2.766933618611111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.3915000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9217,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.1832,"joy":0.0036,"surprise":0.0223,"sadness":0.0111,"fear":0.703,"anger":0.0551,"disgust":0.0217},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for adversarial attacks on tabular data, which indirectly supports sustainability by improving the robustness of machine learning models used in energy, finance, and healthcare. The concrete action is the development and evaluation of attack algorithms across various models and datasets. The evidence is based on quantitative imperceptibility metrics and analysis of trade-offs, but it is still in the applied research phase with no clear path to deployment or economic viability yet.","key_impact_metrics":["Effectiveness of attacks","Imperceptibility of perturbations"],"technology_tags":["Adversarial attacks","Tabular data","Machine learning"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T12:31:25.843364Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3ba8f1c2160b","title":"Are Language Models Consequentialist or Deontological Moral Reasoners?","content":"arXiv:2505.21479v2 Announce Type: replace Abstract: As AI systems increasingly navigate applications in healthcare, law, and governance, understanding how they handle ethically complex scenarios becomes critical. Previous work has mainly examined the moral judgments in large language models (LLMs), rather than their underlying moral reasoning process. In contrast, we focus on a large-scale analysis of the moral reasoning traces provided by LLMs. Furthermore, unlike prior work that attempted to draw inferences from only a handful of moral dilemmas, our study leverages over 600 distinct trolley problems as probes for revealing the reasoning patterns that emerge within different LLMs. We introduce and test a taxonomy of moral rationales to systematically classify reasoning traces according to two main normative ethical theories: consequentialism and deontology. Our analysis reveals that LLM chains-of-thought tend to favor deontological principles based on moral obligations, while post-hoc explanations shift notably toward consequentialist rationales that emphasize utility. Our framework provides a foundation for understanding how LLMs process and articulate ethical considerations, an important step toward safe and interpretable deployment of LLMs in high-stakes decision-making environments. Our code is available at https://github.com/keenansamway/moral-lens .","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21479","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.189774","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Keenan Samway, Max Kleiman-Weiner, David Guzman Piedrahita, Rada Mihalcea, Bernhard Sch\\\"olkopf, Zhijing Jin","raw_content_length":1379,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["LLM","Deontological Moral Reasoners","Are Language Models Consequentialist"],"persons":[],"locations":[],"monetary":[]},"char_count":1378,"language_detected":"en","key_concepts":{"key_phrases":["Language Models Consequentialist","Deontological Moral Reasoners","LLMs","arXiv250521479v2","Announce Type","Abstract","AI systems","applications","healthcare","law"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Language Models Consequentialist":2.0,"Deontological Moral Reasoners":2.0,"LLMs":2.0,"arXiv250521479v2":1.0,"Announce Type":1.0,"Abstract":1.0,"AI systems":1.0,"applications":1.0,"healthcare":1.0,"law":1.0}},"age_hours":2.7669642899999998,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8535,"joy":0.0063,"surprise":0.022,"sadness":0.0107,"fear":0.0255,"anger":0.0407,"disgust":0.0414},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research analyzes the moral reasoning of LLMs using a large dataset of trolley problems. While it doesn't directly impact climate change, understanding AI ethics is crucial for deploying AI in areas like resource allocation and policy making, which can indirectly influence sustainability outcomes. The study provides a framework for analyzing LLM reasoning, but it's still in the early stages of application and lacks concrete deployment in real-world sustainability initiatives.","key_impact_metrics":["600 distinct trolley problems","Taxonomy of moral rationales"],"technology_tags":["Large Language Models","Moral Reasoning","AI Ethics"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:31:33.891945Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e22257c2cfbd","title":"Learning Shared Representations from Unpaired Data","content":"arXiv:2505.21524v2 Announce Type: replace Abstract: Learning shared representations is a primary area of multimodal representation learning. The current approaches to achieve a shared embedding space rely heavily on paired samples from each modality, which are significantly harder to obtain than unpaired ones. In this work, we demonstrate that shared representations can be learned almost exclusively from unpaired data. Our arguments are grounded in the spectral embeddings of the random walk matrices constructed independently from each unimodal representation. Empirical results in computer vision and natural language processing domains support its potential, revealing the effectiveness of unpaired data in capturing meaningful cross-modal relations, demonstrating high capabilities in retrieval tasks, generation, arithmetics, zero-shot, and cross-domain classification. This work, to the best of our knowledge, is the first to demonstrate these capabilities almost exclusively from unpaired samples, giving rise to a cross-modal embedding that could be viewed as universal, i.e., independent of the specific modalities of the data. Our project page: https://shaham-lab.github.io/SUE_page.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21524","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.190158","language":"en","tags":["statml","cslg","preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Amitai Yacobi, Nir Ben-Ari, Ronen Talmon, Uri Shaham","raw_content_length":1198,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["Learning Shared Representations","Unpaired Data arXiv:2505.21524v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1197,"language_detected":"en","key_concepts":{"key_phrases":["Shared Representations","Unpaired Data","shared representations","arXiv250521524v2 Announce Type","Abstract","Learning","a primary area","multimodal representation learning","The current approaches","a shared embedding space"],"filter_categories":{"ai_ml":["Unpaired Data","Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Shared Representations":2.0,"Unpaired Data":2.0,"shared representations":2.0,"arXiv250521524v2 Announce Type":1.0,"Abstract":1.0,"Learning":1.0,"a primary area":1.0,"multimodal representation learning":1.0,"The current approaches":1.0,"a shared embedding space":1.0}},"age_hours":2.7669784975,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9108,"joy":0.0074,"surprise":0.0206,"sadness":0.0105,"fear":0.0123,"anger":0.0197,"disgust":0.0187},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for learning shared representations from unpaired data, which could potentially improve the efficiency of machine learning models used in various sustainability applications. However, it is currently in the basic research phase with no deployed technology or measured outcomes related to climate impact, economic viability, or deployment readiness. The vaporware flag is raised because it is about an early-stage concept with no mention of deployed units or operational data.","key_impact_metrics":[],"technology_tags":["machine learning","cross-modal representation learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:31:39.399559Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d28036ba4d1c","title":"Inclusive, Differentially Private Federated Learning for Clinical Data","content":"arXiv:2505.22108v3 Announce Type: replace Abstract: Federated Learning (FL) offers a promising approach for training clinical AI models without centralizing sensitive patient data. However, its real-world adoption is hindered by challenges related to privacy, resource constraints, and compliance. Existing Differential Privacy (DP) approaches often apply uniform noise, which disproportionately degrades model performance, even among well-compliant institutions. In this work, we propose a novel compliance-aware FL framework that enhances DP by adaptively adjusting noise based on quantifiable client compliance scores. Additionally, we introduce a compliance scoring tool based on key healthcare and security standards to promote secure, inclusive, and equitable participation across diverse clinical settings. Extensive experiments on public datasets demonstrate that integrating under-resourced, less compliant clinics with highly regulated institutions yields accuracy improvements of up to 15% over traditional FL. This work advances FL by balancing privacy, compliance, and performance, making it a viable solution for real-world clinical workflows in global healthcare.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.22108","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.190553","language":"en","tags":["cslg","csai","preprints","csdc","research","cscr","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Santhosh Parampottupadam, Melih Co\\c{s}\\u{g}un, Sarthak Pati, Maximilian Zenk, Saikat Roy, Dimitrios Bounias, Benjamin Hamm, Sinem Sav, Ralf Floca, Klaus Maier-Hein","raw_content_length":1179,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1178,"language_detected":"en","key_concepts":{"key_phrases":["Inclusive","Differentially Private Federated Learning","Clinical Data","Announce Type","Abstract","Federated Learning","a promising approach","training","clinical AI models","sensitive patient data"],"filter_categories":{"ai_ml":["training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Inclusive":2.0,"Differentially Private Federated Learning":2.0,"Clinical Data":2.0,"Announce Type":1.0,"Abstract":1.0,"Federated Learning":1.0,"a promising approach":1.0,"training":1.0,"clinical AI models":1.0,"sensitive patient data":1.0}},"age_hours":2.766993112222222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8125,"joy":0.0048,"surprise":0.0267,"sadness":0.0401,"fear":0.0283,"anger":0.0326,"disgust":0.055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a novel federated learning framework that adaptively adjusts noise based on client compliance scores, aiming to improve accuracy and inclusivity in clinical data analysis. The concrete action is the development and testing of this framework on public datasets. The evidence supporting claims is the reported accuracy improvement of up to 15% over traditional FL when integrating under-resourced clinics.","key_impact_metrics":["Accuracy improvements of up to 15%"],"technology_tags":["Federated Learning","Differential Privacy"],"sdg_alignment":[3,10],"analyzed_at":"2025-10-29T12:31:42.398145Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_888466911e6f","title":"Latent Reasoning via Sentence Embedding Prediction","content":"arXiv:2505.22202v2 Announce Type: replace Abstract: Autoregressive language models (LMs) generate one token at a time, yet human reasoning operates over higher-level abstractions - sentences, propositions, and concepts. This contrast raises a central question- Can LMs likewise learn to reason over structured semantic units rather than raw token sequences? In this work, we investigate whether pretrained LMs can be lifted into such abstract reasoning spaces by building on their learned representations. We present a framework that adapts a pretrained token-level LM to operate in sentence space by autoregressively predicting continuous embeddings of next sentences. We explore two embedding paradigms inspired by classical representation learning: 1) semantic embeddings, learned via autoencoding to preserve surface meaning; and 2) contextual embeddings, trained via next-sentence prediction to encode anticipatory structure. We evaluate both under two inference regimes: Discretized, which decodes each predicted embedding into text before re-encoding; and Continuous, which reasons entirely in embedding space for improved efficiency. Across four domains - mathematics, logic, commonsense, and planning - contextual embeddings under continuous inference show competitive performance with Chain-of-Thought (CoT) while reducing inference-time FLOPs on average by half. We also present early signs of scalability and modular adaptation. Finally, to visualize latent trajectories, we introduce SentenceLens, a diagnostic tool that decodes intermediate model states into interpretable sentences. Together, our results indicate that pretrained LMs can effectively transition to abstract, structured reasoning within latent embedding spaces.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.22202","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.190959","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo","raw_content_length":1742,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1741,"language_detected":"en","key_concepts":{"key_phrases":["Latent Reasoning","Sentence Embedding Prediction","LMs","arXiv250522202v2 Announce Type","Autoregressive language models","a time","human reasoning","higher-level abstractions","sentences","propositions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Latent Reasoning":2.0,"Sentence Embedding Prediction":2.0,"LMs":2.0,"arXiv250522202v2 Announce Type":1.0,"Autoregressive language models":1.0,"a time":1.0,"human reasoning":1.0,"higher-level abstractions":1.0,"sentences":1.0,"propositions":1.0}},"age_hours":2.767007605,"is_recent":true,"quality_score":0.7,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7804,"joy":0.003,"surprise":0.022,"sadness":0.0078,"fear":0.0819,"anger":0.0481,"disgust":0.0568},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to language models that could potentially improve efficiency in various domains, including those relevant to sustainability (mathematics, logic, commonsense, and planning). The concrete action is the development of a framework that adapts pretrained token-level LMs to operate in sentence space. The evidence supporting claims includes a reduction in inference-time FLOPs by half compared to Chain-of-Thought (CoT) in certain domains. This is currently at the basic research stage.","key_impact_metrics":["inference-time FLOPs reduction by half"],"technology_tags":["language models","sentence embeddings","artificial intelligence"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:31:45.881880Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_abba79dca7e9","title":"Does Machine Unlearning Truly Remove Knowledge?","content":"arXiv:2505.23270v2 Announce Type: replace Abstract: In recent years, Large Language Models (LLMs) have achieved remarkable advancements, drawing significant attention from the research community. Their capabilities are largely attributed to large-scale architectures, which require extensive training on massive datasets. However, such datasets often contain sensitive or copyrighted content sourced from the public internet, raising concerns about data privacy and ownership. Regulatory frameworks, such as the General Data Protection Regulation (GDPR), grant individuals the right to request the removal of such sensitive information. This has motivated the development of machine unlearning algorithms that aim to remove specific knowledge from models without the need for costly retraining. Despite these advancements, evaluating the efficacy of unlearning algorithms remains a challenge due to the inherent complexity and generative nature of LLMs. In this work, we introduce a comprehensive auditing framework for unlearning evaluation, comprising three benchmark datasets, six unlearning algorithms, and five prompt-based auditing methods. By using various auditing algorithms, we evaluate the effectiveness and robustness of different unlearning strategies. To explore alternatives beyond prompt-based auditing, we propose a novel technique that leverages intermediate activation perturbations, addressing the limitations of auditing methods that rely solely on model inputs and outputs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23270","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.191352","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong Gu, Claudia Grosser, Denis Krompass, Nassir Navab, Volker Tresp","raw_content_length":1496,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["the General Data Protection Regulation"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1495,"language_detected":"en","key_concepts":{"key_phrases":["Machine Unlearning Truly Remove Knowledge","arXiv250523270v2 Announce Type","Abstract","recent years","Large Language Models","LLMs","remarkable advancements","significant attention","the research community","Their capabilities"],"filter_categories":{"ai_ml":["Large Language Models"],"research_academic":["the research community"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Machine Unlearning Truly Remove Knowledge":2.0,"arXiv250523270v2 Announce Type":1.0,"Abstract":1.0,"recent years":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable advancements":1.0,"significant attention":1.0,"the research community":1.0,"Their capabilities":1.0}},"age_hours":2.7670215766666666,"is_recent":true,"quality_score":1.0,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5504,"joy":0.008,"surprise":0.0723,"sadness":0.0146,"fear":0.2751,"anger":0.0644,"disgust":0.0152},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":5,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on developing a framework to audit machine unlearning algorithms for LLMs. While it addresses data privacy concerns related to sensitive information in training datasets, it's still in the research phase with no deployed technology or measured outcomes in terms of environmental impact. The work introduces benchmark datasets and auditing methods, but the actual impact on reducing energy consumption or promoting sustainable practices is theoretical at this stage.","key_impact_metrics":["Effectiveness of unlearning algorithms","Robustness of unlearning strategies"],"technology_tags":["Machine Unlearning","Large Language Models","Data Privacy"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:31:49.201437Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_604aec13ee4d","title":"Jigsaw","content":"arXiv:2505.23590v3 Announce Type: replace Abstract: The application of rule-based reinforcement learning (RL) to multimodal large language models (MLLMs) introduces unique challenges and potential deviations from findings in text-only domains, particularly for perception-heavy tasks. This paper provides a comprehensive study of rule-based visual RL, using jigsaw puzzles as a structured experimental framework. Jigsaw puzzles offer inherent ground truth, adjustable difficulty, and demand complex decision-making, making them ideal for this study. Our research reveals several key findings: \\textit{Firstly,} we find that MLLMs, initially performing near to random guessing on the simplest jigsaw puzzles, achieve near-perfect accuracy and generalize to complex, unseen configurations through fine-tuning. \\textit{Secondly,} training on jigsaw puzzles can induce generalization to other visual tasks, with effectiveness tied to specific task configurations. \\textit{Thirdly,} MLLMs can learn and generalize with or without explicit reasoning, though open-source models often favor direct answering. Consequently, even when trained for step-by-step reasoning, they can ignore the thinking process in deriving the final answer. \\textit{Fourthly,} we observe that complex reasoning patterns appear to be pre-existing rather than emergent, with their frequency increasing alongside training and task difficulty. \\textit{Finally,} our results demonstrate that RL exhibits more effective generalization than Supervised Fine-Tuning (SFT), and an initial SFT cold start phase can hinder subsequent RL optimization. Although these observations are based on jigsaw puzzles and may vary across other visual tasks, this research contributes a valuable piece of jigsaw to the larger puzzle of collective understanding rule-based visual RL and its potential in multimodal learning. The code is available at: https://github.com/zifuwanggg/Jigsaw-R1","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23590","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.192165","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Zifu Wang, Junyi Zhu, Bo Tang, Zhiyu Li, Feiyu Xiong, Jiaqian Yu, Matthew B. Blaschko","raw_content_length":1936,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1935,"language_detected":"en","key_concepts":{"key_phrases":["Jigsaw","Announce Type","Abstract","The application","rule-based reinforcement learning","large language models","MLLMs","unique challenges","potential deviations","findings"],"filter_categories":{"ai_ml":["rule-based reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Jigsaw":2.0,"Announce Type":1.0,"Abstract":1.0,"The application":1.0,"rule-based reinforcement learning":1.0,"large language models":1.0,"MLLMs":1.0,"unique challenges":1.0,"potential deviations":1.0,"findings":1.0}},"age_hours":2.7670516377777776,"is_recent":true,"quality_score":0.7,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.807,"joy":0.0557,"surprise":0.111,"sadness":0.0073,"fear":0.0077,"anger":0.0085,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on applying rule-based reinforcement learning to multimodal large language models using jigsaw puzzles as a framework. While the research demonstrates improved accuracy and generalization in visual tasks, it is currently in the basic research stage with no deployed technology or measured outcomes related to sustainability. The potential climate impact is minimal as it's focused on AI learning methodologies, not direct environmental applications.","key_impact_metrics":[],"technology_tags":["Reinforcement Learning","Multimodal Large Language Models","Visual AI"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:31:53.013233Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d71f7a68d4c9","title":"Muddit: Liberating Generation Beyond Text","content":"arXiv:2505.23606v2 Announce Type: replace Abstract: Unified generation models aim to handle diverse tasks across modalities -- such as text generation, image generation, and vision-language reasoning -- within a single architecture and decoding paradigm. Autoregressive unified models suffer from slow inference due to sequential decoding, and non-autoregressive unified models suffer from weak generalization due to limited pretrained backbones. We introduce Muddit, a unified discrete diffusion transformer that enables fast and parallel generation across both text and image modalities. Unlike prior unified diffusion models trained from scratch, Muddit integrates strong visual priors from a pretrained text-to-image backbone with a lightweight text decoder, enabling flexible and high-quality multimodal generation under a unified architecture. Empirical results show that Muddit achieves competitive or superior performance compared to significantly larger autoregressive models in both quality and efficiency. The work highlights the potential of purely discrete diffusion, when equipped with strong visual priors, as a scalable and effective backbone for unified generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23606","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.192562","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Qingyu Shi, Jinbin Bai, Zhuoran Zhao, Wenhao Chai, Kaidong Yu, Jianzong Wu, Shuangyong Song, Yunhai Tong, Xiangtai Li, Xuelong Li, Shuicheng Yan","raw_content_length":1183,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1182,"language_detected":"en","key_concepts":{"key_phrases":["Muddit","Liberating Generation","Text","Announce Type","Abstract","Unified generation models","diverse tasks","modalities","text generation","image generation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Muddit":3.0,"Liberating Generation":2.0,"Text":2.0,"Announce Type":1.0,"Abstract":1.0,"Unified generation models":1.0,"diverse tasks":1.0,"modalities":1.0,"text generation":1.0,"image generation":1.0}},"age_hours":2.7670659858333333,"is_recent":true,"quality_score":0.7,"sentiment_score":1.9379999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6124,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.881,"joy":0.0089,"surprise":0.0354,"sadness":0.0378,"fear":0.0129,"anger":0.0089,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI model (Muddit) for multimodal generation. While it claims competitive or superior performance compared to larger models in both quality and efficiency, it is still in the research phase with no deployed units or real-world data. The potential climate impact is indirect, stemming from potentially reduced computational resources needed for AI tasks, but this is not quantified.","key_impact_metrics":["Competitive performance compared to larger models","Faster generation speed"],"technology_tags":["AI","Multimodal Generation","Diffusion Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:31:56.179717Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c6761e55146b","title":"SkewRoute: Training","content":"arXiv:2505.23841v2 Announce Type: replace Abstract: Large language models excel at many tasks but often incur high inference costs during deployment. To mitigate hallucination, many systems use a knowledge graph to enhance retrieval-augmented generation (KG-RAG). However, the large amount of retrieved knowledge contexts increase these inference costs further. A promising solution to balance performance and cost is LLM routing, which directs simple queries to smaller LLMs and complex ones to larger LLMs. However, no dedicated routing methods currently exist for RAG, and existing training-based routers face challenges scaling to this domain due to the need for extensive training data. We observe that the score distributions produced by the retrieval scorer strongly correlate with query difficulty. Based on this, we propose an extremely simple yet effective routing framework, the first specifically designed for KG-RAG that efficiently balances performance and cost in a plug-and-play manner. It delivers over 3x higher routing effectiveness while reducing runtime to less than 0.001x compared to existing methods. Our code is available at https://github.com/hrwang00/SkewRoute.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23841","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.193354","language":"en","tags":["computer-science","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Hairu Wang, Yuan Feng, Yukun Cao, Xike Xie, S Kevin Zhou","raw_content_length":1189,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["KG-RAG","SkewRoute"],"persons":["RAG","Announce Type"],"locations":[],"monetary":[]},"char_count":1188,"language_detected":"en","key_concepts":{"key_phrases":["SkewRoute","Training","arXiv250523841v2 Announce Type","Large language models","many tasks","high inference costs","deployment","hallucination","many systems","a knowledge graph"],"filter_categories":{"ai_ml":["Training","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SkewRoute":2.0,"Training":2.0,"arXiv250523841v2 Announce Type":1.0,"Large language models":1.0,"many tasks":1.0,"high inference costs":1.0,"deployment":1.0,"hallucination":1.0,"many systems":1.0,"a knowledge graph":1.0}},"age_hours":2.7670957994444447,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4365,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8873,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8896,"joy":0.0092,"surprise":0.03,"sadness":0.0092,"fear":0.0431,"anger":0.0098,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel routing framework (SkewRoute) for KG-RAG that reduces inference costs by directing queries to smaller or larger LLMs based on difficulty. The framework achieves over 3x higher routing effectiveness and reduces runtime to less than 0.001x compared to existing methods. While promising, it's still in the applied research stage with no deployment data, thus flagged as vaporware.","key_impact_metrics":["3x higher routing effectiveness","0.001x runtime reduction"],"technology_tags":["Large Language Models","Knowledge Graph","Retrieval-Augmented Generation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:31:59.614833Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_36a435f2b401","title":"AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits","content":"arXiv:2505.24138v2 Announce Type: replace Abstract: Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated circuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit design has remained a longstanding challenge due to its difficulty and complexity. Although recent advances in Multi-modal Large Language Models (MLLMs) offer promising potential for supporting AMS circuit analysis and design, current research typically evaluates MLLMs on isolated tasks within the domain, lacking a comprehensive benchmark that systematically assesses model capabilities across diverse AMS-related challenges. To address this gap, we introduce AMSbench, a benchmark suite designed to evaluate MLLM performance across critical tasks including circuit schematic perception, circuit analysis, and circuit design. AMSbench comprises approximately 8000 test questions spanning multiple difficulty levels and assesses eight prominent models, encompassing both open-source and proprietary solutions such as Qwen 2.5-VL and Gemini 2.5 Pro. Our evaluation highlights significant limitations in current MLLMs, particularly in complex multi-modal reasoning and sophisticated circuit design tasks. These results underscore the necessity of advancing MLLMs' understanding and effective application of circuit-specific knowledge, thereby narrowing the existing performance gap relative to human expertise and moving toward fully automated AMS circuit design workflows. Our data is released at this URL.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.24138","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.193773","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Yichen Shi, Ze Zhang, Hongyang Wang, Zhuofu Tao, Zhongyi Li, Bingyu Chen, Yaxin Wang, Zhen huang, Xuhua Liu, Quan Chen, Zhiping Yu, Ting-Jung Lin, Lei He","raw_content_length":1510,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["AMSbench","Analog/Mixed-Signal"],"persons":[],"locations":["AMSbench","Multi"],"monetary":[]},"char_count":1509,"language_detected":"en","key_concepts":{"key_phrases":["AMSbench","A Comprehensive Benchmark","Evaluating","MLLM Capabilities","AMS Circuits","MLLMs","Announce Type","AnalogMixed-Signal AMS circuits","a critical role","the integrated circuit"],"filter_categories":{"ai_ml":["MLLM Capabilities"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AMSbench":2.0,"A Comprehensive Benchmark":2.0,"Evaluating":2.0,"MLLM Capabilities":2.0,"AMS Circuits":2.0,"MLLMs":2.0,"Announce Type":1.0,"AnalogMixed-Signal AMS circuits":1.0,"a critical role":1.0,"the integrated circuit":1.0}},"age_hours":2.767110838611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9025,"joy":0.0215,"surprise":0.0469,"sadness":0.0059,"fear":0.0124,"anger":0.0077,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (AMSbench) for evaluating MLLMs in AMS circuit design. While the benchmark itself doesn't directly reduce emissions, improved circuit design automation could lead to more efficient electronics and energy systems in the future. The benchmark includes approximately 8000 test questions and assesses eight models, providing some level of concrete data, but it's still in the early stages of research and development.","key_impact_metrics":["8000 test questions","8 prominent models assessed"],"technology_tags":["MLLM","AMS circuit design","circuit analysis","circuit schematic perception"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T12:32:03.048947Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_63f2e981d2f2","title":"QiMeng-CodeV","content":"arXiv:2505.24183v4 Announce Type: replace Abstract: Large language models (LLMs) trained via reinforcement learning with verifiable reward (RLVR) have achieved breakthroughs on tasks with explicit, automatable verification, such as software programming and mathematical problems. Extending RLVR to electronic design automation (EDA), especially automatically generating hardware description languages (HDLs) like Verilog from natural-language (NL) specifications, however, poses three key challenges: the lack of automated and accurate verification environments, the scarcity of high-quality NL-code pairs, and the prohibitive computation cost of RLVR. To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs. First, we develop a rule-based testbench generator that performs robust equivalence checking against golden references. Second, we propose a round-trip data synthesis method that pairs open-source Verilog snippets with LLM-generated NL descriptions, verifies code-NL-code consistency via the generated testbench, and filters out inequivalent examples to yield a high-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training pipeline: distillation for the cold start of reasoning abilities, followed by adaptive DAPO, our novel RLVR algorithm that can reduce training cost by adaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art by 12~20%, while even exceeding the performance of 671B DeepSeek-R1 on RTLLM. We have released our model, training code, and dataset to facilitate research in EDA and LLM communities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.24183","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.194181","language":"en","tags":["computer-science","cslg","csar","cspl","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Yaoyu Zhu, Di Huang, Hanqi Lyu, Xiaoyun Zhang, Chongxiao Li, Wenxuan Shi, Yutong Wu, Jianan Mu, Jinghua Wang, Yang Zhao, Pengwei Jin, Shuyao Cheng, Shengwen Liang, Xishan Zhang, Rui Zhang, Zidong Du, Qi Guo, Xing Hu, Yunji Chen","raw_content_length":1704,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["EDA"],"persons":["Verilog"],"locations":[],"monetary":[]},"char_count":1703,"language_detected":"en","key_concepts":{"key_phrases":["QiMeng-CodeV","RLVR","arXiv250524183v4 Announce Type","Large language models","LLMs","reinforcement learning","verifiable reward","breakthroughs","tasks","explicit automatable verification"],"filter_categories":{"ai_ml":["Large language models","reinforcement learning"],"research_academic":["breakthroughs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"QiMeng-CodeV":2.0,"RLVR":2.0,"arXiv250524183v4 Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"reinforcement learning":1.0,"verifiable reward":1.0,"breakthroughs":1.0,"tasks":1.0,"explicit automatable verification":1.0}},"age_hours":2.7671253488888885,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9061,"joy":0.0111,"surprise":0.0541,"sadness":0.0061,"fear":0.0118,"anger":0.008,"disgust":0.0028},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a framework for automatically generating hardware description languages, potentially reducing the energy and resource consumption associated with hardware design. The model achieves 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art, but it's still in the applied research stage with no deployment data available.","key_impact_metrics":["68.6% pass@1 on VerilogEval v2","72.9% pass@1 on RTLLM v1.1"],"technology_tags":["Large Language Models","Reinforcement Learning","Electronic Design Automation","Verilog Generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:32:06.745258Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_93c023c14e29","title":"Equivalent Linear Mappings of Large Language Models","content":"arXiv:2505.24293v3 Announce Type: replace Abstract: Despite significant progress in transformer interpretability, an understanding of the computational mechanisms of large language models (LLMs) remains a fundamental challenge. Many approaches interpret a network's hidden representations but remain agnostic about how those representations are generated. We address this by mapping LLM inference for a given input sequence to an equivalent and interpretable linear system which reconstructs the predicted output embedding with relative error below $10^{-13}$ at double floating-point precision, requiring no additional model training. We exploit a property of transformers wherein every operation (gated activations, attention, and normalization) can be expressed as $A(x) \\cdot x$, where $A(x)$ represents an input-dependent linear transform and $x$ preserves the linear pathway. To expose this linear structure, we strategically detach components of the gradient computation with respect to an input sequence, freezing the $A(x)$ terms at their values computed during inference, such that the Jacobian yields an equivalent linear mapping. This detached Jacobian of the model reconstructs the output with one linear operator per input token, which is shown for Qwen 3, Gemma 3 and Llama 3, up to Qwen 3 14B. These linear representations demonstrate that LLMs operate in extremely low-dimensional subspaces where the singular vectors can be decoded to interpretable semantic concepts. The computation for each intermediate output also has a linear equivalent, and we examine how the linear representations of individual layers and their attention and multilayer perceptron modules build predictions, and use these as steering operators to insert semantic concepts into unrelated text. Despite their global nonlinearity, LLMs can be interpreted through equivalent linear representations that reveal low-dimensional semantic structures in the next-token prediction process.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.24293","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.194623","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":272,"author":"James R. Golden","raw_content_length":1973,"priority":7,"update_frequency":1,"reading_time_minutes":1.36,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1972,"language_detected":"en","key_concepts":{"key_phrases":["Equivalent Linear Mappings","Large Language Models","arXiv250524293v3 Announce Type","Abstract","significant progress","transformer interpretability","an understanding","the computational mechanisms","large language models","LLMs"],"filter_categories":{"ai_ml":["Large Language Models","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Equivalent Linear Mappings":2.0,"Large Language Models":2.0,"arXiv250524293v3 Announce Type":1.0,"Abstract":1.0,"significant progress":1.0,"transformer interpretability":1.0,"an understanding":1.0,"the computational mechanisms":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7671396802777775,"is_recent":true,"quality_score":0.7,"sentiment_score":3.9739999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2052,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8452,"joy":0.0052,"surprise":0.015,"sadness":0.0126,"fear":0.0654,"anger":0.0292,"disgust":0.0274},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for interpreting LLMs, showing they operate in low-dimensional subspaces. While this could potentially lead to more efficient and less energy-intensive models in the future, there are no current deployments or measured outcomes related to energy consumption or emissions reduction. The research is primarily theoretical at this stage.","key_impact_metrics":["relative error below $10^{-13}"],"technology_tags":["Large Language Models","Transformer Interpretability","Linear Mapping"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:32:11.715963Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eeab7f4509c1","title":"SMELLNET: A Large","content":"arXiv:2506.00239v2 Announce Type: replace Abstract: The ability of AI to sense and identify various substances based on their smell alone can have profound impacts on allergen detection (e.g., smelling gluten or peanuts in a cake), monitoring the manufacturing process, and sensing hormones that indicate emotional states, stress levels, and diseases. Despite these broad impacts, there are virtually no large-scale benchmarks, and therefore little progress, for training and evaluating AI systems' ability to smell in the real world. In this paper, we use small gas and chemical sensors to create SmellNet, the first large-scale database that digitizes a diverse range of smells in the natural world. SmellNet contains about 828,000 data points across 50 substances, spanning nuts, spices, herbs, fruits, and vegetables, and 43 mixtures among them, with 68 hours of data collected. Using SmellNet, we developed ScentFormer, a Transformer-based architecture combining temporal differencing and sliding-window augmentation for smell data. For the SmellNet-Base classification task, ScentFormer achieves 58.5% Top-1 accuracy, and for the SmellNet-Mixture distribution prediction task, ScentFormer achieves 50.2% Top-1@0.1 on the test-seen split. ScentFormer's ability to generalize across conditions and capture transient chemical dynamics demonstrates the promise of temporal modeling in olfactory AI. SmellNet and ScentFormer lay the groundwork for real-world olfactory applications across healthcare, food and beverage, environmental monitoring, manufacturing, and entertainment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00239","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.195394","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Dewei Feng, Carol Li, Wei Dai, Paul Pu Liang","raw_content_length":1581,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Transformer","SmellNet"],"persons":["ScentFormer"],"locations":[],"monetary":[]},"char_count":1580,"language_detected":"en","key_concepts":{"key_phrases":["SMELLNET","arXiv250600239v2 Announce Type","Abstract","The ability","various substances","their smell","profound impacts","allergen detection","a cake","the manufacturing process"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SMELLNET":2.0,"arXiv250600239v2 Announce Type":1.0,"Abstract":1.0,"The ability":1.0,"various substances":1.0,"their smell":1.0,"profound impacts":1.0,"allergen detection":1.0,"a cake":1.0,"the manufacturing process":1.0}},"age_hours":2.7671702227777777,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2435,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1513,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8682,"joy":0.0113,"surprise":0.0667,"sadness":0.0141,"fear":0.0179,"anger":0.0094,"disgust":0.0125},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes the creation of a large-scale smell database (SmellNet) and a Transformer-based architecture (ScentFormer) for smell data analysis. While the database is built using gas and chemical sensors and contains a significant amount of data (828,000 data points), it is still in the applied research phase with no deployed applications or customer contracts. The potential climate impact is indirect, through applications like environmental monitoring, but not directly quantified.","key_impact_metrics":["58.5% Top-1 accuracy on SmellNet-Base","50.2% Top-1@0.1 on SmellNet-Mixture"],"technology_tags":["AI","olfactory AI","gas sensors","chemical sensors","Transformer architecture"],"sdg_alignment":[2,3,9,12],"analyzed_at":"2025-10-29T12:32:15.657440Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a990c531d91c","title":"$\\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio","content":"arXiv:2506.00358v2 Announce Type: replace Abstract: While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur $\\textit{simultaneously}$ in both audio and visual modalities, we introduce $\\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the test-time robustness of audio-visual recognition models. $\\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets, $\\texttt{AUDIOSET-2C}$, $\\texttt{VGGSOUND-2C}$, $\\texttt{KINETICS-2C}$, and $\\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual corruptions that are $\\textit{co-occurring}$ and $\\textit{correlated}$. Through extensive evaluations, we observe that state-of-the-art supervised and self-supervised audio-visual models exhibit declining robustness as corruption severity increases. Furthermore, online test-time adaptation (TTA) methods, on $\\texttt{VGGSOUND-2C}$ and $\\texttt{KINETICS-2C}$, offer minimal improvements in performance under bimodal corruptions. We further propose $\\texttt{AV2C}$, a simple TTA approach enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which achieves improvements on $\\texttt{VGGSOUND-2C}$. We hope that $\\texttt{AVROBUSTBENCH}$ will steer the development of more effective and robust audio-visual TTA approaches. Our code is available $\\href{https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark}{here}$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00358","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.196254","language":"en","tags":["cslg","csai","eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Sarthak Kumar Maharana, Saksham Singh Kushwaha, Baoming Zhang, Adrian Rodriguez, Songtao Wei, Yapeng Tian, Yunhui Guo","raw_content_length":1689,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["\\texttt{AVROBUSTBENCH}$","\\textit{co-occurring}$","\\texttt{EPICKITCHENS-2C}$"],"locations":[],"monetary":["\\textit{simultaneously}$"]},"char_count":1688,"language_detected":"en","key_concepts":{"key_phrases":["textttAVROBUSTBENCH","the Robustness","Audio","arXiv250600358v2 Announce Type","Abstract","recent audio-visual models","impressive performance","their robustness","distributional shifts","test-time"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"textttAVROBUSTBENCH":2.0,"the Robustness":2.0,"Audio":2.0,"arXiv250600358v2 Announce Type":1.0,"Abstract":1.0,"recent audio-visual models":1.0,"impressive performance":1.0,"their robustness":1.0,"distributional shifts":1.0,"test-time":1.0}},"age_hours":2.7671998194444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8301,"joy":0.0122,"surprise":0.0878,"sadness":0.0049,"fear":0.0196,"anger":0.0311,"disgust":0.0144},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for audio-visual model robustness, which is a necessary step for deploying these models in real-world scenarios. While the benchmark itself doesn't directly reduce emissions, improving model robustness can indirectly contribute to sustainability by enabling more reliable AI systems in various applications, including those related to climate monitoring or resource management. The research is at an early stage, with no deployed units or economic viability demonstrated.","key_impact_metrics":["75 bimodal audio-visual corruptions","Declining robustness as corruption severity increases"],"technology_tags":["Audio-visual models","Robustness benchmarks","Test-time adaptation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:32:26.966021Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
