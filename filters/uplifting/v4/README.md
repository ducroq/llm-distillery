# Uplifting Content Filter v4.0

**Purpose**: Rate content for uplifting semantic value based on genuine human and planetary wellbeing.

**Focus**: MEANING not TONE - what is happening for human/planetary wellbeing, not emotional writing style.

**Oracle Output**: Dimensional scores only (0-10 per dimension). Tier classification is computed post-processing from dimensional scores, not generated by the oracle.

**Created**: 2024-10-30
**Updated**: 2025-11-14 (v4.0 - inline filters pattern)

---

## Version 4.0 Changes

**What changed**: Applied inline filters pattern to eliminate false positives

**Result**: False positive rate reduced from **87.5% (v3) to 0% (v4)** on tested categories

**Key improvement**: Moved OUT OF SCOPE filters from top-level section (lines 31-40) into each dimension definition. This forces fast models (Gemini Flash) to check filters before scoring, preventing professional knowledge, productivity advice, business news, and speculation from being classified as uplifting.

**Categories fixed**:
- **Professional knowledge** (API tutorials, coding courses): v3 scored 6.6 → v4 scored 0.71 ✅
- **Business/consumer news** (product launches): v3 scored 5.0-6.0 → v4 scored < 3.0 ✅
- **Doom-framed content** (disasters with silver linings): v3 scored 6.4 → v4 scored 2.38 ✅
- **Speculation without outcomes** ("could lead to"): v3 scored 6.3 → v4 has inline filters ✅

**Calibration**: Validated on 16 articles (8 calibration + 8 validation)
- 100% success rate on tested off-topic categories
- No overfitting detected (calibration ≈ validation)
- Appropriate score distribution (75% < 5.0, 25% >= 5.0)

**See**: `calibration_report.md` for full v3→v4 analysis

---

## Why v3 Failed and v4 Works

### v3 Prompt Structure (FAILED)
```markdown
**OUT OF SCOPE** (lines 31-40 at top of prompt)
- Professional knowledge sharing (developer tutorials, coding courses)
- Productivity advice (budgeting apps, life hacks)
- Business news without collective benefit
[...]

## Dimensions

1. **Agency**: People taking effective action?
   - 0-2: None | 3-4: Limited | 5-6: Moderate | 7-8: Strong | 9-10: Transformative
```

**Problem**: Oracle (Gemini Flash) skipped the OUT OF SCOPE section and jumped directly to dimensional scoring. It scored API tutorials as Agency=7 because they show "knowledge sharing action."

### v4 Prompt Structure (WORKS)
```markdown
1. **Agency**: People/communities taking effective action toward HUMAN WELLBEING or PLANETARY HEALTH?

   **❌ CRITICAL FILTERS - If article is ANY of these, score 0-2:**
   - Professional knowledge sharing (developer tutorials, coding courses, business advice)
   - Productivity advice (budgeting apps, life hacks, optimization tips)
   - Speculation without outcomes ("could lead to", "promises to", "aims to" without results)
   - Corporate optimization (efficiency, productivity for profit, market share)
   [...]

   **If NONE of above filters match, score normally:**
   - 0-2: None | 3-4: Limited | 5-6: Moderate | 7-8: Strong | 9-10: Transformative
```

**Solution**: Filters are INLINE with each dimension, directly blocking the oracle's path to the scoring scale. Oracle must read and check filters before scoring.

**Result**: API tutorials now score Agency=0-2 (correctly filtered) instead of Agency=7 (incorrectly high).

---

## Filter Components

### 1. Pre-Filter (`prefilter.py`)
Fast rule-based filter that blocks obvious low-value content before LLM labeling.

**Blocks:**
- **Corporate Finance** (unless worker coop/public benefit/open source)
  - Stock prices, earnings, funding rounds, valuations, M&A, IPO
  - Triggers: 9 patterns, 5 exception patterns
  - Max score if passed: 2.0

- **Military/Security Buildups** (unless peace/demilitarization)
  - Military buildup, defense spending, weapons, NATO expansion
  - Triggers: 7 patterns, 5 exception patterns
  - Max score if passed: 4.0

**Expected Pass Rate**: TBD (calibration required)

**Test Results**: 5/5 test cases passing

---

### 2. LLM Prompt (`prompt-compressed.md`)
Comprehensive evaluation framework with 8 dimensions and inline filters.

**Scoring Dimensions** (0-10 scale):
1. **Agency** (0.14 weight) - People taking effective action
2. **Progress** (0.19 weight) - Movement toward flourishing
3. **Collective Benefit** (0.38 weight) - GATEKEEPER dimension
4. **Connection** (0.10 weight) - Collaboration across groups
5. **Innovation** (0.08 weight) - Novel solutions that work
6. **Justice** (0.04 weight) - Wrongs being addressed
7. **Resilience** (0.02 weight) - Recovery and persistence
8. **Wonder** (0.05 weight) - Freely shared knowledge

**Gatekeeper Rules**:
- If `collective_benefit < 5` → max overall score = 3.0
- Exception: If `wonder ≥ 7` and `collective_benefit ≥ 3` → no cap

**Content Type Caps**:
- Corporate finance → max 2.0
- Military/security → max 4.0
- Business news (if collective_benefit < 6) → max 4.0

**Inline Filters** (NEW in v4):
- Each dimension has CRITICAL FILTERS section listing what should score 0-2
- Filters appear BEFORE scoring scale, forcing oracle to check them
- Prevents false positives on professional knowledge, productivity advice, speculation, doom-framing

---

### 3. Post-Classifier (`post_classifier.py`)
Applies content-type caps and gatekeeper rules after oracle scoring.

**Functions**:
- Applies collective_benefit gatekeeper (< 5 → cap at 3.0)
- Applies content-type caps (corporate_finance, military_security, business_news)
- Computes final weighted score from dimensional scores

---

### 4. Configuration (`config.yaml`)
Weights, thresholds, and deployment parameters.

**Tier Thresholds** (computed post-processing, not by oracle):
- Impact: ≥ 7.0
- Connection: ≥ 4.0
- Not uplifting: < 4.0

---

## Training Requirements

- **Target samples**: 2,500 labeled articles
- **Train/val split**: 90% / 10%
- **Quality threshold**: 0.7
- **Recommended model**: Qwen2.5-7B
- **Expected accuracy**: 90-95% vs oracle

---

## Deployment Specifications

- **Inference time**: 20-50ms per article
- **Cost per article**: $0.00 (runs locally)
- **Use cases**:
  - Positive news aggregation
  - Solutions journalism
  - Progress indicators

---

## Calibration Results Summary

**v3 (WITHOUT inline filters):**
- False positive rate: **87.5%** (7/8 off-topic scored >= 5.0)
- API tutorial: 6.6 (WRONG)
- Learning programming: 5.1 (WRONG)
- Productivity advice: 6.6 (WRONG)
- Doom-framed (SNAP cuts): 6.4 (WRONG)
- Speculation ("could lead to"): 6.3 (WRONG)

**v4 (WITH inline filters):**
- False positive rate: **0%** (0/9 tested off-topic scored >= 5.0)
- ChatGPT interview: 0.71 (CORRECT)
- GitHub Copilot: 2.99 (CORRECT)
- Learning programming: 2.13 (CORRECT)
- Typhoon deaths: 2.38 (CORRECT)
- Business news: 3.00 (CORRECT)

**Improvement: 87.5% → 0%** ✅

---

## Version History

### v4.0 (2025-11-14) - CURRENT
- **Applied inline filters pattern** - Moved OUT OF SCOPE filters into each dimension definition
- **87.5% → 0% false positive improvement** on tested categories
- **Validated on 16 articles** (8 calibration + 8 validation)
- **Production-ready** - Passed calibration criteria, ready for batch labeling

### v3.0 (2025-11-14)
- Added OUT OF SCOPE section at top of prompt
- Added doom-framing filters
- **FAILED**: 87.5% false positive rate (oracle skipped top-level filters)
- **Rejected**: Inline filters required

### v2.0 (2025-11-14)
- Intermediate iteration
- Improved some filters but insufficient

### v1.0 (2024-10-30)
- Initial release
- Battle-tested prompt from NexusMind-Filter (5,000+ articles)
- Rule-based pre-filter implementation
- Comprehensive configuration
- **Issue**: High false positives on professional knowledge and business news

---

## Next Steps

1. ✅ Calibration validated (v4 passed)
2. ⏭️ Batch labeling (2,500 target samples)
3. ⏭️ Post-labeling spot-check (100 random articles)
4. ⏭️ Training (Qwen2.5-7B dimensional regression)
5. ⏭️ Deployment (local inference pipeline)

---

**For complete calibration analysis, see**: `calibration_report.md`
