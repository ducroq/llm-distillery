{"id":"science_arxiv_cs_80c88bf5cd20","title":"IVEBench: Modern Benchmark Suite for Instruction","content":"arXiv:2510.11647v1 Announce Type: new Abstract: Instruction-guided video editing has emerged as a rapidly advancing research direction, offering new opportunities for intuitive content transformation while also posing significant challenges for systematic evaluation. Existing video editing benchmarks fail to support the evaluation of instruction-guided video editing adequately and further suffer from limited source diversity, narrow task coverage and incomplete evaluation metrics. To address the above limitations, we introduce IVEBench, a modern benchmark suite specifically designed for instruction-guided video editing assessment. IVEBench comprises a diverse database of 600 high-quality source videos, spanning seven semantic dimensions, and covering video lengths ranging from 32 to 1,024 frames. It further includes 8 categories of editing tasks with 35 subcategories, whose prompts are generated and refined through large language models and expert review. Crucially, IVEBench establishes a three-dimensional evaluation protocol encompassing video quality, instruction compliance and video fidelity, integrating both traditional metrics and multimodal large language model-based assessments. Extensive experiments demonstrate the effectiveness of IVEBench in benchmarking state-of-the-art instruction-guided video editing methods, showing its ability to provide comprehensive and human-aligned evaluation outcomes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11647","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.015393","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Yinan Chen, Jiangning Zhang, Teng Hu, Yuxiang Zeng, Zhucun Xue, Qingdong He, Chengjie Wang, Yong Liu, Xiaobin Hu, Shuicheng Yan","raw_content_length":1428,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["IVEBench"],"persons":["Benchmark Suite"],"locations":[],"monetary":[]},"char_count":1427,"language_detected":"en","key_concepts":{"key_phrases":["IVEBench","Modern Benchmark Suite","Instruction","arXiv251011647v1 Announce Type","new Abstract","Instruction-guided video editing","a rapidly advancing research direction","new opportunities","intuitive content transformation","significant challenges"],"filter_categories":{"research_academic":["a rapidly advancing research direction"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"IVEBench":2.0,"Modern Benchmark Suite":2.0,"Instruction":2.0,"arXiv251011647v1 Announce Type":1.0,"new Abstract":1.0,"Instruction-guided video editing":1.0,"a rapidly advancing research direction":1.0,"new opportunities":1.0,"intuitive content transformation":1.0,"significant challenges":1.0}},"age_hours":2.760555660277778,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6694,"joy":0.006,"surprise":0.0405,"sadness":0.1768,"fear":0.0545,"anger":0.0321,"disgust":0.0207},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new benchmark for instruction-guided video editing. While potentially useful for developing more efficient algorithms, it doesn't directly address climate change or sustainability in a measurable way. It is currently in the applied research stage, with no deployment or measured outcomes.","key_impact_metrics":[],"technology_tags":["video editing","instruction-guided editing","benchmarking"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:06:50.803100Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1410493a963c","title":"PhySIC: Physically Plausible 3D Human","content":"arXiv:2510.11649v1 Announce Type: new Abstract: Reconstructing metrically accurate humans and their surrounding scenes from a single image is crucial for virtual reality, robotics, and comprehensive 3D scene understanding. However, existing methods struggle with depth ambiguity, occlusions, and physically inconsistent contacts. To address these challenges, we introduce PhySIC, a framework for physically plausible Human-Scene Interaction and Contact reconstruction. PhySIC recovers metrically consistent SMPL-X human meshes, dense scene surfaces, and vertex-level contact maps within a shared coordinate frame from a single RGB image. Starting from coarse monocular depth and body estimates, PhySIC performs occlusion-aware inpainting, fuses visible depth with unscaled geometry for a robust metric scaffold, and synthesizes missing support surfaces like floors. A confidence-weighted optimization refines body pose, camera parameters, and global scale by jointly enforcing depth alignment, contact priors, interpenetration avoidance, and 2D reprojection consistency. Explicit occlusion masking safeguards invisible regions against implausible configurations. PhySIC is efficient, requiring only 9 seconds for joint human-scene optimization and under 27 seconds end-to-end. It naturally handles multiple humans, enabling reconstruction of diverse interactions. Empirically, PhySIC outperforms single-image baselines, reducing mean per-vertex scene error from 641 mm to 227 mm, halving PA-MPJPE to 42 mm, and improving contact F1 from 0.09 to 0.51. Qualitative results show realistic foot-floor interactions, natural seating, and plausible reconstructions of heavily occluded furniture. By converting a single image into a physically plausible 3D human-scene pair, PhySIC advances scalable 3D scene understanding. Our implementation is publicly available at https://yuxuan-xue.com/physic.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11649","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.015826","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Pradyumna Yalandur Muralidhar, Yuxuan Xue, Xianghui Xie, Margaret Kostyrko, Gerard Pons-Moll","raw_content_length":1891,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["RGB","PhySIC","SMPL","Human-Scene Interaction"],"persons":[],"locations":[],"monetary":[]},"char_count":1890,"language_detected":"en","key_concepts":{"key_phrases":["PhySIC","Physically Plausible 3D Human","arXiv251011649v1 Announce Type","new Abstract","metrically accurate humans","their surrounding scenes","a single image","virtual reality","robotics","comprehensive 3D scene understanding"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PhySIC":3.0,"Physically Plausible 3D Human":2.0,"arXiv251011649v1 Announce Type":1.0,"new Abstract":1.0,"metrically accurate humans":1.0,"their surrounding scenes":1.0,"a single image":1.0,"virtual reality":1.0,"robotics":1.0,"comprehensive 3D scene understanding":1.0}},"age_hours":2.76056993,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9141,"joy":0.0128,"surprise":0.0213,"sadness":0.0058,"fear":0.025,"anger":0.0148,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (PhySIC) for 3D human-scene reconstruction from a single image, improving accuracy and physical plausibility. While it doesn't directly address climate change, it could indirectly contribute to sustainability by enabling more efficient design and simulation in various fields. The technology is currently in the applied research phase, with demonstrated improvements in reconstruction accuracy (e.g., reducing mean per-vertex scene error from 641 mm to 227 mm).","key_impact_metrics":["mean per-vertex scene error reduction: 641 mm to 227 mm","PA-MPJPE halved to 42 mm","contact F1 improved from 0.09 to 0.51"],"technology_tags":["3D reconstruction","human-scene interaction","computer vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:06:54.819815Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf8648772f66","title":"InfiniHuman: Infinite 3D Human Creation with Precise Control","content":"arXiv:2510.11650v1 Announce Type: new Abstract: Generating realistic and controllable 3D human avatars is a long-standing challenge, particularly when covering broad attribute ranges such as ethnicity, age, clothing styles, and detailed body shapes. Capturing and annotating large-scale human datasets for training generative models is prohibitively expensive and limited in scale and diversity. The central question we address in this paper is: Can existing foundation models be distilled to generate theoretically unbounded, richly annotated 3D human data? We introduce InfiniHuman, a framework that synergistically distills these models to produce richly annotated human data at minimal cost and with theoretically unlimited scalability. We propose InfiniHumanData, a fully automatic pipeline that leverages vision-language and image generation models to create a large-scale multi-modal dataset. User study shows our automatically generated identities are undistinguishable from scan renderings. InfiniHumanData contains 111K identities spanning unprecedented diversity. Each identity is annotated with multi-granularity text descriptions, multi-view RGB images, detailed clothing images, and SMPL body-shape parameters. Building on this dataset, we propose InfiniHumanGen, a diffusion-based generative pipeline conditioned on text, body shape, and clothing assets. InfiniHumanGen enables fast, realistic, and precisely controllable avatar generation. Extensive experiments demonstrate significant improvements over state-of-the-art methods in visual quality, generation speed, and controllability. Our approach enables high-quality avatar generation with fine-grained control at effectively unbounded scale through a practical and affordable solution. We will publicly release the automatic data generation pipeline, the comprehensive InfiniHumanData dataset, and the InfiniHumanGen models at https://yuxuan-xue.com/infini-human.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11650","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.016234","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Yuxuan Xue, Xianghui Xie, Margaret Kostyrko, Gerard Pons-Moll","raw_content_length":1935,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1934,"language_detected":"en","key_concepts":{"key_phrases":["InfiniHuman","Infinite 3D Human Creation","Precise Control","Announce Type","new Abstract","realistic and controllable 3D human avatars","a long-standing challenge","broad attribute","ranges","ethnicity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"InfiniHuman":2.0,"Infinite 3D Human Creation":2.0,"Precise Control":2.0,"Announce Type":1.0,"new Abstract":1.0,"realistic and controllable 3D human avatars":1.0,"a long-standing challenge":1.0,"broad attribute":1.0,"ranges":1.0,"ethnicity":1.0}},"age_hours":2.7605846975,"is_recent":true,"quality_score":0.7,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5793,"joy":0.0068,"surprise":0.0157,"sadness":0.0134,"fear":0.2708,"anger":0.0774,"disgust":0.0366},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework for generating 3D human avatars. While innovative, its direct climate impact is minimal. The technical credibility is relatively high due to the use of existing foundation models and user studies, but it's still in the early stages of deployment.","key_impact_metrics":["111K identities spanning unprecedented diversity","Undistinguishable from scan renderings"],"technology_tags":["3D human avatars","Generative models","Diffusion models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:00.241037Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4ce379366981","title":"ACADREASON: Exploring the Limits of Reasoning Models with Academic Research Problems","content":"arXiv:2510.11652v1 Announce Type: new Abstract: In recent years, the research focus of large language models (LLMs) and agents has shifted increasingly from demonstrating novel capabilities to complex reasoning and tackling challenging tasks. However, existing evaluations focus mainly on math/code contests or general tasks, while existing multi-domain academic benchmarks lack sufficient reasoning depth, leaving the field without a rigorous benchmark for high-level reasoning. To fill this gap, we introduce the Acadreason benchmark, designed to evaluate the ability of LLMs and agents to acquire and reason over academic knowledge. It consists of 50 expert-annotated academic problems across five high-reasoning domains, including computer science, economics, law, mathematics, and philosophy. All questions are sourced from top-tier publications in recent years and undergo rigorous annotation and quality control to ensure they are both challenging and answerable. We conduct systematic evaluations of over 10 mainstream LLMs and agents. The results show that most LLMs scored below 20 points, with even the cutting-edge GPT-5 achieving only 16 points. While agents achieved higher scores, none exceeded 40 points. This demonstrates the current capability gap between LLMs and agents in super-intelligent academic research tasks and highlights the challenges of Acadreason.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11652","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.016645","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Xin Gui, King Zhu, JinCheng Ren, Qianben Chen, Zekun Moore Wang, Yizhi LI, Xinpeng Liu, Xiaowan Li, Wenli Ren, Linyu Miao, Tianrui Qin, Ziqi Shu, He Zhu, Xiangru Tang, Dingfeng Shi, Jiaheng Liu, Yuchen Eleanor Jiang, Minghao Liu, Ge Zhang, Wangchunshu Zhou","raw_content_length":1380,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Acadreason","the Limits of Reasoning Models with Academic Research Problems arXiv:2510.11652v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1379,"language_detected":"en","key_concepts":{"key_phrases":["ACADREASON","the Limits","Reasoning Models","Academic Research Problems","arXiv251011652v1 Announce Type","new Abstract","recent years","the research focus","large language models","LLMs"],"filter_categories":{"research_academic":["Academic Research Problems","the research focus"],"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ACADREASON":2.0,"the Limits":2.0,"Reasoning Models":2.0,"Academic Research Problems":2.0,"arXiv251011652v1 Announce Type":1.0,"new Abstract":1.0,"recent years":1.0,"the research focus":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7605997211111113,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8659,"joy":0.0068,"surprise":0.0409,"sadness":0.0238,"fear":0.0206,"anger":0.024,"disgust":0.018},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a benchmark for evaluating LLMs on academic reasoning. While it doesn't directly impact sustainability, it could indirectly contribute by improving AI's ability to solve complex problems related to climate change and sustainability in the future. The benchmark uses expert-annotated problems and evaluates existing LLMs, providing concrete metrics on their performance.","key_impact_metrics":["GPT-5 score: 16 points","Agent score: below 40 points"],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:04.143269Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fbfe58a0a822","title":"MATH","content":"arXiv:2510.11653v1 Announce Type: new Abstract: With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL) methods has emerged that seem to unlock stronger mathematical reasoning. However, a closer look at the open-source ecosystem reveals a critical limitation: with sufficiently many draws (e.g., $\\texttt{pass@1024}$), many existing base models already solve nearly all questions on widely used math benchmarks such as MATH-500 and AIME 2024. This suggests that the RL fine-tuning methods prevalent in the LLM reasoning literature largely sharpen existing solution modes rather than discovering entirely new ones. Such sharpening stands in contrast to the broader promise of RL: to foster exploration and to acquire new skills. To move beyond this plateau, we introduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat common open-source models of up to 8B parameters even under large sampling budgets. Improving performance on our benchmark via RL requires methods that learn to reason in ways that go beyond base model capabilities in repeated sampling. Since the problems are drawn from subsets of DAPO-Math-17K and DeepScaleR datasets, they remain topically equivalent to standard high-school math. Validating our premise, RL fine-tuned models such as Nemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform poorly on MATH-B at $\\texttt{pass@1024}$, showing how existing approaches fall short on tackling harder instances. We hope MATH-B will catalyze exploration-driven RL approaches that elicit deeper reasoning capabilities. We release MATH-B at https://huggingface.co/datasets/brendel-group/MATH-Beyond.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11653","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.017057","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":225,"author":"Prasanna Mayilvahanan, Ricardo Dominguez-Olmedo, Thadd\\\"aus Wiedemer, Wieland Brendel","raw_content_length":1668,"priority":7,"update_frequency":1,"reading_time_minutes":1.125,"robust_parsing_used":true,"entities":{"organizations":["LLM","DeepSeek-R1"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1667,"language_detected":"en","key_concepts":{"key_phrases":["MATH","arXiv251011653v1 Announce Type","new Abstract","the advent","DeepSeek-R1","a new wave","reinforcement learning","RL methods","stronger mathematical reasoning","a closer look"],"filter_categories":{"ai_ml":["reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MATH":2.0,"arXiv251011653v1 Announce Type":1.0,"new Abstract":1.0,"the advent":1.0,"DeepSeek-R1":1.0,"a new wave":1.0,"reinforcement learning":1.0,"RL methods":1.0,"stronger mathematical reasoning":1.0,"a closer look":1.0}},"age_hours":2.7606148491666667,"is_recent":true,"quality_score":0.7,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.859,"joy":0.0126,"surprise":0.107,"sadness":0.0065,"fear":0.0041,"anger":0.007,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark, MATH-B, for evaluating reinforcement learning methods in mathematical reasoning. While the research aims to improve AI reasoning capabilities, it currently has no direct or measurable impact on sustainability. It's a basic research project with no deployed technology or proven outcomes related to climate change or other sustainability dimensions.","key_impact_metrics":["pass@1024"],"technology_tags":["Reinforcement Learning","Mathematical Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:07:07.219168Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_34466c9c14d8","title":"Automatically Generating Questions About Scratch Programs","content":"arXiv:2510.11658v1 Announce Type: new Abstract: When learning to program, students are usually assessed based on the code they wrote. However, the mere completion of a programming task does not guarantee actual comprehension of the underlying concepts. Asking learners questions about the code they wrote has therefore been proposed as a means to assess program comprehension. As creating targeted questions for individual student programs can be tedious and challenging, prior work has proposed to generate such questions automatically. In this paper we generalize this idea to the block-based programming language Scratch. We propose a set of 30 different questions for Scratch code covering an established program comprehension model, and extend the LitterBox static analysis tool to automatically generate corresponding questions for a given Scratch program. On a dataset of 600,913 projects we generated 54,118,694 questions automatically. Our initial experiments with 34 ninth graders demonstrate that this approach can indeed generate meaningful questions for Scratch programs, and we find that the ability of students to answer these questions on their programs relates to their overall performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11658","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.018208","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Florian Oberm\\\"uller, Gordon Fraser","raw_content_length":1208,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Scratch","LitterBox"],"persons":["Scratch"],"locations":[],"monetary":[]},"char_count":1207,"language_detected":"en","key_concepts":{"key_phrases":["Automatically Generating Questions","Scratch Programs","the code","arXiv251011658v1 Announce Type","new Abstract","students","the mere completion","a programming task","actual comprehension","the underlying concepts"],"filter_categories":{"engineering":["a programming task"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Automatically Generating Questions":2.0,"Scratch Programs":2.0,"the code":2.0,"arXiv251011658v1 Announce Type":1.0,"new Abstract":1.0,"students":1.0,"the mere completion":1.0,"a programming task":1.0,"actual comprehension":1.0,"the underlying concepts":1.0}},"age_hours":2.7606589080555555,"is_recent":true,"quality_score":1.0,"sentiment_score":5.589500000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1179,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9127,"joy":0.0138,"surprise":0.0215,"sadness":0.0034,"fear":0.0166,"anger":0.0196,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on automatically generating questions for Scratch programs to assess comprehension. While it could indirectly improve education in sustainability-related fields, there's no direct, measurable climate impact or deployment of a physical technology. The study involves initial experiments with ninth graders, indicating a pilot stage, and generates a large number of questions (54,118,694).","key_impact_metrics":["54,118,694 questions generated","34 ninth graders in experiment"],"technology_tags":["AI","Education Technology","Scratch Programming"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:07:10.822242Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2159766919c8","title":"Boundary","content":"arXiv:2510.11683v1 Announce Type: new Abstract: A key challenge in applying reinforcement learning (RL) to diffusion large language models (dLLMs) lies in the intractability of their likelihood functions, which are essential for the RL objective, necessitating corresponding approximation in each training step. While existing methods approximate the log-likelihoods by their evidence lower bounds (ELBOs) via customized Monte Carlo (MC) sampling, the forward computational graphs of all MC samples need to be retained for the gradient computation of non-linear terms in the RL objective, resulting in significant memory overhead. This constraint restricts feasible sample sizes, leading to imprecise likelihood approximations and ultimately distorting the RL objective. To overcome this limitation, we propose \\emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient RL algorithm that maximizes a specially constructed lower bound of the ELBO-based objective. This lower bound is carefully designed to satisfy two key properties: (1) Linearity: it is formulated in a linear sum where each term depends only on a single MC sample, thereby enabling gradient accumulation across samples and ensuring constant memory usage; (2) Equivalence: Both the value and gradient of this lower bound are equal to those of the ELBO-based objective in on-policy training, making it also an effective approximation for the original RL objective. These properties allow BGPO to adopt a large MC sample size, resulting in more accurate likelihood approximations and improved RL objective estimation, which in turn leads to enhanced performance. Experiments show that BGPO significantly outperforms previous RL algorithms for dLLMs in math problem solving, code generation, and planning tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11683","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.020587","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Nianyi Lin, Jiajie Zhang, Lei Hou, Juanzi Li","raw_content_length":1787,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Boundary arXiv:2510.11683v1 Announce Type"],"persons":["Monte Carlo"],"locations":[],"monetary":[]},"char_count":1786,"language_detected":"en","key_concepts":{"key_phrases":["Boundary","arXiv251011683v1","Announce Type","new Abstract","A key challenge","reinforcement learning","large language models","the intractability","their likelihood functions","which"],"filter_categories":{"ai_ml":["reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Boundary":2.0,"arXiv251011683v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"A key challenge":1.0,"reinforcement learning":1.0,"large language models":1.0,"the intractability":1.0,"their likelihood functions":1.0,"which":1.0}},"age_hours":2.7607467758333333,"is_recent":true,"quality_score":1.0,"sentiment_score":2.1405000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5719,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9182,"joy":0.0099,"surprise":0.041,"sadness":0.0059,"fear":0.0075,"anger":0.0112,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel reinforcement learning algorithm (BGPO) to improve the efficiency of large language models, specifically in math problem solving, code generation, and planning tasks. While improved efficiency in these areas could indirectly contribute to sustainability by reducing computational energy consumption, the article doesn't provide concrete evidence of energy savings or environmental impact. The research is at an early stage, with no deployment or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Reinforcement Learning","Large Language Models","Policy Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:07:16.682485Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3d7b541f46a4","title":"Representation-Based Exploration for Language Models: From Test","content":"arXiv:2510.11686v1 Announce Type: new Abstract: Reinforcement learning (RL) promises to expand the capabilities of language models, but it is unclear if current RL techniques promote the discovery of novel behaviors, or simply sharpen those already present in the base model. In this paper, we investigate the value of deliberate exploration -- explicitly incentivizing the model to discover novel and diverse behaviors -- and aim to understand how the knowledge in pre-trained models can guide this search. Our main finding is that exploration with a simple, principled, representation-based bonus derived from the pre-trained language model's hidden states significantly improves diversity and pass@k rates -- both for post-training, and in a novel inference-time scaling setting we introduce. For inference-time, exploration with representation-based diversity improves efficiency, consistently improving pass@k rates across a variety of models and reasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50% improvement in verifier efficiency on almost all tasks. For post-training, we show that integrating this exploration strategy into an RL pipeline improves reasoning performance over that of the initial model and over standard RL post-training. For example, on AIME 2024, our post-trained Qwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model, demonstrating a 3x improvement in test-time sample efficiency. Overall, our findings suggest that deliberate exploration -- with the right notion of diversity -- is a practical path toward discovery of new behaviors beyond sharpening.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11686","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.020997","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Jens Tuyls, Dylan J. Foster, Akshay Krishnamurthy, Jordan T. Ash","raw_content_length":1629,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Representation-Based Exploration for Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1628,"language_detected":"en","key_concepts":{"key_phrases":["Representation-Based Exploration","Language Models","Test","arXiv251011686v1 Announce Type","new Abstract","Reinforcement learning","the capabilities","language models","current RL techniques","the discovery"],"filter_categories":{"ai_ml":["Reinforcement learning"],"research_academic":["the discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Representation-Based Exploration":2.0,"Language Models":2.0,"Test":2.0,"arXiv251011686v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement learning":1.0,"the capabilities":1.0,"language models":1.0,"current RL techniques":1.0,"the discovery":1.0}},"age_hours":2.7607620222222224,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9343,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9299,"joy":0.0205,"surprise":0.0245,"sadness":0.0033,"fear":0.0068,"anger":0.0095,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a new reinforcement learning technique for language models that improves diversity and efficiency. The concrete action is the development and testing of a representation-based bonus for exploration. Evidence includes a 50% improvement in verifier efficiency on some tasks and a 3x improvement in test-time sample efficiency on AIME 2024. The stage is applied research, as it is a proof of concept with promising results but not yet deployed.","key_impact_metrics":["50% improvement in verifier efficiency","3x improvement in test-time sample efficiency"],"technology_tags":["Reinforcement Learning","Language Models","AI"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:07:20.165090Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cd5757850ca9","title":"Beyond 'Templates': Category","content":"arXiv:2510.11687v1 Announce Type: new Abstract: Estimating an object's 6D pose, size, and shape from visual input is a fundamental problem in computer vision, with critical applications in robotic grasping and manipulation. Existing methods either rely on object-specific priors such as CAD models or templates, or suffer from limited generalization across categories due to pose-shape entanglement and multi-stage pipelines. In this work, we propose a unified, category-agnostic framework that simultaneously predicts 6D pose, size, and dense shape from a single RGB-D image, without requiring templates, CAD models, or category labels at test time. Our model fuses dense 2D features from vision foundation models with partial 3D point clouds using a Transformer encoder enhanced by a Mixture-of-Experts, and employs parallel decoders for pose-size estimation and shape reconstruction, achieving real-time inference at 28 FPS. Trained solely on synthetic data from 149 categories in the SOPE dataset, our framework is evaluated on four diverse benchmarks SOPE, ROPE, ObjaversePose, and HANDAL, spanning over 300 categories. It achieves state-of-the-art accuracy on seen categories while demonstrating remarkably strong zero-shot generalization to unseen real-world objects, establishing a new standard for open-set 6D understanding in robotics and embodied AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11687","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.021386","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Jinyu Zhang, Haitao Lin, Jiashu Hou, Xiangyang Xue, Yanwei Fu","raw_content_length":1362,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Transformer","CAD","vision foundation","RGB"],"persons":["Templates"],"locations":[],"monetary":[]},"char_count":1361,"language_detected":"en","key_concepts":{"key_phrases":["Templates"," Category","arXiv251011687v1 Announce Type","new Abstract","an objects 6D","size","shape","visual input","a fundamental problem","computer vision"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Templates":2.0," Category":2.0,"arXiv251011687v1 Announce Type":1.0,"new Abstract":1.0,"an objects 6D":1.0,"size":1.0,"shape":1.0,"visual input":1.0,"a fundamental problem":1.0,"computer vision":1.0}},"age_hours":2.7607775194444444,"is_recent":true,"quality_score":1.0,"sentiment_score":1.0470000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7906,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.841,"joy":0.0044,"surprise":0.0241,"sadness":0.0423,"fear":0.0307,"anger":0.0284,"disgust":0.029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a category-agnostic framework for 6D pose estimation, size, and shape prediction from RGB-D images. While it achieves state-of-the-art accuracy on seen categories and strong zero-shot generalization, it's trained solely on synthetic data and evaluated on benchmarks, indicating it's still in the applied research stage with no real-world deployment yet. The real-time inference at 28 FPS is a concrete metric.","key_impact_metrics":["real-time inference at 28 FPS","evaluated on four diverse benchmarks"],"technology_tags":["6D pose estimation","Transformer encoder","Mixture-of-Experts"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:23.172369Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d94111cef8ee","title":"PACEbench: A Framework for Evaluating Practical AI Cyber","content":"arXiv:2510.11688v1 Announce Type: new Abstract: The increasing autonomy of Large Language Models (LLMs) necessitates a rigorous evaluation of their potential to aid in cyber offense. Existing benchmarks often lack real-world complexity and are thus unable to accurately assess LLMs' cybersecurity capabilities. To address this gap, we introduce PACEbench, a practical AI cyber-exploitation benchmark built on the principles of realistic vulnerability difficulty, environmental complexity, and cyber defenses. Specifically, PACEbench comprises four scenarios spanning single, blended, chained, and defense vulnerability exploitations. To handle these complex challenges, we propose PACEagent, a novel agent that emulates human penetration testers by supporting multi-phase reconnaissance, analysis, and exploitation. Extensive experiments with seven frontier LLMs demonstrate that current models struggle with complex cyber scenarios, and none can bypass defenses. These findings suggest that current models do not yet pose a generalized cyber offense threat. Nonetheless, our work provides a robust benchmark to guide the trustworthy development of future models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11688","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.021789","language":"en","tags":["computer-science","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Zicheng Liu, Lige Huang, Jie Zhang, Dongrui Liu, Yuan Tian, Jing Shao","raw_content_length":1164,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","PACEbench"],"persons":[],"locations":[],"monetary":[]},"char_count":1163,"language_detected":"en","key_concepts":{"key_phrases":["PACEbench","A Framework","Practical AI Cyber","arXiv251011688v1 Announce Type","new Abstract","The increasing autonomy","Large Language Models","LLMs","a rigorous evaluation","their potential"],"filter_categories":{"ai_ml":["Practical AI Cyber","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PACEbench":3.0,"A Framework":2.0,"Practical AI Cyber":2.0,"arXiv251011688v1 Announce Type":1.0,"new Abstract":1.0,"The increasing autonomy":1.0,"Large Language Models":1.0,"LLMs":1.0,"a rigorous evaluation":1.0,"their potential":1.0}},"age_hours":2.7607921880555555,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2850000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.743,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8032,"joy":0.0131,"surprise":0.0236,"sadness":0.008,"fear":0.1153,"anger":0.0303,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for evaluating AI's cybersecurity capabilities. While it doesn't directly address climate change, it could indirectly contribute by securing infrastructure related to sustainable technologies. The research is in the early stages, with no deployed technology or measured environmental outcomes.","key_impact_metrics":["None"],"technology_tags":["AI","Cybersecurity","Large Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:07:26.448143Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f0ddff61c6e","title":"Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim","content":"arXiv:2510.11689v1 Announce Type: new Abstract: Learning robotic manipulation policies directly in the real world can be expensive and time-consuming. While reinforcement learning (RL) policies trained in simulation present a scalable alternative, effective sim-to-real transfer remains challenging, particularly for tasks that require precise dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL pipeline that combines vision-language model (VLM)-inferred physical parameter estimates with interactive adaptation through uncertainty-aware fusion. Our approach consists of three core components: (1) high-fidelity geometric reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions over physical parameters, and (3) online physical parameter estimation from interaction data. Phys2Real conditions policies on interpretable physical parameters, refining VLM predictions with online estimates via ensemble-based uncertainty quantification. On planar pushing tasks of a T-block with varying center of mass (CoM) and a hammer with an off-center mass distribution, Phys2Real achieves substantial improvements over a domain randomization baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23% in the challenging top-weighted T-block, and 15% faster average task completion for hammer pushing. Ablation studies indicate that the combination of VLM and interaction information is essential for success. Project website: https://phys2real.github.io/ .","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11689","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.022184","language":"en","tags":["computer-science","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Maggie Wang, Stephen Tian, Aiden Swann, Ola Shorinwa, Jiajun Wu, Mac Schwager","raw_content_length":1510,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["VLM"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1509,"language_detected":"en","key_concepts":{"key_phrases":["VLM Priors","Interactive Online Adaptation","Uncertainty-Aware Sim","arXiv251011689v1 Announce Type","new Abstract","robotic manipulation policies","the real world","reinforcement learning RL policies","simulation","a scalable alternative"],"filter_categories":{"ai_ml":["Uncertainty-Aware Sim","reinforcement learning RL policies"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VLM Priors":2.0,"Interactive Online Adaptation":2.0,"Uncertainty-Aware Sim":2.0,"arXiv251011689v1 Announce Type":1.0,"new Abstract":1.0,"robotic manipulation policies":1.0,"the real world":1.0,"reinforcement learning RL policies":1.0,"simulation":1.0,"a scalable alternative":1.0}},"age_hours":2.760807698611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5594,"joy":0.0087,"surprise":0.0169,"sadness":0.027,"fear":0.3215,"anger":0.0455,"disgust":0.021},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving sim-to-real transfer for robotics, which could potentially reduce the cost and time associated with real-world robot training. The article presents measurable outcomes in terms of success rates and task completion time compared to a baseline, but it's still in the applied research stage with no real-world deployments. The impact on climate is indirect, as it could potentially enable more efficient automation in various sectors, but this is not quantified.","key_impact_metrics":["100% vs 79% success rate for the bottom-weighted T-block","15% faster average task completion for hammer pushing"],"technology_tags":["Reinforcement Learning","Robotics","Simulation","Vision-Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:30.014709Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_71b6a4073b10","title":"Diffusion Transformers with Representation Autoencoders","content":"arXiv:2510.11690v1 Announce Type: new Abstract: Latent generative modeling, where a pretrained autoencoder maps pixels into a latent space for the diffusion process, has become the standard strategy for Diffusion Transformers (DiT); however, the autoencoder component has barely evolved. Most DiTs continue to rely on the original VAE encoder, which introduces several limitations: outdated backbones that compromise architectural simplicity, low-dimensional latent spaces that restrict information capacity, and weak representations that result from purely reconstruction-based training and ultimately limit generative quality. In this work, we explore replacing the VAE with pretrained representation encoders (e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term Representation Autoencoders (RAEs). These models provide both high-quality reconstructions and semantically rich latent spaces, while allowing for a scalable transformer-based architecture. Since these latent spaces are typically high-dimensional, a key challenge is enabling diffusion transformers to operate effectively within them. We analyze the sources of this difficulty, propose theoretically motivated solutions, and validate them empirically. Our approach achieves faster convergence without auxiliary representation alignment losses. Using a DiT variant equipped with a lightweight, wide DDT head, we achieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no guidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers clear advantages and should be the new default for diffusion transformer training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11690","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.022606","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Boyang Zheng, Nanye Ma, Shengbang Tong, Saining Xie","raw_content_length":1635,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":["DINO","MAE","Diffusion Transformers","VAE","DiT"],"persons":["Representation Autoencoders","DiTs"],"locations":["SigLIP"],"monetary":[]},"char_count":1634,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Transformers","Representation Autoencoders","arXiv251011690v1 Announce Type","new Abstract","Latent generative modeling","a pretrained autoencoder maps","a latent space","the diffusion process","the standard strategy","DiT"],"filter_categories":{"ai_ml":["Diffusion Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Transformers":3.0,"Representation Autoencoders":2.0,"arXiv251011690v1 Announce Type":1.0,"new Abstract":1.0,"Latent generative modeling":1.0,"a pretrained autoencoder maps":1.0,"a latent space":1.0,"the diffusion process":1.0,"the standard strategy":1.0,"DiT":1.0}},"age_hours":2.760821698333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9159,"joy":0.0044,"surprise":0.0464,"sadness":0.0092,"fear":0.0039,"anger":0.0085,"disgust":0.0118},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to diffusion transformers, achieving improved image generation results as measured by FID scores (1.51 at 256x256, 1.13 at 256x256 and 512x512). While the research is promising, it is still in the early stages of development and lacks concrete deployment or economic viability data. The climate impact is indirect, as improved image generation itself doesn't directly reduce emissions, but could potentially improve efficiency in other AI applications that do.","key_impact_metrics":["FID at 256x256: 1.51","FID at 512x512: 1.13"],"technology_tags":["Diffusion Transformers","Representation Autoencoders","Generative AI"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:07:33.844049Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_59a1a1ec0faf","title":"Tight Regret Upper and Lower Bounds for Optimistic Hedge in Two","content":"arXiv:2510.11691v1 Announce Type: new Abstract: In two-player zero-sum games, the learning dynamic based on optimistic Hedge achieves one of the best-known regret upper bounds among strongly-uncoupled learning dynamics. With an appropriately chosen learning rate, the social and individual regrets can be bounded by $O(\\log(mn))$ in terms of the numbers of actions $m$ and $n$ of the two players. This study investigates the optimality of the dependence on $m$ and $n$ in the regret of optimistic Hedge. To this end, we begin by refining existing regret analysis and show that, in the strongly-uncoupled setting where the opponent's number of actions is known, both the social and individual regret bounds can be improved to $O(\\sqrt{\\log m \\log n})$. In this analysis, we express the regret upper bound as an optimization problem with respect to the learning rates and the coefficients of certain negative terms, enabling refined analysis of the leading constants. We then show that the existing social regret bound as well as these new social and individual regret upper bounds cannot be further improved for optimistic Hedge by providing algorithm-dependent individual regret lower bounds. Importantly, these social regret upper and lower bounds match exactly including the constant factor in the leading term. Finally, building on these results, we improve the last-iterate convergence rate and the dynamic regret of a learning dynamic based on optimistic Hedge, and complement these bounds with algorithm-dependent dynamic regret lower bounds that match the improved bounds.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11691","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.023015","language":"en","tags":["statml","computer-science","cslg","preprints","csgt","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Taira Tsuchiya","raw_content_length":1580,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["Lower Bounds for Optimistic Hedge","Tight Regret Upper","Hedge"],"persons":[],"locations":[],"monetary":[]},"char_count":1579,"language_detected":"en","key_concepts":{"key_phrases":["Tight Regret Upper","Lower Bounds","Optimistic Hedge","arXiv251011691v1 Announce Type","new Abstract","two-player zero-sum games","the learning dynamic","optimistic Hedge","the best-known regret upper bounds","strongly-uncoupled learning dynamics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tight Regret Upper":2.0,"Lower Bounds":2.0,"Optimistic Hedge":2.0,"arXiv251011691v1 Announce Type":1.0,"new Abstract":1.0,"two-player zero-sum games":1.0,"the learning dynamic":1.0,"optimistic Hedge":1.0,"the best-known regret upper bounds":1.0,"strongly-uncoupled learning dynamics":1.0}},"age_hours":2.7608375863888885,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3394,"joy":0.0087,"surprise":0.0074,"sadness":0.5911,"fear":0.0038,"anger":0.0264,"disgust":0.0232},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article presents theoretical improvements to an algorithm used in game theory. While the improved algorithm could potentially be applied to resource allocation problems relevant to sustainability, there are no concrete actions or deployments described, and the impact on climate or other sustainability dimensions is indirect and speculative. The technical credibility is relatively high due to the mathematical nature of the work and the potential for peer review.","key_impact_metrics":["Regret bound improved to O(log m log n)","Improved last-iterate convergence rate"],"technology_tags":["Optimistic Hedge algorithm","Game theory","Learning dynamics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:37.563752Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_04acdf8cda8d","title":"Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real","content":"arXiv:2510.11692v1 Announce Type: new Abstract: We present an analysis on the convergence properties of the so-called geometric heat flow equation for computing geodesics (shortest-path~curves) on Riemannian manifolds. Computing geodesics numerically in real-time has become an important capability in several fields, including control and motion planning. The geometric heat flow equation involves solving a parabolic partial differential equation whose solution is a geodesic. In practice, solving this PDE numerically can be done efficiently, and tends to be more numerically stable and exhibit a better rate of convergence compared to numerical optimization. We prove that the geometric heat flow equation is globally exponentially stable in $L_2$ if the curvature of the Riemannian manifold is not too positive, and that asymptotic convergence in $L_2$ is always guaranteed. We also present a pseudospectral method that leverages Chebyshev polynomials to accurately compute geodesics in only a few milliseconds for non-contrived manifolds. Our analysis was verified with our custom pseudospectral method by computing geodesics on common non-Euclidean surfaces, and in feedback for a contraction-based controller with a non-flat metric for a nonlinear system.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11692","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.023398","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Samuel G. Gessow, Brett T. Lopez","raw_content_length":1264,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["PDE"],"persons":[],"locations":[],"monetary":["$L_2$"]},"char_count":1263,"language_detected":"en","key_concepts":{"key_phrases":["Analysis","the Geometric Heat Flow Equation","Computing Geodesics","arXiv251011692v1 Announce Type","new Abstract","an analysis","the convergence properties","the so-called geometric heat flow equation","geodesics","shortest-path"],"filter_categories":{"business_innovation":["Analysis"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Analysis":2.0,"the Geometric Heat Flow Equation":2.0,"Computing Geodesics":2.0,"arXiv251011692v1 Announce Type":1.0,"new Abstract":1.0,"an analysis":1.0,"the convergence properties":1.0,"the so-called geometric heat flow equation":1.0,"geodesics":1.0,"shortest-path":1.0}},"age_hours":2.760852916111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8872,"joy":0.0246,"surprise":0.0485,"sadness":0.0076,"fear":0.0104,"anger":0.0155,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an analysis of an algorithm for computing geodesics. While the algorithm is verified with a custom method and used in a controller, it is still in the early stages of development and lacks real-world deployment data. The impact on sustainability is indirect, potentially enabling more efficient control systems, but not directly reducing emissions or addressing climate change.","key_impact_metrics":["milliseconds for geodesic computation"],"technology_tags":["geometric heat flow","pseudospectral method","geodesics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:40.797937Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9d1c7e1704d0","title":"Scaling Language","content":"arXiv:2510.11693v1 Announce Type: new Abstract: Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approaches stems from implicit cross-modal alignment achieved during generative pretraining, where the language decoder learns to exploit multimodal signals within a shared representation space for generating unimodal outputs. Through analysis of anisotropy and kernel similarity structure, we empirically confirm that latent alignment emerges within MLLM representations, allowing CL to serve as a lightweight refinement stage. Leveraging this insight, we propose a Language-Centric Omnimodal Embedding framework, termed LCO-Emb. Extensive experiments across diverse backbones and benchmarks demonstrate its effectiveness, achieving state-of-the-art performance across modalities. Furthermore, we identify a Generation-Representation Scaling Law (GRSL), showing that the representational capabilities gained through contrastive refinement scales positively with the MLLM's generative capabilities. This suggests that improving generative abilities evolves as an effective paradigm for enhancing representation quality. We provide a theoretical explanation of GRSL, which formally links the MLLM's generative quality to the upper bound on its representation performance, and validate it on a challenging, low-resource visual-document retrieval task, showing that continual generative pretraining before CL can further enhance the potential of a model's embedding capabilities. Codes, models, and resources are available at https://github.com/LCO-Embedding/LCO-Embedding.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11693","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.023831","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Chenghao Xiao, Hou Pong Chan, Hao Zhang, Weiwen Xu, Mahani Aljunied, Yu Rong","raw_content_length":1812,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["LCO-Emb","Language-Centric Omnimodal Embedding"],"persons":[],"locations":[],"monetary":[]},"char_count":1811,"language_detected":"en","key_concepts":{"key_phrases":["Scaling","Language","arXiv251011693v1 Announce Type","new Abstract","Recent multimodal embedding approaches","multimodal large language models","MLLMs","contrastive learning","promising results","the underlying reasons"],"filter_categories":{"ai_ml":["Language","multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scaling":2.0,"Language":2.0,"arXiv251011693v1 Announce Type":1.0,"new Abstract":1.0,"Recent multimodal embedding approaches":1.0,"multimodal large language models":1.0,"MLLMs":1.0,"contrastive learning":1.0,"promising results":1.0,"the underlying reasons":1.0}},"age_hours":2.7608668422222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8647,"joy":0.0279,"surprise":0.0387,"sadness":0.0164,"fear":0.0092,"anger":0.025,"disgust":0.018},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to multimodal embedding using large language models. While the research shows promising results in improving representation quality, it is still in the early stages of development with no deployed technology or measured environmental outcomes. The potential climate impact is currently theoretical and requires further research to determine its real-world applicability.","key_impact_metrics":["State-of-the-art performance across modalities"],"technology_tags":["Multimodal Large Language Models","Contrastive Learning","Omnimodal Embedding"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:07:44.315491Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_87bc2297cc91","title":"When Agents Trade: Live Multi","content":"arXiv:2510.11695v1 Announce Type: new Abstract: Although Large Language Model (LLM)-based agents are increasingly used in financial trading, it remains unclear whether they can reason and adapt in live markets, as most studies test models instead of agents, cover limited periods and assets, and rely on unverified data. To address these gaps, we introduce Agent Market Arena (AMA), the first lifelong, real-time benchmark for evaluating LLM-based trading agents across multiple markets. AMA integrates verified trading data, expert-checked news, and diverse agent architectures within a unified trading framework, enabling fair and continuous comparison under real conditions. It implements four agents, including InvestorAgent as a single-agent baseline, TradeAgent and HedgeFundAgent with different risk styles, and DeepFundAgent with memory-based reasoning, and evaluates them across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets demonstrate that agent frameworks display markedly distinct behavioral patterns, spanning from aggressive risk-taking to conservative decision-making, whereas model backbones contribute less to outcome variation. AMA thus establishes a foundation for rigorous, reproducible, and continuously evolving evaluation of financial reasoning and trading intelligence in LLM-based agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11695","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.024598","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Lingfei Qian, Xueqing Peng, Yan Wang, Vincent Jim Zhang, Huan He, Hanley Smith, Yi Han, Yueru He, Haohang Li, Yupeng Cao, Yangyang Yu, Alejandro Lopez-Lira, Peng Lu, Jian-Yun Nie, Guojun Xiong, Jimin Huang, Sophia Ananiadou","raw_content_length":1401,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["InvestorAgent","AMA","LLM","TradeAgent"],"persons":["Market Arena","Claude-sonnet-4"],"locations":[],"monetary":[]},"char_count":1400,"language_detected":"en","key_concepts":{"key_phrases":["When Agents Trade","Live Multi","arXiv251011695v1 Announce Type","new Abstract","Large Language Model LLM-based agents","financial trading","live markets","agents","limited periods","assets"],"filter_categories":{"ai_ml":["Large Language Model LLM-based agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"When Agents Trade":2.0,"Live Multi":2.0,"arXiv251011695v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Model LLM-based agents":1.0,"financial trading":1.0,"live markets":1.0,"agents":1.0,"limited periods":1.0,"assets":1.0}},"age_hours":2.7608979244444445,"is_recent":true,"quality_score":1.0,"sentiment_score":3.5199999999999996,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.296,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9153,"joy":0.0065,"surprise":0.0457,"sadness":0.0036,"fear":0.0114,"anger":0.0137,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a benchmark (AMA) for evaluating LLM-based trading agents in live markets. While it uses real-time data and evaluates different agent architectures, it's still in the early stages of development and deployment. The impact on sustainability is indirect, as it focuses on financial trading strategies, and there's no concrete evidence of emissions reduction or other environmental benefits.","key_impact_metrics":["Distinct behavioral patterns","Aggressive risk-taking to conservative decision-making"],"technology_tags":["Large Language Models","Financial Trading Agents"],"sdg_alignment":[8,9],"analyzed_at":"2025-10-29T12:07:47.909241Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0597165ac153","title":"QeRL: Beyond Efficiency -","content":"arXiv:2510.11696v1 Announce Type: new Abstract: We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for large language models (LLMs). While RL is essential for LLMs' reasoning capabilities, it is resource-intensive, requiring substantial GPU memory and long rollout durations. QeRL addresses these issues by combining NVFP4 quantization with Low-Rank Adaptation (LoRA), accelerating rollout phase of RL while reducing memory overhead. Beyond efficiency, our findings show that quantization noise increases policy entropy, enhancing exploration, and enabling the discovery of better strategies during RL. To further optimize exploration, QeRL introduces an Adaptive Quantization Noise (AQN) mechanism, which dynamically adjusts noise during training. Experiments demonstrate that QeRL delivers over 1.5 times speedup in the rollout phase. Moreover, this is the first framework to enable RL training of a 32B LLM on a single H100 80GB GPU, while delivering overall speedups for RL training. It also achieves faster reward growth and higher final accuracy than 16-bit LoRA and QLoRA, while matching the performance of full-parameter fine-tuning on mathematical benchmarks such as GSM8K (90.8%) and MATH 500 (77.4%) in the 7B model. These results establish QeRL as an efficient and effective framework for RL training in LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11696","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.024991","language":"en","tags":["computer-science","cslg","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Wei Huang, Yi Ge, Shuai Yang, Yicheng Xiao, Huizi Mao, Yujun Lin, Hanrong Ye, Sifei Liu, Ka Chun Cheung, Hongxu Yin, Yao Lu, Xiaojuan Qi, Song Han, Yukang Chen","raw_content_length":1345,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Quantization Noise","LoRA","QeRL","Reinforcement Learning","AQN","GPU"],"persons":[],"locations":[],"monetary":[]},"char_count":1344,"language_detected":"en","key_concepts":{"key_phrases":["QeRL","Efficiency","arXiv251011696v1","Announce Type","new Abstract","a Quantization-enhanced Reinforcement Learning framework","large language models","LLMs","LLMs reasoning capabilities","substantial GPU memory"],"filter_categories":{"ai_ml":["a Quantization-enhanced Reinforcement Learning framework","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"QeRL":3.0,"Efficiency":2.0,"arXiv251011696v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"a Quantization-enhanced Reinforcement Learning framework":1.0,"large language models":1.0,"LLMs":1.0,"LLMs reasoning capabilities":1.0,"substantial GPU memory":1.0}},"age_hours":2.7609131955555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8972,"joy":0.0279,"surprise":0.0313,"sadness":0.0109,"fear":0.0068,"anger":0.019,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (QeRL) to improve the efficiency of training large language models, specifically reducing GPU memory usage and accelerating the rollout phase. It achieves over 1.5 times speedup in the rollout phase and enables RL training of a 32B LLM on a single H100 80GB GPU. The climate impact is indirect, stemming from potentially reducing the energy consumption associated with training large AI models, but this is theoretical at this stage.","key_impact_metrics":["1.5 times speedup in rollout phase","32B LLM training on single H100 80GB GPU"],"technology_tags":["Quantization","Reinforcement Learning","Large Language Models","Low-Rank Adaptation"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:07:52.100002Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f5631b17901","title":"Demystifying Reinforcement Learning in Agentic Reasoning","content":"arXiv:2510.11701v1 Announce Type: new Abstract: Recently, the emergence of agentic RL has showcased that RL could also effectively improve the agentic reasoning ability of LLMs, yet the key design principles and optimal practices remain unclear. In this work, we conduct a comprehensive and systematic investigation to demystify reinforcement learning in agentic reasoning from three key perspectives: data, algorithm, and reasoning mode. We highlight our key insights: (i) Replacing stitched synthetic trajectories with real end-to-end tool-use trajectories yields a far stronger SFT initialization; high-diversity, model-aware datasets sustain exploration and markedly improve RL performance. (ii) Exploration-friendly techniques are crucial for agentic RL, such as clip higher, overlong reward shaping, and maintaining adequate policy entropy could improve the training efficiency. (iii) A deliberative strategy with fewer tool calls outperforms frequent tool calls or verbose self-reasoning, improving tool efficiency and final accuracy. Together, these simple practices consistently enhance agentic reasoning and training efficiency, achieving strong results on challenging benchmarks with smaller models, and establishing a practical baseline for future agentic RL research. Beyond these empirical insights, we further contribute a high-quality, real end-to-end agentic SFT dataset along with a high-quality RL dataset, and demonstrate the effectiveness of our insights in boosting the agentic reasoning ability of LLMs across four challenging benchmarks, including AIME2024/AIME2025, GPQA-Diamond, and LiveCodeBench-v6. With our recipes, 4B-sized models could also achieve superior agentic reasoning performance compared to 32B-sized models. Code and models: https://github.com/Gen-Verse/Open-AgentRL","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11701","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.025768","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Zhaochen Yu, Ling Yang, Jiaru Zou, Shuicheng Yan, Mengdi Wang","raw_content_length":1808,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["SFT","Demystifying Reinforcement Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1807,"language_detected":"en","key_concepts":{"key_phrases":["Reinforcement Learning","Agentic Reasoning","arXiv251011701v1 Announce Type","new Abstract","the emergence","agentic RL","the agentic reasoning ability","LLMs","the key design principles","optimal practices"],"filter_categories":{"ai_ml":["Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reinforcement Learning":2.0,"Agentic Reasoning":2.0,"arXiv251011701v1 Announce Type":1.0,"new Abstract":1.0,"the emergence":1.0,"agentic RL":1.0,"the agentic reasoning ability":1.0,"LLMs":1.0,"the key design principles":1.0,"optimal practices":1.0}},"age_hours":2.760941192222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9001,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8852,"joy":0.02,"surprise":0.0502,"sadness":0.0068,"fear":0.012,"anger":0.0171,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of agentic reasoning in LLMs using reinforcement learning. The concrete action is the development of new techniques and datasets that allow smaller models (4B parameters) to achieve performance comparable to larger models (32B parameters), potentially reducing the energy consumption associated with training and running large language models. While promising, the impact on climate is indirect and depends on the broader adoption and energy efficiency of LLMs.","key_impact_metrics":["4B-sized models achieve superior agentic reasoning performance compared to 32B-sized models","Improved training efficiency"],"technology_tags":["Reinforcement Learning","Large Language Models","Agentic Reasoning"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-29T12:07:55.993868Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_061223865dab","title":"Bayesian Topological Convolutional Neural Nets","content":"arXiv:2510.11704v1 Announce Type: new Abstract: Convolutional neural networks (CNNs) have been established as the main workhorse in image data processing; nonetheless, they require large amounts of data to train, often produce overconfident predictions, and frequently lack the ability to quantify the uncertainty of their predictions. To address these concerns, we propose a new Bayesian topological CNN that promotes a novel interplay between topology-aware learning and Bayesian sampling. Specifically, it utilizes information from important manifolds to accelerate training while reducing calibration error by placing prior distributions on network parameters and properly learning appropriate posteriors. One important contribution of our work is the inclusion of a consistency condition in the learning cost, which can effectively modify the prior distributions to improve the performance of our novel network architecture. We evaluate the model on benchmark image classification datasets and demonstrate its superiority over conventional CNNs, Bayesian neural networks (BNNs), and topological CNNs. In particular, we supply evidence that our method provides an advantage in situations where training data is limited or corrupted. Furthermore, we show that the new model allows for better uncertainty quantification than standard BNNs since it can more readily identify examples of out-of-distribution data on which it has not been trained. Our results highlight the potential of our novel hybrid approach for more efficient and robust image classification.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11704","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.026161","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Sarah Harkins Dayton, Hayden Everett, Ioannis Schizas, David L. Boothe Jr., Vasileios Maroulas","raw_content_length":1564,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["Bayesian Topological Convolutional Neural Nets arXiv:2510.11704v1","CNN"],"persons":[],"locations":[],"monetary":[]},"char_count":1563,"language_detected":"en","key_concepts":{"key_phrases":["Bayesian Topological Convolutional Neural Nets","arXiv251011704v1 Announce Type","new Abstract","Convolutional neural networks","CNNs","the main workhorse","image data processing","large amounts","data","overconfident predictions"],"filter_categories":{"ai_ml":["Convolutional neural networks","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bayesian Topological Convolutional Neural Nets":2.0,"arXiv251011704v1 Announce Type":1.0,"new Abstract":1.0,"Convolutional neural networks":1.0,"CNNs":1.0,"the main workhorse":1.0,"image data processing":1.0,"large amounts":1.0,"data":1.0,"overconfident predictions":1.0}},"age_hours":2.7609552,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.794,"joy":0.0067,"surprise":0.0177,"sadness":0.0152,"fear":0.134,"anger":0.0211,"disgust":0.0112},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel Bayesian topological CNN architecture that improves image classification accuracy and uncertainty quantification, particularly in data-limited scenarios. While the research demonstrates improved performance on benchmark datasets, it remains in the early stages of development with no deployed applications or quantified climate impact. The potential for sustainability impact is indirect, relying on the application of improved image classification to areas like environmental monitoring or resource optimization.","key_impact_metrics":["Reduced calibration error","Improved uncertainty quantification"],"technology_tags":["Convolutional Neural Networks","Bayesian Learning","Topological Data Analysis","Image Classification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:07:59.373897Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_10db3adf0d11","title":"Adversarial Attacks Leverage Interference Between Features in Superposition","content":"arXiv:2510.11709v1 Announce Type: new Abstract: Fundamental questions remain about when and why adversarial examples arise in neural networks, with competing views characterising them either as artifacts of the irregularities in the decision landscape or as products of sensitivity to non-robust input features. In this paper, we instead argue that adversarial vulnerability can stem from efficient information encoding in neural networks. Specifically, we show how superposition - where networks represent more features than they have dimensions - creates arrangements of latent representations that adversaries can exploit. We demonstrate that adversarial perturbations leverage interference between superposed features, making attack patterns predictable from feature arrangements. Our framework provides a mechanistic explanation for two known phenomena: adversarial attack transferability between models with similar training regimes and class-specific vulnerability patterns. In synthetic settings with precisely controlled superposition, we establish that superposition suffices to create adversarial vulnerability. We then demonstrate that these findings persist in a ViT trained on CIFAR-10. These findings reveal adversarial vulnerability can be a byproduct of networks' representational compression, rather than flaws in the learning process or non-robust inputs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11709","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.026563","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Edward Stevinson, Lucas Prieto, Melih Barsbey, Tolga Birdal","raw_content_length":1375,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1374,"language_detected":"en","key_concepts":{"key_phrases":["Adversarial Attacks Leverage Interference","Features","Superposition","neural networks","new Abstract","Fundamental questions","adversarial examples","competing views","them","artifacts"],"filter_categories":{"ai_ml":["neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adversarial Attacks Leverage Interference":2.0,"Features":2.0,"Superposition":2.0,"neural networks":2.0,"new Abstract":1.0,"Fundamental questions":1.0,"adversarial examples":1.0,"competing views":1.0,"them":1.0,"artifacts":1.0}},"age_hours":2.7609688730555555,"is_recent":true,"quality_score":0.7,"sentiment_score":0.64,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.872,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8619,"joy":0.0089,"surprise":0.0219,"sadness":0.0088,"fear":0.0462,"anger":0.0361,"disgust":0.0161},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents research on adversarial vulnerabilities in neural networks, specifically how superposition can be exploited. While the research is technically sound and potentially impactful for improving the robustness of AI systems, it is currently in the basic research stage with no direct deployment or measurable climate impact. The connection to sustainability is indirect, as more robust AI could potentially improve the efficiency of climate models or optimize resource allocation, but this is speculative at this stage.","key_impact_metrics":[],"technology_tags":["neural networks","adversarial attacks","machine learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:08:02.731949Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d593ab33e5dd","title":"Reinforced sequential Monte Carlo for amortised sampling","content":"arXiv:2510.11711v1 Announce Type: new Abstract: This paper proposes a synergy of amortised and particle-based methods for sampling from distributions defined by unnormalised density functions. We state a connection between sequential Monte Carlo (SMC) and neural sequential samplers trained by maximum-entropy reinforcement learning (MaxEnt RL), wherein learnt sampling policies and value functions define proposal kernels and twist functions. Exploiting this connection, we introduce an off-policy RL training procedure for the sampler that uses samples from SMC -- using the learnt sampler as a proposal -- as a behaviour policy that better explores the target distribution. We describe techniques for stable joint training of proposals and twist functions and an adaptive weight tempering scheme to reduce training signal variance. Furthermore, building upon past attempts to use experience replay to guide the training of neural samplers, we derive a way to combine historical samples with annealed importance sampling weights within a replay buffer. On synthetic multi-modal targets (in both continuous and discrete spaces) and the Boltzmann distribution of alanine dipeptide conformations, we demonstrate improvements in approximating the true distribution as well as training stability compared to both amortised and Monte Carlo methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11711","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.026953","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Sanghyeok Choi, Sarthak Mittal, V\\'ictor Elvira, Jinkyoo Park, Nikolay Malkin","raw_content_length":1345,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["SMC"],"persons":["wherein learnt","Monte Carlo","MaxEnt RL"],"locations":[],"monetary":[]},"char_count":1344,"language_detected":"en","key_concepts":{"key_phrases":["Reinforced sequential Monte Carlo","amortised sampling","arXiv251011711v1 Announce Type","new Abstract","This paper","a synergy","amortised and particle-based methods","distributions","unnormalised density functions","a connection"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reinforced sequential Monte Carlo":2.0,"amortised sampling":2.0,"arXiv251011711v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"a synergy":1.0,"amortised and particle-based methods":1.0,"distributions":1.0,"unnormalised density functions":1.0,"a connection":1.0}},"age_hours":2.760983578888889,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.849,"joy":0.0494,"surprise":0.0747,"sadness":0.0056,"fear":0.0043,"anger":0.0109,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for improving sampling from complex distributions, which could potentially improve the efficiency of simulations used in materials science and drug discovery, indirectly impacting sustainability by accelerating research. The method is validated on synthetic and molecular datasets, demonstrating improvements in approximation accuracy and training stability, but is still in the applied research phase with no real-world deployment.","key_impact_metrics":["Improvements in approximating the true distribution","Improvements in training stability"],"technology_tags":["Reinforcement Learning","Sequential Monte Carlo","Amortised Sampling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:06.272605Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_efc306647287","title":"DiT360: High","content":"arXiv:2510.11712v1 Announce Type: new Abstract: In this work, we propose DiT360, a DiT-based framework that performs hybrid training on perspective and panoramic data for panoramic image generation. For the issues of maintaining geometric fidelity and photorealism in generation quality, we attribute the main reason to the lack of large-scale, high-quality, real-world panoramic data, where such a data-centric view differs from prior methods that focus on model design. Basically, DiT360 has several key modules for inter-domain transformation and intra-domain augmentation, applied at both the pre-VAE image level and the post-VAE token level. At the image level, we incorporate cross-domain knowledge through perspective image guidance and panoramic refinement, which enhance perceptual quality while regularizing diversity and photorealism. At the token level, hybrid supervision is applied across multiple modules, which include circular padding for boundary continuity, yaw loss for rotational robustness, and cube loss for distortion awareness. Extensive experiments on text-to-panorama, inpainting, and outpainting tasks demonstrate that our method achieves better boundary consistency and image fidelity across eleven quantitative metrics. Our code is available at https://github.com/Insta360-Research-Team/DiT360.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11712","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.027350","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Haoran Feng, Dizhe Zhang, Xiangtai Li, Bo Du, Lu Qi","raw_content_length":1325,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["DiT360","DiT"],"persons":["yaw loss f"],"locations":[],"monetary":[]},"char_count":1324,"language_detected":"en","key_concepts":{"key_phrases":["DiT360","arXiv251011712v1 Announce Type","new Abstract","this work","a DiT-based framework","hybrid training","perspective and panoramic data","panoramic image generation","the issues","geometric fidelity"],"filter_categories":{"ai_ml":["hybrid training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DiT360":4.0,"arXiv251011712v1 Announce Type":1.0,"new Abstract":1.0,"this work":1.0,"a DiT-based framework":1.0,"hybrid training":1.0,"perspective and panoramic data":1.0,"panoramic image generation":1.0,"the issues":1.0,"geometric fidelity":1.0}},"age_hours":2.7609988738888886,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9036,"joy":0.0193,"surprise":0.0545,"sadness":0.0068,"fear":0.0039,"anger":0.0077,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new AI framework (DiT360) for generating panoramic images. While the technology itself doesn't directly address climate change, improved image generation could potentially contribute to applications like virtual tourism reducing travel emissions, or better environmental monitoring, but these are speculative. The article provides quantitative metrics on image quality but lacks information on real-world deployment or energy consumption.","key_impact_metrics":["eleven quantitative metrics on image quality"],"technology_tags":["AI","image generation","panoramic images"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:08:09.572653Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f31bd1b932fb","title":"Are Large Reasoning Models Interruptible?","content":"arXiv:2510.11713v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) excel at complex reasoning but are traditionally evaluated in static, \"frozen world\" settings: model responses are assumed to be instantaneous, and the context of a request is presumed to be immutable over the duration of the response. While generally true for short-term tasks, the \"frozen world\" assumption breaks down in modern reasoning tasks such as assistive programming, where models may take hours to think through problems and code may change dramatically from the time the model starts thinking to the model's final output. In this work, we challenge the frozen world assumption and evaluate LRM robustness under two realistic dynamic scenarios: interruptions, which test the quality of the model's partial outputs on a limited budget, and dynamic context, which tests model adaptation to in-flight changes. Across mathematics and programming benchmarks that require long-form reasoning, static evaluations consistently overestimate robustness: even state-of-the-art LRMs, which achieve high accuracy in static settings, can fail unpredictably when interrupted or exposed to changing context, with performance dropping by up to 60% when updates are introduced late in the reasoning process. Our analysis further reveals several novel failure modes, including reasoning leakage, where models fold the reasoning into their final answer when interrupted; panic, where under time pressure models abandon reasoning entirely and return incorrect answers; and self-doubt, where performance degrades while incorporating updated information.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11713","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.027777","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Tsung-Han Wu, Mihran Miroyan, David M. Chan, Trevor Darrell, Narges Norouzi, Joseph E. Gonzalez","raw_content_length":1621,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Are Large Reasoning Models Interruptible","LRM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1620,"language_detected":"en","key_concepts":{"key_phrases":["Large Reasoning Models Interruptible","arXiv251011713v1 Announce Type","new Abstract","Large Reasoning Models","LRMs","complex reasoning","static","model responses","the context","a request"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Reasoning Models Interruptible":2.0,"arXiv251011713v1 Announce Type":1.0,"new Abstract":1.0,"Large Reasoning Models":1.0,"LRMs":1.0,"complex reasoning":1.0,"static":1.0,"model responses":1.0,"the context":1.0,"a request":1.0}},"age_hours":2.7610141875,"is_recent":true,"quality_score":1.0,"sentiment_score":8.0935,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6187,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8506,"joy":0.0028,"surprise":0.0342,"sadness":0.0068,"fear":0.0386,"anger":0.0373,"disgust":0.0297},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores the robustness of Large Reasoning Models (LRMs) under dynamic conditions, revealing performance drops of up to 60% when interrupted or exposed to changing context. While the research itself doesn't directly impact climate, improving the efficiency and reliability of AI could indirectly contribute to sustainability efforts in other sectors. The research is at a basic research stage, focusing on identifying failure modes in LRMs.","key_impact_metrics":["Performance drop under interruption: 60%"],"technology_tags":["Large Reasoning Models","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:13.101273Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3cc35eef3730","title":"Ev4DGS: Novel","content":"arXiv:2510.11717v1 Announce Type: new Abstract: Event cameras offer various advantages for novel view rendering compared to synchronously operating RGB cameras, and efficient event-based techniques supporting rigid scenes have been recently demonstrated in the literature. In the case of non-rigid objects, however, existing approaches additionally require sparse RGB inputs, which can be a substantial practical limitation; it remains unknown if similar models could be learned from event streams only. This paper sheds light on this challenging open question and introduces Ev4DGS, i.e., the first approach for novel view rendering of non-rigidly deforming objects in the explicit observation space (i.e., as RGB or greyscale images) from monocular event streams. Our method regresses a deformable 3D Gaussian Splatting representation through 1) a loss relating the outputs of the estimated model with the 2D event observation space, and 2) a coarse 3D deformation model trained from binary masks generated from events. We perform experimental comparisons on existing synthetic and newly recorded real datasets with non-rigid objects. The results demonstrate the validity of Ev4DGS and its superior performance compared to multiple naive baselines that can be applied in our setting. We will release our models and the datasets used in the evaluation for research purposes; see the project webpage: https://4dqv.mpi-inf.mpg.de/Ev4DGS/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11717","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.028554","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Takuya Nakabayashi, Navami Kairanda, Hideo Saito, Vladislav Golyanik","raw_content_length":1438,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["RGB","Novel arXiv:2510.11717v1 Announce Type: new Abstract: Event"],"persons":[],"locations":[],"monetary":[]},"char_count":1437,"language_detected":"en","key_concepts":{"key_phrases":["Ev4DGS","Novel","arXiv251011717v1 Announce Type","new Abstract","Event cameras","various advantages","novel view","RGB cameras","efficient event-based techniques","rigid scenes"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Ev4DGS":2.0,"Novel":2.0,"arXiv251011717v1 Announce Type":1.0,"new Abstract":1.0,"Event cameras":1.0,"various advantages":1.0,"novel view":1.0,"RGB cameras":1.0,"efficient event-based techniques":1.0,"rigid scenes":1.0}},"age_hours":2.761044462777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.36,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.872,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8637,"joy":0.036,"surprise":0.0641,"sadness":0.0079,"fear":0.0085,"anger":0.014,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel method (Ev4DGS) for rendering non-rigidly deforming objects from monocular event streams. While the technology itself doesn't directly address climate change, it could potentially contribute to more efficient robotics or computer vision applications in the future. It is currently in the basic research stage with experimental comparisons on synthetic and real datasets.","key_impact_metrics":["Superior performance compared to multiple naive baselines"],"technology_tags":["Event cameras","3D Gaussian Splatting","Novel view rendering"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:16.448197Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_96b8d38d0241","title":"CodePlot","content":"arXiv:2510.11718v1 Announce Type: new Abstract: Recent advances in Large Language Models (LLMs) and Vision Language Models (VLMs) have shown significant progress in mathematical reasoning, yet they still face a critical bottleneck with problems requiring visual assistance, such as drawing auxiliary lines or plotting functions to solve the problems. Most LLMs and VLMs are constrained to text-only reasoning chains, while multimodal unified models that can generate interleaved text and images lack the necessary precision and controllability for such tasks. To address this, we propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for \"thinking with images\" in mathematics. Our approach leverages the VLM to generate text reasoning as well as executable plotting code, which is then rendered into images as \"visual thought\", to solve mathematical problems. To achieve this, we first construct Math-VR, the first large-scale, bilingual dataset and benchmark for Mathematics problems with Visual Reasoning, comprising 178K samples. Second, to create high-quality training data, we develop a state-of-the-art image-to-code converter specialized for parsing complex mathematical figures into codes. Finally, using these training data, we train the CodePlot-CoT model for solving mathematical problems. Experimental results show that our model achieves up to 21% increase over base model on our new benchmark, fully validating the efficacy of our proposed code-driven reasoning paradigm. Our work opens a new direction for multimodal mathematical reasoning and provides the community with the first large-scale dataset, comprehensive benchmark, and strong approach for such problems. To facilitate future research, we make our datasets, code, and pretrained models publicly available at https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11718","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.028972","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Chengqi Duan, Kaiyue Sun, Rongyao Fang, Manyuan Zhang, Yan Feng, Ying Luo, Yufang Liu, Ke Wang, Peng Pei, Xunliang Cai, Hongsheng Li, Yi Ma, Xihui Liu","raw_content_length":1844,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","CodePlot-CoT","Vision Language Models","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1843,"language_detected":"en","key_concepts":{"key_phrases":["CodePlot","VLMs","Announce Type","new Abstract","Recent advances","Large Language Models","LLMs","Vision Language Models","significant progress","mathematical reasoning"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CodePlot":2.0,"VLMs":2.0,"Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"Large Language Models":1.0,"LLMs":1.0,"Vision Language Models":1.0,"significant progress":1.0,"mathematical reasoning":1.0}},"age_hours":2.7610595541666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8461,"joy":0.006,"surprise":0.0329,"sadness":0.0147,"fear":0.0475,"anger":0.0253,"disgust":0.0275},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to mathematical reasoning using AI. The concrete action is the development of a new model and dataset, but there are no deployed units or real-world applications yet. The evidence supporting the claims is the 21% increase over the base model on the new benchmark, but this is still in the research phase.","key_impact_metrics":["21% increase over base model"],"technology_tags":["Large Language Models","Vision Language Models","AI","Mathematical Reasoning"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:08:19.859557Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c7b87ee3a6d","title":"Detecting Conspiracy Theory Against COVID","content":"arXiv:2211.13003v1 Announce Type: cross Abstract: Since the beginning of the vaccination trial, social media has been flooded with anti-vaccination comments and conspiracy beliefs. As the day passes, the number of COVID- 19 cases increases, and online platforms and a few news portals entertain sharing different conspiracy theories. The most popular conspiracy belief was the link between the 5G network spreading COVID-19 and the Chinese government spreading the virus as a bioweapon, which initially created racial hatred. Although some disbelief has less impact on society, others create massive destruction. For example, the 5G conspiracy led to the burn of the 5G Tower, and belief in the Chinese bioweapon story promoted an attack on the Asian-Americans. Another popular conspiracy belief was that Bill Gates spread this Coronavirus disease (COVID-19) by launching a mass vaccination program to track everyone. This Conspiracy belief creates distrust issues among laypeople and creates vaccine hesitancy. This study aims to discover the conspiracy theory against the vaccine on social platforms. We performed a sentiment analysis on the 598 unique sample comments related to COVID-19 vaccines. We used two different models, BERT and Perspective API, to find out the sentiment and toxicity of the sentence toward the COVID-19 vaccine.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2211.13003","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.029366","language":"en","tags":["cslg","cscy","csai","preprints","research","cscl","computer-science","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Md Hasibul Amin (University Of Houston), Harika Madanu (University Of Houston), Sahithi Lavu (University Of Houston), Hadi Mansourifar (University Of Houston), Dana Alsagheer (University Of Houston), Weidong Shi (University Of Houston)","raw_content_length":1341,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["COVID-19","Coronavirus"],"persons":["Conspiracy","COVID-19","Announce Type","Bill Gates"],"locations":[],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["Conspiracy Theory","COVID","arXiv221113003v1 Announce Type","cross","the beginning","the vaccination trial","social media","anti-vaccination comments and conspiracy beliefs","the day","the number"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Conspiracy Theory":2.0,"COVID":2.0,"arXiv221113003v1 Announce Type":1.0,"cross":1.0,"the beginning":1.0,"the vaccination trial":1.0,"social media":1.0,"anti-vaccination comments and conspiracy beliefs":1.0,"the day":1.0,"the number":1.0}},"age_hours":2.761074373333333,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2524999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7495,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8677,"joy":0.0122,"surprise":0.0543,"sadness":0.0048,"fear":0.0277,"anger":0.0299,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":5,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article focuses on detecting conspiracy theories related to COVID-19 vaccines using sentiment analysis. While it addresses a societal problem, it doesn't directly contribute to climate change mitigation or adaptation. The study uses BERT and Perspective API to analyze 598 comments, but this is still in the research phase with no deployment or measurable environmental outcomes.","key_impact_metrics":["598 unique sample comments","Sentiment analysis using BERT and Perspective API"],"technology_tags":["Sentiment Analysis","Natural Language Processing"],"sdg_alignment":[3,16],"analyzed_at":"2025-10-29T12:08:23.106188Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f7056c2ca9df","title":"Performance of Machine Learning Methods for Gravity Inversion: Successes and Challenges","content":"arXiv:2510.09632v1 Announce Type: cross Abstract: Gravity inversion is the problem of estimating subsurface density distributions from observed gravitational field data. We consider the two-dimensional (2D) case, in which recovering density models from one-dimensional (1D) measurements leads to an underdetermined system with substantially more model parameters than measurements, making the inversion ill-posed and non-unique. Recent advances in machine learning have motivated data-driven approaches for gravity inversion. We first design a convolutional neural network (CNN) trained to directly map gravity anomalies to density fields, where a customized data structure is introduced to enhance the inversion performance. To further investigate generative modeling, we employ Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), reformulating inversion as a latent-space optimization constrained by the forward operator. In addition, we assess whether classical iterative solvers such as Gradient Descent (GD), GMRES, LGMRES, and a recently proposed Improved Conjugate Gradient (ICG) method can refine CNN-based initial guesses and improve inversion accuracy. Our results demonstrate that CNN inversion not only provides the most reliable reconstructions but also significantly outperforms previously reported methods. Generative models remain promising but unstable, and iterative solvers offer only marginal improvements, underscoring the persistent ill-posedness of gravity inversion.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09632","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.031940","language":"en","tags":["statml","cslg","physicsgeo-ph","preprints","research","csna","mathna","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Vahid Negahdari, Shirin Samadi Bahrami, Seyed Reza Moghadasi, Mohammad Reza Razvan","raw_content_length":1515,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["Generative Adversarial Networks","CNN","Challenges arXiv:2510.09632v1 Announce Type: cross","Variational Autoencoders"],"persons":[],"locations":[],"monetary":[]},"char_count":1514,"language_detected":"en","key_concepts":{"key_phrases":["Performance","Machine Learning Methods","Gravity Inversion","Successes","Challenges","Announce Type","Gravity inversion","the problem","subsurface density distributions","observed gravitational field data"],"filter_categories":{"ai_ml":["Machine Learning Methods"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Performance":2.0,"Machine Learning Methods":2.0,"Gravity Inversion":2.0,"Successes":2.0,"Challenges":2.0,"Announce Type":1.0,"Gravity inversion":1.0,"the problem":1.0,"subsurface density distributions":1.0,"observed gravitational field data":1.0}},"age_hours":2.7611628241666666,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8342,"joy":0.0095,"surprise":0.0335,"sadness":0.0387,"fear":0.0187,"anger":0.0337,"disgust":0.0317},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores machine learning methods for gravity inversion, which could potentially improve resource exploration and geological understanding. The research is at an applied research stage, with CNN inversion showing promising results. However, there's no immediate deployment or economic viability demonstrated, and the impact on climate is indirect and theoretical at this stage.","key_impact_metrics":["Inversion accuracy improvement with CNN"],"technology_tags":["Machine Learning","Gravity Inversion","Convolutional Neural Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:27.686264Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_73112d5c2a24","title":"Combining Blotto Networks and Voter Models to Simulate Voter Behavior in Response to Competitive Election Spending","content":"arXiv:2510.09697v1 Announce Type: cross Abstract: In the past, the Voter Model has been explicitly used to model the impact of propaganda on a dynamic, interconnected population, and certain factors have been identified that influence the behavior of voters when under outside influence. The Blotto Game has also been explicitly used to study information wars between two opposing parties, whether in regards to a political issue or advertising war. Both the graph theory behind the Voter Model and the game theory aspects of the Blotto Game are relevant to the behavior of voters or consumers when they are under the influence of competing propaganda campaigns, and for this reason both are useful to understand the most effective spending strategy. In this project, we seek to combine the two problems into a Voter-Blotto Game and examine what components of the graph most effect its value in the eyes of the competing players.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09697","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.032313","language":"en","tags":["physicssoc-ph","preprints","research","computer-science","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Renee Jerome","raw_content_length":930,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Simulate Voter Behavior","Voter Models"],"persons":["Blotto Networks"],"locations":[],"monetary":[]},"char_count":929,"language_detected":"en","key_concepts":{"key_phrases":["Blotto Networks","Voter Models","Simulate Voter Behavior","Response","Competitive Election Spending","the Voter Model","arXiv251009697v1 Announce Type","cross","the past","the impact"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Blotto Networks":2.0,"Voter Models":2.0,"Simulate Voter Behavior":2.0,"Response":2.0,"Competitive Election Spending":2.0,"the Voter Model":2.0,"arXiv251009697v1 Announce Type":1.0,"cross":1.0,"the past":1.0,"the impact":1.0}},"age_hours":2.7611783275,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9242,"joy":0.0087,"surprise":0.04,"sadness":0.0046,"fear":0.0049,"anger":0.0116,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a theoretical model combining the Voter Model and Blotto Game to simulate voter behavior under competing propaganda campaigns. It is currently in the basic research stage with no deployed technology or measured outcomes. The impact on sustainability is indirect, as it aims to understand information warfare, but lacks concrete actions or evidence of reducing emissions or promoting climate justice.","key_impact_metrics":[],"technology_tags":["Voter Model","Blotto Game","Agent-based Modeling"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:08:31.113237Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b32df808cdaf","title":"Leveraging Cellular Automata for Real","content":"arXiv:2510.09708v1 Announce Type: cross Abstract: Wildfires are becoming increasingly frequent and devastating, and therefore the technology to combat them must adapt accordingly. Modern predictive models have failed to balance predictive accuracy and operational viability, resulting in consistently delayed or misinformed fire suppression and public safety efforts. The present study addresses this gap by developing and validating a predictive model based on cellular automata (CA) that incorporates key environmental variables, including vegetation density (NDVI), wind speed and direction, and topographic slope derived from open-access datasets. The presented CA framework offers a lightweight alternative to data-heavy approaches that fail in emergency contexts. Evaluation of the model using a confusion matrix against burn scars from the 2025 Pacific Palisades Fire yielded a recall of 0.860, a precision of 0.605, and an overall F1 score of 0.711 after 50 parameter optimization trials, with each simulation taking an average of 1.22 seconds. CA-based models can bridge the gap between accuracy and applicability, successfully guiding public safety and fire suppression efforts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09708","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.032724","language":"en","tags":["physicssoc-ph","cscy","nlincg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Connor Weinhouse, Jameson Augustin","raw_content_length":1189,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["NDVI"],"persons":["Wildfires"],"locations":[],"monetary":[]},"char_count":1188,"language_detected":"en","key_concepts":{"key_phrases":["Cellular Automata","arXiv251009708v1 Announce Type","cross","Wildfires","the technology","them","Modern predictive models","predictive accuracy","operational viability","consistently delayed or misinformed fire suppression"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cellular Automata":2.0,"arXiv251009708v1 Announce Type":1.0,"cross":1.0,"Wildfires":1.0,"the technology":1.0,"them":1.0,"Modern predictive models":1.0,"predictive accuracy":1.0,"operational viability":1.0,"consistently delayed or misinformed fire suppression":1.0}},"age_hours":2.7611924208333334,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5330000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8934,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.348,"joy":0.0071,"surprise":0.0339,"sadness":0.2379,"fear":0.3028,"anger":0.0558,"disgust":0.0145},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a wildfire prediction model based on cellular automata, validated against a real fire event. The model achieves a recall of 0.860, a precision of 0.605, and an F1 score of 0.711, demonstrating its potential for guiding fire suppression efforts. However, it is still in the applied research stage, lacking deployment and economic viability data.","key_impact_metrics":["recall of 0.860","F1 score of 0.711"],"technology_tags":["cellular automata","wildfire prediction","NDVI"],"sdg_alignment":[13,15],"analyzed_at":"2025-10-29T12:08:34.182296Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e7c46457155","title":"Chlorophyll","content":"arXiv:2510.09736v1 Announce Type: cross Abstract: The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09736","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.033547","language":"en","tags":["eessiv","computer-science","csai","physicsao-ph","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":264,"author":"Antonio Mart\\'inez-Ibarra, Aurora Gonz\\'alez-Vidal, Adri\\'an C\\'anovas-Rodr\\'iguez, Antonio F. Skarmeta","raw_content_length":1969,"priority":7,"update_frequency":1,"reading_time_minutes":1.32,"robust_parsing_used":true,"entities":{"organizations":["C2RCC","Sentinel 2","The Mar Menor","Chlorophyll arXiv:2510.09736v1 Announce Type:"],"persons":["Chl"],"locations":["Europe","Spain"],"monetary":[]},"char_count":1968,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251009736v1 Announce Type","cross","Abstract","The Mar Menor","Europes largest coastal lagoon","Spain","severe eutrophication crises","a Chl-a","harmful algal blooms","mitigation"],"filter_categories":{"ai_ml":["Spain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251009736v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"The Mar Menor":1.0,"Europes largest coastal lagoon":1.0,"Spain":1.0,"severe eutrophication crises":1.0,"a Chl-a":1.0,"harmful algal blooms":1.0,"mitigation":1.0}},"age_hours":2.7612225708333336,"is_recent":true,"quality_score":1.0,"sentiment_score":3.5125,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2975,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5924,"joy":0.0328,"surprise":0.0303,"sadness":0.0472,"fear":0.2584,"anger":0.0276,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":6,"technical_credibility":8,"economic_viability":5,"deployment_readiness":5,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The study presents a validated methodology for depth-specific chlorophyll-a mapping using Sentinel 2 imagery and buoy data. The models achieved R2 values ranging from 0.66 to 0.89 at different depths, demonstrating a concrete ability to monitor eutrophication events. This is a pilot-stage deployment with potential for wider application in similar coastal systems.","key_impact_metrics":["R2 = 0.89 at the surface","R2 = 0.87 at 1-2 m"],"technology_tags":["Sentinel 2 imagery","Machine Learning","Eutrophication monitoring"],"sdg_alignment":[6,14],"analyzed_at":"2025-10-29T12:08:38.841466Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06378500e37a","title":"Bounds in the Projective Unitary Group with Respect to Global Phase Invariant Metric","content":"arXiv:2510.09765v1 Announce Type: cross Abstract: We consider a global phase-invariant metric in the projective unitary group PUn, relevant for universal quantum computing. We obtain the volume and measure of small metric ball in PUn and derive the Gilbert-Varshamov and Hamming bounds in PUn. In addition, we provide upper and lower bounds for the kissing radius of the codebooks in PUn as a function of the minimum distance. Using the lower bound of the kissing radius, we find a tight Hamming bound. Also, we establish bounds on the distortion-rate function for quantizing a source uniformly distributed over PUn. As example codebooks in PUn, we consider the projective Pauli and Clifford groups, as well as the projective group of diagonal gates in the Clifford hierarchy, and find their minimum distances. For any code in PUn with given cardinality we provide a lower bound of covering radius. Also, we provide expected value of the covering radius of randomly distributed points on PUn, when cardinality of code is sufficiently large. We discuss codebooks at various stages of the projective Clifford + T and projective Clifford + S constructions in PU2, and obtain their minimum distance, distortion, and covering radius. Finally, we verify the analytical results by simulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09765","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.033949","language":"en","tags":["computer-science","quant-ph","preprints","mathit","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Bhanu Pratap Yadav, Mahdi Bayanifar, Olav Tirkkonen","raw_content_length":1286,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Respect","the Projective Unitary Group","Hamming"],"persons":["Clifford"],"locations":["Pauli"],"monetary":[]},"char_count":1285,"language_detected":"en","key_concepts":{"key_phrases":["PUn","Bounds","the Projective Unitary Group","Respect","Global Phase Invariant Metric","the kissing radius","arXiv251009765v1 Announce Type","cross","Abstract","a global phase-invariant metric"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PUn":3.0,"Bounds":2.0,"the Projective Unitary Group":2.0,"Respect":2.0,"Global Phase Invariant Metric":2.0,"the kissing radius":2.0,"arXiv251009765v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"a global phase-invariant metric":1.0}},"age_hours":2.7612387686111113,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8754,"joy":0.0361,"surprise":0.0663,"sadness":0.0056,"fear":0.0035,"anger":0.0099,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical bounds and analysis of codebooks in the projective unitary group, relevant to quantum computing. While quantum computing has the potential for significant impact on various fields, including materials science and energy, this paper focuses on the theoretical underpinnings and does not present any deployed technology or measured outcomes related to sustainability. The research is at a very early stage and lacks concrete actions or evidence of impact.","key_impact_metrics":[],"technology_tags":["quantum computing","codebooks","error correction"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:08:42.500597Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_476a650a2479","title":"Rapid Development of Omics Data Analysis Applications through Vibe Coding","content":"arXiv:2510.09804v1 Announce Type: cross Abstract: Building custom data analysis platforms traditionally requires extensive software engineering expertise, limiting accessibility for many researchers. Here, I demonstrate that modern large language models (LLMs) and autonomous coding agents can dramatically lower this barrier through a process called 'vibe coding', an iterative, conversational style of software creation where users describe goals in natural language and AI agents generate, test, and refine executable code in real-time. As a proof of concept, I used Vibe coding to create a fully functional proteomics data analysis website capable of performing standard tasks, including data normalization, differential expression testing, and volcano plot visualization. The entire application, including user interface, backend logic, and data upload pipeline, was developed in less than ten minutes using only four natural-language prompts, without any manual coding, at a cost of under $2. Previous works in this area typically require tens of thousands of dollars in research effort from highly trained programmers. I detail the step-by-step generation process and evaluate the resulting code's functionality. This demonstration highlights how vibe coding enables domain experts to rapidly prototype sophisticated analytical tools, transforming the pace and accessibility of computational biology software development.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09804","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.034338","language":"en","tags":["computer-science","q-bioot","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Jesse G. Meyer","raw_content_length":1429,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["Rapid Development of Omics Data Analysis Applications"],"persons":["Announce Type"],"locations":["Vibe Coding"],"monetary":[]},"char_count":1428,"language_detected":"en","key_concepts":{"key_phrases":["Rapid Development","Omics Data Analysis Applications","Vibe Coding","arXiv251009804v1 Announce Type","cross","custom data analysis platforms","extensive software engineering expertise","accessibility","many researchers","modern large language models"],"filter_categories":{"engineering":["Rapid Development","extensive software engineering expertise"],"research_academic":["many researchers"],"ai_ml":["modern large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Rapid Development":2.0,"Omics Data Analysis Applications":2.0,"Vibe Coding":2.0,"arXiv251009804v1 Announce Type":1.0,"cross":1.0,"custom data analysis platforms":1.0,"extensive software engineering expertise":1.0,"accessibility":1.0,"many researchers":1.0,"modern large language models":1.0}},"age_hours":2.7612538325,"is_recent":true,"quality_score":1.0,"sentiment_score":4.08,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.184,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8815,"joy":0.0443,"surprise":0.0503,"sadness":0.0026,"fear":0.0083,"anger":0.009,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":7,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method for rapid application development using LLMs, demonstrated by creating a proteomics data analysis website. While the application is functional and cost-effective, it remains a prototype with no deployment or real-world impact data. The vaporware flag is raised due to the lack of deployed units or customer contracts.","key_impact_metrics":["development time of less than 10 minutes","cost of under $2"],"technology_tags":["Large Language Models","Autonomous Coding Agents","Proteomics Data Analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:46.215685Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_767c2a1d2a9b","title":"Quantum Circuit for Quantum Fourier Transform for Arbitrary Qubit Connectivity Graphs","content":"arXiv:2510.09824v1 Announce Type: cross Abstract: In the paper, we consider quantum circuits for the Quantum Fourier Transform (QFT) algorithm. The QFT algorithm is a very popular technique used in many quantum algorithms. We present a generic method for constructing quantum circuits for this algorithm implementing on quantum devices with restrictions. Many quantum devices (for example, based on superconductors) have restrictions on applying two-qubit gates. These restrictions are presented by a qubit connectivity graph. Typically, researchers consider only the linear nearest neighbor (LNN) architecture of the qubit connection, but current devices have more complex graphs. We present a method for arbitrary connected graphs that minimizes the number of CNOT gates in the circuit for implementing on such architecture. We compare quantum circuits built by our algorithm with existing quantum circuits optimized for specific graphs that are Linear-nearest-neighbor (LNN) architecture, ``sun'' (a cycle with tails, presented by the 16-qubit IBMQ device) and ``two joint suns'' (two joint cycles with tails, presented by the 27-qubit IBMQ device). Our generic method gives similar results with existing optimized circuits for ``sun'' and ``two joint suns'' architectures, and a circuit with slightly more CNOT gates for the LNN architecture. At the same time, our method allows us to construct a circuit for arbitrary connected graphs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09824","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.034768","language":"en","tags":["computer-science","quant-ph","csds","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Kamil Khadiev, Aliya Khadieva, Vadim Sagitov, Kamil Khasanov","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Quantum Circuit","QFT","LNN","the Quantum Fourier Transform"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1440,"language_detected":"en","key_concepts":{"key_phrases":["Quantum Circuit","Quantum Fourier Transform","Arbitrary Qubit Connectivity Graphs","quantum circuits","restrictions","arXiv251009824v1","Announce Type","cross","the paper","the Quantum Fourier Transform"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantum Circuit":2.0,"Quantum Fourier Transform":2.0,"Arbitrary Qubit Connectivity Graphs":2.0,"quantum circuits":2.0,"restrictions":2.0,"arXiv251009824v1":1.0,"Announce Type":1.0,"cross":1.0,"the paper":1.0,"the Quantum Fourier Transform":1.0}},"age_hours":2.7612688,"is_recent":true,"quality_score":1.0,"sentiment_score":7.377000000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4754,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8338,"joy":0.0594,"surprise":0.086,"sadness":0.0051,"fear":0.0024,"anger":0.0102,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method for optimizing quantum circuits, specifically the Quantum Fourier Transform, on quantum devices with restricted qubit connectivity. The concrete action is the development of an algorithm that minimizes the number of CNOT gates. The evidence is a comparison with existing circuits, showing similar results for some architectures, but this remains at the basic research stage with no deployment.","key_impact_metrics":["CNOT gate count","Qubit connectivity graph complexity"],"technology_tags":["Quantum Computing","Quantum Fourier Transform","Quantum Algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:49.547194Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ddffcee9d62b","title":"Learning with Incomplete Context: Linear Contextual Bandits with Pretrained Imputation","content":"arXiv:2510.09908v1 Announce Type: cross Abstract: The rise of large-scale pretrained models has made it feasible to generate predictive or synthetic features at low cost, raising the question of how to incorporate such surrogate predictions into downstream decision-making. We study this problem in the setting of online linear contextual bandits, where contexts may be complex, nonstationary, and only partially observed. In addition to bandit data, we assume access to an auxiliary dataset containing fully observed contexts--common in practice since such data are collected without adaptive interventions. We propose PULSE-UCB, an algorithm that leverages pretrained models trained on the auxiliary data to impute missing features during online decision-making. We establish regret guarantees that decompose into a standard bandit term plus an additional component reflecting pretrained model quality. In the i.i.d. context case with H\\\"older-smooth missing features, PULSE-UCB achieves near-optimal performance, supported by matching lower bounds. Our results quantify how uncertainty in predicted contexts affects decision quality and how much historical data is needed to improve downstream learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09908","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.035918","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Hao Yan, Heyan Zhang, Yongyi Guo","raw_content_length":1207,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1206,"language_detected":"en","key_concepts":{"key_phrases":["Incomplete Context","Pretrained Imputation","arXiv251009908v1 Announce Type","cross","The rise","large-scale pretrained models","predictive or synthetic features","low cost","the question","such surrogate predictions"],"filter_categories":{"ai_ml":["Pretrained Imputation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Incomplete Context":2.0,"Pretrained Imputation":2.0,"arXiv251009908v1 Announce Type":1.0,"cross":1.0,"The rise":1.0,"large-scale pretrained models":1.0,"predictive or synthetic features":1.0,"low cost":1.0,"the question":1.0,"such surrogate predictions":1.0}},"age_hours":2.761310552222222,"is_recent":true,"quality_score":0.7,"sentiment_score":1.8005,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6399,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9132,"joy":0.0084,"surprise":0.0394,"sadness":0.0057,"fear":0.0114,"anger":0.0138,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an algorithm (PULSE-UCB) for improving decision-making in online linear contextual bandits using pretrained models to impute missing features. While the algorithm shows promise in improving decision quality, it is currently in the research stage and lacks concrete deployment or measurable outcomes related to climate or sustainability. The impact is theoretical at this point.","key_impact_metrics":[],"technology_tags":["machine learning","contextual bandits","pretrained models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:52.897003Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_96a024bd939d","title":"Bounds on Eventually Universal Quantum Gate Sets","content":"arXiv:2510.09931v1 Announce Type: cross Abstract: Say a collection of $n$-qu$d$it gates $\\Gamma$ is eventually universal if and only if there exists $N_0 \\geq n$ such that for all $N \\geq N_0$, one can approximate any $N$-qu$d$it unitary to arbitrary precision by a circuit over $\\Gamma$. In this work, we improve the best known upper bound on the smallest $N_0$ with the above property. Our new bound is roughly $d^4n$, where $d$ is the local dimension (the `$d$' in qu$d$it), whereas the previous bound was roughly $d^8n$. For qubits ($d = 2$), our result implies that if an $n$-qubit gate set is eventually universal, then it will exhibit universality when acting on a $16n$ qubit system, as opposed to the previous bound of a $256n$ qubit system. In other words, if adding just $15n$ ancillary qubits to a quantum system (as opposed to the previous bound of $255 n$ ancillary qubits) does not boost a gate set to universality, then no number of ancillary qubits ever will. Our proof relies on the invariants of finite linear groups as well as a classification result for all finite groups that are unitary $2$-designs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09931","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.036695","language":"en","tags":["computer-science","quant-ph","preprints","cscc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Chaitanya Karamchedu, Matthew Fox, Daniel Gottesman","raw_content_length":1123,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["n$-qu$d$it","N$-qu$d$it","d^4n$","qu$d$it","N_0"],"locations":[],"monetary":["$N_0$","$n$-qubit gate","roughly $","just $15n$","16n$","256n$","255","\\Gamma$"]},"char_count":1122,"language_detected":"en","key_concepts":{"key_phrases":["Bounds","Eventually Universal Quantum Gate Sets","arXiv251009931v1 Announce Type","cross","Abstract","a collection","Gamma","N_0 geq","all N geq N_0","one"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bounds":2.0,"Eventually Universal Quantum Gate Sets":2.0,"arXiv251009931v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"a collection":1.0,"Gamma":1.0,"N_0 geq":1.0,"all N geq N_0":1.0,"one":1.0}},"age_hours":2.761342478888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8757,"joy":0.0316,"surprise":0.0745,"sadness":0.0046,"fear":0.0028,"anger":0.0077,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article presents theoretical improvements in quantum gate set universality, reducing the required number of qubits for universality from 256n to 16n. While this is a significant theoretical advancement, it is still in the basic research phase and has no direct, measurable impact on climate change or sustainability in its current form. The impact is indirect, as improved quantum computing could potentially accelerate the development of sustainable technologies in the future.","key_impact_metrics":["Reduction in required qubits from 256n to 16n"],"technology_tags":["Quantum Computing","Quantum Gate Sets","Quantum Universality"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:08:56.183026Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5a0b2c2ed9f6","title":"Egocentric Visual Navigation through Hippocampal Sequences","content":"arXiv:2510.09951v1 Announce Type: cross Abstract: Sequential activation of place-tuned neurons in an animal during navigation is typically interpreted as reflecting the sequence of input from adjacent positions along the trajectory. More recent theories about such place cells suggest sequences arise from abstract cognitive objectives like planning. Here, we propose a mechanistic and parsimonious interpretation to complement these ideas: hippocampal sequences arise from intrinsic recurrent circuitry that propagates activity without readily available input, acting as a temporal memory buffer for extremely sparse inputs.We implement a minimal sequence generator inspired by neurobiology and pair it with an actor-critic learner for egocentric visual navigation. Our agent reliably solves a continuous maze without explicit geometric cues, with performance depending on the length of the recurrent sequence. Crucially, the model outperforms LSTM cores under sparse input conditions (16 channels, ~2.5% activity), but not under dense input, revealing a strong interaction between representational sparsity and memory architecture.In contrast to LSTM agents, hidden sequence units develop localized place fields, distance-dependent spatial kernels, and task-dependent remapping, while inputs orthogonalize and spatial information increases across layers. These phenomena align with neurobiological data and are causal to performance. Together, our results show that sparse input synergizes with sequence-generating dynamics, providing both a mechanistic account of place cell sequences in the mammalian hippocampus and a simple inductive bias for reinforcement learning based on sparse egocentric inputs in navigation tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09951","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.037462","language":"en","tags":["cslg","preprints","research","q-bionc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Xiao-Xiong Lin, Yuk Hoi Yiu, Christian Leibold","raw_content_length":1727,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Hippocampal Sequences"],"persons":[],"locations":[],"monetary":[]},"char_count":1726,"language_detected":"en","key_concepts":{"key_phrases":["Egocentric Visual Navigation","Hippocampal Sequences","arXiv251009951v1 Announce Type","cross","Sequential activation","place-tuned neurons","an animal","navigation","the sequence","input"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Egocentric Visual Navigation":2.0,"Hippocampal Sequences":2.0,"arXiv251009951v1 Announce Type":1.0,"cross":1.0,"Sequential activation":1.0,"place-tuned neurons":1.0,"an animal":1.0,"navigation":1.0,"the sequence":1.0,"input":1.0}},"age_hours":2.761371088611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8901,"joy":0.0235,"surprise":0.0456,"sadness":0.0065,"fear":0.0095,"anger":0.012,"disgust":0.0127},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI architecture for navigation using sparse inputs, inspired by hippocampal sequences. While it shows improved performance in simulated mazes compared to LSTMs under specific conditions (16 channels, ~2.5% activity), it is currently at the basic research stage with no real-world deployment or quantified environmental impact. The potential for sustainability impact is theoretical, relying on future applications in robotics or autonomous systems that could improve efficiency or reduce resource consumption.","key_impact_metrics":["2.5% activity (input sparsity)","Performance in continuous maze"],"technology_tags":["AI","Reinforcement Learning","Egocentric Visual Navigation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:09:01.367459Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0ff38cb27d39","title":"Generative Latent Video Compression","content":"arXiv:2510.09987v1 Announce Type: cross Abstract: Perceptual optimization is widely recognized as essential for neural compression, yet balancing the rate-distortion-perception tradeoff remains challenging. This difficulty is especially pronounced in video compression, where frame-wise quality fluctuations often cause perceptually optimized neural video codecs to suffer from flickering artifacts. In this paper, inspired by the success of latent generative models, we present Generative Latent Video Compression (GLVC), an effective framework for perceptual video compression. GLVC employs a pretrained continuous tokenizer to project video frames into a perceptually aligned latent space, thereby offloading perceptual constraints from the rate-distortion optimization. We redesign the codec architecture explicitly for the latent domain, drawing on extensive insights from prior neural video codecs, and further equip it with innovations such as unified intra/inter coding and a recurrent memory mechanism. Experimental results across multiple benchmarks show that GLVC achieves state-of-the-art performance in terms of DISTS and LPIPS metrics. Notably, our user study confirms GLVC rivals the latest neural video codecs at nearly half their rate while maintaining stable temporal coherence, marking a step toward practical perceptual video compression.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09987","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.038242","language":"en","tags":["eessiv","computer-science","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Zongyu Guo, Zhaoyang Jia, Jiahao Li, Xiaoyi Zhang, Bin Li, Yan Lu","raw_content_length":1359,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1358,"language_detected":"en","key_concepts":{"key_phrases":["Generative Latent Video Compression","arXiv251009987v1","Announce Type","cross","Perceptual optimization","neural compression","the rate-distortion-perception tradeoff","This difficulty","video compression","frame-wise quality fluctuations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative Latent Video Compression":2.0,"arXiv251009987v1":1.0,"Announce Type":1.0,"cross":1.0,"Perceptual optimization":1.0,"neural compression":1.0,"the rate-distortion-perception tradeoff":1.0,"This difficulty":1.0,"video compression":1.0,"frame-wise quality fluctuations":1.0}},"age_hours":2.7613989308333333,"is_recent":true,"quality_score":0.7,"sentiment_score":8.907,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7814,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5084,"joy":0.0073,"surprise":0.0251,"sadness":0.0404,"fear":0.3166,"anger":0.0606,"disgust":0.0416},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel video compression technique (GLVC) that achieves state-of-the-art performance in DISTS and LPIPS metrics and rivals existing codecs at nearly half the rate. This suggests a potential for reduced energy consumption during video transmission and storage, though the actual energy savings are not quantified. The technology is in the applied research phase, demonstrated through experimental results and user studies, but lacks real-world deployment data.","key_impact_metrics":["Half the rate of existing codecs","State-of-the-art DISTS and LPIPS metrics"],"technology_tags":["Video compression","Neural networks","Generative models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:09:04.832743Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4de7df654d1e","title":"Enabling High-Quality In","content":"arXiv:2510.10083v1 Announce Type: cross Abstract: We tackle the challenge of robust, in-the-wild imaging using ultra-thin nanophotonic metalens cameras. Meta-lenses, composed of planar arrays of nanoscale scatterers, promise dramatic reductions in size and weight compared to conventional refractive optics. However, severe chromatic aberration, pronounced light scattering, narrow spectral bandwidth, and low light efficiency continue to limit their practical adoption. In this work, we present an end-to-end solution for in-the-wild imaging that pairs a metalens several times thinner than conventional optics with a bespoke multi-image restoration framework optimized for practical metalens cameras. Our method centers on a lightweight convolutional network paired with a memory-efficient burst fusion algorithm that adaptively corrects noise, saturation clipping, and lens-induced distortions across rapid sequences of extremely degraded metalens captures. Extensive experiments on diverse, real-world handheld captures demonstrate that our approach consistently outperforms existing burst-mode and single-image restoration techniques.These results point toward a practical route for deploying metalens-based cameras in everyday imaging applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10083","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.039019","language":"en","tags":["computer-science","physicsoptics","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Debabrata Mandal, Zhihan Peng, Yujie Wang, Praneeth Chakravarthula","raw_content_length":1255,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1254,"language_detected":"en","key_concepts":{"key_phrases":["High-Quality","arXiv251010083v1 Announce Type","Abstract","the challenge","robust in-the-wild imaging","ultra-thin nanophotonic metalens cameras","Meta-lenses","planar arrays","nanoscale scatterers","dramatic reductions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"High-Quality":2.0,"arXiv251010083v1 Announce Type":1.0,"Abstract":1.0,"the challenge":1.0,"robust in-the-wild imaging":1.0,"ultra-thin nanophotonic metalens cameras":1.0,"Meta-lenses":1.0,"planar arrays":1.0,"nanoscale scatterers":1.0,"dramatic reductions":1.0}},"age_hours":2.7614275466666665,"is_recent":true,"quality_score":0.7,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8683,"joy":0.0317,"surprise":0.0415,"sadness":0.0108,"fear":0.0259,"anger":0.0135,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel metalens camera technology and a restoration framework. While it demonstrates improved imaging quality in real-world handheld captures compared to existing techniques, it is still in the early stages of development with no deployed units. The potential climate impact is indirect, stemming from potential future applications in areas like remote sensing or environmental monitoring, but this is not quantified.","key_impact_metrics":["several times thinner than conventional optics","outperforms existing burst-mode and single-image restoration techniques"],"technology_tags":["metalens","nanophotonics","image restoration","convolutional network"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:09:08.250194Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f1dc61e5c222","title":"Distributionally Robust Control with End","content":"arXiv:2510.10214v1 Announce Type: cross Abstract: Wasserstein distributionally robust control (DRC) recently emerges as a principled paradigm for handling uncertainty in stochastic dynamical systems. However, it constructs data-driven ambiguity sets via uniform distribution shifts before sequentially incorporating them into downstream control synthesis. This segregation between ambiguity set construction and control objectives inherently introduces a structural misalignment, which undesirably leads to conservative control policies with sub-optimal performance. To address this limitation, we propose a novel end-to-end finite-horizon Wasserstein DRC framework that integrates the learning of anisotropic Wasserstein metrics with downstream control tasks in a closed-loop manner, thus enabling ambiguity sets to be systematically adjusted along performance-critical directions and yielding more effective control policies. This framework is formulated as a bilevel program: the inner level characterizes dynamical system evolution under DRC, while the outer level refines the anisotropic metric leveraging control-performance feedback across a range of initial conditions. To solve this program efficiently, we develop a stochastic augmented Lagrangian algorithm tailored to the bilevel structure. Theoretically, we prove that the learned ambiguity sets preserve statistical finite-sample guarantees under a novel radius adjustment mechanism, and we establish the well-posedness of the bilevel formulation by demonstrating its continuity with respect to the learnable metric. Furthermore, we show that the algorithm converges to stationary points of the outer level problem, which are statistically consistent with the optimal metric at a non-asymptotic convergence rate. Experiments on both numerical and inventory control tasks verify that the proposed framework achieves superior closed-loop performance and robustness compared against state-of-the-art methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10214","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.040209","language":"en","tags":["eesssy","csai","cssy","preprints","research","mathoc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Jingyi Wu, Chao Ning, Yang Shi","raw_content_length":1970,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["DRC"],"persons":["Wasserstein"],"locations":["Wasserstein"],"monetary":[]},"char_count":1969,"language_detected":"en","key_concepts":{"key_phrases":["Distributionally Robust Control","End","arXiv251010214v1 Announce Type","cross","Wasserstein distributionally robust control","DRC","a principled paradigm","uncertainty","stochastic dynamical systems","uniform distribution shifts"],"filter_categories":{"ai_ml":["uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Distributionally Robust Control":2.0,"End":2.0,"arXiv251010214v1 Announce Type":1.0,"cross":1.0,"Wasserstein distributionally robust control":1.0,"DRC":1.0,"a principled paradigm":1.0,"uncertainty":1.0,"stochastic dynamical systems":1.0,"uniform distribution shifts":1.0}},"age_hours":2.7614677275,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7808,"joy":0.0054,"surprise":0.027,"sadness":0.0132,"fear":0.1016,"anger":0.0295,"disgust":0.0426},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel control framework that aims to improve the efficiency and robustness of control policies in stochastic dynamical systems. While the research demonstrates improved performance in numerical and inventory control tasks, it is still in the early stages of development with no real-world deployments. The vaporware flag is raised due to the lack of deployed units and operational data.","key_impact_metrics":["Superior closed-loop performance compared to state-of-the-art methods","Non-asymptotic convergence rate"],"technology_tags":["Distributionally Robust Control","Wasserstein Metric Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:09:11.603410Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_633c028c5f3e","title":"Neural variational inference for cutting feedback during uncertainty propagation","content":"arXiv:2510.10268v1 Announce Type: cross Abstract: In many scientific applications, uncertainty of estimates from an earlier (upstream) analysis needs to be propagated in subsequent (downstream) Bayesian analysis, without feedback. Cutting feedback methods, also termed cut-Bayes, achieve this by constructing a cut-posterior distribution that prevents backward information flow. Cutting feedback like nested MCMC is computationally challenging while variational inference (VI) cut-Bayes methods need two variational approximations and require access to the upstream data and model. In this manuscript we propose, NeVI-Cut, a provably accurate and modular neural network-based variational inference method for cutting feedback. We directly utilize samples from the upstream analysis without requiring access to the upstream data or model. This simultaneously preserves modularity of analysis and reduces approximation errors by avoiding a variational approximation for the upstream model. We then use normalizing flows to specify the conditional variational family for the downstream parameters and estimate the conditional cut-posterior as a variational solution of Monte Carlo average loss over all the upstream samples. We provide theoretical guarantees on the NeVI-Cut estimate to approximate any cut-posterior. Our results are in a fixed-data regime and provide convergence rates of the actual variational solution, quantifying how richness of the neural architecture and the complexity of the target cut-posterior dictate the approximation quality. In the process, we establish new results on uniform Kullback-Leibler approximation rates of conditional normalizing flows. Simulation studies and two real-world analyses illustrate how NeVI-Cut achieves significant computational gains over traditional cutting feedback methods and is considerably more accurate than parametric variational cut approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10268","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.041017","language":"en","tags":["statml","cslg","preprints","statme","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Jiafang Song, Sandipan Pramanik, Abhirup Datta","raw_content_length":1909,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["NeVI-Cut"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1908,"language_detected":"en","key_concepts":{"key_phrases":["feedback","Neural variational inference","uncertainty propagation","arXiv251010268v1 Announce Type","cross","Abstract","many scientific applications","uncertainty","estimates","an earlier upstream analysis"],"filter_categories":{"ai_ml":["uncertainty propagation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"feedback":4.0,"Neural variational inference":2.0,"uncertainty propagation":2.0,"arXiv251010268v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"many scientific applications":1.0,"uncertainty":1.0,"estimates":1.0,"an earlier upstream analysis":1.0}},"age_hours":2.7614970322222225,"is_recent":true,"quality_score":1.0,"sentiment_score":3.0604999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3879,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8967,"joy":0.0048,"surprise":0.0228,"sadness":0.0061,"fear":0.0235,"anger":0.0259,"disgust":0.0202},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (NeVI-Cut) for uncertainty propagation in Bayesian analysis, potentially improving the accuracy and computational efficiency of scientific modeling. While the method is demonstrated with simulation studies and real-world analyses, it remains in the applied research stage with no evidence of deployment. The impact on climate change is indirect, as it improves modeling accuracy, but doesn't directly reduce emissions or sequester carbon.","key_impact_metrics":["Computational gains over traditional cutting feedback methods","Accuracy improvements over parametric variational cut approaches"],"technology_tags":["Neural Variational Inference","Bayesian Analysis","Uncertainty Propagation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:09:15.149844Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_937d9b2bd45d","title":"Artificial intelligence as a surrogate brain: Bridging neural dynamical models and data","content":"arXiv:2510.10308v1 Announce Type: cross Abstract: Recent breakthroughs in artificial intelligence (AI) are reshaping the way we construct computational counterparts of the brain, giving rise to a new class of ``surrogate brains''. In contrast to conventional hypothesis-driven biophysical models, the AI-based surrogate brain encompasses a broad spectrum of data-driven approaches to solve the inverse problem, with the primary objective of accurately predicting future whole-brain dynamics with historical data. Here, we introduce a unified framework of constructing an AI-based surrogate brain that integrates forward modeling, inverse problem solving, and model evaluation. Leveraging the expressive power of AI models and large-scale brain data, surrogate brains open a new window for decoding neural systems and forecasting complex dynamics with high dimensionality, nonlinearity, and adaptability. We highlight that the learned surrogate brain serves as a simulation platform for dynamical systems analysis, virtual perturbation, and model-guided neurostimulation. We envision that the AI-based surrogate brain will provide a functional bridge between theoretical neuroscience and translational neuroengineering.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10308","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.041399","language":"en","tags":["computer-science","preprints","research","q-bionc","csne","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Yinuo Zhang, Demao Liu, Zhichao Liang, Jiani Cheng, Kexin Lou, Jinqiao Duan, Ting Gao, Bin Hu, Quanying Liu","raw_content_length":1219,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1218,"language_detected":"en","key_concepts":{"key_phrases":["Artificial intelligence","a surrogate brain","neural dynamical models","data","arXiv251010308v1 Announce Type","cross","Abstract","Recent breakthroughs","artificial intelligence","the way"],"filter_categories":{"ai_ml":["Artificial intelligence","data","artificial intelligence"],"research_academic":["Recent breakthroughs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Artificial intelligence":2.0,"a surrogate brain":2.0,"neural dynamical models":2.0,"data":2.0,"arXiv251010308v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Recent breakthroughs":1.0,"artificial intelligence":1.0,"the way":1.0}},"age_hours":2.761512111111111,"is_recent":true,"quality_score":0.7,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8054,"joy":0.0349,"surprise":0.1317,"sadness":0.004,"fear":0.0085,"anger":0.011,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a theoretical framework for AI-based surrogate brains. While potentially impactful for neuroscience, its direct climate impact is minimal and unproven. It is currently in the basic research stage with no deployed units or measurable outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Neural Networks","Brain Modeling"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:09:18.329703Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e7176a408b4a","title":"A Spatio","content":"arXiv:2510.10322v1 Announce Type: cross Abstract: Spatio temporal data consist of measurement for one or more raster fields such as weather, traffic volume, crime rate, or disease incidents. Advances in modern technology have increased the number of available information for this type of data hence the rise of multidimensional data. In this paper we take advantage of the multidimensional structure of the data but also its temporal and spatial structure. In fact, we will be using the NCAR Climate Data Gateway website which provides data discovery and access services for global and regional climate model data. The daily values of total precipitation (prec), maximum (tmax), and minimum (tmin) temperature are combined to create a multidimensional data called tensor (a multidimensional array). In this paper, we propose a spatio temporal principal component analysis to initialize CP decomposition component. We take full advantage of the spatial and temporal structure of the data in the initialization step for cp component analysis. The performance of our method is tested via comparison with most popular initialization method. We also run a clustering analysis to further show the performance of our analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10322","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.041810","language":"en","tags":["computer-science","statap","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Fatoumata Sanogo","raw_content_length":1221,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1220,"language_detected":"en","key_concepts":{"key_phrases":["A Spatio","arXiv251010322v1 Announce Type","cross","Abstract","Spatio temporal data consist","measurement","one or more raster fields","weather","traffic volume","crime rate"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Spatio":2.0,"arXiv251010322v1 Announce Type":1.0,"cross":1.0,"Abstract":1.0,"Spatio temporal data consist":1.0,"measurement":1.0,"one or more raster fields":1.0,"weather":1.0,"traffic volume":1.0,"crime rate":1.0}},"age_hours":2.7615272133333333,"is_recent":true,"quality_score":0.7,"sentiment_score":4.9355,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0129,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6964,"joy":0.1037,"surprise":0.1748,"sadness":0.0101,"fear":0.0057,"anger":0.0071,"disgust":0.0021},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for spatio-temporal principal component analysis using climate data from the NCAR Climate Data Gateway. It focuses on improving the initialization step for CP component analysis. There are no concrete actions or measurable outcomes related to GHG emissions reduction or climate adaptation; it's a methodological improvement at the research stage.","key_impact_metrics":[],"technology_tags":["spatio-temporal analysis","climate modeling","principal component analysis"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T12:09:21.756284Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_54d371cabd19","title":"Generative Modeling of Aerosol State Representations","content":"arXiv:2510.10361v1 Announce Type: cross Abstract: Aerosol-cloud--radiation interactions remain among the most uncertain components of the Earth's climate system, in partdue to the high dimensionality of aerosol state representations and the difficulty of obtaining complete \\textit{in situ} measurements. Addressing these challenges requires methods that distill complex aerosol properties into compact yet physically meaningful forms. Generative autoencoder models provide such a pathway. We present a framework for learning deep variational autoencoder (VAE) models of speciated mass and number concentration distributions, which capture detailed aerosol size-composition characteristics. By compressing hundreds of original dimensions into ten latent variables, the approach enables efficient storage and processing while preserving the fidelity of key diagnostics, including cloud condensation nuclei (CCN) spectra, optical scattering and absorption coefficients, and ice nucleation properties. Results show that CCN spectra are easiest to reconstruct accurately, optical properties are moderately difficult, and ice nucleation properties are the most challenging. To improve performance, we introduce a preprocessing optimization strategy that avoids repeated retraining and yields latent representations resilient to high-magnitude Gaussian noise, boosting accuracy for CCN spectra, optical coefficients, and frozen fraction spectra. Finally, we propose a novel realism metric -- based on the sliced Wasserstein distance between generated samples and a held-out test set -- for optimizing the KL divergence weight in VAEs. Together, these contributions enable compact, robust, and physically meaningful representations of aerosol states for large-scale climate applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10361","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.042598","language":"en","tags":["computer-science","cslg","physicsao-ph","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Ehsan Saleh, Saba Ghaffari, Jeffrey H. Curtis, Lekha Patel, Peter A. Bosler, Nicole Riemer, Matthew West","raw_content_length":1781,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["CCN","VAE"],"persons":[],"locations":["Earth"],"monetary":[]},"char_count":1780,"language_detected":"en","key_concepts":{"key_phrases":["Generative Modeling","Aerosol State Representations","arXiv251010361v1 Announce Type","cross","Aerosol-cloud--radiation interactions","the most uncertain components","the Earths climate system","the high dimensionality","aerosol state representations","the difficulty"],"filter_categories":{"ai_ml":["the most uncertain components"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative Modeling":2.0,"Aerosol State Representations":2.0,"arXiv251010361v1 Announce Type":1.0,"cross":1.0,"Aerosol-cloud--radiation interactions":1.0,"the most uncertain components":1.0,"the Earths climate system":1.0,"the high dimensionality":1.0,"aerosol state representations":1.0,"the difficulty":1.0}},"age_hours":2.7615555166666668,"is_recent":true,"quality_score":1.0,"sentiment_score":3.4165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3167,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4267,"joy":0.0128,"surprise":0.048,"sadness":0.009,"fear":0.4825,"anger":0.0148,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a framework for learning deep variational autoencoder (VAE) models of aerosol distributions, compressing hundreds of dimensions into ten latent variables. While it improves the efficiency of aerosol state representation, enabling potentially more accurate climate models, it's still in the applied research phase with no deployed units or economic viability demonstrated. The technical credibility is supported by peer-reviewed research and specific metrics like CCN spectra reconstruction accuracy.","key_impact_metrics":["Hundreds of original dimensions compressed into ten latent variables","Improved accuracy for CCN spectra, optical coefficients, and frozen fraction spectra"],"technology_tags":["Generative Autoencoder Models","Variational Autoencoder (VAE)","Aerosol Modeling"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T12:09:26.265609Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_faf383414746","title":"Synchrosqueezed windowed linear canonical transform: A method for mode retrieval from multicomponent signals with crossing instantaneous frequencies","content":"arXiv:2510.10438v1 Announce Type: cross Abstract: In nature, signals often appear in the form of the superposition of multiple non-stationary signals. The overlap of signal components in the time-frequency domain poses a significant challenge for signal analysis. One approach to addressing this problem is to introduce an additional chirprate parameter and use the chirplet transform (CT) to elevate the two-dimensional time-frequency representation to a three-dimensional time-frequency-chirprate representation. From a certain point of view, the CT of a signal can be regarded as a windowed special linear canonical transform of that signal, undergoing a shift and a modulation. In this paper, we develop this idea to propose a novel windowed linear canonical transform (WLCT), which provides a new time-frequency-chirprate representation. We discuss four types of WLCTs. In addition, we use a special X-ray transform to further sharpen the time-frequency-chirprate representation. Furthermore, we derive the corresponding three-dimensional synchrosqueezed transform, demonstrating that the WLCTs have great potential for three-dimensional signal separation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10438","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.043347","language":"en","tags":["eesssp","preprints","research","csna","mathna","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Shuixin Li, Jiecheng Chen, Qingtang Jiang, Jian Lu","raw_content_length":1164,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["linear canonical transform"],"persons":[],"locations":[],"monetary":[]},"char_count":1161,"language_detected":"en","key_concepts":{"key_phrases":["Synchrosqueezed windowed linear canonical transform","A method","mode retrieval","multicomponent signals","instantaneous frequencies","arXiv251010438v1 Announce Type","cross","nature","signals","the form"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Synchrosqueezed windowed linear canonical transform":2.0,"A method":2.0,"mode retrieval":2.0,"multicomponent signals":2.0,"instantaneous frequencies":2.0,"arXiv251010438v1 Announce Type":1.0,"cross":1.0,"nature":1.0,"signals":1.0,"the form":1.0}},"age_hours":2.761585478611111,"is_recent":true,"quality_score":1.0,"sentiment_score":3.721,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2558,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7145,"joy":0.0057,"surprise":0.0222,"sadness":0.0104,"fear":0.1667,"anger":0.0468,"disgust":0.0336},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel signal processing method. While the method could potentially be applied to analyze signals from climate-relevant technologies (e.g., wind turbine vibrations, seismic monitoring for carbon storage), the paper itself does not demonstrate any concrete application or provide quantifiable impact metrics. It remains at the theoretical research stage.","key_impact_metrics":[],"technology_tags":["signal processing","time-frequency analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:09:29.575889Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e2b35ef34f63","title":"Towards Efficient 3D Gaussian Human Avatar Compression: A Prior","content":"arXiv:2510.10492v1 Announce Type: cross Abstract: This paper proposes an efficient 3D avatar coding framework that leverages compact human priors and canonical-to-target transformation to enable high-quality 3D human avatar video compression at ultra-low bit rates. The framework begins by training a canonical Gaussian avatar using articulated splatting in a network-free manner, which serves as the foundation for avatar appearance modeling. Simultaneously, a human-prior template is employed to capture temporal body movements through compact parametric representations. This decomposition of appearance and temporal evolution minimizes redundancy, enabling efficient compression: the canonical avatar is shared across the sequence, requiring compression only once, while the temporal parameters, consisting of just 94 parameters per frame, are transmitted with minimal bit-rate. For each frame, the target human avatar is generated by deforming canonical avatar via Linear Blend Skinning transformation, facilitating temporal coherent video reconstruction and novel view synthesis. Experimental results demonstrate that the proposed method significantly outperforms conventional 2D/3D codecs and existing learnable dynamic 3D Gaussian splatting compression method in terms of rate-distortion performance on mainstream multi-view human video datasets, paving the way for seamless immersive multimedia experiences in meta-verse applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10492","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.043763","language":"en","tags":["eessiv","computer-science","preprints","cscv","csmm","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Shanzhi Yin, Bolin Chen, Xinju Wu, Ru-Ling Liao, Jie Chen, Shiqi Wang, Yan Ye","raw_content_length":1444,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1443,"language_detected":"en","key_concepts":{"key_phrases":["Efficient 3D Gaussian Human Avatar Compression","Announce Type","Abstract","This paper","an efficient 3D avatar coding framework","compact human priors","target","high-quality 3D human avatar video compression","ultra-low bit rates","The framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Efficient 3D Gaussian Human Avatar Compression":2.0,"Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"an efficient 3D avatar coding framework":1.0,"compact human priors":1.0,"target":1.0,"high-quality 3D human avatar video compression":1.0,"ultra-low bit rates":1.0,"The framework":1.0}},"age_hours":2.7616006080555553,"is_recent":true,"quality_score":0.7,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9079,"joy":0.0464,"surprise":0.0205,"sadness":0.0035,"fear":0.0053,"anger":0.0099,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method for compressing 3D human avatar video at ultra-low bit rates, which could reduce the energy consumption associated with transmitting and storing such data. The claim is supported by experimental results on multi-view human video datasets, but it's still in the early stages of development with no deployed units. The impact is limited to reducing data transmission energy, and the economic viability is unclear.","key_impact_metrics":["94 parameters per frame","ultra-low bit rates"],"technology_tags":["3D avatar compression","Gaussian splatting","Linear Blend Skinning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:09:33.166074Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8ca5a62bdd27","title":"JND-Guided Light","content":"arXiv:2510.10648v1 Announce Type: cross Abstract: Just Noticeable Distortion (JND)-guided pre-filter is a promising technique for improving the perceptual compression efficiency of image coding. However, existing methods are often computationally expensive, and the field lacks standardized benchmarks for fair comparison. To address these challenges, this paper introduces a twofold contribution. First, we develop and open-source FJNDF-Pytorch, a unified benchmark for frequency-domain JND-Guided pre-filters. Second, leveraging this platform, we propose a complete learning framework for a novel, lightweight Convolutional Neural Network (CNN). Experimental results demonstrate that our proposed method achieves state-of-the-art compression efficiency, consistently outperforming competitors across multiple datasets and encoders. In terms of computational cost, our model is exceptionally lightweight, requiring only 7.15 GFLOPs to process a 1080p image, which is merely 14.1% of the cost of recent lightweight network. Our work presents a robust, state-of-the-art solution that excels in both performance and efficiency, supported by a reproducible research platform. The open-source implementation is available at https://github.com/viplab-fudan/FJNDF-Pytorch.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10648","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.045228","language":"en","tags":["eessiv","computer-science","preprints","cscv","csmm","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Chenlong He, Zijing Dong, Min Li, Zhijian Hao, Leilei Huang, Xiaoyang Zeng, Yibo Fan","raw_content_length":1267,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["JND-Guided Light arXiv:2510.10648v1 Announce Type: cross","Just Noticeable Distortion","FJNDF-Pytorch","Convolutional Neural Network","CNN","JND-Guided"],"persons":[],"locations":[],"monetary":[]},"char_count":1266,"language_detected":"en","key_concepts":{"key_phrases":["JND-Guided Light","arXiv251010648v1 Announce Type","cross","Just Noticeable Distortion","JND-guided pre","a promising technique","the perceptual compression efficiency","image coding","existing methods","the field"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"JND-Guided Light":2.0,"arXiv251010648v1 Announce Type":1.0,"cross":1.0,"Just Noticeable Distortion":1.0,"JND-guided pre":1.0,"a promising technique":1.0,"the perceptual compression efficiency":1.0,"image coding":1.0,"existing methods":1.0,"the field":1.0}},"age_hours":2.7616528816666666,"is_recent":true,"quality_score":1.0,"sentiment_score":9.520999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9042,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9419,"joy":0.0096,"surprise":0.0187,"sadness":0.0066,"fear":0.0058,"anger":0.0109,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel CNN architecture for image compression, achieving state-of-the-art compression efficiency with significantly reduced computational cost (7.15 GFLOPs for 1080p image, 14.1% of a recent lightweight network). The open-source benchmark and reproducible research platform enhance credibility. However, it's still in the applied research stage with no deployment data, limiting immediate climate impact.","key_impact_metrics":["7.15 GFLOPs","14.1% computational cost reduction"],"technology_tags":["image compression","convolutional neural network","JND-guided pre-filter"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:09:36.238240Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
