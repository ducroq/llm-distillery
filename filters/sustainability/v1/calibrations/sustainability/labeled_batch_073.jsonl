{"id":"science_arxiv_cs_a4a750612b1b","title":"LOTION: Smoothing the Optimization Landscape for Quantized Training","content":"arXiv:2510.08757v1 Announce Type: new Abstract: Optimizing neural networks for quantized objectives is fundamentally challenging because the quantizer is piece-wise constant, yielding zero gradients everywhere except at quantization thresholds where the derivative is undefined. Most existing methods deal with this issue by relaxing gradient computations with techniques like Straight Through Estimators (STE) and do not provide any guarantees of convergence. In this work, taking inspiration from Nesterov smoothing, we approximate the quantized loss surface with a continuous loss surface. In particular, we introduce LOTION, \\textbf{L}ow-precision \\textbf{O}ptimization via s\\textbf{T}ochastic-no\\textbf{I}se sm\\textbf{O}othi\\textbf{N}g, a principled smoothing framework that replaces the raw quantized loss with its expectation under unbiased randomized-rounding noise. In this framework, standard optimizers are guaranteed to converge to a local minimum of the loss surface. Moreover, when using noise derived from stochastic rounding, we show that the global minima of the original quantized loss are preserved. We empirically demonstrate that this method outperforms standard QAT on synthetic testbeds and on 150M- and 300M- parameter language models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08757","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.586596","language":"en","tags":["research","preprints","cslg","csar","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Mujin Kwun, Depen Morwani, Chloe Huangyuan Su, Stephanie Gil, Nikhil Anand, Sham Kakade","raw_content_length":1260,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Straight Through Estimators","STE"],"persons":["LOTION","Nesterov"],"locations":[],"monetary":[]},"char_count":1259,"language_detected":"en","key_concepts":{"key_phrases":["LOTION","the Optimization Landscape","Quantized Training","arXiv251008757v1 Announce Type","new Abstract","neural networks","quantized objectives","the quantizer","piece-wise constant","zero gradients"],"filter_categories":{"ai_ml":["Quantized Training","neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LOTION":2.0,"the Optimization Landscape":2.0,"Quantized Training":2.0,"arXiv251008757v1 Announce Type":1.0,"new Abstract":1.0,"neural networks":1.0,"quantized objectives":1.0,"the quantizer":1.0,"piece-wise constant":1.0,"zero gradients":1.0}},"age_hours":2.7613758225000002,"is_recent":true,"quality_score":1.0,"sentiment_score":9.506499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9013,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9017,"joy":0.0041,"surprise":0.0138,"sadness":0.0072,"fear":0.0356,"anger":0.0194,"disgust":0.0182},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (LOTION) for optimizing quantized neural networks, which could lead to more efficient AI models. The method is empirically demonstrated on synthetic testbeds and language models, showing improved performance over standard quantization-aware training (QAT). However, it's still in the research phase, lacking real-world deployment and economic viability data.","key_impact_metrics":["150M- parameter language models","300M- parameter language models"],"technology_tags":["Quantized Neural Networks","Stochastic Rounding","AI Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:26:01.986926Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_223940bf1288","title":"BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities","content":"arXiv:2510.08759v1 Announce Type: new Abstract: Embodied capabilities refer to a suite of fundamental abilities for an agent to perceive, comprehend, and interact with the physical world. While multimodal large language models (MLLMs) show promise as embodied agents, a thorough and systematic evaluation of their embodied capabilities remains underexplored, as existing benchmarks primarily focus on specific domains such as planning or spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive and fine-grained benchmark that evaluates MLLMs on atomic embodied capabilities. BEAR comprises 4,469 interleaved image-video-text entries across 14 domains in 6 categories, including tasks from low-level pointing, trajectory understanding, spatial reasoning, to high-level planning. Extensive evaluation results of 20 representative MLLMs reveal their persistent limitations across all domains of embodied capabilities. To tackle the shortfall, we propose BEAR-Agent, a multimodal conversable agent that integrates pretrained vision models to strengthen MLLM perception, 3D understanding, and planning capabilities. It substantially enhances MLLM performance across diverse embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that improving MLLM embodied capabilities can benefit embodied tasks in simulated environments. Project website: https://bear-official66.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08759","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.587007","language":"en","tags":["research","preprints","csro","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Yu Qi, Haibo Zhao, Ziyu Guo, Siyuan Ma, Ziyan Chen, Yaokun Han, Renrui Zhang, Zitiantao Lin, Shiji Xin, Yijian Huang, Kai Cheng, Peiheng Wang, Jiazheng Liu, Jiayi Zhang, Yizhe Zhu, Wenqing Wang, Yiran Qin, Xupeng Zhu, Haojie Huang, Lawson L. S. Wong","raw_content_length":1485,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["BEAR"],"persons":["arXiv:2510.08759v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1484,"language_detected":"en","key_concepts":{"key_phrases":["BEAR","Multimodal Language Models","Atomic Embodied Capabilities","new Abstract","Embodied capabilities","a suite","fundamental abilities","an agent","the physical world","multimodal large language models"],"filter_categories":{"ai_ml":["multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BEAR":3.0,"Multimodal Language Models":2.0,"Atomic Embodied Capabilities":2.0,"new Abstract":1.0,"Embodied capabilities":1.0,"a suite":1.0,"fundamental abilities":1.0,"an agent":1.0,"the physical world":1.0,"multimodal large language models":1.0}},"age_hours":2.7613919894444448,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8775,"joy":0.0046,"surprise":0.0138,"sadness":0.0062,"fear":0.0429,"anger":0.0289,"disgust":0.0261},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (BEAR) and an improved agent (BEAR-Agent) for evaluating and enhancing multimodal language models' embodied capabilities. While the paper demonstrates a 9.12% absolute gain and a 17.5% relative improvement on GPT-5, the impact on climate is indirect, as it focuses on improving AI's ability to understand and interact with the physical world, which *could* be applied to sustainability tasks in the future. It is still in the applied research stage, with no real-world deployment.","key_impact_metrics":["9.12% absolute gain on BEAR benchmark","17.5% relative improvement on GPT-5"],"technology_tags":["Multimodal Language Models","Embodied AI","Computer Vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:05.440306Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_82020a1bbdda","title":"SAFER-AiD: Saccade","content":"arXiv:2510.08761v1 Announce Type: new Abstract: Adversarial attacks significantly challenge the safe deployment of deep learning models, particularly in real-world applications. Traditional defenses often rely on computationally intensive optimization (e.g., adversarial training or data augmentation) to improve robustness, whereas the human visual system achieves inherent robustness to adversarial perturbations through evolved biological mechanisms. We hypothesize that attention guided non-homogeneous sparse sampling and predictive coding plays a key role in this robustness. To test this hypothesis, we propose a novel defense framework incorporating three key biological mechanisms: foveal-peripheral processing, saccadic eye movements, and cortical filling-in. Our approach employs reinforcement learning-guided saccades to selectively capture multiple foveal-peripheral glimpses, which are integrated into a reconstructed image before classification. This biologically inspired preprocessing effectively mitigates adversarial noise, preserves semantic integrity, and notably requires no retraining or fine-tuning of downstream classifiers, enabling seamless integration with existing systems. Experiments on the ImageNet dataset demonstrate that our method improves system robustness across diverse classifiers and attack types, while significantly reducing training overhead compared to both biologically and non-biologically inspired defense techniques.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08761","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.587477","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Jiayang Liu, Daniel Tso, Yiming Bu, Qinru Qiu","raw_content_length":1466,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1465,"language_detected":"en","key_concepts":{"key_phrases":["SAFER-AiD Saccade","arXiv251008761v1 Announce Type","new Abstract","Adversarial attacks","the safe deployment","deep learning models","real-world applications","Traditional defenses","computationally intensive optimization","eg adversarial training or data augmentation"],"filter_categories":{"ai_ml":["SAFER-AiD Saccade","deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SAFER-AiD Saccade":2.0,"arXiv251008761v1 Announce Type":1.0,"new Abstract":1.0,"Adversarial attacks":1.0,"the safe deployment":1.0,"deep learning models":1.0,"real-world applications":1.0,"Traditional defenses":1.0,"computationally intensive optimization":1.0,"eg adversarial training or data augmentation":1.0}},"age_hours":2.7614064541666665,"is_recent":true,"quality_score":0.7,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.85,"joy":0.0133,"surprise":0.0574,"sadness":0.0075,"fear":0.019,"anger":0.039,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel defense framework against adversarial attacks on deep learning models, inspired by biological mechanisms. It shows improved robustness on the ImageNet dataset, reducing training overhead. However, it is still in the early stages of development with no real-world deployments or economic viability demonstrated.","key_impact_metrics":["Improved system robustness across diverse classifiers","Reduced training overhead"],"technology_tags":["Adversarial defense","Deep learning","Reinforcement learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:08.342410Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b1aed8a13a2","title":"Spatial Deconfounder: Interference","content":"arXiv:2510.08762v1 Announce Type: new Abstract: Causal inference in spatial domains faces two intertwined challenges: (1) unmeasured spatial factors, such as weather, air pollution, or mobility, that confound treatment and outcome, and (2) interference from nearby treatments that violate standard no-interference assumptions. While existing methods typically address one by assuming away the other, we show they are deeply connected: interference reveals structure in the latent confounder. Leveraging this insight, we propose the Spatial Deconfounder, a two-stage method that reconstructs a substitute confounder from local treatment vectors using a conditional variational autoencoder (CVAE) with a spatial prior, then estimates causal effects via a flexible outcome model. We show that this approach enables nonparametric identification of both direct and spillover effects under weak assumptions--without requiring multiple treatment types or a known model of the latent field. Empirically, we extend SpaCE, a benchmark suite for spatial confounding, to include treatment interference, and show that the Spatial Deconfounder consistently improves effect estimation across real-world datasets in environmental health and social science. By turning interference into a multi-cause signal, our framework bridges spatial and deconfounding literatures to advance robust causal inference in structured data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08762","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.587902","language":"en","tags":["statml","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Ayush Khot, Miruna Oprescu, Maresa Schr\\\"oder, Ai Kagawa, Xihaier Luo","raw_content_length":1407,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["CVAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1406,"language_detected":"en","key_concepts":{"key_phrases":["Spatial Deconfounder Interference","arXiv251008762v1 Announce Type","new Abstract","Causal inference","spatial domains","two intertwined challenges","1 unmeasured spatial factors","weather","air pollution","mobility"],"filter_categories":{"ai_ml":["spatial domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Spatial Deconfounder Interference":2.0,"arXiv251008762v1 Announce Type":1.0,"new Abstract":1.0,"Causal inference":1.0,"spatial domains":1.0,"two intertwined challenges":1.0,"1 unmeasured spatial factors":1.0,"weather":1.0,"air pollution":1.0,"mobility":1.0}},"age_hours":2.7614219383333336,"is_recent":true,"quality_score":1.0,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8523,"joy":0.0057,"surprise":0.0468,"sadness":0.0156,"fear":0.0242,"anger":0.035,"disgust":0.0205},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel method for causal inference in spatial domains, specifically addressing unmeasured spatial confounders and interference. The method is validated on real-world datasets in environmental health, suggesting potential for improving the accuracy of impact assessments. However, it's currently in the research stage with no deployed technology or quantified environmental impact.","key_impact_metrics":[],"technology_tags":["causal inference","spatial analysis","variational autoencoders"],"sdg_alignment":[3,11],"analyzed_at":"2025-10-29T09:26:11.201198Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e6df964fcb6","title":"Reinforcement Learning","content":"arXiv:2510.08763v1 Announce Type: new Abstract: Protocol optimization is critical in Computed Tomography (CT) to achieve high diagnostic image quality while minimizing radiation dose. However, due to the complex interdependencies among CT acquisition and reconstruction parameters, traditional optimization methods rely on exhaustive testing of combinations of these parameters, which is often impractical. This study introduces a novel methodology that combines virtual imaging tools with reinforcement learning to optimize CT protocols more efficiently. Human models with liver lesions were imaged using a validated CT simulator and reconstructed with a novel CT reconstruction toolkit. The optimization parameter space included tube voltage, tube current, reconstruction kernel, slice thickness, and pixel size. The optimization process was performed using a Proximal Policy Optimization (PPO) agent, which was trained to maximize an image quality objective, specifically the detectability index (d') of liver lesions in the reconstructed images. Optimization performance was compared against an exhaustive search performed on a supercomputer. The proposed reinforcement learning approach achieved the global maximum d' across test cases while requiring 79.7% fewer steps than the exhaustive search, demonstrating both accuracy and computational efficiency. The proposed framework is flexible and can accommodate various image quality objectives. The findings highlight the potential of integrating virtual imaging tools with reinforcement learning for CT protocol management.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08763","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.588333","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"David Fenwick, Navid NaderiAlizadeh, Vahid Tarokh, Nicholas Felice, Darin Clark, Jayasai Rajagopal, Anuj Kapadia, Benjamin Wildman-Tobriner, Ehsan Samei, Ehsan Abadi","raw_content_length":1580,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Computed Tomography","Reinforcement Learning arXiv:2510.08763v1 Announce Type","PPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1579,"language_detected":"en","key_concepts":{"key_phrases":["Reinforcement Learning","new Abstract","Protocol optimization","Computed Tomography","high diagnostic image quality","radiation dose","the complex interdependencies","CT acquisition","reconstruction parameters","traditional optimization methods"],"filter_categories":{"ai_ml":["Reinforcement Learning"],"business_innovation":["CT acquisition"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reinforcement Learning":2.0,"new Abstract":1.0,"Protocol optimization":1.0,"Computed Tomography":1.0,"high diagnostic image quality":1.0,"radiation dose":1.0,"the complex interdependencies":1.0,"CT acquisition":1.0,"reconstruction parameters":1.0,"traditional optimization methods":1.0}},"age_hours":2.761436461111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8559,"joy":0.0129,"surprise":0.0562,"sadness":0.0321,"fear":0.0117,"anger":0.0176,"disgust":0.0135},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research uses reinforcement learning to optimize CT scan protocols, reducing radiation dose while maintaining image quality. The concrete action is the development and testing of an RL agent that achieves comparable image quality with 79.7% fewer steps than exhaustive search. The study is currently in the applied research stage, using a validated CT simulator.","key_impact_metrics":["79.7% fewer steps than exhaustive search","detectability index (d') of liver lesions"],"technology_tags":["Reinforcement Learning","Computed Tomography"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:26:14.287904Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c765d91e6105","title":"Zero","content":"arXiv:2510.09574v1 Announce Type: new Abstract: Autonomous navigation in unfamiliar environments requires robots to simultaneously explore, localise, and plan under uncertainty, without relying on predefined maps or extensive training. We present a biologically inspired, Active Inference-based framework, Active Inference MAPping and Planning (AIMAPP). This model unifies mapping, localisation, and decision-making within a single generative model. Inspired by hippocampal navigation, it uses topological reasoning, place-cell encoding, and episodic memory to guide behaviour. The agent builds and updates a sparse topological map online, learns state transitions dynamically, and plans actions by minimising Expected Free Energy. This allows it to balance goal-directed and exploratory behaviours. We implemented a ROS-compatible navigation system that is sensor and robot-agnostic, capable of integrating with diverse hardware configurations. It operates in a fully self-supervised manner, is resilient to drift, and supports both exploration and goal-directed navigation without any pre-training. We demonstrate robust performance in large-scale real and simulated environments against state-of-the-art planning models, highlighting the system's adaptability to ambiguous observations, environmental changes, and sensor noise. The model offers a biologically inspired, modular solution to scalable, self-supervised navigation in unstructured settings. AIMAPP is available at https://github.com/decide-ugent/AIMAPP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.09574","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.775076","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Daria de tinguy, Tim Verbelen, Emilio Gamba, Bart Dhoedt","raw_content_length":1519,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["AIMAPP","Expected Free Energy","Active Inference MAPping and Planning","ROS"],"persons":["Zero arXiv:2510.09574v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1518,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251009574v1 Announce Type","new Abstract","Autonomous navigation","unfamiliar environments","robots","uncertainty","predefined maps","extensive training","a biologically inspired Active Inference-based framework","Active Inference MAPping"],"filter_categories":{"ai_ml":["uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251009574v1 Announce Type":1.0,"new Abstract":1.0,"Autonomous navigation":1.0,"unfamiliar environments":1.0,"robots":1.0,"uncertainty":1.0,"predefined maps":1.0,"extensive training":1.0,"a biologically inspired Active Inference-based framework":1.0,"Active Inference MAPping":1.0}},"age_hours":2.7682494930555555,"is_recent":true,"quality_score":0.7,"sentiment_score":9.2775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8555,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8529,"joy":0.0103,"surprise":0.0187,"sadness":0.0047,"fear":0.0831,"anger":0.0175,"disgust":0.0126},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a novel AI-based navigation system (AIMAPP) for robots in unstructured environments. It demonstrates robust performance in real and simulated environments, suggesting potential for applications in areas like logistics and environmental monitoring, which could indirectly reduce emissions. However, the article lacks concrete data on energy consumption or direct emissions reductions, and it's currently in the pilot stage.","key_impact_metrics":[],"technology_tags":["autonomous navigation","active inference","robotics","AI"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T09:26:17.137378Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f3f98cd04370","title":"Prioritizing Latency with Profit: A DRL","content":"arXiv:2510.08769v1 Announce Type: new Abstract: 5G networks enable diverse services such as eMBB, URLLC, and mMTC through network slicing, necessitating intelligent admission control and resource allocation to meet stringent QoS requirements while maximizing Network Service Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL) frameworks focus primarily on profit optimization without explicitly accounting for service delay, potentially leading to QoS violations for latency-sensitive slices. Moreover, commonly used epsilon-greedy exploration of DRL often results in unstable convergence and suboptimal policy learning. To address these gaps, we propose DePSAC -- a Delay and Profit-aware Slice Admission Control scheme. Our DRL-based approach incorporates a delay-aware reward function, where penalties due to service delay incentivize the prioritization of latency-critical slices such as URLLC. Additionally, we employ Boltzmann exploration to achieve smoother and faster convergence. We implement and evaluate DePSAC on a simulated 5G core network substrate with realistic Network Slice Request (NSLR) arrival patterns. Experimental results demonstrate that our method outperforms the DSARA baseline in terms of overall profit, reduced URLLC slice delays, improved acceptance rates, and improved resource consumption. These findings validate the effectiveness of the proposed DePSAC in achieving better QoS-profit trade-offs for practical 5G network slicing scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08769","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.589146","language":"en","tags":["research","csni","preprints","cslg","cspf","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Proggya Chakraborty, Aaquib Asrar, Jayasree Sengupta, Sipra Das Bit","raw_content_length":1499,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["Network Service Provider (NSP","Deep Reinforcement Learning","DePSAC","Slice Admission Control","QoS","DRL","URLLC"],"persons":["Boltzmann","Delay"],"locations":[],"monetary":[]},"char_count":1498,"language_detected":"en","key_concepts":{"key_phrases":["Prioritizing Latency","Profit","A DRL","arXiv251008769v1 Announce Type","new Abstract","5G networks","diverse services","eMBB","URLLC","mMTC"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Prioritizing Latency":2.0,"Profit":2.0,"A DRL":2.0,"arXiv251008769v1 Announce Type":1.0,"new Abstract":1.0,"5G networks":1.0,"diverse services":1.0,"eMBB":1.0,"URLLC":1.0,"mMTC":1.0}},"age_hours":2.761467372777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9001,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9294,"joy":0.0133,"surprise":0.0123,"sadness":0.0057,"fear":0.0104,"anger":0.0196,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a DRL-based approach (DePSAC) for 5G network slicing that prioritizes latency and profit. While it shows improved performance in simulations, it's still in the applied research phase with no real-world deployments. The impact on climate is indirect, through potential resource consumption improvements.","key_impact_metrics":["overall profit","reduced URLLC slice delays"],"technology_tags":["Deep Reinforcement Learning","5G network slicing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:19.971311Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3706ce48c3bd","title":"LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super","content":"arXiv:2510.08771v1 Announce Type: new Abstract: Generative models for Image Super-Resolution (SR) are increasingly powerful, yet their reliance on self-attention's quadratic complexity (O(N^2)) creates a major computational bottleneck. Linear Attention offers an O(N) solution, but its promise for photorealistic SR has remained largely untapped, historically hindered by a cascade of interrelated and previously unsolved challenges. This paper introduces LinearSR, a holistic framework that, for the first time, systematically overcomes these critical hurdles. Specifically, we resolve a fundamental, training instability that causes catastrophic model divergence using our novel \"knee point\"-based Early-Stopping Guided Fine-tuning (ESGF) strategy. Furthermore, we mitigate the classic perception-distortion trade-off with a dedicated SNR-based Mixture of Experts (MoE) architecture. Finally, we establish an effective and lightweight guidance paradigm, TAG, derived from our \"precision-over-volume\" principle. Our resulting LinearSR model simultaneously delivers state-of-the-art perceptual quality with exceptional efficiency. Its core diffusion forward pass (1-NFE) achieves SOTA-level speed, while its overall multi-step inference time remains highly competitive. This work provides the first robust methodology for applying Linear Attention in the photorealistic SR domain, establishing a foundational paradigm for future research in efficient generative super-resolution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08771","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.589957","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Xiaohui Li, Shaobin Zhuang, Shuo Cao, Yang Yang, Yuandong Pu, Qi Qin, Siqi Luo, Bin Fu, Yihao Liu","raw_content_length":1480,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Mixture of Experts (MoE","Early-Stopping Guided Fine","Efficient Image Super arXiv:2510.08771v1 Announce Type","Linear Attention","SNR"],"persons":["LinearSR"],"locations":[],"monetary":[]},"char_count":1479,"language_detected":"en","key_concepts":{"key_phrases":[" Unlocking Linear Attention","Stable and Efficient Image Super","arXiv251008771v1 Announce Type","new Abstract","Generative models","Image Super","Resolution","their reliance","self-attentions quadratic complexity","ON2"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{" Unlocking Linear Attention":2.0,"Stable and Efficient Image Super":2.0,"arXiv251008771v1 Announce Type":1.0,"new Abstract":1.0,"Generative models":1.0,"Image Super":1.0,"Resolution":1.0,"their reliance":1.0,"self-attentions quadratic complexity":1.0,"ON2":1.0}},"age_hours":2.7614996183333336,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4365,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8873,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7559,"joy":0.0084,"surprise":0.066,"sadness":0.0934,"fear":0.0252,"anger":0.03,"disgust":0.0211},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel method (LinearSR) for improving image super-resolution using linear attention, which could potentially reduce computational costs. While the paper claims SOTA-level speed and competitive inference time, it is still in the research phase with no deployed units or real-world data. The impact on climate is indirect, as it could potentially reduce energy consumption in image processing applications, but this is not quantified.","key_impact_metrics":["SOTA-level speed (1-NFE)","Competitive multi-step inference time"],"technology_tags":["Image Super-Resolution","Linear Attention","Generative Models","Diffusion Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:22.999127Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3ef9bd44b571","title":"Struc","content":"arXiv:2510.08774v1 Announce Type: new Abstract: Text embeddings from Large Language Models (LLMs) have become foundational for numerous applications. However, these models typically operate on raw text, overlooking the rich structural information, such as hyperlinks or citations, that provides crucial context in many real-world datasets. This paper introduces and systematically evaluates a new paradigm for generating structure-aware text embeddings by integrating these structural relations directly into the LLM's internal encoding process, rather than relying on traditional post-hoc aggregation. We investigate two primary in-process methods: sequential concatenation and parallel caching. Through extensive zero-shot experiments across retrieval, clustering, classification, and recommendation tasks, we demonstrate that our structure-aware approaches consistently outperform both text-only and post-hoc baselines. Our analysis reveals critical trade-offs: sequential concatenation excels with noisy, moderate-length contexts, while parallel caching scales more effectively to long, high-signal contexts but is more susceptible to distractors. To address the challenge of noisy structural data, we also introduce and validate two effective techniques: Context Distillation and Semantic Balancing. This work provides the first comprehensive analysis of in-process structure-aware encoding, offering a blueprint for building more powerful and contextually aware embedding models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08774","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.590380","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Shikun Liu, Haoyu Wang, Mufei Li, Pan Li","raw_content_length":1486,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["LLM","Large Language Models","Struc arXiv:2510.08774v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1485,"language_detected":"en","key_concepts":{"key_phrases":["Struc","arXiv251008774v1 Announce Type","new Abstract","Text embeddings","Large Language Models","LLMs","numerous applications","these models","raw text","the rich structural information"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Struc":2.0,"arXiv251008774v1 Announce Type":1.0,"new Abstract":1.0,"Text embeddings":1.0,"Large Language Models":1.0,"LLMs":1.0,"numerous applications":1.0,"these models":1.0,"raw text":1.0,"the rich structural information":1.0}},"age_hours":2.761514269722222,"is_recent":true,"quality_score":0.7,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8031,"joy":0.0543,"surprise":0.0897,"sadness":0.0072,"fear":0.0153,"anger":0.0229,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method for generating structure-aware text embeddings. While this could potentially improve the efficiency of information retrieval for sustainability-related data, it is currently at the basic research stage with no deployed technology or measured outcomes related to climate impact. The paper does present quantitative results from zero-shot experiments, increasing the technical credibility.","key_impact_metrics":["Outperforms text-only baselines","Outperforms post-hoc baselines"],"technology_tags":["Large Language Models","Text Embeddings","Structure-Aware Encoding"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T09:26:26.089457Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2265084681f4","title":"Measuring Moral LLM Responses in Multilingual Capacities","content":"arXiv:2510.08776v1 Announce Type: new Abstract: With LLM usage becoming widespread across countries, languages, and humanity more broadly, the need to understand and guardrail their multilingual responses increases. Large-scale datasets for testing and benchmarking have been created to evaluate and facilitate LLM responses across multiple dimensions. In this study, we evaluate the responses of frontier and leading open-source models in five dimensions across low and high-resource languages to measure LLM accuracy and consistency across multilingual contexts. We evaluate the responses using a five-point grading rubric and a judge LLM. Our study shows that GPT-5 performed the best on average in each category, while other models displayed more inconsistency across language and category. Most notably, in the Consent & Autonomy and Harm Prevention & Safety categories, GPT scored the highest with averages of 3.56 and 4.73, while Gemini 2.5 Pro scored the lowest with averages of 1.39 and 1.98, respectively. These findings emphasize the need for further testing on how linguistic shifts impact LLM responses across various categories and improvement in these areas.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08776","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.591198","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Kimaya Basu, Savi Kolari, Allison Yu","raw_content_length":1174,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Harm Prevention & Safety","Gemini","LLM","GPT","the Consent & Autonomy"],"persons":[],"locations":[],"monetary":[]},"char_count":1173,"language_detected":"en","key_concepts":{"key_phrases":["Moral LLM Responses","Multilingual Capacities","arXiv251008776v1 Announce Type","new Abstract","LLM usage","countries","languages","humanity","their multilingual responses increases","Large-scale datasets"],"filter_categories":{"ai_ml":["Moral LLM Responses"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Moral LLM Responses":2.0,"Multilingual Capacities":2.0,"arXiv251008776v1 Announce Type":1.0,"new Abstract":1.0,"LLM usage":1.0,"countries":1.0,"languages":1.0,"humanity":1.0,"their multilingual responses increases":1.0,"Large-scale datasets":1.0}},"age_hours":2.7615461719444445,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8951,"joy":0.0452,"surprise":0.0324,"sadness":0.0019,"fear":0.0051,"anger":0.0143,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper evaluates the moral responses of LLMs across multiple languages. While important for ethical AI development, it does not directly address climate change or environmental sustainability. The study uses a five-point grading rubric and a judge LLM to evaluate the responses.","key_impact_metrics":["Average score in Consent & Autonomy category: 3.56 (GPT-5)","Average score in Harm Prevention & Safety category: 4.73 (GPT-5)"],"technology_tags":["Large Language Models","Multilingual AI"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T09:26:29.106559Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f57d26a6f3f","title":"Understanding and Predicting Temporal Visual Attention Influenced by Dynamic Highlights in Monitoring Task","content":"arXiv:2510.08777v1 Announce Type: new Abstract: Monitoring interfaces are crucial for dynamic, highstakes tasks where effective user attention is essential. Visual highlights can guide attention effectively but may also introduce unintended disruptions. To investigate this, we examined how visual highlights affect users' gaze behavior in a drone monitoring task, focusing on when, how long, and how much attention they draw. We found that highlighted areas exhibit distinct temporal characteristics compared to non-highlighted ones, quantified using normalized saliency (NS) metrics. Highlights elicited immediate responses, with NS peaking quickly, but this shift came at the cost of reduced search efforts elsewhere, potentially impacting situational awareness. To predict these dynamic changes and support interface design, we developed the Highlight-Informed Saliency Model (HISM), which provides granular predictions of NS over time. These predictions enable evaluations of highlight effectiveness and inform the optimal timing and deployment of highlights in future monitoring interface designs, particularly for time-sensitive tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08777","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.591607","language":"en","tags":["research","computer-science","preprints","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Zekun Wu, Anna Maria Feit","raw_content_length":1143,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["Predicting Temporal Visual Attention Influenced","Dynamic Highlights","the Highlight-Informed Saliency Model"],"persons":[],"locations":[],"monetary":[]},"char_count":1142,"language_detected":"en","key_concepts":{"key_phrases":["Temporal Visual Attention","Dynamic Highlights","Monitoring Task","Announce Type","new Abstract","Monitoring interfaces","dynamic highstakes tasks","effective user attention","Visual highlights","attention"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Temporal Visual Attention":2.0,"Dynamic Highlights":2.0,"Monitoring Task":2.0,"Announce Type":1.0,"new Abstract":1.0,"Monitoring interfaces":1.0,"dynamic highstakes tasks":1.0,"effective user attention":1.0,"Visual highlights":1.0,"attention":1.0}},"age_hours":2.761562261944444,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8169,"joy":0.0094,"surprise":0.0661,"sadness":0.0193,"fear":0.0364,"anger":0.0311,"disgust":0.0208},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research into visual attention in monitoring tasks, specifically drone monitoring. While improved monitoring could indirectly support more efficient resource use and potentially reduce environmental impact (e.g., in agriculture or infrastructure), the link is weak and unquantified. The Highlight-Informed Saliency Model (HISM) is still in development, so deployment readiness is low.","key_impact_metrics":["Normalized Saliency (NS) metrics"],"technology_tags":["visual attention","saliency model","drone monitoring"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:32.122239Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aa6bd250a5c4","title":"Guiding Exploration in Reinforcement Learning Through LLM","content":"arXiv:2510.08779v1 Announce Type: new Abstract: Reinforcement Learning (RL) agents often struggle in sparse-reward environments where traditional exploration strategies fail to discover effective action sequences. Large Language Models (LLMs) possess procedural knowledge and reasoning capabilities from text pretraining that could guide RL exploration, but existing approaches create rigid dependencies where RL policies must follow LLM suggestions or incorporate them directly into reward functions. We propose a framework that provides LLM-generated action recommendations through augmented observation spaces, allowing RL agents to learn when to follow or ignore this guidance. Our method leverages LLMs' world knowledge and reasoning abilities while maintaining flexibility through soft constraints. We evaluate our approach on three BabyAI environments of increasing complexity and show that the benefits of LLM guidance scale with task difficulty. In the most challenging environment, we achieve 71% relative improvement in final success rates over baseline. The approach provides substantial sample efficiency gains, with agents reaching performance thresholds up to 9 times faster, and requires no modifications to existing RL algorithms. Our results demonstrate an effective method for leveraging LLM planning capabilities to accelerate RL training in challenging environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08779","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.592007","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Vaibhav Jain, Gerrit Grossmann","raw_content_length":1388,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["LLM","Guiding Exploration"],"persons":[],"locations":[],"monetary":[]},"char_count":1387,"language_detected":"en","key_concepts":{"key_phrases":["Guiding Exploration","Reinforcement Learning","LLM","arXiv251008779v1 Announce Type","new Abstract","Reinforcement Learning RL agents","sparse-reward environments","traditional exploration strategies","effective action sequences","Large Language Models"],"filter_categories":{"ai_ml":["Reinforcement Learning","Reinforcement Learning RL agents","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Guiding Exploration":2.0,"Reinforcement Learning":2.0,"LLM":2.0,"arXiv251008779v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement Learning RL agents":1.0,"sparse-reward environments":1.0,"traditional exploration strategies":1.0,"effective action sequences":1.0,"Large Language Models":1.0}},"age_hours":2.7615763625,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6721,"joy":0.0055,"surprise":0.0108,"sadness":0.0456,"fear":0.1742,"anger":0.0525,"disgust":0.0393},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores using LLMs to guide RL agents in sparse-reward environments, showing a 71% relative improvement in final success rates in a challenging BabyAI environment and up to 9 times faster performance. While promising for improving the efficiency of RL in various applications, including those related to sustainability, it's currently at the applied research stage with no deployed units or economic viability demonstrated. The impact on climate is indirect, depending on the applications of the improved RL agents.","key_impact_metrics":["71% relative improvement in final success rates","9 times faster performance"],"technology_tags":["Reinforcement Learning","Large Language Models","AI"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:26:35.389400Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_624340b70047","title":"Weights initialization of neural networks for function approximation","content":"arXiv:2510.08780v1 Announce Type: new Abstract: Neural network-based function approximation plays a pivotal role in the advancement of scientific computing and machine learning. Yet, training such models faces several challenges: (i) each target function often requires training a new model from scratch; (ii) performance is highly sensitive to architectural and hyperparameter choices; and (iii) models frequently generalize poorly beyond the training domain. To overcome these challenges, we propose a reusable initialization framework based on basis function pretraining. In this approach, basis neural networks are first trained to approximate families of polynomials on a reference domain. Their learned parameters are then used to initialize networks for more complex target functions. To enhance adaptability across arbitrary domains, we further introduce a domain mapping mechanism that transforms inputs into the reference domain, thereby preserving structural correspondence with the pretrained models. Extensive numerical experiments in one- and two-dimensional settings demonstrate substantial improvements in training efficiency, generalization, and model transferability, highlighting the promise of initialization-based strategies for scalable and modular neural function approximation. The full code is made publicly available on Gitee.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08780","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.592438","language":"en","tags":["research","mathna","preprints","csna","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Xinwen Hu, Yunqing Huang, Nianyu Yi, Peimeng Yin","raw_content_length":1353,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1352,"language_detected":"en","key_concepts":{"key_phrases":["Weights initialization","neural networks","function approximation","Announce Type","new Abstract","Neural network-based function approximation","a pivotal role","the advancement","scientific computing","machine learning"],"filter_categories":{"ai_ml":["neural networks","machine learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Weights initialization":2.0,"neural networks":2.0,"function approximation":2.0,"Announce Type":1.0,"new Abstract":1.0,"Neural network-based function approximation":1.0,"a pivotal role":1.0,"the advancement":1.0,"scientific computing":1.0,"machine learning":1.0}},"age_hours":2.7615915969444447,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7833,"joy":0.0072,"surprise":0.0225,"sadness":0.027,"fear":0.0921,"anger":0.0276,"disgust":0.0403},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a reusable initialization framework for neural networks, aiming to improve training efficiency and generalization. While the numerical experiments show improvements in training efficiency, the impact on climate change is indirect and theoretical. The technology is at an early stage of development, with no deployed units or real-world data beyond the numerical experiments.","key_impact_metrics":["Improvements in training efficiency","Improvements in generalization"],"technology_tags":["neural networks","function approximation","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:38.164259Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cc0f96a79c1f","title":"Geometry","content":"arXiv:2510.08787v1 Announce Type: new Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks imitation learning by treating demonstrations as geometric curves rather than collections of state-action samples. From these curves, GPI derives distance fields that give rise to two complementary control primitives: a progression flow that advances along expert trajectories and an attraction flow that corrects deviations. Their combination defines a controllable, non-parametric vector field that directly guides robot behavior. This formulation decouples metric learning from policy synthesis, enabling modular adaptation across low-dimensional robot states and high-dimensional perceptual inputs. GPI naturally supports multimodality by preserving distinct demonstrations as separate models and allows efficient composition of new demonstrations through simple additions to the distance field. We evaluate GPI in simulation and on real robots across diverse tasks. Experiments show that GPI achieves higher success rates than diffusion-based policies while running 20 times faster, requiring less memory, and remaining robust to perturbations. These results establish GPI as an efficient, interpretable, and scalable alternative to generative approaches for robotic imitation learning. Project website: https://yimingli1998.github.io/projects/GPI/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08787","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.593232","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Yiming Li, Nael Darwiche, Amirreza Razmjoo, Sichao Liu, Yilun Du, Auke Ijspeert, Sylvain Calinon","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["GPI"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Geometry","arXiv251008787v1 Announce Type","new Abstract","a Geometry-aware Policy Imitation GPI approach","demonstrations","geometric curves","collections","state-action samples","these curves","GPI"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Geometry":2.0,"arXiv251008787v1 Announce Type":1.0,"new Abstract":1.0,"a Geometry-aware Policy Imitation GPI approach":1.0,"demonstrations":1.0,"geometric curves":1.0,"collections":1.0,"state-action samples":1.0,"these curves":1.0,"GPI":1.0}},"age_hours":2.761622311111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9097,"joy":0.0216,"surprise":0.0455,"sadness":0.0037,"fear":0.0027,"anger":0.0122,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a geometry-aware policy imitation approach (GPI) for robotics. While it demonstrates higher success rates and faster performance compared to diffusion-based policies in simulation and on real robots, its direct climate impact is currently theoretical. The technology is in the pilot stage, with real robot experiments, but lacks clear economic viability or systemic impact on decarbonization.","key_impact_metrics":["20 times faster","higher success rates"],"technology_tags":["robotics","imitation learning","geometric control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:40.906041Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e1667356b42","title":"Robust autobidding for noisy conversion prediction models","content":"arXiv:2510.08788v1 Announce Type: new Abstract: Managing millions of digital auctions is an essential task for modern advertising auction systems. The main approach to managing digital auctions is an autobidding approach, which depends on the Click-Through Rate and Conversion Rate values. While these quantities are estimated with ML models, their prediction uncertainty directly impacts advertisers' revenue and bidding strategies. To address this issue, we propose RobustBid, an efficient method for robust autobidding taking into account uncertainty in CTR and CVR predictions. Our approach leverages advanced, robust optimization techniques to prevent large errors in bids if the estimates of CTR/CVR are perturbed. We derive the analytical solution of the stated robust optimization problem, which leads to the runtime efficiency of the RobustBid method. The synthetic, iPinYou, and BAT benchmarks are used in our experimental evaluation of RobustBid. We compare our method with the non-robust baseline and the RiskBid algorithm in terms of total conversion volume (TCV) and average cost-per-click ($CPC_{avg}$) performance metrics. The experiments demonstrate that RobustBid provides bids that yield larger TCV and smaller $CPC_{avg}$ than competitors in the case of large perturbations in CTR/CVR predictions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08788","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.593652","language":"en","tags":["research","csgt","preprints","computer-science","mathoc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Andrey Pudovikov, Alexandra Khirianova, Ekaterina Solodneva, Gleb Molodtsov, Aleksandr Katrutsa, Yuriy Dorn, Egor Samosvat","raw_content_length":1318,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["CTR/CVR","BAT","Conversion Rate","CVR","RobustBid","the Click-Through Rate","CTR"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1317,"language_detected":"en","key_concepts":{"key_phrases":["Robust autobidding","noisy conversion prediction models","digital auctions","arXiv251008788v1 Announce Type","new Abstract","Managing millions","an essential task","modern advertising auction systems","The main approach","an autobidding approach"],"filter_categories":{"ai_ml":["The main approach"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust autobidding":2.0,"noisy conversion prediction models":2.0,"digital auctions":2.0,"arXiv251008788v1 Announce Type":1.0,"new Abstract":1.0,"Managing millions":1.0,"an essential task":1.0,"modern advertising auction systems":1.0,"The main approach":1.0,"an autobidding approach":1.0}},"age_hours":2.761637776388889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8113,"joy":0.0054,"surprise":0.0166,"sadness":0.011,"fear":0.1222,"anger":0.023,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new autobidding method (RobustBid) that aims to improve the efficiency of digital advertising auctions. While more efficient advertising could indirectly reduce energy consumption by optimizing resource allocation, the direct climate impact is minimal and difficult to quantify. The method is evaluated on synthetic and real-world benchmarks, but there's no evidence of real-world deployment or independent verification.","key_impact_metrics":["Total conversion volume (TCV)","Average cost-per-click ($CPC_{avg}$)"],"technology_tags":["Autobidding","Robust Optimization","Machine Learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:26:44.058898Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f996742effc","title":"COMPASS: Enhancing Agent Long","content":"arXiv:2510.08790v1 Announce Type: new Abstract: Long-horizon tasks that require sustained reasoning and multiple tool interactions remain challenging for LLM agents: small errors compound across steps, and even state-of-the-art models often hallucinate or lose coherence. We identify context management as the central bottleneck -- extended histories cause agents to overlook critical evidence or become distracted by irrelevant information, thus failing to replan or reflect from previous mistakes. To address this, we propose COMPASS (Context-Organized Multi-Agent Planning and Strategy System), a lightweight hierarchical framework that separates tactical execution, strategic oversight, and context organization into three specialized components: (1) a Main Agent that performs reasoning and tool use, (2) a Meta-Thinker that monitors progress and issues strategic interventions, and (3) a Context Manager that maintains concise, relevant progress briefs for different reasoning stages. Across three challenging benchmarks -- GAIA, BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20% relative to both single- and multi-agent baselines. We further introduce a test-time scaling extension that elevates performance to match established DeepResearch agents, and a post-training pipeline that delegates context management to smaller models for enhanced efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08790","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.594483","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Guangya Wan, Mingyang Ling, Xiaoqi Ren, Rujun Han, Sheng Li, Zizhao Zhang","raw_content_length":1392,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Meta-Thinker","LLM","Context","Context-Organized Multi-Agent Planning and Strategy System"],"persons":[],"locations":[],"monetary":[]},"char_count":1391,"language_detected":"en","key_concepts":{"key_phrases":["COMPASS","Agent","Announce Type","new Abstract","Long-horizon tasks","sustained reasoning","multiple tool interactions","LLM agents","small errors","steps"],"filter_categories":{"ai_ml":["sustained reasoning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"COMPASS":2.0,"Agent":2.0,"Announce Type":1.0,"new Abstract":1.0,"Long-horizon tasks":1.0,"sustained reasoning":1.0,"multiple tool interactions":1.0,"LLM agents":1.0,"small errors":1.0,"steps":1.0}},"age_hours":2.761671525277778,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5575000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8885,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4256,"joy":0.0026,"surprise":0.0139,"sadness":0.0149,"fear":0.4768,"anger":0.041,"disgust":0.0252},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel AI framework (COMPASS) that improves the accuracy of LLM agents on long-horizon tasks. While it shows a 20% accuracy improvement on benchmarks, it's still in the early stages of development and lacks concrete deployment or real-world impact data. The post-training pipeline for enhanced efficiency suggests a potential for reduced energy consumption, but this is not quantified.","key_impact_metrics":["Accuracy improvement of up to 20%"],"technology_tags":["AI","LLM","Context Management"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:26:46.863482Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9d502a7482e","title":"Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering","content":"arXiv:2510.08791v1 Announce Type: new Abstract: Medical Visual Question Answering (Med-VQA) is a challenging task that requires a deep understanding of both medical images and textual questions. Although recent works leveraging Medical Vision-Language Pre-training (Med-VLP) have shown strong performance on the Med-VQA task, there is still no unified solution for modality alignment, and the issue of hard negatives remains under-explored. Additionally, commonly used knowledge fusion techniques for Med-VQA may introduce irrelevant information. In this work, we propose a framework to address these challenges through three key contributions: (1) a unified solution for heterogeneous modality alignments across multiple levels, modalities, views, and stages, leveraging methods like contrastive learning and optimal transport theory; (2) a hard negative mining method that employs soft labels for multi-modality alignments and enforces the hard negative pair discrimination; and (3) a Gated Cross-Attention Module for Med-VQA that integrates the answer vocabulary as prior knowledge and selects relevant information from it. Our framework outperforms the previous state-of-the-art on widely used Med-VQA datasets like RAD-VQA, SLAKE, PathVQA and VQA-2019.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08791","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.594872","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Yuanhao Zou, Zhaozheng Yin","raw_content_length":1258,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["Medical Vision-Language Pre-training","Med-VLP","Med-VQA"],"persons":[],"locations":[],"monetary":[]},"char_count":1257,"language_detected":"en","key_concepts":{"key_phrases":["Medical Visual Question Answering","Alignment","Mining","Fusion","Representation Alignment","Hard Negative Mining","Selective Knowledge Fusion","Announce Type","new Abstract","Med-VQA"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Medical Visual Question Answering":3.0,"Alignment":2.0,"Mining":2.0,"Fusion":2.0,"Representation Alignment":2.0,"Hard Negative Mining":2.0,"Selective Knowledge Fusion":2.0,"Announce Type":1.0,"new Abstract":1.0,"Med-VQA":1.0}},"age_hours":2.7616888152777777,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4095,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5181,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8678,"joy":0.0038,"surprise":0.0203,"sadness":0.0076,"fear":0.0657,"anger":0.0186,"disgust":0.0162},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new framework for medical visual question answering (Med-VQA) using AI. While it outperforms previous state-of-the-art methods on Med-VQA datasets, it is still in the research phase with no deployed technology or measurable environmental outcomes. The potential impact on sustainability is indirect and theoretical at this stage.","key_impact_metrics":["Performance on RAD-VQA dataset","Performance on SLAKE dataset"],"technology_tags":["Medical Imaging","Visual Question Answering","Artificial Intelligence"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:26:50.120523Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c8b7ef91443","title":"On Estimation of Angles of Arrival in Monostatic ISAC Without Instantaneous Transmit CSI","content":"arXiv:2510.08793v1 Announce Type: new Abstract: This paper explores the fundamental limits of Integrated Sensing and Communication (ISAC) in a more realistic setting compared to previous literature when the Base Staion (BS) has only statistical CSI of the communication user rather than full CSI. We analyze a monostatic setting where the BS performs multi-target Angle of Arrival (AoA) estimation while simultaneously communicating with one of the targets. We assume that the BS has statistical CSI about all AoAs, with less uncertainty in the AoA of the communication receiver. The communication receiver is assumed to have perfect CSI. Utilizing a Bayesian Cram\\'er-Rao Bound (BCRB) framework to characterize the fundamental limits of sensing under minimum mean square error (MMSE) criteria, we derive achievable BCRB-rate trade-off regions. Our approach introduces a number of transmission strategies that share power across sensing and communication beams over a coherence time. Our analysis reveals that beam allocation strategies leveraging the principal eigenvectors of the target-specific sensing matrices minimize individual AoA estimation errors, while strategies balancing sensing and communication directions optimize joint estimation performance at the cost of individual accuracy. We demonstrate that leveraging updated BCRB-based sensing information for the communication receiver, due to its lower channel uncertainty, enables significantly improved communication rates.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08793","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.597805","language":"en","tags":["research","mathit","preprints","eesssp","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Ataher Sams, Simone Di Bari, Besma Smida, Natasha Devroye, Daniela Tuninetti, Giorgio Taricco","raw_content_length":1488,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["the Base Staion (BS","Integrated Sensing and Communication","CSI"],"persons":[],"locations":[],"monetary":[]},"char_count":1487,"language_detected":"en","key_concepts":{"key_phrases":["Arrival","Estimation","Angles","Monostatic","Instantaneous Transmit","CSI","the BS","arXiv251008793v1 Announce Type","new Abstract","This paper"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Arrival":3.0,"Estimation":2.0,"Angles":2.0,"Monostatic":2.0,"Instantaneous Transmit":2.0,"CSI":2.0,"the BS":2.0,"arXiv251008793v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0}},"age_hours":2.7617207308333334,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8298,"joy":0.0315,"surprise":0.1075,"sadness":0.0055,"fear":0.0069,"anger":0.0139,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores theoretical limits of ISAC technology, focusing on AoA estimation. It's currently in the basic research phase with no deployed technology or measured outcomes. While it could potentially improve communication efficiency, there's no concrete evidence of GHG reduction or climate adaptation at this stage.","key_impact_metrics":[],"technology_tags":["Integrated Sensing and Communication","Angle of Arrival Estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:01.961448Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d73a7df06d10","title":"Deceptive Exploration in Multi","content":"arXiv:2510.08794v1 Announce Type: new Abstract: We consider a multi-armed bandit setting in which each arm has a public and a private reward distribution. An observer expects an agent to follow Thompson Sampling according to the public rewards, however, the deceptive agent aims to quickly identify the best private arm without being noticed. The observer can observe the public rewards and the pulled arms, but not the private rewards. The agent, on the other hand, observes both the public and private rewards. We formalize detectability as a stepwise Kullback-Leibler (KL) divergence constraint between the actual pull probabilities used by the agent and the anticipated pull probabilities by the observer. We model successful pulling of public suboptimal arms as a % Bernoulli process where the success probability decreases with each successful pull, and show these pulls can happen at most at a $\\Theta(\\sqrt{T}) $ rate under the KL constraint. We then formulate a maximin problem based on public and private means, whose solution characterizes the optimal error exponent for best private arm identification. We finally propose an algorithm inspired by top-two algorithms. This algorithm naturally adapts its exploration according to the hardness of pulling arms based on the public suboptimality gaps. We provide numerical examples illustrating the $\\Theta(\\sqrt{T}) $ rate and the behavior of the proposed algorithm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08794","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.598246","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"I. Arda Vurankaya, Mustafa O. Karabag, Wesley A. Suttle, Jesse Milzman, David Fridovich-Keil, Ufuk Topcu","raw_content_length":1425,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Deceptive Exploration","Thompson Sampling","Kullback-Leibler"],"persons":["Bernoulli"],"locations":[],"monetary":[]},"char_count":1424,"language_detected":"en","key_concepts":{"key_phrases":["Deceptive Exploration","Multi","the public rewards","arXiv251008794v1 Announce Type","new Abstract","which","each arm","a public","a private reward distribution","An observer"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deceptive Exploration":2.0,"Multi":2.0,"the public rewards":2.0,"arXiv251008794v1 Announce Type":1.0,"new Abstract":1.0,"which":1.0,"each arm":1.0,"a public":1.0,"a private reward distribution":1.0,"An observer":1.0}},"age_hours":2.76173721,"is_recent":true,"quality_score":1.0,"sentiment_score":9.290000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.858,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7846,"joy":0.0048,"surprise":0.0166,"sadness":0.0126,"fear":0.0153,"anger":0.0348,"disgust":0.1313},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical algorithm for optimizing exploration in a multi-armed bandit setting, focusing on detecting deceptive agents. While the algorithm is inspired by real-world problems, it remains at the basic research stage with no deployed technology or measured outcomes related to sustainability. The impact on climate or other sustainability dimensions is theoretical and unproven.","key_impact_metrics":["Theta(sqrt(T)) rate of pulling public suboptimal arms"],"technology_tags":["Multi-armed bandit","Thompson Sampling","Kullback-Leibler divergence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:27:05.099655Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ac7cc30a4827","title":"Edu","content":"arXiv:2510.08802v1 Announce Type: new Abstract: Understanding learner emotions in online education is critical for improving engagement and personalized instruction. While prior work in emotion recognition has explored multimodal fusion and temporal modeling, existing methods often rely on static fusion strategies and assume that modality inputs are consistently reliable, which is rarely the case in real-world learning environments. We introduce Edu-EmotionNet, a novel framework that jointly models temporal emotion evolution and modality reliability for robust affect recognition. Our model incorporates three key components: a Cross-Modality Attention Alignment (CMAA) module for dynamic cross-modal context sharing, a Modality Importance Estimator (MIE) that assigns confidence-based weights to each modality at every time step, and a Temporal Feedback Loop (TFL) that leverages previous predictions to enforce temporal consistency. Evaluated on educational subsets of IEMOCAP and MOSEI, re-annotated for confusion, curiosity, boredom, and frustration, Edu-EmotionNet achieves state-of-the-art performance and demonstrates strong robustness to missing or noisy modalities. Visualizations confirm its ability to capture emotional transitions and adaptively prioritize reliable signals, making it well suited for deployment in real-time learning systems","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08802","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.600782","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"S M Rafiuddin","raw_content_length":1360,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Modality Importance Estimator (MIE","Cross-Modality Attention Alignment","Edu-EmotionNet","TFL"],"persons":[],"locations":[],"monetary":[]},"char_count":1359,"language_detected":"en","key_concepts":{"key_phrases":["Edu","arXiv251008802v1 Announce Type","new Abstract","learner emotions","online education","engagement","personalized instruction","prior work","emotion recognition","multimodal fusion"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Edu":2.0,"arXiv251008802v1 Announce Type":1.0,"new Abstract":1.0,"learner emotions":1.0,"online education":1.0,"engagement":1.0,"personalized instruction":1.0,"prior work":1.0,"emotion recognition":1.0,"multimodal fusion":1.0}},"age_hours":2.761832461111111,"is_recent":true,"quality_score":0.7,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8846,"joy":0.0234,"surprise":0.0628,"sadness":0.0039,"fear":0.0074,"anger":0.0137,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for emotion recognition in online education. While it achieves state-of-the-art performance on educational subsets of IEMOCAP and MOSEI, it is still in the research phase with no deployed units or real-world impact on sustainability. The vaporware flag is set because it is a prototype with no deployment.","key_impact_metrics":["State-of-the-art performance on IEMOCAP and MOSEI datasets"],"technology_tags":["Emotion Recognition","Machine Learning","Artificial Intelligence"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T09:27:08.131294Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_42ca6b50b6de","title":"MOSAIC: Multi","content":"arXiv:2510.08804v1 Announce Type: new Abstract: We present MOSAIC, a multi-agent Large Language Model (LLM) framework for solving challenging scientific coding tasks. Unlike general-purpose coding, scientific workflows require algorithms that are rigorous, interconnected with deep domain knowledge, and incorporate domain-specific reasoning, as well as algorithm iteration without requiring I/O test cases. Many scientific problems also require a sequence of subproblems to be solved, leading to the final desired result. MOSAIC is designed as a training-free framework with specially designed agents to self-reflect, create the rationale, code, and debug within a student-teacher paradigm to address the challenges of scientific code generation. This design facilitates stepwise problem decomposition, targeted error correction, and, when combined with our Consolidated Context Window (CCW), mitigates LLM hallucinations when solving complex scientific tasks involving chained subproblems. We evaluate MOSAIC on scientific coding benchmarks and demonstrate that our specialized agentic framework outperforms existing approaches in terms of accuracy, robustness, and interpretability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08804","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.601601","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Siddeshwar Raghavan, Tanwi Mallick","raw_content_length":1186,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["Consolidated Context Window","LLM","MOSAIC","CCW"],"persons":["Large Language Model"],"locations":[],"monetary":[]},"char_count":1185,"language_detected":"en","key_concepts":{"key_phrases":["MOSAIC","Multi","arXiv251008804v1 Announce Type","new Abstract","We present MOSAIC","LLM","challenging scientific coding tasks","general-purpose coding","scientific workflows","algorithms"],"filter_categories":{"ai_ml":["MOSAIC","algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MOSAIC":2.0,"Multi":2.0,"arXiv251008804v1 Announce Type":1.0,"new Abstract":1.0,"We present MOSAIC":1.0,"LLM":1.0,"challenging scientific coding tasks":1.0,"general-purpose coding":1.0,"scientific workflows":1.0,"algorithms":1.0}},"age_hours":2.7618628500000004,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8502,"joy":0.0147,"surprise":0.0262,"sadness":0.0059,"fear":0.0613,"anger":0.031,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework (MOSAIC) for scientific coding, which could indirectly contribute to sustainability by accelerating scientific discovery in climate-related fields. However, it's currently in the applied research stage with no deployed units or concrete metrics on emissions reduction. The technical credibility is relatively high due to the mention of benchmarks and accuracy improvements.","key_impact_metrics":["accuracy improvement","robustness improvement"],"technology_tags":["Large Language Model","Multi-Agent System","Scientific Coding"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:27:11.038718Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_040df9057e7b","title":"Humanoid Everyday: A Comprehensive Robotic Dataset for Open","content":"arXiv:2510.08807v1 Announce Type: new Abstract: From loco-motion to dextrous manipulation, humanoid robots have made remarkable strides in demonstrating complex full-body capabilities. However, the majority of current robot learning datasets and benchmarks mainly focus on stationary robot arms, and the few existing humanoid datasets are either confined to fixed environments or limited in task diversity, often lacking human-humanoid interaction and lower-body locomotion. Moreover, there are a few standardized evaluation platforms for benchmarking learning-based policies on humanoid data. In this work, we present Humanoid Everyday, a large-scale and diverse humanoid manipulation dataset characterized by extensive task variety involving dextrous object manipulation, human-humanoid interaction, locomotion-integrated actions, and more. Leveraging a highly efficient human-supervised teleoperation pipeline, Humanoid Everyday aggregates high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile inputs, together with natural language annotations, comprising 10.3k trajectories and over 3 million frames of data across 260 tasks across 7 broad categories. In addition, we conduct an analysis of representative policy learning methods on our dataset, providing insights into their strengths and limitations across different task categories. For standardized evaluation, we introduce a cloud-based evaluation platform that allows researchers to seamlessly deploy their policies in our controlled setting and receive performance feedback. By releasing Humanoid Everyday along with our policy learning analysis and a standardized cloud-based evaluation platform, we intend to advance research in general-purpose humanoid manipulation and lay the groundwork for more capable and embodied robotic agents in real-world scenarios. Our dataset, data collection code, and cloud evaluation website are made publicly available on our project website.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08807","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.602051","language":"en","tags":["research","preprints","cslg","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Zhenyu Zhao, Hongyi Jing, Xiawei Liu, Jiageng Mao, Abha Jha, Hanwen Yang, Rong Xue, Sergey Zakharor, Vitor Guizilini, Yue Wang","raw_content_length":1965,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["Humanoid"],"persons":["Humanoid Everyday"],"locations":[],"monetary":[]},"char_count":1964,"language_detected":"en","key_concepts":{"key_phrases":["Humanoid","A Comprehensive Robotic Dataset","Open","arXiv251008807v1","Announce Type","new Abstract","loco-motion","dextrous manipulation","humanoid robots","remarkable strides"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Humanoid":2.0,"A Comprehensive Robotic Dataset":2.0,"Open":2.0,"arXiv251008807v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"loco-motion":1.0,"dextrous manipulation":1.0,"humanoid robots":1.0,"remarkable strides":1.0}},"age_hours":2.761878331666667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.858,"joy":0.0144,"surprise":0.1011,"sadness":0.0058,"fear":0.0081,"anger":0.008,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a large-scale humanoid manipulation dataset, which could indirectly contribute to sustainability by enabling the development of robots that can perform tasks more efficiently. However, the direct climate impact is minimal at this stage, as it is primarily a research dataset. The technical credibility is relatively high due to the scale of the dataset and the analysis of policy learning methods, but it is still in the applied research phase with no deployment yet.","key_impact_metrics":["10.3k trajectories","3 million frames of data"],"technology_tags":["robotics","machine learning","humanoid robots"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:13.964173Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f247e3b711a8","title":"TinyGraphEstimator: Adapting Lightweight Language Models for Graph Structure Inference","content":"arXiv:2510.08808v1 Announce Type: new Abstract: Graphs provide a universal framework for representing complex relational systems, and inferring their structural properties is a core challenge in graph analysis and reasoning. While large language models have recently demonstrated emerging abilities to perform symbolic and numerical reasoning, the potential of smaller, resource-efficient models in this context remains largely unexplored. This paper investigates whether compact transformer-based language models can infer graph-theoretic parameters directly from textual graph representations. To enable systematic evaluation, we introduce the TinyGraphEstimator dataset - a balanced collection of connected graphs generated from multiple random graph models and annotated with detailed structural metadata. We evaluate several small open models on their ability to predict key graph parameters such as density, clustering, and chromatic number. Furthermore, we apply lightweight fine-tuning using the Low-Rank Adaptation (LoRA) technique, achieving consistent improvements across all evaluated metrics. The results demonstrate that small language models possess non-trivial reasoning capacity over graph-structured data and can be effectively adapted for structural inference tasks through efficient parameter tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08808","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.602480","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Michal Podstawski","raw_content_length":1321,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Graphs"],"locations":[],"monetary":[]},"char_count":1320,"language_detected":"en","key_concepts":{"key_phrases":["TinyGraphEstimator","Lightweight Language Models","Graph Structure Inference","new Abstract","Graphs","a universal framework","complex relational systems","their structural properties","a core challenge","graph analysis"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"TinyGraphEstimator":2.0,"Lightweight Language Models":2.0,"Graph Structure Inference":2.0,"new Abstract":1.0,"Graphs":1.0,"a universal framework":1.0,"complex relational systems":1.0,"their structural properties":1.0,"a core challenge":1.0,"graph analysis":1.0}},"age_hours":2.7618928158333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8545,"joy":0.0249,"surprise":0.0455,"sadness":0.0066,"fear":0.0332,"anger":0.0246,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the potential of small language models for graph structure inference, which could indirectly contribute to sustainability by improving analysis of complex systems like energy grids or supply chains. The research is at an early stage, with evaluations performed on a newly created dataset, but no real-world deployment or quantified impact on emissions is mentioned. The use of LoRA fine-tuning shows a concrete action to improve model performance.","key_impact_metrics":["density","clustering"],"technology_tags":["language models","graph analysis","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:17.186050Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0d01a5c57a84","title":"PyMigTool: a tool for end","content":"arXiv:2510.08810v1 Announce Type: new Abstract: Library migration is the process of replacing a library with a similar one in a software project. Manual library migration is time consuming and error prone, as it requires developers to understand the Application Programming Interfaces (API) of both libraries, map equivalent APIs, and perform the necessary code transformations. Due to the difficulty of the library migration process, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of libraries and code transformations. In this paper, we develop an end-to-end solution that can automatically migrate code between any arbitrary pair of Python libraries that provide similar functionality. Due to the promising capabilities of Large Language Models (LLMs) in code generation and transformation, we use LLMs as the primary engine for migration. Before building the tool, we first study the capabilities of LLMs for library migration on a benchmark of 321 real-world library migrations. We find that LLMs can effectively perform library migration, but some post-processing steps can further improve the performance. Based on this, we develop PyMigTool, a command line application that combines the power of LLMs, static analysis, and dynamic analysis to provide accurate library migration. We evaluate PyMigTool on 717 real-world Python applications that are not from our benchmark. We find that PyMigTool can migrate 32% of the migrations with complete correctness. Of the remaining migrations, only 14% of the migration-related changes are left for developers to fix for more than half of the projects.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08810","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.602917","language":"en","tags":["csse","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":251,"author":"Mohayeminul Islam, Ajay Kumar Jha, May Mahmoud, Sarah Nadi","raw_content_length":1664,"priority":7,"update_frequency":1,"reading_time_minutes":1.255,"robust_parsing_used":true,"entities":{"organizations":["the Application Programming Interfaces","API","Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1663,"language_detected":"en","key_concepts":{"key_phrases":["PyMigTool","a tool","end","Announce Type","new Abstract","Library migration","the process","a library","a similar one","a software project"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PyMigTool":2.0,"a tool":2.0,"end":2.0,"Announce Type":1.0,"new Abstract":1.0,"Library migration":1.0,"the process":1.0,"a library":1.0,"a similar one":1.0,"a software project":1.0}},"age_hours":2.761908615277778,"is_recent":true,"quality_score":1.0,"sentiment_score":1.8755,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6249,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8766,"joy":0.0073,"surprise":0.0306,"sadness":0.0242,"fear":0.0456,"anger":0.009,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a tool (PyMigTool) that automates library migration in Python code, potentially reducing developer time and errors. The tool is evaluated on 717 real-world applications, showing a 32% success rate for complete migrations. This could indirectly support sustainability by improving the efficiency of software development for climate-related projects, but the direct impact is difficult to quantify at this stage.","key_impact_metrics":["32% migration correctness","14% migration-related changes left for developers"],"technology_tags":["Large Language Models","Code Migration","Software Engineering"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:20.170369Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_66a2b4762175","title":"Adaptive Motion Planning via Contact","content":"arXiv:2510.08811v1 Announce Type: new Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to human intent to ensure safe and efficient cooperation in shared spaces. Although large language models (LLMs) provide high-level reasoning for inferring human intent, their application to reliable motion planning in HRC remains challenging. Physical human-robot interaction (pHRI) is intuitive but often relies on continuous kinesthetic guidance, which imposes burdens on operators. To address these challenges, a contact-informed adaptive motion-planning framework is introduced to infer human intent directly from physical contact and employ the inferred intent for online motion correction in HRC. First, an optimization-based force estimation method is proposed to infer human-intended contact forces and locations from joint torque measurements and a robot dynamics model, thereby reducing cost and installation complexity while enabling whole-body sensitivity. Then, a torque-based contact detection mechanism with link-level localization is introduced to reduce the optimization search space and to enable real-time estimation. Subsequently, a contact-informed adaptive motion planner is developed to infer human intent from contacts and to replan robot motion online, while maintaining smoothness and adapting to human corrections. Finally, experiments on a 7-DOF manipulator are conducted to demonstrate the accuracy of the proposed force estimation method and the effectiveness of the contact-informed adaptive motion planner under perception uncertainty in HRC.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08811","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.603355","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Jiurun Song, Xiao Liang, Minghui Zheng","raw_content_length":1595,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["HRC","Contact arXiv:2510.08811v1","Adaptive Motion Planning"],"persons":[],"locations":[],"monetary":[]},"char_count":1594,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive Motion Planning","Contact","HRC","arXiv251008811v1 Announce Type","new Abstract","Human-robot collaboration","robots","their motions","human intent","safe and efficient cooperation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive Motion Planning":2.0,"Contact":2.0,"HRC":2.0,"arXiv251008811v1 Announce Type":1.0,"new Abstract":1.0,"Human-robot collaboration":1.0,"robots":1.0,"their motions":1.0,"human intent":1.0,"safe and efficient cooperation":1.0}},"age_hours":2.761923788888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.429,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6858,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9535,"joy":0.0082,"surprise":0.0113,"sadness":0.0037,"fear":0.0088,"anger":0.008,"disgust":0.0066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a contact-informed adaptive motion-planning framework for human-robot collaboration. The framework is tested on a 7-DOF manipulator, demonstrating the accuracy of force estimation. However, the article lacks information on deployment outside of a lab setting and does not quantify the environmental impact of the system.","key_impact_metrics":["Accuracy of force estimation","Effectiveness of motion planner"],"technology_tags":["robotics","motion planning","human-robot collaboration"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:22.864657Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_607881a8c731","title":"Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning","content":"arXiv:2510.08812v1 Announce Type: new Abstract: Deep space missions face extreme communication delays and environmental uncertainty that prevent real-time ground operations. To support autonomous science operations in communication-constrained environments, we present a partially observable Markov decision process (POMDP) framework that adaptively sequences spacecraft science instruments. We integrate a Bayesian network into the POMDP observation space to manage the high-dimensional and uncertain measurements typical of astrobiology missions. This network compactly encodes dependencies among measurements and improves the interpretability and computational tractability of science data. Instrument operation policies are computed offline, allowing resource-aware plans to be generated and thoroughly validated prior to launch. We use the Enceladus Orbilander's proposed Life Detection Suite (LDS) as a case study, demonstrating how Bayesian network structure and reward shaping influence system performance. We compare our method against the mission's baseline Concept of Operations (ConOps), evaluating both misclassification rates and performance in off-nominal sample accumulation scenarios. Our approach reduces sample identification errors by nearly 40%","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08812","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.603761","language":"en","tags":["research","csai","preprints","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Grace Ra Kim, Hailey Warner, Duncan Eddy, Evan Astle, Zachary Booth, Edward Balaban, Mykel J. Kochenderfer","raw_content_length":1266,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Science Operations","POMDP","Life Detection Suite"],"persons":["Markov"],"locations":[],"monetary":[]},"char_count":1265,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive Science Operations","Deep Space Missions","Offline Belief State Planning","Announce Type","new Abstract","Deep space missions","extreme communication delays","environmental uncertainty","real-time ground operations","autonomous science operations"],"filter_categories":{"research_academic":["Adaptive Science Operations"],"ai_ml":["environmental uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive Science Operations":2.0,"Deep Space Missions":2.0,"Offline Belief State Planning":2.0,"Announce Type":1.0,"new Abstract":1.0,"Deep space missions":1.0,"extreme communication delays":1.0,"environmental uncertainty":1.0,"real-time ground operations":1.0,"autonomous science operations":1.0}},"age_hours":2.761938516111111,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.3389,"joy":0.0052,"surprise":0.0074,"sadness":0.0098,"fear":0.6126,"anger":0.0163,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a POMDP framework for autonomous science operations in deep space missions. The concrete action is the development and testing of an algorithm that reduces sample identification errors by nearly 40% compared to the baseline ConOps. It is still in the early stages of development and has not been deployed.","key_impact_metrics":["Sample identification errors reduced by 40%"],"technology_tags":["POMDP","Bayesian network","Autonomous science operations"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:25.723006Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6f881925510e","title":"$\\mathsf{P} \\neq \\mathsf{NP}$: A Non","content":"arXiv:2510.08814v1 Announce Type: new Abstract: We give a compositional, information-theoretic framework that turns short programs into locality on many independent blocks, and combine it with symmetry and sparsity of masked random Unique-SAT to obtain distributional lower bounds that contradict the self-reduction upper bound under $\\mathsf{P}=\\mathsf{NP}$. We work in the weakness quantale $w_Q=K_{\\mathrm{poly}}(\\cdot\\mid\\cdot)$. For an efficiently samplable ensemble $D_m$ made by masking random $3$-CNFs with fresh $S_m\\ltimes(\\mathbb{Z}_2)^m$ symmetries and a small-seed Valiant--Vazirani isolation layer, we prove a Switching-by-Weakness normal form: for any polytime decoder $P$ of description length $\\le \\delta t$ (with $t=\\Theta(m)$ blocks), a short wrapper $W$ makes $(P\\circ W)$ per-bit local on a $\\gamma$-fraction of blocks. Two ingredients then force near-randomness on $\\Omega(t)$ blocks for every short decoder: (a) a sign-invariant neutrality lemma giving $\\Pr[X_i=1\\mid \\mathcal{I}]=1/2$ for any sign-invariant view $\\mathcal{I}$; and (b) a template sparsification theorem at logarithmic radius showing that any fixed local rule appears with probability $m^{-\\Omega(1)}$. Combined with single-block bounds for tiny $\\mathrm{ACC}^0$/streaming decoders, this yields a success bound $2^{-\\Omega(t)}$ and, by Compression-from-Success, $K_{\\mathrm{poly}}\\big((X_1,\\ldots,X_t)\\mid(\\Phi_1,\\ldots,\\Phi_t)\\big)\\ge \\eta t$. If $\\mathsf{P}=\\mathsf{NP}$, a uniform constant-length program maps any on-promise instance to its unique witness in polytime (bit fixing via a $\\mathrm{USAT}$ decider), so $K_{\\mathrm{poly}}(X\\mid\\Phi)\\le O(1)$ and the tuple complexity is $O(1)$, contradicting the linear bound. The proof is non-relativizing and non-natural; symmetry, sparsification, and switching yield a quantale upper-lower clash, hence $\\mathsf{P}\\ne\\mathsf{NP}$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08814","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.604600","language":"en","tags":["research","csai","cscc","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Ben Goertzel","raw_content_length":1872,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["Unique-SAT"],"persons":["Vazirani","D_m$","w_Q"],"locations":[],"monetary":["\\gamma$-fraction","\\Omega(t)$","t=\\Theta(m)$","3$-CNFs","S_m\\ltimes(\\mathbb{Z}_2)^m$"]},"char_count":1871,"language_detected":"en","key_concepts":{"key_phrases":["mathsfP neq","A Non","arXiv251008814v1 Announce Type","new Abstract","a compositional information-theoretic framework","short programs","locality","many independent blocks","symmetry","sparsity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"mathsfP neq":2.0,"A Non":2.0,"arXiv251008814v1 Announce Type":1.0,"new Abstract":1.0,"a compositional information-theoretic framework":1.0,"short programs":1.0,"locality":1.0,"many independent blocks":1.0,"symmetry":1.0,"sparsity":1.0}},"age_hours":2.7619693452777776,"is_recent":true,"quality_score":1.0,"sentiment_score":1.6475,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6705,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7755,"joy":0.0598,"surprise":0.1351,"sadness":0.0089,"fear":0.0051,"anger":0.0115,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":8,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":9,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This is a theoretical computer science paper addressing the P vs NP problem. While it is a significant theoretical breakthrough, it has no direct, concrete sustainability impact. The research is at a very early stage and does not involve any deployed technology or measurable environmental outcomes.","key_impact_metrics":[],"technology_tags":["Theoretical Computer Science","Complexity Theory"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:27:28.344547Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13a76bf062a4","title":"Audible Networks: Deconstructing and Manipulating Sounds with Deep Non","content":"arXiv:2510.08816v1 Announce Type: new Abstract: We propose the use of Non-Negative Autoencoders (NAEs) for sound deconstruction and user-guided manipulation of sounds for creative purposes. NAEs offer a versatile and scalable extension of traditional Non-Negative Matrix Factorization (NMF)-based approaches for interpretable audio decomposition. By enforcing non-negativity constraints through projected gradient descent, we obtain decompositions where internal weights and activations can be directly interpreted as spectral shapes and temporal envelopes, and where components can themselves be listened to as individual sound events. In particular, multi-layer Deep NAE architectures enable hierarchical representations with an adjustable level of granularity, allowing sounds to be deconstructed at multiple levels of abstraction: from high-level note envelopes down to fine-grained spectral details. This framework enables a wide new range of expressive, controllable, and randomized sound transformations. We introduce novel manipulation operations including cross-component and cross-layer synthesis, hierarchical deconstructions, and several randomization strategies that control timbre and event density. Through visualizations and resynthesis of practical examples, we demonstrate how NAEs can serve as flexible and interpretable tools for object-based sound editing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08816","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.605004","language":"en","tags":["research","cssd","preprints","eessas","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Juan Jos\\'e Burred, Carmine-Emanuele Cella","raw_content_length":1378,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Non-Negative Matrix Factorization","Deep NAE","Non-Negative Autoencoders"],"persons":[],"locations":[],"monetary":[]},"char_count":1377,"language_detected":"en","key_concepts":{"key_phrases":["Audible Networks","Manipulating Sounds","Deep Non","NAEs","arXiv251008816v1 Announce Type","new Abstract","the use","Non-Negative Autoencoders","sound deconstruction","user-guided manipulation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Audible Networks":2.0,"Manipulating Sounds":2.0,"Deep Non":2.0,"NAEs":2.0,"arXiv251008816v1 Announce Type":1.0,"new Abstract":1.0,"the use":1.0,"Non-Negative Autoencoders":1.0,"sound deconstruction":1.0,"user-guided manipulation":1.0}},"age_hours":2.761984963888889,"is_recent":true,"quality_score":1.0,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.882,"joy":0.0507,"surprise":0.0278,"sadness":0.0046,"fear":0.0108,"anger":0.0146,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for sound deconstruction using NAEs. While the technology itself doesn't directly address climate change, it could potentially be used in applications that indirectly support sustainability, such as improving the efficiency of sound-based monitoring systems or creating more engaging educational content. The research is at an early stage, with no deployed units or quantified impact data.","key_impact_metrics":[],"technology_tags":["Non-Negative Autoencoders","Audio Decomposition","Deep Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:27:31.152197Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_84752e131b6d","title":"Joint Detection, Channel Estimation and Interference Nulling for Terrestrial-Satellite Downlink Co","content":"arXiv:2510.08824v1 Announce Type: new Abstract: The upper mid-band FR3 spectrum (7-24 GHz) has garnered significant interest for future cellular services. However, utilizing a large portion of this band requires careful interference coordination with incumbent satellite systems. This paper investigates interference from high-power terrestrial base stations (TN-BSs) to satellite downlink receivers. A central challenge is that the victim receivers, i.e., ground-based non-terrestrial user equipment (NTN-UEs) such as satellite customer premises equipment, must first be detected and their channels estimated before the TN-BS can effectively place nulls in their directions. We explore a potential solution where NTN-UEs periodically transmit preambles or beacon signals that TN-BSs can use for detection and channel estimation. The performance of this nulling approach is analyzed in a simplified scenario with a single victim, revealing the interplay between path loss and estimation quality in determining nulling performance. To further validate the method, we conduct a detailed multi-user site-specific ray-tracing (RT) simulation in a rural environment. The results show that the proposed nulling approach is effective under realistic parameters, even with high densities of victim units, although TN-BS may require a substantial number of antennas.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08824","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.605836","language":"en","tags":["research","preprints","eesssy","cssy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Shizhen Jia, Mingjun Ying, Marco Mezzavilla, Doru Calin, Theodore S. Rappaport, Sundeep Rangan","raw_content_length":1358,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["NTN","Channel Estimation","Joint Detection,","Terrestrial-Satellite Downlink Co arXiv:2510.08824v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1357,"language_detected":"en","key_concepts":{"key_phrases":["Joint Detection","Channel Estimation","Interference","Nulling","Terrestrial-Satellite Downlink Co","arXiv251008824v1 Announce Type","new Abstract","The upper mid-band FR3 spectrum","7-24 GHz","significant interest"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Joint Detection":2.0,"Channel Estimation":2.0,"Interference":2.0,"Nulling":2.0,"Terrestrial-Satellite Downlink Co":2.0,"arXiv251008824v1 Announce Type":1.0,"new Abstract":1.0,"The upper mid-band FR3 spectrum":1.0,"7-24 GHz":1.0,"significant interest":1.0}},"age_hours":2.7620171075,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9026,"joy":0.0094,"surprise":0.0287,"sadness":0.0126,"fear":0.0273,"anger":0.0129,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a method for terrestrial base stations to avoid interfering with satellite downlink receivers, which could enable more efficient use of the FR3 spectrum. The concrete action is the proposed nulling approach, validated through ray-tracing simulation. However, it is still in the applied research phase with no deployed units or economic viability demonstrated, making it vaporware at this stage.","key_impact_metrics":["Nulling performance under realistic parameters","Number of antennas required for TN-BS"],"technology_tags":["Terrestrial-Satellite Communication","Interference Nulling","Ray-Tracing Simulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:34.249191Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e1a48dc87a5e","title":"CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization","content":"arXiv:2510.08829v1 Announce Type: new Abstract: The increasing adoption of LLM agents with access to numerous tools and sensitive data significantly widens the attack surface for indirect prompt injections. Due to the context-dependent nature of attacks, however, current defenses are often ill-calibrated as they cannot reliably differentiate malicious and benign instructions, leading to high false positive rates that prevent their real-world adoption. To address this, we present a novel approach inspired by the fundamental principle of computer security: data should not contain executable instructions. Instead of sample-level classification, we propose a token-level sanitization process, which surgically removes any instructions directed at AI systems from tool outputs, capturing malicious instructions as a byproduct. In contrast to existing safety classifiers, this approach is non-blocking, does not require calibration, and is agnostic to the context of tool outputs. Further, we can train such token-level predictors with readily available instruction-tuning data only, and don't have to rely on unrealistic prompt injection examples from challenges or of other synthetic origin. In our experiments, we find that this approach generalizes well across a wide range of attacks and benchmarks like AgentDojo, BIPIA, InjecAgent, ASB and SEP, achieving a 7-10x reduction of attack success rate (ASR) (34% to 3% on AgentDojo), without impairing agent utility in both benign and malicious settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08829","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.607053","language":"en","tags":["cscr","research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Debeshee Das, Luca Beurer-Kellner, Marc Fischer, Maximilian Baader","raw_content_length":1508,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["LLM","Securing AI Agents with Surgical Precision Prompt Sanitization arXiv:2510.08829v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1507,"language_detected":"en","key_concepts":{"key_phrases":["CommandSans","Securing","AI Agents","Surgical Precision Prompt Sanitization","Announce Type","new Abstract","The increasing adoption","LLM agents","access","numerous tools"],"filter_categories":{"ai_ml":["AI Agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CommandSans":2.0,"Securing":2.0,"AI Agents":2.0,"Surgical Precision Prompt Sanitization":2.0,"Announce Type":1.0,"new Abstract":1.0,"The increasing adoption":1.0,"LLM agents":1.0,"access":1.0,"numerous tools":1.0}},"age_hours":2.7620633097222225,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7197,"joy":0.0077,"surprise":0.0089,"sadness":0.0109,"fear":0.1768,"anger":0.0563,"disgust":0.0198},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a novel approach to securing AI agents, which could indirectly support sustainability by preventing malicious use of AI in areas like energy management or resource allocation. The approach achieves a 7-10x reduction of attack success rate (ASR) on AgentDojo, but it's currently in the applied research phase with no deployed units. The technical credibility is supported by peer-reviewed research and specific metrics.","key_impact_metrics":["7-10x reduction of attack success rate (ASR)","34% to 3% on AgentDojo"],"technology_tags":["AI security","prompt sanitization","LLM agents"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:27:37.578966Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf2038ebc23b","title":"Everyone prefers human writers, including AI","content":"arXiv:2510.08831v1 Announce Type: new Abstract: As AI writing tools become widespread, we need to understand how both humans and machines evaluate literary style, a domain where objective standards are elusive and judgments are inherently subjective. We conducted controlled experiments using Raymond Queneau's Exercises in Style (1947) to measure attribution bias across evaluators. Study 1 compared human participants (N=556) and AI models (N=13) evaluating literary passages from Queneau versus GPT-4-generated versions under three conditions: blind, accurately labeled, and counterfactually labeled. Study 2 tested bias generalization across a 14$\\times$14 matrix of AI evaluators and creators. Both studies revealed systematic pro-human attribution bias. Humans showed +13.7 percentage point (pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3 percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect (P$<$0.001). Study 2 confirmed this bias operates across AI architectures (+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically devalue creative content when labeled as \"AI-generated\" regardless of which AI created it. We also find that attribution labels cause evaluators to invert assessment criteria, with identical features receiving opposing evaluations based solely on perceived authorship. This suggests AI models have absorbed human cultural biases against artificial creativity during training. Our study represents the first controlled comparison of attribution bias between human and artificial evaluators in aesthetic judgment, revealing that AI systems not only replicate but amplify this human tendency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08831","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.607504","language":"en","tags":["research","csai","preprints","cshc","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Wouter Haverals, Meredith Martin","raw_content_length":1695,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":["AI arXiv:2510.08831v1 Announce Type: new Abstract"],"persons":["Queneau","Raymond Queneau's","Cohen"],"locations":[],"monetary":[]},"char_count":1694,"language_detected":"en","key_concepts":{"key_phrases":["Everyone","human writers","Announce Type","new Abstract","AI writing tools","both humans","machines","literary style","a domain","objective standards"],"filter_categories":{"ai_ml":["AI writing tools"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Everyone":2.0,"human writers":2.0,"Announce Type":1.0,"new Abstract":1.0,"AI writing tools":1.0,"both humans":1.0,"machines":1.0,"literary style":1.0,"a domain":1.0,"objective standards":1.0}},"age_hours":2.762079920833333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8906,"joy":0.016,"surprise":0.0623,"sadness":0.0047,"fear":0.0077,"anger":0.0091,"disgust":0.0096},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":8,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores bias in AI and human evaluation of creative content. While it doesn't directly address climate change, understanding and mitigating biases in AI systems could indirectly impact sustainability efforts if AI is used in climate modeling or resource allocation. The study uses controlled experiments with quantified results (percentage point bias) and is published on arXiv, suggesting peer review.","key_impact_metrics":["+13.7 percentage point (pp) bias","+34.3 percentage point bias"],"technology_tags":["AI bias","Attribution bias","GPT-4"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:27:40.754098Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6b4190c091bd","title":"Identifying Video Game Debugging Bottlenecks: An Industry Perspective","content":"arXiv:2510.08834v1 Announce Type: new Abstract: Conventional debugging techniques used in traditional software are similarly used when debugging video games. However, the reality of video games require its own set of unique debugging techniques such as On-Screen Console, Debug Draws, Debug Camera, Cheats and In-Game Menus, and Data Scrubbing. In this article, we provide insights from a video game studio on how 20 seasoned industry game developers debug during the production of a game. Our experiments rely on the recordings of debugging sessions for the most critical bugs categorized as Crashes, Object Behaviors, and Object Persistence. In this paper, we focus on identifying the debugging activities that bottleneck bug resolution. We also identify the debugging tools used to perform debugging techniques. Lastly, we present how different disciplines collaborate during debugging and how technical roles are at the core of debugging. Our thematic analysis has identified game developers spend 36.6\\% of their time inspecting game artifacts and 35.1\\% of their time reproducing the bug locally.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08834","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.607894","language":"en","tags":["csse","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Carlos Pinto Gomez, Fabio Petrillo","raw_content_length":1103,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Data Scrubbing","Crashes"],"persons":["Debug Camera","Debug Draws","arXiv:2510.08834v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1102,"language_detected":"en","key_concepts":{"key_phrases":["Video Game Debugging Bottlenecks","video games","arXiv251008834v1 Announce Type","new Abstract","Conventional debugging techniques","traditional software","the reality","its own set","unique debugging techniques","On-Screen Console"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Video Game Debugging Bottlenecks":2.0,"video games":2.0,"arXiv251008834v1 Announce Type":1.0,"new Abstract":1.0,"Conventional debugging techniques":1.0,"traditional software":1.0,"the reality":1.0,"its own set":1.0,"unique debugging techniques":1.0,"On-Screen Console":1.0}},"age_hours":2.762096275277778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9067,"joy":0.0243,"surprise":0.0504,"sadness":0.0045,"fear":0.0041,"anger":0.0061,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":4,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper identifies bottlenecks in video game debugging, focusing on time spent inspecting artifacts (36.6%) and reproducing bugs (35.1%). While it doesn't directly address climate impact, optimizing debugging processes could indirectly reduce energy consumption by developers, but this is theoretical. The study is based on recordings and thematic analysis, providing some evidence, but lacks peer review.","key_impact_metrics":["Time spent inspecting game artifacts 36.6%","Time spent reproducing the bug locally 35.1%"],"technology_tags":["Software Debugging","Game Development"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:27:43.570841Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_672d75526761","title":"The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective","content":"arXiv:2510.08840v1 Announce Type: new Abstract: As machine learning (ML) algorithms are increasingly used in medical image analysis, concerns have emerged about their potential biases against certain social groups. Although many approaches have been proposed to ensure the fairness of ML models, most existing works focus only on medical image diagnosis tasks, such as image classification and segmentation, and overlooked prognosis scenarios, which involve predicting the likely outcome or progression of a medical condition over time. To address this gap, we introduce FairTTE, the first comprehensive framework for assessing fairness in time-to-event (TTE) prediction in medical imaging. FairTTE encompasses a diverse range of imaging modalities and TTE outcomes, integrating cutting-edge TTE prediction and fairness algorithms to enable systematic and fine-grained analysis of fairness in medical image prognosis. Leveraging causal analysis techniques, FairTTE uncovers and quantifies distinct sources of bias embedded within medical imaging datasets. Our large-scale evaluation reveals that bias is pervasive across different imaging modalities and that current fairness methods offer limited mitigation. We further demonstrate a strong association between underlying bias sources and model disparities, emphasizing the need for holistic approaches that target all forms of bias. Notably, we find that fairness becomes increasingly difficult to maintain under distribution shifts, underscoring the limitations of existing solutions and the pressing need for more robust, equitable prognostic models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08840","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.609122","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Thai-Hoang Pham, Jiayuan Chen, Seungyeon Lee, Yuanlong Wang, Sayoko Moroi, Xueru Zhang, Ping Zhang","raw_content_length":1605,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["TTE"],"persons":[],"locations":[],"monetary":[]},"char_count":1604,"language_detected":"en","key_concepts":{"key_phrases":["The Boundaries","Fair AI","Medical Image Prognosis","A Causal Perspective","arXiv251008840v1 Announce Type","new Abstract","medical image analysis","concerns","their potential biases","certain social groups"],"filter_categories":{"ai_ml":["Fair AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Boundaries":2.0,"Fair AI":2.0,"Medical Image Prognosis":2.0,"A Causal Perspective":2.0,"arXiv251008840v1 Announce Type":1.0,"new Abstract":1.0,"medical image analysis":1.0,"concerns":1.0,"their potential biases":1.0,"certain social groups":1.0}},"age_hours":2.7621428766666667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7203,"joy":0.02,"surprise":0.0357,"sadness":0.0173,"fear":0.1487,"anger":0.0462,"disgust":0.0118},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a framework (FairTTE) for assessing fairness in medical image prognosis, uncovering and quantifying bias within medical imaging datasets. While it identifies a problem and proposes a solution, it's in the early stages of research with no deployed technology or measured outcomes in a real-world setting. The vaporware flag is raised due to the lack of deployment data.","key_impact_metrics":["Bias quantification in medical imaging datasets","Disparities in model predictions"],"technology_tags":["AI fairness","Medical image analysis","Causal analysis"],"sdg_alignment":[3,10],"analyzed_at":"2025-10-29T09:27:46.793864Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13bcf53fe58b","title":"Maple: A Multi","content":"arXiv:2510.08842v1 Announce Type: new Abstract: Training deep learning (DL) models across Graphics Processing Unit (GPU) clusters is technically challenging. One aspect is that users have to compose command lines to adapt to the heterogeneous launchers, schedulers, affinity options, DL framework arguments, and environment variables. Composing correct command lines is error-prone and can easily frustrate users, impeding research or wasting resources. In this work, we present Maple, a multi-agent system that generates correct DL command lines with users' natural language input. Maple consists of four agents with the functionalities of information extraction, template retrieval, command line verification, and error correction. We evaluate Maple on nine GPU clusters across national computing centers in the U.S., five representative deep learning model families, and four commonly used parallel DL training paradigms. Our experiments also cover schedulers of SLURM and PBS and heterogeneous architectures, such as NVIDIA A100/H200 GPUs and Intel Max series GPUs. Maple achieves 92.0% accuracy in generating command lines across the 567 test cases. Leverage multiple language models with an aggregated size of 10B parameters, Maple delivers comparable performance to the state-of-the-art models of GPT-5, Claude, and Gemini. Together, these results highlight Maple's practical value in enabling portable and scalable distributed DL across heterogeneous HPC environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08842","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.609550","language":"en","tags":["computer-science","csdc","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Molang Wu, Zhao Zhang","raw_content_length":1477,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["Graphics Processing Unit","PBS","GPU"],"persons":["Maple"],"locations":["U.S."],"monetary":[]},"char_count":1476,"language_detected":"en","key_concepts":{"key_phrases":["Maple","users","Announce Type","new Abstract","Training deep learning DL models","Graphics Processing Unit GPU clusters","One aspect","command lines","the heterogeneous launchers","schedulers"],"filter_categories":{"ai_ml":["Training deep learning DL models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Maple":3.0,"users":2.0,"Announce Type":1.0,"new Abstract":1.0,"Training deep learning DL models":1.0,"Graphics Processing Unit GPU clusters":1.0,"One aspect":1.0,"command lines":1.0,"the heterogeneous launchers":1.0,"schedulers":1.0}},"age_hours":2.762159123611111,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0673,"joy":0.0012,"surprise":0.0038,"sadness":0.0088,"fear":0.0228,"anger":0.8402,"disgust":0.0558},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"Maple aims to improve the efficiency of training deep learning models on GPU clusters, which could indirectly reduce energy consumption. The system achieves 92.0% accuracy in generating command lines across 567 test cases, demonstrating its potential. However, it is still in the applied research stage with no clear path to economic viability or large-scale deployment.","key_impact_metrics":["92.0% accuracy in command line generation","567 test cases"],"technology_tags":["Multi-agent system","Deep learning","GPU clusters"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T09:27:49.912712Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ffa337244fae","title":"What Is Your Agent's GPA? A Framework for Evaluating Agent Goal","content":"arXiv:2510.08847v1 Announce Type: new Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation paradigm based on an agent's operational loop of setting goals, devising plans, and executing actions. The framework includes five evaluation metrics: Goal Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan Adherence. Logical Consistency checks that an agent's actions are consistent with its prior actions. Execution Efficiency checks whether the agent executes in the most efficient way to achieve its goal. Plan Quality checks whether an agent's plans are aligned with its goals; Plan Adherence checks if an agent's actions are aligned with its plan; and Goal Fulfillment checks that agent's final outcomes match the stated goals. Our experimental results on two benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for a production-grade data agent - show that this framework (a) provides a systematic way to cover a broad range of agent failures, including all agent errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that exhibit strong agreement with human annotation, covering 80% to over 95% errors; and (c) localizes errors with 86% agreement to enable targeted improvement of agent performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08847","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.609949","language":"en","tags":["research","csai","csma","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Allison Sihan Jia, Daniel Huang, Nikhil Vytla, Nirvika Choudhury, John C Mitchell, Anupam Datta","raw_content_length":1292,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Plan Quality","Goal Fulfillment","Execution Efficiency","GPA"],"persons":["Goal arXiv:2510.08847v1"],"locations":[],"monetary":[]},"char_count":1291,"language_detected":"en","key_concepts":{"key_phrases":["What","Your Agents GPA","A Framework","Evaluating Agent Goal","Execution Efficiency","arXiv251008847v1 Announce Type","new Abstract","the Agent GPA Goal-Plan-Action framework","an evaluation paradigm","an agents operational loop"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Your Agents GPA":2.0,"A Framework":2.0,"Evaluating Agent Goal":2.0,"Execution Efficiency":2.0,"arXiv251008847v1 Announce Type":1.0,"new Abstract":1.0,"the Agent GPA Goal-Plan-Action framework":1.0,"an evaluation paradigm":1.0,"an agents operational loop":1.0}},"age_hours":2.762175513888889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9063,"joy":0.0138,"surprise":0.0468,"sadness":0.0029,"fear":0.0084,"anger":0.0172,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (Agent GPA) for evaluating AI agent performance, focusing on goal fulfillment, consistency, efficiency, plan quality, and adherence. While it shows promise in improving agent performance and localizing errors (86% agreement), it's still in the research phase with limited deployment and unclear economic viability. The impact on climate is indirect, as it could improve the efficiency of AI agents used in sustainability applications.","key_impact_metrics":["Error localization agreement 86%","Error coverage 80-95%"],"technology_tags":["AI agent evaluation","Goal-Plan-Action framework"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T09:27:53.347974Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_77a1d326c400","title":"FOLK: Fast Open","content":"arXiv:2510.08849v1 Announce Type: new Abstract: Open-vocabulary 3D instance segmentation seeks to segment and classify instances beyond the annotated label space. Existing methods typically map 3D instances to 2D RGB-D images, and then employ vision-language models (VLMs) for classification. However, such a mapping strategy usually introduces noise from 2D occlusions and incurs substantial computational and memory costs during inference, slowing down the inference speed. To address the above problems, we propose a Fast Open-vocabulary 3D instance segmentation method via Label-guided Knowledge distillation (FOLK). Our core idea is to design a teacher model that extracts high-quality instance embeddings and distills its open-vocabulary knowledge into a 3D student model. In this way, during inference, the distilled 3D model can directly classify instances from the 3D point cloud, avoiding noise caused by occlusions and significantly accelerating the inference process. Specifically, we first design a teacher model to generate a 2D CLIP embedding for each 3D instance, incorporating both visibility and viewpoint diversity, which serves as the learning target for distillation. We then develop a 3D student model that directly produces a 3D embedding for each 3D instance. During training, we propose a label-guided distillation algorithm to distill open-vocabulary knowledge from label-consistent 2D embeddings into the student model. FOLK conducted experiments on the ScanNet200 and Replica datasets, achieving state-of-the-art performance on the ScanNet200 dataset with an AP50 score of 35.7, while running approximately 6.0x to 152.2x faster than previous methods. All codes will be released after the paper is accepted.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08849","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.610390","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Hongrui Wu, Zhicheng Gao, Jin Cao, Kelu Yao, Wen Shen, Zhihua Wei","raw_content_length":1736,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["RGB"],"persons":[],"locations":[],"monetary":[]},"char_count":1735,"language_detected":"en","key_concepts":{"key_phrases":["FOLK","Fast Open","Announce Type","new Abstract","Open-vocabulary 3D instance segmentation","instances","the annotated label space","Existing methods","3D instances","2D RGB-D images"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"FOLK":2.0,"Fast Open":2.0,"Announce Type":1.0,"new Abstract":1.0,"Open-vocabulary 3D instance segmentation":1.0,"instances":1.0,"the annotated label space":1.0,"Existing methods":1.0,"3D instances":1.0,"2D RGB-D images":1.0}},"age_hours":2.7621910577777777,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.938,"joy":0.0039,"surprise":0.0224,"sadness":0.0109,"fear":0.0051,"anger":0.013,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new method (FOLK) for 3D instance segmentation, claiming significant speed improvements (6.0x to 152.2x faster). While the method shows promise and has metrics on the ScanNet200 dataset, it's still in the research phase with no deployed units or real-world applications yet, making it vaporware. The climate impact is indirect, potentially improving efficiency in areas like robotics and building design, but not directly reducing emissions.","key_impact_metrics":["AP50 score of 35.7","6.0x to 152.2x faster"],"technology_tags":["3D instance segmentation","vision-language models","knowledge distillation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:27:56.553017Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d8fbe0395336","title":"Repository","content":"arXiv:2510.08850v1 Announce Type: new Abstract: Modern codebases make it hard for developers and AI coding assistants to find the right source files when answering questions like \"How does this feature work?\" or \"Where was the bug introduced?\" Traditional code search (keyword or IR based) often misses semantic context and cross file links, while large language models (LLMs) understand natural language but lack repository specific detail. We present a method for file path retrieval that fine tunes a strong LLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file paths directly from a natural language query. To build training data, we introduce six code aware strategies that use abstract syntax tree (AST) structure and repository content to generate realistic question-answer pairs, where answers are sets of file paths. The strategies range from single file prompts to hierarchical repository summaries, providing broad coverage. We fine tune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch, and obtain high retrieval accuracy: up to 91\\% exact match and 93\\% recall on held out queries, clearly beating single strategy training. On a large codebase like PyTorch (about 4,000 Python files), the model reaches 59\\% recall, showing scalability. We analyze how multi level code signals help the LLM reason over cross file context and discuss dataset design, limits (for example, context length in very large repos), and future integration of retrieval with LLM based code intelligence.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08850","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.610797","language":"en","tags":["research","csse","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Vasudha Yanuganti, Ishaan Puri, Swapnil Chhatre, Mantinder Singh, Ashok Jallepalli, Hritvik Shrivastava, Pradeep Kumar Sharma","raw_content_length":1535,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1534,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251008850v1 Announce Type","new Abstract","developers","AI coding assistants","the right source files","questions","this feature","the bug","Traditional code search","keyword"],"filter_categories":{"ai_ml":["AI coding assistants"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251008850v1 Announce Type":1.0,"new Abstract":1.0,"developers":1.0,"AI coding assistants":1.0,"the right source files":1.0,"questions":1.0,"this feature":1.0,"the bug":1.0,"Traditional code search":1.0,"keyword":1.0}},"age_hours":2.762208245555555,"is_recent":true,"quality_score":1.0,"sentiment_score":5.589500000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1179,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8947,"joy":0.0028,"surprise":0.0704,"sadness":0.0106,"fear":0.0042,"anger":0.0097,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method for improving code search using LLMs, which could indirectly support sustainability efforts by making software development more efficient. The research shows high retrieval accuracy (up to 91% exact match) on held-out queries, but it is still in the applied research phase with no real-world deployment. The impact on climate is indirect, as it depends on how the improved code search is used in sustainability-related projects.","key_impact_metrics":["Retrieval accuracy: 91%","Recall on PyTorch: 59%"],"technology_tags":["Large Language Models","Code Search","Abstract Syntax Tree"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:27:59.820795Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e6cc83df39c0","title":"CDE: Concept","content":"arXiv:2510.08851v1 Announce Type: new Abstract: Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\\% success rate in a real-world manipulation task.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08851","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.611181","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Le Mao, Andrew H. Liu, Renos Zabounidis, Zachary Kingston, Joseph Campbell","raw_content_length":1224,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["Concept-Driven Exploration","CDE","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1223,"language_detected":"en","key_concepts":{"key_phrases":["CDE","Concept","arXiv251008851v1 Announce Type","new Abstract","Intelligent exploration","a critical challenge","reinforcement learning","visual control tasks","low-dimensional state-based RL","visual RL"],"filter_categories":{"ai_ml":["reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CDE":3.0,"Concept":2.0,"arXiv251008851v1 Announce Type":1.0,"new Abstract":1.0,"Intelligent exploration":1.0,"a critical challenge":1.0,"reinforcement learning":1.0,"visual control tasks":1.0,"low-dimensional state-based RL":1.0,"visual RL":1.0}},"age_hours":2.7622243630555556,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7159,"joy":0.0108,"surprise":0.0306,"sadness":0.0235,"fear":0.025,"anger":0.0919,"disgust":0.1023},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a novel reinforcement learning approach (CDE) for visual control tasks, demonstrating real-world transfer on a Franka Research 3 arm with an 80% success rate in a manipulation task. While the technology shows promise, its direct climate impact is currently theoretical and requires further development and deployment in relevant sectors to quantify its potential for reducing emissions or improving resource efficiency. The peer-reviewed nature of the work lends credibility to the technical claims.","key_impact_metrics":["Success rate in real-world manipulation task: 80%"],"technology_tags":["Reinforcement Learning","Vision-Language Models","Robotics","Visual Control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:28:03.584719Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_218a0a877be2","title":"On the Alignment Between Supervised and Self","content":"arXiv:2510.08852v1 Announce Type: new Abstract: Self-supervised contrastive learning (CL) has achieved remarkable empirical success, often producing representations that rival supervised pre-training on downstream tasks. Recent theory explains this by showing that the CL loss closely approximates a supervised surrogate, Negatives-Only Supervised Contrastive Learning (NSCL) loss, as the number of classes grows. Yet this loss-level similarity leaves an open question: {\\em Do CL and NSCL also remain aligned at the representation level throughout training, not just in their objectives?} We address this by analyzing the representation alignment of CL and NSCL models trained under shared randomness (same initialization, batches, and augmentations). First, we show that their induced representations remain similar: specifically, we prove that the similarity matrices of CL and NSCL stay close under realistic conditions. Our bounds provide high-probability guarantees on alignment metrics such as centered kernel alignment (CKA) and representational similarity analysis (RSA), and they clarify how alignment improves with more classes, higher temperatures, and its dependence on batch size. In contrast, we demonstrate that parameter-space coupling is inherently unstable: divergence between CL and NSCL weights can grow exponentially with training time. Finally, we validate these predictions empirically, showing that CL-NSCL alignment strengthens with scale and temperature, and that NSCL tracks CL more closely than other supervised objectives. This positions NSCL as a principled bridge between self-supervised and supervised learning. Our code and project page are available at [\\href{https://github.com/DLFundamentals/understanding_ssl_v2}{code}, \\href{https://dlfundamentals.github.io/cl-nscl-representation-alignment/}{project page}].","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08852","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.611612","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Achleshwar Luthra, Priyadarsi Mishra, Tomer Galanti","raw_content_length":1852,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["NSCL"],"persons":[],"locations":[],"monetary":[]},"char_count":1847,"language_detected":"en","key_concepts":{"key_phrases":["the Alignment","Supervised","Self","NSCL","Announce Type","new Abstract","Self-supervised contrastive learning","remarkable empirical success","representations","rival"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Alignment":2.0,"Supervised":2.0,"Self":2.0,"NSCL":2.0,"Announce Type":1.0,"new Abstract":1.0,"Self-supervised contrastive learning":1.0,"remarkable empirical success":1.0,"representations":1.0,"rival":1.0}},"age_hours":2.7622408847222224,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7949,"joy":0.0246,"surprise":0.1431,"sadness":0.0088,"fear":0.0108,"anger":0.0114,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes the alignment between self-supervised and supervised learning methods, specifically contrastive learning (CL) and Negatives-Only Supervised Contrastive Learning (NSCL). The research provides theoretical bounds and empirical validation on the similarity of representations learned by these methods. While the research is scientifically sound and provides insights into representation learning, it is currently in the basic research stage with no immediate deployment or measurable environmental impact.","key_impact_metrics":["Centered Kernel Alignment (CKA) score","Representational Similarity Analysis (RSA) score"],"technology_tags":["Self-Supervised Learning","Contrastive Learning","Representation Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:28:06.984417Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_44401774306c","title":"Time","content":"arXiv:2510.08855v1 Announce Type: new Abstract: Understanding the internal representations of large language models is crucial for ensuring their reliability and safety, with sparse autoencoders (SAEs) emerging as a promising interpretability approach. However, current SAE training methods face feature absorption, where features (or neurons) are absorbed into each other to minimize $L_1$ penalty, making it difficult to consistently identify and analyze model behaviors. We introduce Adaptive Temporal Masking (ATM), a novel training approach that dynamically adjusts feature selection by tracking activation magnitudes, frequencies, and reconstruction contributions to compute importance scores that evolve over time. ATM applies a probabilistic masking mechanism based on statistical thresholding of these importance scores, creating a more natural feature selection process. Through extensive experiments on the Gemma-2-2b model, we demonstrate that ATM achieves substantially lower absorption scores compared to existing methods like TopK and JumpReLU SAEs, while maintaining excellent reconstruction quality. These results establish ATM as a principled solution for learning stable, interpretable features in neural networks, providing a foundation for more reliable model analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08855","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.612004","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"T. Ed Li, Junyu Ren","raw_content_length":1291,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Temporal Masking","ATM","SAE"],"persons":[],"locations":[],"monetary":["$L_1$"]},"char_count":1290,"language_detected":"en","key_concepts":{"key_phrases":["Time","arXiv251008855v1 Announce Type","new Abstract","the internal representations","large language models","their reliability","safety","sparse autoencoders","SAEs","a promising interpretability approach"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Time":2.0,"arXiv251008855v1 Announce Type":1.0,"new Abstract":1.0,"the internal representations":1.0,"large language models":1.0,"their reliability":1.0,"safety":1.0,"sparse autoencoders":1.0,"SAEs":1.0,"a promising interpretability approach":1.0}},"age_hours":2.762256103888889,"is_recent":true,"quality_score":0.7,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9065,"joy":0.0043,"surprise":0.0129,"sadness":0.0246,"fear":0.0151,"anger":0.0224,"disgust":0.0142},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (ATM) for training sparse autoencoders to improve the interpretability of large language models. While interpretability is crucial for ensuring the safe and reliable deployment of these models, the direct climate impact is currently theoretical and indirect, as it focuses on improving model analysis rather than directly reducing emissions. The research is at an early stage, with experiments conducted on the Gemma-2-2b model, but no real-world deployment or quantified environmental benefits are presented.","key_impact_metrics":["Lower absorption scores compared to existing methods","Excellent reconstruction quality"],"technology_tags":["Large Language Models","Sparse Autoencoders","Interpretability"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:28:10.315716Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1cf257b092c0","title":"Sparse components distinguish visual pathways & their alignment to neural networks","content":"arXiv:2510.08858v1 Announce Type: new Abstract: The ventral, dorsal, and lateral streams in high-level human visual cortex are implicated in distinct functional processes. Yet, deep neural networks (DNNs) trained on a single task model the entire visual system surprisingly well, hinting at common computational principles across these pathways. To explore this inconsistency, we applied a novel sparse decomposition approach to identify the dominant components of visual representations within each stream. Consistent with traditional neuroscience research, we find a clear difference in component response profiles across the three visual streams -- identifying components selective for faces, places, bodies, text, and food in the ventral stream; social interactions, implied motion, and hand actions in the lateral stream; and some less interpretable components in the dorsal stream. Building on this, we introduce Sparse Component Alignment (SCA), a new method for measuring representational alignment between brains and machines that better captures the latent neural tuning of these two visual systems. Using SCA, we find that standard visual DNNs are more aligned with the ventral than either dorsal or lateral representations. SCA reveals these distinctions with greater resolution than conventional population-level geometry, offering a measure of representational alignment that is sensitive to a system's underlying axes of neural tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08858","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.612428","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Ammar I Marvi, Nancy G Kanwisher, Meenakshi Khosla","raw_content_length":1451,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1450,"language_detected":"en","key_concepts":{"key_phrases":["Sparse components","visual pathways","their alignment","neural networks","arXiv251008858v1 Announce Type","new Abstract","dorsal","lateral streams","high-level human visual cortex","distinct functional processes"],"filter_categories":{"ai_ml":["neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sparse components":2.0,"visual pathways":2.0,"their alignment":2.0,"neural networks":2.0,"arXiv251008858v1 Announce Type":1.0,"new Abstract":1.0,"dorsal":1.0,"lateral streams":1.0,"high-level human visual cortex":1.0,"distinct functional processes":1.0}},"age_hours":2.7622720902777775,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.2235,"joy":0.0059,"surprise":0.7336,"sadness":0.0028,"fear":0.0074,"anger":0.017,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on understanding visual pathways in the brain and comparing them to deep neural networks. While potentially leading to more efficient AI, which could indirectly reduce energy consumption, it's currently at a basic research stage with no concrete actions or measurable outcomes related to sustainability. The technical credibility is high due to the scientific nature of the research.","key_impact_metrics":[],"technology_tags":["sparse decomposition","neural networks","visual processing"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:28:13.339456Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_07cc3fc7269e","title":"Pattern Enhanced Multi","content":"arXiv:2510.08859v1 Announce Type: new Abstract: Large language models (LLMs) remain vulnerable to multi-turn jailbreaking attacks that exploit conversational context to bypass safety constraints gradually. These attacks target different harm categories (like malware generation, harassment, or fraud) through distinct conversational approaches (educational discussions, personal experiences, hypothetical scenarios). Existing multi-turn jailbreaking methods often rely on heuristic or ad hoc exploration strategies, providing limited insight into underlying model weaknesses. The relationship between conversation patterns and model vulnerabilities across harm categories remains poorly understood. We propose Pattern Enhanced Chain of Attack (PE-CoA), a framework of five conversation patterns to construct effective multi-turn jailbreaks through natural dialogue. Evaluating PE-CoA on twelve LLMs spanning ten harm categories, we achieve state-of-the-art performance, uncovering pattern-specific vulnerabilities and LLM behavioral characteristics: models exhibit distinct weakness profiles where robustness to one conversational pattern does not generalize to others, and model families share similar failure modes. These findings highlight limitations of safety training and indicate the need for pattern-aware defenses. Code available on: https://github.com/Ragib-Amin-Nihal/PE-CoA","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08859","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.612825","language":"en","tags":["cscr","research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Ragib Amin Nihal, Rui Wen, Kazuhiro Nakadai, Jun Sakuma","raw_content_length":1386,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["PE-CoA","Pattern Enhanced Multi arXiv:2510.08859v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1385,"language_detected":"en","key_concepts":{"key_phrases":["Pattern Enhanced Multi","arXiv251008859v1 Announce Type","new Abstract","Large language models","LLMs","jailbreaking attacks","conversational context","bypass safety constraints","These attacks","different harm categories"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Pattern Enhanced Multi":2.0,"arXiv251008859v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"jailbreaking attacks":1.0,"conversational context":1.0,"bypass safety constraints":1.0,"These attacks":1.0,"different harm categories":1.0}},"age_hours":2.7622880319444443,"is_recent":true,"quality_score":1.0,"sentiment_score":0.363,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9274,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5431,"joy":0.0032,"surprise":0.0128,"sadness":0.0187,"fear":0.3248,"anger":0.0511,"disgust":0.0464},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies vulnerabilities in LLMs that could be exploited to bypass safety constraints and generate harmful content. While the research itself doesn't directly impact climate change, it highlights the need for more robust AI safety measures, which could indirectly support sustainability by preventing the misuse of AI for harmful purposes. The research is at a basic research stage, with code available on GitHub.","key_impact_metrics":["State-of-the-art performance on jailbreaking 12 LLMs","Evaluation across 10 harm categories"],"technology_tags":["Large Language Models","AI Safety","Jailbreaking Attacks"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:28:16.264990Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2cbc73c9c548","title":"Multi-robot Rigid Formation Navigation via Synchronous Motion and Discrete","content":"arXiv:2510.02624v2 Announce Type: replace Abstract: Rigid-formation navigation of multiple robots is essential for applications such as cooperative transportation. This process involves a team of collaborative robots maintaining a predefined geometric configuration, such as a square, while in motion. For untethered collaborative motion, inter-robot communication must be conducted through a wireless network. Notably, few existing works offer a comprehensive solution for multi-robot formation navigation executable on microprocessor platforms via wireless networks, particularly for formations that must traverse complex curvilinear paths. To address this gap, we introduce a novel \"hold-and-hit\" communication-control framework designed to work seamlessly with the widely-used Robotic Operating System (ROS) platform. The hold-and-hit framework synchronizes robot movements in a manner robust against wireless network delays and packet loss. It operates over discrete-time communication-control cycles, making it suitable for implementation on contemporary microprocessors. Complementary to hold-and-hit, we propose an intra-cycle optimization approach that enables rigid formations to closely follow desired curvilinear paths, even under the nonholonomic movement constraints inherent to most vehicular robots. The combination of hold-and-hit and intra-cycle optimization ensures precise and reliable navigation even in challenging scenarios. Simulations in a virtual environment demonstrate the superiority of our method in maintaining a four-robot square formation along an S-shaped path, outperforming two existing approaches. Furthermore, real-world experiments validate the effectiveness of our framework: the robots maintained an inter-distance error within $\\pm 0.069m$ and an inter-angular orientation error within $\\pm19.15^{\\circ}$ while navigating along an S-shaped path at a fixed linear velocity of $0.1 m/s$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02624","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.937135","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Qun Yang, Soung Chang Liew","raw_content_length":1928,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["Robotic Operating System","Synchronous Motion and Discrete arXiv:2510.02624v2","ROS"],"persons":[],"locations":[],"monetary":[]},"char_count":1927,"language_detected":"en","key_concepts":{"key_phrases":["Multi-robot Rigid Formation Navigation","Synchronous Motion","Discrete","Announce Type","Abstract","Rigid-formation navigation","multiple robots","applications","cooperative transportation","This process"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multi-robot Rigid Formation Navigation":2.0,"Synchronous Motion":2.0,"Discrete":2.0,"Announce Type":1.0,"Abstract":1.0,"Rigid-formation navigation":1.0,"multiple robots":1.0,"applications":1.0,"cooperative transportation":1.0,"This process":1.0}},"age_hours":2.7739659830555556,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9348,"joy":0.0077,"surprise":0.0365,"sadness":0.0053,"fear":0.0049,"anger":0.0061,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research presents a novel framework for multi-robot navigation, validated through simulations and real-world experiments. While the direct climate impact is limited, the technology could potentially improve efficiency in cooperative transportation or other applications. The real-world experiments provide some evidence of the framework's effectiveness, but it is still in the applied research stage.","key_impact_metrics":["inter-distance error within $\\pm 0.069m$","inter-angular orientation error within $\\pm19.15^{\\circ}$"],"technology_tags":["multi-robot systems","rigid formation navigation","robotics","ROS"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:28:19.477698Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7eb44232b64f","title":"ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review","content":"arXiv:2510.08867v1 Announce Type: new Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from inconsistencies, reviewer subjectivity, and scalability challenges. We introduce ReviewerToo, a modular framework for studying and deploying AI-assisted peer review to complement human judgment with systematic and consistent assessments. ReviewerToo supports systematic experiments with specialized reviewer personas and structured evaluation criteria, and can be partially or fully integrated into real conference workflows. We validate ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR 2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy for the task of categorizing a paper as accept/reject compared to 83.9% for the average human reviewer. Additionally, ReviewerToo-generated reviews are rated as higher quality than the human average by an LLM judge, though still trailing the strongest expert contributions. Our analysis highlights domains where AI reviewers excel (e.g., fact-checking, literature coverage) and where they struggle (e.g., assessing methodological novelty and theoretical contributions), underscoring the continued need for human expertise. Based on these findings, we propose guidelines for integrating AI into peer-review pipelines, showing how AI can enhance consistency, coverage, and fairness while leaving complex evaluative judgments to domain experts. Our work provides a foundation for systematic, hybrid peer-review systems that scale with the growth of scientific publishing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08867","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.613988","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Gaurav Sahu, Hugo Larochelle, Laurent Charlin, Christopher Pal","raw_content_length":1592,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["gpt","The Program Committee","ReviewerToo"],"persons":[],"locations":[],"monetary":[]},"char_count":1591,"language_detected":"en","key_concepts":{"key_phrases":["ReviewerToo","The Program Committee","The Future","Peer Review","new Abstract","Peer review","the cornerstone","scientific publishing","inconsistencies","reviewer subjectivity"],"filter_categories":{"research_academic":["Peer Review","Peer review"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ReviewerToo":4.0,"The Program Committee":2.0,"The Future":2.0,"Peer Review":2.0,"new Abstract":1.0,"Peer review":1.0,"the cornerstone":1.0,"scientific publishing":1.0,"inconsistencies":1.0,"reviewer subjectivity":1.0}},"age_hours":2.762334778611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7172,"joy":0.0046,"surprise":0.0205,"sadness":0.0192,"fear":0.1588,"anger":0.0415,"disgust":0.0382},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on an AI-assisted peer review system. While it shows promising accuracy (81.8% vs 83.9% for humans) in categorizing papers, it's still in the research phase with no real-world deployment, and the economic viability of widespread adoption is unclear. The potential climate impact is indirect, related to improving the efficiency of scientific publishing, which could accelerate climate research, but is not directly measurable at this stage.","key_impact_metrics":["Accuracy: 81.8%","Dataset size: 1,963"],"technology_tags":["AI","Machine Learning","Natural Language Processing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:28:22.628405Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c0ae22948690","title":"Measuring the Hidden Cost of Data Valuation through Collective Disclosure","content":"arXiv:2510.08869v1 Announce Type: new Abstract: Data valuation methods assign marginal utility to each data point that has contributed to the training of a machine learning model. If used directly as a payout mechanism, this creates a hidden cost of valuation, in which contributors with near-zero marginal value would receive nothing, even though their data had to be collected and assessed. To better formalize this cost, we introduce a conceptual and game-theoretic model, the Information Disclosure Game, between a Data Union (sometimes also called a data trust), a member-run agent representing contributors, and a Data Consumer (e.g., a platform). After first aggregating members' data, the DU releases information progressively by adding Laplacian noise under a differentially-private mechanism. Through simulations with strategies guided by data Shapley values and multi-armed bandit exploration, we demonstrate on a Yelp review helpfulness prediction task that data valuation inherently incurs an explicit acquisition cost and that the DU's collective disclosure policy changes how this cost is distributed across members.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08869","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.614391","language":"en","tags":["computer-science","csgt","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Patrick Mesana, Gilles Caporossi, Sebastien Gambs","raw_content_length":1132,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Shapley","the Hidden Cost of Data Valuation through Collective Disclosure arXiv:2510.08869v1","a Data Consumer"],"persons":["Laplacian"],"locations":[],"monetary":[]},"char_count":1131,"language_detected":"en","key_concepts":{"key_phrases":["the Hidden Cost","Data Valuation","Collective Disclosure","new Abstract","Data valuation methods","marginal utility","each data point","the training","a machine learning model","a payout mechanism"],"filter_categories":{"ai_ml":["the training","a machine learning model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Hidden Cost":2.0,"Data Valuation":2.0,"Collective Disclosure":2.0,"new Abstract":1.0,"Data valuation methods":1.0,"marginal utility":1.0,"each data point":1.0,"the training":1.0,"a machine learning model":1.0,"a payout mechanism":1.0}},"age_hours":2.7623511569444443,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7465,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7493,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7451,"joy":0.0083,"surprise":0.0126,"sadness":0.0086,"fear":0.0371,"anger":0.1059,"disgust":0.0823},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical model (Information Disclosure Game) and simulations to analyze the cost of data valuation in Data Unions. While the research explores a novel approach to data sharing and compensation, it remains at the conceptual and simulation stage, lacking real-world deployment or measured environmental outcomes. The 'vaporware' flag is raised due to the absence of deployed units or operational data.","key_impact_metrics":["Near-zero marginal value contributors","Explicit acquisition cost"],"technology_tags":["Data valuation","Differential privacy","Data Union"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:28:25.842030Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e33140d34e6","title":"Quality Estimation Reranking for Document","content":"arXiv:2510.08870v1 Announce Type: new Abstract: Quality estimation (QE) reranking is a form of quality-aware decoding which aims to improve machine translation (MT) by scoring and selecting the best candidate from a pool of generated translations. While known to be effective at the sentence level, its application to the increasingly prominent domain of document-level translation remains underexplored. In this work, we evaluate QE reranking performance on document-level (rather than the typical sentence-level) translation, using various learned and large language model (LLM)-based QE metrics. We find that with our best learned metric, SLIDE, BLEURT-20 scores improve by +2.00 with only two candidates, and by +5.09 with 32, across both decoder-only LLM models and encoder-decoder neural machine translation (NMT) models. Using the best LLM-based metric, GEMBA-DA, gains of +1.63 and +4.30 are achieved under the same conditions. Although gains shrink with longer inputs, reranking with 32 candidates yields improvements of +2.34 (SLIDE) and +1.40 (GEMBA-DA) on our longest documents (512-1024 source tokens). These findings demonstrate the practical value of document-level QE, with minimal runtime overhead given suitable translation models and hardware.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08870","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.614778","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Krzysztof Mrozinski, Minji Kang, Ahmed Khota, Vincent Michael Sutanto, Giovanni Gatti De Giacomo","raw_content_length":1263,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["BLEURT-20","Quality Estimation Reranking for Document arXiv:2510.08870v1","SLIDE","NMT","LLM"],"persons":["+5.09","+2.00"],"locations":[],"monetary":[]},"char_count":1262,"language_detected":"en","key_concepts":{"key_phrases":["Quality Estimation Reranking","Document","Announce Type","new Abstract Quality estimation QE reranking","a form","quality-aware decoding","which","machine translation","the best candidate","a pool"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quality Estimation Reranking":2.0,"Document":2.0,"Announce Type":1.0,"new Abstract Quality estimation QE reranking":1.0,"a form":1.0,"quality-aware decoding":1.0,"which":1.0,"machine translation":1.0,"the best candidate":1.0,"a pool":1.0}},"age_hours":2.762367666111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5765,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9153,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9059,"joy":0.0181,"surprise":0.0406,"sadness":0.007,"fear":0.0057,"anger":0.0126,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores improving machine translation, which could indirectly support sustainability by improving access to information about climate change and related topics. The article presents performance improvements in BLEURT-20 scores using QE reranking, but it's still in the research phase with no clear path to deployment or direct environmental impact. The vaporware flag is raised as it is an early-stage concept.","key_impact_metrics":["BLEURT-20 score improvement +2.00","BLEURT-20 score improvement +5.09"],"technology_tags":["Machine Translation","Quality Estimation","Large Language Models"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T09:28:28.936874Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4a6d2a2dac74","title":"GTAlign: Game","content":"arXiv:2510.08872v1 Announce Type: new Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a mutual welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and mutual welfare compared to baselines across diverse tasks. The code is available at https://github.com/ulab-uiuc/GTAlign .","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08872","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.615381","language":"en","tags":["research","csai","csgt","csma","preprints","cshc","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Siqi Zhu, David Zhang, Pedro Cisneros-Velarde, Jiaxuan You","raw_content_length":1730,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Game-Theoretic Alignment","LLM","GTAlign"],"persons":[],"locations":[],"monetary":[]},"char_count":1729,"language_detected":"en","key_concepts":{"key_phrases":["GTAlign Game","users","arXiv251008872v1 Announce Type","new Abstract","Large Language Models","LLMs","remarkable progress","reasoning","responses","tasks"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GTAlign Game":2.0,"users":2.0,"arXiv251008872v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable progress":1.0,"reasoning":1.0,"responses":1.0,"tasks":1.0}},"age_hours":2.762382694722222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.071999999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2144,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4774,"joy":0.0052,"surprise":0.0186,"sadness":0.0664,"fear":0.1318,"anger":0.1472,"disgust":0.1533},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel AI alignment framework (GTAlign) that aims to improve LLM reasoning efficiency and answer quality. It is currently in the research phase, with code available but no deployed units or customer contracts. The framework's potential climate impact is indirect, as it could improve the efficiency of information seeking related to sustainability, but there are no direct GHG reductions or carbon sequestration actions.","key_impact_metrics":["Reasoning efficiency improvement","Answer quality improvement"],"technology_tags":["Large Language Models","AI Alignment","Game Theory"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T09:28:31.924225Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0a2055cf227e","title":"Mozart: A Chiplet Ecosystem","content":"arXiv:2510.08873v1 Announce Type: new Abstract: Modern AI acceleration faces a fundamental challenge: conventional assumptions about memory requirements, batching effectiveness, and latency-throughput tradeoffs are systemwide generalizations that ignore the heterogeneous computational patterns of individual neural network operators. However, going towards network-level customization and operator-level heterogeneity incur substantial Non-Recurring Engineering (NRE) costs. While chiplet-based approaches have been proposed to amortize NRE costs, reuse opportunities remain limited without carefully identifying which chiplets are truly necessary. This paper introduces Mozart, a chiplet ecosystem and accelerator codesign framework that systematically constructs low cost bespoke application-specific integrated circuits (BASICs). BASICs leverage operator-level disaggregation to explore chiplet and memory heterogeneity, tensor fusion, and tensor parallelism, with place-and-route validation ensuring physical implementability. The framework also enables constraint-aware system-level optimization across deployment contexts ranging from datacenter inference serving to edge computing in autonomous vehicles. The evaluation confirms that with just 8 strategically selected chiplets, Mozart-generated composite BASICs achieve 43.5%, 25.4%, 67.7%, and 78.8% reductions in energy, energy-cost product, energy-delay product (EDP), and energy-delay-cost product compared to traditional homogeneous accelerators. For datacenter LLM serving, Mozart achieves 15-19% energy reduction and 35-39% energy-cost improvement. In speculative decoding, Mozart delivers throughput improvements of 24.6-58.6% while reducing energy consumption by 38.6-45.6%. For autonomous vehicle perception, Mozart reduces energy-cost by 25.54% and energy by 10.53% under real-time constraints.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08873","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.615814","language":"en","tags":["csar","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Haoran Jin, Jirong Yang, Yunpeng Liu, Barry Lyu, Kangqi Zhang, Nathaniel Bleier","raw_content_length":1865,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Non-Recurring Engineering"],"persons":["Mozart"],"locations":[],"monetary":[]},"char_count":1864,"language_detected":"en","key_concepts":{"key_phrases":["Mozart","A Chiplet Ecosystem","arXiv251008873v1 Announce Type","new Abstract","Modern AI acceleration","a fundamental challenge","conventional assumptions","memory requirements","effectiveness","latency-throughput tradeoffs"],"filter_categories":{"ai_ml":["Modern AI acceleration"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mozart":2.0,"A Chiplet Ecosystem":2.0,"arXiv251008873v1 Announce Type":1.0,"new Abstract":1.0,"Modern AI acceleration":1.0,"a fundamental challenge":1.0,"conventional assumptions":1.0,"memory requirements":1.0,"effectiveness":1.0,"latency-throughput tradeoffs":1.0}},"age_hours":2.7623972555555554,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8793,"joy":0.0052,"surprise":0.0189,"sadness":0.031,"fear":0.0204,"anger":0.0272,"disgust":0.0181},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":7,"technical_credibility":8,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"Mozart is a chiplet ecosystem that reduces energy consumption in AI acceleration. The paper presents concrete energy reduction metrics (e.g., 43.5% energy reduction compared to traditional accelerators) validated through place-and-route, suggesting a proof-of-concept stage. However, it is still in research and development, with no deployed units or customer contracts mentioned.","key_impact_metrics":["43.5% reduction in energy","15-19% energy reduction for datacenter LLM serving"],"technology_tags":["chiplet architecture","AI acceleration","low-power computing"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T09:28:34.850917Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aabe2d8d43ee","title":"Slicing Is All You Need: Towards A Universal One","content":"arXiv:2510.08874v1 Announce Type: new Abstract: Many important applications across science, data analytics, and AI workloads depend on distributed matrix multiplication. Prior work has developed a large array of algorithms suitable for different problem sizes and partitionings including 1D, 2D, 1.5D, and 2.5D algorithms. A limitation of current work is that existing algorithms are limited to a subset of partitionings. Multiple algorithm implementations are required to support the full space of possible partitionings. If no algorithm implementation is available for a particular set of partitionings, one or more operands must be redistributed, increasing communication costs. This paper presents a universal one-sided algorithm for distributed matrix multiplication that supports all combinations of partitionings and replication factors. Our algorithm uses slicing (index arithmetic) to compute the sets of overlapping tiles that must be multiplied together. This list of local matrix multiplies can then either be executed directly, or reordered and lowered to an optimized IR to maximize overlap. We implement our algorithm using a high-level C++-based PGAS programming framework that performs direct GPU-to-GPU communication using intra-node interconnects. We evaluate performance for a wide variety of partitionings and replication factors, finding that our work is competitive with PyTorch DTensor, a highly optimized distributed tensor library targeting AI models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08874","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.616232","language":"en","tags":["csdc","research","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Benjamin Brock, Renato Golin","raw_content_length":1478,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1477,"language_detected":"en","key_concepts":{"key_phrases":["All","You","A Universal One","partitionings","new Abstract","Many important applications","science","data analytics","distributed matrix multiplication","Prior work"],"filter_categories":{"ai_ml":["science"],"research_academic":["science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"All":2.0,"You":2.0,"A Universal One":2.0,"partitionings":2.0,"new Abstract":1.0,"Many important applications":1.0,"science":1.0,"data analytics":1.0,"distributed matrix multiplication":1.0,"Prior work":1.0}},"age_hours":2.762413071944444,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9379999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6124,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9193,"joy":0.0156,"surprise":0.0441,"sadness":0.0065,"fear":0.0037,"anger":0.008,"disgust":0.0029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for distributed matrix multiplication, which could potentially improve the efficiency of AI and data analytics workloads. This could lead to reduced energy consumption for these tasks, but the impact is not quantified. The algorithm is implemented and evaluated, but not yet deployed in a real-world setting.","key_impact_metrics":["Competitive with PyTorch DTensor"],"technology_tags":["distributed matrix multiplication","high-performance computing","GPU computing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:28:37.827548Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
