{"id":"science_arxiv_cs_e62d2ed8ef92","title":"Countermind: A Multi","content":"arXiv:2510.11837v1 Announce Type: new Abstract: The security of Large Language Model (LLM) applications is fundamentally challenged by \"form-first\" attacks like prompt injection and jailbreaking, where malicious instructions are embedded within user inputs. Conventional defenses, which rely on post hoc output filtering, are often brittle and fail to address the root cause: the model's inability to distinguish trusted instructions from untrusted data. This paper proposes Countermind, a multi-layered security architecture intended to shift defenses from a reactive, post hoc posture to a proactive, pre-inference, and intra-inference enforcement model. The architecture proposes a fortified perimeter designed to structurally validate and transform all inputs, and an internal governance mechanism intended to constrain the model's semantic processing pathways before an output is generated. The primary contributions of this work are conceptual designs for: (1) A Semantic Boundary Logic (SBL) with a mandatory, time-coupled Text Crypter intended to reduce the plaintext prompt injection attack surface, provided all ingestion paths are enforced. (2) A Parameter-Space Restriction (PSR) mechanism, leveraging principles from representation engineering, to dynamically control the LLM's access to internal semantic clusters, with the goal of mitigating semantic drift and dangerous emergent behaviors. (3) A Secure, Self-Regulating Core that uses an OODA loop and a learning security module to adapt its defenses based on an immutable audit log. (4) A Multimodal Input Sandbox and Context-Defense mechanisms to address threats from non-textual data and long-term semantic poisoning. This paper outlines an evaluation plan designed to quantify the proposed architecture's effectiveness in reducing the Attack Success Rate (ASR) for form-first attacks and to measure its potential latency overhead.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11837","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.233146","language":"en","tags":["preprints","csai","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":261,"author":"Dominik Schwarz","raw_content_length":1901,"priority":7,"update_frequency":1,"reading_time_minutes":1.305,"robust_parsing_used":true,"entities":{"organizations":["intra-inference enforcement","Countermind"],"persons":[],"locations":[],"monetary":[]},"char_count":1900,"language_detected":"en","key_concepts":{"key_phrases":["Countermind","arXiv251011837v1 Announce Type","new Abstract","The security","LLM","form-first attacks","prompt injection","jailbreaking","malicious instructions","user inputs"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Countermind":3.0,"arXiv251011837v1 Announce Type":1.0,"new Abstract":1.0,"The security":1.0,"LLM":1.0,"form-first attacks":1.0,"prompt injection":1.0,"jailbreaking":1.0,"malicious instructions":1.0,"user inputs":1.0}},"age_hours":2.737417168611111,"is_recent":true,"quality_score":1.0,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3335,"joy":0.0036,"surprise":0.0146,"sadness":0.0256,"fear":0.39,"anger":0.1411,"disgust":0.0916},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel security architecture for LLMs, aiming to mitigate prompt injection attacks. While the concepts are innovative and could indirectly support sustainability by preventing misuse of AI, the paper focuses on conceptual designs and an evaluation plan, lacking concrete deployments or measured outcomes. The technology is at a very early stage of development, with no clear path to economic viability or deployment readiness.","key_impact_metrics":["Attack Success Rate (ASR) reduction","Latency overhead"],"technology_tags":["Large Language Models","AI Security","Prompt Injection Defense"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:35:19.742274Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8bcd69817fa7","title":"Lingxi: Repository","content":"arXiv:2510.11838v1 Announce Type: new Abstract: Driven by the advancements of Large Language Models (LLMs), LLM-powered agents are making significant improvements in software engineering tasks, yet struggle with complex, repository-level issue resolution. Existing agent-based methods have two key limitations. First, they lack of procedural knowledge (i.e., how an issue is fixed step-by-step and rationales behind it) to learn and leverage for issue resolution. Second, they rely on massive computational power to blindly explore the solution space. % To address those limitations, we propose Lingxi, an issue resolution framework that leverages procedural knowledge extracted from historical issue-fixing data to guide agents in solving repository-level issues. \\ourTool first constructs this knowledge offline through a hierarchical abstraction mechanism, enabling agents to learn the how and why behind a fix, not just the final solution. During online application, it employs a knowledge-driven scaling method that leverages the procedural knowledge of similar issues to intelligently analyze the target issue from multiple perspectives, in sharp contrast to undirected, brute-force exploration. % Lingxi successfully resolves 74.6\\% of bugs on the SWE-bench Verified benchmark in Past@1 setting, outperforming five state-of-the-art techniques by a significant margin (5.4\\% to 14.9\\%). Our comprehensive ablation study confirmed that the success of Lingxi comes directly from its use of procedural knowledge. Without it, the performance gains from scaling alone is negligible. Our qualitative study further shows that the ``design patterns $\\&$ coding practices'' is the most critical knowledge aspect, and that the roles of different knowledge aspects switch across different stages (i.e., analysis, planning, and fixing).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11838","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.233635","language":"en","tags":["preprints","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Xu Yang, Jiayuan Zhou, Michael Pacheco, Wenhan Zhu, Pengfei He, Shaowei Wang, Kui Liu, Ruiqi Pan","raw_content_length":1831,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Lingxi"],"persons":[],"locations":[],"monetary":[]},"char_count":1830,"language_detected":"en","key_concepts":{"key_phrases":["Lingxi","Repository","arXiv251011838v1 Announce Type","new Abstract","the advancements","Large Language Models","LLMs","LLM-powered agents","significant improvements","software engineering tasks"],"filter_categories":{"ai_ml":["Large Language Models"],"engineering":["software engineering tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lingxi":2.0,"Repository":2.0,"arXiv251011838v1 Announce Type":1.0,"new Abstract":1.0,"the advancements":1.0,"Large Language Models":1.0,"LLMs":1.0,"LLM-powered agents":1.0,"significant improvements":1.0,"software engineering tasks":1.0}},"age_hours":2.737432337777778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8856,"joy":0.0043,"surprise":0.0353,"sadness":0.03,"fear":0.0144,"anger":0.014,"disgust":0.0163},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new framework, Lingxi, that improves the efficiency of LLM-powered agents in software engineering, specifically issue resolution. It claims a 74.6% success rate on the SWE-bench Verified benchmark, outperforming other techniques. While promising, it is still in the applied research stage with no deployed units or customer contracts, hence the vaporware flag.","key_impact_metrics":["74.6% bug resolution rate","5.4% to 14.9% performance improvement"],"technology_tags":["Large Language Models","Software Engineering","Issue Resolution"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:35:26.583820Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d68743c2947c","title":"WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation","content":"arXiv:2510.11839v1 Announce Type: new Abstract: Time series are ubiquitous in many applications that involve forecasting, classification and causal inference tasks, such as healthcare, finance, audio signal processing and climate sciences. Still, large, high-quality time series datasets remain scarce. Synthetic generation can address this limitation; however, current models confined either to the time or frequency domains struggle to reproduce the inherently multi-scaled structure of real-world time series. We introduce WaveletDiff, a novel framework that trains diffusion models directly on wavelet coefficients to exploit the inherent multi-resolution structure of time series data. The model combines dedicated transformers for each decomposition level with cross-level attention mechanisms that enable selective information exchange between temporal and frequency scales through adaptive gating. It also incorporates energy preservation constraints for individual levels based on Parseval's theorem to preserve spectral fidelity throughout the diffusion process. Comprehensive tests across six real-world datasets from energy, finance, and neuroscience domains demonstrate that WaveletDiff consistently outperforms state-of-the-art time-domain and frequency-domain generative methods on both short and long time series across five diverse performance metrics. For example, WaveletDiff achieves discriminative scores and Context-FID scores that are $3\\times$ smaller on average than the second-best baseline across all datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11839","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.234067","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Yu-Hsiang Wang, Olgica Milenkovic","raw_content_length":1538,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Multilevel Wavelet Diffusion For Time Series Generation arXiv:2510.11839v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1537,"language_detected":"en","key_concepts":{"key_phrases":["WaveletDiff","Multilevel Wavelet Diffusion","Time Series Generation","Announce Type","new Abstract","Time series","many applications","forecasting","classification","causal"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"WaveletDiff":2.0,"Multilevel Wavelet Diffusion":2.0,"Time Series Generation":2.0,"Announce Type":1.0,"new Abstract":1.0,"Time series":1.0,"many applications":1.0,"forecasting":1.0,"classification":1.0,"causal":1.0}},"age_hours":2.737446931388889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9095,"joy":0.0044,"surprise":0.0291,"sadness":0.0205,"fear":0.0133,"anger":0.0139,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel method for generating synthetic time series data, which could be used to improve the quality and quantity of data available for climate modeling and forecasting. The model outperforms existing methods, achieving discriminative scores and Context-FID scores that are $3\\times$ smaller on average. However, it is still in the research phase with no deployment or economic viability demonstrated.","key_impact_metrics":["discriminative scores $3\\times$ smaller","Context-FID scores $3\\times$ smaller"],"technology_tags":["wavelet diffusion","time series generation","diffusion models"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T15:35:29.884665Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dd58df6d86d4","title":"Balancing Synthetic Data and Replay for Enhancing Task","content":"arXiv:2510.11842v1 Announce Type: new Abstract: Adapting language models to new tasks through continued pretraining faces a fundamental trade-off: models must learn new capabilities while avoiding catastrophic forgetting of existing knowledge. While prior work has studied synthetic data generation techniques, the optimal replay ratios for balancing task performance and knowledge retention under computational constraints remain poorly understood. We present a comprehensive empirical study investigating the interplay between replay ratio configuration and computational budget when adapting language models to new tasks. Using the bAbI reasoning tasks as our target objective, we apply synthetic data generation and systematically evaluate different total token budgets and replay ratio configurations. We analyze their effects on both task mastery and general knowledge retention. Our experiments reveal an optimal configuration that balances task-specific performance with general knowledge retention. Based on our findings, we provide empirically-grounded guidelines for selecting replay ratios based on computational budget, enabling practitioners to achieve strong task adaptation with significantly reduced training costs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11842","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.234477","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Urs Spiegelhalter, J\\\"org K. H. Franke, Frank Hutter","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["Synthetic Data","Replay","Task","Announce Type","new Abstract","language models","new tasks","continued pretraining","a fundamental trade-off","models"],"filter_categories":{"ai_ml":["continued pretraining"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Synthetic Data":2.0,"Replay":2.0,"Task":2.0,"Announce Type":1.0,"new Abstract":1.0,"language models":1.0,"new tasks":1.0,"continued pretraining":1.0,"a fundamental trade-off":1.0,"models":1.0}},"age_hours":2.737460490277778,"is_recent":true,"quality_score":0.7,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8429,"joy":0.0091,"surprise":0.0297,"sadness":0.0217,"fear":0.0477,"anger":0.0367,"disgust":0.0122},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents an empirical study on optimizing language model training for new tasks while retaining existing knowledge. The concrete action is the systematic evaluation of different replay ratios and computational budgets using bAbI reasoning tasks. The evidence supporting claims is the analysis of task mastery and general knowledge retention, with the goal of providing guidelines for selecting replay ratios to reduce training costs. This is currently in the applied research stage, with no mention of deployment.","key_impact_metrics":["Reduced training costs","Optimal replay ratio configuration"],"technology_tags":["Language Models","Synthetic Data Generation","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:35:41.177729Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4243976c5487","title":"Deep Research Brings Deeper Harm","content":"arXiv:2510.11851v1 Announce Type: new Abstract: Deep Research (DR) agents built on Large Language Models (LLMs) can perform complex, multi-step research by decomposing tasks, retrieving online information, and synthesizing detailed reports. However, the misuse of LLMs with such powerful capabilities can lead to even greater risks. This is especially concerning in high-stakes and knowledge-intensive domains such as biosecurity, where DR can generate a professional report containing detailed forbidden knowledge. Unfortunately, we have found such risks in practice: simply submitting a harmful query, which a standalone LLM directly rejects, can elicit a detailed and dangerous report from DR agents. This highlights the elevated risks and underscores the need for a deeper safety analysis. Yet, jailbreak methods designed for LLMs fall short in exposing such unique risks, as they do not target the research ability of DR agents. To address this gap, we propose two novel jailbreak strategies: Plan Injection, which injects malicious sub-goals into the agent's plan; and Intent Hijack, which reframes harmful queries as academic research questions. We conducted extensive experiments across different LLMs and various safety benchmarks, including general and biosecurity forbidden prompts. These experiments reveal 3 key findings: (1) Alignment of the LLMs often fail in DR agents, where harmful prompts framed in academic terms can hijack agent intent; (2) Multi-step planning and execution weaken the alignment, revealing systemic vulnerabilities that prompt-level safeguards cannot address; (3) DR agents not only bypass refusals but also produce more coherent, professional, and dangerous content, compared with standalone LLMs. These results demonstrate a fundamental misalignment in DR agents and call for better alignment techniques tailored to DR agents. Code and datasets are available at https://chenxshuo.github.io/deeper-harm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11851","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.235579","language":"en","tags":["preprints","computer-science","cscr","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":272,"author":"Shuo Chen, Zonggen Li, Zhen Han, Bailan He, Tong Liu, Haokun Chen, Georg Groh, Philip Torr, Volker Tresp, Jindong Gu","raw_content_length":1943,"priority":7,"update_frequency":1,"reading_time_minutes":1.36,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","LLM","Deep Research Brings"],"persons":[],"locations":[],"monetary":[]},"char_count":1942,"language_detected":"en","key_concepts":{"key_phrases":["Deep Research","Deeper Harm","LLMs","arXiv251011851v1","Announce Type","new Abstract","Deep Research DR agents","Large Language Models","complex multi-step research","tasks"],"filter_categories":{"research_academic":["Deep Research","Deep Research DR agents","complex multi-step research"],"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deep Research":2.0,"Deeper Harm":2.0,"LLMs":2.0,"arXiv251011851v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Deep Research DR agents":1.0,"Large Language Models":1.0,"complex multi-step research":1.0,"tasks":1.0}},"age_hours":2.737491155,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.217,"joy":0.0029,"surprise":0.0074,"sadness":0.0251,"fear":0.644,"anger":0.0587,"disgust":0.045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research identifies vulnerabilities in AI agents that could lead to the generation of harmful information, particularly in biosecurity. The concrete action is the development and testing of jailbreak strategies against these agents. The evidence is based on experiments across different LLMs and safety benchmarks, demonstrating the agents' ability to bypass refusals and produce dangerous content.","key_impact_metrics":["Failure rate of alignment in DR agents","Coherence of dangerous content produced"],"technology_tags":["Large Language Models","AI Safety","Biosecurity"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T15:35:44.328300Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3484039dd576","title":"Actor","content":"arXiv:2510.11856v1 Announce Type: new Abstract: Predictive Process Monitoring (PPM) is a key task in Process Mining that aims to predict future behavior, outcomes, or performance indicators. Accurate prediction of the latter is critical for proactive decision-making. Given that processes are often resource-driven, understanding and incorporating actor behavior in forecasting is crucial. Although existing research has incorporated aspects of actor behavior, its role as a time-varying signal in PPM remains limited. This study investigates whether incorporating actor behavior information, modeled as time series, can improve the predictive performance of throughput time (TT) forecasting models. Using real-life event logs, we construct multivariate time series that include TT alongside actor-centric features, i.e., actor involvement, the frequency of continuation, interruption, and handover behaviors, and the duration of these behaviors. We train and compare several models to study the benefits of adding actor behavior. The results show that actor-enriched models consistently outperform baseline models, which only include TT features, in terms of RMSE, MAE, and R2. These findings demonstrate that modeling actor behavior over time and incorporating this information into forecasting models enhances performance indicator predictions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11856","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.236396","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Aurelie Leribaux, Rafael Oyamada, Johannes De Smedt, Zahra Dasht Bozorgi, Artem Polyvyanyy, Jochen De Weerdt","raw_content_length":1348,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Process Mining","PPM"],"persons":["arXiv:2510.11856v1 Announce"],"locations":[],"monetary":[]},"char_count":1347,"language_detected":"en","key_concepts":{"key_phrases":["Actor","arXiv251011856v1 Announce Type","new Abstract","Predictive Process Monitoring","PPM","a key task","Process Mining","future behavior","outcomes","performance indicators"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Actor":2.0,"arXiv251011856v1 Announce Type":1.0,"new Abstract":1.0,"Predictive Process Monitoring":1.0,"PPM":1.0,"a key task":1.0,"Process Mining":1.0,"future behavior":1.0,"outcomes":1.0,"performance indicators":1.0}},"age_hours":2.7375226891666666,"is_recent":true,"quality_score":0.7,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9214,"joy":0.0075,"surprise":0.0264,"sadness":0.005,"fear":0.0274,"anger":0.0076,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores improving predictive process monitoring by incorporating actor behavior, leading to better throughput time forecasting. The concrete action is the development and comparison of different models using real-life event logs. While the results show improved performance (RMSE, MAE, R2), it is still in the applied research phase with no real-world deployment.","key_impact_metrics":["RMSE improvement","MAE improvement","R2 improvement"],"technology_tags":["Predictive Process Monitoring","Time Series Analysis","Machine Learning"],"sdg_alignment":[8,9],"analyzed_at":"2025-10-29T15:35:48.411447Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8cee0cb81c1b","title":"Rationally Analyzing Shelby: Proving Incentive Compatibility in a Decentralized Storage Network","content":"arXiv:2510.11866v1 Announce Type: new Abstract: Decentralized storage is one of the most natural applications built on blockchains and a central component of the Web3 ecosystem. Yet despite a decade of active development -- from IPFS and Filecoin to more recent entrants -- most of these storage protocols have received limited formal analysis of their incentive properties. Claims of incentive compatibility are sometimes made, but rarely proven. This gap matters: without well-designed incentives, a system may distribute storage but fail to truly decentralize it. We analyze Shelby -- a storage network protocol recently proposed by Aptos Labs and Jump Crypto -- and provide the first formal proof of its incentive properties. Our game-theoretic model shows that while off-chain audits alone collapse to universal shirking, Shelby's combination of peer audits with occasional on-chain verification yields incentive compatibility under natural parameter settings. We also examine coalition behavior and outline a simple modification that strengthens the protocol's collusion-resilience.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11866","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.236819","language":"en","tags":["preprints","csgt","computer-science","research","csdc","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Michael Crystal, Guy Goren, Scott Duke Kominers","raw_content_length":1091,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["IPFS"],"persons":["Jump Crypto","Shelby","Filecoin","Aptos Labs"],"locations":[],"monetary":[]},"char_count":1088,"language_detected":"en","key_concepts":{"key_phrases":["Rationally Analyzing Shelby","Incentive Compatibility","a Decentralized Storage Network","arXiv251011866v1","Announce Type","new Abstract","Decentralized storage","the most natural applications","blockchains","a central component"],"filter_categories":{"ai_ml":["blockchains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Rationally Analyzing Shelby":2.0,"Incentive Compatibility":2.0,"a Decentralized Storage Network":2.0,"arXiv251011866v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Decentralized storage":1.0,"the most natural applications":1.0,"blockchains":1.0,"a central component":1.0}},"age_hours":2.7375378619444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3885,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8777,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8798,"joy":0.0105,"surprise":0.0675,"sadness":0.0058,"fear":0.0056,"anger":0.0211,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a formal proof of incentive compatibility for a decentralized storage network protocol. While this could indirectly support sustainability by enabling more efficient data storage and potentially reducing energy consumption compared to centralized solutions, there are no concrete actions or measurable outcomes presented in the abstract. The research is at an early stage (basic research) with no deployment data.","key_impact_metrics":[],"technology_tags":["decentralized storage","blockchain","incentive mechanism"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:35:53.369785Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_409fba6e7385","title":"Improving Knowledge Graph Embeddings through Contrastive Learning with Negative Statements","content":"arXiv:2510.11868v1 Announce Type: new Abstract: Knowledge graphs represent information as structured triples and serve as the backbone for a wide range of applications, including question answering, link prediction, and recommendation systems. A prominent line of research for exploring knowledge graphs involves graph embedding methods, where entities and relations are represented in low-dimensional vector spaces that capture underlying semantics and structure. However, most existing methods rely on assumptions such as the Closed World Assumption or Local Closed World Assumption, treating missing triples as false. This contrasts with the Open World Assumption underlying many real-world knowledge graphs. Furthermore, while explicitly stated negative statements can help distinguish between false and unknown triples, they are rarely included in knowledge graphs and are often overlooked during embedding training. In this work, we introduce a novel approach that integrates explicitly declared negative statements into the knowledge embedding learning process. Our approach employs a dual-model architecture, where two embedding models are trained in parallel, one on positive statements and the other on negative statements. During training, each model generates negative samples by corrupting positive samples and selecting the most likely candidates as scored by the other model. The proposed approach is evaluated on both general-purpose and domain-specific knowledge graphs, with a focus on link prediction and triple classification tasks. The extensive experiments demonstrate that our approach improves predictive performance over state-of-the-art embedding models, demonstrating the value of integrating meaningful negative knowledge into embedding learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11868","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.237246","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Rita T. Sousa, Heiko Paulheim","raw_content_length":1777,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["the Closed World Assumption or Local Closed World Assumption","Contrastive Learning with Negative Statements arXiv:2510.11868v1 Announce"],"persons":[],"locations":[],"monetary":[]},"char_count":1774,"language_detected":"en","key_concepts":{"key_phrases":["Knowledge Graph Embeddings","Contrastive Learning","Negative Statements","arXiv251011868v1 Announce Type","new Abstract","Knowledge graphs","information","structured triples","the backbone","a wide range"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Knowledge Graph Embeddings":2.0,"Contrastive Learning":2.0,"Negative Statements":2.0,"arXiv251011868v1 Announce Type":1.0,"new Abstract":1.0,"Knowledge graphs":1.0,"information":1.0,"structured triples":1.0,"the backbone":1.0,"a wide range":1.0}},"age_hours":2.7375526569444446,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8829,"joy":0.0246,"surprise":0.0333,"sadness":0.0052,"fear":0.0088,"anger":0.0281,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel approach to improve knowledge graph embeddings using contrastive learning with negative statements. While the research shows improved predictive performance in link prediction and triple classification tasks, it's still in the applied research phase with no clear path to economic viability or deployment at scale. The impact on climate is indirect, potentially improving efficiency in applications that could contribute to sustainability.","key_impact_metrics":["predictive performance improvement over state-of-the-art embedding models","link prediction accuracy"],"technology_tags":["knowledge graph embeddings","contrastive learning","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:35:59.670674Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e08676d62102","title":"Robust Adversarial Reinforcement Learning in Stochastic Games via Sequence Modeling","content":"arXiv:2510.11877v1 Announce Type: new Abstract: The Transformer, a highly expressive architecture for sequence modeling, has recently been adapted to solve sequential decision-making, most notably through the Decision Transformer (DT), which learns policies by conditioning on desired returns. Yet, the adversarial robustness of reinforcement learning methods based on sequence modeling remains largely unexplored. Here we introduce the Conservative Adversarially Robust Decision Transformer (CART), to our knowledge the first framework designed to enhance the robustness of DT in adversarial stochastic games. We formulate the interaction between the protagonist and the adversary at each stage as a stage game, where the payoff is defined as the expected maximum value over subsequent states, thereby explicitly incorporating stochastic state transitions. By conditioning Transformer policies on the NashQ value derived from these stage games, CART generates policy that are simultaneously less exploitable (adversarially robust) and conservative to transition uncertainty. Empirically, CART achieves more accurate minimax value estimation and consistently attains superior worst-case returns across a range of adversarial stochastic games.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11877","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.238798","language":"en","tags":["preprints","csgt","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Xiaohang Tang, Zhuowen Cheng, Satyabrat Kumar","raw_content_length":1243,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Sequence Modeling arXiv:2510.11877v1","Robust Adversarial Reinforcement Learning","the Conservative Adversarially Robust Decision Transformer","Transformer","the Decision Transformer"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1242,"language_detected":"en","key_concepts":{"key_phrases":["Robust Adversarial Reinforcement Learning","Stochastic Games","Sequence Modeling","sequence modeling","arXiv251011877v1 Announce Type","new Abstract","The Transformer","a highly expressive architecture","sequential decision-making","the Decision Transformer"],"filter_categories":{"ai_ml":["Robust Adversarial Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Adversarial Reinforcement Learning":2.0,"Stochastic Games":2.0,"Sequence Modeling":2.0,"sequence modeling":2.0,"arXiv251011877v1 Announce Type":1.0,"new Abstract":1.0,"The Transformer":1.0,"a highly expressive architecture":1.0,"sequential decision-making":1.0,"the Decision Transformer":1.0}},"age_hours":2.7375814963888887,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9009,"joy":0.0172,"surprise":0.0258,"sadness":0.0039,"fear":0.0122,"anger":0.0244,"disgust":0.0156},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the robustness of reinforcement learning algorithms in adversarial environments, potentially leading to more reliable and efficient control systems. While the research shows improved minimax value estimation and worst-case returns, it is still in the early stages of development with no deployed systems or economic viability demonstrated. The potential climate impact is theoretical at this stage, as the application to specific climate-relevant domains is not yet clear.","key_impact_metrics":["more accurate minimax value estimation","superior worst-case returns"],"technology_tags":["reinforcement learning","adversarial learning","transformer networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:03.369998Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9825816e840","title":"A Longitudinal Study on Different Annotator Feedback Loops in Complex RAG Tasks","content":"arXiv:2510.11897v1 Announce Type: new Abstract: Grounding conversations in existing passages, known as Retrieval-Augmented Generation (RAG), is an important aspect of Chat-Based Assistants powered by Large Language Models (LLMs) to ensure they are faithful and don't provide misinformation. Several benchmarks have been created to measure the performance of LLMs on this task. We present a longitudinal study comparing the feedback loop of an internal and external human annotator group for the complex annotation task of creating multi-turn RAG conversations for evaluating LLMs. We analyze the conversations produced by both groups and provide results of a survey comparing their experiences. Our study highlights the advantages of each annotator population and the impact of the different feedback loops; a closer loop creates higher quality conversations with a decrease in quantity and diversity. Further, we present guidance for how to best utilize two different population groups when performing annotation tasks, particularly when the task is complex.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11897","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.240504","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Sara Rosenthal, Maeda Hanafi, Yannis Katsis, Lucian Popa, Marina Danilevsky","raw_content_length":1060,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["Different Annotator Feedback Loops","Chat-Based","Retrieval-Augmented Generation (RAG"],"persons":["Large Language Models","RAG"],"locations":[],"monetary":[]},"char_count":1059,"language_detected":"en","key_concepts":{"key_phrases":["A Longitudinal Study","Different Annotator Feedback Loops","Complex RAG Tasks","LLMs","arXiv251011897v1 Announce Type","new Abstract","conversations","existing passages","Retrieval-Augmented Generation","RAG"],"filter_categories":{"research_academic":["A Longitudinal Study"],"ai_ml":["LLMs"],"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Longitudinal Study":2.0,"Different Annotator Feedback Loops":2.0,"Complex RAG Tasks":2.0,"LLMs":2.0,"arXiv251011897v1 Announce Type":1.0,"new Abstract":1.0,"conversations":1.0,"existing passages":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0}},"age_hours":2.7376418319444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2525,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8505,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9182,"joy":0.0126,"surprise":0.0432,"sadness":0.0042,"fear":0.0049,"anger":0.0107,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a study on improving the quality of RAG conversations for LLMs. While better LLMs can indirectly support sustainability efforts by improving information access and decision-making, the study itself doesn't have direct or measurable climate impact. It is still in the research phase with no deployed technology.","key_impact_metrics":["Decrease in quantity of conversation","Increase in quality of conversation"],"technology_tags":["Large Language Models","Retrieval-Augmented Generation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:36:06.523303Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3c831c403cc","title":"Lightweight CNN","content":"arXiv:2510.11898v1 Announce Type: new Abstract: Wi-Fi networks are ubiquitous in both home and enterprise environments, serving as a primary medium for Internet access and forming the backbone of modern IoT ecosystems. However, their inherent vulnerabilities, combined with widespread adoption, create opportunities for malicious actors to gain unauthorized access or compromise sensitive data stored on connected devices. To address these challenges, we propose a deep learning based network intrusion detection system (NIDS) for Wi-Fi environments. Building on our previous work, we convert network traffic into two-dimensional data representations and use them to train DL models based on convolutional neural network (CNN) architectures. We implement five distinct techniques for generating the two-dimensional representations, and to ensure low detection latency, we adopt lightweight CNN architectures in our NIDS. The models are trained using the AWID3 dataset, a publicly available benchmark for Wi-Fi NIDS research, and are evaluated for both binary and multi-class classification tasks. Experimental results demonstrate that the proposed approach achieves competitive detection performance with low inference time, making it suitable for real-world Wi-Fi deployment scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11898","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.240939","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Rayed Suhail Ahmad, Rehan Ahmad, Quamar Niyaz","raw_content_length":1287,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["CNN","IoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1286,"language_detected":"en","key_concepts":{"key_phrases":["Lightweight CNN","arXiv251011898v1 Announce Type","new Abstract","Wi-Fi networks","both home and enterprise environments","a primary medium","Internet access","the backbone","modern IoT ecosystems","their inherent vulnerabilities"],"filter_categories":{"engineering":["modern IoT ecosystems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lightweight CNN":2.0,"arXiv251011898v1 Announce Type":1.0,"new Abstract":1.0,"Wi-Fi networks":1.0,"both home and enterprise environments":1.0,"a primary medium":1.0,"Internet access":1.0,"the backbone":1.0,"modern IoT ecosystems":1.0,"their inherent vulnerabilities":1.0}},"age_hours":2.7376563127777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8632,"joy":0.0096,"surprise":0.0338,"sadness":0.0085,"fear":0.0519,"anger":0.025,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a lightweight CNN architecture for network intrusion detection, which could indirectly reduce energy consumption by optimizing network security and reducing the need for extensive computational resources. However, the impact is theoretical and not directly quantified. The research is in the applied research phase, using the AWID3 dataset for training and evaluation.","key_impact_metrics":["low inference time","competitive detection performance"],"technology_tags":["CNN","Network Intrusion Detection","Deep Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:11.177727Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e933288748d0","title":"ADARL: Adaptive Low","content":"arXiv:2510.11899v1 Announce Type: new Abstract: Robust reinforcement learning (Robust RL) seeks to handle epistemic uncertainty in environment dynamics, but existing approaches often rely on nested min--max optimization, which is computationally expensive and yields overly conservative policies. We propose \\textbf{Adaptive Rank Representation (AdaRL)}, a bi-level optimization framework that improves robustness by aligning policy complexity with the intrinsic dimension of the task. At the lower level, AdaRL performs policy optimization under fixed-rank constraints with dynamics sampled from a Wasserstein ball around a centroid model. At the upper level, it adaptively adjusts the rank to balance the bias--variance trade-off, projecting policy parameters onto a low-rank manifold. This design avoids solving adversarial worst-case dynamics while ensuring robustness without over-parameterization. Empirical results on MuJoCo continuous control benchmarks demonstrate that AdaRL not only consistently outperforms fixed-rank baselines (e.g., SAC) and state-of-the-art robust RL methods (e.g., RNAC, Parseval), but also converges toward the intrinsic rank of the underlying tasks. These results highlight that adaptive low-rank policy representations provide an efficient and principled alternative for robust RL under model uncertainty.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11899","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.241344","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Chenliang Li, Junyu Leng, Jiaxiang Li, Youbang Sun, Shixiang Chen, Shahin Shahrampour, Alfredo Garcia","raw_content_length":1342,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Rank Representation"],"persons":["Wasserstein","max"],"locations":[],"monetary":[]},"char_count":1341,"language_detected":"en","key_concepts":{"key_phrases":["ADARL","arXiv251011899v1 Announce Type","new Abstract","Robust reinforcement learning","Robust RL","epistemic uncertainty","environment dynamics","existing approaches","nested min--max optimization","which"],"filter_categories":{"ai_ml":["Robust reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ADARL":2.0,"arXiv251011899v1 Announce Type":1.0,"new Abstract":1.0,"Robust reinforcement learning":1.0,"Robust RL":1.0,"epistemic uncertainty":1.0,"environment dynamics":1.0,"existing approaches":1.0,"nested min--max optimization":1.0,"which":1.0}},"age_hours":2.7376706330555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.520999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9042,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7782,"joy":0.0085,"surprise":0.0215,"sadness":0.0106,"fear":0.075,"anger":0.061,"disgust":0.0453},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel reinforcement learning algorithm (AdaRL) that improves robustness and efficiency in continuous control tasks. Empirical results on MuJoCo benchmarks show improved performance compared to existing methods. However, it is still in the research phase with no real-world deployments or quantified climate impact, thus the low scores.","key_impact_metrics":["Outperforms fixed-rank baselines (e.g., SAC)","Converges toward the intrinsic rank of the underlying tasks"],"technology_tags":["Reinforcement Learning","Robust Control"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:14.557340Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a6900775bae7","title":"Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks","content":"arXiv:2510.11903v1 Announce Type: new Abstract: User event modeling plays a central role in many machine learning applications, with use cases spanning e-commerce, social media, finance, cybersecurity, and other domains. User events can be broadly categorized into personal events, which involve individual actions, and relational events, which involve interactions between two users. These two types of events are typically modeled separately, using sequence-based methods for personal events and graph-based methods for relational events. Despite the need to capture both event types in real-world systems, prior work has rarely considered them together. This is often due to the convenient simplification that user behavior can be adequately represented by a single formalization, either as a sequence or a graph. To address this gap, there is a need for public datasets and prediction tasks that explicitly incorporate both personal and relational events. In this work, we introduce a collection of such datasets, propose a unified formalization, and empirically show that models benefit from incorporating both event types. Our results also indicate that current methods leave a notable room for improvements. We release these resources to support further research in unified user event modeling and encourage progress in this direction.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11903","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.241775","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Rizal Fathony, Igor Melnyk, Owen Reinert, Nam H. Nguyen, Daniele Rosa, C. Bayan Bruss","raw_content_length":1343,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Relational Modeling for User Events: Datasets and Prediction Tasks"],"persons":[],"locations":["Sequential"],"monetary":[]},"char_count":1342,"language_detected":"en","key_concepts":{"key_phrases":["Sequential and Relational Modeling","User Events","Datasets","Prediction Tasks","personal events","which","arXiv251011903v1 Announce Type","new Abstract","User event modeling","a central role"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sequential and Relational Modeling":2.0,"User Events":2.0,"Datasets":2.0,"Prediction Tasks":2.0,"personal events":2.0,"which":2.0,"arXiv251011903v1 Announce Type":1.0,"new Abstract":1.0,"User event modeling":1.0,"a central role":1.0}},"age_hours":2.737686233611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.927,"joy":0.0076,"surprise":0.0397,"sadness":0.0041,"fear":0.007,"anger":0.0108,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces datasets and a unified formalization for user event modeling, aiming to improve machine learning applications across various domains. While the research is valuable, it's in the early stages with no deployed technology or measured outcomes related to specific sustainability impacts. The potential for sustainability impact is indirect and depends on how the improved user event modeling is applied in practice.","key_impact_metrics":[],"technology_tags":["machine learning","user event modeling","data analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:36:17.937608Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46360fadf57a","title":"LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance","content":"arXiv:2510.11905v1 Announce Type: new Abstract: For Large Language Models (LLMs) to be reliable, they must learn robust knowledge that can be generally applied in diverse settings -- often unlike those seen during training. Yet, extensive research has shown that LLM performance can be brittle, with models exhibiting excessive sensitivity to trivial input variations. In this work, we explore whether this brittleness is a direct result of unstable internal knowledge representations. To explore this question, we build on previous work showing that LLM representations encode statement truthfulness -- i.e., true, factual statements can be easily separated from false, inaccurate ones. Specifically, we test the robustness of learned knowledge by evaluating representation separability on samples that have undergone superficial transformations to drive them out-of-distribution (OOD), such as typos or reformulations. By applying semantically-preserving perturbations, we study how separability degrades as statements become more OOD, across four LLM families, five evaluation datasets, and three knowledge probing methods. Our results reveal that internal representations of statement truthfulness collapse as the samples' presentations become less similar to those seen during pre-training. While LLMs can often distinguish between true and false statements when they closely resemble the pre-training data, this ability is highly dependent on the statement's exact surface form. These findings offer a possible explanation for brittle benchmark performance: LLMs may learn shallow, non-robust knowledge representations that allow for only limited generalizability. Our work presents a fundamental challenge for the utility of truthfulness probes, and more broadly, calls for further research on improving the robustness of learned knowledge representations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11905","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.242225","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Patrick Haller, Mark Ibrahim, Polina Kirichenko, Levent Sagun, Samuel J. Bell","raw_content_length":1864,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1863,"language_detected":"en","key_concepts":{"key_phrases":["LLM Knowledge","Brittle","Truthfulness Representations","Superficial Resemblance","arXiv251011905v1 Announce Type","new Abstract","Large Language Models","LLMs","robust knowledge","diverse settings"],"filter_categories":{"ai_ml":["LLM Knowledge","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM Knowledge":2.0,"Brittle":2.0,"Truthfulness Representations":2.0,"Superficial Resemblance":2.0,"arXiv251011905v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"robust knowledge":1.0,"diverse settings":1.0}},"age_hours":2.7377015202777777,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7477,"joy":0.0049,"surprise":0.0107,"sadness":0.0139,"fear":0.0726,"anger":0.0513,"disgust":0.0989},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores the brittleness of LLM knowledge representations, finding that truthfulness representations collapse with superficial transformations. While it identifies a fundamental challenge for AI's role in sustainability (e.g., verifying claims), it is currently in the basic research stage with no concrete deployment or measurable impact on climate change or other sustainability dimensions. The evidence strength is high due to peer-reviewed research and specific metrics on representation separability.","key_impact_metrics":["Representation separability degradation as statements become more OOD","Performance degradation with semantically-preserving perturbations"],"technology_tags":["Large Language Models","Knowledge Representation","Truthfulness Probes"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:36:21.608337Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f0c9463bcd81","title":"Robust ML","content":"arXiv:2510.11915v1 Announce Type: new Abstract: Phishing remains a critical cybersecurity threat, especially with the advent of large language models (LLMs) capable of generating highly convincing malicious content. Unlike earlier phishing attempts which are identifiable by grammatical errors, misspellings, incorrect phrasing, and inconsistent formatting, LLM generated emails are grammatically sound, contextually relevant, and linguistically natural. These advancements make phishing emails increasingly difficult to distinguish from legitimate ones, challenging traditional detection mechanisms. Conventional phishing detection systems often fail when faced with emails crafted by LLMs or manipulated using adversarial perturbation techniques. To address this challenge, we propose a robust phishing email detection system featuring an enhanced text preprocessing pipeline. This pipeline includes spelling correction and word splitting to counteract adversarial modifications and improve detection accuracy. Our approach integrates widely adopted natural language processing (NLP) feature extraction techniques and machine learning algorithms. We evaluate our models on publicly available datasets comprising both phishing and legitimate emails, achieving a detection accuracy of 94.26% and F1-score of 84.39% in model deployment setting. To assess robustness, we further evaluate our models using adversarial phishing samples generated by four attack methods in Python TextAttack framework. Additionally, we evaluate models' performance against phishing emails generated by LLMs including ChatGPT and Llama. Results highlight the resilience of models against evolving AI-powered phishing threats.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11915","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.243818","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Deeksha Hareesha Kulal, Chidozie Princewill Arannonu, Afsah Anwar, Nidhi Rastogi, Quamar Niyaz","raw_content_length":1703,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1702,"language_detected":"en","key_concepts":{"key_phrases":["Robust ML","new Abstract","Phishing","a critical cybersecurity threat","the advent","large language models","LLMs","highly convincing malicious content","earlier phishing attempts","which"],"filter_categories":{"ai_ml":["Robust ML","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust ML":2.0,"new Abstract":1.0,"Phishing":1.0,"a critical cybersecurity threat":1.0,"the advent":1.0,"large language models":1.0,"LLMs":1.0,"highly convincing malicious content":1.0,"earlier phishing attempts":1.0,"which":1.0}},"age_hours":2.7377431891666664,"is_recent":true,"quality_score":1.0,"sentiment_score":6.692,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3384,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.913,"joy":0.0161,"surprise":0.0173,"sadness":0.0033,"fear":0.0269,"anger":0.0127,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel system for detecting AI-generated phishing emails, achieving a detection accuracy of 94.26% and F1-score of 84.39% in a model deployment setting. While this addresses a growing cybersecurity threat, its direct climate impact is minimal as it is still in the applied research phase with no concrete deployment at scale. The technical credibility is supported by evaluation on publicly available datasets and adversarial attacks, but economic viability and deployment readiness are low.","key_impact_metrics":["detection accuracy: 94.26%","F1-score: 84.39%"],"technology_tags":["machine learning","natural language processing","cybersecurity","phishing detection"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:36:25.298622Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38d901e48650","title":"Variational Mixture of Graph Neural Experts for Alzheimer's Disease Biomarker Recognition in EEG Brain Networks","content":"arXiv:2510.11917v1 Announce Type: new Abstract: Dementia disorders such as Alzheimer's disease (AD) and frontotemporal dementia (FTD) exhibit overlapping electrophysiological signatures in EEG that challenge accurate diagnosis. Existing EEG-based methods are limited by full-band frequency analysis that hinders precise differentiation of dementia subtypes and severity stages. We propose a variational mixture of graph neural experts (VMoGE) that integrates frequency-specific biomarker identification with structured variational inference for enhanced dementia diagnosis and staging. VMoGE employs a multi-granularity transformer to extract multi-scale temporal patterns across four frequency bands, followed by a variational graph convolutional encoder using Gaussian Markov Random Field priors. Through structured variational inference and adaptive gating, VMoGE links neural specialization to physiologically meaningful EEG frequency bands. Evaluated on two diverse datasets for both subtype classification and severity staging, VMoGE achieves superior performance with AUC improvements of +4% to +10% over state-of-the-art methods. Moreover, VMoGE provides interpretable insights through expert weights that correlate with clinical indicators and spatial patterns aligned with neuropathological signatures, facilitating EEG biomarker discovery for comprehensive dementia diagnosis and monitoring.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11917","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.244256","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Jun-En Ding, Anna Zilverstand, Shihao Yang, Albert Chih-Chieh Yang, Feng Liu","raw_content_length":1403,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["FTD","EEG","Disease Biomarker Recognition","EEG Brain Networks arXiv:2510.11917v1 Announce Type: new Abstract"],"persons":["Gaussian Markov Random Field"],"locations":[],"monetary":[]},"char_count":1402,"language_detected":"en","key_concepts":{"key_phrases":["Variational Mixture","Graph Neural Experts","Alzheimers Disease Biomarker Recognition","EEG Brain Networks","Announce Type","new Abstract","Dementia disorders","Alzheimers disease","frontotemporal dementia","FTD"],"filter_categories":{"ai_ml":["EEG Brain Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Variational Mixture":2.0,"Graph Neural Experts":2.0,"Alzheimers Disease Biomarker Recognition":2.0,"EEG Brain Networks":2.0,"Announce Type":1.0,"new Abstract":1.0,"Dementia disorders":1.0,"Alzheimers disease":1.0,"frontotemporal dementia":1.0,"FTD":1.0}},"age_hours":2.7377581294444444,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8113,"joy":0.0047,"surprise":0.0532,"sadness":0.0366,"fear":0.0605,"anger":0.0183,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel method (VMoGE) for Alzheimer's diagnosis using EEG data and graph neural networks. While it shows improved AUC scores (+4% to +10%) compared to existing methods, it's currently in the research phase with no deployed units or clear path to economic viability. The sustainability impact is indirect, potentially improving healthcare resource allocation, but not directly addressing climate change.","key_impact_metrics":["AUC improvements of +4% to +10%"],"technology_tags":["Graph Neural Networks","EEG Analysis","Alzheimer's Diagnosis"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:36:33.830430Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a123ce59ef2","title":"LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens","content":"arXiv:2510.11919v1 Announce Type: new Abstract: Large reasoning models (LRMs) have led to new possibilities in terms of problem-solving, through the devising of a natural language thought process prior to answering a query. While their capabilities are well known across mathematics and coding tasks, their impact on the task of machine translation (MT) remains underexplored. In this work, we explore the benefits of the generation of intermediate tokens when performing MT across multiple language pairs of different levels of resourcedness and multiple setups. We find that \"thinking tokens\" do not help LRMs better perform MT. This result generalizes to models fine-tuned to reason before translating using distilled chain of thought (CoT) inspired by human translators' practices. Specifically, fine-tuning a model with synthetic CoT explanations detailing how to translate step-by-step does not outperform standard input-output fine-tuning. However, constructing the intermediate tokens by combining the outputs of modular translation-specific prompting strategies results in improvements. Our findings underscore that the contribution of intermediate tokens during fine-tuning highly depends on the presence of translation attempts within them. More broadly, our results suggest that using a teacher to refine target translations or to expand parallel corpora is more impactful than distilling their CoT explanations into \"thinking\" MT models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11919","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.244717","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Armel Zebaze, Rachel Bawden, Beno\\^it Sagot","raw_content_length":1451,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1450,"language_detected":"en","key_concepts":{"key_phrases":["LLM Reasoning","Machine Translation","Synthetic Data Generation","Thinking Tokens","arXiv251011919v1 Announce Type","new Abstract","Large reasoning models","LRMs","new possibilities","terms"],"filter_categories":{"ai_ml":["LLM Reasoning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM Reasoning":2.0,"Machine Translation":2.0,"Synthetic Data Generation":2.0,"Thinking Tokens":2.0,"arXiv251011919v1 Announce Type":1.0,"new Abstract":1.0,"Large reasoning models":1.0,"LRMs":1.0,"new possibilities":1.0,"terms":1.0}},"age_hours":2.737774299166667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8643,"joy":0.0578,"surprise":0.0461,"sadness":0.0048,"fear":0.0068,"anger":0.0135,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article explores the use of large reasoning models for machine translation, finding that 'thinking tokens' do not significantly improve performance unless they contain translation attempts. The research is in the applied research stage, focusing on synthetic data generation and fine-tuning, but lacks real-world deployment or quantified impact metrics related to sustainability.","key_impact_metrics":[],"technology_tags":["machine translation","large language models","artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:37.429328Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bf99617143aa","title":"Indoor Localization using Compact, Telemetry-Agnostic, Transfer","content":"arXiv:2510.11926v1 Announce Type: new Abstract: Indoor Wi-Fi positioning remains a challenging problem due to the high sensitivity of radio signals to environmental dynamics, channel propagation characteristics, and hardware heterogeneity. Conventional fingerprinting and model-based approaches typically require labor-intensive calibration and suffer rapid performance degradation when devices, channel or deployment conditions change. In this paper, we introduce Locaris, a decoder-only large language model (LLM) for indoor localization. Locaris treats each access point (AP) measurement as a token, enabling the ingestion of raw Wi-Fi telemetry without pre-processing. By fine-tuning its LLM on different Wi-Fi datasets, Locaris learns a lightweight and generalizable mapping from raw signals directly to device location. Our experimental study comparing Locaris with state-of-the-art methods consistently shows that Locaris matches or surpasses existing techniques for various types of telemetry. Our results demonstrate that compact LLMs can serve as calibration-free regression models for indoor localization, offering scalable and robust cross-environment performance in heterogeneous Wi-Fi deployments. Few-shot adaptation experiments, using only a handful of calibration points per device, further show that Locaris maintains high accuracy when applied to previously unseen devices and deployment scenarios. This yields sub-meter accuracy with just a few hundred samples, robust performance under missing APs and supports any and all available telemetry. Our findings highlight the practical viability of Locaris for indoor positioning in the real-world scenarios, particularly in large-scale deployments where extensive calibration is infeasible.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11926","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.245159","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Nayan Sanjay Bhatia, Pranay Kocheta, Russell Elliott, Harikrishna S. Kuttivelil, Katia Obraczka","raw_content_length":1758,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Locaris"],"locations":[],"monetary":[]},"char_count":1757,"language_detected":"en","key_concepts":{"key_phrases":["Indoor Localization","Compact Telemetry-Agnostic Transfer","arXiv251011926v1","Announce Type","new Abstract","Indoor Wi-Fi positioning","a challenging problem","the high sensitivity","radio signals","environmental dynamics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Indoor Localization":2.0,"Compact Telemetry-Agnostic Transfer":2.0,"arXiv251011926v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Indoor Wi-Fi positioning":1.0,"a challenging problem":1.0,"the high sensitivity":1.0,"radio signals":1.0,"environmental dynamics":1.0}},"age_hours":2.7377897022222224,"is_recent":true,"quality_score":1.0,"sentiment_score":1.0775000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7845,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9051,"joy":0.0028,"surprise":0.0305,"sadness":0.0114,"fear":0.0194,"anger":0.0178,"disgust":0.013},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to indoor localization using LLMs, showing improved accuracy compared to existing methods. The concrete action is the development and testing of the Locaris model, with sub-meter accuracy achieved using a few hundred samples. However, it is still in the research phase with no mention of actual deployment or commercialization, hence the low deployment readiness score.","key_impact_metrics":["sub-meter accuracy","few hundred samples"],"technology_tags":["indoor localization","large language models","Wi-Fi telemetry"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:44.430094Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2f3e6113ab5e","title":"Visual Stenography: Feature Recreation and Preservation in Sketches of Noisy Line Charts","content":"arXiv:2510.11927v1 Announce Type: new Abstract: Line charts surface many features in time series data, from trends to periodicity to peaks and valleys. However, not every potentially important feature in the data may correspond to a visual feature which readers can detect or prioritize. In this study, we conducted a visual stenography task, where participants re-drew line charts to solicit information about the visual features they believed to be important. We systematically varied noise levels (SNR ~5-30 dB) across line charts to observe how visual clutter influences which features people prioritize in their sketches. We identified three key strategies that correlated with the noise present in the stimuli: the Replicator attempted to retain all major features of the line chart including noise; the Trend Keeper prioritized trends disregarding periodicity and peaks; and the De-noiser filtered out noise while preserving other features. Further, we found that participants tended to faithfully retain trends and peaks and valleys when these features were present, while periodicity and noise were represented in more qualitative or gestural ways: semantically rather than accurately. These results suggest a need to consider more flexible and human-centric ways of presenting, summarizing, pre-processing, or clustering time series data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11927","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.245602","language":"en","tags":["preprints","cshc","computer-science","research","csgr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Rifat Ara Proma, Michael Correll, Ghulam Jilani Quadri, Paul Rosen","raw_content_length":1349,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["SNR","Trend Keeper"],"persons":[],"locations":[],"monetary":[]},"char_count":1348,"language_detected":"en","key_concepts":{"key_phrases":["Visual Stenography","Feature Recreation","Preservation","Sketches","Noisy Line Charts","arXiv251011927v1 Announce Type","new Abstract","Line charts","many features","time series data"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Visual Stenography":2.0,"Feature Recreation":2.0,"Preservation":2.0,"Sketches":2.0,"Noisy Line Charts":2.0,"arXiv251011927v1 Announce Type":1.0,"new Abstract":1.0,"Line charts":1.0,"many features":1.0,"time series data":1.0}},"age_hours":2.7378060886111113,"is_recent":true,"quality_score":1.0,"sentiment_score":3.418,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3164,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8989,"joy":0.01,"surprise":0.0205,"sadness":0.0048,"fear":0.0285,"anger":0.0194,"disgust":0.0179},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores how people perceive and prioritize features in noisy line charts, which could inform better data visualization for time series data related to sustainability. While it doesn't directly reduce emissions or deploy technology, it could indirectly improve the communication and understanding of sustainability data. The study uses SNR values (5-30 dB) as a metric for noise levels.","key_impact_metrics":["SNR ~5-30 dB"],"technology_tags":["data visualization","time series analysis"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T15:36:47.356942Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6197f9625c19","title":"Stable and Fault","content":"arXiv:2510.11937v1 Announce Type: new Abstract: Cloud providers have recently decentralized their wide-area network traffic engineering (TE) systems to contain the impact of TE controller failures. In the decentralized design, a controller fault only impacts its slice of the network, limiting the blast radius to a fraction of the network. However, we find that autonomous slice controllers can arrive at divergent traffic allocations that overload links by 30% beyond their capacity. We present Symphony, a decentralized TE system that addresses the challenge of divergence-induced congestion while preserving the fault-isolation benefits of decentralization. By augmenting TE objectives with quadratic regularization, Symphony makes traffic allocations robust to demand perturbations, ensuring TE controllers naturally converge to compatible allocations without coordination. In parallel, Symphony's randomized slicing algorithm partitions the network to minimize blast radius by distributing critical traffic sources across slices, preventing any single failure from becoming catastrophic. These innovations work in tandem: regularization ensures algorithmic stability to traffic allocations while intelligent slicing provides architectural resilience in the network. Through extensive evaluation on cloud provider WANs, we show Symphony reduces divergence-induced congestion by 14x and blast radius by 79% compared to current practice.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11937","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.246826","language":"en","tags":["preprints","csni","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Arjun Devraj, Umesh Krishnaswamy, Ying Zhang, Karuna Grewal, Justin Hsu, Eva Tardos, Rachee Singh","raw_content_length":1441,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["Symphony","Fault arXiv:2510.11937v1 Announce Type:"],"persons":["Symphony"],"locations":[],"monetary":[]},"char_count":1440,"language_detected":"en","key_concepts":{"key_phrases":["Fault","the network","arXiv251011937v1 Announce Type","new Abstract","Cloud providers","the impact","TE controller failures","the decentralized design","a controller fault","its slice"],"filter_categories":{"ai_ml":["TE controller failures"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Fault":2.0,"the network":2.0,"arXiv251011937v1 Announce Type":1.0,"new Abstract":1.0,"Cloud providers":1.0,"the impact":1.0,"TE controller failures":1.0,"the decentralized design":1.0,"a controller fault":1.0,"its slice":1.0}},"age_hours":2.737852109444445,"is_recent":true,"quality_score":1.0,"sentiment_score":0.8645000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8271,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8827,"joy":0.0038,"surprise":0.0697,"sadness":0.0074,"fear":0.0084,"anger":0.0225,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a decentralized traffic engineering system (Symphony) that reduces divergence-induced congestion by 14x and blast radius by 79% compared to current practice. This is a concrete action with measurable outcomes, suggesting potential for reducing energy waste in cloud networks. The claims are supported by 'extensive evaluation on cloud provider WANs,' implying a level of validation, but it's still in the applied research phase.","key_impact_metrics":["congestion reduction by 14x","blast radius reduction by 79%"],"technology_tags":["traffic engineering","cloud computing","network optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:50.734338Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8a50e067a440","title":"TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition","content":"arXiv:2510.11944v1 Announce Type: new Abstract: Large Language Models (LLMs) excel at both informal and formal (e.g. Lean 4) mathematical reasoning but still struggle with autoformalisation, the task of transforming informal into formal mathematical statements. Autoformalisation helps pair the informal reasoning of LLMs with formal proof assistants which enable machine-verifiable generation and mitigate hallucinations. Yet, the performance of current Math LLMs is constrained by the scarcity of large-scale corpora, particularly those containing pairs of informal and formal statements. Although current models are trained to generate code from natural language instructions, structural and syntactic differences between these and formal mathematics limit effective transfer learning. We propose TopoAlign, a framework that unlocks widely available code repositories as training resources for Math LLMs. TopoAlign decomposes code into docstrings, main functions, and dependency functions, and reassembles these components into analogues that structurally mirror formal statements. This produces structurally aligned code data that can be used for training Math LLMs without requiring additional human annotation. We train two state-of-the-art models, DeepSeek-Math and Herald, and evaluate them on the minif2f, Putnam, and ProofNet benchmarks. TopoAlign provides substantial gains for DeepSeek-Math, improving performance by 17.77% on BEq@10 and 68.82% on typecheck@10. Despite introducing no new mathematical knowledge, our framework achieves gains of 0.12% and 1.09% for Herald on BEq@10 and typecheck@10, respectively, demonstrating that training on aligned code data is beneficial even for specialized models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11944","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.248425","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Yupei Li, Philipp Borchert, Gerasimos Lampouras","raw_content_length":1718,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["Topological Decomposition arXiv:2510.11944v1 Announce Type","TopoAlign"],"persons":["Lean 4"],"locations":[],"monetary":[]},"char_count":1717,"language_detected":"en","key_concepts":{"key_phrases":["TopoAlign","A Framework","Aligning Code","Math","Topological Decomposition","LLMs","arXiv251011944v1 Announce Type","new Abstract","Large Language Models","eg Lean 4 mathematical reasoning"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TopoAlign":2.0,"A Framework":2.0,"Aligning Code":2.0,"Math":2.0,"Topological Decomposition":2.0,"LLMs":2.0,"arXiv251011944v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"eg Lean 4 mathematical reasoning":1.0}},"age_hours":2.737911679722222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.753,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7905,"joy":0.0127,"surprise":0.0147,"sadness":0.0081,"fear":0.1169,"anger":0.0338,"disgust":0.0233},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (TopoAlign) to improve Math LLMs by leveraging code repositories. While it improves model performance (17.77% on BEq@10 for DeepSeek-Math), it's currently in the research phase with no clear path to direct climate impact or economic viability. The technical credibility is supported by benchmark results and peer-review potential, but it's still early stage.","key_impact_metrics":["17.77% improvement on BEq@10","68.82% improvement on typecheck@10"],"technology_tags":["Large Language Models","Autoformalisation","Code Decomposition"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:36:54.068134Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0dd1f1237d3c","title":"Recovery of Integer Images from Limited DFT Measurements with Lattice Methods","content":"arXiv:2510.11949v1 Announce Type: new Abstract: Exact reconstruction of an image from measurements of its Discrete Fourier Transform (DFT) typically requires all DFT coefficients to be available. However, incorporating the prior assumption that the image contains only integer values enables unique recovery from a limited subset of DFT coefficients. This paper develops both theoretical and algorithmic foundations for this problem. We use algebraic properties of the DFT to define a reduction from two-dimensional recovery to several well-chosen one-dimensional recoveries. Our reduction framework characterizes the minimum number and location of DFT coefficients that must be sampled to guarantee unique reconstruction of an integer-valued image. Algorithmically, we develop reconstruction procedures which use dynamic programming to efficiently recover an integer signal or image from its minimal set of DFT measurements. While the new inversion algorithms still involve NP-hard subproblems, we demonstrate how the divide-and-conquer approach drastically reduces the associated search space. To solve the NP-hard subproblems, we employ a lattice-based framework which leverages the LLL approximation algorithm to make the algorithms fast and practical. We provide an analysis of the lattice method, suggesting approximate parameter choices to ensure correct inversion. Numerical results for the algorithms support the parameter analysis and demonstrate successful recovery of large integer images.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11949","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.250163","language":"en","tags":["preprints","mathna","csna","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Howard W Levinson, Isaac Viviano","raw_content_length":1502,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["DFT"],"persons":[],"locations":[],"monetary":[]},"char_count":1501,"language_detected":"en","key_concepts":{"key_phrases":["Recovery","Integer Images","Limited DFT Measurements","Lattice Methods","arXiv251011949v1 Announce Type","new Abstract","Exact reconstruction","an image","measurements","its Discrete Fourier Transform"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Recovery":2.0,"Integer Images":2.0,"Limited DFT Measurements":2.0,"Lattice Methods":2.0,"arXiv251011949v1 Announce Type":1.0,"new Abstract":1.0,"Exact reconstruction":1.0,"an image":1.0,"measurements":1.0,"its Discrete Fourier Transform":1.0}},"age_hours":2.7379267138888888,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5095,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4981,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9151,"joy":0.0178,"surprise":0.0417,"sadness":0.0061,"fear":0.0063,"anger":0.0079,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for image reconstruction from limited data, potentially reducing data transmission and storage needs. While the algorithm is demonstrated with numerical results, it is still in the research phase and lacks real-world deployment or economic viability. The impact on climate is indirect, potentially reducing energy consumption related to data processing, but this is not quantified.","key_impact_metrics":["Minimum number of DFT coefficients sampled","Recovery of large integer images"],"technology_tags":["Image Reconstruction","Discrete Fourier Transform","Lattice Methods","Dynamic Programming"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:36:57.794554Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6e7ac5359cc6","title":"GRAVITY: A Framework for Personalized Text Generation via Profile","content":"arXiv:2510.11952v1 Announce Type: new Abstract: Personalization in LLMs often relies on costly human feedback or interaction logs, limiting scalability and neglecting deeper user attributes. To reduce the reliance on human annotations, we introduce GRAVITY (Generative Response with Aligned Values, Interests, and Traits of You), a framework for generating synthetic, profile-grounded preference data that captures users' interests, values, beliefs, and personality traits. By integrating demographic, cultural, and psychological frameworks -- including Hofstede's cultural dimensions, Schwartz's basic values, the World Values Survey, and Big Five OCEAN traits -- GRAVITY synthesizes preference pairs to guide personalized content generation. We evaluate GRAVITY on book descriptions for 400 Amazon users, comparing it to prompt-based conditioning, standard fine-tuning, and naive synthetic pair generation. Profile-grounded synthetic data consistently improves generation, especially across multiple cultures (USA, Brazil, Japan, India), achieving over 4% higher preference gains across baselines, with user studies showing that GRAVITY outputs are preferred over 86% of the time. Our results show that scenario-grounded synthetic data can capture richer user variation, reduce reliance on costly annotation, and produce more engaging, user-centered content, offering a scalable path for LLM personalization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11952","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.250653","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Priyanka Dey, Daniele Rosa, Wenqing Zheng, Daniel Barcklow, Jieyu Zhao, Emilio Ferrara","raw_content_length":1411,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["Amazon","GRAVITY","Hofstede","the World Values Survey"],"persons":["Schwartz"],"locations":[],"monetary":[]},"char_count":1410,"language_detected":"en","key_concepts":{"key_phrases":["GRAVITY","A Framework","Personalized Text Generation","Profile","arXiv251011952v1 Announce Type","new Abstract","Personalization","LLMs","costly human feedback","interaction logs"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GRAVITY":3.0,"A Framework":2.0,"Personalized Text Generation":2.0,"Profile":2.0,"arXiv251011952v1 Announce Type":1.0,"new Abstract":1.0,"Personalization":1.0,"LLMs":1.0,"costly human feedback":1.0,"interaction logs":1.0}},"age_hours":2.737942320277778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9246,"joy":0.0053,"surprise":0.0211,"sadness":0.0076,"fear":0.0048,"anger":0.0236,"disgust":0.0129},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (GRAVITY) for generating synthetic data to improve LLM personalization, reducing reliance on costly human annotation. While it shows a 4% improvement in preference gains and user preference in 86% of cases, it's still in the research phase with no real-world deployment or quantifiable environmental impact. The vaporware flag is set due to the lack of deployed units or operational data.","key_impact_metrics":["4% higher preference gains","86% user preference"],"technology_tags":["LLM","Personalization","Synthetic Data Generation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:37:01.892331Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bd13ecd216a3","title":"Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors","content":"arXiv:2510.11953v1 Announce Type: new Abstract: Learning disentangled representations, where distinct factors of variation are captured by independent latent variables, is a central goal in machine learning. The dominant approach has been the Variational Autoencoder (VAE) framework, which uses a Kullback-Leibler (KL) divergence penalty to encourage the latent space to match a factorized Gaussian prior. In this work, however, we provide direct evidence that this KL-based regularizer is an unreliable mechanism, consistently failing to enforce the target distribution on the aggregate posterior. We validate this and quantify the resulting entanglement using our novel, unsupervised Latent Predictability Score (LPS). To address this failure, we introduce the Programmable Prior Framework, a method built on the Maximum Mean Discrepancy (MMD). Our framework allows practitioners to explicitly sculpt the latent space, achieving state-of-the-art mutual independence on complex datasets like CIFAR-10 and Tiny ImageNet without the common reconstruction trade-off. Furthermore, we demonstrate how this programmability can be used to engineer sophisticated priors that improve alignment with semantically meaningful features. Ultimately, our work provides a foundational tool for representation engineering, opening new avenues for model identifiability and causal reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11953","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.251083","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Quentin Fruytier, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, Aryan Mokhtari, Sujay Sanghavi","raw_content_length":1375,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["MMD","Kullback-Leibler","the Maximum Mean Discrepancy","LPS","the Variational Autoencoder (","Latent Predictability Score","VAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1374,"language_detected":"en","key_concepts":{"key_phrases":["Sculpting Latent Spaces","MMD","Disentanglement","Programmable Priors","arXiv251011953v1 Announce Type","new Abstract","Learning","representations","distinct factors","variation"],"filter_categories":{"ai_ml":["Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sculpting Latent Spaces":2.0,"MMD":2.0,"Disentanglement":2.0,"Programmable Priors":2.0,"arXiv251011953v1 Announce Type":1.0,"new Abstract":1.0,"Learning":1.0,"representations":1.0,"distinct factors":1.0,"variation":1.0}},"age_hours":2.7379577824999997,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8215,"joy":0.0219,"surprise":0.0242,"sadness":0.0185,"fear":0.0206,"anger":0.048,"disgust":0.0453},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning framework for disentangled representation learning. While it demonstrates improved performance on complex datasets, its direct climate impact is currently theoretical and unproven. It is at the basic research stage with no deployed units or economic viability demonstrated.","key_impact_metrics":["Latent Predictability Score (LPS)","Mutual Independence on CIFAR-10 and Tiny ImageNet"],"technology_tags":["Machine Learning","Representation Learning","Variational Autoencoders"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:37:05.065643Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fe97cca93867","title":"VizCopilot: Fostering Appropriate Reliance on Enterprise Chatbots with Context Visualization","content":"arXiv:2510.11954v1 Announce Type: new Abstract: Enterprise chatbots show promise in supporting knowledge workers in information synthesis tasks by retrieving context from large, heterogeneous databases before generating answers. However, when the retrieved context misaligns with user intentions, the chatbot often produces \"irrelevantly right\" responses that provide little value. In this work, we introduce VizCopilot, a prototype that incorporates visualization techniques to actively involve end-users in context alignment. By combining topic modeling with document visualization, VizCopilot enables human oversight and modification of retrieved context while keeping cognitive overhead manageable. We used VizCopilot as a design probe in a Research-through-Design study to evaluate the role of visualization in context alignment and to surface future design opportunities. Our findings show that visualization not only helps users detect and correct misaligned context but also encourages them to adapt their prompting strategies, enabling the system to retrieve more relevant context from the outset. At the same time, the study reveals limitations in verification support regarding close-reading and trust in AI summaries. We outline future directions for visualization-enhanced chatbots, focusing on personalization, proactivity, and sustainable human-AI collaboration.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11954","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.251501","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Sam Yu-Te Lee, Jingya Chen, Albert Calzaretto, Richard Lee, Alice Ferng, Mihaela Vorvoreanu","raw_content_length":1378,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["VizCopilot"],"persons":[],"locations":[],"monetary":[]},"char_count":1377,"language_detected":"en","key_concepts":{"key_phrases":["VizCopilot","Appropriate Reliance","Enterprise Chatbots","Context Visualization","arXiv251011954v1","Announce Type","new Abstract","Enterprise chatbots","promise","knowledge workers"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"VizCopilot":3.0,"Appropriate Reliance":2.0,"Enterprise Chatbots":2.0,"Context Visualization":2.0,"arXiv251011954v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Enterprise chatbots":1.0,"promise":1.0,"knowledge workers":1.0}},"age_hours":2.7379723605555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.718,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7436,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8539,"joy":0.0102,"surprise":0.0347,"sadness":0.0191,"fear":0.0102,"anger":0.0329,"disgust":0.0391},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a prototype (VizCopilot) and a Research-through-Design study. There are no deployed units or quantified impact metrics related to GHG emissions. The potential climate impact is theoretical, based on improving information synthesis for knowledge workers, which *could* indirectly support climate-related decision-making.","key_impact_metrics":[],"technology_tags":["enterprise chatbot","visualization","topic modeling","human-AI collaboration"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:37:08.880455Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e4f1f1eb258d","title":"Evaluating Retrieval","content":"arXiv:2510.11956v1 Announce Type: new Abstract: Real-world use cases often present RAG systems with complex queries for which relevant information is missing from the corpus or is incomplete. In these settings, RAG systems must be able to reject unanswerable, out-of-scope queries and identify failures of retrieval and multi-hop reasoning. Despite this, existing RAG benchmarks rarely reflect realistic task complexity for multi-hop or out-of-scope questions, which often can be cheated via disconnected reasoning (i.e., solved without genuine multi-hop inference) or require only simple factual recall. This limits the ability for such benchmarks to uncover limitations of existing RAG systems. To address this gap, we present the first pipeline for automatic, difficulty-controlled creation of un$\\underline{c}$heatable, $\\underline{r}$ealistic, $\\underline{u}$nanswerable, and $\\underline{m}$ulti-hop $\\underline{q}$uerie$\\underline{s}$ (CRUMQs), adaptable to any corpus and domain. We use our pipeline to create CRUMQs over two popular RAG datasets and demonstrate its effectiveness via benchmark experiments on leading retrieval-augmented LLMs. Results show that compared to prior RAG benchmarks, CRUMQs are highly challenging for RAG systems and achieve up to 81.0\\% reduction in cheatability scores. More broadly, our pipeline offers a simple way to enhance benchmark difficulty and realism and drive development of more capable RAG systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11956","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.252340","language":"en","tags":["preprints","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Gabrielle Kaili-May Liu, Bryan Li, Arman Cohan, William Gantt Walden, Eugene Yang","raw_content_length":1450,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["RAG","un$\\underline{c}$heatable"],"persons":["RAG"],"locations":[],"monetary":["\\underline{u}$nanswerable"]},"char_count":1449,"language_detected":"en","key_concepts":{"key_phrases":["Evaluating Retrieval","RAG systems","which","scope","arXiv251011956v1 Announce Type","new Abstract","Real-world use cases","complex queries","relevant information","the corpus"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Evaluating Retrieval":2.0,"RAG systems":2.0,"which":2.0,"scope":2.0,"arXiv251011956v1 Announce Type":1.0,"new Abstract":1.0,"Real-world use cases":1.0,"complex queries":1.0,"relevant information":1.0,"the corpus":1.0}},"age_hours":2.7380011130555557,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5964999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8807,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8467,"joy":0.0035,"surprise":0.0429,"sadness":0.0223,"fear":0.0177,"anger":0.0336,"disgust":0.0335},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for evaluating RAG systems, which could indirectly improve the efficiency of AI systems used in sustainability applications. However, it's currently at the research stage with no deployed technology or measured outcomes related to climate impact. The '81.0% reduction in cheatability scores' is a metric related to the AI system's performance, not a direct environmental impact.","key_impact_metrics":["81.0% reduction in cheatability scores"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","AI Benchmarking"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:37:14.244105Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_68fa90fd3336","title":"Direct Multi","content":"arXiv:2510.11958v1 Announce Type: new Abstract: Decoder-only transformers have become the standard architecture for large language models (LLMs) due to their strong performance. Recent studies suggest that, in pre-trained LLMs, early, middle, and late layers may serve distinct roles: Early layers focus on understanding the input context, middle layers handle task-specific processing, and late layers convert abstract representations into output tokens. We hypothesize that once representations have been processed by the early and middle layers, the resulting hidden states may encapsulate sufficient information to support the generation of multiple tokens using only the late layers, eliminating the need to repeatedly traverse the early and middle layers. We refer to this inference paradigm as Direct Multi-Token Decoding (DMTD). Unlike speculative decoding, our method introduces no additional parameters, auxiliary routines, or post-generation verification. Despite being trained on a limited dataset, a fine-tuned DMTD Qwen3-4B model has already demonstrated promising results, achieving up to a 2x speedup with only minor performance loss. Moreover, as shown in our scaling analysis, its performance is expected to further improve with larger training datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11958","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.252769","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Xuan Luo, Weizhi Wang, Xifeng Yan","raw_content_length":1273,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Direct Multi-Token Decoding","Direct Multi arXiv:2510.11958v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1272,"language_detected":"en","key_concepts":{"key_phrases":["Direct Multi","arXiv251011958v1 Announce Type","new Abstract","Decoder-only transformers","the standard architecture","large language models","LLMs","their strong performance","Recent studies","pre-trained LLMs"],"filter_categories":{"ai_ml":["Decoder-only transformers","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Direct Multi":2.0,"arXiv251011958v1 Announce Type":1.0,"new Abstract":1.0,"Decoder-only transformers":1.0,"the standard architecture":1.0,"large language models":1.0,"LLMs":1.0,"their strong performance":1.0,"Recent studies":1.0,"pre-trained LLMs":1.0}},"age_hours":2.7380163863888884,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8817,"joy":0.0207,"surprise":0.0482,"sadness":0.0032,"fear":0.0142,"anger":0.0213,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel inference method (DMTD) for LLMs that could potentially reduce computational energy consumption by speeding up the decoding process. The concrete action is the development and fine-tuning of a DMTD Qwen3-4B model, achieving up to a 2x speedup. However, the model is trained on a limited dataset and the results are preliminary, placing it at the applied research stage with limited deployment readiness.","key_impact_metrics":["2x speedup","minor performance loss"],"technology_tags":["Large Language Models","Inference Optimization","Decoder-only Transformers"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T15:37:17.729765Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0381aeddb4cc","title":"MosaicDiff: Training","content":"arXiv:2510.11962v1 Announce Type: new Abstract: Diffusion models are renowned for their generative capabilities, yet their pretraining processes exhibit distinct phases of learning speed that have been entirely overlooked in prior post-training acceleration efforts in the community. In this study, we introduce a novel framework called MosaicDiff that aligns diffusion pretraining dynamics with post-training sampling acceleration via trajectory-aware structural pruning. Our approach leverages the observation that the middle, fast-learning stage of diffusion pretraining requires more conservative pruning to preserve critical model features, while the early and later, slow-learning stages benefit from a more aggressive pruning strategy. This adaptive pruning mechanism is the first to explicitly mirror the inherent learning speed variations of diffusion pretraining, thereby harmonizing the model's inner training dynamics with its accelerated sampling process. Extensive experiments on DiT and SDXL demonstrate that our method achieves significant speed-ups in sampling without compromising output quality, outperforming previous state-of-the-art methods by large margins, also providing a new viewpoint for more efficient and robust training-free diffusion acceleration.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11962","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.253173","language":"en","tags":["preprints","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Bowei Guo, Shengkun Tang, Cong Zeng, Zhiqiang Shen","raw_content_length":1280,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["MosaicDiff"],"persons":[],"locations":[],"monetary":[]},"char_count":1279,"language_detected":"en","key_concepts":{"key_phrases":["MosaicDiff","Training","Announce Type","new Abstract","Diffusion models","their generative capabilities","their pretraining processes","distinct phases","speed","prior post-training acceleration efforts"],"filter_categories":{"ai_ml":["MosaicDiff"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MosaicDiff":3.0,"Training":2.0,"Announce Type":1.0,"new Abstract":1.0,"Diffusion models":1.0,"their generative capabilities":1.0,"their pretraining processes":1.0,"distinct phases":1.0,"speed":1.0,"prior post-training acceleration efforts":1.0}},"age_hours":2.738030059722222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.3004999999999995,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4601,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8006,"joy":0.0167,"surprise":0.1358,"sadness":0.0047,"fear":0.0134,"anger":0.0204,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework, MosaicDiff, for improving the efficiency of diffusion models, which are used for generative tasks. The concrete action is trajectory-aware structural pruning. The evidence supporting the claims comes from experiments on DiT and SDXL, demonstrating speed-ups in sampling. The innovation stage is applied research, as it is a framework tested on existing models but not yet deployed.","key_impact_metrics":["Significant speed-ups in sampling","Outperforming previous state-of-the-art methods by large margins"],"technology_tags":["Diffusion models","Structural pruning","Machine learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:37:34.244773Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6d180847b9b5","title":"QLENS: Towards A Quantum Perspective of Language Transformers","content":"arXiv:2510.11963v1 Announce Type: new Abstract: In natural language processing, current methods for understanding Transformers are successful at identifying intermediate predictions during a model's inference. However, these approaches function as limited diagnostic checkpoints, lacking a mathematical framework for mechanistically modeling how each layer facilitates transitions between these evolving states. This interpretability gap and past successes of interdisciplinary outlooks inspire us to turn to physics in search of a descriptive mathematical framework for Transformers. We observe that language models are intrinsically probabilistic, an attribute that is echoed in the core postulates of quantum mechanics. This parallel inspires us to translate insights from this discipline to that of natural language processing. Towards this objective, we propose QLENS a novel attempt to develop a physics-based perspective on the Transformer generation process. Under QLENS, a Transformer is studied by converting its latent activations into a state vector in a Hilbert space derived from the model's output units. This state subsequently evolves through hidden layers - reformulated as unitary operators and analogously defined Hamiltonians - during inference. The model's final probability distribution is obtained by applying the Born rule to the end state using a specific measurement operator. To demonstrate QLENS's potential, we conduct a proof-of-concept by probing a toy Transformer to investigate the influence of individual layers in a model's prediction trajectory. We present our work as a foundation for cross-domain insights to be leveraged towards a broader understanding of Transformers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11963","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.253614","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Aditya Gupta, Kirandeep Kaur, Vinayak Gupta","raw_content_length":1710,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["QLENS","A Quantum Perspective of Language Transformers"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1709,"language_detected":"en","key_concepts":{"key_phrases":["QLENS","A Quantum Perspective","Language Transformers","arXiv251011963v1 Announce Type","new Abstract","natural language processing","current methods","Transformers","intermediate predictions","a models inference"],"filter_categories":{"ai_ml":["Language Transformers","natural language processing","Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"QLENS":2.0,"A Quantum Perspective":2.0,"Language Transformers":2.0,"arXiv251011963v1 Announce Type":1.0,"new Abstract":1.0,"natural language processing":1.0,"current methods":1.0,"Transformers":1.0,"intermediate predictions":1.0,"a models inference":1.0}},"age_hours":2.7380443019444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8497,"joy":0.0085,"surprise":0.0474,"sadness":0.0288,"fear":0.0203,"anger":0.0224,"disgust":0.0229},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework (QLENS) for understanding language transformers using concepts from quantum mechanics. It's a proof-of-concept study on a toy transformer, meaning it's in the very early stages of research and has no immediate, direct impact on sustainability. The potential impact is highly speculative and depends on future research and applications.","key_impact_metrics":[],"technology_tags":["quantum computing","natural language processing","machine learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:37:40.142395Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4549d94577cf","title":"CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence","content":"arXiv:2510.11974v1 Announce Type: new Abstract: Cyber threat intelligence (CTI) is central to modern cybersecurity, providing critical insights for detecting and mitigating evolving threats. With the natural language understanding and reasoning capabilities of large language models (LLMs), there is increasing interest in applying them to CTI, which calls for benchmarks that can rigorously evaluate their performance. Several early efforts have studied LLMs on some CTI tasks but remain limited: (i) they adopt only closed-book settings, relying on parametric knowledge without leveraging CTI knowledge bases; (ii) they cover only a narrow set of tasks, lacking a systematic view of the CTI landscape; and (iii) they restrict evaluation to single-source analysis, unlike realistic scenarios that require reasoning across multiple sources. To fill these gaps, we present CTIArena, the first benchmark for evaluating LLM performance on heterogeneous, multi-source CTI under knowledge-augmented settings. CTIArena spans three categories, structured, unstructured, and hybrid, further divided into nine tasks that capture the breadth of CTI analysis in modern security operations. We evaluate ten widely used LLMs and find that most struggle in closed-book setups but show noticeable gains when augmented with security-specific knowledge through our designed retrieval-augmented techniques. These findings highlight the limitations of general-purpose LLMs and the need for domain-tailored techniques to fully unlock their potential for CTI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11974","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.254425","language":"en","tags":["preprints","csai","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Yutong Cheng, Yang Liu, Changze Li, Dawn Song, Peng Gao","raw_content_length":1539,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["CTIArena","CTI"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1538,"language_detected":"en","key_concepts":{"key_phrases":["CTIArena","Benchmarking LLM Knowledge","Reasoning","Heterogeneous Cyber Threat Intelligence","CTI","LLMs","arXiv251011974v1","Announce Type","new Abstract","Cyber threat intelligence"],"filter_categories":{"ai_ml":["Benchmarking LLM Knowledge"],"hydrogen_energy":["CTI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CTIArena":2.0,"Benchmarking LLM Knowledge":2.0,"Reasoning":2.0,"Heterogeneous Cyber Threat Intelligence":2.0,"CTI":2.0,"LLMs":2.0,"arXiv251011974v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Cyber threat intelligence":1.0}},"age_hours":2.738073860833333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6624,"joy":0.0132,"surprise":0.0351,"sadness":0.0075,"fear":0.2418,"anger":0.0342,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a benchmark (CTIArena) for evaluating LLMs on cyber threat intelligence. While it addresses a relevant area for security and potentially resource optimization, it's currently in the research phase with no concrete deployments or measurable outcomes related to climate impact. The impact is theoretical at this stage.","key_impact_metrics":[],"technology_tags":["large language models","cyber threat intelligence","benchmarking"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T15:37:44.348736Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5827c18b9d5d","title":"Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation","content":"arXiv:2510.11977v1 Announce Type: new Abstract: AI agents have been developed for complex real-world tasks from coding to customer service. But AI agent evaluations suffer from many challenges that undermine our understanding of how well agents really work. We introduce the Holistic Agent Leaderboard (HAL) to address these challenges. We make three main contributions. First, we provide a standardized evaluation harness that orchestrates parallel evaluations across hundreds of VMs, reducing evaluation time from weeks to hours while eliminating common implementation bugs. Second, we conduct three-dimensional analysis spanning models, scaffolds, and benchmarks. We validate the harness by conducting 21,730 agent rollouts across 9 models and 9 benchmarks in coding, web navigation, science, and customer service with a total cost of about $40,000. Our analysis reveals surprising insights, such as higher reasoning effort reducing accuracy in the majority of runs. Third, we use LLM-aided log inspection to uncover previously unreported behaviors, such as searching for the benchmark on HuggingFace instead of solving a task, or misusing credit cards in flight booking tasks. We share all agent logs, comprising 2.5B tokens of language model calls, to incentivize further research into agent behavior. By standardizing how the field evaluates agents and addressing common pitfalls in agent evaluation, we hope to shift the focus from agents that ace benchmarks to agents that work reliably in the real world.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11977","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.254869","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Sayash Kapoor, Benedikt Stroebl, Peter Kirgis, Nitya Nadgir, Zachary S Siegel, Boyi Wei, Tianci Xue, Ziru Chen, Felix Chen, Saiteja Utpala, Franck Ndzomga, Dheeraj Oruganty, Sophie Luskin, Kangheng Liu, Botao Yu, Amit Arora, Dongyoon Hahm, Harsh Trivedi, Huan Sun, Juyong Lee, Tengjun Jin, Yifan Mai, Yifei Zhou, Yuxuan Zhu, Rishi Bommasani, Daniel Kang, Dawn Song, Peter Henderson, Yu Su, Percy Liang, Arvind Narayanan","raw_content_length":1514,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["Holistic","The Missing Infrastructure for AI Agent Evaluation arXiv:2510.11977v1 Announce Type"],"persons":[],"locations":[],"monetary":["about $40,000"]},"char_count":1513,"language_detected":"en","key_concepts":{"key_phrases":["Holistic Agent Leaderboard","The Missing Infrastructure","AI Agent Evaluation","new Abstract","AI agents","complex real-world tasks","customer service","AI agent evaluations","many challenges","our understanding"],"filter_categories":{"ai_ml":["AI Agent Evaluation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Holistic Agent Leaderboard":2.0,"The Missing Infrastructure":2.0,"AI Agent Evaluation":2.0,"new Abstract":1.0,"AI agents":1.0,"complex real-world tasks":1.0,"customer service":1.0,"AI agent evaluations":1.0,"many challenges":1.0,"our understanding":1.0}},"age_hours":2.7380899647222225,"is_recent":true,"quality_score":1.0,"sentiment_score":1.596,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6808,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8573,"joy":0.0039,"surprise":0.0146,"sadness":0.056,"fear":0.0376,"anger":0.0157,"disgust":0.0148},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a standardized evaluation harness for AI agents, which could indirectly support sustainability efforts by improving the reliability and efficiency of AI systems used in climate modeling, resource management, or other related fields. However, the direct climate impact is theoretical at this stage, as it's focused on improving evaluation rather than deploying a specific climate technology. The technical credibility is relatively high due to the validation of the harness with 21,730 agent rollouts and the sharing of agent logs.","key_impact_metrics":["21,730 agent rollouts","2.5B tokens of language model calls"],"technology_tags":["AI agents","Evaluation harness"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:37:48.538410Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e35edb63df5c","title":"Learning Dynamics of VLM Finetuning","content":"arXiv:2510.11978v1 Announce Type: new Abstract: Preference-based finetuning of vision--language models (VLMs) is brittle: trivially wrong negatives inject uninformative gradients that destabilize training. We recast alignment as \\textbf{learning-dynamics--aware optimization} and introduce \\textbf{Cooling-Weighted DPO (CW-DPO)}, a two-stage recipe that explicitly models and exploits the training trajectory. \\textbf{Stage 1} performs supervised finetuning with \\textbf{gentle negatives}: \\textbf{low-weight smoothed supervision} that regularizes the base policy and curbs overconfidence without explicit penalties. \\textbf{Stage 2} applies a DPO objective in which the \\textbf{negative term is scaled by a cooling weight} computed from the model's \\textbf{average token log-probability} on each negative, suppressing uninformative gradients from easy or off-distribution samples while preserving signal from hard negatives. In practice, we emphasize \\textbf{on-policy negatives} and allow \\textbf{mixed negatives} by blending a controllable fraction of dataset negatives to maintain contrast freshness. Throughout, we instrument training with $\\Delta\\!\\log p$ probes on positives and negatives as first-class signals for early stopping, curriculum design, and failure diagnosis. Across diverse VLM tasks, CW-DPO yields \\textbf{more stable optimization}, \\textbf{better calibration}, and \\textbf{higher pairwise win-rates} than SFT-only and vanilla DPO, while \\textbf{converging in fewer steps}. Ablations isolate the \\textbf{cooling-weight mechanism} as the primary driver of these gains and show complementary benefits from mixing on-policy and dataset negatives. Taken together, our results show that \\textbf{smoothing learning dynamics before cooling preferences} is a simple, general principle for robust VLM alignment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11978","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.256741","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Jusheng Zhang, Kaitong Cai, Jing Yang, Keze Wang","raw_content_length":1826,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["DPO","Learning Dynamics","CW-DPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1825,"language_detected":"en","key_concepts":{"key_phrases":["Learning Dynamics","VLM Finetuning","arXiv251011978v1 Announce Type","new Abstract","Preference-based finetuning","vision","language models","VLMs","trivially wrong negatives","uninformative gradients"],"filter_categories":{"ai_ml":["vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Learning Dynamics":2.0,"VLM Finetuning":2.0,"arXiv251011978v1 Announce Type":1.0,"new Abstract":1.0,"Preference-based finetuning":1.0,"vision":1.0,"language models":1.0,"VLMs":1.0,"trivially wrong negatives":1.0,"uninformative gradients":1.0}},"age_hours":2.7381051438888893,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5385,"joy":0.006,"surprise":0.0423,"sadness":0.0305,"fear":0.1167,"anger":0.1817,"disgust":0.0843},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm (CW-DPO) for improving the training of vision-language models. While the algorithm itself doesn't directly reduce GHG emissions, it could potentially improve the efficiency of AI models used in climate-related applications, leading to indirect energy savings. The research is at a basic research stage with no deployed units or real-world data yet.","key_impact_metrics":["fewer steps to convergence","higher pairwise win-rates"],"technology_tags":["vision-language models","preference-based finetuning","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:37:52.148287Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0afb0e3c00f3","title":"Learning by Steering the Neural Dynamics: A Statistical Mechanics Perspective","content":"arXiv:2510.11984v1 Announce Type: new Abstract: Despite the striking successes of deep neural networks trained with gradient-based optimization, these methods differ fundamentally from their biological counterparts. This gap raises key questions about how nature achieves robust, sample-efficient learning at minimal energy costs and solves the credit-assignment problem without backpropagation. We take a step toward bridging contemporary AI and computational neuroscience by studying how neural dynamics can support fully local, distributed learning that scales to simple machine-learning benchmarks. Using tools from statistical mechanics, we identify conditions for the emergence of robust dynamical attractors in random asymmetric recurrent networks. We derive a closed-form expression for the number of fixed points as a function of self-coupling strength, and we reveal a phase transition in their structure: below a critical self-coupling, isolated fixed points coexist with exponentially many narrow clusters showing the overlap-gap property; above it, subdominant yet dense and extensive clusters appear. These fixed points become accessible, including to a simple asynchronous dynamical rule, after an algorithm-dependent self-coupling threshold. Building on this analysis, we propose a biologically plausible algorithm for supervised learning with any binary recurrent network. Inputs are mapped to fixed points of the dynamics, by relaxing under transient external stimuli and stabilizing the resulting configurations via local plasticity. We show that our algorithm can learn an entangled version of MNIST, leverages depth to develop hierarchical representations and increase hetero-association capacity, and is applicable to several architectures. Finally, we highlight the strong connection between algorithm performance and the unveiled phase transition, and we suggest a cortex-inspired alternative to self-couplings for its emergence.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11984","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.257198","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":259,"author":"Mattia Scardecchia","raw_content_length":1954,"priority":7,"update_frequency":1,"reading_time_minutes":1.295,"robust_parsing_used":true,"entities":{"organizations":["Steering the Neural Dynamics: A Statistical Mechanics Perspective"],"persons":[],"locations":[],"monetary":[]},"char_count":1953,"language_detected":"en","key_concepts":{"key_phrases":["the Neural Dynamics","arXiv251011984v1","Announce Type","new Abstract","the striking successes","deep neural networks","gradient-based optimization","these methods","their biological counterparts","This gap"],"filter_categories":{"ai_ml":["deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Neural Dynamics":2.0,"arXiv251011984v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"the striking successes":1.0,"deep neural networks":1.0,"gradient-based optimization":1.0,"these methods":1.0,"their biological counterparts":1.0,"This gap":1.0}},"age_hours":2.738119769166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.8420000000000005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5684,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9037,"joy":0.0144,"surprise":0.0389,"sadness":0.0076,"fear":0.0101,"anger":0.0139,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for neural network learning that aims to be more biologically plausible and energy-efficient. While the algorithm shows promise in machine learning benchmarks, it is currently in the basic research stage with no concrete deployments or quantified impact on energy consumption or emissions reduction. The potential climate impact is theoretical at this point.","key_impact_metrics":[],"technology_tags":["neural networks","machine learning","algorithm"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:37:55.761142Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1780c506c9b7","title":"CGBench: Benchmarking Language Model Scientific Reasoning for Clinical Genetics Research","content":"arXiv:2510.11985v1 Announce Type: new Abstract: Variant and gene interpretation are fundamental to personalized medicine and translational biomedicine. However, traditional approaches are manual and labor-intensive. Generative language models (LMs) can facilitate this process, accelerating the translation of fundamental research into clinically-actionable insights. While existing benchmarks have attempted to quantify the capabilities of LMs for interpreting scientific data, these studies focus on narrow tasks that do not translate to real-world research. To meet these challenges, we introduce CGBench, a robust benchmark that tests reasoning capabilities of LMs on scientific publications. CGBench is built from ClinGen, a resource of expert-curated literature interpretations in clinical genetics. CGBench measures the ability to 1) extract relevant experimental results following precise protocols and guidelines, 2) judge the strength of evidence, and 3) categorize and describe the relevant outcome of experiments. We test 8 different LMs and find that while models show promise, substantial gaps exist in literature interpretation, especially on fine-grained instructions. Reasoning models excel in fine-grained tasks but non-reasoning models are better at high-level interpretations. Finally, we measure LM explanations against human explanations with an LM judge approach, revealing that models often hallucinate or misinterpret results even when correctly classifying evidence. CGBench reveals strengths and weaknesses of LMs for precise interpretation of scientific publications, opening avenues for future research in AI for clinical genetics and science more broadly.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11985","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.257642","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Owen Queen, Harrison G. Zhang, James Zou","raw_content_length":1686,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["ClinGen","CGBench"],"persons":["Variant"],"locations":[],"monetary":[]},"char_count":1685,"language_detected":"en","key_concepts":{"key_phrases":["CGBench","Benchmarking Language Model Scientific Reasoning","Clinical Genetics Research","LMs","arXiv251011985v1 Announce Type","new Abstract","Variant and gene interpretation","personalized medicine","translational biomedicine","traditional approaches"],"filter_categories":{"research_academic":["Clinical Genetics Research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CGBench":2.0,"Benchmarking Language Model Scientific Reasoning":2.0,"Clinical Genetics Research":2.0,"LMs":2.0,"arXiv251011985v1 Announce Type":1.0,"new Abstract":1.0,"Variant and gene interpretation":1.0,"personalized medicine":1.0,"translational biomedicine":1.0,"traditional approaches":1.0}},"age_hours":2.7381338136111113,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9106,"joy":0.0192,"surprise":0.0252,"sadness":0.0028,"fear":0.0119,"anger":0.0232,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces CGBench, a benchmark for evaluating language models in clinical genetics research. While it doesn't directly reduce GHG emissions, it aims to accelerate the translation of research into clinically-actionable insights, potentially leading to more efficient healthcare and resource utilization. The benchmark is built from ClinGen, an expert-curated resource, lending technical credibility, but it's currently in the applied research stage with no deployed units or customer contracts.","key_impact_metrics":["Strength of evidence judged by LMs","Accuracy of outcome categorization by LMs"],"technology_tags":["Language Models","Clinical Genetics","Scientific Reasoning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:37:59.123251Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_599010bf3122","title":"Conjecturing: An Overlooked Step in Formal Mathematical Reasoning","content":"arXiv:2510.11986v1 Announce Type: new Abstract: Autoformalisation, the task of expressing informal mathematical statements in formal language, is often viewed as a direct translation process. This, however, disregards a critical preceding step: conjecturing. Many mathematical problems cannot be formalised directly without first conjecturing a conclusion such as an explicit answer, or a specific bound. Since Large Language Models (LLMs) already struggle with autoformalisation, and the evaluation of their conjecturing ability is limited and often entangled within autoformalisation or proof, it is particularly challenging to understand its effect. To address this gap, we augment existing datasets to create ConjectureBench, and redesign the evaluation framework and metric specifically to measure the conjecturing capabilities of LLMs both as a distinct task and within the autoformalisation pipeline. Our evaluation of foundational models, including GPT-4.1 and DeepSeek-V3.1, reveals that their autoformalisation performance is substantially overestimated when the conjecture is accounted for during evaluation. However, the conjecture should not be assumed to be provided. We design an inference-time method, Lean-FIRe to improve conjecturing and autoformalisation, which, to the best of our knowledge, achieves the first successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1 and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite knowledge to generate accurate conjectures, improving autoformalisation performance requires treating conjecturing as an independent task, and investigating further how to correctly integrate it within autoformalisation. Finally, we provide forward-looking guidance to steer future research toward improving conjecturing, an overlooked step of formal mathematical reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11986","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.258073","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Jasivan Alex Sivakumar, Philipp Borchert, Ronald Cardenas, Gerasimos Lampouras","raw_content_length":1865,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["ConjectureBench"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1864,"language_detected":"en","key_concepts":{"key_phrases":["An Overlooked Step","Formal Mathematical Reasoning","arXiv251011986v1 Announce Type","new Abstract","Autoformalisation","the task","informal mathematical statements","formal language","a direct translation process","a critical preceding step"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Overlooked Step":2.0,"Formal Mathematical Reasoning":2.0,"arXiv251011986v1 Announce Type":1.0,"new Abstract":1.0,"Autoformalisation":1.0,"the task":1.0,"informal mathematical statements":1.0,"formal language":1.0,"a direct translation process":1.0,"a critical preceding step":1.0}},"age_hours":2.738148079166667,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2105,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7579,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8416,"joy":0.007,"surprise":0.0508,"sadness":0.0063,"fear":0.034,"anger":0.0287,"disgust":0.0316},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the conjecturing capabilities of LLMs in mathematical reasoning. While it demonstrates improved autoformalization of PutnamBench problems, there are no direct concrete actions or measurable outcomes related to sustainability. The research is in the early stages, with no deployment or economic viability demonstrated.","key_impact_metrics":["13 PutnamBench problems autoformalized with GPT-4.1","7 PutnamBench problems autoformalized with DeepSeek-V3.1"],"technology_tags":["Large Language Models","Autoformalization","Mathematical Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:38:01.958995Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c7390097b2e","title":"PanoTPS","content":"arXiv:2510.11992v1 Announce Type: new Abstract: Accurately estimating the 3D layout of rooms is a crucial task in computer vision, with potential applications in robotics, augmented reality, and interior design. This paper proposes a novel model, PanoTPS-Net, to estimate room layout from a single panorama image. Leveraging a Convolutional Neural Network (CNN) and incorporating a Thin Plate Spline (TPS) spatial transformation, the architecture of PanoTPS-Net is divided into two stages: First, a convolutional neural network extracts the high-level features from the input images, allowing the network to learn the spatial parameters of the TPS transformation. Second, the TPS spatial transformation layer is generated to warp a reference layout to the required layout based on the predicted parameters. This unique combination empowers the model to properly predict room layouts while also generalizing effectively to both cuboid and non-cuboid layouts. Extensive experiments on publicly available datasets and comparisons with state-of-the-art methods demonstrate the effectiveness of the proposed method. The results underscore the model's accuracy in room layout estimation and emphasize the compatibility between the TPS transformation and panorama images. The robustness of the model in handling both cuboid and non-cuboid room layout estimation is evident with a 3DIoU value of 85.49, 86.16, 81.76, and 91.98 on PanoContext, Stanford-2D3D, Matterport3DLayout, and ZInD datasets, respectively. The source code is available at: https://github.com/HatemHosam/PanoTPS_Net.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11992","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.258888","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Hatem Ibrahem, Ahmed Salem, Qinmin Vivian Hu, Guanghui Wang","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["Thin Plate Spline","TPS","CNN"],"persons":[],"locations":[],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["PanoTPS-Net","Announce Type","new Abstract","the 3D layout","rooms","a crucial task","computer vision","potential applications","robotics","augmented reality"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PanoTPS-Net":2.0,"Announce Type":1.0,"new Abstract":1.0,"the 3D layout":1.0,"rooms":1.0,"a crucial task":1.0,"computer vision":1.0,"potential applications":1.0,"robotics":1.0,"augmented reality":1.0}},"age_hours":2.738177938611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8905,"joy":0.0149,"surprise":0.0557,"sadness":0.0035,"fear":0.013,"anger":0.0151,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel model for room layout estimation, which could potentially contribute to energy efficiency in buildings by optimizing interior design. However, the impact is indirect and not quantified. The model's accuracy is demonstrated on publicly available datasets, but it is still in the applied research stage with no real-world deployment.","key_impact_metrics":["3DIoU value of 85.49 on PanoContext","3DIoU value of 86.16 on Stanford-2D3D"],"technology_tags":["Convolutional Neural Network","Thin Plate Spline"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T15:38:05.031495Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4369a8034805","title":"Prompt-Guided Spatial Understanding with RGB","content":"arXiv:2510.11996v1 Announce Type: new Abstract: Spatial reasoning in large-scale 3D environments such as warehouses remains a significant challenge for vision-language systems due to scene clutter, occlusions, and the need for precise spatial understanding. Existing models often struggle with generalization in such settings, as they rely heavily on local appearance and lack explicit spatial grounding. In this work, we introduce a dedicated spatial reasoning framework for the Physical AI Spatial Intelligence Warehouse dataset introduced in the Track 3 2025 AI City Challenge. Our approach enhances spatial comprehension by embedding mask dimensions in the form of bounding box coordinates directly into the input prompts, enabling the model to reason over object geometry and layout. We fine-tune the framework across four question categories namely: Distance Estimation, Object Counting, Multi-choice Grounding, and Spatial Relation Inference using task-specific supervision. To further improve consistency with the evaluation system, normalized answers are appended to the GPT response within the training set. Our comprehensive pipeline achieves a final score of 73.0606, placing 4th overall on the public leaderboard. These results demonstrate the effectiveness of structured prompt enrichment and targeted optimization in advancing spatial reasoning for real-world industrial environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11996","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.259291","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Tanner Muturi, Blessing Agyei Kyem, Joshua Kofi Asamoah, Neema Jakisa Owor, Richard Dyzinela, Andrews Danyo, Yaw Adu-Gyamfi, Armstrong Aboah","raw_content_length":1400,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Prompt-Guided Spatial Understanding","Distance Estimation","RGB arXiv:2510.11996v1 Announce Type","AI City Challenge","Spatial Relation Inference","the Physical AI Spatial Intelligence Warehouse"],"persons":[],"locations":[],"monetary":[]},"char_count":1399,"language_detected":"en","key_concepts":{"key_phrases":["Prompt-Guided Spatial Understanding","RGB","arXiv251011996v1 Announce Type","new Abstract","Spatial reasoning","large-scale 3D environments","warehouses","a significant challenge","vision-language systems","scene clutter"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Prompt-Guided Spatial Understanding":2.0,"RGB":2.0,"arXiv251011996v1 Announce Type":1.0,"new Abstract":1.0,"Spatial reasoning":1.0,"large-scale 3D environments":1.0,"warehouses":1.0,"a significant challenge":1.0,"vision-language systems":1.0,"scene clutter":1.0}},"age_hours":2.7381928380555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9286,"joy":0.0049,"surprise":0.0247,"sadness":0.008,"fear":0.0111,"anger":0.0136,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a spatial reasoning framework for warehouse environments, achieving a score of 73.0606 on a public leaderboard. This is a pilot-stage project, as it is based on a challenge dataset and lacks real-world deployment data. The impact on climate is indirect, potentially improving warehouse efficiency but without quantified emissions reductions.","key_impact_metrics":["Score on leaderboard: 73.0606"],"technology_tags":["spatial reasoning","vision-language models","warehouse automation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:38:10.608959Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9045a03866a6","title":"SAGE: A Top-Down Bottom-Up Knowledge","content":"arXiv:2510.11997v1 Announce Type: new Abstract: Evaluating multi-turn interactive agents is challenging due to the need for human assessment. Evaluation with simulated users has been introduced as an alternative, however existing approaches typically model generic users and overlook the domain-specific principles required to capture realistic behavior. We propose SAGE, a novel user Simulation framework for multi-turn AGent Evaluation that integrates knowledge from business contexts. SAGE incorporates top-down knowledge rooted in business logic, such as ideal customer profiles, grounding user behavior in realistic customer personas. We further integrate bottom-up knowledge taken from business agent infrastructure (e.g., product catalogs, FAQs, and knowledge bases), allowing the simulator to generate interactions that reflect users' information needs and expectations in a company's target market. Through empirical evaluation, we find that this approach produces interactions that are more realistic and diverse, while also identifying up to 33% more agent errors, highlighting its effectiveness as an evaluation tool to support bug-finding and iterative agent improvement.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11997","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.259692","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Ryan Shea, Yunan Lu, Liang Qiu, Zhou Yu","raw_content_length":1185,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1184,"language_detected":"en","key_concepts":{"key_phrases":["SAGE","arXiv251011997v1 Announce Type","new Abstract","Evaluating multi-turn interactive agents","the need","human assessment","Evaluation","simulated users","an alternative","existing approaches"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SAGE":3.0,"arXiv251011997v1 Announce Type":1.0,"new Abstract":1.0,"Evaluating multi-turn interactive agents":1.0,"the need":1.0,"human assessment":1.0,"Evaluation":1.0,"simulated users":1.0,"an alternative":1.0,"existing approaches":1.0}},"age_hours":2.7382077213888887,"is_recent":true,"quality_score":0.7,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9347,"joy":0.0097,"surprise":0.0246,"sadness":0.005,"fear":0.0113,"anger":0.0103,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel user simulation framework (SAGE) for evaluating multi-turn interactive agents. While it identifies up to 33% more agent errors, this is an early-stage concept without demonstrated real-world impact on climate or other sustainability dimensions. The technology is at the applied research stage, with potential but unproven economic viability and deployment readiness.","key_impact_metrics":["33% more agent errors identified"],"technology_tags":["AI","User Simulation","Agent Evaluation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:38:15.688350Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f1672c0b543","title":"Choose Your Own Solution: Supporting Optional Blocks in Block Ordering Problems","content":"arXiv:2510.11999v1 Announce Type: new Abstract: This paper extends the functionality of block ordering problems (such as Parsons problems and Proof Blocks) to include optional blocks. We detail the algorithms used to implement the optional block feature and present usage experiences from instructors who have integrated it into their curriculum. The optional blocks feature enables instructors to create more complex Parsons problems with multiple correct solutions utilizing omitted or optional blocks. This affords students a method to engage with questions that have several valid solutions composed of different answer components. Instructors can specify blocks with multiple mutually exclusive dependencies, which we represent using a multigraph structure. This multigraph is then collapsed into multiple directed acyclic graphs (DAGs), allowing us to reuse existing algorithms for grading block ordering problems represented as a DAG. We present potential use cases for this feature across various domains, including helping students learn Git workflows, shell command sequences, mathematical proofs, and Python programming concepts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11999","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.260077","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Skyler Oakeson, David H. Smith IV, Jaxton Winder, Seth Poulsen","raw_content_length":1141,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Proof Blocks"],"locations":[],"monetary":[]},"char_count":1140,"language_detected":"en","key_concepts":{"key_phrases":["Your Own Solution","Optional Blocks","Block Ordering Problems","instructors","arXiv251011999v1 Announce Type","new Abstract","This paper","the functionality","block","problems"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Your Own Solution":2.0,"Optional Blocks":2.0,"Block Ordering Problems":2.0,"instructors":2.0,"arXiv251011999v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"the functionality":1.0,"block":1.0,"problems":1.0}},"age_hours":2.7382225858333333,"is_recent":true,"quality_score":1.0,"sentiment_score":0.363,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9274,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8369,"joy":0.0839,"surprise":0.0615,"sadness":0.0051,"fear":0.0024,"anger":0.0076,"disgust":0.0028},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an extension to block ordering problems, including optional blocks. While it details algorithms and usage experiences from instructors, it lacks concrete deployment data or measurable outcomes related to sustainability. The impact on climate or other sustainability dimensions is minimal and theoretical.","key_impact_metrics":[],"technology_tags":["educational software","algorithm"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T15:38:18.428397Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4cb42e26d983","title":"UALM: Unified Audio Language Model for Understanding, Generation and Reasoning","content":"arXiv:2510.12000v1 Announce Type: new Abstract: Recent advances in the audio language modeling (ALM) domain tackle audio understanding and text-to-audio generation as separate tasks. Very few studies attempt to unify these tasks -- an essential step toward advanced multimodal reasoning. This paper introduces U}nified Audio Language Model (UALM), which aims to unify audio understanding, text-to-audio generation, and multimodal reasoning in a single model. To achieve this goal, we first present UALM-Gen, a text-to-audio language model that directly predicts audio tokens and is comparable to state-of-the-art diffusion-based models. We then demonstrate, using proper data blending, training recipes, and inference techniques, that our single UALM model matches the quality of state-of-the-art specialized models in audio understanding, text-to-audio generation, and text reasoning. Furthermore, we present UALM-Reason, a multimodal reasoning model that utilizes both text and audio in the intermediate thinking steps to facilitate complex generation tasks. To our knowledge, this is the first demonstration in audio research of cross-modal generative reasoning, with its effectiveness confirmed by subjective evaluations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12000","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.260471","language":"en","tags":["preprints","computer-science","cslg","research","cscl","cssd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Jinchuan Tian, Sang-gil Lee, Zhifeng Kong, Sreyan Ghosh, Arushi Goel, Chao-Han Huck Yang, Wenliang Dai, Zihan Liu, Hanrong Ye, Shinji Watanabe, Mohammad Shoeybi, Bryan Catanzaro, Rafael Valle, Wei Ping","raw_content_length":1226,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["UALM","UALM-Gen","ALM","UALM-Reason"],"persons":["Announce Type","Language Model"],"locations":[],"monetary":[]},"char_count":1225,"language_detected":"en","key_concepts":{"key_phrases":["UALM","Unified Audio Language Model","Understanding","Generation","Reasoning","audio","arXiv251012000v1 Announce Type","new Abstract","Recent advances","the audio language modeling"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"UALM":3.0,"Unified Audio Language Model":2.0,"Understanding":2.0,"Generation":2.0,"Reasoning":2.0,"audio":2.0,"arXiv251012000v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"the audio language modeling":1.0}},"age_hours":2.738239085,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8975,"joy":0.019,"surprise":0.0539,"sadness":0.0058,"fear":0.007,"anger":0.0113,"disgust":0.0055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel audio language model (UALM) capable of understanding, generating, and reasoning with audio data. The concrete action is the development of the model itself, but it is still in the research phase with no deployed units or real-world data. The effectiveness is confirmed by subjective evaluations, but lacks quantifiable metrics related to sustainability impact.","key_impact_metrics":[],"technology_tags":["audio language model","multimodal reasoning","text-to-audio generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:38:23.280133Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03372df8848f","title":"Generate Logical Equivalence Questions","content":"arXiv:2510.12001v1 Announce Type: new Abstract: Academic dishonesty is met with zero tolerance in higher education, yet plagiarism has become increasingly prevalent in the era of online teaching and learning. Automatic Question Generation (AQG) presents a potential solution to mitigate copying by creating unique questions for each student. Additionally, AQG can provide a vast array of practice questions. Our AQG focuses on generating logical equivalence questions for Discrete Mathematics, a foundational course for first-year computer science students. A literature review reveals that existing AQGs for this type of question generate all propositions that meet user-defined constraints, resulting in inefficiencies and a lack of uniform question difficulty. To address this, we propose a new approach that defines logical equivalence questions using a formal language, translates this language into two sets of generation rules, and develops a linear-time algorithm for question generation. We evaluated our AQG through two experiments. The first involved a group of students completing questions generated by our system. Statistical analysis shows that the accuracy of these questions is comparable to that of textbook questions. The second experiment assessed the number of steps required to solve our generated questions, textbook questions, and those generated by multiple large language models. The results indicated that the difficulty of our questions was similar to that of textbook questions, confirming the quality of our AQG.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12001","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.260894","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Xinyu Wang, Haoming Yu, Yicheng Yang, Zhiyuan Li","raw_content_length":1543,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["Automatic Question Generation","AQG","Generate Logical Equivalence Questions arXiv:2510.12001v1","Discrete Mathematics"],"persons":[],"locations":[],"monetary":[]},"char_count":1542,"language_detected":"en","key_concepts":{"key_phrases":["Generate Logical Equivalence Questions","AQG","Announce Type","new Abstract","Academic dishonesty","zero tolerance","higher education","plagiarism","the era","online teaching"],"filter_categories":{"research_academic":["Academic dishonesty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generate Logical Equivalence Questions":2.0,"AQG":2.0,"Announce Type":1.0,"new Abstract":1.0,"Academic dishonesty":1.0,"zero tolerance":1.0,"higher education":1.0,"plagiarism":1.0,"the era":1.0,"online teaching":1.0}},"age_hours":2.738253805,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8865,"joy":0.0068,"surprise":0.0058,"sadness":0.0045,"fear":0.0375,"anger":0.0354,"disgust":0.0235},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm for generating logical equivalence questions, which could indirectly support sustainability education by reducing plagiarism and providing more practice questions. The technical credibility is relatively high due to the statistical analysis comparing the accuracy and difficulty of generated questions to textbook questions. However, the deployment readiness is low as it is still in the pilot stage and the climate impact potential is minimal as it is primarily focused on education.","key_impact_metrics":["Accuracy of questions comparable to textbook questions","Difficulty of questions similar to textbook questions"],"technology_tags":["Automatic Question Generation","Educational Technology"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T15:38:26.336287Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_411d6a31ceb3","title":"Asking Clarifying Questions for Preference Elicitation With Large Language Models","content":"arXiv:2510.12015v1 Announce Type: new Abstract: Large Language Models (LLMs) have made it possible for recommendation systems to interact with users in open-ended conversational interfaces. In order to personalize LLM responses, it is crucial to elicit user preferences, especially when there is limited user history. One way to get more information is to present clarifying questions to the user. However, generating effective sequential clarifying questions across various domains remains a challenge. To address this, we introduce a novel approach for training LLMs to ask sequential questions that reveal user preferences. Our method follows a two-stage process inspired by diffusion models. Starting from a user profile, the forward process generates clarifying questions to obtain answers and then removes those answers step by step, serving as a way to add ``noise'' to the user profile. The reverse process involves training a model to ``denoise'' the user profile by learning to ask effective clarifying questions. Our results show that our method significantly improves the LLM's proficiency in asking funnel questions and eliciting user preferences effectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12015","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.263287","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Ali Montazeralghaem, Guy Tennenholtz, Craig Boutilier, Ofer Meshi","raw_content_length":1173,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1172,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Clarifying Questions","Preference Elicitation","arXiv251012015v1 Announce Type","new Abstract","LLMs","recommendation systems","users","open-ended conversational interfaces","order"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"Clarifying Questions":2.0,"Preference Elicitation":2.0,"arXiv251012015v1 Announce Type":1.0,"new Abstract":1.0,"LLMs":1.0,"recommendation systems":1.0,"users":1.0,"open-ended conversational interfaces":1.0,"order":1.0}},"age_hours":2.738314135,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8856,"joy":0.0291,"surprise":0.0161,"sadness":0.0065,"fear":0.0236,"anger":0.024,"disgust":0.0151},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel method for training LLMs to elicit user preferences, which could indirectly support sustainability by improving recommendation systems for sustainable products or services. However, the article focuses on the algorithm itself and does not provide concrete actions or measurable outcomes related to climate change or other sustainability dimensions. It is currently at the basic research stage with no deployment or quantified impact.","key_impact_metrics":[],"technology_tags":["Large Language Models","Recommendation Systems"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:38:32.031779Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_89f58b22d3e6","title":"Evaluating the Explainability of Vision Transformers in Medical Imaging","content":"arXiv:2510.12021v1 Announce Type: new Abstract: Understanding model decisions is crucial in medical imaging, where interpretability directly impacts clinical trust and adoption. Vision Transformers (ViTs) have demonstrated state-of-the-art performance in diagnostic imaging; however, their complex attention mechanisms pose challenges to explainability. This study evaluates the explainability of different Vision Transformer architectures and pre-training strategies - ViT, DeiT, DINO, and Swin Transformer - using Gradient Attention Rollout and Grad-CAM. We conduct both quantitative and qualitative analyses on two medical imaging tasks: peripheral blood cell classification and breast ultrasound image classification. Our findings indicate that DINO combined with Grad-CAM offers the most faithful and localized explanations across datasets. Grad-CAM consistently produces class-discriminative and spatially precise heatmaps, while Gradient Attention Rollout yields more scattered activations. Even in misclassification cases, DINO with Grad-CAM highlights clinically relevant morphological features that appear to have misled the model. By improving model transparency, this research supports the reliable and explainable integration of ViTs into critical medical diagnostic workflows.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12021","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.264196","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Leili Barekatain, Ben Glocker","raw_content_length":1291,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["DINO","Vision Transformer","Gradient Attention Rollout","Vision Transformers","ViT","Grad-CAM","DeiT"],"persons":["Swin Transformer"],"locations":[],"monetary":[]},"char_count":1290,"language_detected":"en","key_concepts":{"key_phrases":["Vision Transformers","the Explainability","Medical Imaging","arXiv251012021v1 Announce Type","new Abstract","Understanding model decisions","medical imaging","interpretability","clinical trust","adoption"],"filter_categories":{"ai_ml":["Vision Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vision Transformers":3.0,"the Explainability":2.0,"Medical Imaging":2.0,"arXiv251012021v1 Announce Type":1.0,"new Abstract":1.0,"Understanding model decisions":1.0,"medical imaging":1.0,"interpretability":1.0,"clinical trust":1.0,"adoption":1.0}},"age_hours":2.7383404408333334,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7859,"joy":0.0376,"surprise":0.0199,"sadness":0.0079,"fear":0.1139,"anger":0.0192,"disgust":0.0157},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the explainability of AI models in medical imaging, which indirectly supports sustainability by potentially improving healthcare outcomes and resource allocation. The study uses quantitative and qualitative analyses on medical imaging tasks, providing some metrics for model performance. However, it's still in the applied research stage with no deployed units or customer contracts.","key_impact_metrics":["Faithfulness of explanations","Localization of explanations"],"technology_tags":["Vision Transformers","Explainable AI","Medical Imaging"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:38:35.643690Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a455b4ec8432","title":"Information Extraction from Conversation Transcripts: Neuro","content":"arXiv:2510.12023v1 Announce Type: new Abstract: The current trend in information extraction (IE) is to rely extensively on large language models, effectively discarding decades of experience in building symbolic or statistical IE systems. This paper compares a neuro-symbolic (NS) and an LLM-based IE system in the agricultural domain, evaluating them on nine interviews across pork, dairy, and crop subdomains. The LLM-based system outperforms the NS one (F1 total: 69.4 vs. 52.7; core: 63.0 vs. 47.2), where total includes all extracted information and core focuses on essential details. However, each system has trade-offs: the NS approach offers faster runtime, greater control, and high accuracy in context-free tasks but lacks generalizability, struggles with contextual nuances, and requires significant resources to develop and maintain. The LLM-based system achieves higher performance, faster deployment, and easier maintenance but has slower runtime, limited control, model dependency and hallucination risks. Our findings highlight the \"hidden cost\" of deploying NLP systems in real-world applications, emphasizing the need to balance performance, efficiency, and control.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12023","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.264612","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Alice Saebom Kwak, Maria Alexeeva, Gus Hahn-Powell, Keith Alcock, Kevin McLaughlin, Doug McCorkle, Gabe McNunn, Mihai Surdeanu","raw_content_length":1185,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1184,"language_detected":"en","key_concepts":{"key_phrases":["Information Extraction","Conversation Transcripts","Neuro","arXiv251012023v1 Announce Type","new Abstract","The current trend","information extraction","large language models","decades","experience"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Information Extraction":2.0,"Conversation Transcripts":2.0,"Neuro":2.0,"arXiv251012023v1 Announce Type":1.0,"new Abstract":1.0,"The current trend":1.0,"information extraction":1.0,"large language models":1.0,"decades":1.0,"experience":1.0}},"age_hours":2.7383570394444448,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8584,"joy":0.0239,"surprise":0.0698,"sadness":0.0071,"fear":0.0057,"anger":0.0176,"disgust":0.0175},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper compares two information extraction systems in the agricultural domain. While it provides F1 scores (69.4 vs. 52.7), it is still in the research phase with no deployed technology or measured environmental outcomes. The vaporware flag is raised because it is a comparison of systems, not a deployed solution with operational data.","key_impact_metrics":["F1 total: 69.4","F1 core: 63.0"],"technology_tags":["Information Extraction","Neuro-Symbolic Systems","Large Language Models"],"sdg_alignment":[2],"analyzed_at":"2025-10-29T15:38:38.651321Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c83e442e25f","title":"Mamaba Can Learn Low-Dimensional Targets In","content":"arXiv:2510.12026v1 Announce Type: new Abstract: Mamba, a recently proposed linear-time sequence model, has attracted significant attention for its computational efficiency and strong empirical performance. However, a rigorous theoretical understanding of its underlying mechanisms remains limited. In this work, we provide a theoretical analysis of Mamba's in-context learning (ICL) capability by focusing on tasks defined by low-dimensional nonlinear target functions. Specifically, we study in-context learning of a single-index model $y \\approx g_*(\\langle \\boldsymbol{\\beta}, \\boldsymbol{x} \\rangle)$, which depends on only a single relevant direction $\\boldsymbol{\\beta}$, referred to as feature. We prove that Mamba, pretrained by gradient-based methods, can achieve efficient ICL via test-time feature learning, extracting the relevant direction directly from context examples. Consequently, we establish a test-time sample complexity that improves upon linear Transformers -- analyzed to behave like kernel methods -- and is comparable to nonlinear Transformers, which have been shown to surpass the Correlational Statistical Query (CSQ) lower bound and achieve near information-theoretically optimal rate in previous works. Our analysis reveals the crucial role of the nonlinear gating mechanism in Mamba for feature extraction, highlighting it as the fundamental driver behind Mamba's ability to achieve both computational efficiency and high performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12026","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.265031","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Junsoo Oh, Wei Huang, Taiji Suzuki","raw_content_length":1466,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Mamba","ICL"],"persons":[],"locations":["Mamaba","\\approx"],"monetary":["\\boldsymbol{\\beta}$"]},"char_count":1465,"language_detected":"en","key_concepts":{"key_phrases":["Mamaba","Low-Dimensional Targets","arXiv251012026v1 Announce Type","new Abstract","Mamba","a recently proposed linear-time sequence model","significant attention","its computational efficiency","strong empirical performance","a rigorous theoretical understanding"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mamaba":2.0,"Low-Dimensional Targets":2.0,"arXiv251012026v1 Announce Type":1.0,"new Abstract":1.0,"Mamba":1.0,"a recently proposed linear-time sequence model":1.0,"significant attention":1.0,"its computational efficiency":1.0,"strong empirical performance":1.0,"a rigorous theoretical understanding":1.0}},"age_hours":2.738372148888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8362,"joy":0.0647,"surprise":0.0589,"sadness":0.0086,"fear":0.01,"anger":0.015,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical analysis of the Mamba model's in-context learning capabilities. While the research demonstrates improved efficiency in feature extraction compared to some transformer models, it remains at the basic research stage with no deployed technology or measured outcomes related to climate impact. The potential for climate impact is indirect and speculative at this point.","key_impact_metrics":[],"technology_tags":["Machine Learning","Sequence Modeling","Mamba"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:38:50.784829Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_77beca35efbc","title":"CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement","content":"arXiv:2510.12029v1 Announce Type: new Abstract: Recent advancements in large language models (LLMs) highlight their fluency in generating responses to diverse prompts. However, these models sometimes generate plausible yet incorrect ``hallucinated\" facts, undermining trust. A frequent but often overlooked cause of such errors is the use of poorly structured or vague prompts by users, leading LLMs to base responses on assumed rather than actual intentions. To mitigate hallucinations induced by these ill-formed prompts, we introduce Curative Prompt Refinement (CPR), a plug-and-play framework for curative prompt refinement that 1) cleans ill-formed prompts, and 2) generates additional informative task descriptions to align the intention of the user and the prompt using a fine-tuned small language model. When applied to language models, we discover that CPR significantly increases the quality of generation while also mitigating hallucination. Empirical studies show that prompts with CPR applied achieves over a 90\\% win rate over the original prompts without any external knowledge.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12029","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.265845","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Jung-Woo Shim, Yeong-Joon Ju, Ji-Hoon Park, Seong-Whan Lee","raw_content_length":1094,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["Curative Prompt Refinement","CPR"],"persons":[],"locations":[],"monetary":[]},"char_count":1093,"language_detected":"en","key_concepts":{"key_phrases":["CPR","Large Language Model Hallucinations","Curative Prompt Refinement","LLMs","responses","arXiv251012029v1","Announce Type","new Abstract","Recent advancements","large language models"],"filter_categories":{"ai_ml":["Large Language Model Hallucinations","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CPR":2.0,"Large Language Model Hallucinations":2.0,"Curative Prompt Refinement":2.0,"LLMs":2.0,"responses":2.0,"arXiv251012029v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Recent advancements":1.0,"large language models":1.0}},"age_hours":2.738401497777778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9410000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4118,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7937,"joy":0.003,"surprise":0.0202,"sadness":0.0284,"fear":0.0301,"anger":0.0777,"disgust":0.0469},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (CPR) to refine prompts for LLMs, reducing hallucinations and improving output quality. While the technology shows promise with a reported 90% win rate in empirical studies, it is still in the applied research phase with no clear path to economic viability or large-scale deployment. The impact on sustainability is indirect, potentially improving the accuracy of information related to climate change, but not directly reducing emissions.","key_impact_metrics":["Win rate over original prompts: 90%"],"technology_tags":["Large Language Models","Prompt Engineering","Artificial Intelligence"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:38:54.761031Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ec4c17f02a49","title":"Multi","content":"arXiv:2510.12273v1 Announce Type: new Abstract: Self-improvement has emerged as a state-of-the-art paradigm in Neural Combinatorial Optimization (NCO), where models iteratively refine their policies by generating and imitating high-quality solutions. Despite strong empirical performance, existing methods face key limitations. Training is computationally expensive, as policy updates require sampling numerous candidate solutions per instance to extract a single expert trajectory. More fundamentally, these approaches fail to exploit the structure of combinatorial problems involving the coordination of multiple agents, such as vehicles in min-max routing or machines in scheduling. By supervising on single-action trajectories, they fail to exploit agent-permutation symmetries, where distinct sequences of actions yield identical solutions, hindering generalization and the ability to learn coordinated behavior. We address these challenges by extending self-improvement to operate over joint multi-agent actions. Our model architecture predicts complete agent-task assignments jointly at each decision step. To explicitly leverage symmetries, we employ a set-prediction loss, which supervises the policy on multiple expert assignments for any given state. This approach enhances sample efficiency and the model's ability to learn coordinated behavior. Furthermore, by generating multi-agent actions in parallel, it drastically accelerates the solution generation phase of the self-improvement loop. Empirically, we validate our method on several combinatorial problems, demonstrating consistent improvements in the quality of the final solution and a reduced generation latency compared to standard self-improvement.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12273","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.338963","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Laurin Luttmann, Lin Xie","raw_content_length":1725,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Neural Combinatorial Optimization"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1722,"language_detected":"en","key_concepts":{"key_phrases":["Multi","arXiv251012273v1 Announce Type","new Abstract","Self-improvement","the-art","Neural Combinatorial Optimization","NCO","models","their policies","high-quality solutions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multi":2.0,"arXiv251012273v1 Announce Type":1.0,"new Abstract":1.0,"Self-improvement":1.0,"the-art":1.0,"Neural Combinatorial Optimization":1.0,"NCO":1.0,"models":1.0,"their policies":1.0,"high-quality solutions":1.0}},"age_hours":2.7405406022222225,"is_recent":true,"quality_score":0.7,"sentiment_score":6.589,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3178,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6994,"joy":0.0054,"surprise":0.0126,"sadness":0.0266,"fear":0.1085,"anger":0.0504,"disgust":0.0971},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel approach to neural combinatorial optimization that improves the efficiency and quality of solutions for multi-agent problems. While the method demonstrates improvements in solution quality and generation latency, it is still in the research phase with no mention of real-world deployment or quantified environmental impact. The vaporware flag is raised because it is an early-stage concept without deployed units.","key_impact_metrics":["reduced generation latency","improvements in the quality of the final solution"],"technology_tags":["neural combinatorial optimization","multi-agent systems","self-improvement algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:38:58.582585Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_db1fc009d6af","title":"CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing","content":"arXiv:2510.12033v1 Announce Type: new Abstract: Modern manufacturing environments demand not only accurate predictions but also interpretable insights to process anomalies, root causes, and potential interventions. Existing AI systems often function as isolated black boxes, lacking the seamless integration of prediction, explanation, and causal reasoning required for a unified decision-support solution. This fragmentation limits their trustworthiness and practical utility in high-stakes industrial environments. In this work, we present CausalTrace, a neurosymbolic causal analysis module integrated into the SmartPilot industrial CoPilot. CausalTrace performs data-driven causal analysis enriched by industrial ontologies and knowledge graphs, including advanced functions such as causal discovery, counterfactual reasoning, and root cause analysis (RCA). It supports real-time operator interaction and is designed to complement existing agents by offering transparent, explainable decision support. We conducted a comprehensive evaluation of CausalTrace using multiple causal assessment methods and the C3AN framework (i.e. Custom, Compact, Composite AI with Neurosymbolic Integration), which spans principles of robustness, intelligence, and trustworthiness. In an academic rocket assembly testbed, CausalTrace achieved substantial agreement with domain experts (ROUGE-1: 0.91 in ontology QA) and strong RCA performance (MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92). It also attained 4.59/5 in the C3AN evaluation, demonstrating precision and reliability for live deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12033","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.267086","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Chathurangi Shyalika, Aryaman Sharma, Fadi El Kalach, Utkarshani Jaimini, Cory Henson, Ramy Harik, Amit Sheth","raw_content_length":1588,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Smart Manufacturing arXiv:2510.12033v1 Announce Type","CoPilot","RCA","Neurosymbolic Causal Analysis","neurosymbolic causal","CausalTrace","SmartPilot"],"persons":["causal discovery"],"locations":[],"monetary":[]},"char_count":1587,"language_detected":"en","key_concepts":{"key_phrases":["CausalTrace","A Neurosymbolic Causal Analysis Agent","Smart Manufacturing","arXiv251012033v1 Announce Type","new Abstract","Modern manufacturing environments","not only accurate predictions","interpretable insights","anomalies","root causes"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CausalTrace":2.0,"A Neurosymbolic Causal Analysis Agent":2.0,"Smart Manufacturing":2.0,"arXiv251012033v1 Announce Type":1.0,"new Abstract":1.0,"Modern manufacturing environments":1.0,"not only accurate predictions":1.0,"interpretable insights":1.0,"anomalies":1.0,"root causes":1.0}},"age_hours":2.7384446516666663,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8928,"joy":0.0054,"surprise":0.057,"sadness":0.0114,"fear":0.0121,"anger":0.0138,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a neurosymbolic causal analysis module (CausalTrace) integrated into an industrial CoPilot. It achieved strong RCA performance (MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92) in an academic rocket assembly testbed and attained 4.59/5 in the C3AN evaluation. While promising, it is still in the early stages of deployment and economic viability is not yet demonstrated.","key_impact_metrics":["MAP@3: 94%","PR@2: 97%"],"technology_tags":["Neurosymbolic AI","Causal Analysis","Smart Manufacturing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:39:02.472847Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4eafc8b230f6","title":"Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions","content":"arXiv:2510.12040v1 Announce Type: new Abstract: The rapid advancement of large language models (LLMs) has transformed the landscape of natural language processing, enabling breakthroughs across a wide range of areas including question answering, machine translation, and text summarization. Yet, their deployment in real-world applications has raised concerns over reliability and trustworthiness, as LLMs remain prone to hallucinations that produce plausible but factually incorrect outputs. Uncertainty quantification (UQ) has emerged as a central research direction to address this issue, offering principled measures for assessing the trustworthiness of model generations. We begin by introducing the foundations of UQ, from its formal definition to the traditional distinction between epistemic and aleatoric uncertainty, and then highlight how these concepts have been adapted to the context of LLMs. Building on this, we examine the role of UQ in hallucination detection, where quantifying uncertainty provides a mechanism for identifying unreliable generations and improving reliability. We systematically categorize a wide spectrum of existing methods along multiple dimensions and present empirical results for several representative approaches. Finally, we discuss current limitations and outline promising future research directions, providing a clearer picture of the current landscape of LLM UQ for hallucination detection.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12040","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.269625","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Sungmin Kang, Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Salman Avestimehr","raw_content_length":1438,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Future Directions"],"persons":[],"locations":[],"monetary":[]},"char_count":1437,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty Quantification","Hallucination Detection","Large Language Models","Foundations","Methodology","Future Directions","LLMs","arXiv251012040v1 Announce Type","new Abstract","The rapid advancement"],"filter_categories":{"ai_ml":["Uncertainty Quantification","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty Quantification":2.0,"Hallucination Detection":2.0,"Large Language Models":2.0,"Foundations":2.0,"Methodology":2.0,"Future Directions":2.0,"LLMs":2.0,"arXiv251012040v1 Announce Type":1.0,"new Abstract":1.0,"The rapid advancement":1.0}},"age_hours":2.7384691625,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.3948,"joy":0.0095,"surprise":0.024,"sadness":0.0093,"fear":0.5338,"anger":0.0189,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on research into uncertainty quantification for hallucination detection in large language models. While it aims to improve the reliability of LLMs, its direct climate impact is minimal as it is still in the basic research phase with no deployed technology or measured outcomes. The vaporware flag is raised because it discusses early-stage concepts without mentioning deployed units or operational data.","key_impact_metrics":[],"technology_tags":["large language models","uncertainty quantification","hallucination detection"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:39:05.514084Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
