{"id":"science_arxiv_cs_af11abd4d4c3","title":"On the Optimal Representation Efficiency of Barlow Twins: An Information","content":"arXiv:2510.10980v1 Announce Type: new Abstract: Self-supervised learning (SSL) has achieved remarkable success by learning meaningful representations without labeled data. However, a unified theoretical framework for understanding and comparing the efficiency of different SSL paradigms remains elusive. In this paper, we introduce a novel information-geometric framework to quantify representation efficiency. We define representation efficiency $\\eta$ as the ratio between the effective intrinsic dimension of the learned representation space and its ambient dimension, where the effective dimension is derived from the spectral properties of the Fisher Information Matrix (FIM) on the statistical manifold induced by the encoder. Within this framework, we present a theoretical analysis of the Barlow Twins method. Under specific but natural assumptions, we prove that Barlow Twins achieves optimal representation efficiency ($\\eta = 1$) by driving the cross-correlation matrix of representations towards the identity matrix, which in turn induces an isotropic FIM. This work provides a rigorous theoretical foundation for understanding the effectiveness of Barlow Twins and offers a new geometric perspective for analyzing SSL algorithms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10980","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.847151","language":"en","tags":["statml","cslg","mathst","preprints","cscv","research","mathit","statth","csit","computer-science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Di Zhang","raw_content_length":1243,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["SSL","the Fisher Information Matrix","the Optimal Representation Efficiency","FIM"],"persons":["Barlow Twins"],"locations":[],"monetary":[]},"char_count":1242,"language_detected":"en","key_concepts":{"key_phrases":["the Optimal Representation Efficiency","Barlow Twins","representation efficiency","arXiv251010980v1 Announce Type","new Abstract","Self-supervised learning","SSL","remarkable success","meaningful representations","labeled data"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Optimal Representation Efficiency":2.0,"Barlow Twins":2.0,"representation efficiency":2.0,"arXiv251010980v1 Announce Type":1.0,"new Abstract":1.0,"Self-supervised learning":1.0,"SSL":1.0,"remarkable success":1.0,"meaningful representations":1.0,"labeled data":1.0}},"age_hours":2.7554220847222224,"is_recent":true,"quality_score":1.0,"sentiment_score":9.850999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9702,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8346,"joy":0.0327,"surprise":0.0872,"sadness":0.0048,"fear":0.0132,"anger":0.0203,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical analysis of a self-supervised learning method (Barlow Twins) and its representation efficiency. While the research is theoretically sound and provides a new geometric perspective, it remains at the basic research stage with no concrete deployment or measured outcomes related to climate impact. The vaporware flag is set because it is about a concept without deployment.","key_impact_metrics":["Representation efficiency Î· = 1"],"technology_tags":["Self-supervised learning","Barlow Twins","Fisher Information Matrix"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:45:35.111444Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f4fdb326b033","title":"ABLEIST: Intersectional Disability Bias in LLM","content":"arXiv:2510.10998v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly under scrutiny for perpetuating identity-based discrimination in high-stakes domains such as hiring, particularly against people with disabilities (PwD). However, existing research remains largely Western-centric, overlooking how intersecting forms of marginalization--such as gender and caste--shape experiences of PwD in the Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring scenarios spanning diverse disability, gender, nationality, and caste profiles. To capture subtle intersectional harms and biases, we introduce ABLEIST (Ableism, Inspiration, Superhumanization, and Tokenism), a set of five ableism-specific and three intersectional harm metrics grounded in disability studies literature. Our results reveal significant increases in ABLEIST harms towards disabled candidates--harms that many state-of-the-art models failed to detect. These harms were further amplified by sharp increases in intersectional harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates, highlighting critical blind spots in current safety tools and the need for intersectional safety evaluations of frontier models in high-stakes domains like hiring.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10998","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.852143","language":"en","tags":["cslg","cscy","csai","preprints","research","cscl","cshc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Mahika Phutane, Hayoung Jung, Matthew Kim, Tanushree Mitra, Aditya Vashistha","raw_content_length":1280,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["PwD"],"persons":[],"locations":["the Global South"],"monetary":[]},"char_count":1279,"language_detected":"en","key_concepts":{"key_phrases":["Intersectional Disability Bias","LLM","PwD","arXiv251010998v1 Announce Type","new Abstract","Large language models","LLMs","scrutiny","identity-based discrimination","high-stakes domains"],"filter_categories":{"ai_ml":["LLM","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Intersectional Disability Bias":2.0,"LLM":2.0,"PwD":2.0,"arXiv251010998v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"scrutiny":1.0,"identity-based discrimination":1.0,"high-stakes domains":1.0}},"age_hours":2.755582205,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8634,"joy":0.0041,"surprise":0.0267,"sadness":0.0096,"fear":0.036,"anger":0.0283,"disgust":0.0318},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":0,"technical_credibility":7,"economic_viability":0,"deployment_readiness":0,"systemic_impact":5,"justice_equity":10,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies and quantifies intersectional biases in LLMs related to hiring, specifically focusing on disability. It introduces ABLEIST metrics and audits six LLMs across 2,820 hiring scenarios, providing concrete evidence of harms. While it doesn't directly impact climate, it addresses a critical justice and equity issue within a rapidly evolving technological landscape.","key_impact_metrics":["Increase in ABLEIST harms towards disabled candidates","Increase in intersectional harms for gender and caste-marginalized disabled candidates"],"technology_tags":["Large Language Models","AI Bias Detection","Fairness Metrics"],"sdg_alignment":[5,10,16],"analyzed_at":"2025-10-29T11:45:38.736352Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c0b94ba99748","title":"ContextGen: Contextual Layout Anchoring for Identity","content":"arXiv:2510.11000v1 Announce Type: new Abstract: Multi-instance image generation (MIG) remains a significant challenge for modern diffusion models due to key limitations in achieving precise control over object layout and preserving the identity of multiple distinct subjects. To address these limitations, we introduce ContextGen, a novel Diffusion Transformer framework for multi-instance generation that is guided by both layout and reference images. Our approach integrates two key technical contributions: a Contextual Layout Anchoring (CLA) mechanism that incorporates the composite layout image into the generation context to robustly anchor the objects in their desired positions, and Identity Consistency Attention (ICA), an innovative attention mechanism that leverages contextual reference images to ensure the identity consistency of multiple instances. Recognizing the lack of large-scale, hierarchically-structured datasets for this task, we introduce IMIG-100K, the first dataset with detailed layout and identity annotations. Extensive experiments demonstrate that ContextGen sets a new state-of-the-art, outperforming existing methods in control precision, identity fidelity, and overall visual quality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11000","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.852557","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Ruihang Xu, Dewei Zhou, Fan Ma, Yi Yang","raw_content_length":1220,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["Diffusion Transformer","ContextGen","Identity Consistency Attention","ICA"],"persons":[],"locations":[],"monetary":[]},"char_count":1219,"language_detected":"en","key_concepts":{"key_phrases":["ContextGen","Contextual Layout Anchoring","Identity","arXiv251011000v1 Announce Type","new Abstract","Multi-instance image generation","MIG","a significant challenge","modern diffusion models","key limitations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ContextGen":3.0,"Contextual Layout Anchoring":2.0,"Identity":2.0,"arXiv251011000v1 Announce Type":1.0,"new Abstract":1.0,"Multi-instance image generation":1.0,"MIG":1.0,"a significant challenge":1.0,"modern diffusion models":1.0,"key limitations":1.0}},"age_hours":2.755596443611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8496,"joy":0.038,"surprise":0.0687,"sadness":0.0062,"fear":0.0195,"anger":0.0142,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for multi-instance image generation. While the technology itself does not directly address climate change, it could potentially be used in applications related to sustainability, such as generating images for environmental monitoring or visualizing climate change impacts. The research is in its early stages, with no deployed units or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["diffusion models","image generation","transformer networks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:45:42.113939Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bcbf146c7bd0","title":"FBS Model","content":"arXiv:2510.11003v1 Announce Type: new Abstract: In manufacturing systems, identifying the causes of failures is crucial for maintaining and improving production efficiency. In knowledge-based failure-cause inference, it is important that the knowledge base (1) explicitly structures knowledge about the target system and about failures, and (2) contains sufficiently long causal chains of failures. In this study, we constructed Diagnostic Knowledge Ontology and proposed a Function-Behavior-Structure (FBS) model-based maintenance-record accumulation method based on it. Failure-cause inference using the maintenance records accumulated by the proposed method showed better agreement with the set of candidate causes enumerated by experts, especially in difficult cases where the number of related cases is small and the vocabulary used differs. In the future, it will be necessary to develop inference methods tailored to these maintenance records, build a user interface, and carry out validation on larger and more diverse systems. Additionally, this approach leverages the understanding and knowledge of the target in the design phase to support knowledge accumulation and problem solving during the maintenance phase, and it is expected to become a foundation for knowledge sharing across the entire engineering chain in the future.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11003","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.853347","language":"en","tags":["computer-science","csai","preprints","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Takuma Fujiu, Sho Okazaki, Kohei Kaminishi, Yuji Nakata, Shota Hamamoto, Kenshin Yokose, Tatsunori Hara, Yasushi Umeda, Jun Ota","raw_content_length":1339,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["FBS","FBS Model arXiv:2510.11003v1 Announce Type","Function-Behavior-Structure"],"persons":[],"locations":[],"monetary":[]},"char_count":1338,"language_detected":"en","key_concepts":{"key_phrases":["failures","FBS Model","arXiv251011003v1 Announce Type","new Abstract","manufacturing systems","the causes","production efficiency","knowledge-based failure-cause inference","the knowledge base","knowledge"],"filter_categories":{"ai_ml":["failures"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"failures":3.0,"FBS Model":2.0,"arXiv251011003v1 Announce Type":1.0,"new Abstract":1.0,"manufacturing systems":1.0,"the causes":1.0,"production efficiency":1.0,"knowledge-based failure-cause inference":1.0,"the knowledge base":1.0,"knowledge":1.0}},"age_hours":2.7556280719444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9307,"joy":0.0095,"surprise":0.0219,"sadness":0.0084,"fear":0.0101,"anger":0.0107,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a method for failure-cause inference in manufacturing systems using a knowledge ontology. While it shows better agreement with expert-identified causes, especially in difficult cases, it is still in the early stages of development with no deployed units or real-world data beyond the described experiment. The economic viability and deployment readiness are low as it requires further development and validation.","key_impact_metrics":["Better agreement with expert causes"],"technology_tags":["Diagnostic Knowledge Ontology","Function-Behavior-Structure Model"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:45:45.211386Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b85114da9a84","title":"Automating Structural Engineering Workflows with Large Language Model Agents","content":"arXiv:2510.11004v1 Announce Type: new Abstract: We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows. Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size. Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities. We present a proof-of-concept showing that most real-world structural engineering workflows can be fully automated through a training-free LLM-based multi-agent system. MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11004","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.853763","language":"en","tags":["csce","csma","csai","preprints","research","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Haoran Liang, Yufa Zhou, Mohammad Talebi Kalaleh, Qipei Mei","raw_content_length":1224,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Announce Type","\\textbf{MASSE}$"],"locations":[],"monetary":[]},"char_count":1223,"language_detected":"en","key_concepts":{"key_phrases":["Automating","Structural Engineering Workflows","Large Language Model Agents","arXiv251011004v1 Announce Type","new Abstract","textbfMASSE","the first Multi-Agent System","Structural Engineering","large language model","LLM-based agents"],"filter_categories":{"ai_ml":["Large Language Model Agents","large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Automating":2.0,"Structural Engineering Workflows":2.0,"Large Language Model Agents":2.0,"arXiv251011004v1 Announce Type":1.0,"new Abstract":1.0,"textbfMASSE":1.0,"the first Multi-Agent System":1.0,"Structural Engineering":1.0,"large language model":1.0,"LLM-based agents":1.0}},"age_hours":2.7556421725,"is_recent":true,"quality_score":1.0,"sentiment_score":6.6000000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.32,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8748,"joy":0.0151,"surprise":0.0658,"sadness":0.0043,"fear":0.0181,"anger":0.0166,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a multi-agent system (MASSE) that automates structural engineering workflows, potentially reducing expert workload from two hours to minutes. While this automation could lead to more efficient use of materials and potentially reduce waste in construction, the article lacks concrete data on emissions reduction or material savings. It is currently in the proof-of-concept stage, limiting its deployment readiness.","key_impact_metrics":["expert workload reduction from 2 hours to minutes"],"technology_tags":["LLM","Multi-Agent System","Structural Engineering Automation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:45:48.433690Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4d7ac02f2a58","title":"Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation","content":"arXiv:2510.11005v1 Announce Type: new Abstract: Accurate segmentation of tumors and adjacent normal tissues in medical images is essential for surgical planning and tumor staging. Although foundation models generally perform well in segmentation tasks, they often struggle to focus on foreground areas in complex, low-contrast backgrounds, where some malignant tumors closely resemble normal organs, complicating contextual differentiation. To address these challenges, we propose the Foreground-Aware Spectrum Segmentation (FASS) framework. First, we introduce a foreground-aware module to amplify the distinction between background and the entire volume space, allowing the model to concentrate more effectively on target areas. Next, a feature-level frequency enhancement module, based on wavelet transform, extracts discriminative high-frequency features to enhance boundary recognition and detail perception. Eventually, we introduce an edge constraint module to preserve geometric continuity in segmentation boundaries. Extensive experiments on multiple medical datasets demonstrate superior performance across all metrics, validating the effectiveness of our framework, particularly in robustness under complex conditions and fine structure recognition. Our framework significantly enhances segmentation of low-contrast images, paving the way for applications in more diverse and complex medical imaging scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11005","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.854156","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Kai Han, Siqi Ma, Chengxuan Qian, Jun Chen, Chongwen Lyu, Yuqing Song, Zhe Liu","raw_content_length":1422,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["the Foreground-Aware Spectrum Segmentation"],"persons":[],"locations":[],"monetary":[]},"char_count":1421,"language_detected":"en","key_concepts":{"key_phrases":["Frequency Domain","New Perspectives","Abdominal Medical Image Segmentation","arXiv251011005v1 Announce Type","new Abstract","Accurate segmentation","tumors","normal tissues","medical images","surgical planning"],"filter_categories":{"ai_ml":["Frequency Domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Frequency Domain":2.0,"New Perspectives":2.0,"Abdominal Medical Image Segmentation":2.0,"arXiv251011005v1 Announce Type":1.0,"new Abstract":1.0,"Accurate segmentation":1.0,"tumors":1.0,"normal tissues":1.0,"medical images":1.0,"surgical planning":1.0}},"age_hours":2.7556574955555555,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9079,"joy":0.0091,"surprise":0.0245,"sadness":0.0089,"fear":0.0163,"anger":0.0135,"disgust":0.0198},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new medical image segmentation framework (FASS) that enhances the accuracy of tumor detection. While improved medical imaging can indirectly contribute to better healthcare outcomes, there is no direct or measurable impact on climate change, GHG emissions, or carbon sequestration. The technology is in the applied research stage, with experiments conducted on medical datasets, but no real-world deployment is mentioned.","key_impact_metrics":["Superior performance across all metrics"],"technology_tags":["Medical Image Segmentation","Wavelet Transform","Deep Learning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:45:51.579040Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b33e173cab7a","title":"GrASP: A Generalizable Address","content":"arXiv:2510.11011v1 Announce Type: new Abstract: Data prefetching--loading data into the cache before it is requested--is essential for reducing I/O overhead and improving database performance. While traditional prefetchers focus on sequential patterns, recent learning-based approaches, especially those leveraging data semantics, achieve higher accuracy for complex access patterns. However, these methods often struggle with today's dynamic, ever-growing datasets and require frequent, timely fine-tuning. Privacy constraints may also restrict access to complete datasets, necessitating prefetchers that can learn effectively from samples. To address these challenges, we present GrASP, a learning-based prefetcher designed for both analytical and transactional workloads. GrASP enhances prefetching accuracy and scalability by leveraging logical block address deltas and combining query representations with result encodings. It frames prefetching as a context-aware multi-label classification task, using multi-layer LSTMs to predict delta patterns from embedded context. This delta modeling approach enables GrASP to generalize predictions from small samples to larger, dynamic datasets without requiring extensive retraining. Experiments on real-world datasets and industrial benchmarks demonstrate that GrASP generalizes to datasets 250 times larger than the training data, achieving up to 45% higher hit ratios, 60% lower I/O time, and 55% lower end-to-end query execution latency than existing baselines. On average, GrASP attains a 91.4% hit ratio, a 90.8% I/O time reduction, and a 57.1% execution latency reduction.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11011","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.854953","language":"en","tags":["cslg","preprints","research","csdb","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Farzaneh Zirak, Farhana Choudhury, Renata Borovica-Gajic","raw_content_length":1628,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1627,"language_detected":"en","key_concepts":{"key_phrases":["GrASP","A Generalizable Address","arXiv251011011v1","Announce Type","new Abstract","Data prefetching","data","the cache","database performance","traditional prefetchers"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GrASP":2.0,"A Generalizable Address":2.0,"arXiv251011011v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Data prefetching":1.0,"data":1.0,"the cache":1.0,"database performance":1.0,"traditional prefetchers":1.0}},"age_hours":2.7556874019444444,"is_recent":true,"quality_score":0.7,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.94,"joy":0.0066,"surprise":0.0259,"sadness":0.0053,"fear":0.0064,"anger":0.011,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"GrASP improves data prefetching, leading to lower I/O time and query execution latency. Experiments show up to 45% higher hit ratios, 60% lower I/O time, and 55% lower end-to-end query execution latency. While promising, it is still in the applied research stage and lacks real-world deployment data.","key_impact_metrics":["I/O time reduction 90.8%","execution latency reduction 57.1%"],"technology_tags":["data prefetching","machine learning","database optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:45:56.664172Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be2802aa4f3d","title":"COCO","content":"arXiv:2510.11012v1 Announce Type: new Abstract: Compositional reasoning remains a persistent weakness of modern vision language models (VLMs): they often falter when a task hinges on understanding how multiple objects, attributes, and relations interact within an image. Multiple research works have attempted to improve compositionality performance by creative tricks such as improving prompt structure, chain of thought reasoning, etc. A more recent line of work attempts to impart additional reasoning in VLMs using well-trained Large Language Models (LLMs), which are far superior in linguistic understanding than VLMs to compensate for the limited linguistic prowess of VLMs. However, these approaches are either resource-intensive or do not provide an interpretable reasoning process. In this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs with carefully designed neurosymbolic concept trees learned from LLMs to improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning process boosts compositionality performance and provides a rationale behind VLM predictions. Empirical results on four compositionality benchmarks, Winoground, EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with varying sizes, demonstrate that COCO-Tree significantly improves compositional generalization by 5-10% over baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11012","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.855341","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Sanchit Sinha, Guangzhi Xiong, Aidong Zhang","raw_content_length":1382,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","COCO-Tree's","VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1381,"language_detected":"en","key_concepts":{"key_phrases":["COCO","arXiv251011012v1 Announce Type","new Abstract","Compositional reasoning","a persistent weakness","modern vision language models","VLMs","a task","how multiple objects","attributes"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"COCO":2.0,"arXiv251011012v1 Announce Type":1.0,"new Abstract":1.0,"Compositional reasoning":1.0,"a persistent weakness":1.0,"modern vision language models":1.0,"VLMs":1.0,"a task":1.0,"how multiple objects":1.0,"attributes":1.0}},"age_hours":2.755701708888889,"is_recent":true,"quality_score":0.7,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3033,"joy":0.0085,"surprise":0.0381,"sadness":0.0557,"fear":0.5274,"anger":0.0453,"disgust":0.0216},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (COCO-Tree) to improve the compositional reasoning of vision language models, demonstrating a 5-10% improvement on compositionality benchmarks. This is currently in the research phase, with no deployed technology or real-world data on energy or emissions impact. The vaporware flag is set because it is a prototype with no deployment.","key_impact_metrics":["compositional generalization improvement by 5-10%"],"technology_tags":["vision language models","neurosymbolic concept trees","large language models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:45:59.659874Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3789a4e6aff5","title":"Instruction","content":"arXiv:2510.11016v1 Announce Type: new Abstract: User representation modeling has become increasingly crucial for personalized applications, yet existing approaches struggle with generalizability across domains and sensitivity to noisy behavioral signals. We present InstructUE, an instruction-aware user embedding foundation model that leverages large language models (LLMs) to generate general and instruction-aware user representations. InstructUE introduces a multi-encoder architecture with a lightweight adapter that efficiently processes heterogeneous data from six different sources while preserving their structural characteristics. Additionally, it proposes a novel contrastive-autoregressive training framework that bridges language and representation spaces through a curated UserQA dataset. The contrastive-autoregressive training framework simultaneously leverages autoregressive learning to capture domain knowledge in language space and contrastive learning to align user-text embeddings in representation space, thereby enhancing the instruction-awareness and noise-robustness of user embeddings. Through extensive experiments on real-world applications, we demonstrate that InstructUE significantly outperforms existing methods across multiple domains including user prediction, marketing, and recommendation scenarios. Our results show that instruction-aware user modeling can effectively achieve instruction-guided denoising of user information in specific scenarios, paving the way for more generalizable and robust user representation learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11016","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.856296","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Ziyi Gao, Yike Xu, Jiahao Yuan, Baokun Wang, Jinyong Wen, Xiaotong Lin, Yun Liu, Xing Fu, Yu Cheng, Yongchao Liu, Weiqiang Wang, Zhongle Xie","raw_content_length":1566,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1565,"language_detected":"en","key_concepts":{"key_phrases":["Instruction","arXiv251011016v1 Announce Type","new Abstract","User representation modeling","personalized applications","existing approaches","generalizability","domains","sensitivity","noisy behavioral signals"],"filter_categories":{"ai_ml":["domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Instruction":2.0,"arXiv251011016v1 Announce Type":1.0,"new Abstract":1.0,"User representation modeling":1.0,"personalized applications":1.0,"existing approaches":1.0,"generalizability":1.0,"domains":1.0,"sensitivity":1.0,"noisy behavioral signals":1.0}},"age_hours":2.7557301297222225,"is_recent":true,"quality_score":0.7,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9018,"joy":0.0159,"surprise":0.0542,"sadness":0.0043,"fear":0.0104,"anger":0.0086,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel user embedding model (InstructUE) that aims to improve the generalizability and robustness of user representations. While the model shows promise in improving user prediction and recommendation scenarios, it is currently in the research phase with no concrete deployments or measured outcomes related to sustainability. The potential climate impact is indirect, relying on downstream applications that could potentially optimize resource use or reduce waste, but this is not explicitly quantified.","key_impact_metrics":["Outperforms existing methods across multiple domains","Instruction-guided denoising of user information"],"technology_tags":["User representation modeling","Large language models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:46:05.691515Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e41b571ddbac","title":"The Easy Path to Robustness: Coreset Selection using Sample Hardness","content":"arXiv:2510.11018v1 Announce Type: new Abstract: Designing adversarially robust models from a data-centric perspective requires understanding which input samples are most crucial for learning resilient features. While coreset selection provides a mechanism for efficient training on data subsets, current algorithms are designed for clean accuracy and fall short in preserving robustness. To address this, we propose a framework linking a sample's adversarial vulnerability to its \\textit{hardness}, which we quantify using the average input gradient norm (AIGN) over training. We demonstrate that \\textit{easy} samples (with low AIGN) are less vulnerable and occupy regions further from the decision boundary. Leveraging this insight, we present EasyCore, a coreset selection algorithm that retains only the samples with low AIGN for training. We empirically show that models trained on EasyCore-selected data achieve significantly higher adversarial accuracy than those trained with competing coreset methods under both standard and adversarial training. As AIGN is a model-agnostic dataset property, EasyCore is an efficient and widely applicable data-centric method for improving adversarial robustness. We show that EasyCore achieves up to 7\\% and 5\\% improvement in adversarial accuracy under standard training and TRADES adversarial training, respectively, compared to existing coreset methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11018","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.857146","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Pranav Ramesh, Arjun Roy, Deepak Ravikumar, Kaushik Roy, Gopalakrishnan Srinivasan","raw_content_length":1401,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1400,"language_detected":"en","key_concepts":{"key_phrases":["The Easy Path","Robustness","Coreset Selection","Sample Hardness","arXiv251011018v1 Announce Type","new Abstract","Designing","adversarially robust models","a data-centric perspective","understanding"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Easy Path":2.0,"Robustness":2.0,"Coreset Selection":2.0,"Sample Hardness":2.0,"arXiv251011018v1 Announce Type":1.0,"new Abstract":1.0,"Designing":1.0,"adversarially robust models":1.0,"a data-centric perspective":1.0,"understanding":1.0}},"age_hours":2.755760296111111,"is_recent":true,"quality_score":0.7,"sentiment_score":9.3445,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8689,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9486,"joy":0.0139,"surprise":0.0166,"sadness":0.0029,"fear":0.0042,"anger":0.0091,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel coreset selection algorithm (EasyCore) that improves adversarial robustness in machine learning models. It demonstrates a 7% and 5% improvement in adversarial accuracy under standard and TRADES adversarial training, respectively, compared to existing coreset methods. This is still in the applied research stage, with no indication of real-world deployment or economic viability.","key_impact_metrics":["7% improvement in adversarial accuracy under standard training","5% improvement in adversarial accuracy under TRADES adversarial training"],"technology_tags":["coreset selection","adversarial robustness","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:10.891424Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_36fabef90eeb","title":"Refinery: Active Fine-tuning and Deployment","content":"arXiv:2510.11019v1 Announce Type: new Abstract: Simulation-based learning has enabled policies for precise, contact-rich tasks (e.g., robotic assembly) to reach high success rates (~80%) under high levels of observation noise and control error. Although such performance may be sufficient for research applications, it falls short of industry standards and makes policy chaining exceptionally brittle. A key limitation is the high variance in individual policy performance across diverse initial conditions. We introduce Refinery, an effective framework that bridges this performance gap, robustifying policy performance across initial conditions. We propose Bayesian Optimization-guided fine-tuning to improve individual policies, and Gaussian Mixture Model-based sampling during deployment to select initializations that maximize execution success. Using Refinery, we improve mean success rates by 10.98% over state-of-the-art methods in simulation-based learning for robotic assembly, reaching 91.51% in simulation and comparable performance in the real world. Furthermore, we demonstrate that these fine-tuned policies can be chained to accomplish long-horizon, multi-part assembly$\\unicode{x2013}$successfully assembling up to 8 parts without requiring explicit multi-step training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11019","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.857556","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Bingjie Tang, Iretiayo Akinola, Jie Xu, Bowen Wen, Dieter Fox, Gaurav S. Sukhatme, Fabio Ramos, Abhishek Gupta, Yashraj Narang","raw_content_length":1288,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Refinery","Bayesian Optimization-guided"],"persons":["Gaussian Mixture Model"],"locations":[],"monetary":[]},"char_count":1287,"language_detected":"en","key_concepts":{"key_phrases":["Refinery","Active Fine-tuning","Deployment","arXiv251011019v1 Announce Type","new Abstract","Simulation-based learning","policies","contact-rich tasks","eg robotic assembly","high success rates"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Refinery":2.0,"Active Fine-tuning":2.0,"Deployment":2.0,"arXiv251011019v1 Announce Type":1.0,"new Abstract":1.0,"Simulation-based learning":1.0,"policies":1.0,"contact-rich tasks":1.0,"eg robotic assembly":1.0,"high success rates":1.0}},"age_hours":2.755775113055556,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.755,"joy":0.0069,"surprise":0.047,"sadness":0.0357,"fear":0.0747,"anger":0.0467,"disgust":0.034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a framework (Refinery) that improves the success rates of robotic assembly in simulation and real-world environments. While the technology shows promise with a 10.98% improvement in mean success rates, reaching 91.51% in simulation, it is still in the early stages of deployment and lacks concrete evidence of widespread adoption or significant impact on emissions. The vaporware flag is set because it's a prototype/early-stage concept without deployed units or customer contracts.","key_impact_metrics":["91.51% success rate in simulation","10.98% improvement in mean success rates"],"technology_tags":["robotic assembly","simulation-based learning","Bayesian Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:14.213899Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_66b5d43e9472","title":"GeoVLMath: Enhancing Geometry Reasoning in Vision","content":"arXiv:2510.11020v1 Announce Type: new Abstract: Auxiliary lines are essential for solving complex geometric problems but remain challenging for large vision-language models (LVLMs). Rather than editing diagrams to draw auxiliary lines, which current image editing models struggle to render with geometric precision, we generate textual descriptions of auxiliary-line constructions to better align with the representational strengths of LVLMs. To bridge the gap between textual descriptions and spatial structure, we propose a reinforcement learning framework that enhances diagram-text alignment. At the core of our approach is a cross-modal reward that evaluates how well the generated auxiliary-line description for an original diagram matches a ground-truth auxiliary-line diagram. Built on this reward, we present GeoVLMath, an open-source LVLM tailored to auxiliary-line reasoning in solid geometry. This fine-grained signal drives a GRPO-based RL stage, yielding precise diagram-text alignment. To support training, we develop a scalable data creation pipeline and construct AuxSolidMath, a dataset of 3,018 real-exam geometry problems with paired diagrams and aligned textual fields. At the 3B and 7B scales, GeoVLMath achieves competitive and often superior performance compared with strong open-source and proprietary LVLMs on auxiliary-line reasoning benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11020","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.857958","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Shasha Guo, Liang Pang, Xi Wang, Yanling Wang, Huawei Shen, Jing Zhang","raw_content_length":1373,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1372,"language_detected":"en","key_concepts":{"key_phrases":["Geometry Reasoning","Vision","LVLMs","textual descriptions","new Abstract","Auxiliary lines","complex geometric problems","large vision-language models","diagrams","auxiliary lines"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Geometry Reasoning":2.0,"Vision":2.0,"LVLMs":2.0,"textual descriptions":2.0,"new Abstract":1.0,"Auxiliary lines":1.0,"complex geometric problems":1.0,"large vision-language models":1.0,"diagrams":1.0,"auxiliary lines":1.0}},"age_hours":2.7557898527777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.763,"joy":0.0135,"surprise":0.0122,"sadness":0.0088,"fear":0.1226,"anger":0.0476,"disgust":0.0323},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new AI model (GeoVLMath) for geometry reasoning, which could potentially improve efficiency in various fields. However, the direct sustainability impact is minimal at this stage, as it's primarily focused on algorithm development and dataset creation (AuxSolidMath with 3,018 problems). It's currently in the applied research phase with no deployment or concrete impact metrics related to sustainability.","key_impact_metrics":["AuxSolidMath dataset size: 3,018"],"technology_tags":["AI","Machine Learning","Geometry Reasoning","Vision-Language Models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:46:18.986168Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0189ce3565b","title":"Parareal in time and spectral in space fast L1 quasilinear subdiffusion solver","content":"arXiv:2510.11023v1 Announce Type: new Abstract: We consider the initial-boundary value problem for a quasilinear time-fractional diffusion equation, and develop a fully discrete solver combining the parareal algorithm in time with a L1 finite-difference approximation of the Caputo derivative and a spectral Galerkin discretization in space. Our main contribution is the first rigorous convergence proof for the parareal-L1 scheme in this nonlinear subdiffusive setting. By constructing suitable energy norms and exploiting the orthogonality of the spectral basis, we establish that the parareal iterations converge exactly to the fully serial L1-spectral solution in a finite number of steps, with rates independent of the fractional exponent. The spectral spatial discretization yields exponential accuracy in space, while the parareal structure induces a clock speedup proportional to the number of processors, making the overall method highly efficient. Numerical experiments for both subdiffusive and classical diffusion problems confirm our theoretical estimates and demonstrate up to an order of magnitude reduction in computational time compared to the conventional sequential solver. We observe that the speedup of the parareal method increases linearly with the fine integrator degrees of freedom.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11023","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.858355","language":"en","tags":["computer-science","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Josefa Caballero, {\\L}ukasz P{\\l}ociniczak, Kishin Sadarangani","raw_content_length":1308,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Galerkin","Announce Type","Caputo"],"locations":[],"monetary":[]},"char_count":1307,"language_detected":"en","key_concepts":{"key_phrases":["time","space","Parareal","new Abstract","the initial-boundary value problem","a quasilinear time-fractional diffusion equation","a fully discrete solver","the parareal algorithm","a L1 finite-difference approximation","the Caputo derivative"],"filter_categories":{"ai_ml":["the parareal algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"time":3.0,"space":3.0,"Parareal":2.0,"new Abstract":1.0,"the initial-boundary value problem":1.0,"a quasilinear time-fractional diffusion equation":1.0,"a fully discrete solver":1.0,"the parareal algorithm":1.0,"a L1 finite-difference approximation":1.0,"the Caputo derivative":1.0}},"age_hours":2.7558048494444445,"is_recent":true,"quality_score":1.0,"sentiment_score":3.3,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.34,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7078,"joy":0.1548,"surprise":0.0993,"sadness":0.0066,"fear":0.0116,"anger":0.0162,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm for solving time-fractional diffusion equations, achieving up to an order of magnitude reduction in computational time compared to conventional solvers. This could potentially accelerate simulations in various fields, including climate modeling and materials science, but it is still in the research phase with no deployed applications. The convergence proof and numerical experiments provide evidence for the algorithm's efficiency.","key_impact_metrics":["order of magnitude reduction in computational time"],"technology_tags":["parareal algorithm","spectral Galerkin discretization","L1 finite-difference approximation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:23.461777Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b5560e545cca","title":"GIR","content":"arXiv:2510.11026v1 Announce Type: new Abstract: Unified multimodal models integrate the reasoning capacity of large language models with both image understanding and generation, showing great promise for advanced multimodal intelligence. However, the community still lacks a rigorous reasoning-centric benchmark to systematically evaluate the alignment between understanding and generation, and their generalization potential in complex visual tasks. To this end, we introduce \\textbf{GIR-Bench}, a comprehensive benchmark that evaluates unified models across three complementary perspectives. Firstly, we investigate understanding-generation consistency (GIR-Bench-UGC), asking whether models can consistently leverage the same knowledge in both understanding and generation tasks. Secondly, we investigate whether models can perform reasoning-centric text-to-image generation that requires applying logical constraints and implicit knowledge to generate faithful visual content (GIR-Bench-T2I). Thirdly, we evaluate whether models can handle multi-step reasoning in editing (GIR-Bench-Edit). For each subset, we carefully design different task-specific evaluation pipelines tailored for each task. This enables fine-grained and interpretable evaluation while mitigating biases from the prevalent MLLM-as-a-Judge paradigm. Extensive ablations over various unified models and generation-only systems have shown that: Although unified models are more capable of reasoning-driven visual tasks, they still exhibit a persistent gap between understanding and generation. The data and code for GIR-Bench are available at \\href{https://hkust-longgroup.github.io/GIR-Bench}{https://hkust-longgroup.github.io/GIR-Bench}.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11026","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.858788","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Hongxiang Li, Yaowei Li, Bin Lin, Yuwei Niu, Yuhang Yang, Xiaoshuang Huang, Jiayin Cai, Xiaolong Jiang, Yao Hu, Long Chen","raw_content_length":1712,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":["GIR"],"persons":[],"locations":[],"monetary":[]},"char_count":1711,"language_detected":"en","key_concepts":{"key_phrases":["GIR","generation","arXiv251011026v1 Announce Type","new Abstract","Unified multimodal models","the reasoning capacity","large language models","both image understanding","great promise","advanced multimodal intelligence"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GIR":2.0,"generation":2.0,"arXiv251011026v1 Announce Type":1.0,"new Abstract":1.0,"Unified multimodal models":1.0,"the reasoning capacity":1.0,"large language models":1.0,"both image understanding":1.0,"great promise":1.0,"advanced multimodal intelligence":1.0}},"age_hours":2.7558189250000003,"is_recent":true,"quality_score":0.7,"sentiment_score":9.5005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9001,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9181,"joy":0.0149,"surprise":0.0422,"sadness":0.0084,"fear":0.0045,"anger":0.0079,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (GIR-Bench) for evaluating the reasoning capabilities of multimodal AI models. While improved AI could indirectly contribute to sustainability by optimizing resource use or accelerating innovation, there is no concrete action or measurable outcome related to climate or environmental impact described in the article. The research is at a very early stage (basic research) with no deployment or real-world application.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Multimodal Models","Image Generation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:46:27.621363Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_af69d5647ee4","title":"Vlaser: Vision","content":"arXiv:2510.11027v1 Announce Type: new Abstract: While significant research has focused on developing embodied reasoning capabilities using Vision-Language Models (VLMs) or integrating advanced VLMs into Vision-Language-Action (VLA) models for end-to-end robot control, few studies directly address the critical gap between upstream VLM-based reasoning and downstream VLA policy learning. In this work, we take an initial step toward bridging embodied reasoning with VLA policy learning by introducing Vlaser - a Vision-Language-Action Model with synergistic embodied reasoning capability, which is a foundational vision-language model designed to integrate high-level reasoning with low-level control for embodied agents. Built upon the high-quality Vlaser-6M dataset, Vlaser achieves state-of-the-art performance across a range of embodied reasoning benchmarks - including spatial reasoning, embodied grounding, embodied QA, and task planning. Furthermore, we systematically examine how different VLM initializations affect supervised VLA fine-tuning, offering novel insights into mitigating the domain shift between internet-scale pre-training data and embodied-specific policy learning data. Based on these insights, our approach achieves state-of-the-art results on the WidowX benchmark and competitive performance on the Google Robot benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11027","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.859173","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Ganlin Yang, Tianyi Zhang, Haoran Hao, Weiyun Wang, Yibin Liu, Dehui Wang, Guanzhou Chen, Zijian Cai, Junting Chen, Weijie Su, Wengang Zhou, Yu Qiao, Jifeng Dai, Jiangmiao Pang, Gen Luo, Wenhai Wang, Yao Mu, Zhi Hou","raw_content_length":1350,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["VLM","Vlaser","Vlaser - a Vision-Language-Action Model","Vision-Language Models","Vision-Language-Action"],"persons":[],"locations":[],"monetary":[]},"char_count":1349,"language_detected":"en","key_concepts":{"key_phrases":["Vlaser","Vision","arXiv251011027v1 Announce Type","new Abstract","significant research","embodied reasoning capabilities","Vision-Language Models","VLMs","advanced VLMs","VLA"],"filter_categories":{"ai_ml":["Vision"],"research_academic":["significant research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vlaser":2.0,"Vision":2.0,"arXiv251011027v1 Announce Type":1.0,"new Abstract":1.0,"significant research":1.0,"embodied reasoning capabilities":1.0,"Vision-Language Models":1.0,"VLMs":1.0,"advanced VLMs":1.0,"VLA":1.0}},"age_hours":2.75583393,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8964,"joy":0.0182,"surprise":0.0315,"sadness":0.0062,"fear":0.0194,"anger":0.0181,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving embodied reasoning in robots, which could indirectly contribute to sustainability by enabling more efficient automation in various sectors. However, the article does not provide concrete actions or measurable outcomes related to environmental impact. The technology is still in the applied research phase, with no deployed units or operational data available.","key_impact_metrics":["State-of-the-art performance on WidowX benchmark","Competitive performance on Google Robot benchmark"],"technology_tags":["Vision-Language Models","Robotics","Embodied AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:31.065055Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b78cc241823b","title":"Enhancing Zero","content":"arXiv:2510.11028v1 Announce Type: new Abstract: Recently, the powerful generalization ability exhibited by foundation models has brought forth new solutions for zero-shot anomaly segmentation tasks. However, guiding these foundation models correctly to address downstream tasks remains a challenge. This paper proposes a novel two-stage framework, for zero-shot anomaly segmentation tasks in industrial anomaly detection. This framework excellently leverages the powerful anomaly localization capability of CLIP and the boundary perception ability of SAM.(1) To mitigate SAM's inclination towards object segmentation, we propose the Co-Feature Point Prompt Generation (PPG) module. This module collaboratively utilizes CLIP and SAM to generate positive and negative point prompts, guiding SAM to focus on segmenting anomalous regions rather than the entire object. (2) To further optimize SAM's segmentation results and mitigate rough boundaries and isolated noise, we introduce the Cascaded Prompts for SAM (CPS) module. This module employs hybrid prompts cascaded with a lightweight decoder of SAM, achieving precise segmentation of anomalous regions. Across multiple datasets, consistent experimental validation demonstrates that our approach achieves state-of-the-art zero-shot anomaly segmentation results. Particularly noteworthy is our performance on the Visa dataset, where we outperform the state-of-the-art methods by 10.3\\% and 7.7\\% in terms of {$F_1$-max} and AP metrics, respectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11028","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.859589","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Yanning Hou, Ke Xu, Junfa Li, Yanran Ruan, Jianfeng Qiu","raw_content_length":1499,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":["the Co-Feature Point Prompt Generation (PPG","SAM","CLIP"],"persons":["Enhancing Zero"],"locations":[],"monetary":[]},"char_count":1498,"language_detected":"en","key_concepts":{"key_phrases":["Zero","zero-shot anomaly segmentation tasks","arXiv251011028v1 Announce Type","new Abstract","the powerful generalization ability","foundation models","new solutions","these foundation models","downstream tasks","a challenge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Zero":2.0,"zero-shot anomaly segmentation tasks":2.0,"arXiv251011028v1 Announce Type":1.0,"new Abstract":1.0,"the powerful generalization ability":1.0,"foundation models":1.0,"new solutions":1.0,"these foundation models":1.0,"downstream tasks":1.0,"a challenge":1.0}},"age_hours":2.755847943888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.68,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.936,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9146,"joy":0.0272,"surprise":0.0335,"sadness":0.0033,"fear":0.0065,"anger":0.0114,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for zero-shot anomaly segmentation, showing improved performance on the Visa dataset. It is still in the applied research phase, with no evidence of deployment or economic viability. The potential climate impact is indirect, as it could improve industrial processes, but there are no quantified emissions reductions.","key_impact_metrics":["F1-max improvement of 10.3%","AP improvement of 7.7%"],"technology_tags":["Anomaly detection","Image segmentation","Machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:34.733259Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b801f0ca7a19","title":"LogiNumSynth: Synthesizing Joint Logical","content":"arXiv:2510.11031v1 Announce Type: new Abstract: Joint logical-numerical reasoning remains a major challenge for language models, yet existing datasets rely on fixed rule sets and offer limited control over task complexity, constraining their generalizability for evaluation and training. We present LogiNumSynth, a flexible natural language problem synthesizer that synthesizes tasks requiring proficiency in joint logical reasoning (e.g., rule-based reasoning) and numerical reasoning (e.g., arithmetic computation). LogiNumSynth supports fine-grained control over reasoning world richness, logical reasoning depth, and the complexity of numerical computations, enabling flexible data synthesis across difficulty levels. We demonstrate three key contributions: (1) Synthesizer -- synthesizing fully controllable joint reasoning tasks over natural language; (2) Evaluation & Process Analysis -- evaluating both process accuracy and answer accuracy; (3) Targeted Training -- using synthesized data to enhance LLMs' reasoning performance. Experiments with multiple LLMs highlight persistent weaknesses in logical-numerical reasoning, showing that LogiNumSynth can serve as both a diagnostic tool and a source of targeted supervision for advancing integrated reasoning skills.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11031","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.859978","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Yiwei Liu, Yucheng Li, Xiao Li, Gong Cheng","raw_content_length":1274,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1273,"language_detected":"en","key_concepts":{"key_phrases":["Joint Logical","arXiv251011031v1 Announce Type","new Abstract","Joint logical-numerical reasoning","a major challenge","language models","existing datasets","fixed rule sets","limited control","task complexity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Joint Logical":2.0,"arXiv251011031v1 Announce Type":1.0,"new Abstract":1.0,"Joint logical-numerical reasoning":1.0,"a major challenge":1.0,"language models":1.0,"existing datasets":1.0,"fixed rule sets":1.0,"limited control":1.0,"task complexity":1.0}},"age_hours":2.7558624586111113,"is_recent":true,"quality_score":1.0,"sentiment_score":5.505,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.101,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8934,"joy":0.0233,"surprise":0.0503,"sadness":0.0061,"fear":0.0107,"anger":0.0112,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel synthesizer for joint logical-numerical reasoning tasks. While it shows promise in enhancing LLMs' reasoning performance, it is currently in the basic research stage with no deployed technology or measured outcomes in a real-world setting. The potential climate impact is indirect, as improved AI reasoning could potentially contribute to sustainability solutions in the future, but this is highly speculative at this stage.","key_impact_metrics":["Process accuracy","Answer accuracy"],"technology_tags":["Natural Language Processing","Language Models","AI Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:46:38.623986Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c6c8d435ec9","title":"SusBench: An Online Benchmark for Evaluating Dark Pattern Susceptibility of Computer","content":"arXiv:2510.11035v1 Announce Type: new Abstract: As LLM-based computer-use agents (CUAs) begin to autonomously interact with real-world interfaces, understanding their vulnerability to manipulative interface designs becomes increasingly critical. We introduce SusBench, an online benchmark for evaluating the susceptibility of CUAs to UI dark patterns, designs that aim to manipulate or deceive users into taking unintentional actions. Drawing nine common dark pattern types from existing taxonomies, we developed a method for constructing believable dark patterns on real-world consumer websites through code injections, and designed 313 evaluation tasks across 55 websites. Our study with 29 participants showed that humans perceived our dark pattern injections to be highly realistic, with the vast majority of participants not noticing that these had been injected by the research team. We evaluated five state-of-the-art CUAs on the benchmark. We found that both human participants and agents are particularly susceptible to the dark patterns of Preselection, Trick Wording, and Hidden Information, while being resilient to other overt dark patterns. Our findings inform the development of more trustworthy CUAs, their use as potential human proxies in evaluating deceptive designs, and the regulation of an online environment increasingly navigated by autonomous agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11035","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.860364","language":"en","tags":["preprints","research","computer-science","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Longjie Guo, Chenjie Yuan, Mingyuan Zhong, Robert Wolfe, Ruican Zhong, Yue Xu, Bingbing Wen, Hua Shen, Lucy Lu Wang, Alexis Hiniker","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["SusBench"],"persons":["An Online Benchmark"],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["SusBench","An Online Benchmark","Evaluating Dark Pattern Susceptibility","Computer","CUAs","arXiv251011035v1 Announce Type","new Abstract","LLM-based computer-use agents","real-world interfaces","their vulnerability"],"filter_categories":{"ai_ml":["Computer"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SusBench":3.0,"An Online Benchmark":2.0,"Evaluating Dark Pattern Susceptibility":2.0,"Computer":2.0,"CUAs":2.0,"arXiv251011035v1 Announce Type":1.0,"new Abstract":1.0,"LLM-based computer-use agents":1.0,"real-world interfaces":1.0,"their vulnerability":1.0}},"age_hours":2.7558777775,"is_recent":true,"quality_score":1.0,"sentiment_score":1.452,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7096,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2867,"joy":0.0074,"surprise":0.0105,"sadness":0.0109,"fear":0.6186,"anger":0.0367,"disgust":0.0293},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on evaluating the susceptibility of AI agents to dark patterns on websites. While it doesn't directly impact climate change, it could indirectly contribute to sustainability by preventing manipulation that leads to unsustainable consumption patterns. The study includes metrics on human and AI agent susceptibility to different dark pattern types.","key_impact_metrics":["313 evaluation tasks","55 websites"],"technology_tags":["AI","Dark Patterns","User Interface"],"sdg_alignment":[12],"analyzed_at":"2025-10-29T11:46:42.242882Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f4f51bdb2f20","title":"XGrasp: Gripper","content":"arXiv:2510.11036v1 Announce Type: new Abstract: Most robotic grasping methods are typically designed for single gripper types, which limits their applicability in real-world scenarios requiring diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp detection framework that efficiently handles multiple gripper configurations. The proposed method addresses data scarcity by systematically augmenting existing datasets with multi-gripper annotations. XGrasp employs a hierarchical two-stage architecture. In the first stage, a Grasp Point Predictor (GPP) identifies optimal locations using global scene information and gripper specifications. In the second stage, an Angle-Width Predictor (AWP) refines the grasp angle and width using local features. Contrastive learning in the AWP module enables zero-shot generalization to unseen grippers by learning fundamental grasping characteristics. The modular framework integrates seamlessly with vision foundation models, providing pathways for future vision-language capabilities. The experimental results demonstrate competitive grasp success rates across various gripper types, while achieving substantial improvements in inference speed compared to existing gripper-aware methods. Project page: https://sites.google.com/view/xgrasp","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11036","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.860764","language":"en","tags":["computer-science","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Yeonseo Lee, Jungwook Mun, Hyosup Shin, Guebin Hwang, Junhee Nam, Taeyeop Lee, Sungho Jo","raw_content_length":1299,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Grasp Point Predictor","Angle-Width Predictor","vision foundation","AWP"],"persons":[],"locations":[],"monetary":[]},"char_count":1298,"language_detected":"en","key_concepts":{"key_phrases":["XGrasp","Gripper","arXiv251011036v1 Announce Type","new Abstract","Most robotic grasping methods","single gripper types","which","their applicability","real-world scenarios","diverse end-effectors"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"XGrasp":4.0,"Gripper":2.0,"arXiv251011036v1 Announce Type":1.0,"new Abstract":1.0,"Most robotic grasping methods":1.0,"single gripper types":1.0,"which":1.0,"their applicability":1.0,"real-world scenarios":1.0,"diverse end-effectors":1.0}},"age_hours":2.755892843888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9114,"joy":0.0087,"surprise":0.0388,"sadness":0.0051,"fear":0.0077,"anger":0.0177,"disgust":0.0105},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel robotic grasping framework (XGrasp). It mentions competitive grasp success rates and improvements in inference speed, but lacks information about real-world deployment or specific energy savings. The technology is still in the early stages of development, with no deployed units or customer contracts mentioned, hence the vaporware flag.","key_impact_metrics":["grasp success rates","inference speed"],"technology_tags":["robotics","grasping","computer vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:45.578585Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_881044f93b12","title":"RepoSummary: Feature","content":"arXiv:2510.11039v1 Announce Type: new Abstract: Repository summarization is a crucial research question in development and maintenance for software engineering. Existing repository summarization techniques primarily focus on summarizing code according to the directory tree, which is insufficient for tracing high-level features to the methods that collaboratively implement them. To address these limitations, we propose RepoSummary, a feature-oriented code repository summarization approach that simultaneously generates repository documentation automatically. Furthermore, it establishes more accurate traceability links from functional features to the corresponding code elements, enabling developers to rapidly locate relevant methods and files during code comprehension and maintenance. Comprehensive experiments against the state-of-the-art baseline (HGEN) demonstrate that RepoSummary achieves higher feature coverage and more accurate traceability. On average, it increases the rate of completely covered features in manual documentation from 61.2% to 71.1%, improves file-level traceability recall from 29.9% to 53.0%, and generates documentation that is more conceptually consistent, easier to understand, and better formatted than that produced by existing approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11039","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.861307","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Yifeng Zhu, Xianlin Zhao, Xutian Li, Yanzhen Zou, Haizhuo Yuan, Yue Wang, Bing Xie","raw_content_length":1281,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["RepoSummary","HGEN"],"persons":[],"locations":[],"monetary":[]},"char_count":1280,"language_detected":"en","key_concepts":{"key_phrases":["RepoSummary Feature","arXiv251011039v1 Announce Type","new Abstract","Repository summarization","a crucial research question","development","maintenance","software engineering","Existing repository summarization techniques","code"],"filter_categories":{"research_academic":["a crucial research question"],"engineering":["development","software engineering"],"ai_ml":["maintenance"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RepoSummary Feature":2.0,"arXiv251011039v1 Announce Type":1.0,"new Abstract":1.0,"Repository summarization":1.0,"a crucial research question":1.0,"development":1.0,"maintenance":1.0,"software engineering":1.0,"Existing repository summarization techniques":1.0,"code":1.0}},"age_hours":2.755906928888889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9101,"joy":0.0095,"surprise":0.0355,"sadness":0.0119,"fear":0.0121,"anger":0.0126,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new approach to repository summarization, RepoSummary, and compares it to an existing baseline. The concrete action is the development and testing of a new algorithm. The evidence supporting claims comes from experiments showing improvements in feature coverage and traceability, but it is still in the applied research phase with no deployment.","key_impact_metrics":["increases the rate of completely covered features in manual documentation from 61.2% to 71.1%","improves file-level traceability recall from 29.9% to 53.0%"],"technology_tags":["repository summarization","software engineering","code comprehension"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:46:48.967215Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_384dfd4ff103","title":"Enabling Doctor","content":"arXiv:2510.11040v1 Announce Type: new Abstract: The rise of large language models (LLMs) has transformed healthcare by offering clinical guidance, yet their direct deployment to patients poses safety risks due to limited domain expertise. To mitigate this, we propose repositioning LLMs as clinical assistants that collaborate with experienced physicians rather than interacting with patients directly. We conduct a two-stage inspiration-feedback survey to identify real-world needs in clinical workflows. Guided by this, we construct DoctorFLAN, a large-scale Chinese medical dataset comprising 92,000 Q&A instances across 22 clinical tasks and 27 specialties. To evaluate model performance in doctor-facing applications, we introduce DoctorFLAN-test (550 single-turn Q&A items) and DotaBench (74 multi-turn conversations). Experimental results with over ten popular LLMs demonstrate that DoctorFLAN notably improves the performance of open-source LLMs in medical contexts, facilitating their alignment with physician workflows and complementing existing patient-oriented models. This work contributes a valuable resource and framework for advancing doctor-centered medical LLM development","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11040","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.861754","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Wenya Xie, Qingying Xiao, Yu Zheng, Xidong Wang, Junying Chen, Ke Ji, Anningzhe Gao, Prayag Tiwari, Xiang Wan, Feng Jiang, Benyou Wang","raw_content_length":1199,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["Q&A","DotaBench"],"persons":[],"locations":[],"monetary":[]},"char_count":1190,"language_detected":"en","key_concepts":{"key_phrases":["Enabling Doctor","LLMs","patients","arXiv251011040v1","Announce Type","new Abstract","The rise","large language models","healthcare","clinical guidance"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Enabling Doctor":2.0,"LLMs":2.0,"patients":2.0,"arXiv251011040v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"The rise":1.0,"large language models":1.0,"healthcare":1.0,"clinical guidance":1.0}},"age_hours":2.755921973888889,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7789,"joy":0.0132,"surprise":0.014,"sadness":0.008,"fear":0.1485,"anger":0.0246,"disgust":0.0128},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a large-scale medical dataset (DoctorFLAN) for improving LLM performance in assisting doctors. The concrete action is the creation and testing of this dataset, with measurable outcomes being the improved performance of open-source LLMs on medical tasks. It is still in the applied research stage, with no actual deployment in clinical settings yet.","key_impact_metrics":["92,000 Q&A instances","550 single-turn Q&A items"],"technology_tags":["Large Language Models","Medical AI"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:46:51.979236Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0d3b90a04f2a","title":"Zephyrus: Scaling Gateways Beyond the Petabit-Era with DPU","content":"arXiv:2510.11043v1 Announce Type: new Abstract: Operating at petabit-scale, ByteDance's cloud gateways are deployed at critical aggregation points to orchestrate a wide array of business traffic. However, this massive scale imposes significant resource pressure on our previous-generation cloud gateways, rendering them unsustainable in the face of ever-growing cloud-network traffic. As the DPU market rapidly expands, we see a promising path to meet our escalating business traffic demands by integrating DPUs with our established Tofino-based gateways. DPUs augment these gateways with substantially larger table capacities and richer programmability without compromising previously low-latency and high-throughput forwarding. Despite compelling advantages, the practical integration of DPUs into cloud gateways remains unexplored, primarily due to underlying challenges. In this paper, we present Zephyrus, a production-scale gateway built upon a unified P4 pipeline spanning high-performance Tofino and feature-rich DPUs, which successfully overcomes these challenges. We further introduce a hierarchical co-offloading architecture (HLCO) to orchestrate traffic flow within this heterogeneous gateway, achieving > 99% hardware offloading while retaining software fallback paths for complex operations. Zephyrus outperforms LuoShen (NSDI '24) with 33% higher throughput and our evaluation further indicates 21% lower power consumption and 14% lower hardware cost. Against FPGA-based systems, Albatross (SIGCOMM '25), it doubles the throughput at a substantially lower Total Cost of Ownership (TCO), showcasing its superior performance-per-dollar. Beyond these performance gains, we also share key lessons from several years of developing and operating Zephyrus at production scale. We believe these insights provide valuable references for researchers and practitioners designing performant cloud gateways.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11043","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.862717","language":"en","tags":["preprints","csni","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":247,"author":"Yuemeng Xu, Haoran Chen, Jiarui Guo, Mingwei Cui, Qiuheng Yin, Cheng Dong, Daxiang Kang, Xian Wu, Chenmin Sun, Peng He, Yang Gao, Lirong Lai, Kai Wang, Hongyu Wu, Tong Yang, Xiyun Xu","raw_content_length":1911,"priority":7,"update_frequency":1,"reading_time_minutes":1.235,"robust_parsing_used":true,"entities":{"organizations":["ByteDance","DPU"],"persons":["Zephyrus"],"locations":[],"monetary":[]},"char_count":1910,"language_detected":"en","key_concepts":{"key_phrases":["Zephyrus","Gateways","the Petabit-Era","DPU","Announce Type","new Abstract","petabit-scale","ByteDances cloud gateways","critical aggregation points","a wide array"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Zephyrus":2.0,"Gateways":2.0,"the Petabit-Era":2.0,"DPU":2.0,"Announce Type":1.0,"new Abstract":1.0,"petabit-scale":1.0,"ByteDances cloud gateways":1.0,"critical aggregation points":1.0,"a wide array":1.0}},"age_hours":2.7559514819444444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6008,"joy":0.0152,"surprise":0.015,"sadness":0.0073,"fear":0.2544,"anger":0.0663,"disgust":0.0409},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"Zephyrus is a production-scale gateway that integrates DPUs with Tofino-based gateways, leading to 21% lower power consumption and 14% lower hardware cost compared to previous generation. It has been deployed at ByteDance's cloud gateways, showing real-world operational data and performance improvements. The paper has been peer-reviewed, adding to its credibility.","key_impact_metrics":["21% lower power consumption","14% lower hardware cost"],"technology_tags":["DPU","P4 pipeline","Cloud gateway"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:46:55.300352Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_14db878dabc9","title":"Benchmarking Deep Learning Models for Laryngeal Cancer Staging Using the LaryngealCT Dataset","content":"arXiv:2510.11047v1 Announce Type: new Abstract: Laryngeal cancer imaging research lacks standardised datasets to enable reproducible deep learning (DL) model development. We present LaryngealCT, a curated benchmark of 1,029 computed tomography (CT) scans aggregated from six collections from The Cancer Imaging Archive (TCIA). Uniform 1 mm isotropic volumes of interest encompassing the larynx were extracted using a weakly supervised parameter search framework validated by clinical experts. 3D DL architectures (3D CNN, ResNet18,50,101, DenseNet121) were benchmarked on (i) early (Tis,T1,T2) vs. advanced (T3,T4) and (ii) T4 vs. non-T4 classification tasks. 3D CNN (AUC-0.881, F1-macro-0.821) and ResNet18 (AUC-0.892, F1-macro-0.646) respectively outperformed the other models in the two tasks. Model explainability assessed using 3D GradCAMs with thyroid cartilage overlays revealed greater peri-cartilage attention in non-T4 cases and focal activations in T4 predictions. Through open-source data, pretrained models, and integrated explainability tools, LaryngealCT offers a reproducible foundation for AI-driven research to support clinical decisions in laryngeal oncology.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11047","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.863112","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Nivea Roy, Son Tran, Atul Sajjanhar, K. Devaraja, Prakashini Koteshwara, Yong Xiang, Divya Rao","raw_content_length":1179,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["ResNet18,50,101","the LaryngealCT Dataset arXiv:2510.11047v1 Announce Type: new Abstract","CNN","The Cancer Imaging Archive","AUC-0.892","Benchmarking Deep Learning Models for Laryngeal Cancer Staging Using"],"persons":["ResNet18"],"locations":[],"monetary":[]},"char_count":1178,"language_detected":"en","key_concepts":{"key_phrases":["Deep Learning Models","Laryngeal Cancer Staging","the LaryngealCT Dataset","arXiv251011047v1 Announce Type","new Abstract","Laryngeal cancer imaging research","standardised datasets","reproducible deep learning DL model development","a curated benchmark","1029 computed tomography"],"filter_categories":{"ai_ml":["Deep Learning Models","reproducible deep learning DL model development"],"research_academic":["Laryngeal cancer imaging research"],"engineering":["reproducible deep learning DL model development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deep Learning Models":2.0,"Laryngeal Cancer Staging":2.0,"the LaryngealCT Dataset":2.0,"arXiv251011047v1 Announce Type":1.0,"new Abstract":1.0,"Laryngeal cancer imaging research":1.0,"standardised datasets":1.0,"reproducible deep learning DL model development":1.0,"a curated benchmark":1.0,"1029 computed tomography":1.0}},"age_hours":2.7559673919444445,"is_recent":true,"quality_score":1.0,"sentiment_score":0.479,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9042,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8899,"joy":0.011,"surprise":0.0631,"sadness":0.0088,"fear":0.0076,"anger":0.0089,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a benchmark dataset and deep learning models for laryngeal cancer staging. While it doesn't directly address climate change, it improves medical diagnostics, potentially leading to more efficient healthcare resource allocation. The models are benchmarked with specific AUC and F1-macro scores, but are not yet deployed in a clinical setting.","key_impact_metrics":["AUC-0.881","F1-macro-0.821"],"technology_tags":["Deep Learning","Medical Imaging"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:46:58.516014Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aa66243cbb74","title":"Latent Refinement Decoding: Enhancing Diffusion","content":"arXiv:2510.11052v1 Announce Type: new Abstract: Autoregressive (AR) models remain the standard for natural language generation but still suffer from high latency due to strictly sequential decoding. Recent diffusion-inspired approaches, such as LlaDA and Dream, mitigate this by generating in parallel, yet they suffer from two core limitations: information loss, as predictive distributions for non-finalized tokens are discarded at each step, and premature commitment, where local decisions are made without sufficient global coordination. We introduce Latent Refinement Decoding (LRD), a two-stage framework with Latent Refinement and a Predictive Feedback Loop. The first stage maintains masked positions as distributional mixtures of predicted tokens and the mask embedding, allowing the model to establish more globally consistent beliefs. The second stage progressively finalizes confident tokens while retaining uncertain ones for iterative feedback. KL-divergence dynamics provide a principled and reliable criterion for convergence and early stopping. Experiments across coding (HumanEval +6.3, MBPP +2.6) and reasoning (GSM8K +2.9, MATH500 +3.8) show that LRD improves accuracy while delivering speedups of up to 10.6x, making it a strong and versatile alternative for parallel sequence generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11052","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.864299","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Qinglin Zhu, Yizhen Yao, Runcong Zhao, Yanzheng Xiang, Amrutha Saseendran, Chen Jin, Philip Alexander Teare, Bin Liang, Yulan He, Lin Gui","raw_content_length":1310,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["LRD","Latent Refinement"],"persons":[],"locations":[],"monetary":[]},"char_count":1309,"language_detected":"en","key_concepts":{"key_phrases":["Latent Refinement Decoding","Enhancing Diffusion","arXiv251011052v1 Announce Type","new Abstract","Autoregressive AR models","the standard","natural language generation","high latency","strictly sequential decoding","Recent diffusion-inspired approaches"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Latent Refinement Decoding":2.0,"Enhancing Diffusion":2.0,"arXiv251011052v1 Announce Type":1.0,"new Abstract":1.0,"Autoregressive AR models":1.0,"the standard":1.0,"natural language generation":1.0,"high latency":1.0,"strictly sequential decoding":1.0,"Recent diffusion-inspired approaches":1.0}},"age_hours":2.7560115838888892,"is_recent":true,"quality_score":1.0,"sentiment_score":0.38449999999999984,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9231,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8405,"joy":0.0036,"surprise":0.0306,"sadness":0.0594,"fear":0.0118,"anger":0.0197,"disgust":0.0344},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (LRD) that improves the speed and accuracy of parallel sequence generation. While it shows speedups of up to 10.6x and accuracy improvements on coding and reasoning tasks, it's currently in the research phase with no deployed applications or quantifiable environmental impact. The potential climate impact is indirect, relying on future applications of faster and more efficient AI.","key_impact_metrics":["speedups of up to 10.6x","HumanEval +6.3"],"technology_tags":["Latent Refinement Decoding","Parallel Sequence Generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:01.499547Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d82dab70e5cc","title":"From Reasoning LLMs to BERT: A Two","content":"arXiv:2510.11056v1 Announce Type: new Abstract: Query-service relevance prediction in e-commerce search systems faces strict latency requirements that prevent the direct application of Large Language Models (LLMs). To bridge this gap, we propose a two-stage reasoning distillation framework to transfer reasoning capabilities from a powerful teacher LLM to a lightweight, deployment-friendly student model. In the first stage, we address the limitations of general-purpose LLMs by constructing a domain-adapted teacher model. This is achieved through a three-step process: domain-adaptive pre-training to inject platform knowledge, supervised fine-tuning to elicit reasoning skills, and preference optimization with a multi-dimensional reward model to ensure the generation of reliable and preference-aligned reasoning paths. This teacher can then automatically annotate massive query-service pairs from search logs with both relevance labels and reasoning chains. In the second stage, to address the challenges of architectural heterogeneity in standard distillation, we introduce Contrastive Reasoning Self-Distillation (CRSD). By modeling the behavior of the same student model under \"standard\" and \"reasoning-augmented\" inputs as a teacher-student relationship, CRSD enables the lightweight model to internalize the teacher's complex decision-making mechanisms without needing the explicit reasoning path at inference. Offline evaluations and online A/B testing in the Meituan search advertising system demonstrate that our framework achieves significant improvements across multiple metrics, validating its effectiveness and practical value.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11056","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.864731","language":"en","tags":["computer-science","csai","preprints","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Runze Xia, Yupeng Ji, Yuxi Zhou, Haodong Liu, Teng Zhang, Piji Li","raw_content_length":1647,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","BERT","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1646,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning LLMs","BERT","arXiv251011056v1 Announce Type","new Abstract","Query-service relevance prediction","e-commerce search systems","strict latency requirements","the direct application","Large Language Models","LLMs"],"filter_categories":{"ai_ml":["Reasoning LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning LLMs":2.0,"BERT":2.0,"arXiv251011056v1 Announce Type":1.0,"new Abstract":1.0,"Query-service relevance prediction":1.0,"e-commerce search systems":1.0,"strict latency requirements":1.0,"the direct application":1.0,"Large Language Models":1.0,"LLMs":1.0}},"age_hours":2.7560271419444446,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9406,"joy":0.0108,"surprise":0.0241,"sadness":0.0041,"fear":0.0083,"anger":0.0084,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AI system within Meituan's search advertising, demonstrating improvements through A/B testing. This indicates a commercial-stage deployment with measured outcomes. The system aims to improve the efficiency of e-commerce search, which could indirectly reduce energy consumption associated with inefficient searches.","key_impact_metrics":["Significant improvements across multiple metrics"],"technology_tags":["AI","Machine Learning","Distillation","E-commerce Search"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:47:04.705128Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2bcb944179ed","title":"Robust Photoplethysmography Signal Denoising via Mamba Networks","content":"arXiv:2510.11058v1 Announce Type: new Abstract: Photoplethysmography (PPG) is widely used in wearable health monitoring, but its reliability is often degraded by noise and motion artifacts, limiting downstream applications such as heart rate (HR) estimation. This paper presents a deep learning framework for PPG denoising with an emphasis on preserving physiological information. In this framework, we propose DPNet, a Mamba-based denoising backbone designed for effective temporal modeling. To further enhance denoising performance, the framework also incorporates a scale-invariant signal-to-distortion ratio (SI-SDR) loss to promote waveform fidelity and an auxiliary HR predictor (HRP) that provides physiological consistency through HR-based supervision. Experiments on the BIDMC dataset show that our method achieves strong robustness against both synthetic noise and real-world motion artifacts, outperforming conventional filtering and existing neural models. Our method can effectively restore PPG signals while maintaining HR accuracy, highlighting the complementary roles of SI-SDR loss and HR-guided supervision. These results demonstrate the potential of our approach for practical deployment in wearable healthcare systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11058","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.865528","language":"en","tags":["cslg","eesssp","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"I Chiu, Yu-Tung Liu, Kuan-Chen Wang, Hung-Yu Wei, Yu Tsao","raw_content_length":1239,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Robust Photoplethysmography Signal","SI-SDR","Mamba Networks","PPG","DPNet","Mamba","BIDMC"],"persons":[],"locations":[],"monetary":[]},"char_count":1238,"language_detected":"en","key_concepts":{"key_phrases":["Mamba Networks","PPG","arXiv251011058v1 Announce Type","new Abstract","Photoplethysmography","wearable health monitoring","its reliability","noise and motion artifacts","downstream applications","heart rate HR estimation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mamba Networks":2.0,"PPG":2.0,"arXiv251011058v1 Announce Type":1.0,"new Abstract":1.0,"Photoplethysmography":1.0,"wearable health monitoring":1.0,"its reliability":1.0,"noise and motion artifacts":1.0,"downstream applications":1.0,"heart rate HR estimation":1.0}},"age_hours":2.756057136388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8619,"joy":0.0092,"surprise":0.0334,"sadness":0.02,"fear":0.0131,"anger":0.0251,"disgust":0.0373},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a deep learning framework for PPG denoising, showing improved performance on the BIDMC dataset. The concrete action is the development and testing of a new algorithm. The evidence is the reported outperformance of existing methods, but deployment is still at the research stage.","key_impact_metrics":["HR accuracy","SI-SDR"],"technology_tags":["deep learning","PPG denoising","Mamba networks"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:47:07.392513Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e7d6b5ffa3ff","title":"Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs","content":"arXiv:2510.11059v1 Announce Type: new Abstract: Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++. To address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance. Using Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11059","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.865937","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Jian Wang, Xiaofei Xie, Qiang Hu, Shangqing Liu, Jiongchi Yu, Jiaolong Klong, Yi Li","raw_content_length":1461,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Automated Program Repair","APR","C/C++","Defects4J"],"persons":["Java","C++ Bugs","Defects4C"],"locations":[],"monetary":[]},"char_count":1456,"language_detected":"en","key_concepts":{"key_phrases":["Defects4C","Large Language Model Repair Capability","CC Bugs","Announce Type","new Abstract","Automated Program Repair","APR","a critical role","the quality","reliability"],"filter_categories":{"ai_ml":["Large Language Model Repair Capability"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Defects4C":2.0,"Large Language Model Repair Capability":2.0,"CC Bugs":2.0,"Announce Type":1.0,"new Abstract":1.0,"Automated Program Repair":1.0,"APR":1.0,"a critical role":1.0,"the quality":1.0,"reliability":1.0}},"age_hours":2.7560740752777777,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9461,"joy":0.0061,"surprise":0.0175,"sadness":0.0097,"fear":0.004,"anger":0.0085,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (Defects4C) to evaluate and improve automated program repair (APR) using LLMs for C/C++ code. While APR can indirectly contribute to sustainability by improving software reliability and reducing resource consumption from bugs, the direct climate impact is theoretical at this stage. The technical credibility is high due to the empirical study and benchmark creation, but deployment readiness is low as it's still in the research phase.","key_impact_metrics":["9M bug-relevant commits","248 high-quality buggy functions"],"technology_tags":["Automated Program Repair","Large Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:10.275584Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_92c55d2bc606","title":"Stronger Together: On","content":"arXiv:2510.11062v1 Announce Type: new Abstract: Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to enhance the agentic capabilities of large language models (LLMs). MAS improves task performance through role-based orchestration, while RL uses environmental rewards to learn stronger policies, such as GRPO-style optimization. However, applying on-policy RL to MAS remains underexplored and presents unique challenges. Algorithmically, standard GRPO grouping assumptions break down because prompts vary by role and by turn. System-wise, the training stack must support MAS-workflow rollouts and on-policy updates for both single-policy and multi-policy models. We propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL algorithm tailored to MAS and (ii) a training system that supports both single- and multi-policy regimes. Across game, planning, coding, and math tasks, AT-GRPO delivers substantial gains. On long-horizon planning, it increases accuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5 percent. It also improves reasoning performance, with average gains of 3.87 to 7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and environments are available at: https://github.com/pettingllms-ai/PettingLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11062","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.866898","language":"en","tags":["cslg","csma","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Yujie Zhao, Lanxiang Hu, Yang Wang, Minmin Hou, Hao Zhang, Ke Ding, Jishen Zhao","raw_content_length":1297,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["MAS","GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1294,"language_detected":"en","key_concepts":{"key_phrases":["MAS","Announce Type","new Abstract","Multi-agent systems","reinforcement learning","the agentic capabilities","large language models","LLMs","task performance","role-based orchestration"],"filter_categories":{"ai_ml":["reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MAS":3.0,"Announce Type":1.0,"new Abstract":1.0,"Multi-agent systems":1.0,"reinforcement learning":1.0,"the agentic capabilities":1.0,"large language models":1.0,"LLMs":1.0,"task performance":1.0,"role-based orchestration":1.0}},"age_hours":2.756090487777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.593,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9186,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8876,"joy":0.0601,"surprise":0.0307,"sadness":0.0071,"fear":0.0044,"anger":0.0066,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (AT-GRPO) for multi-agent reinforcement learning that improves performance on game, planning, coding, and math tasks. The concrete action is the development and testing of this algorithm. The evidence supporting claims are the performance gains reported on various tasks, such as an increase in accuracy from 14.0-47.0% to 96.0-99.5% on long-horizon planning. However, it is still in the applied research stage with no real-world deployment yet, hence the low scores in deployment readiness and economic viability.","key_impact_metrics":["accuracy increase on long-horizon planning from 14.0-47.0% to 96.0-99.5%","average gains of 3.87-7.62% on coding tasks"],"technology_tags":["multi-agent systems","reinforcement learning","large language models"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:47:14.409177Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_702abb56d773","title":"LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation","content":"arXiv:2510.11063v1 Announce Type: new Abstract: This report presents an overview of the 7th Large-scale Video Object Segmentation (LSVOS) Challenge held in conjunction with ICCV 2025. Besides the two traditional tracks of LSVOS that jointly target robustness in realistic video scenarios: Classic VOS (VOS), and Referring VOS (RVOS), the 2025 edition features a newly introduced track, Complex VOS (MOSEv2). Building upon prior insights, MOSEv2 substantially increases difficulty, introducing more challenging but realistic scenarios including denser small objects, frequent disappear/reappear events, severe occlusions, adverse weather and lighting, etc., pushing long-term consistency and generalization beyond curated benchmarks. The challenge retains standard ${J}$, $F$, and ${J\\&F}$ metrics for VOS and RVOS, while MOSEv2 adopts ${J\\&\\dot{F}}$ as the primary ranking metric to better evaluate objects across scales and disappearance cases. We summarize datasets and protocols, highlight top-performing solutions, and distill emerging trends, such as the growing role of LLM/MLLM components and memory-aware propagation, aiming to chart future directions for resilient, language-aware video segmentation in the wild.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11063","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.867330","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Chang Liu, Henghui Ding, Kaining Ying, Lingyi Hong, Ning Xu, Linjie Yang, Yuchen Fan, Mingqi Gao, Jingkun Chen, Yunqi Miao, Gengshen Wu, Zhijin Qin, Jungong Han, Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Chang Soo Lim, Joonyoung Moon, Donghyeon Cho, Tingmin Li, Yixuan Li, Yang Yang, An Yan, Leilei Cao, Feng Lu, Ran Hong, Youhai Jiang, Fengjie Zhu, Yujie Xie, Hongyang Zhang, Zhihui Liu, Shihai Ruan, Quanzhu Niu, Dengxian Gong, Shihao Chen, Tao Zhang, Yikang Zhou, Haobo Yuan, Lu Qi, Xiangtai Li, Shunping Ji, Ran Hong, Feng Lu, Leilei Cao, An Yan, Alexey Nekrasov, Ali Athar, Daan de Geus, Alexander Hermans, Bastian Leibe","raw_content_length":1226,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["MOSEv2","Complex Video Object Segmentation arXiv:2510.11063v1","RVOS","Video Object Segmentation","VOS"],"persons":[],"locations":[],"monetary":[]},"char_count":1221,"language_detected":"en","key_concepts":{"key_phrases":["LSVOS 2025 Challenge Report","Recent Advances","Complex Video Object Segmentation","LSVOS","MOSEv2","arXiv251011063v1 Announce Type","new Abstract","This report","an overview","conjunction"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LSVOS 2025 Challenge Report":2.0,"Recent Advances":2.0,"Complex Video Object Segmentation":2.0,"LSVOS":2.0,"MOSEv2":2.0,"arXiv251011063v1 Announce Type":1.0,"new Abstract":1.0,"This report":1.0,"an overview":1.0,"conjunction":1.0}},"age_hours":2.756106763611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7869,"joy":0.081,"surprise":0.1093,"sadness":0.0055,"fear":0.0052,"anger":0.0094,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a video object segmentation challenge and new datasets. While improved video segmentation could potentially contribute to sustainability by enabling better monitoring of environmental changes or optimizing resource use, the article itself doesn't present any concrete actions or measurable outcomes related to sustainability. It is primarily focused on advancing the technical capabilities of video segmentation algorithms.","key_impact_metrics":["J metric","F metric"],"technology_tags":["video object segmentation","computer vision","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:17.619162Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3bc857ae976e","title":"Detecting Gender Stereotypes in Scratch Programming Tutorials","content":"arXiv:2510.11064v1 Announce Type: new Abstract: Gender stereotypes in introductory programming courses often go unnoticed, yet they can negatively influence young learners' interest and learning, particularly under-represented groups such as girls. Popular tutorials on block-based programming with Scratch may unintentionally reinforce biases through character choices, narrative framing, or activity types. Educators currently lack support in identifying and addressing such bias. With large language models~(LLMs) increasingly used to generate teaching materials, this problem is potentially exacerbated by LLMs trained on biased datasets. However, LLMs also offer an opportunity to address this issue. In this paper, we explore the use of LLMs for automatically identifying gender-stereotypical elements in Scratch tutorials, thus offering feedback on how to improve teaching content. We develop a framework for assessing gender bias considering characters, content, instructions, and programming concepts. Analogous to how code analysis tools provide feedback on code in terms of code smells, we operationalise this framework using an automated tool chain that identifies *gender stereotype smells*. Evaluation on 73 popular Scratch tutorials from leading educational platforms demonstrates that stereotype smells are common in practice. LLMs are not effective at detecting them, but our gender bias evaluation framework can guide LLMs in generating tutorials with fewer stereotype smells.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11064","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.867781","language":"en","tags":["cscy","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Isabella Gra{\\ss}l, Benedikt Fein, Gordon Fraser","raw_content_length":1495,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Scratch","Scratch Programming Tutorials arXiv:2510.11064v1 Announce Type"],"persons":["Gender Stereotypes"],"locations":[],"monetary":[]},"char_count":1494,"language_detected":"en","key_concepts":{"key_phrases":["Gender Stereotypes","Scratch Programming Tutorials","arXiv251011064v1 Announce Type","new Abstract","Gender stereotypes","introductory programming courses","young learners interest","learning","particularly under-represented groups","girls"],"filter_categories":{"engineering":["Scratch Programming Tutorials","introductory programming courses"],"ai_ml":["learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gender Stereotypes":2.0,"Scratch Programming Tutorials":2.0,"arXiv251011064v1 Announce Type":1.0,"new Abstract":1.0,"Gender stereotypes":1.0,"introductory programming courses":1.0,"young learners interest":1.0,"learning":1.0,"particularly under-represented groups":1.0,"girls":1.0}},"age_hours":2.756121366111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5835,"joy":0.0058,"surprise":0.0334,"sadness":0.0622,"fear":0.0426,"anger":0.0618,"disgust":0.2107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on identifying and mitigating gender stereotypes in educational programming materials using LLMs. While it doesn't directly impact climate change, it addresses equity in STEM education, which can indirectly contribute to a more diverse and inclusive workforce tackling climate challenges. The study evaluates its framework on 73 Scratch tutorials, demonstrating a pilot-level application.","key_impact_metrics":["Stereotype smells identified in 73 tutorials"],"technology_tags":["LLM","Gender Bias Detection","Educational Software"],"sdg_alignment":[4,5,10],"analyzed_at":"2025-10-29T11:47:21.319607Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_753f89fa3594","title":"Decoupled Multimodal Fusion for User Interest Modeling in Click","content":"arXiv:2510.11066v1 Announce Type: new Abstract: Modern industrial recommendation systems improve recommendation performance by integrating multimodal representations from pre-trained models into ID-based Click-Through Rate (CTR) prediction frameworks. However, existing approaches typically adopt modality-centric modeling strategies that process ID-based and multimodal embeddings independently, failing to capture fine-grained interactions between content semantics and behavioral signals. In this paper, we propose Decoupled Multimodal Fusion (DMF), which introduces a modality-enriched modeling strategy to enable fine-grained interactions between ID-based collaborative representations and multimodal representations for user interest modeling. Specifically, we construct target-aware features to bridge the semantic gap across different embedding spaces and leverage them as side information to enhance the effectiveness of user interest modeling. Furthermore, we design an inference-optimized attention mechanism that decouples the computation of target-aware features and ID-based embeddings before the attention layer, thereby alleviating the computational bottleneck introduced by incorporating target-aware features. To achieve comprehensive multimodal integration, DMF combines user interest representations learned under the modality-centric and modality-enriched modeling strategies. Offline experiments on public and industrial datasets demonstrate the effectiveness of DMF. Moreover, DMF has been deployed on the product recommendation system of the international e-commerce platform Lazada, achieving relative improvements of 5.30% in CTCVR and 7.43% in GMV with negligible computational overhead.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11066","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.868597","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Alin Fan, Hanqing Li, Sihan Lu, Jingsong Yuan, Jiandong Zhang","raw_content_length":1715,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["Click-Through Rate","CTR","Decoupled Multimodal Fusion","DMF"],"persons":[],"locations":[],"monetary":[]},"char_count":1714,"language_detected":"en","key_concepts":{"key_phrases":["Multimodal Fusion","User Interest Modeling","Click","arXiv251011066v1 Announce Type","new Abstract","Modern industrial recommendation systems","recommendation performance","multimodal representations","pre-trained models","CTR"],"filter_categories":{"ai_ml":["pre-trained models"],"hydrogen_energy":["CTR"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multimodal Fusion":2.0,"User Interest Modeling":2.0,"Click":2.0,"arXiv251011066v1 Announce Type":1.0,"new Abstract":1.0,"Modern industrial recommendation systems":1.0,"recommendation performance":1.0,"multimodal representations":1.0,"pre-trained models":1.0,"CTR":1.0}},"age_hours":2.7561491386111108,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8846,"joy":0.0046,"surprise":0.0352,"sadness":0.0218,"fear":0.0107,"anger":0.0247,"disgust":0.0182},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes the deployment of a new algorithm (DMF) on Lazada's e-commerce platform. The algorithm achieved a 5.30% relative improvement in CTCVR and a 7.43% relative improvement in GMV. While the impact on climate is indirect (potentially reducing resource waste by improving recommendation accuracy), the deployment and measurable outcomes provide a basis for scoring.","key_impact_metrics":["CTCVR improvement 5.30%","GMV improvement 7.43%"],"technology_tags":["Recommendation Systems","Machine Learning","E-commerce Optimization"],"sdg_alignment":[12],"analyzed_at":"2025-10-29T11:47:24.151011Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8991ac71357f","title":"Efficient Edge Test","content":"arXiv:2510.11068v1 Announce Type: new Abstract: Edge devices face significant challenges due to limited computational resources and distribution shifts, making efficient and adaptable machine learning essential. Existing test-time adaptation (TTA) methods often rely on gradient-based optimization or batch processing, which are inherently unsuitable for resource-constrained edge scenarios due to their reliance on backpropagation and high computational demands. Gradient-free alternatives address these issues but often suffer from limited learning capacity, lack flexibility, or impose architectural constraints. To overcome these limitations, we propose a novel single-instance TTA method tailored for edge devices (TED), which employs forward-only coordinate optimization in the principal subspace of latent using the covariance matrix adaptation evolution strategy (CMA-ES). By updating a compact low-dimensional vector, TED not only enhances output confidence but also aligns the latent representation closer to the source latent distribution within the latent principal subspace. This is achieved without backpropagation, keeping the model parameters frozen, and enabling efficient, forgetting-free adaptation with minimal memory and computational overhead. Experiments on image classification and keyword spotting tasks across the ImageNet and Google Speech Commands series datasets demonstrate that TED achieves state-of-the-art performance while $\\textit{reducing computational complexity by up to 63 times}$, offering a practical and scalable solution for real-world edge applications. Furthermore, we successfully $\\textit{deployed TED on the ZYNQ-7020 platform}$, demonstrating its feasibility and effectiveness for resource-constrained edge devices in real-world deployments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11068","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.869023","language":"en","tags":["eessiv","cslg","eessas","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Xinyu Luo, Jie Liu, Kecheng Chen, Junyi Yang, Bo Ding, Arindam Basu, Haoliang Li","raw_content_length":1791,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["CMA-ES","TED"],"persons":[],"locations":[],"monetary":[]},"char_count":1790,"language_detected":"en","key_concepts":{"key_phrases":["Efficient Edge Test","arXiv251011068v1 Announce Type","new Abstract","Edge devices","significant challenges","limited computational resources","distribution shifts","efficient and adaptable machine","Existing test-time adaptation","TTA methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Efficient Edge Test":2.0,"arXiv251011068v1 Announce Type":1.0,"new Abstract":1.0,"Edge devices":1.0,"significant challenges":1.0,"limited computational resources":1.0,"distribution shifts":1.0,"efficient and adaptable machine":1.0,"Existing test-time adaptation":1.0,"TTA methods":1.0}},"age_hours":2.7561635244444447,"is_recent":true,"quality_score":1.0,"sentiment_score":9.063,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8126,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5409,"joy":0.0047,"surprise":0.0113,"sadness":0.018,"fear":0.35,"anger":0.0419,"disgust":0.0332},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a novel method (TED) for efficient machine learning on edge devices, specifically deployed on the ZYNQ-7020 platform. It demonstrates a reduction in computational complexity by up to 63 times, suggesting potential energy savings. The research is presented as a pre-print, indicating peer review is likely underway, enhancing credibility.","key_impact_metrics":["computational complexity reduction by up to 63 times"],"technology_tags":["edge computing","machine learning","test-time adaptation","coordinate optimization"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:47:26.796636Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3b9fe56fc8c7","title":"PhysHSI: Towards a Real","content":"arXiv:2510.11072v1 Announce Type: new Abstract: Deploying humanoid robots to interact with real-world environments--such as carrying objects or sitting on chairs--requires generalizable, lifelike motions and robust scene perception. Although prior approaches have advanced each capability individually, combining them in a unified system is still an ongoing challenge. In this work, we present a physical-world humanoid-scene interaction system, PhysHSI, that enables humanoids to autonomously perform diverse interaction tasks while maintaining natural and lifelike behaviors. PhysHSI comprises a simulation training pipeline and a real-world deployment system. In simulation, we adopt adversarial motion prior-based policy learning to imitate natural humanoid-scene interaction data across diverse scenarios, achieving both generalization and lifelike behaviors. For real-world deployment, we introduce a coarse-to-fine object localization module that combines LiDAR and camera inputs to provide continuous and robust scene perception. We validate PhysHSI on four representative interactive tasks--box carrying, sitting, lying, and standing up--in both simulation and real-world settings, demonstrating consistently high success rates, strong generalization across diverse task goals, and natural motion patterns.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11072","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.869431","language":"en","tags":["cslg","eesssy","csai","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Huayi Wang, Wentao Zhang, Runyi Yu, Tao Huang, Junli Ren, Feiyu Jia, Zirui Wang, Xiaojie Niu, Xiao Chen, Jiahe Chen, Qifeng Chen, Jingbo Wang, Jiangmiao Pang","raw_content_length":1316,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1315,"language_detected":"en","key_concepts":{"key_phrases":["PhysHSI","Announce Type","new Abstract","humanoid robots","real-world environments","objects","chairs","generalizable lifelike motions","robust scene perception","prior approaches"],"filter_categories":{"ai_ml":["chairs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PhysHSI":3.0,"Announce Type":1.0,"new Abstract":1.0,"humanoid robots":1.0,"real-world environments":1.0,"objects":1.0,"chairs":1.0,"generalizable lifelike motions":1.0,"robust scene perception":1.0,"prior approaches":1.0}},"age_hours":2.756178304444444,"is_recent":true,"quality_score":0.7,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9295,"joy":0.0165,"surprise":0.0287,"sadness":0.003,"fear":0.006,"anger":0.0076,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a humanoid robot system, PhysHSI, capable of performing interactive tasks in real-world environments. While the system demonstrates high success rates in simulation and real-world settings for tasks like box carrying and sitting, the climate impact is minimal and indirect. The system is in the early stages of deployment, and economic viability is not addressed.","key_impact_metrics":["high success rates in interactive tasks"],"technology_tags":["humanoid robots","LiDAR","camera vision","motion planning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:29.654845Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4338c75395fd","title":"DebugTA: An LLM","content":"arXiv:2510.11076v1 Announce Type: new Abstract: In programming education, Debugging and Teaching (DT) task is a common scenario where students receive assistance in correcting their erroneous code. The task involves multiple inputs, including erroneous code, error messages, reference solutions, and the question description, with the goal of generating modification suggestions to the erroneous code. However, two key challenges hinder the effectiveness of existing approaches. Firstly, the complexity and heterogeneity of inputs inherent in DT tasks significantly elevate the reasoning challenges faced by LLMs. Second, existing approaches often fail to fully leverage the availability of standard code in DT tasks, forcing models to rely solely on complex multi-step reasoning, which limits the potential of LLMs in addressing DT tasks effectively. To address these challenges, we propose DebugTA, a novel LLM-based debugging and teaching agent with specialized tools for standard code retrieval, variable substitution to align reference code, and an external compiler for real-time code analysis. Guided by explicit pedagogical and debugging principles, DebugTA acts as an agent that decomposes a complex task into sequential LLM interactions, each utilizing distinct tools for specific subtasks, thereby simplifying the logical reasoning at each step and reducing overall reasoning complexity. Furthermore, DebugTA utilizes tool calls to align the standard code with the erroneous code as much as possible, allowing the LLM to focus on logic errors within the erroneous code and improving the accuracy of the generated suggestions. To rigorously assess the quality of modification suggestions, we introduce a student simulator-teacher interaction paradigm. Experimental results on three real-world code datasets demonstrate that DebugTA consistently improves teaching effectiveness while significantly reducing computational costs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11076","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.870251","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":266,"author":"Lingyue Fu, Haowei Yuan, Datong Chen, Xinyi Dai, Qingyao Li, Weinan Zhang, Weiwen Liu, Yong Yu","raw_content_length":1937,"priority":7,"update_frequency":1,"reading_time_minutes":1.33,"robust_parsing_used":true,"entities":{"organizations":["LLM","Debugging and Teaching"],"persons":["DebugTA"],"locations":[],"monetary":[]},"char_count":1936,"language_detected":"en","key_concepts":{"key_phrases":["DebugTA An LLM","arXiv251011076v1 Announce Type","new Abstract","programming education","Debugging","Teaching DT task","a common scenario","students","assistance","their erroneous code"],"filter_categories":{"ai_ml":["DebugTA An LLM"],"engineering":["programming education"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DebugTA An LLM":2.0,"arXiv251011076v1 Announce Type":1.0,"new Abstract":1.0,"programming education":1.0,"Debugging":1.0,"Teaching DT task":1.0,"a common scenario":1.0,"students":1.0,"assistance":1.0,"their erroneous code":1.0}},"age_hours":2.756208061666667,"is_recent":true,"quality_score":1.0,"sentiment_score":0.7790000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8442,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6243,"joy":0.0177,"surprise":0.0567,"sadness":0.1574,"fear":0.0509,"anger":0.0566,"disgust":0.0363},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel LLM-based debugging and teaching agent (DebugTA) that reduces computational costs. The impact on climate is indirect, potentially reducing energy consumption of computing resources, but this is not quantified. The technology is in the applied research stage, with experimental results on real-world code datasets, but no deployment is mentioned.","key_impact_metrics":["Computational costs reduction"],"technology_tags":["LLM","Debugging","Teaching Agent"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T11:47:32.448860Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_49873e58b72c","title":"Argumentation","content":"arXiv:2510.11079v1 Announce Type: new Abstract: Artificial Intelligence (AI) systems are increasingly deployed in legal contexts, where their opacity raises significant challenges for fairness, accountability, and trust. The so-called ``black box problem'' undermines the legitimacy of automated decision-making, as affected individuals often lack access to meaningful explanations. In response, the field of Explainable AI (XAI) has proposed a variety of methods to enhance transparency, ranging from example-based and rule-based techniques to hybrid and argumentation-based approaches. This paper promotes computational models of arguments and their role in providing legally relevant explanations, with particular attention to their alignment with emerging regulatory frameworks such as the EU General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). We analyze the strengths and limitations of different explanation strategies, evaluate their applicability to legal reasoning, and highlight how argumentation frameworks -- by capturing the defeasible, contestable, and value-sensitive nature of law -- offer a particularly robust foundation for explainable legal AI. Finally, we identify open challenges and research directions, including bias mitigation, empirical validation in judicial settings, and compliance with evolving ethical and legal standards, arguing that computational argumentation is best positioned to meet both technical and normative requirements of transparency in the law domain.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11079","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.870676","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Andrada Iulia Prajescu, Roberto Confalonieri","raw_content_length":1534,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["AIA","EU General Data Protection Regulation","Argumentation arXiv:2510.11079v1 Announce Type","the Artificial Intelligence Act"],"persons":[],"locations":[],"monetary":[]},"char_count":1533,"language_detected":"en","key_concepts":{"key_phrases":["Argumentation","arXiv251011079v1 Announce Type","new Abstract","legal contexts","their opacity","significant challenges","fairness","accountability","trust","The so-called black box problem"],"filter_categories":{"ai_ml":["fairness"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Argumentation":2.0,"arXiv251011079v1 Announce Type":1.0,"new Abstract":1.0,"legal contexts":1.0,"their opacity":1.0,"significant challenges":1.0,"fairness":1.0,"accountability":1.0,"trust":1.0,"The so-called black box problem":1.0}},"age_hours":2.7562224625,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8193,"joy":0.0051,"surprise":0.0086,"sadness":0.0087,"fear":0.059,"anger":0.0612,"disgust":0.038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the use of AI argumentation in legal contexts to improve transparency and accountability. While it addresses fairness and regulatory compliance, it lacks concrete actions or measurable outcomes related to direct environmental impact. The research is at an early stage with no deployed technology or quantified environmental benefits.","key_impact_metrics":[],"technology_tags":["Explainable AI","Computational Argumentation"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T11:47:34.946056Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fd026b22ba03","title":"Flow Matching","content":"arXiv:2510.11083v1 Announce Type: new Abstract: Modeling interactive driving behaviors in complex scenarios remains a fundamental challenge for autonomous driving planning. Learning-based approaches attempt to address this challenge with advanced generative models, removing the dependency on over-engineered architectures for representation fusion. However, brute-force implementation by simply stacking transformer blocks lacks a dedicated mechanism for modeling interactive behaviors that are common in real driving scenarios. The scarcity of interactive driving data further exacerbates this problem, leaving conventional imitation learning methods ill-equipped to capture high-value interactive behaviors. We propose Flow Planner, which tackles these problems through coordinated innovations in data modeling, model architecture, and learning scheme. Specifically, we first introduce fine-grained trajectory tokenization, which decomposes the trajectory into overlapping segments to decrease the complexity of whole trajectory modeling. With a sophisticatedly designed architecture, we achieve efficient temporal and spatial fusion of planning and scene information, to better capture interactive behaviors. In addition, the framework incorporates flow matching with classifier-free guidance for multi-modal behavior generation, which dynamically reweights agent interactions during inference to maintain coherent response strategies, providing a critical boost for interactive scenario understanding. Experimental results on the large-scale nuPlan dataset and challenging interactive interPlan dataset demonstrate that Flow Planner achieves state-of-the-art performance among learning-based approaches while effectively modeling interactive behaviors in complex driving scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11083","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.872056","language":"en","tags":["computer-science","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Tianyi Tan, Yinan Zheng, Ruiming Liang, Zexu Wang, Kexin Zheng, Jinliang Zheng, Jianxiong Li, Xianyuan Zhan, Jingjing Liu","raw_content_length":1787,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["Flow Planner"],"persons":[],"locations":[],"monetary":[]},"char_count":1786,"language_detected":"en","key_concepts":{"key_phrases":["Flow Matching","arXiv251011083v1 Announce Type","new Abstract","Modeling interactive driving behaviors","complex scenarios","a fundamental challenge","autonomous driving planning","Learning-based approaches attempt","this challenge","advanced generative models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Flow Matching":2.0,"arXiv251011083v1 Announce Type":1.0,"new Abstract":1.0,"Modeling interactive driving behaviors":1.0,"complex scenarios":1.0,"a fundamental challenge":1.0,"autonomous driving planning":1.0,"Learning-based approaches attempt":1.0,"this challenge":1.0,"advanced generative models":1.0}},"age_hours":2.7562639597222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.912,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5824,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7971,"joy":0.0113,"surprise":0.0672,"sadness":0.0076,"fear":0.0327,"anger":0.0598,"disgust":0.0243},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (Flow Planner) to improve autonomous driving planning, potentially leading to more efficient traffic flow and reduced fuel consumption in the future. However, it's still in the research phase, with experimental results on datasets but no real-world deployment. The impact on GHG emissions is theoretical at this point.","key_impact_metrics":["State-of-the-art performance on nuPlan dataset","Improved modeling of interactive behaviors"],"technology_tags":["Autonomous driving","Trajectory planning","Machine learning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T11:47:37.781801Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8bef53cb64cd","title":"Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series","content":"arXiv:2510.11084v1 Announce Type: new Abstract: Disentangling complex causal relationships is important for accurate detection of anomalies. In multivariate time series analysis, dynamic interactions among data variables over time complicate the interpretation of causal relationships. Traditional approaches assume statistical independence between variables in unsupervised settings, whereas recent methods capture feature correlations through graph representation learning. However, their representations fail to explicitly infer the causal relationships over different time periods. To solve the problem, we propose Causally Disentangled Representation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and identify their causal relationships in multivariate time series. First, we design the causal process as model input, the temporal heterogeneous graph, and causal relationships. Second, our representation identifies causal relationships over different time periods and disentangles latent variables to infer the corresponding causal factors. Third, our experiments on real-world datasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms of accuracy and root cause analysis. Fourth, our model analysis validates hyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct a case study to show how our approach assists human experts in diagnosing the root causes of anomalies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11084","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.872494","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Wonah Kim, Jeonghyeon Park, Dongsan Jun, Jungkyu Han, Sejin Chun","raw_content_length":1437,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Causally Disentangled Representation Learning for Anomaly Detection","Causal Disentanglement Learning"],"persons":["CDRL4AD"],"locations":[],"monetary":[]},"char_count":1436,"language_detected":"en","key_concepts":{"key_phrases":["Causal Disentanglement Learning","Accurate Anomaly Detection","Multivariate Time Series","arXiv251011084v1 Announce Type","new Abstract","Disentangling complex causal relationships","accurate detection","anomalies","multivariate time series analysis","dynamic interactions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Causal Disentanglement Learning":2.0,"Accurate Anomaly Detection":2.0,"Multivariate Time Series":2.0,"arXiv251011084v1 Announce Type":1.0,"new Abstract":1.0,"Disentangling complex causal relationships":1.0,"accurate detection":1.0,"anomalies":1.0,"multivariate time series analysis":1.0,"dynamic interactions":1.0}},"age_hours":2.7562773574999997,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8906,"joy":0.01,"surprise":0.0351,"sadness":0.007,"fear":0.0169,"anger":0.027,"disgust":0.0135},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (CDRL4AD) for anomaly detection in multivariate time series, which could potentially be applied to various sustainability-related systems (e.g., energy grids, industrial processes) to improve efficiency and reduce waste. The paper demonstrates improved accuracy compared to state-of-the-art methods on real-world datasets, but it is still in the applied research phase with no clear path to economic viability or deployment at scale. The impact on climate is indirect and depends on the specific application.","key_impact_metrics":["accuracy improvement over state-of-the-art methods","time complexity of CDRL4AD"],"technology_tags":["anomaly detection","causal disentanglement learning","multivariate time series analysis"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:47:41.447117Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c0df008f521","title":"UXer","content":"arXiv:2510.11087v1 Announce Type: new Abstract: In recent years, discussions on integrating Artificial Intelligence (AI) into UX design have intensified. However, the practical application of AI tools in design is limited by their operation within overly simplified scenarios, inherent complexity and unpredictability, and a general lack of relevant education. This study proposes an effective UXer-AI collaboration process to address these issues and seeks to identify efficient AI collaboration strategies through a series of user studies. In a preliminary study, two participatory design workshops identified major barriers to UXer-AI collaboration, including unfamiliarity with AI, inadequate internal support, and trust issues. To address the particularly critical issue of diminished trust, this study developed a new AI prototype model, TW-AI, that incorporates verification and decision-making processes to enhance trust and operational efficiency in UX design tasks. Task performance experiments and in-depth interviews evaluated the TW-AI model, revealing significant improvements in practitioners' trust, work efficiency, understanding of usage timing, and controllability. The \"Source\" function, based on Retrieval-Augmented Generation (RAG) technology, notably enhanced the reliability of the AI tool. Participants noted improved communication efficiency and reduced decision-making time, attributing these outcomes to the model's comprehensive verification features and streamlined approach to complex verification tasks. This study advances UXer-AI collaboration by providing key insights, bridging research and practice with actionable strategies, and establishing guidelines for AI tool designs tailored to UX. It contributes to the HCI community by outlining a scalable UXer-AI collaboration framework that addresses immediate operational challenges and lays the foundation for future advancements in AI-driven UX methodologies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11087","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.873344","language":"en","tags":["preprints","research","computer-science","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Harin Yoon, Dongwhan Kim, Changhoon Oh, Soojin Jun","raw_content_length":1947,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["Artificial Intelligence (AI","TW-AI","UXer arXiv:2510.11087v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1946,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011087v1 Announce Type","new Abstract","recent years","discussions","Artificial Intelligence","UX design","the practical application","AI tools","design","their operation"],"filter_categories":{"ai_ml":["Artificial Intelligence"],"engineering":["design"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011087v1 Announce Type":1.0,"new Abstract":1.0,"recent years":1.0,"discussions":1.0,"Artificial Intelligence":1.0,"UX design":1.0,"the practical application":1.0,"AI tools":1.0,"design":1.0,"their operation":1.0}},"age_hours":2.7563064444444443,"is_recent":true,"quality_score":0.7,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8661,"joy":0.0173,"surprise":0.0549,"sadness":0.0069,"fear":0.0315,"anger":0.0189,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a prototype AI tool (TW-AI) designed to improve UX design processes. While it reports improvements in trust and work efficiency based on user studies, there is no evidence of real-world deployment or quantified environmental impact. The study is still in the research phase, focusing on developing and testing the prototype.","key_impact_metrics":["Improved communication efficiency","Reduced decision-making time"],"technology_tags":["Artificial Intelligence","User Experience Design","Retrieval-Augmented Generation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:47:44.949445Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c9e5b1c76c19","title":"Establishing assembly","content":"arXiv:2510.11089v1 Announce Type: new Abstract: Modular product design has become a strategic enabler for companies seeking to balance product variety, operational efficiency, and market responsiveness, making the alignment between modular architecture and manufacturing considerations increasingly critical. Modular Function Deployment (MFD) is a widely adopted method for defining modular product architectures, yet it lacks systematic support for assembly considerations during early concept and system-level development. This limitation increases the risk of delayed production ramp-up and lifecycle inefficiencies. This paper proposes a set of enhancements to MFD that integrate Design for Assembly (DFA) logic into architectural synthesis. The extended method introduces structured heuristics, assembly-oriented module drivers, a coded interface taxonomy, and quantitative metrics for assessing assembly feasibility and automation readiness. These additions preserve compatibility with standard MFD workflows while enriching decision-making with traceable, production-informed reasoning. An illustrative case study involving a handheld leaf blower demonstrates the method's usability and effectiveness. The redesigned architecture shows reduced assembly effort, simplified interfaces, and increased automation potential. By supporting early-stage evaluation of architectural alternatives through an assembly lens, the method enables faster transition to efficient volume production and provides a foundation for continuous improvement throughout the product lifecycle.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11089","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.873769","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Fabio Marco Monetti, Adam Lundstr\\\"om, Colin de Kwant, Magnus Gyllenskepp, Antonio Maffei","raw_content_length":1575,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Modular Function Deployment","MFD","DFA","Design for Assembly"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1574,"language_detected":"en","key_concepts":{"key_phrases":["assembly","arXiv251011089v1 Announce Type","new Abstract","Modular product design","a strategic enabler","companies","product variety","operational efficiency","market responsiveness","the alignment"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"assembly":2.0,"arXiv251011089v1 Announce Type":1.0,"new Abstract":1.0,"Modular product design":1.0,"a strategic enabler":1.0,"companies":1.0,"product variety":1.0,"operational efficiency":1.0,"market responsiveness":1.0,"the alignment":1.0}},"age_hours":2.7563201,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9154,"joy":0.0064,"surprise":0.0415,"sadness":0.0078,"fear":0.0122,"anger":0.0116,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a method to improve modular product design for assembly, aiming to reduce assembly effort and increase automation potential. While the case study shows a redesigned architecture with simplified interfaces, it's still in the early stages of development with no deployed units or real-world data. The impact is theoretical at this point, focusing on potential efficiency gains in manufacturing rather than direct climate impact.","key_impact_metrics":["reduced assembly effort","increased automation potential"],"technology_tags":["modular design","design for assembly","manufacturing optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:47:48.825757Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4fd1ae30cccf","title":"Source","content":"arXiv:2510.11090v1 Announce Type: new Abstract: Source-Free Object Detection (SFOD) enables knowledge transfer from a source domain to an unsupervised target domain for object detection without access to source data. Most existing SFOD approaches are either confined to conventional object detection (OD) models like Faster R-CNN or designed as general solutions without tailored adaptations for novel OD architectures, especially Detection Transformer (DETR). In this paper, we introduce Feature Reweighting ANd Contrastive Learning NetworK (FRANCK), a novel SFOD framework specifically designed to perform query-centric feature enhancement for DETRs. FRANCK comprises four key components: (1) an Objectness Score-based Sample Reweighting (OSSR) module that computes attention-based objectness scores on multi-scale encoder feature maps, reweighting the detection loss to emphasize less-recognized regions; (2) a Contrastive Learning with Matching-based Memory Bank (CMMB) module that integrates multi-level features into memory banks, enhancing class-wise contrastive learning; (3) an Uncertainty-weighted Query-fused Feature Distillation (UQFD) module that improves feature distillation through prediction quality reweighting and query feature fusion; and (4) an improved self-training pipeline with a Dynamic Teacher Updating Interval (DTUI) that optimizes pseudo-label quality. By leveraging these components, FRANCK effectively adapts a source-pre-trained DETR model to a target domain with enhanced robustness and generalization. Extensive experiments on several widely used benchmarks demonstrate that our method achieves state-of-the-art performance, highlighting its effectiveness and compatibility with DETR-based SFOD models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11090","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.874177","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Huizai Yao, Sicheng Zhao, Shuo Lu, Hui Chen, Yangyang Li, Guoping Liu, Tengfei Xing, Chenggang Yan, Jianhua Tao, Guiguang Ding","raw_content_length":1738,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["DETRs","Faster R-CNN","Objectness Score","Source-Free Object Detection","FRANCK","Detection Transformer","SFOD","Memory Bank","Contrastive Learning","OSSR"],"persons":["Feature Reweighting ANd","Sample Reweighting"],"locations":[],"monetary":[]},"char_count":1737,"language_detected":"en","key_concepts":{"key_phrases":["Source","arXiv251011090v1","Announce Type","new Abstract","Source-Free Object Detection","SFOD","knowledge transfer","a source domain","an unsupervised target domain","object detection"],"filter_categories":{"ai_ml":["a source domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Source":2.0,"arXiv251011090v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Source-Free Object Detection":1.0,"SFOD":1.0,"knowledge transfer":1.0,"a source domain":1.0,"an unsupervised target domain":1.0,"object detection":1.0}},"age_hours":2.7563352541666664,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8866,"joy":0.0252,"surprise":0.0612,"sadness":0.0056,"fear":0.0057,"anger":0.0108,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel source-free object detection framework (FRANCK) designed for DETR models. While it demonstrates state-of-the-art performance on benchmarks, it is still in the applied research phase with no mention of real-world deployment or quantified environmental benefits. The technical credibility is supported by extensive experiments, but economic viability and deployment readiness are low.","key_impact_metrics":["State-of-the-art performance on several widely used benchmarks"],"technology_tags":["Source-Free Object Detection","Detection Transformer","Contrastive Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:51.768117Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f82e60955ebc","title":"Text","content":"arXiv:2510.11091v1 Announce Type: new Abstract: With the widespread adoption of Computer-Aided Design(CAD) drawings in engineering, architecture, and industrial design, the ability to accurately interpret and analyze these drawings has become increasingly critical. Among various subtasks, panoptic symbol spotting plays a vital role in enabling downstream applications such as CAD automation and design retrieval. Existing methods primarily focus on geometric primitives within the CAD drawings to address this task, but they face following major problems: they usually overlook the rich textual annotations present in CAD drawings and they lack explicit modeling of relationships among primitives, resulting in incomprehensive understanding of the holistic drawings. To fill this gap, we propose a panoptic symbol spotting framework that incorporates textual annotations. The framework constructs unified representations by jointly modeling geometric and textual primitives. Then, using visual features extract by pretrained CNN as the initial representations, a Transformer-based backbone is employed, enhanced with a type-aware attention mechanism to explicitly model the different types of spatial dependencies between various primitives. Extensive experiments on the real-world dataset demonstrate that the proposed method outperforms existing approaches on symbol spotting tasks involving textual annotations, and exhibits superior robustness when applied to complex CAD drawings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11091","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.874594","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Xianlin Liu, Yan Gong, Bohao Li, Jiajing Huang, Bowen Du, Junchen Ye, Liyan Xu","raw_content_length":1488,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["CAD","Computer-Aided Design(CAD"],"persons":[],"locations":[],"monetary":[]},"char_count":1487,"language_detected":"en","key_concepts":{"key_phrases":["Text","new Abstract","the widespread adoption","Computer-Aided DesignCAD","engineering","architecture","industrial design","the ability","these drawings","various subtasks"],"filter_categories":{"ai_ml":["Computer-Aided DesignCAD"],"engineering":["engineering","architecture"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Text":2.0,"new Abstract":1.0,"the widespread adoption":1.0,"Computer-Aided DesignCAD":1.0,"engineering":1.0,"architecture":1.0,"industrial design":1.0,"the ability":1.0,"these drawings":1.0,"various subtasks":1.0}},"age_hours":2.756348881666667,"is_recent":true,"quality_score":0.7,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9372,"joy":0.0129,"surprise":0.0291,"sadness":0.0029,"fear":0.0064,"anger":0.0078,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for panoptic symbol spotting in CAD drawings, incorporating textual annotations to improve accuracy. While this could potentially lead to more efficient design processes and resource utilization in the long run, the impact on sustainability is currently theoretical and unquantified. The research is at an early stage, with no deployed units or real-world data available.","key_impact_metrics":[],"technology_tags":["Computer-Aided Design","Panoptic Symbol Spotting","Transformer Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:47:54.663650Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e5a2b80faf4d","title":"Future-Aware End","content":"arXiv:2510.11092v1 Announce Type: new Abstract: End-to-end autonomous driving methods aim to directly map raw sensor inputs to future driving actions such as planned trajectories, bypassing traditional modular pipelines. While these approaches have shown promise, they often operate under a one-shot paradigm that relies heavily on the current scene context, potentially underestimating the importance of scene dynamics and their temporal evolution. This limitation restricts the model's ability to make informed and adaptive decisions in complex driving scenarios. We propose a new perspective: the future trajectory of an autonomous vehicle is closely intertwined with the evolving dynamics of its environment, and conversely, the vehicle's own future states can influence how the surrounding scene unfolds. Motivated by this bidirectional relationship, we introduce SeerDrive, a novel end-to-end framework that jointly models future scene evolution and trajectory planning in a closed-loop manner. Our method first predicts future bird's-eye view (BEV) representations to anticipate the dynamics of the surrounding scene, then leverages this foresight to generate future-context-aware trajectories. Two key components enable this: (1) future-aware planning, which injects predicted BEV features into the trajectory planner, and (2) iterative scene modeling and vehicle planning, which refines both future scene prediction and trajectory generation through collaborative optimization. Extensive experiments on the NAVSIM and nuScenes benchmarks show that SeerDrive significantly outperforms existing state-of-the-art methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11092","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.874997","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Bozhou Zhang, Nan Song, Jingyu Li, Xiatian Zhu, Jiankang Deng, Li Zhang","raw_content_length":1628,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Future-Aware End arXiv:2510.11092v1 Announce Type","SeerDrive"],"persons":[],"locations":[],"monetary":[]},"char_count":1627,"language_detected":"en","key_concepts":{"key_phrases":["Future-Aware End","arXiv251011092v1 Announce Type","new Abstract","end","future driving actions","planned trajectories","traditional modular pipelines","these approaches","promise","a one-shot paradigm"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Future-Aware End":2.0,"arXiv251011092v1 Announce Type":1.0,"new Abstract":1.0,"end":1.0,"future driving actions":1.0,"planned trajectories":1.0,"traditional modular pipelines":1.0,"these approaches":1.0,"promise":1.0,"a one-shot paradigm":1.0}},"age_hours":2.756363671111111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8883,"joy":0.0034,"surprise":0.0232,"sadness":0.0119,"fear":0.0256,"anger":0.0237,"disgust":0.0239},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel end-to-end framework (SeerDrive) for autonomous driving that aims to improve decision-making in complex scenarios. The framework is evaluated on NAVSIM and nuScenes benchmarks, showing outperformance compared to existing methods. However, it is still in the applied research stage with no mention of real-world deployment or economic viability.","key_impact_metrics":["Outperforms existing state-of-the-art methods on NAVSIM and nuScenes"],"technology_tags":["autonomous driving","end-to-end learning","trajectory planning","scene understanding"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T11:48:18.464717Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f58a5ee822e","title":"Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami","content":"arXiv:2510.11094v1 Announce Type: new Abstract: Effective rehabilitation methods are essential for the recovery of lower limb dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are usually heavy and need a lot of work to help the patients to put them on. Moreover, it also requires extra compliance control to guarantee the safety. In contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic compliance, but their complex nonlinear human-robot interaction dynamics would pose significant challenges for control. In this work, based on the pneumatic actuators inspired by origami, we design a rehabilitation exoskeleton for knee that is easy and comfortable to wear. To guarantee the control performance and enable a nice human-robot interaction, we first use Deep Koopman Network to model the human-robot interaction dynamics. In particular, by viewing the electromyography (EMG) signals and the duty cycle of the PWM wave that controls the pneumatic robot's valves and pump as the inputs, the linear Koopman model accurately captures the complex human-robot interaction dynamics. Next, based on the obtained Koopman model, we further use Model Predictive Control (MPC) to control the soft robot and help the user to do rehabilitation training in real-time. The goal of the rehabilitation training is to track a given reference signal shown on the screen. Experiments show that by integrating the EMG signals into the Koopman model, we have improved the model accuracy to great extent. In addition, a personalized Koopman model trained from the individual's own data performs better than the non-personalized model. Consequently, our control framework outperforms the traditional PID control in both passive and active training modes. Hence the proposed method provides a new control framework for soft rehabilitation robots.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11094","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.875430","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":288,"author":"Junxiang Wang, Han Zhang, Zehao Wang, Huaiyuan Chen, Pu Wang, Weidong Chen","raw_content_length":1951,"priority":7,"update_frequency":1,"reading_time_minutes":1.44,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["Origami"],"monetary":[]},"char_count":1950,"language_detected":"en","key_concepts":{"key_phrases":["Design and Koopman Model Predictive Control","A Soft Exoskeleton","Origami","arXiv251011094v1 Announce Type","new Abstract","Effective rehabilitation methods","the recovery","lower limb dysfunction","stroke","robotic exoskeletons"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Design and Koopman Model Predictive Control":2.0,"A Soft Exoskeleton":2.0,"Origami":2.0,"arXiv251011094v1 Announce Type":1.0,"new Abstract":1.0,"Effective rehabilitation methods":1.0,"the recovery":1.0,"lower limb dysfunction":1.0,"stroke":1.0,"robotic exoskeletons":1.0}},"age_hours":2.7563787283333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9027,"joy":0.0171,"surprise":0.0287,"sadness":0.015,"fear":0.0145,"anger":0.0118,"disgust":0.01},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel control framework for soft rehabilitation robots using origami-inspired pneumatic actuators. The concrete action is the design and control of a soft exoskeleton, with experiments showing improved model accuracy by integrating EMG signals. However, it is still in the applied research stage with no deployed units or commercialization, hence the low deployment readiness and economic viability scores.","key_impact_metrics":["Improved model accuracy using EMG signals","Outperforms traditional PID control"],"technology_tags":["Soft Exoskeleton","Origami-inspired Pneumatic Actuators","Koopman Model Predictive Control"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:48:21.589839Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0ce3eab66792","title":"CoDefend: Cross","content":"arXiv:2510.11096v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success in tasks such as image captioning, visual question answering, and cross-modal reasoning by integrating visual and textual modalities. However, their multimodal nature also exposes them to adversarial threats, where attackers can perturb either modality or both jointly to induce harmful, misleading, or policy violating outputs. Existing defense strategies, such as adversarial training and input purification, face notable limitations: adversarial training typically improves robustness only against known attacks while incurring high computational costs, whereas conventional purification approaches often suffer from degraded image quality and insufficient generalization to complex multimodal tasks. In this work, we focus on defending the visual modality, which frequently serves as the primary entry point for adversarial manipulation. We propose a supervised diffusion based denoising framework that leverages paired adversarial clean image datasets to fine-tune diffusion models with directional, task specific guidance. Unlike prior unsupervised purification methods such as DiffPure, our approach achieves higher quality reconstructions while significantly improving defense robustness in multimodal tasks. Furthermore, we incorporate prompt optimization as a complementary defense mechanism, enhancing resistance against diverse and unseen attack strategies. Extensive experiments on image captioning and visual question answering demonstrate that our method not only substantially improves robustness but also exhibits strong transferability to unknown adversarial attacks. These results highlight the effectiveness of supervised diffusion based denoising for multimodal defense, paving the way for more reliable and secure deployment of MLLMs in real world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11096","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.876360","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Fengling Zhu, Boshi Liu, Jingyu Hua, Sheng Zhong","raw_content_length":1910,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1905,"language_detected":"en","key_concepts":{"key_phrases":["CoDefend Cross","arXiv251011096v1 Announce Type","new Abstract","Multimodal Large Language Models","MLLMs","remarkable success","tasks","visual question","cross-modal reasoning","visual and textual modalities"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CoDefend Cross":2.0,"arXiv251011096v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal Large Language Models":1.0,"MLLMs":1.0,"remarkable success":1.0,"tasks":1.0,"visual question":1.0,"cross-modal reasoning":1.0,"visual and textual modalities":1.0}},"age_hours":2.756406955,"is_recent":true,"quality_score":0.7,"sentiment_score":1.0775000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7845,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7132,"joy":0.0064,"surprise":0.0146,"sadness":0.0106,"fear":0.1268,"anger":0.0856,"disgust":0.0428},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel defense mechanism against adversarial attacks on multimodal AI systems. While it demonstrates improved robustness and transferability in experiments, it remains in the applied research stage with no deployed units or real-world data. The climate impact is indirect, as it aims to secure AI systems, which could potentially be used in climate-related applications.","key_impact_metrics":["Higher quality reconstructions","Improved defense robustness"],"technology_tags":["Multimodal Large Language Models","Diffusion Models","Adversarial Defense"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:48:48.844924Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_91afecb07552","title":"HoMer: Addressing Heterogeneities by Modeling Sequential and Set","content":"arXiv:2510.11100v1 Announce Type: new Abstract: Click-through rate (CTR) prediction, which models behavior sequence and non-sequential features (e.g., user/item profiles or cross features) to infer user interest, underpins industrial recommender systems. However, most methods face three forms of heterogeneity that degrade predictive performance: (i) Feature Heterogeneity persists when limited sequence side features provide less granular interest representation compared to extensive non-sequential features, thereby impairing sequence modeling performance; (ii) Context Heterogeneity arises because a user's interest in an item will be influenced by other items, yet point-wise prediction neglects cross-item interaction context from the entire item set; (iii) Architecture Heterogeneity stems from the fragmented integration of specialized network modules, which compounds the model's effectiveness, efficiency and scalability in industrial deployments. To tackle the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for modeling sequential and set-wise contexts. First, we align sequence side features with non-sequential features for accurate sequence modeling and fine-grained interest representation. Second, we shift the prediction paradigm from point-wise to set-wise, facilitating cross-item interaction in a highly parallel manner. Third, HoMer's unified encoder-decoder architecture achieves dual optimization through structural simplification and shared computation, ensuring computational efficiency while maintaining scalability with model size. Without arduous modification to the prediction pipeline, HoMer successfully scales up and outperforms our industrial baseline by 0.0099 in the AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%. Additionally, HoMer saves 27% of GPU resources via preliminary engineering optimization, further validating its superiority and practicality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11100","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.877312","language":"en","tags":["computer-science","csai","preprints","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Shuwei Chen, Jiajun Cui, Zhengqi Xu, Fan Zhang, Jiangke Fan, Teng Zhang, Xingxing Wang","raw_content_length":1949,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["Modeling Sequential","CTR","Set arXiv:2510.11100v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1948,"language_detected":"en","key_concepts":{"key_phrases":["HoMer","Heterogeneities","Modeling Sequential","Set","arXiv251011100v1 Announce Type","new Abstract Click-through rate CTR prediction","which","behavior sequence","non-sequential features","useritem profiles"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"HoMer":2.0,"Heterogeneities":2.0,"Modeling Sequential":2.0,"Set":2.0,"arXiv251011100v1 Announce Type":1.0,"new Abstract Click-through rate CTR prediction":1.0,"which":1.0,"behavior sequence":1.0,"non-sequential features":1.0,"useritem profiles":1.0}},"age_hours":2.7564375711111113,"is_recent":true,"quality_score":1.0,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9117,"joy":0.0046,"surprise":0.0303,"sadness":0.0102,"fear":0.0089,"anger":0.0177,"disgust":0.0166},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel recommender system (HoMer) that improves efficiency and scalability in industrial deployments. It reports a 1.99% increase in CTR/RPM and a 27% reduction in GPU resources. While the impact on climate is indirect (reduced energy consumption of recommender systems), the measurable outcomes and peer-review potential provide some credibility.","key_impact_metrics":["CTR/RPM increase by 1.99%","GPU resources saved by 27%"],"technology_tags":["recommender systems","machine learning","energy efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:48:52.240905Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d0f0ee94beee","title":"A Primer on SO(3) Action Representations in Deep Reinforcement Learning","content":"arXiv:2510.11103v1 Announce Type: new Abstract: Many robotic control tasks require policies to act on orientations, yet the geometry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quaternions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learning, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard continuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regularization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the practical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation-induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11103","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.877744","language":"en","tags":["computer-science","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Martin Schuck, Sherif Samy, Angela P. Schoellig","raw_content_length":1360,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["PPO","Euler","SAC","Euclidean n"],"persons":["Lie algebra coordinates","TD3"],"locations":[],"monetary":[]},"char_count":1359,"language_detected":"en","key_concepts":{"key_phrases":["SO3","Deep Reinforcement Learning","arXiv251011103v1 Announce Type","new Abstract","Many robotic control tasks","policies","orientations","the geometry","this nontrivial","no global smooth minimal parameterization"],"filter_categories":{"ai_ml":["Deep Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SO3":4.0,"Deep Reinforcement Learning":2.0,"arXiv251011103v1 Announce Type":1.0,"new Abstract":1.0,"Many robotic control tasks":1.0,"policies":1.0,"orientations":1.0,"the geometry":1.0,"this nontrivial":1.0,"no global smooth minimal parameterization":1.0}},"age_hours":2.7564525783333336,"is_recent":true,"quality_score":1.0,"sentiment_score":3.5199999999999996,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.296,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8447,"joy":0.0168,"surprise":0.0796,"sadness":0.006,"fear":0.0218,"anger":0.0177,"disgust":0.0133},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a systematic evaluation of different SO(3) action representations in reinforcement learning for robotics. The concrete action is the comparison of different representations across standard control algorithms. The evidence supporting the claims comes from empirical studies and analysis of projections. The stage of deployment is at the pilot level, as it is tested on robotics benchmarks but not yet deployed in real-world applications.","key_impact_metrics":["Training stability","Exploration performance"],"technology_tags":["Reinforcement Learning","Robotics","SO(3) Action Representations"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:48:55.466448Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_09cc2909a8e4","title":"Enhancing LLM Reasoning via Non","content":"arXiv:2510.11104v1 Announce Type: new Abstract: Current approaches for strengthening LLM reasoning tend to introduce a training bias toward human-like reasoning trajectories. In step-wise preference optimization, in particular, dependence on human or higher-capacity model annotations for intermediate steps limits exploration of alternative, non-human-like reasoning paths and thus constrains achievable performance. Furthermore, through a small-scale pilot study, we observed that in approximately 75% of cases, the model's first erroneous step occurs after the lowest-confidence point. This suggests that guiding the model at its lowest-confidence point before an error provides more accurate supervision than locating the first explicit error. In this paper, we propose Confidence-Guided Reasoning Path Preference Optimization (CGPO), a method that leverages a confidence signal to identify points of maximal uncertainty in the model's reasoning process and applies self-generated, non-human-like reasoning-path guidance to mitigate trajectory drift. Our experiments span diverse models applied to both code and mathematical reasoning tasks. The results show that, with the same amount of training data, our method using data generated by a small model can achieve better performance in most cases compared with approaches using data generated by a strong model or human-annotated.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11104","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.878143","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Junjie Lu, Yuliang Liu, Chaofeng Qu, Wei Shen, Zhouhan Lin, Min Xu","raw_content_length":1386,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Non arXiv:2510.11104v1 Announce Type: new Abstract","Confidence-Guided Reasoning Path Preference Optimization"],"persons":[],"locations":[],"monetary":[]},"char_count":1385,"language_detected":"en","key_concepts":{"key_phrases":["LLM Reasoning","Non","arXiv251011104v1 Announce Type","new Abstract","Current approaches","LLM reasoning","a training bias","human-like reasoning trajectories","step-wise preference optimization","in particular dependence"],"filter_categories":{"ai_ml":["LLM Reasoning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM Reasoning":2.0,"Non":2.0,"arXiv251011104v1 Announce Type":1.0,"new Abstract":1.0,"Current approaches":1.0,"LLM reasoning":1.0,"a training bias":1.0,"human-like reasoning trajectories":1.0,"step-wise preference optimization":1.0,"in particular dependence":1.0}},"age_hours":2.7564673947222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.85,"joy":0.0142,"surprise":0.0362,"sadness":0.0156,"fear":0.0164,"anger":0.0341,"disgust":0.0335},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method (CGPO) for enhancing LLM reasoning, which could indirectly support sustainability efforts by improving the efficiency and accuracy of AI models used in climate modeling, resource management, or other sustainability-related applications. The method is currently in the applied research stage, with experiments showing improved performance using smaller models. The concrete action is the development and testing of a new algorithm, but deployment and real-world impact are not yet established.","key_impact_metrics":["75% reduction in erroneous steps","Better performance with smaller models"],"technology_tags":["Large Language Models","AI Reasoning","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:49:11.069832Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
