{"id":"science_arxiv_cs_714fd4f42aa8","title":"CryoFastAR: Fast Cryo","content":"arXiv:2506.05864v2 Announce Type: replace Abstract: Pose estimation from unordered images is fundamental for 3D reconstruction, robotics, and scientific imaging. Recent geometric foundation models, such as DUSt3R, enable end-to-end dense 3D reconstruction but remain underexplored in scientific imaging fields like cryo-electron microscopy (cryo-EM) for near-atomic protein reconstruction. In cryo-EM, pose estimation and 3D reconstruction from unordered particle images still depend on time-consuming iterative optimization, primarily due to challenges such as low signal-to-noise ratios (SNR) and distortions from the contrast transfer function (CTF). We introduce CryoFastAR, the first geometric foundation model that can directly predict poses from Cryo-EM noisy images for Fast ab initio Reconstruction. By integrating multi-view features and training on large-scale simulated cryo-EM data with realistic noise and CTF modulations, CryoFastAR enhances pose estimation accuracy and generalization. To enhance training stability, we propose a progressive training strategy that first allows the model to extract essential features under simpler conditions before gradually increasing difficulty to improve robustness. Experiments show that CryoFastAR achieves comparable quality while significantly accelerating inference over traditional iterative approaches on both synthetic and real datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05864","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.595141","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Jiakai Zhang, Shouchen Zhou, Haizhao Dai, Xinhang Liu, Peihao Wang, Zhiwen Fan, Yuan Pei, Jingyi Yu","raw_content_length":1400,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["CryoFastAR","Fast Cryo arXiv:2506.05864v2 Announce Type","CTF","SNR","Cryo-EM","Reconstruction"],"persons":[],"locations":[],"monetary":[]},"char_count":1399,"language_detected":"en","key_concepts":{"key_phrases":["CryoFastAR Fast Cryo","3D reconstruction","cryo-EM","Announce Type","Abstract","Pose estimation","unordered images","robotics","scientific imaging","Recent geometric foundation models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CryoFastAR Fast Cryo":2.0,"3D reconstruction":2.0,"cryo-EM":2.0,"Announce Type":1.0,"Abstract":1.0,"Pose estimation":1.0,"unordered images":1.0,"robotics":1.0,"scientific imaging":1.0,"Recent geometric foundation models":1.0}},"age_hours":2.747467461944445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.5115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8604,"joy":0.0134,"surprise":0.0534,"sadness":0.008,"fear":0.0322,"anger":0.0213,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"CryoFastAR accelerates cryo-EM pose estimation, potentially reducing energy consumption in research. The article presents experimental results showing improved inference speed compared to traditional methods, but lacks information on actual energy savings or deployment beyond research settings. It is still in the applied research stage.","key_impact_metrics":["inference acceleration","pose estimation accuracy"],"technology_tags":["cryo-electron microscopy","pose estimation","geometric foundation models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:23.841688Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b119fe77e3c0","title":"A Fast and Lightweight Model for Causal Audio","content":"arXiv:2506.06689v2 Announce Type: replace Abstract: Audio-visual speech separation (AVSS) aims to extract a target speech signal from a mixed signal by leveraging both auditory and visual (lip movement) cues. However, most existing AVSS methods exhibit complex architectures and rely on future context, operating offline, which renders them unsuitable for real-time applications. Inspired by the pipeline of RTFSNet, we propose a novel streaming AVSS model, named Swift-Net, which enhances the causal processing capabilities required for real-time applications. Swift-Net adopts a lightweight visual feature extraction module and an efficient fusion module for audio-visual integration. Additionally, Swift-Net employs Grouped SRUs to integrate historical information across different feature spaces, thereby improving the utilization efficiency of historical information. We further propose a causal transformation template to facilitate the conversion of non-causal AVSS models into causal counterparts. Experiments on three standard benchmark datasets (LRS2, LRS3, and VoxCeleb2) demonstrated that under causal conditions, our proposed Swift-Net exhibited outstanding performance, highlighting the potential of this method for processing speech in complex environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.06689","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.595695","language":"en","tags":["preprints","computer-science","eessas","research","cssd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Wendi Sang, Kai Li, Runxuan Yang, Jianqiang Huang, Xiaolin Hu","raw_content_length":1273,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["AVSS","Swift-Net"],"persons":["Grouped"],"locations":[],"monetary":[]},"char_count":1272,"language_detected":"en","key_concepts":{"key_phrases":["A Fast and Lightweight Model","Causal Audio","which","Announce Type","Abstract","Audio-visual speech separation","AVSS","a target speech signal","a mixed signal","most existing AVSS methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Fast and Lightweight Model":2.0,"Causal Audio":2.0,"which":2.0,"Announce Type":1.0,"Abstract":1.0,"Audio-visual speech separation":1.0,"AVSS":1.0,"a target speech signal":1.0,"a mixed signal":1.0,"most existing AVSS methods":1.0}},"age_hours":2.7474823352777777,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9159,"joy":0.0099,"surprise":0.0293,"sadness":0.0076,"fear":0.0117,"anger":0.0162,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel model for audio-visual speech separation (AVSS) with improved causal processing capabilities. While the model shows promising performance on benchmark datasets, it is still in the early stages of development and lacks real-world deployment or quantified environmental impact. The vaporware flag is raised because it is a prototype with no deployed units.","key_impact_metrics":["Outstanding performance on LRS2","Outstanding performance on LRS3"],"technology_tags":["Audio-visual speech separation","Causal processing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:26.722235Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3826af707675","title":"Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations","content":"arXiv:2506.06907v2 Announce Type: replace Abstract: Graph Neural Networks have achieved impressive results across diverse network modeling tasks, but accurately estimating uncertainty on graphs remains difficult, especially under distributional shifts. Unlike traditional uncertainty estimation, graph-based uncertainty must account for randomness arising from both the graph's structure and its label distribution, which adds complexity. In this paper, making an analogy between the evolution of a stochastic partial differential equation (SPDE) driven by Matern Gaussian Process and message passing using GNN layers, we present a principled way to design a novel message passing scheme that incorporates spatial-temporal noises motivated by the Gaussian Process approach to SPDE. Our method simultaneously captures uncertainty across space and time and allows explicit control over the covariance kernel smoothness, thereby enhancing uncertainty estimates on graphs with both low and high label informativeness. Our extensive experiments on Out-of-Distribution (OOD) detection on graph datasets with varying label informativeness demonstrate the soundness and superiority of our model to existing approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.06907","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.601214","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Fred Xu, Thomas Markovich","raw_content_length":1211,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["GNN","SPDE","Structure Informed Stochastic Partial Differential Equations","Graph Neural Networks","Uncertainty Estimation on Graphs"],"persons":[],"locations":[],"monetary":[]},"char_count":1210,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty Estimation","Graphs","Structure Informed Stochastic Partial Differential Equations","arXiv250606907v2 Announce Type","Abstract","Graph Neural Networks","impressive results","diverse network modeling tasks","uncertainty","graphs"],"filter_categories":{"ai_ml":["Uncertainty Estimation","Graph Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty Estimation":2.0,"Graphs":2.0,"Structure Informed Stochastic Partial Differential Equations":2.0,"arXiv250606907v2 Announce Type":1.0,"Abstract":1.0,"Graph Neural Networks":1.0,"impressive results":1.0,"diverse network modeling tasks":1.0,"uncertainty":1.0,"graphs":1.0}},"age_hours":2.7474962494444446,"is_recent":true,"quality_score":1.0,"sentiment_score":0.489,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9022,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3137,"joy":0.0104,"surprise":0.0403,"sadness":0.0126,"fear":0.5922,"anger":0.0192,"disgust":0.0117},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for uncertainty estimation on graphs, which could potentially improve the accuracy of predictions in various sustainability-related applications, such as predicting energy consumption or identifying vulnerable communities. The method is based on a stochastic partial differential equation (SPDE) approach and shows superiority to existing methods in out-of-distribution detection on graph datasets. However, it is still in the early stages of development with no clear path to economic viability or deployment at scale.","key_impact_metrics":["Superiority in OOD detection on graph datasets"],"technology_tags":["Graph Neural Networks","Uncertainty Estimation","Stochastic Partial Differential Equations"],"sdg_alignment":[7,9,11],"analyzed_at":"2025-10-29T16:44:29.841032Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c2b4ea3345bb","title":"BridgeVLA: Input","content":"arXiv:2506.07961v2 Announce Type: replace Abstract: Recently, leveraging pre-trained vision-language models (VLMs) for building vision-language-action (VLA) models has emerged as a promising approach to effective robot manipulation learning. However, only few methods incorporate 3D signals into VLMs for action prediction, and they do not fully leverage the spatial structure inherent in 3D data, leading to low sample efficiency. In this paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D inputs to multiple 2D images, ensuring input alignment with the VLM backbone, and (2) utilizes 2D heatmaps for action prediction, unifying the input and output spaces within a consistent 2D image space. In addition, we propose a scalable pre-training method that equips the VLM backbone with the capability to predict 2D heatmaps before downstream policy learning. Extensive experiments show the proposed method is able to learn 3D manipulation efficiently and effectively. BridgeVLA outperforms state-of-the-art baseline methods across three simulation benchmarks. In RLBench, it improves the average success rate from 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better performance in challenging generalization settings, boosting the average success rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing baseline methods in terms of average success rate. In real-robot experiments, BridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It generalizes robustly in multiple out-of-distribution settings, including visual disturbances and unseen instructions. Remarkably, it is able to achieve a success rate of 96.8% on 10+ tasks with only 3 trajectories per task, highlighting its extraordinary sample efficiency. Project Website:https://bridgevla.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.07961","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.602177","language":"en","tags":["preprints","csai","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Peiyan Li, Yixiang Chen, Hongtao Wu, Xiao Ma, Xiangnan Wu, Yan Huang, Liang Wang, Tao Kong, Tieniu Tan","raw_content_length":1827,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["VLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1826,"language_detected":"en","key_concepts":{"key_phrases":["BridgeVLA","Input","VLMs","Announce Type","Abstract","pre-trained vision-language models","vision-language-action VLA models","a promising approach","effective robot manipulation learning","only few methods"],"filter_categories":{"ai_ml":["pre-trained vision-language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BridgeVLA":3.0,"Input":2.0,"VLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"pre-trained vision-language models":1.0,"vision-language-action VLA models":1.0,"a promising approach":1.0,"effective robot manipulation learning":1.0,"only few methods":1.0}},"age_hours":2.747526675555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9116,"joy":0.013,"surprise":0.042,"sadness":0.0058,"fear":0.0095,"anger":0.0107,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for robot manipulation learning using vision-language models. The concrete action is the development and testing of the BridgeVLA model in simulation and real-robot experiments, showing improved success rates in manipulation tasks. While the results are promising, it's still in the applied research stage with limited economic viability data.","key_impact_metrics":["average success rate in RLBench improved from 81.4% to 88.2%","success rate of 96.8% on 10+ tasks with only 3 trajectories per task"],"technology_tags":["robot manipulation","vision-language models","3D perception"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:44:32.897227Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6da3a7b089e2","title":"Learning to Explore in Diverse Reward Settings via Temporal","content":"arXiv:2506.13345v2 Announce Type: replace Abstract: Numerous heuristics and advanced approaches have been proposed for exploration in different settings for deep reinforcement learning. Noise-based exploration generally fares well with dense-shaped rewards and bonus-based exploration with sparse rewards. However, these methods usually require additional tuning to deal with undesirable reward settings by adjusting hyperparameters and noise distributions. Rewards that actively discourage exploration, i.e., with an action cost and no other dense signal to follow, can pose a major challenge. We propose a novel exploration method, Stable Error-seeking Exploration (SEE), that is robust across dense, sparse, and exploration-adverse reward settings. To this endeavor, we revisit the idea of maximizing the TD-error as a separate objective. Our method introduces three design choices to mitigate instability caused by far-off-policy learning, the conflict of interest of maximizing the cumulative TD-error in an episodic setting, and the non-stationary nature of TD-errors. SEE can be combined with off-policy algorithms without modifying the optimization pipeline of the original objective. In our experimental analysis, we show that a Soft-Actor Critic agent with the addition of SEE performs robustly across three diverse reward settings in a variety of tasks without hyperparameter adjustments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.13345","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.603057","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Sebastian Griesbach, Carlo D'Eramo","raw_content_length":1400,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1399,"language_detected":"en","key_concepts":{"key_phrases":["Explore","Diverse Reward Settings","arXiv250613345v2 Announce Type","Abstract","Numerous heuristics","advanced approaches","exploration","different settings","deep reinforcement learning","Noise-based exploration"],"filter_categories":{"ai_ml":["deep reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Explore":2.0,"Diverse Reward Settings":2.0,"arXiv250613345v2 Announce Type":1.0,"Abstract":1.0,"Numerous heuristics":1.0,"advanced approaches":1.0,"exploration":1.0,"different settings":1.0,"deep reinforcement learning":1.0,"Noise-based exploration":1.0}},"age_hours":2.7475558344444444,"is_recent":true,"quality_score":0.7,"sentiment_score":9.776,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9552,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8971,"joy":0.0083,"surprise":0.0322,"sadness":0.0187,"fear":0.01,"anger":0.0129,"disgust":0.0207},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel exploration method (SEE) for reinforcement learning, potentially improving the efficiency of algorithms used in various applications. While the method shows promise in diverse reward settings, it is still in the research phase and lacks concrete deployment or quantifiable impact on sustainability. The potential for sustainability impact is theoretical, as the algorithm itself doesn't directly address climate change but could improve the efficiency of systems that do.","key_impact_metrics":[],"technology_tags":["Reinforcement Learning","Exploration Algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:35.636008Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ef9179481a20","title":"Leveraging Predictive Equivalence in Decision Trees","content":"arXiv:2506.14143v3 Announce Type: replace Abstract: Decision trees are widely used for interpretable machine learning due to their clearly structured reasoning process. However, this structure belies a challenge we refer to as predictive equivalence: a given tree's decision boundary can be represented by many different decision trees. The presence of models with identical decision boundaries but different evaluation processes makes model selection challenging. The models will have different variable importance and behave differently in the presence of missing values, but most optimization procedures will arbitrarily choose one such model to return. We present a boolean logical representation of decision trees that does not exhibit predictive equivalence and is faithful to the underlying decision boundary. We apply our representation to several downstream machine learning tasks. Using our representation, we show that decision trees are surprisingly robust to test-time missingness of feature values; we address predictive equivalence's impact on quantifying variable importance; and we present an algorithm to optimize the cost of reaching predictions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14143","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.603458","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Hayden McTavish, Zachery Boner, Jon Donnelly, Margo Seltzer, Cynthia Rudin","raw_content_length":1166,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1165,"language_detected":"en","key_concepts":{"key_phrases":["Predictive Equivalence","Decision Trees","Announce Type","Abstract","Decision trees","interpretable machine learning","their clearly structured reasoning process","this structure","a challenge","predictive equivalence"],"filter_categories":{"ai_ml":["interpretable machine learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Predictive Equivalence":2.0,"Decision Trees":2.0,"Announce Type":1.0,"Abstract":1.0,"Decision trees":1.0,"interpretable machine learning":1.0,"their clearly structured reasoning process":1.0,"this structure":1.0,"a challenge":1.0,"predictive equivalence":1.0}},"age_hours":2.7475695469444443,"is_recent":true,"quality_score":0.7,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8812,"joy":0.0148,"surprise":0.0187,"sadness":0.0117,"fear":0.019,"anger":0.0214,"disgust":0.0333},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency and robustness of decision trees in machine learning. While potentially beneficial for optimizing resource allocation in various sectors, including energy and environmental management, there are no concrete actions or measurable outcomes related to sustainability described in the article. The research is at a basic research stage with no deployment or quantified impact data.","key_impact_metrics":[],"technology_tags":["machine learning","decision trees","optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:38.380241Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d1143018009d","title":"HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models","content":"arXiv:2506.15065v2 Announce Type: replace Abstract: Large language models (LLMs) are increasingly being adopted as the cognitive core of embodied agents. However, inherited hallucinations, which stem from failures to ground user instructions in the observed physical environment, can lead to navigation errors, such as searching for a refrigerator that does not exist. In this paper, we present the first systematic study of hallucinations in LLM-based embodied agents performing long-horizon tasks under scene-task inconsistencies. Our goal is to understand to what extent hallucinations occur, what types of inconsistencies trigger them, and how current models respond. To achieve these goals, we construct a hallucination probing set by building on an existing benchmark, capable of inducing hallucination rates up to 40x higher than base prompts. Evaluating 12 models across two simulation environments, we find that while models exhibit reasoning, they fail to resolve scene-task inconsistencies-highlighting fundamental limitations in handling infeasible tasks. We also provide actionable insights on ideal model behavior for each scenario, offering guidance for developing more robust and reliable planning strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.15065","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.603883","language":"en","tags":["preprints","computer-science","cslg","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Trishna Chakraborty, Udita Ghosh, Xiaopan Zhang, Fahim Faisal Niloy, Yue Dong, Jiachen Li, Amit K. Roy-Chowdhury, Chengyu Song","raw_content_length":1226,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1225,"language_detected":"en","key_concepts":{"key_phrases":["HEAL","An Empirical Study","Hallucinations","Embodied Agents","Large Language Models","Announce Type","Abstract","Large language models","LLMs","the cognitive core"],"filter_categories":{"healthcare_tech":["HEAL"],"research_academic":["An Empirical Study"],"ai_ml":["Large Language Models","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HEAL":2.0,"An Empirical Study":2.0,"Hallucinations":2.0,"Embodied Agents":2.0,"Large Language Models":2.0,"Announce Type":1.0,"Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"the cognitive core":1.0}},"age_hours":2.7475843791666668,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7903,"joy":0.0078,"surprise":0.0502,"sadness":0.0231,"fear":0.0977,"anger":0.0156,"disgust":0.0152},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper identifies and quantifies hallucinations in LLM-based embodied agents, showing a significant failure rate (up to 40x higher than base prompts) in simulated environments. While the research is valuable for understanding limitations, it is still in the early stages (basic research) and does not directly translate to measurable climate impact or economic viability at this point. The study provides actionable insights for improving model behavior, but these are not yet deployed.","key_impact_metrics":["Hallucination rates up to 40x higher than base prompts"],"technology_tags":["Large Language Models","Embodied Agents","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:42.050173Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_187b1e26a8f0","title":"Revela: Dense Retriever Learning via Language Modeling","content":"arXiv:2506.16552v2 Announce Type: replace Abstract: Dense retrievers play a vital role in accessing external and specialized knowledge to augment language models (LMs). Training dense retrievers typically requires annotated query-document pairs, which are costly to create and scarce in specialized domains (e.g., code) or in complex settings (e.g., requiring reasoning). These practical challenges have sparked growing interest in self-supervised retriever learning. Since LMs are trained to capture token-level dependencies through a self-supervised learning objective (i.e., next token prediction), we can analogously cast retrieval as learning dependencies among chunks of tokens. This analogy naturally leads to the question: How can we adapt self-supervised learning objectives in the spirit of language modeling to train retrievers? To answer this question, we introduce Revela, a unified and scalable training framework for self-supervised retriever learning via language modeling. Revela models semantic dependencies among documents by conditioning next token prediction on local and cross-document context through an in-batch attention mechanism. This attention is weighted by retriever-computed similarity scores, enabling the retriever to be optimized as part of language modeling. We evaluate Revela on domain-specific (CoIR), reasoning-intensive (BRIGHT), and general-domain (BEIR) benchmarks across various retriever backbones. Without annotated or synthetic query-document pairs, Revela surpasses larger supervised models and proprietary APIs on CoIR and matches them on BRIGHT. It achieves BEIR's unsupervised SoTA with ~ 1000x less training data and 10x less compute. Performance increases with batch size and model size, highlighting Revela's scalability and its promise for self-supervised retriever learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.16552","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.605117","language":"en","tags":["preprints","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Fengyu Cai, Tong Chen, Xinran Zhao, Sihao Chen, Hongming Zhang, Sherry Tongshuang Wu, Iryna Gurevych, Heinz Koeppl","raw_content_length":1832,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["Language Modeling arXiv:2506.16552v2"],"persons":["Revela"],"locations":[],"monetary":[]},"char_count":1829,"language_detected":"en","key_concepts":{"key_phrases":["Revela","Dense Retriever Learning","Language Modeling","LMs","Announce Type","Abstract","Dense retrievers","a vital role","external and specialized knowledge","language models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Revela":2.0,"Dense Retriever Learning":2.0,"Language Modeling":2.0,"LMs":2.0,"Announce Type":1.0,"Abstract":1.0,"Dense retrievers":1.0,"a vital role":1.0,"external and specialized knowledge":1.0,"language models":1.0}},"age_hours":2.747627552222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.259500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8519,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8998,"joy":0.0173,"surprise":0.0255,"sadness":0.0065,"fear":0.0141,"anger":0.026,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (Revela) for self-supervised retriever learning, achieving state-of-the-art unsupervised performance on BEIR with 1000x less training data and 10x less compute. This could indirectly impact climate change by improving access to information related to climate solutions and potentially reducing the energy consumption of training large language models. However, it is currently in the research phase with no deployed units.","key_impact_metrics":["1000x less training data","10x less compute"],"technology_tags":["retriever learning","language modeling","self-supervised learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:44:45.321040Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3502911fd11","title":"Riemannian generative decoder","content":"arXiv:2506.19133v2 Announce Type: replace Abstract: Riemannian representation learning typically relies on an encoder to estimate densities on chosen manifolds. This involves optimizing numerically brittle objectives, potentially harming model training and quality. To completely circumvent this issue, we introduce the Riemannian generative decoder, a unifying approach for finding manifold-valued latents on any Riemannian manifold. Latents are learned with a Riemannian optimizer while jointly training a decoder network. By discarding the encoder, we vastly simplify the manifold constraint compared to current approaches which often only handle few specific manifolds. We validate our approach on three case studies -- a synthetic branching diffusion process, human migrations inferred from mitochondrial DNA, and cells undergoing a cell division cycle -- each showing that learned representations respect the prescribed geometry and capture intrinsic non-Euclidean structure. Our method requires only a decoder, is compatible with existing architectures, and yields interpretable latent spaces aligned with data geometry. Code available on https://github.com/yhsure/riemannian-generative-decoder.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.19133","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.605514","language":"en","tags":["preprints","statml","computer-science","cslg","research","q-bioqm","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Andreas Bjerregaard, S{\\o}ren Hauberg, Anders Krogh","raw_content_length":1203,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1202,"language_detected":"en","key_concepts":{"key_phrases":["Riemannian generative decoder","arXiv250619133v2","Announce Type","Abstract","Riemannian representation learning","an encoder","densities","chosen manifolds","numerically brittle objectives","potentially harming model training"],"filter_categories":{"ai_ml":["potentially harming model training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Riemannian generative decoder":2.0,"arXiv250619133v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Riemannian representation learning":1.0,"an encoder":1.0,"densities":1.0,"chosen manifolds":1.0,"numerically brittle objectives":1.0,"potentially harming model training":1.0}},"age_hours":2.747641149166667,"is_recent":true,"quality_score":0.7,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7966,"joy":0.0028,"surprise":0.0174,"sadness":0.0163,"fear":0.0172,"anger":0.1074,"disgust":0.0423},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to representation learning on Riemannian manifolds. While the method itself doesn't directly address climate change, it could potentially be applied to model complex systems relevant to sustainability, such as climate models or resource allocation. The research is at an early stage, with no deployed technology or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Riemannian geometry","Generative models","Machine learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:44:47.859892Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4c59faad7038","title":"KaLM","content":"arXiv:2506.20923v5 Announce Type: replace Abstract: Recent advancements in Large Language Models (LLMs)-based text embedding models primarily focus on data scaling or synthesis, yet limited exploration of training techniques and data quality, thereby constraining performance. In this work, we propose KaLM-Embedding-V2, a series of versatile and compact embedding models, systematically incentivizing advanced embedding capability in LLMs by superior training techniques and high-quality data. For model architecture, we implement the models on a 0.5B compact size with simple mean-pooling to produce fixed-length embeddings and remove the causal attention mask to enable fully bidirectional representation learning. For training techniques, we propose a progressive multi-stage training pipeline: pre-training on weakly supervised large-scale datasets, fine-tuning with supervised high-quality datasets, and contrastive distillation with fine-grained soft signals, integrated with focal-style reweighting and online hard-negative mixing to emphasize difficult samples and enrich hard negatives, respectively. For training data, we curate over 20 categories for pre-training and 100 categories for fine-tuning and contrastive distillation, to improve both performance and generalization, leveraging task-specific instructions, hard-negative mining, and example-based multi-class labeling to ensure high quality. Combining these techniques, our KaLM-Embedding-V2 series achieves state-of-the-art performance on the Massive Text Embedding Benchmark, outperforming models of comparable size and rivaling models 3-26x larger, setting a new standard for versatile and compact embedding models under 1B parameters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.20923","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.611492","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Xin Zhang, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, Min Zhang","raw_content_length":1710,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","0.5B"],"persons":[],"locations":[],"monetary":[]},"char_count":1709,"language_detected":"en","key_concepts":{"key_phrases":["KaLM","arXiv250620923v5 Announce Type","Abstract","Large Language Models","text embedding models","data scaling","synthesis","training techniques","data quality","performance"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"KaLM":2.0,"arXiv250620923v5 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"text embedding models":1.0,"data scaling":1.0,"synthesis":1.0,"training techniques":1.0,"data quality":1.0,"performance":1.0}},"age_hours":2.7476694402777775,"is_recent":true,"quality_score":0.7,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8731,"joy":0.0431,"surprise":0.0399,"sadness":0.0052,"fear":0.0055,"anger":0.0202,"disgust":0.0129},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new text embedding model that is more efficient than existing models. While this could indirectly support sustainability efforts by reducing computational resources needed for AI, there is no direct or quantified climate impact. The model is in the applied research stage, with performance metrics reported on a benchmark, but no real-world deployment data.","key_impact_metrics":["model size with 0.5B parameters","outperforming models 3-26x larger"],"technology_tags":["Large Language Models","Text Embedding Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:44:51.133245Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2d1b0dc2386e","title":"VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents","content":"arXiv:2506.21582v4 Announce Type: replace Abstract: Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.21582","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.611992","language":"en","tags":["preprints","cshc","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Sam Yu-Te Lee, Chenyang Ji, Shicheng Wen, Lifu Huang, Dongyu Liu, Kwan-Liu Ma","raw_content_length":1496,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Interactive Decomposition","Monte-Carlo Tree Search","NLP","Natural Language Processing"],"persons":[],"locations":[],"monetary":[]},"char_count":1495,"language_detected":"en","key_concepts":{"key_phrases":["VIDEE","Visual","Interactive Decomposition","Execution","Evaluation","Text Analytics","Intelligent Agents","NLP","arXiv250621582v4 Announce Type","Abstract"],"filter_categories":{"ai_ml":["NLP"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VIDEE":3.0,"Visual":2.0,"Interactive Decomposition":2.0,"Execution":2.0,"Evaluation":2.0,"Text Analytics":2.0,"Intelligent Agents":2.0,"NLP":2.0,"arXiv250621582v4 Announce Type":1.0,"Abstract":1.0}},"age_hours":2.747684837777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.88,"joy":0.0115,"surprise":0.0544,"sadness":0.0047,"fear":0.0245,"anger":0.0142,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a system (VIDEE) that uses intelligent agents to assist in text analytics. While it could potentially be used to analyze sustainability data and identify areas for improvement, there are no concrete actions or measurable outcomes related to climate change or environmental impact described in the article. The system is in the prototype/pilot stage and lacks deployment data.","key_impact_metrics":["Effectiveness of VIDEE","Usability of VIDEE"],"technology_tags":["Natural Language Processing","Large Language Models","Text Analytics"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:44:53.921470Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_029d2b108dd8","title":"SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space","content":"arXiv:2506.21857v2 Announce Type: replace Abstract: The rapid growth of digital pathology and advances in self-supervised deep learning have enabled the development of foundational models for various pathology tasks across diverse diseases. While multimodal approaches integrating diverse data sources have emerged, a critical gap remains in the comprehensive integration of whole-slide images (WSIs) with spatial transcriptomics (ST), which is crucial for capturing critical molecular heterogeneity beyond standard hematoxylin & eosin (H&E) staining. We introduce SPADE, a foundation model that integrates histopathology with ST data to guide image representation learning within a unified framework, in effect creating an ST-informed latent space. SPADE leverages a mixture-of-data experts technique, where experts are created via two-stage imaging feature-space clustering using contrastive learning to learn representations of co-registered WSI patches and gene expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is evaluated on 20 downstream tasks, demonstrating significantly superior few-shot performance compared to baseline models, highlighting the benefits of integrating morphological and molecular information into one latent space. Code and pretrained weights are available at https://github.com/uclabair/SPADE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.21857","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.612440","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Ekaterina Redekop, Mara Pleasure, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey W. Arnold","raw_content_length":1355,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["H&E","standard hematoxylin & eosin","Spatial Transcriptomics and Pathology Alignment Using"],"persons":[],"locations":[],"monetary":[]},"char_count":1350,"language_detected":"en","key_concepts":{"key_phrases":["SPADE Spatial Transcriptomics and Pathology Alignment","a Mixture","Data Experts","an Expressive Latent Space","arXiv250621857v2 Announce Type","Abstract","The rapid growth","digital pathology","advances","self-supervised deep learning"],"filter_categories":{"ai_ml":["self-supervised deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SPADE Spatial Transcriptomics and Pathology Alignment":2.0,"a Mixture":2.0,"Data Experts":2.0,"an Expressive Latent Space":2.0,"arXiv250621857v2 Announce Type":1.0,"Abstract":1.0,"The rapid growth":1.0,"digital pathology":1.0,"advances":1.0,"self-supervised deep learning":1.0}},"age_hours":2.747699643333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8774,"joy":0.0122,"surprise":0.0643,"sadness":0.0075,"fear":0.0171,"anger":0.0133,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (SPADE) for integrating histopathology with spatial transcriptomics data. The concrete action is the development of a foundation model and its evaluation on 20 downstream tasks, demonstrating superior few-shot performance. However, it is still in the early stages of research and lacks real-world deployment or economic viability.","key_impact_metrics":["superior few-shot performance compared to baseline models"],"technology_tags":["spatial transcriptomics","histopathology","deep learning","foundation model"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:44:57.337377Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ddcfd9fc24e2","title":"Lost at the Beginning of Reasoning","content":"arXiv:2506.22058v2 Announce Type: replace Abstract: Recent advancements in large language models (LLMs) have significantly advanced complex reasoning capabilities, particularly through extended chain-of-thought (CoT) reasoning that incorporates mechanisms such as backtracking, self-reflection, and self-correction. Despite these developments, the self-correction abilities of LLMs during long CoT reasoning remain underexplored. And recent findings on overthinking suggest that such models often engage in unnecessarily redundant reasoning. In this work, we empirically show that the first reasoning step exerts a disproportionately large influence on the final prediction. I.e., errors introduced at this stage can substantially degrade subsequent reasoning quality. This phenomenon is consistently observed across various state-of-the-art open- and closed-source reasoning models. Leveraging this insight, we propose an efficient sampling strategy that leverages a reward model to identify and retain high-quality first reasoning steps while discarding suboptimal ones, achieving up to a 70% reduction in inference cost without sacrificing any accuracy. Our work highlights the central role of the first reasoning step in generating a high-quality reasoning trajectory, and thus enabling significantly efficient sampling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.22058","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.612867","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Baohao Liao, Xinyi Chen, Sara Rajaee, Yuhui Xu, Christian Herold, Anders S{\\o}gaard, Maarten de Rijke, Christof Monz","raw_content_length":1325,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1324,"language_detected":"en","key_concepts":{"key_phrases":["the Beginning","Reasoning","LLMs","Announce Type","Recent advancements","large language models","significantly advanced complex reasoning capabilities","thought","reasoning","mechanisms"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Beginning":2.0,"Reasoning":2.0,"LLMs":2.0,"Announce Type":1.0,"Recent advancements":1.0,"large language models":1.0,"significantly advanced complex reasoning capabilities":1.0,"thought":1.0,"reasoning":1.0,"mechanisms":1.0}},"age_hours":2.747713759722222,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8621,"joy":0.0048,"surprise":0.0628,"sadness":0.0257,"fear":0.0228,"anger":0.0111,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of large language models (LLMs) in reasoning tasks, specifically by optimizing the initial reasoning step. The concrete action is the proposal of an efficient sampling strategy that reduces inference cost by up to 70% without sacrificing accuracy. The evidence supporting this claim comes from empirical observations across various state-of-the-art models, but deployment readiness is low as it's still in the research phase.","key_impact_metrics":["70% reduction in inference cost"],"technology_tags":["Large Language Models","AI Efficiency","Reasoning Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:45:01.068624Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d8c07ee56f74","title":"SAFER: Probing Safety in Reward Models with Sparse Autoencoder","content":"arXiv:2507.00665v2 Announce Type: replace Abstract: Reinforcement learning from human feedback (RLHF) is a key paradigm for aligning large language models (LLMs) with human values, yet the reward models at its core remain largely opaque. In this work, we present sparse Autoencoder For Enhanced Reward model (\\textbf{SAFER}), a novel framework for interpreting and improving reward models through mechanistic analysis. Leveraging Sparse Autoencoders (SAEs), we uncover human-interpretable features in reward model activations, enabling insight into safety-relevant decision-making. We apply SAFER to safety-oriented preference datasets and quantify the salience of individual features by activation differences between chosen and rejected responses. Using these feature-level signals, we design targeted data poisoning and denoising strategies. Experiments show that SAFER can precisely degrade or enhance safety alignment with minimal data modification, without sacrificing general chat performance. Our approach contributes to interpreting, auditing and refining reward models in high-stakes LLM alignment tasks. Our codes are available at https://github.com/xzy-101/SAFER-code. \\textit{This paper discusses topics related to large language model safety and may include discussions or examples that highlight potential risks or unsafe outcomes.}","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.00665","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.613269","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang","raw_content_length":1348,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Autoencoder For Enhanced Reward","Probing Safety in Reward Models"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1347,"language_detected":"en","key_concepts":{"key_phrases":["Probing Safety","Reward Models","arXiv250700665v2 Announce Type","Abstract","Reinforcement learning","human feedback","RLHF","a key paradigm","large language models","LLMs"],"filter_categories":{"ai_ml":["Reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Probing Safety":2.0,"Reward Models":2.0,"arXiv250700665v2 Announce Type":1.0,"Abstract":1.0,"Reinforcement learning":1.0,"human feedback":1.0,"RLHF":1.0,"a key paradigm":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.747728790833333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.908,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9816,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8945,"joy":0.0157,"surprise":0.0284,"sadness":0.0069,"fear":0.0169,"anger":0.0224,"disgust":0.0151},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework (SAFER) for interpreting and improving reward models in LLMs. It uses sparse autoencoders to uncover human-interpretable features and designs data poisoning/denoising strategies. While the research is promising, it's still in the applied research stage with no clear path to economic viability or large-scale deployment, limiting its immediate climate impact.","key_impact_metrics":["activation differences between chosen and rejected responses","minimal data modification"],"technology_tags":["sparse autoencoders","reinforcement learning","large language models"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T16:45:04.451217Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_627052a01394","title":"Dual Perspectives on Non","content":"arXiv:2507.01028v2 Announce Type: replace Abstract: The {\\em stop gradient} and {\\em exponential moving average} iterative procedures are commonly used in non-contrastive approaches to self-supervised learning to avoid representation collapse, with excellent performance in downstream applications in practice. This presentation investigates these procedures from the dual viewpoints of optimization and dynamical systems. We show that, in general, although they {\\em do not} optimize the original objective, or {\\em any} other smooth function, they {\\em do} avoid collapse Following~\\citet{Tian21}, but without any of the extra assumptions used in their proofs, we then show using a dynamical system perspective that, in the linear case, minimizing the original objective function without the use of a stop gradient or exponential moving average {\\em always} leads to collapse. Conversely, we characterize explicitly the equilibria of the dynamical systems associated with these two procedures in this linear setting as algebraic varieties in their parameter space, and show that they are, in general, {\\em asymptotically stable}. Our theoretical findings are illustrated by empirical experiments with real and synthetic data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.01028","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.613686","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Jean Ponce (ENS-PSL, NYU), Basile Terver (FAIR, WILLOW), Martial Hebert (CMU), Michael Arbel (Thoth)","raw_content_length":1228,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["linear"],"persons":[],"locations":[],"monetary":[]},"char_count":1227,"language_detected":"en","key_concepts":{"key_phrases":["Dual Perspectives","Non","Announce Type","Abstract","em exponential moving average iterative procedures","non-contrastive approaches","self-supervised learning","representation collapse","excellent performance","downstream applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dual Perspectives":2.0,"Non":2.0,"Announce Type":1.0,"Abstract":1.0,"em exponential moving average iterative procedures":1.0,"non-contrastive approaches":1.0,"self-supervised learning":1.0,"representation collapse":1.0,"excellent performance":1.0,"downstream applications":1.0}},"age_hours":2.7477431486111112,"is_recent":true,"quality_score":1.0,"sentiment_score":4.0765,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1847,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9141,"joy":0.0321,"surprise":0.024,"sadness":0.006,"fear":0.005,"anger":0.0109,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical findings on optimization procedures used in self-supervised learning. While the research is technically credible and innovative, it is at a very early stage and has no direct, measurable impact on climate change or sustainability in its current form. The paper focuses on theoretical analysis and empirical experiments with synthetic data, not deployed technology or real-world outcomes.","key_impact_metrics":[],"technology_tags":["self-supervised learning","optimization","dynamical systems"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:45:07.636141Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_633dc44d1a10","title":"OmniDraft: A Cross","content":"arXiv:2507.02659v3 Announce Type: replace Abstract: Speculative decoding generally dictates having a small, efficient draft model that is either pretrained or distilled offline to a particular target model series, for instance, Llama or Qwen models. However, within online deployment settings, there are two major challenges: 1) usage of a target model that is incompatible with the draft model; 2) expectation of latency improvements over usage and time. In this work, we propose OmniDraft, a unified framework that enables a single draft model to operate with any target model and adapt dynamically to user data. We introduce an online n-gram cache with hybrid distillation fine-tuning to address the cross-vocabulary mismatch across draft and target models; and further improve decoding speed by leveraging adaptive drafting techniques. OmniDraft is particularly suitable for on-device LLM applications where model cost, efficiency and user customization are the major points of contention. This further highlights the need to tackle the above challenges and motivates the \\textit{``one drafter for all''} paradigm. We showcase the proficiency of the OmniDraft framework by performing online learning on math reasoning, coding and text generation tasks. Notably, OmniDraft enables a single Llama-68M model to pair with various target models including Vicuna-7B, Qwen2-7B and Llama3-8B models for speculative decoding; and additionally provides up to 1.5-2x speedup.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.02659","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.614528","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Shaojie Zhuo, Chen Feng, Yicheng Lin, Chenzheng Su, Xiaopeng Zhang","raw_content_length":1469,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["OmniDraft","Qwen"],"persons":[],"locations":[],"monetary":[]},"char_count":1468,"language_detected":"en","key_concepts":{"key_phrases":["OmniDraft","A Cross","arXiv250702659v3 Announce Type","Abstract","a small efficient draft model","a particular target model series","instance","Llama or Qwen models","online deployment settings","two major challenges"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"OmniDraft":3.0,"A Cross":2.0,"arXiv250702659v3 Announce Type":1.0,"Abstract":1.0,"a small efficient draft model":1.0,"a particular target model series":1.0,"instance":1.0,"Llama or Qwen models":1.0,"online deployment settings":1.0,"two major challenges":1.0}},"age_hours":2.7477725491666667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6801,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8801,"joy":0.0058,"surprise":0.0117,"sadness":0.005,"fear":0.0501,"anger":0.0287,"disgust":0.0185},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"OmniDraft improves the efficiency of large language models, potentially reducing the energy consumption associated with their use. The article mentions a 1.5-2x speedup, which could translate to lower energy usage. However, this is still in the research phase with no deployed units or real-world operational data.","key_impact_metrics":["1.5-2x speedup"],"technology_tags":["speculative decoding","large language models","on-device LLM"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T16:45:23.991672Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f0a6fc57cf6d","title":"Energy","content":"arXiv:2507.04361v2 Announce Type: replace Abstract: We introduce a fast, constrained meshfree solver designed specifically to inherit energy conservation (EC) in second-order time-dependent Hamiltonian wave equations. For discretization, we adopt the Kansa method, also known as the kernel-based collocation method, combined with time-stepping. This approach ensures that the critical structural feature of energy conservation is maintained over time by embedding a quadratic constraint into the definition of the numerical solution. To address the computational challenges posed by the nonlinearity in the Hamiltonian wave equations and the EC constraint, we propose a fast iterative solver based on the Newton method with successive linearization. This novel solver significantly accelerates the computation, making the method highly effective for practical applications. Numerical comparisons with the traditional secant methods highlight the competitive performance of our scheme. These results demonstrate that our method not only conserves the energy but also offers a promising new direction for solving Hamiltonian wave equations more efficiently. While we focus on the Kansa method and corresponding convergence theories in this study, the proposed solver is based solely on linear algebra techniques and has the potential to be applied to EC constrained optimization problems arising from other PDE discretization methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.04361","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.615323","language":"en","tags":["preprints","mathna","csna","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Xiaobin Li, Meng Chen, Zhengjie Sun, Leevan Ling, Siqing Li","raw_content_length":1433,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Kansa"],"persons":[],"locations":["Newton"],"monetary":[]},"char_count":1432,"language_detected":"en","key_concepts":{"key_phrases":["Energy","energy conservation","Announce Type","Abstract","a fast constrained meshfree solver","second-order time-dependent Hamiltonian wave equations","discretization","the Kansa method","the kernel-based collocation method","This approach"],"filter_categories":{"hydrogen_energy":["Energy"],"renewable_energy":["Energy"],"ai_ml":["a fast constrained meshfree solver"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Energy":2.0,"energy conservation":2.0,"Announce Type":1.0,"Abstract":1.0,"a fast constrained meshfree solver":1.0,"second-order time-dependent Hamiltonian wave equations":1.0,"discretization":1.0,"the Kansa method":1.0,"the kernel-based collocation method":1.0,"This approach":1.0}},"age_hours":2.7478007352777776,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9153,"joy":0.0181,"surprise":0.0467,"sadness":0.005,"fear":0.0021,"anger":0.0086,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel solver for Hamiltonian wave equations that conserves energy. While the method shows promising computational performance in numerical comparisons, it is currently in the basic research stage with no deployed applications or economic viability demonstrated. The impact potential is modest as it could improve the efficiency of simulations related to energy systems, but it is not directly reducing emissions.","key_impact_metrics":["Competitive performance compared to secant methods"],"technology_tags":["Meshfree solver","Hamiltonian wave equations","Energy conservation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:45:29.520523Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_70b745d3acb4","title":"Attention-Aware GNN","content":"arXiv:2507.07146v2 Announce Type: replace Abstract: Large Language Models (LLMs) have gained significant traction in various applications, yet their capabilities present risks for both constructive and malicious exploitation. Despite extensive training and fine-tuning efforts aimed at enhancing safety, LLMs remain susceptible to jailbreak attacks. Recently, the emergence of multi-turn attacks has intensified this vulnerability. Unlike single-turn attacks, multi-turn attacks incrementally escalate dialogue complexity, rendering them more challenging to detect and mitigate. In this study, we introduce G-Guard, an innovative attention-aware Graph Neural Network (GNN)-based input classifier specifically designed to defend against multi-turn jailbreak attacks targeting LLMs. G-Guard constructs an entity graph for multi-turn queries, which captures the interrelationships between queries and harmful keywords that present in multi-turn queries. Furthermore, we propose an attention-aware augmentation mechanism that retrieves the most relevant single-turn query based on the ongoing multi-turn conversation. The retrieved query is incorporated as a labeled node within the graph, thereby enhancing the GNN's capacity to classify the current query as harmful or benign. Evaluation results show that G-Guard consistently outperforms all baselines across diverse datasets and evaluation metrics, demonstrating its efficacy as a robust defense mechanism against multi-turn jailbreak attacks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.07146","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.615745","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Zixuan Huang, Kecheng Huang, Lihao Yin, Bowei He, Huiling Zhen, Mingxuan Yuan, Zili Shao","raw_content_length":1496,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["G-Guard","Attention-Aware GNN","Graph Neural Network"],"persons":[],"locations":[],"monetary":[]},"char_count":1493,"language_detected":"en","key_concepts":{"key_phrases":["Attention-Aware GNN","LLMs","Announce Type","Large Language Models","significant traction","various applications","their capabilities","risks","both constructive and malicious exploitation","extensive training and fine-tuning efforts"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Attention-Aware GNN":2.0,"LLMs":2.0,"Announce Type":1.0,"Large Language Models":1.0,"significant traction":1.0,"various applications":1.0,"their capabilities":1.0,"risks":1.0,"both constructive and malicious exploitation":1.0,"extensive training and fine-tuning efforts":1.0}},"age_hours":2.747815846111111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.882,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8236,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3653,"joy":0.0051,"surprise":0.0131,"sadness":0.0226,"fear":0.4846,"anger":0.0893,"disgust":0.02},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel GNN-based input classifier (G-Guard) to defend against multi-turn jailbreak attacks on LLMs. While it demonstrates improved performance compared to baselines, it's currently in the applied research stage with no deployed units or real-world data on its impact on energy consumption or other sustainability metrics. The impact on sustainability is indirect and speculative, as it focuses on cybersecurity rather than direct environmental benefits.","key_impact_metrics":["Improved classification accuracy","Reduced vulnerability to jailbreak attacks"],"technology_tags":["Graph Neural Networks","Large Language Models","Cybersecurity"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T16:45:33.768211Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_14b3c14c6175","title":"OST","content":"arXiv:2507.07984v2 Announce Type: replace Abstract: Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is: https://rbler1234.github.io/OSTBench.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.07984","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.616160","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Jingli Lin, Chenming Zhu, Runsen Xu, Xiaohan Mao, Xihui Liu, Tai Wang, Jiangmiao Pang","raw_content_length":1723,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["OST-Bench","Online","Online Spatio-Temporal","ARKitScenes","OST","ScanNet","Spatio-Temporal"],"persons":["Matterport3D"],"locations":[],"monetary":[]},"char_count":1722,"language_detected":"en","key_concepts":{"key_phrases":["OST","arXiv250707984v2 Announce Type","Abstract","Recent advances","multimodal large language models","MLLMs","remarkable capabilities","vision","language","complex reasoning"],"filter_categories":{"ai_ml":["multimodal large language models","vision","language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"OST":2.0,"arXiv250707984v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"multimodal large language models":1.0,"MLLMs":1.0,"remarkable capabilities":1.0,"vision":1.0,"language":1.0,"complex reasoning":1.0}},"age_hours":2.747830488611111,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7042,"joy":0.0406,"surprise":0.2321,"sadness":0.0033,"fear":0.0055,"anger":0.0107,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark (OST-Bench) for evaluating the spatio-temporal reasoning capabilities of multimodal large language models in embodied perception. While the research is technically sound and uses a dataset of 1.4k scenes and 10k question-answer pairs, it's currently at the basic research stage with no immediate deployment or measurable environmental impact. The potential climate impact is low as it's primarily focused on improving AI algorithms, though improved AI could indirectly help with sustainability in the future.","key_impact_metrics":["1.4k scenes","10k question-answer pairs"],"technology_tags":["multimodal large language models","embodied perception","spatio-temporal reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:45:36.898131Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_18b9400576f8","title":"Knowledge Fusion via Bidirectional Information Aggregation","content":"arXiv:2507.08704v2 Announce Type: replace Abstract: Knowledge graphs (KGs) are the cornerstone of the semantic web, offering up-to-date representations of real-world entities and relations. Yet large language models (LLMs) remain largely static after pre-training, causing their internal knowledge to become outdated and limiting their utility in time-sensitive web applications. To bridge this gap between dynamic knowledge and static models, a prevalent approach is to enhance LLMs with KGs. However, prevailing methods typically rely on parameter-invasive fine-tuning, which risks catastrophic forgetting and often degrades LLMs' general capabilities. Moreover, their static integration frameworks cannot keep pace with the continuous evolution of real-world KGs, hindering their deployment in dynamic web environments. To bridge this gap, we introduce KGA (\\textit{\\underline{K}nowledge \\underline{G}raph-guided \\underline{A}ttention}), a novel framework that dynamically integrates external KGs into LLMs exclusively at inference-time without any parameter modification. Inspired by research on neuroscience, we rewire the self-attention module by innovatively introducing two synergistic pathways: a \\textit{bottom-up knowledge fusion} pathway and a \\textit{top-down attention guidance} pathway. The \\textit{bottom-up pathway} dynamically integrates external knowledge into input representations via input-driven KG fusion, which is akin to the \\textit{stimulus-driven attention process} in the human brain. Complementarily, the \\textit{top-down pathway} aims to assess the contextual relevance of each triple through a \\textit{goal-directed verification process}, thereby suppressing task-irrelevant signals and amplifying knowledge-relevant patterns. By synergistically combining these two pathways, our method supports real-time knowledge fusion. Extensive experiments on four benchmarks verify KGA's strong fusion performance and efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.08704","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.621773","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Songlin Zhai, Guilin Qi, Yue Wang, Yuan Meng","raw_content_length":1952,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["Bidirectional Information Aggregation arXiv:2507.08704v2","Knowledge Fusion","KGA"],"persons":[],"locations":[],"monetary":[]},"char_count":1951,"language_detected":"en","key_concepts":{"key_phrases":["Knowledge Fusion","Bidirectional Information Aggregation","KGs","LLMs","arXiv250708704v2","Announce Type","Abstract","Knowledge graphs","the cornerstone","the semantic web"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Knowledge Fusion":2.0,"Bidirectional Information Aggregation":2.0,"KGs":2.0,"LLMs":2.0,"arXiv250708704v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Knowledge graphs":1.0,"the cornerstone":1.0,"the semantic web":1.0}},"age_hours":2.747845613611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9389,"joy":0.0042,"surprise":0.028,"sadness":0.0099,"fear":0.0042,"anger":0.0091,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (KGA) for integrating knowledge graphs into large language models to improve their accuracy and reduce reliance on outdated information. While the research shows strong fusion performance and efficiency on benchmarks, it is still in the basic research phase with no clear path to economic viability or deployment readiness. The climate impact is indirect, relying on the potential for improved decision-making in climate-related applications.","key_impact_metrics":["Strong fusion performance on four benchmarks","Efficiency of knowledge integration"],"technology_tags":["Knowledge Graphs","Large Language Models","Artificial Intelligence"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:45:40.125269Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c68985fa14e7","title":"Feature Distillation is the Better Choice for Model","content":"arXiv:2507.10348v3 Announce Type: replace Abstract: Model-Heterogeneous Federated Learning (Hetero-FL) has attracted growing attention for its ability to aggregate knowledge from heterogeneous models while keeping private data locally. To better aggregate knowledge from clients, ensemble distillation, as a widely used and effective technique, is often employed after global aggregation to enhance the performance of the global model. However, simply combining Hetero-FL and ensemble distillation does not always yield promising results and can make the training process unstable. The reason is that existing methods primarily focus on logit distillation, which, while being model-agnostic with softmax predictions, fails to compensate for the knowledge bias arising from heterogeneous models. To tackle this challenge, we propose a stable and efficient Feature Distillation for model-heterogeneous Federated learning, dubbed FedFD, that can incorporate aligned feature information via orthogonal projection to integrate knowledge from heterogeneous models better. Specifically, a new feature-based ensemble federated knowledge distillation paradigm is proposed. The global model on the server needs to maintain a projection layer for each client-side model architecture to align the features separately. Orthogonal techniques are employed to re-parameterize the projection layer to mitigate knowledge bias from heterogeneous models and thus maximize the distilled knowledge. Extensive experiments show that FedFD achieves superior performance compared to state-of-the-art methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.10348","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.622242","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Yichen Li, Xiuying Wang, Wenchao Xu, Haozhao Wang, Yining Qi, Jiahua Dong, Ruixuan Li","raw_content_length":1583,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["Feature Distillation","Federated","Hetero-FL","the Better Choice for Model arXiv:2507.10348v3 Announce Type:","Model-Heterogeneous Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1582,"language_detected":"en","key_concepts":{"key_phrases":["Feature Distillation","the Better Choice","Model","knowledge","arXiv250710348v3 Announce Type","Abstract","Model-Heterogeneous Federated Learning","Hetero-FL","growing attention","its ability"],"filter_categories":{"ai_ml":["Model"],"business_innovation":["Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Feature Distillation":2.0,"the Better Choice":2.0,"Model":2.0,"knowledge":2.0,"arXiv250710348v3 Announce Type":1.0,"Abstract":1.0,"Model-Heterogeneous Federated Learning":1.0,"Hetero-FL":1.0,"growing attention":1.0,"its ability":1.0}},"age_hours":2.7478599105555555,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6435,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9287,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9239,"joy":0.0283,"surprise":0.0303,"sadness":0.0032,"fear":0.0028,"anger":0.0071,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (FedFD) to feature distillation in federated learning, aiming to improve model aggregation and stability. While the approach is supported by 'extensive experiments' suggesting superior performance, the lack of information on deployment and real-world data limits the assessment of its actual impact. The technology is in the applied research phase, with no indication of commercial readiness or deployment.","key_impact_metrics":["Superior performance compared to state-of-the-art methods"],"technology_tags":["Federated Learning","Feature Distillation","Orthogonal Projection"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:45:43.522669Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f073817e0f56","title":"GTPBD: A Fine","content":"arXiv:2507.14697v2 Announce Type: replace Abstract: Agricultural parcels serve as basic units for conducting agricultural practices and applications, which is vital for land ownership registration, food security assessment, soil erosion monitoring, etc. However, existing agriculture parcel extraction studies only focus on mid-resolution mapping or regular plain farmlands while lacking representation of complex terraced terrains due to the demands of precision agriculture.In this paper, we introduce a more fine-grained terraced parcel dataset named GTPBD (Global Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset covering major worldwide terraced regions with more than 200,000 complex terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution images with three-level labels, including pixel-level boundary labels, mask labels, and parcel labels. It covers seven major geographic zones in China and transcontinental climatic regions around the world.Compared to the existing datasets, the GTPBD dataset brings considerable challenges due to the: (1) terrain diversity; (2) complex and irregular parcel objects; and (3) multiple domain styles. Our proposed GTPBD dataset is suitable for four different tasks, including semantic segmentation, edge detection, terraced parcel extraction, and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the GTPBD dataset on eight semantic segmentation methods, four edge extraction methods, three parcel extraction methods, and five UDA methods, along with a multi-dimensional evaluation framework integrating pixel-level and object-level metrics. GTPBD fills a critical gap in terraced remote sensing research, providing a basic infrastructure for fine-grained agricultural terrain analysis and cross-scenario knowledge transfer.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.14697","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.622731","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":238,"author":"Zhiwei Zhang, Zi Ye, Yibin Wen, Shuai Yuan, Haohuan Fu, Jianxi Huang, Juepeng Zheng","raw_content_length":1842,"priority":7,"update_frequency":1,"reading_time_minutes":1.19,"robust_parsing_used":true,"entities":{"organizations":["Global Terraced Parcel","GTPBD"],"persons":["GTPBD"],"locations":["China"],"monetary":[]},"char_count":1841,"language_detected":"en","key_concepts":{"key_phrases":["GTPBD","arXiv250714697v2 Announce Type","Abstract","Agricultural parcels","basic units","agricultural practices","applications","which","land ownership registration food security assessment","soil erosion monitoring"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GTPBD":2.0,"arXiv250714697v2 Announce Type":1.0,"Abstract":1.0,"Agricultural parcels":1.0,"basic units":1.0,"agricultural practices":1.0,"applications":1.0,"which":1.0,"land ownership registration food security assessment":1.0,"soil erosion monitoring":1.0}},"age_hours":2.7478743494444444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7641,"joy":0.0536,"surprise":0.0229,"sadness":0.0211,"fear":0.0181,"anger":0.1011,"disgust":0.0191},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article introduces a new dataset (GTPBD) for fine-grained analysis of terraced agricultural parcels. While the dataset itself doesn't directly reduce emissions, it enables more precise monitoring of agricultural practices, which could indirectly support sustainable land management. The technical credibility is relatively high due to the benchmarked methods and multi-dimensional evaluation framework, but the economic viability and deployment readiness are low as it's primarily a research dataset at this stage.","key_impact_metrics":["200,000+ complex terraced parcels","47,537 high-resolution images"],"technology_tags":["remote sensing","image analysis","agricultural monitoring"],"sdg_alignment":[2,15],"analyzed_at":"2025-10-29T16:45:46.706336Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0fea153d4853","title":"FENIX: Enabling In","content":"arXiv:2507.14891v3 Announce Type: replace Abstract: Machine learning (ML) is increasingly used in network data planes for advanced traffic analysis, but existing solutions (such as FlowLens, N3IC, BoS) still struggle to simultaneously achieve low latency, high throughput, and high accuracy. To address these challenges, we present FENIX, a hybrid in-network ML system that performs feature extraction on programmable switch ASICs and deep neural network inference on FPGAs. FENIX introduces a Data Engine that leverages a probabilistic token bucket algorithm to control the sending rate of feature streams, effectively addressing the throughput gap between programmable switch ASICs and FPGAs. In addition, FENIX designs a Model Engine to enable high-accuracy deep neural network inference in the network, overcoming the difficulty of deploying complex models on resource-constrained switch chips. We implement FENIX on a programmable switch platform that integrates a Tofino ASIC and a ZU19EG FPGA directly, and evaluate it on real-world network traffic datasets. Our results show that FENIX achieves microsecond-level inference latency and multi-terabit throughput with low hardware overhead, and delivers over 90% accuracy on mainstream network traffic classification tasks, outperforming the state of the art.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.14891","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.623157","language":"en","tags":["preprints","csni","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Xiangyu Gao (Tsinghua University), Tong Li (Renmin University of China), Yinchao Zhang (Tsinghua University), Ziqiang Wang (Southeast University), Xiangsheng Zeng (Huazhong University of Science and Technology), Su Yao (Tsinghua University), Ke Xu (Tsinghua University)","raw_content_length":1315,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Model Engine","Data Engine","FENIX","BoS"],"persons":[],"locations":[],"monetary":[]},"char_count":1314,"language_detected":"en","key_concepts":{"key_phrases":["FENIX","Announce Type","Machine learning","network data planes","advanced traffic analysis","existing solutions","FlowLens","N3IC","BoS","low latency"],"filter_categories":{"ai_ml":["Machine learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FENIX":4.0,"Announce Type":1.0,"Machine learning":1.0,"network data planes":1.0,"advanced traffic analysis":1.0,"existing solutions":1.0,"FlowLens":1.0,"N3IC":1.0,"BoS":1.0,"low latency":1.0}},"age_hours":2.7478894499999997,"is_recent":true,"quality_score":1.0,"sentiment_score":3.091,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3818,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7345,"joy":0.0098,"surprise":0.0141,"sadness":0.0132,"fear":0.152,"anger":0.0514,"disgust":0.0251},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":5,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed system (FENIX) using programmable switch ASICs and FPGAs for network traffic analysis. It presents measured outcomes such as microsecond-level inference latency, multi-terabit throughput, and over 90% accuracy on traffic classification. While promising, the impact on climate is indirect (more efficient networks) and the system is still in a pilot stage.","key_impact_metrics":["microsecond-level inference latency","multi-terabit throughput"],"technology_tags":["machine learning","network traffic analysis","FPGA","ASIC"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:45:50.589631Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5a7819c7dc03","title":"Finding Dori: Memorization in Text","content":"arXiv:2507.16880v2 Announce Type: replace Abstract: Text-to-image diffusion models (DMs) have achieved remarkable success in image generation. However, concerns about data privacy and intellectual property remain due to their potential to inadvertently memorize and replicate training data. Recent mitigation efforts have focused on identifying and pruning weights responsible for triggering verbatim training data replication, based on the assumption that memorization can be localized. We challenge this assumption and demonstrate that, even after such pruning, small perturbations to the text embeddings of previously mitigated prompts can re-trigger data replication, revealing the fragility of such defenses. Our further analysis then provides multiple indications that memorization is indeed not inherently local: (1) replication triggers for memorized images are distributed throughout text embedding space; (2) embeddings yielding the same replicated image produce divergent model activations; and (3) different pruning methods identify inconsistent sets of memorization-related weights for the same image. Finally, we show that bypassing the locality assumption enables more robust mitigation through adversarial fine-tuning. These findings provide new insights into the nature of memorization in text-to-image DMs and inform the development of more reliable mitigations against DM memorization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.16880","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.623622","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Antoni Kowalczuk, Dominik Hintersdorf, Lukas Struppek, Kristian Kersting, Adam Dziedzic, Franziska Boenisch","raw_content_length":1405,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1404,"language_detected":"en","key_concepts":{"key_phrases":["Finding Dori","Memorization","Text","arXiv250716880v2 Announce Type","image","DMs","remarkable success","image generation","concerns","data privacy"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Finding Dori":2.0,"Memorization":2.0,"Text":2.0,"arXiv250716880v2 Announce Type":1.0,"image":1.0,"DMs":1.0,"remarkable success":1.0,"image generation":1.0,"concerns":1.0,"data privacy":1.0}},"age_hours":2.747903916666667,"is_recent":true,"quality_score":0.7,"sentiment_score":9.691,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9382,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6606,"joy":0.0067,"surprise":0.0134,"sadness":0.0176,"fear":0.2222,"anger":0.061,"disgust":0.0186},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on the security and privacy vulnerabilities of text-to-image diffusion models, specifically their tendency to memorize and replicate training data. While not directly related to climate impact, it has indirect relevance as AI models become more prevalent in climate modeling and mitigation efforts. The research is in the early stages, focusing on identifying and mitigating these vulnerabilities through adversarial fine-tuning.","key_impact_metrics":[],"technology_tags":["text-to-image diffusion models","AI security","data privacy"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:45:54.200592Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_477344dddf92","title":"Reconstruction of SINR Maps from Sparse Measurements using Group Equivariant Non","content":"arXiv:2507.19349v2 Announce Type: replace Abstract: As sixth generation (6G) wireless networks evolve, accurate signal-to-interference-noise ratio (SINR) maps are becoming increasingly critical for effective resource management and optimization. However, acquiring such maps at high resolution is often cost-prohibitive, creating a severe data scarcity challenge. This necessitates machine learning (ML) approaches capable of robustly reconstructing the full map from extremely sparse measurements. To address this, we introduce a novel reconstruction framework based on Group Equivariant Non-Expansive Operators (GENEOs). Unlike data-hungry ML models, GENEOs are low-complexity operators that embed domain-specific geometric priors, such as translation invariance, directly into their structure. This provides a strong inductive bias, enabling effective reconstruction from very few samples. Our key insight is that for network management, preserving the topological structure of the SINR map, such as the geometry of coverage holes and interference patterns, is often more critical than minimizing pixel-wise error. We validate our approach on realistic ray-tracing-based urban scenarios, evaluating performance with both traditional statistical metrics (mean squared error (MSE)) and, crucially, a topological metric (1-Wasserstein distance). Results show that while maintaining competitive MSE, our method dramatically outperforms established ML baselines in topological fidelity. This demonstrates the practical advantage of GENEOs for creating structurally accurate SINR maps that are more reliable for downstream network optimization tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.19349","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.624075","language":"en","tags":["preprints","csni","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Lorenzo Mario Amorosa, Francesco Conti, Nicola Quercioli, Flavio Zabini, Tayebeh Lotfi Mahyari, Yiqun Ge, Patrizio Frosini","raw_content_length":1648,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["Reconstruction of SINR Maps","Group Equivariant Non-Expansive Operators","Group Equivariant Non arXiv:2507.19349v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1647,"language_detected":"en","key_concepts":{"key_phrases":["Reconstruction","SINR Maps","Sparse Measurements","Group Equivariant Non","Announce Type","Abstract","interference-noise","SINR","effective resource management","optimization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reconstruction":2.0,"SINR Maps":2.0,"Sparse Measurements":2.0,"Group Equivariant Non":2.0,"Announce Type":1.0,"Abstract":1.0,"interference-noise":1.0,"SINR":1.0,"effective resource management":1.0,"optimization":1.0}},"age_hours":2.747918855,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8468,"joy":0.0084,"surprise":0.0344,"sadness":0.0155,"fear":0.053,"anger":0.0331,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel machine learning approach (GENEOs) for reconstructing SINR maps, which can improve resource management in 6G networks. This could lead to more efficient energy use in wireless communication. The approach is validated on realistic urban scenarios, with performance evaluated using MSE and 1-Wasserstein distance, but it is still in the research/prototype phase.","key_impact_metrics":["MSE","1-Wasserstein distance"],"technology_tags":["6G wireless networks","machine learning","signal processing","resource management"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:45:59.273342Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2a126dc26f72","title":"A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers","content":"arXiv:2507.22337v3 Announce Type: replace Abstract: Understanding and solving complex reasoning tasks is vital for addressing the information needs of a user. Although dense neural models learn contextualised embeddings, they still underperform on queries containing negation. To understand this phenomenon, we study negation in both traditional neural information retrieval and LLM-based models. We (1) introduce a taxonomy of negation that derives from philosophical, linguistic, and logical definitions; (2) generate two benchmark datasets that can be used to evaluate the performance of neural information retrieval models and to fine-tune models for a more robust performance on negation; and (3) propose a logic-based classification mechanism that can be used to analyze the performance of retrieval models on existing datasets. Our taxonomy produces a balanced data distribution over negation types, providing a better training setup that leads to faster convergence on the NevIR dataset. Moreover, we propose a classification schema that reveals the coverage of negation types in existing datasets, offering insights into the factors that might affect the generalization of fine-tuned models on negation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.22337","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.624915","language":"en","tags":["preprints","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Roxana Petcu, Samarth Bhargav, Maarten de Rijke, Evangelos Kanoulas","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["NLP","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["negation","A Comprehensive Taxonomy","Negation","NLP","Neural Retrievers","arXiv250722337v3 Announce Type","Abstract","complex reasoning tasks","the information needs","a user"],"filter_categories":{"ai_ml":["NLP"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"negation":3.0,"A Comprehensive Taxonomy":2.0,"Negation":2.0,"NLP":2.0,"Neural Retrievers":2.0,"arXiv250722337v3 Announce Type":1.0,"Abstract":1.0,"complex reasoning tasks":1.0,"the information needs":1.0,"a user":1.0}},"age_hours":2.747947232777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8855,"joy":0.0079,"surprise":0.0356,"sadness":0.0082,"fear":0.0192,"anger":0.0225,"disgust":0.0211},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a taxonomy and datasets to improve negation handling in NLP models. While improved NLP could indirectly support sustainability by enabling better information retrieval and analysis related to climate change, there are no concrete actions or measurable outcomes directly reducing GHG emissions or promoting sustainability. The research is in an early stage, focused on dataset creation and model fine-tuning.","key_impact_metrics":[],"technology_tags":["Natural Language Processing","Neural Information Retrieval"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:46:01.859160Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3c4a7775ef4a","title":"Capturing More: Learning Multi","content":"arXiv:2508.01427v2 Announce Type: replace Abstract: In this paper, we propose SPECTRUM, a temporal-frequency synergistic model that unlocks the untapped potential of multi-domain representation learning for online handwriting verification (OHV). SPECTRUM comprises three core components: (1) a multi-scale interactor that finely combines temporal and frequency features through dual-modal sequence interaction and multi-scale aggregation, (2) a self-gated fusion module that dynamically integrates global temporal and frequency features via self-driven balancing. These two components work synergistically to achieve micro-to-macro spectral-temporal integration. (3) A multi-domain distance-based verifier then utilizes both temporal and frequency representations to improve discrimination between genuine and forged handwriting, surpassing conventional temporal-only approaches. Extensive experiments demonstrate SPECTRUM's superior performance over existing OHV methods, underscoring the effectiveness of temporal-frequency multi-domain learning. Furthermore, we reveal that incorporating multiple handwritten biometrics fundamentally enhances the discriminative power of handwriting representations and facilitates verification. These findings not only validate the efficacy of multi-domain learning in OHV but also pave the way for future research in multi-domain approaches across both feature and biometric domains. Code is publicly available at https://github.com/NiceRingNode/SPECTRUM.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.01427","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.625775","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Peirong Zhang, Kai Ding, Lianwen Jin","raw_content_length":1494,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["SPECTRUM"],"persons":[],"locations":[],"monetary":[]},"char_count":1493,"language_detected":"en","key_concepts":{"key_phrases":["Learning Multi","SPECTRUM","arXiv250801427v2 Announce Type","Abstract","this paper","a temporal-frequency synergistic model","the untapped potential","multi-domain representation learning","online handwriting verification","OHV"],"filter_categories":{"ai_ml":["multi-domain representation learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Learning Multi":2.0,"SPECTRUM":2.0,"arXiv250801427v2 Announce Type":1.0,"Abstract":1.0,"this paper":1.0,"a temporal-frequency synergistic model":1.0,"the untapped potential":1.0,"multi-domain representation learning":1.0,"online handwriting verification":1.0,"OHV":1.0}},"age_hours":2.747975935,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8818,"joy":0.0491,"surprise":0.0488,"sadness":0.0031,"fear":0.0038,"anger":0.01,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to online handwriting verification using multi-domain learning. While the research demonstrates superior performance over existing methods, it is currently in the basic research stage with no deployed units or real-world data related to sustainability. The impact on climate change is minimal, as it's primarily focused on improving handwriting verification accuracy.","key_impact_metrics":["Superior performance over existing OHV methods","Effectiveness of temporal-frequency multi-domain learning"],"technology_tags":["Multi-domain representation learning","Online handwriting verification"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:46:04.928964Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3af9dbc8cc1","title":"mmWave Radar-Based Non-Line-of","content":"arXiv:2508.02348v2 Announce Type: replace Abstract: Pedestrians Localization in Non-Line-of-Sight (NLoS) regions within urban environments poses a significant challenge for autonomous driving systems. While mmWave radar has demonstrated potential for detecting objects in such scenarios, the 2D radar point cloud (PCD) data is susceptible to distortions caused by multipath reflections, making accurate spatial inference difficult. Additionally, although camera images provide high-resolution visual information, they lack depth perception and cannot directly observe objects in NLoS regions. In this paper, we propose a novel framework that interprets radar PCD through road layout inferred from camera for localization of NLoS pedestrians. The proposed method leverages visual information from the camera to interpret 2D radar PCD, enabling spatial scene reconstruction. The effectiveness of the proposed approach is validated through experiments conducted using a radar-camera system mounted on a real vehicle. The localization performance is evaluated using a dataset collected in outdoor NLoS driving environments, demonstrating the practical applicability of the method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.02348","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.626611","language":"en","tags":["preprints","csai","computer-science","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Byeonggyu Park, Hee-Yeun Kim, Byonghyok Choi, Hansang Cho, Byungkwan Kim, Soomok Lee, Mingu Jeon, Seong-Woo Kim","raw_content_length":1177,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Radar-Based Non-Line-of arXiv:2508.02348v2 Announce Type: replace Abstract","NLoS"],"persons":[],"locations":["NLoS"],"monetary":[]},"char_count":1176,"language_detected":"en","key_concepts":{"key_phrases":["mmWave","Non-Line","Announce Type","Abstract","Pedestrians Localization","of-Sight NLoS","urban environments","a significant challenge","autonomous driving systems","mmWave radar"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"mmWave":2.0,"Non-Line":2.0,"Announce Type":1.0,"Abstract":1.0,"Pedestrians Localization":1.0,"of-Sight NLoS":1.0,"urban environments":1.0,"a significant challenge":1.0,"autonomous driving systems":1.0,"mmWave radar":1.0}},"age_hours":2.7480052341666665,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7772,"joy":0.0062,"surprise":0.0287,"sadness":0.0415,"fear":0.0894,"anger":0.0218,"disgust":0.0353},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method for pedestrian localization using radar and camera data, which could improve the safety and efficiency of autonomous vehicles. This has a modest potential to reduce emissions by optimizing traffic flow and reducing accidents, but the impact is theoretical at this stage. The method is validated through experiments, providing some evidence, but lacks peer review and widespread deployment.","key_impact_metrics":["Localization performance in NLoS environments","Accuracy of spatial scene reconstruction"],"technology_tags":["mmWave radar","autonomous driving","computer vision"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:46:08.718325Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f0cae57f132a","title":"DMSC: Dynamic Multi","content":"arXiv:2508.02753v3 Announce Type: replace Abstract: Time Series Forecasting (TSF) faces persistent challenges in modeling intricate temporal dependencies across different scales. Despite recent advances leveraging different decomposition operations and novel architectures based on CNN, MLP or Transformer, existing methods still struggle with static decomposition strategies, fragmented dependency modeling, and inflexible fusion mechanisms, limiting their ability to model intricate temporal dependencies. To explicitly solve the mentioned three problems respectively, we propose a novel Dynamic Multi-Scale Coordination Framework (DMSC) with Multi-Scale Patch Decomposition block (EMPD), Triad Interaction Block (TIB) and Adaptive Scale Routing MoE block (ASR-MoE). Specifically, EMPD is designed as a built-in component to dynamically segment sequences into hierarchical patches with exponentially scaled granularities, eliminating predefined scale constraints through input-adaptive patch adjustment. TIB then jointly models intra-patch, inter-patch, and cross-variable dependencies within each layer's decomposed representations. EMPD and TIB are jointly integrated into layers forming a multi-layer progressive cascade architecture, where coarse-grained representations from earlier layers adaptively guide fine-grained feature extraction in subsequent layers via gated pathways. And ASR-MoE dynamically fuses multi-scale predictions by leveraging specialized global and local experts with temporal-aware weighting. Comprehensive experiments on thirteen real-world benchmarks demonstrate that DMSC consistently maintains state-of-the-art (SOTA) performance and superior computational efficiency for TSF tasks. Code is available at https://github.com/1327679995/DMSC.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.02753","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.632206","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Haonan Yang, Jianchao Tang, Zhuo Li, Long Lan","raw_content_length":1774,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["Multi-Scale Patch Decomposition","Time Series Forecasting","TSF","EMPD","Dynamic Multi-Scale Coordination Framework","CNN","Dynamic Multi arXiv:2508.02753v3 Announce","TIB","DMSC","Adaptive Scale Routing MoE","Triad Interaction Block","Transformer","ASR-MoE"],"persons":[],"locations":[],"monetary":[]},"char_count":1773,"language_detected":"en","key_concepts":{"key_phrases":["DMSC","Dynamic Multi","arXiv250802753v3 Announce Type","Time Series Forecasting","TSF","persistent challenges","intricate temporal dependencies","different scales","recent advances","different decomposition operations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DMSC":2.0,"Dynamic Multi":2.0,"arXiv250802753v3 Announce Type":1.0,"Time Series Forecasting":1.0,"TSF":1.0,"persistent challenges":1.0,"intricate temporal dependencies":1.0,"different scales":1.0,"recent advances":1.0,"different decomposition operations":1.0}},"age_hours":2.7480185894444444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9007,"joy":0.0038,"surprise":0.0298,"sadness":0.0158,"fear":0.0253,"anger":0.0168,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (DMSC) for time series forecasting, claiming superior computational efficiency and state-of-the-art performance on real-world benchmarks. The concrete action is the development of a new algorithm, but it's still in the research phase with no deployment. The evidence is based on experiments on thirteen real-world benchmarks, but lacks independent verification or deployment data.","key_impact_metrics":["Superior computational efficiency","State-of-the-art performance"],"technology_tags":["Time Series Forecasting","Machine Learning","Dynamic Multi-Scale Coordination Framework"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:46:11.711556Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0704edbd2f51","title":"Macro-from","content":"arXiv:2508.03334v3 Announce Type: replace Abstract: Current autoregressive diffusion models excel at video generation but are generally limited to short temporal durations. Our theoretical analysis indicates that the autoregressive modeling typically suffers from temporal drift caused by error accumulation and hinders parallelization in long video synthesis. To address these limitations, we propose a novel planning-then-populating framework centered on Macro-from-Micro Planning (MMPL) for long video generation. MMPL sketches a global storyline for the entire video through two hierarchical stages: Micro Planning and Macro Planning. Specifically, Micro Planning predicts a sparse set of future keyframes within each short video segment, offering motion and appearance priors to guide high-quality video segment generation. Macro Planning extends the in-segment keyframes planning across the entire video through an autoregressive chain of micro plans, ensuring long-term consistency across video segments. Subsequently, MMPL-based Content Populating generates all intermediate frames in parallel across segments, enabling efficient parallelization of autoregressive generation. The parallelization is further optimized by Adaptive Workload Scheduling for balanced GPU execution and accelerated autoregressive video generation. Extensive experiments confirm that our method outperforms existing long video generation models in quality and stability. Generated videos and comparison results are in our project page.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.03334","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.632672","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Xunzhi Xiang, Yabo Chen, Guiyu Zhang, Zhongyu Wang, Zhe Gao, Quanming Xiang, Gonghu Shang, Junqi Liu, Haibin Huang, Yang Gao, Chi Zhang, Qi Fan, Xuelong Li","raw_content_length":1520,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Micro Planning","Macro Planning","Macro","Micro Planning and Macro Planning"],"persons":[],"locations":[],"monetary":[]},"char_count":1519,"language_detected":"en","key_concepts":{"key_phrases":["Macro","Announce Type","Current autoregressive diffusion models","video generation","short temporal durations","Our theoretical analysis","the autoregressive modeling","temporal drift","error accumulation","parallelization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Macro":2.0,"Announce Type":1.0,"Current autoregressive diffusion models":1.0,"video generation":1.0,"short temporal durations":1.0,"Our theoretical analysis":1.0,"the autoregressive modeling":1.0,"temporal drift":1.0,"error accumulation":1.0,"parallelization":1.0}},"age_hours":2.7480326927777776,"is_recent":true,"quality_score":1.0,"sentiment_score":1.3655,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7269,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7562,"joy":0.0103,"surprise":0.063,"sadness":0.1067,"fear":0.0275,"anger":0.0177,"disgust":0.0186},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for long video generation, but there are no concrete actions or measurable outcomes related to sustainability. The research is in the early stages, with no deployed units or real-world data to assess its impact on climate change or other sustainability dimensions. The potential for energy savings from efficient parallelization is theoretical at this point.","key_impact_metrics":[],"technology_tags":["autoregressive diffusion models","video generation","parallelization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:46:14.450720Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_66df6eadafea","title":"EMSEdit: Efficient Multi-Step Meta","content":"arXiv:2508.04012v2 Announce Type: replace Abstract: Large Language Models (LLMs) power numerous AI applications, yet updating their knowledge remains costly. Model editing provides a lightweight alternative through targeted parameter modifications, with meta-learning-based model editing (MLME) demonstrating strong effectiveness and efficiency. However, we find that MLME struggles in low-data regimes and incurs high training costs due to the use of KL divergence. To address these issues, we propose $\\textbf{E}$fficient $\\textbf{M}$ulti-$\\textbf{S}$tep $\\textbf{Edit (EMSEdit)}$, which leverages multi-step backpropagation (MSBP) to effectively capture gradient-activation mapping patterns within editing samples, performs multi-step edits per sample to enhance editing performance under limited data, and introduces norm-based regularization to preserve unedited knowledge while improving training efficiency. Experiments on two datasets and three LLMs show that EMSEdit consistently outperforms state-of-the-art methods in both sequential and batch editing. Moreover, MSBP can be seamlessly integrated into existing approaches to yield additional performance gains. Further experiments on a multi-hop reasoning editing task demonstrate EMSEdit's robustness in handling complex edits, while ablation studies validate the contribution of each design component. Our code is available at https://github.com/xpq-tech/emsedit.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.04012","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.633097","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Xiaopeng Li, Shasha Li, Xi Wang, Shezheng Song, Bin Ji, Shangwen Wang, Jun Ma, Xiaodong Liu, Mina Liu, Jie Yu","raw_content_length":1427,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["MLME","Efficient Multi-Step Meta arXiv:2508.04012v2 Announce Type: replace"],"persons":[],"locations":[],"monetary":["$\\textbf{E}$fficient $\\textbf{M}$ulti-$\\textbf{S}$tep $"]},"char_count":1426,"language_detected":"en","key_concepts":{"key_phrases":["EMSEdit Efficient Multi-Step Meta","Announce Type","Abstract","LLMs","their knowledge","Model editing","a lightweight alternative","targeted parameter modifications","meta-learning-based model editing","MLME"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EMSEdit Efficient Multi-Step Meta":2.0,"Announce Type":1.0,"Abstract":1.0,"LLMs":1.0,"their knowledge":1.0,"Model editing":1.0,"a lightweight alternative":1.0,"targeted parameter modifications":1.0,"meta-learning-based model editing":1.0,"MLME":1.0}},"age_hours":2.748047963888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.871,"joy":0.0053,"surprise":0.0197,"sadness":0.0664,"fear":0.005,"anger":0.0141,"disgust":0.0186},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (EMSEdit) for efficiently updating knowledge in large language models, which could indirectly contribute to sustainability by reducing the computational resources required for AI development. The article provides experimental results demonstrating the method's effectiveness, but it is still in the applied research stage with no deployed units or operational data. The vaporware flag is raised due to the lack of deployment.","key_impact_metrics":["Performance gains on sequential and batch editing","Training efficiency improvements"],"technology_tags":["Large Language Models","Meta-Learning","Model Editing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:46:17.341036Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a83cac90c351","title":"Adaptive Decentralized Queue Disclosure for Impatient Tenants in Edge and Non","content":"arXiv:2508.04241v2 Announce Type: replace Abstract: We study how queue-state information disclosures affect impatient tenants in multi-tenant edge systems. We propose an information-bulletin strategy in which each queue periodically broadcasts two Markov models. One is a model of steady-state service-rate behavior and the other a model of the queue length inter-change times. Tenants autonomously decide to renege or jockey based on this information. The queues observe tenant responses and adapt service rates via a learned, rule-based predictive policy designed for decentralized, partially-observed, and time-varying environments. We compare this decentralized, information-driven policy to the classical, centralized Markov Decision Process (MDP) hedging-point policy for M/M/2 systems. Numerical experiments quantify the tradeoffs in average delay, impatience and robustness to stale information. Results show that when full, instantaneous state information and stationarity hold, the hedging-point policy yields less impatience but this diminishes as information becomes partial or stale. The rule-based predictive policy on the other hand is more robust to staleness in dispatched information, making it conducive for conditions typical of edge cloud and non-terrestrial deployments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.04241","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.633502","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Anthony Kiggundu, Bin Han, Hans D. Schotten","raw_content_length":1293,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Non arXiv:2508.04241v2 Announce Type"],"persons":["Markov","Markov Decision Process"],"locations":[],"monetary":[]},"char_count":1292,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive Decentralized Queue Disclosure","Impatient Tenants","Edge","Non","arXiv250804241v2 Announce Type","Abstract","queue-state information disclosures","impatient tenants","multi-tenant edge systems","an information-bulletin strategy"],"filter_categories":{"engineering":["Edge"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive Decentralized Queue Disclosure":2.0,"Impatient Tenants":2.0,"Edge":2.0,"Non":2.0,"arXiv250804241v2 Announce Type":1.0,"Abstract":1.0,"queue-state information disclosures":1.0,"impatient tenants":1.0,"multi-tenant edge systems":1.0,"an information-bulletin strategy":1.0}},"age_hours":2.748063521666667,"is_recent":true,"quality_score":1.0,"sentiment_score":2.3665000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5267,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.749,"joy":0.0053,"surprise":0.0466,"sadness":0.0056,"fear":0.0079,"anger":0.1767,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to queue management in edge systems, aiming to reduce tenant impatience and improve resource utilization. While the numerical experiments show tradeoffs in average delay and impatience, the research is still in the early stages of development with no real-world deployments. The vaporware flag is raised due to the lack of deployed units and operational data.","key_impact_metrics":["average delay","impatience"],"technology_tags":["queue management","edge computing","Markov models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:46:20.957525Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_163e1c87d46d","title":"DSNS: The Deep Space Network Simulator","content":"arXiv:2508.04317v2 Announce Type: replace Abstract: Simulation tools are commonly used in the development and testing of new protocols or new networks. However, as satellite networks start to grow to encompass thousands of nodes, and as companies and space agencies begin to realize the interplanetary internet, existing satellite and network simulation tools have become impractical for use in this context. We therefore present the Deep Space Network Simulator (DSNS): a new network simulator with a focus on large-scale satellite networks. We demonstrate its improved capabilities compared to existing offerings, showcase its flexibility and extensibility through an implementation of existing protocols and the DTN simulation reference scenarios recommended by CCSDS, and evaluate its scalability, showing that it exceeds existing tools while providing better fidelity. DSNS provides concrete usefulness to both standards bodies and satellite operators, enabling fast iteration on protocol development and testing of parameters under highly realistic conditions. By removing roadblocks to research and innovation, we can accelerate the development of upcoming satellite networks and ensure that their communication is both fast and secure.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.04317","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.633921","language":"en","tags":["preprints","csni","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Joshua Smailes, Filip Futera, Sebastian K\\\"ohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic","raw_content_length":1248,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["DTN","the Deep Space Network Simulator","DSNS"],"persons":[],"locations":[],"monetary":[]},"char_count":1243,"language_detected":"en","key_concepts":{"key_phrases":["DSNS","The Deep Space Network Simulator","arXiv250804317v2 Announce Type","Abstract","Simulation tools","the development","testing","new protocols","new networks","satellite networks"],"filter_categories":{"engineering":["the development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DSNS":3.0,"The Deep Space Network Simulator":2.0,"arXiv250804317v2 Announce Type":1.0,"Abstract":1.0,"Simulation tools":1.0,"the development":1.0,"testing":1.0,"new protocols":1.0,"new networks":1.0,"satellite networks":1.0}},"age_hours":2.7480779811111113,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9282,"joy":0.0114,"surprise":0.0272,"sadness":0.0084,"fear":0.0102,"anger":0.009,"disgust":0.0055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new network simulator (DSNS) designed for large-scale satellite networks. While the simulator itself doesn't directly reduce GHG emissions, it can accelerate the development and testing of satellite communication protocols, potentially leading to more efficient and secure communication in future satellite networks. The article mentions improved capabilities and scalability compared to existing tools, along with implementation of existing protocols, suggesting some level of validation, but lacks concrete deployment data.","key_impact_metrics":["Scalability exceeding existing tools","Better fidelity compared to existing tools"],"technology_tags":["Network Simulation","Satellite Communication","Interplanetary Internet"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:46:23.796522Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fb06a801cdc3","title":"Levarging Learning Bias for Noisy Anomaly Detection","content":"arXiv:2508.07441v2 Announce Type: replace Abstract: This paper addresses the challenge of fully unsupervised image anomaly detection (FUIAD), where training data may contain unlabeled anomalies. Conventional methods assume anomaly-free training data, but real-world contamination leads models to absorb anomalies as normal, degrading detection performance. To mitigate this, we propose a two-stage framework that systematically exploits inherent learning bias in models. The learning bias stems from: (1) the statistical dominance of normal samples, driving models to prioritize learning stable normal patterns over sparse anomalies, and (2) feature-space divergence, where normal data exhibit high intra-class consistency while anomalies display high diversity, leading to unstable model responses. Leveraging the learning bias, stage 1 partitions the training set into subsets, trains sub-models, and aggregates cross-model anomaly scores to filter a purified dataset. Stage 2 trains the final detector on this dataset. Experiments on the Real-IAD benchmark demonstrate superior anomaly detection and localization performance under different noise conditions. Ablation studies further validate the framework's contamination resilience, emphasizing the critical role of learning bias exploitation. The model-agnostic design ensures compatibility with diverse unsupervised backbones, offering a practical solution for real-world scenarios with imperfect training data. Code is available at https://github.com/hustzhangyuxin/LLBNAD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.07441","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.634320","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Yuxin Zhang, Yunkang Cao, Yuqi Cheng, Yihan Sun, Weiming Shen","raw_content_length":1532,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["anomaly scores","Noisy Anomaly Detection arXiv:2508.07441v2 Announce Type: replace Abstract"],"persons":["Learning Bias"],"locations":[],"monetary":[]},"char_count":1531,"language_detected":"en","key_concepts":{"key_phrases":["Levarging Learning Bias","Noisy Anomaly Detection","models","arXiv250807441v2","Announce Type","Abstract","This paper","the challenge","fully unsupervised image anomaly detection","FUIAD"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Levarging Learning Bias":2.0,"Noisy Anomaly Detection":2.0,"models":2.0,"arXiv250807441v2":1.0,"Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"the challenge":1.0,"fully unsupervised image anomaly detection":1.0,"FUIAD":1.0}},"age_hours":2.7480933180555556,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5830000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8834,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8493,"joy":0.0025,"surprise":0.0097,"sadness":0.0137,"fear":0.0232,"anger":0.0321,"disgust":0.0695},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for anomaly detection in image data, which could potentially be applied to improve the accuracy of monitoring systems for environmental changes or industrial processes. The method is validated on the Real-IAD benchmark, demonstrating superior anomaly detection and localization performance, but lacks real-world deployment data. The code is available, suggesting potential for further development and application.","key_impact_metrics":["anomaly detection performance","localization performance"],"technology_tags":["image anomaly detection","machine learning","unsupervised learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:46:28.276532Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2fbe00a13f39","title":"Boosting Generic Semi","content":"arXiv:2508.08549v2 Announce Type: replace Abstract: Both limited annotation and domain shift are significant challenges frequently encountered in medical image segmentation, leading to derivative scenarios like semi-supervised medical (SSMIS), semi-supervised medical domain generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA). Conventional methods are generally tailored to specific tasks in isolation, the error accumulation hinders the effective utilization of unlabeled data and limits further improvements, resulting in suboptimal performance when these issues occur. In this paper, we aim to develop a generic framework that masters all three tasks. We found that the key to solving the problem lies in how to generate reliable pseudo labels for the unlabeled data in the presence of domain shift with labeled data and increasing the diversity of the model. To tackle this issue, we employ a Diverse Teaching and Label Propagation Network (DTLP-Net) to boosting the Generic Semi-Supervised Medical Image Segmentation. Our DTLP-Net involves a single student model and two diverse teacher models, which can generate reliable pseudo-labels for the student model. The first teacher model decouple the training process with labeled and unlabeled data, The second teacher is momentum-updated periodically, thus generating reliable yet divers pseudo-labels. To fully utilize the information within the data, we adopt inter-sample and intra-sample data augmentation to learn the global and local knowledge. In addition, to further capture the voxel-level correlations, we propose label propagation to enhance the model robust. We evaluate our proposed framework on five benchmark datasets for SSMIS, UMDA, and Semi-MDG tasks. The results showcase notable improvements compared to state-of-the-art methods across all five settings, indicating the potential of our framework to tackle more challenging SSL scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.08549","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.634773","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":270,"author":"Wei Li, Pengcheng Zhou, Linye Ma, Wenyi Zhao, Huihua Yang","raw_content_length":1937,"priority":7,"update_frequency":1,"reading_time_minutes":1.35,"robust_parsing_used":true,"entities":{"organizations":["UMDA"],"persons":[],"locations":[],"monetary":[]},"char_count":1936,"language_detected":"en","key_concepts":{"key_phrases":["Generic Semi","Announce Type","Abstract","Both limited annotation and domain shift","significant challenges","medical image segmentation","derivative scenarios","SSMIS","semi-supervised medical domain generalization","Semi"],"filter_categories":{"ai_ml":["Both limited annotation and domain shift"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generic Semi":2.0,"Announce Type":1.0,"Abstract":1.0,"Both limited annotation and domain shift":1.0,"significant challenges":1.0,"medical image segmentation":1.0,"derivative scenarios":1.0,"SSMIS":1.0,"semi-supervised medical domain generalization":1.0,"Semi":1.0}},"age_hours":2.748107391944444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9243,"joy":0.0047,"surprise":0.0279,"sadness":0.0115,"fear":0.0116,"anger":0.0123,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (DTLP-Net) for improving semi-supervised medical image segmentation. While the results showcase improvements on benchmark datasets, it remains in the applied research phase with no mention of real-world deployment or economic viability. The impact on climate change is indirect, potentially reducing energy consumption in medical imaging analysis, but this is not quantified.","key_impact_metrics":["Notable improvements compared to state-of-the-art methods"],"technology_tags":["Medical Image Segmentation","Semi-Supervised Learning","Domain Adaptation"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:46:31.068010Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_667ea1d0e1b9","title":"Interpretable Reward Model via Sparse Autoencoder","content":"arXiv:2508.08746v3 Announce Type: replace Abstract: Large language models (LLMs) have been widely deployed across numerous fields. Reinforcement Learning from Human Feedback (RLHF) leverages reward models (RMs) as proxies for human preferences to align LLM behaviors with human values, making the accuracy, reliability, and interpretability of RMs critical for effective alignment. However, traditional RMs lack interpretability, offer limited insight into the reasoning behind reward assignments, and are inflexible toward user preference shifts. While recent multidimensional RMs aim for improved interpretability, they often fail to provide feature-level attribution and require costly annotations. To overcome these limitations, we introduce the Sparse Autoencoder-enhanced Reward Model (SARM), a novel architecture that integrates a pretrained Sparse Autoencoder (SAE) into a reward model. SARM maps the hidden activations of LLM-based RM into an interpretable, sparse, and monosemantic feature space, from which a scalar head aggregates feature activations to produce transparent and conceptually meaningful reward scores. Empirical evaluations demonstrate that SARM facilitates direct feature-level attribution of reward assignments, allows dynamic adjustment to preference shifts, and achieves superior alignment performance compared to conventional reward models. Our code is available at https://github.com/schrieffer-z/sarm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.08746","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.635181","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Shuyi Zhang, Wei Shi, Sihang Li, Jiayi Liao, Tao Liang, Hengxing Cai, Xiang Wang","raw_content_length":1436,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["SAE","LLM","Reinforcement Learning"],"persons":["Sparse Autoencoder","Reward Model"],"locations":[],"monetary":[]},"char_count":1435,"language_detected":"en","key_concepts":{"key_phrases":["Interpretable Reward Model","Sparse Autoencoder","RMs","arXiv250808746v3 Announce Type","Large language models","LLMs","numerous fields","Reinforcement Learning","Human Feedback","RLHF"],"filter_categories":{"ai_ml":["Large language models","Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Interpretable Reward Model":2.0,"Sparse Autoencoder":2.0,"RMs":2.0,"arXiv250808746v3 Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"numerous fields":1.0,"Reinforcement Learning":1.0,"Human Feedback":1.0,"RLHF":1.0}},"age_hours":2.7481217525,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1355,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8271,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9032,"joy":0.006,"surprise":0.0122,"sadness":0.0064,"fear":0.0326,"anger":0.0226,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel architecture (SARM) for improving the interpretability and alignment of reward models in LLMs. While it demonstrates superior alignment performance compared to conventional reward models, it is still in the early stages of development with no deployed units or real-world data. The code is available, suggesting potential for further development and eventual deployment, but currently lacks concrete action in terms of GHG reduction or other sustainability metrics.","key_impact_metrics":["Superior alignment performance"],"technology_tags":["Sparse Autoencoder","Reward Model","Large Language Model"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:46:34.451493Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5ecc9d828c6b","title":"Pattern","content":"arXiv:2508.09281v2 Announce Type: replace Abstract: Effective personalized learning in computer science education depends on accurately modeling what students know and what they need to learn. While Knowledge Components (KCs) provide a foundation for such modeling, automated KC extraction from student code is inherently challenging due to insufficient explainability of discovered KCs and the open-endedness of programming problems with significant structural variability across student solutions and complex interactions among programming concepts. In this work, we propose a novel, explainable framework for automated KC discovery through pattern-based KCs: recurring structural patterns within student code that capture the specific programming patterns and language constructs that students must master. Toward this, we train a Variational Autoencoder to generate important representative patterns from student code guided by an explainable, attention-based code representation model that identifies important correct and incorrect pattern implementations from student code. These patterns are then clustered to form pattern-based KCs. We evaluate our KCs using two well-established methods informed by Cognitive Science: learning curve analysis and Deep Knowledge Tracing (DKT). Experimental results demonstrate meaningful learning trajectories and significant improvements in DKT predictive performance over traditional KT methods. This work advances knowledge modeling in CS education by providing an automated, scalable, and explainable framework for identifying granular code patterns and algorithmic constructs, essential for student learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.09281","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.635610","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Muntasir Hoq, Griffin Pitts, Andrew Lan, Peter Brusilovsky, Bita Akram","raw_content_length":1656,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["a Variational Autoencoder"],"locations":[],"monetary":[]},"char_count":1655,"language_detected":"en","key_concepts":{"key_phrases":["Pattern","what","arXiv250809281v2","Announce Type","Abstract","Effective personalized learning","computer science education","students","Knowledge Components","KCs"],"filter_categories":{"research_academic":["computer science education"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Pattern":2.0,"what":2.0,"arXiv250809281v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Effective personalized learning":1.0,"computer science education":1.0,"students":1.0,"Knowledge Components":1.0,"KCs":1.0}},"age_hours":2.748135063888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7929,"joy":0.0053,"surprise":0.0211,"sadness":0.0069,"fear":0.125,"anger":0.0317,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for automated knowledge component discovery in computer science education. While it shows improvements in predictive performance using Deep Knowledge Tracing (DKT), it is still in the applied research stage with no clear path to economic viability or deployment at scale. The climate impact is minimal as it primarily focuses on improving learning outcomes in computer science.","key_impact_metrics":["Improvements in DKT predictive performance"],"technology_tags":["Variational Autoencoder","Knowledge Component Discovery","Deep Knowledge Tracing"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T16:46:37.347222Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a17c197479f7","title":"KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging","content":"arXiv:2508.09823v2 Announce Type: replace Abstract: KonfAI is a modular, extensible, and fully configurable deep learning framework specifically designed for medical imaging tasks. It enables users to define complete training, inference, and evaluation workflows through structured YAML configuration files, without modifying the underlying code. This declarative approach enhances reproducibility, transparency, and experimental traceability while reducing development time. Beyond the capabilities of standard pipelines, KonfAI provides native abstractions for advanced strategies including patch-based learning, test-time augmentation, model ensembling, and direct access to intermediate feature representations for deep supervision. It also supports complex multi-model training setups such as generative adversarial architectures. Thanks to its modular and extensible architecture, KonfAI can easily accommodate custom models, loss functions, and data processing components. The framework has been successfully applied to segmentation, registration, and image synthesis tasks, and has contributed to top-ranking results in several international medical imaging challenges. KonfAI is open source and available at https://github.com/vboussot/KonfAI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.09823","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.636001","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Valentin Boussot, Jean-Louis Dillenseger","raw_content_length":1253,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["KonfAI"],"persons":[],"locations":[],"monetary":[]},"char_count":1252,"language_detected":"en","key_concepts":{"key_phrases":["KonfAI","A Modular and Fully Configurable Framework","Deep Learning","Medical Imaging","arXiv250809823v2 Announce Type","Abstract","medical imaging tasks","users","complete training","inference"],"filter_categories":{"ai_ml":["KonfAI","Deep Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"KonfAI":3.0,"A Modular and Fully Configurable Framework":2.0,"Deep Learning":2.0,"Medical Imaging":2.0,"arXiv250809823v2 Announce Type":1.0,"Abstract":1.0,"medical imaging tasks":1.0,"users":1.0,"complete training":1.0,"inference":1.0}},"age_hours":2.748148701111111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.875,"joy":0.0563,"surprise":0.0388,"sadness":0.0036,"fear":0.0069,"anger":0.0121,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a deep learning framework for medical imaging, which could indirectly contribute to sustainability by improving healthcare efficiency and resource allocation. However, there are no concrete actions or measurable outcomes related to direct GHG emission reductions or other environmental benefits. The framework is in the applied research stage, with successful applications in challenges, but lacking real-world deployment data.","key_impact_metrics":[],"technology_tags":["deep learning","medical imaging","AI"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:46:39.986029Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_62e8b0b32864","title":"Retroactive Monotonic Priority Queues via Range Searching","content":"arXiv:2508.09892v2 Announce Type: replace Abstract: The best-known fully retroactive priority queue costs $O(\\log^2 m \\log \\log m)$ time per operation, where $m$ is the number of operations performed on the data structure. In contrast, standard (non-retroactive) and partially retroactive priority queues can cost $O(\\log m)$ time per operation. So far, it is unknown whether this $O(\\log m)$ bound can be achieved for fully retroactive priority queues. In this work, we study a restricted variant of priority queues known as monotonic priority queues. First, we show that finding the minimum in a retroactive monotonic priority queue is a special case of the range-searching problem. Then, we design a fully retroactive monotonic priority queue with a cost of $O(\\log m + T(m))$ time per operation, where $T(m)$ is the maximum between the query and the update time of a specific range-searching data structure with $m$ elements. Finally, we design a fully retroactive monotonic priority queue that costs $O(\\log m \\log \\log m)$ time per operation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.09892","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.636379","language":"en","tags":["preprints","computer-science","cscg","research","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Lucas Castro, Rosiane de Freitas","raw_content_length":1051,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Retroactive Monotonic Priority Queues","Range Searching arXiv:2508.09892v2"],"persons":["O(\\log","O(\\log^2"],"locations":[],"monetary":["T(m)$"]},"char_count":1048,"language_detected":"en","key_concepts":{"key_phrases":["Retroactive Monotonic Priority Queues","Range Searching","operation","arXiv250809892v2","Announce Type","Abstract","The best-known fully retroactive priority queue","Olog2","log log","m time"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Retroactive Monotonic Priority Queues":2.0,"Range Searching":2.0,"operation":2.0,"arXiv250809892v2":1.0,"Announce Type":1.0,"Abstract":1.0,"The best-known fully retroactive priority queue":1.0,"Olog2":1.0,"log log":1.0,"m time":1.0}},"age_hours":2.7481642980555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8774,"joy":0.0093,"surprise":0.0827,"sadness":0.0149,"fear":0.0023,"anger":0.0091,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical improvements to priority queue data structures, which could potentially improve the efficiency of algorithms used in various applications, including those related to sustainability. However, the impact is indirect and difficult to quantify without knowing the specific applications and their energy consumption. The research is at a basic research stage with no deployment.","key_impact_metrics":["O(log m log log m) time per operation"],"technology_tags":["data structures","algorithms","priority queues","range searching"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:46:43.393948Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_73ac21b71867","title":"Contrast Sensitivity in Multimodal Large Language Models: A Psychophysics","content":"arXiv:2508.10367v2 Announce Type: replace Abstract: Understanding how Multimodal Large Language Models (MLLMs) process low-level visual features is critical for evaluating their perceptual abilities and has not been systematically characterized. Inspired by human psychophysics, we introduce a behavioural method for estimating the Contrast Sensitivity Function (CSF) in MLLMs by treating them as end-to-end observers. Models are queried with structured prompts while viewing noise-based stimuli filtered at specific spatial frequencies. Psychometric functions are derived from the binary verbal responses, and contrast thresholds (and CSFs) are obtained without relying on internal activations or classifier-based proxies. Our results reveal that some models resemble human CSFs in shape or scale, but none capture both. We also find that CSF estimates are highly sensitive to prompt phrasing, indicating limited linguistic robustness. Finally, we show that CSFs predict model performance under frequency-filtered and adversarial conditions. These findings highlight systematic differences in frequency tuning across MLLMs and establish CSF estimation as a scalable diagnostic tool for multimodal perception.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10367","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.641884","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Pablo Hern\\'andez-C\\'amara, Alexandra Gomez-Villa, Jose Manuel Ja\\'en-Lorites, Jorge Vila-Tom\\'as, Valero Laparra, Jesus Malo","raw_content_length":1210,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["Contrast Sensitivity","the Contrast Sensitivity Function","CSF"],"persons":[],"locations":[],"monetary":[]},"char_count":1209,"language_detected":"en","key_concepts":{"key_phrases":["Contrast Sensitivity","Multimodal Large Language Models","A Psychophysics","MLLMs","arXiv250810367v2 Announce Type","Abstract","their perceptual abilities","human psychophysics","a behavioural method","the Contrast Sensitivity Function"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contrast Sensitivity":2.0,"Multimodal Large Language Models":2.0,"A Psychophysics":2.0,"MLLMs":2.0,"arXiv250810367v2 Announce Type":1.0,"Abstract":1.0,"their perceptual abilities":1.0,"human psychophysics":1.0,"a behavioural method":1.0,"the Contrast Sensitivity Function":1.0}},"age_hours":2.748179041111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8577,"joy":0.0101,"surprise":0.0646,"sadness":0.0055,"fear":0.0274,"anger":0.0196,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on understanding how MLLMs process visual information, specifically contrast sensitivity. While it doesn't directly address climate change or sustainability, improving the perceptual abilities of AI models could indirectly contribute to more efficient resource management or improved climate modeling in the future. The research is based on a behavioral method and derives contrast thresholds from model responses, providing some measurable outcomes.","key_impact_metrics":["Contrast Sensitivity Function (CSF)","Spatial frequencies"],"technology_tags":["Multimodal Large Language Models","Psychophysics","Contrast Sensitivity"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:46:46.248228Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e753c87dcdec","title":"STRIDE","content":"arXiv:2508.10427v2 Announce Type: replace Abstract: Vision-Language Models (VLMs) have been applied to autonomous driving to support decision-making in complex real-world scenarios. However, their training on static, web-sourced image-text pairs fundamentally limits the precise spatiotemporal reasoning required to understand and predict dynamic traffic scenes. We address this critical gap with STRIDE-QA, a large-scale visual question answering (VQA) dataset for physically grounded reasoning from an ego-centric perspective. Constructed from 100 hours of multi-sensor driving data in Tokyo, capturing diverse and challenging conditions, STRIDE-QA is the largest VQA dataset for spatiotemporal reasoning in urban driving, offering 16 million QA pairs over 285K frames. Grounded by dense, automatically generated annotations including 3D bounding boxes, segmentation masks, and multi-object tracks, the dataset uniquely supports both object-centric and ego-centric reasoning through three novel QA tasks that require spatial localization and temporal prediction. Our benchmarks demonstrate that existing VLMs struggle significantly, achieving near-zero scores on prediction consistency. In contrast, VLMs fine-tuned on STRIDE-QA exhibit dramatic performance gains, achieving 55% success in spatial localization and 28% consistency in future motion prediction, compared to near-zero scores from general-purpose VLMs. Therefore, STRIDE-QA establishes a comprehensive foundation for developing more reliable VLMs for safety-critical autonomous systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.10427","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.642386","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Keishi Ishihara, Kento Sasaki, Tsubasa Takahashi, Daiki Shiono, Yu Yamaguchi","raw_content_length":1552,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["VQA","Vision-Language Models"],"persons":["STRIDE arXiv:2508.10427v2 Announce Type"],"locations":["Tokyo"],"monetary":[]},"char_count":1551,"language_detected":"en","key_concepts":{"key_phrases":["STRIDE","arXiv250810427v2 Announce Type","Abstract","Vision-Language Models","VLMs","autonomous driving","decision-making","complex real-world scenarios","their training","static web-sourced image-text pairs"],"filter_categories":{"ai_ml":["their training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"STRIDE":2.0,"arXiv250810427v2 Announce Type":1.0,"Abstract":1.0,"Vision-Language Models":1.0,"VLMs":1.0,"autonomous driving":1.0,"decision-making":1.0,"complex real-world scenarios":1.0,"their training":1.0,"static web-sourced image-text pairs":1.0}},"age_hours":2.748194367777778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.985,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.397,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7967,"joy":0.0076,"surprise":0.0173,"sadness":0.0085,"fear":0.1087,"anger":0.0421,"disgust":0.0191},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a new dataset (STRIDE-QA) for improving the spatiotemporal reasoning of VLMs in autonomous driving. While improved autonomous driving *could* lead to more efficient transportation and reduced emissions, this is a very indirect and theoretical impact. The dataset is a concrete output, and the performance gains of fine-tuned VLMs (55% success in spatial localization and 28% consistency in future motion prediction) are measurable outcomes, but the technology is still in the applied research phase.","key_impact_metrics":["55% success in spatial localization","28% consistency in future motion prediction"],"technology_tags":["Vision-Language Models","Autonomous Driving","Spatiotemporal Reasoning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:46:49.482380Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_73d68302c224","title":"The Cultural Gene of Large Language Models: A Study on the Impact of Cross","content":"arXiv:2508.12411v2 Announce Type: replace Abstract: Large language models (LLMs) are deployed globally, yet their underlying cultural and ethical assumptions remain underexplored. We propose the notion of a \"cultural gene\" -- a systematic value orientation that LLMs inherit from their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200 prompts targeting two classic cross-cultural dimensions: Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized zero-shot prompts, we compare a Western-centric model (GPT-4) and an Eastern-centric model (ERNIE Bot). Human annotation shows significant and consistent divergence across both dimensions. GPT-4 exhibits individualistic and low-power-distance tendencies (IDV score approx 1.21; PDI score approx -1.05), while ERNIE Bot shows collectivistic and higher-power-distance tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically significant (p < 0.001). We further compute a Cultural Alignment Index (CAI) against Hofstede's national scores and find GPT-4 aligns more closely with the USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative analyses of dilemma resolution and authority-related judgments illustrate how these orientations surface in reasoning. Our results support the view that LLMs function as statistical mirrors of their cultural corpora and motivate culturally aware evaluation and deployment to avoid algorithmic cultural hegemony.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.12411","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.642877","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Emanuel Z. Fenech-Borg, Tilen P. Meznaric-Kos, Milica D. Lekovic-Bojovic, Arni J. Hentze-Djurhuus","raw_content_length":1563,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["IDV","CPD","PDI","Power Distance","Eastern","Individualism-Collectivism"],"persons":["GPT-4"],"locations":[],"monetary":[]},"char_count":1562,"language_detected":"en","key_concepts":{"key_phrases":["The Cultural Gene","Large Language Models","A Study","the Impact","Cross","LLMs","arXiv250812411v2 Announce Type","Large language models","their underlying cultural and ethical assumptions","the notion"],"filter_categories":{"ai_ml":["Large Language Models","Large language models"],"research_academic":["A Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Cultural Gene":2.0,"Large Language Models":2.0,"A Study":2.0,"the Impact":2.0,"Cross":2.0,"LLMs":2.0,"arXiv250812411v2 Announce Type":1.0,"Large language models":1.0,"their underlying cultural and ethical assumptions":1.0,"the notion":1.0}},"age_hours":2.7482103855555553,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8501,"joy":0.0103,"surprise":0.0571,"sadness":0.0161,"fear":0.0091,"anger":0.0345,"disgust":0.0227},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies cultural biases in LLMs, which could indirectly impact sustainability efforts by influencing decision-making and resource allocation. The study uses a Cultural Probe Dataset (CPD) and compares GPT-4 and ERNIE Bot, finding statistically significant differences in individualism-collectivism and power distance. The research is in the basic research stage, with no immediate deployment or measurable environmental impact.","key_impact_metrics":["IDV score approx 1.21","PDI score approx -1.05"],"technology_tags":["Large Language Models","Cultural Bias Detection"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:46:52.487129Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c1f0831cb9ca","title":"Scaling Multi","content":"arXiv:2508.12840v2 Announce Type: replace Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for reasoning about both the physical world and the beliefs of agents, with applications in domains where information flow and awareness among agents are critical. The richness of MEP requires states to be represented as Kripke structures, i.e., directed labeled graphs. This representation limits the applicability of existing heuristics, hindering the scalability of epistemic solvers, which must explore an exponential search space without guidance, resulting often in intractability. To address this, we exploit Graph Neural Networks (GNNs) to learn patterns and relational structures within epistemic states, to guide the planning process. GNNs, which naturally capture the graph-like nature of Kripke models, allow us to derive meaningful estimates of state quality -- e.g., the distance from the nearest goal -- by generalizing knowledge obtained from previously solved planning instances. We integrate these predictive heuristics into an epistemic planning pipeline and evaluate them against standard baselines, showing improvements in the scalability of multi-agent epistemic planning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.12840","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.643297","language":"en","tags":["preprints","csai","computer-science","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Giovanni Briglia, Francesco Fabiano, Stefano Mariani","raw_content_length":1220,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["MEP","Graph Neural Networks","Epistemic Planning"],"persons":[],"locations":[],"monetary":[]},"char_count":1219,"language_detected":"en","key_concepts":{"key_phrases":["Multi","MEP","agents","arXiv250812840v2 Announce Type","Multi-agent Epistemic Planning","an autonomous planning framework","reasoning","both the physical world","the beliefs","applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multi":2.0,"MEP":2.0,"agents":2.0,"arXiv250812840v2 Announce Type":1.0,"Multi-agent Epistemic Planning":1.0,"an autonomous planning framework":1.0,"reasoning":1.0,"both the physical world":1.0,"the beliefs":1.0,"applications":1.0}},"age_hours":2.7482244169444443,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.867,"joy":0.0187,"surprise":0.053,"sadness":0.0093,"fear":0.0149,"anger":0.022,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the scalability of multi-agent epistemic planning using Graph Neural Networks. While the research aims to improve planning processes, it's at an early stage (applied research) with no concrete deployment or measurable climate impact yet. The technical credibility is relatively high due to the use of GNNs and evaluation against standard baselines, but economic viability and deployment readiness are low as it's still in the research phase.","key_impact_metrics":["Improvements in scalability of multi-agent epistemic planning"],"technology_tags":["Graph Neural Networks","Multi-agent Epistemic Planning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:46:55.807730Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e69032ef121b","title":"AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM","content":"arXiv:2508.13423v2 Announce Type: replace Abstract: In recent years, recommendation systems have evolved from providing a single list of recommendations to offering a comprehensive suite of topic focused services. To better accomplish this task, conversational recommendation systems (CRS) have progressed from basic retrieval augmented LLM generation to agentic systems with advanced reasoning and self correction capabilities. However, agentic systems come with notable response latency, a longstanding challenge for conversational recommendation systems. To balance the trade off between handling complex queries and minimizing latency, we propose AdaptJobRec, the first conversational job recommendation system that leverages autonomous agent to integrate personalized recommendation algorithm tools. The system employs a user query complexity identification mechanism to minimize response latency. For straightforward queries, the agent directly selects the appropriate tool for rapid responses. For complex queries, the agent uses the memory processing module to filter chat history for relevant content, then passes the results to the intelligent task decomposition planner, and finally executes the tasks using personalized recommendation tools. Evaluation on Walmart's real world career recommendation scenarios demonstrates that AdaptJobRec reduces average response latency by up to 53.3% compared to competitive baselines, while significantly improving recommendation accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.13423","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.643744","language":"en","tags":["preprints","csai","csir","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Qixin Wang, Dawei Wang, Kun Chen, Yaowei Hu, Puneet Girdhar, Ruoteng Wang, Aadesh Gupta, Chaitanya Devella, Wenlai Guo, Shangwen Huang, Bachir Aoun, Greg Hayworth, Han Li, Xintao Wu","raw_content_length":1489,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["CRS"],"persons":[],"locations":[],"monetary":[]},"char_count":1488,"language_detected":"en","key_concepts":{"key_phrases":["AdaptJobRec","Conversational Career Recommendation","an LLM","agentic systems","arXiv250813423v2 Announce Type","Abstract","recent years","recommendation systems","a single list","recommendations"],"filter_categories":{"ai_ml":["an LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AdaptJobRec":2.0,"Conversational Career Recommendation":2.0,"an LLM":2.0,"agentic systems":2.0,"arXiv250813423v2 Announce Type":1.0,"Abstract":1.0,"recent years":1.0,"recommendation systems":1.0,"a single list":1.0,"recommendations":1.0}},"age_hours":2.748237856111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9307,"joy":0.0111,"surprise":0.0411,"sadness":0.0036,"fear":0.0047,"anger":0.006,"disgust":0.0029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a conversational job recommendation system that reduces response latency and improves recommendation accuracy. The system is evaluated on Walmart's real-world career recommendation scenarios, demonstrating a 53.3% reduction in average response latency. However, it's still in the applied research stage and lacks information on deployment beyond the Walmart scenario.","key_impact_metrics":["response latency reduction 53.3%","recommendation accuracy improvement (unspecified)"],"technology_tags":["conversational AI","recommendation systems","machine learning"],"sdg_alignment":[4,8],"analyzed_at":"2025-10-29T16:46:59.092386Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_30973b2ce53e","title":"Hard Examples Are All You Need: Maximizing GRPO Post","content":"arXiv:2508.14094v4 Announce Type: replace Abstract: Collecting high-quality training examples for language model fine-tuning is expensive, with practical budgets limiting the amount of data that can be procured. We investigate whether example difficulty affects GRPO training effectiveness by comparing selection strategies (easy, medium, hard, random) across multiple models and reasoning tasks. Training on the hardest 10\\% of examples (those where the base model fails most often) yields dramatic performance gains up to 47\\%, while easy examples produce minimal improvements of 3-15\\%. This occurs because GRPO requires outcome variance to generate learning signals; hard examples maintain mixed success/failure outcomes throughout training while easy examples quickly converge to consistent success, eliminating learning opportunities. Moreover, models trained on hard examples show superior out-of-distribution generalization, with only hard-trained models achieving meaningful gains on the AIME2025 benchmark. Our findings provide clear guidance: when budget-constrained, prioritize collecting and annotating examples where your base model struggles, as these drive nearly all learning value in GRPO fine-tuning","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.14094","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.644168","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Benjamin Pikus, Pratyush Ranjan Tiwari, Burton Ye","raw_content_length":1219,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["GRPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1218,"language_detected":"en","key_concepts":{"key_phrases":["Hard Examples","All","You","arXiv250814094v4 Announce Type","Abstract","high-quality training examples","language model fine-tuning","practical budgets","the amount","data"],"filter_categories":{"ai_ml":["high-quality training examples","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hard Examples":2.0,"All":2.0,"You":2.0,"arXiv250814094v4 Announce Type":1.0,"Abstract":1.0,"high-quality training examples":1.0,"language model fine-tuning":1.0,"practical budgets":1.0,"the amount":1.0,"data":1.0}},"age_hours":2.7482525358333336,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8984,"joy":0.0047,"surprise":0.0278,"sadness":0.024,"fear":0.0101,"anger":0.0184,"disgust":0.0165},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents research on improving language model fine-tuning, showing that training on the hardest 10% of examples yields performance gains up to 47%. This could indirectly impact sustainability by improving the efficiency of AI models used in climate modeling, resource management, or other sustainability applications. However, it's currently in the research phase with no deployed technology or direct climate impact.","key_impact_metrics":["Performance gains up to 47%"],"technology_tags":["Language Models","Fine-tuning","GRPO"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:47:01.959205Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fe2dac180ffd","title":"Modular Embedding Recomposition for Incremental Learning","content":"arXiv:2508.16463v2 Announce Type: replace Abstract: The advent of pre-trained Vision-Language Models (VLMs) has significantly transformed Continual Learning (CL), mainly due to their zero-shot classification abilities. Such proficiency makes VLMs well-suited for real-world applications, enabling robust performance on novel unseen classes without requiring adaptation. However, fine-tuning remains essential when downstream tasks deviate significantly from the pre-training domain. Prior CL approaches primarily focus on preserving the zero-shot capabilities of VLMs during incremental fine-tuning on a downstream task. We take a step further by devising an approach that transforms preservation into enhancement of the zero-shot capabilities of VLMs. Our approach, named MoDular Embedding Recomposition (MoDER), introduces a modular framework that trains multiple textual experts, each specialized in a single seen class, and stores them in a foundational hub. At inference time, for each unseen class, we query the hub and compose the retrieved experts to synthesize a refined prototype that improves classification. We show the effectiveness of our method across two popular zero-shot incremental protocols, Class-IL and MTIL, comprising a total of 14 datasets. The codebase is available at https://github.com/aimagelab/mammoth.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16463","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.644596","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Aniello Panariello, Emanuele Frascaroli, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara","raw_content_length":1333,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["Continual Learning","Incremental Learning arXiv:2508.16463v2","Vision-Language Models","MoDular Embedding Recomposition"],"persons":[],"locations":[],"monetary":[]},"char_count":1332,"language_detected":"en","key_concepts":{"key_phrases":["Modular Embedding Recomposition","Incremental Learning","VLMs","arXiv250816463v2 Announce Type","Abstract","The advent","pre-trained Vision-Language Models","Continual Learning","their zero-shot classification abilities","Such proficiency"],"filter_categories":{"ai_ml":["pre-trained Vision-Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Modular Embedding Recomposition":2.0,"Incremental Learning":2.0,"VLMs":2.0,"arXiv250816463v2 Announce Type":1.0,"Abstract":1.0,"The advent":1.0,"pre-trained Vision-Language Models":1.0,"Continual Learning":1.0,"their zero-shot classification abilities":1.0,"Such proficiency":1.0}},"age_hours":2.7482672780555553,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9305,"joy":0.0128,"surprise":0.0175,"sadness":0.0062,"fear":0.0155,"anger":0.0096,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning approach (MoDER) to improve zero-shot classification in vision-language models. While it enhances AI capabilities, its direct impact on climate change is minimal at this stage, as it's primarily theoretical research with no deployed applications or quantified environmental benefits. The codebase is available, indicating some level of development, but it remains in the early stages.","key_impact_metrics":[],"technology_tags":["Machine Learning","Vision-Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:47:04.730620Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d7083620bc9","title":"Abmax: A JAX","content":"arXiv:2508.16508v2 Announce Type: replace Abstract: Agent-based modeling (ABM) is a principal approach for studying complex systems. By decomposing a system into simpler, interacting agents, agent-based modeling (ABM) allows researchers to observe the emergence of complex phenomena. High-performance array computing libraries like JAX can help scale such computational models to a large number of agents by using automatic vectorization and just-in-time (JIT) compilation. One of the caveats of using JAX to achieve such scaling is that the shapes of arrays used in the computational model should remain immutable throughout the simulation. In the context of agent-based modeling (ABM), this can pose constraints on certain agent manipulation operations that require flexible data structures. A subset of which is represented by the ability to update a dynamically selected number of agents by applying distinct changes to them during a simulation. To this effect, we introduce Abmax, an ABM framework based on JAX that implements multiple just-in-time (JIT) compilable algorithms to provide this functionality. On the canonical predation model benchmark, Abmax achieves runtime performance comparable to state-of-the-art implementations. Further, we show that this functionality can also be vectorized, making it possible to run many similar agent-based models in parallel. We also present two examples in the form of a traffic-flow model and a financial market model to show the use case of Abmax.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16508","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.645026","language":"en","tags":["preprints","computer-science","csse","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Siddharth Chaturvedi, Ahmed El-Gazzar, Marcel van Gerven","raw_content_length":1501,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["JAX"],"persons":["Abmax"],"locations":[],"monetary":[]},"char_count":1500,"language_detected":"en","key_concepts":{"key_phrases":["Abmax","A JAX","ABM","arXiv250816508v2","Announce Type","Abstract","Agent-based modeling","a principal approach","complex systems","a system"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Abmax":2.0,"A JAX":2.0,"ABM":2.0,"arXiv250816508v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Agent-based modeling":1.0,"a principal approach":1.0,"complex systems":1.0,"a system":1.0}},"age_hours":2.748282503611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9243,"joy":0.0222,"surprise":0.0391,"sadness":0.0033,"fear":0.0032,"anger":0.0054,"disgust":0.0026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new framework (Abmax) for agent-based modeling using JAX, achieving comparable runtime performance to state-of-the-art implementations on a predation model benchmark. While the framework could potentially be used to model and optimize systems related to sustainability (e.g., traffic flow, financial markets), there's no direct evidence of deployed technology or measured outcomes related to climate impact. It's currently in the applied research stage, with potential for future applications.","key_impact_metrics":["runtime performance comparable to state-of-the-art implementations"],"technology_tags":["agent-based modeling","JAX","high-performance computing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:47:08.490362Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a3ee3462dddb","title":"NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows","content":"arXiv:2508.16845v2 Announce Type: replace Abstract: Recent advances in Vision-Language-Action (VLA) models have established a two-component architecture, where a pre-trained Vision-Language Model (VLM) encodes visual observations and task descriptions, and an action decoder maps these representations to continuous actions. Diffusion models have been widely adopted as action decoders due to their ability to model complex, multimodal action distributions. However, they require multiple iterative denoising steps at inference time or downstream techniques to speed up sampling, limiting their practicality in real-world settings where high-frequency control is crucial. In this work, we present NinA (Normalizing Flows in Action), a fast and expressive alternative to diffusion-based decoders for VLAs. NinA replaces the diffusion action decoder with a Normalizing Flow (NF) that enables one-shot sampling through an invertible transformation, significantly reducing inference time. We integrate NinA into the FLOWER VLA architecture and fine-tune on the LIBERO benchmark. Our experiments show that NinA matches the performance of its diffusion-based counterpart under the same training regime, while achieving substantially faster inference. These results suggest that NinA offers a promising path toward efficient, high-frequency VLA control without compromising performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.16845","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.645450","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Denis Tarasov, Alexander Nikulin, Ilya Zisman, Albina Klepach, Nikita Lyubaykin, Andrei Polubarov, Alexander Derevyagin, Vladislav Kurenkov","raw_content_length":1380,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Vision-Language Model","VLM","Normalizing Flows arXiv:2508.16845v2 Announce Type"],"persons":[],"locations":["Vision-Language-Action"],"monetary":[]},"char_count":1379,"language_detected":"en","key_concepts":{"key_phrases":["Normalizing Flows","Action","Training VLA Models","arXiv250816845v2 Announce Type","Abstract","Recent advances","VLA","a two-component architecture","a pre-trained Vision-Language Model","VLM"],"filter_categories":{"ai_ml":["Training VLA Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Normalizing Flows":4.0,"Action":2.0,"Training VLA Models":2.0,"arXiv250816845v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"VLA":1.0,"a two-component architecture":1.0,"a pre-trained Vision-Language Model":1.0,"VLM":1.0}},"age_hours":2.748297688333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9109,"joy":0.0169,"surprise":0.0534,"sadness":0.004,"fear":0.0032,"anger":0.0076,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new AI model (NinA) that improves the efficiency of VLA models, potentially reducing the energy consumption associated with running these models. The claim of faster inference is supported by experiments on the LIBERO benchmark, but there's no information about real-world deployment or energy savings. It's still in the applied research stage.","key_impact_metrics":["Substantially faster inference"],"technology_tags":["Normalizing Flows","Vision-Language-Action Models","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:47:11.721411Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
