{"id":"science_arxiv_cs_067c15ff31ad","title":"Learning to Throw","content":"arXiv:2510.10357v1 Announce Type: new Abstract: Dynamic manipulation, such as robot tossing or throwing objects, has recently gained attention as a novel paradigm to speed up logistic operations. However, the focus has predominantly been on the object's landing location, irrespective of its final orientation. In this work, we present a method enabling a robot to accurately \"throw-flip\" objects to a desired landing pose (position and orientation). Conventionally, objects thrown by revolute robots suffer from parasitic rotation, resulting in highly restricted and uncontrollable landing poses. Our approach is based on two key design choices: first, leveraging the impulse-momentum principle, we design a family of throwing motions that effectively decouple the parasitic rotation, significantly expanding the feasible set of landing poses. Second, we combine a physics-based model of free flight with regression-based learning methods to account for unmodeled effects. Real robot experiments demonstrate that our framework can learn to throw-flip objects to a pose target within ($\\pm$5 cm, $\\pm$45 degrees) threshold in dozens of trials. Thanks to data assimilation, incorporating projectile dynamics reduces sample complexity by an average of 40% when throw-flipping to unseen poses compared to end-to-end learning methods. Additionally, we show that past knowledge on in-hand object spinning can be effectively reused, accelerating learning by 70% when throwing a new object with a Center of Mass (CoM) shift. A video summarizing the proposed method and the hardware experiments is available at https://youtu.be/txYc9b1oflU.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10357","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.696240","language":"en","tags":["computer-science","cslg","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Yang Liu, Bruno Da Costa, Aude Billard","raw_content_length":1633,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1632,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251010357v1 Announce Type","new Abstract","Dynamic manipulation","throwing objects","attention","a novel paradigm","logistic operations","the focus","the objects landing location","its final orientation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251010357v1 Announce Type":1.0,"new Abstract":1.0,"Dynamic manipulation":1.0,"throwing objects":1.0,"attention":1.0,"a novel paradigm":1.0,"logistic operations":1.0,"the focus":1.0,"the objects landing location":1.0,"its final orientation":1.0}},"age_hours":2.7504533011111114,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9022,"joy":0.026,"surprise":0.0418,"sadness":0.0036,"fear":0.0048,"anger":0.013,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel method for robot throwing, demonstrating improved accuracy in landing pose. The concrete action is the development and testing of a throwing algorithm on a real robot, achieving a pose target within ($\\pm$5 cm, $\\pm$45 degrees) in dozens of trials. While this could improve logistics efficiency, the direct climate impact is currently theoretical and requires further development and deployment.","key_impact_metrics":["Accuracy within 5 cm","Accuracy within 45 degrees"],"technology_tags":["robotics","machine learning","dynamic manipulation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:19:48.520722Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0c55fb4f6c9c","title":"RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models","content":"arXiv:2510.10390v1 Announce Type: new Abstract: The ability of language models in RAG systems to selectively refuse to answer based on flawed context is critical for safety, yet remains a significant failure point. Our large-scale study reveals that even frontier models struggle in this setting, with refusal accuracy dropping below 50% on multi-document tasks, while exhibiting either dangerous overconfidence or overcaution. Static benchmarks fail to reliably evaluate this capability, as models exploit dataset-specific artifacts and memorize test instances. We introduce RefusalBench, a generative methodology that programmatically creates diagnostic test cases through controlled linguistic perturbation. Our framework employs 176 distinct perturbation strategies across six categories of informational uncertainty and three intensity levels. Evaluation of over 30 models uncovers systematic failure patterns: refusal comprises separable detection and categorization skills, and neither scale nor extended reasoning improves performance. We find that selective refusal is a trainable, alignment-sensitive capability, offering a clear path for improvement. We release two benchmarks -- RefusalBench-NQ (single document) and RefusalBench-GaRAGe (multi-document) -- and our complete generation framework to enable continued, dynamic evaluation of this critical capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10390","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.701534","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Aashiq Muhamed, Leonardo F. R. Ribeiro, Markus Dreyer, Virginia Smith, Mona T. Diab","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["RAG","RefusalBench","Grounded Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["RefusalBench","Generative Evaluation","Selective Refusal","Grounded Language Models","Announce Type","new Abstract","The ability","language models","RAG systems","flawed context"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"RefusalBench":2.0,"Generative Evaluation":2.0,"Selective Refusal":2.0,"Grounded Language Models":2.0,"Announce Type":1.0,"new Abstract":1.0,"The ability":1.0,"language models":1.0,"RAG systems":1.0,"flawed context":1.0}},"age_hours":2.7506537983333335,"is_recent":true,"quality_score":1.0,"sentiment_score":0.7224999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8555,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4859,"joy":0.0042,"surprise":0.0133,"sadness":0.0233,"fear":0.3836,"anger":0.0581,"disgust":0.0316},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the reliability of language models in refusing to answer questions based on flawed context, which is crucial for safety in RAG systems. The concrete action is the development and release of RefusalBench, a generative methodology for creating diagnostic test cases. The evidence supporting claims comes from a large-scale study evaluating over 30 models, and the innovation is currently at the applied research stage, with the release of benchmarks for further evaluation.","key_impact_metrics":["refusal accuracy dropping below 50% on multi-document tasks","176 distinct perturbation strategies"],"technology_tags":["language models","RAG systems","generative evaluation","selective refusal"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:20:00.614259Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_80d1478d6ca4","title":"MRSAudio: A Large","content":"arXiv:2510.10396v1 Announce Type: new Abstract: Humans rely on multisensory integration to perceive spatial environments, where auditory cues enable sound source localization in three-dimensional space. Despite the critical role of spatial audio in immersive technologies such as VR/AR, most existing multimodal datasets provide only monaural audio, which limits the development of spatial audio generation and understanding. To address these challenges, we introduce MRSAudio, a large-scale multimodal spatial audio dataset designed to advance research in spatial audio understanding and generation. MRSAudio spans four distinct components: MRSLife, MRSSpeech, MRSMusic, and MRSSing, covering diverse real-world scenarios. The dataset includes synchronized binaural and ambisonic audio, exocentric and egocentric video, motion trajectories, and fine-grained annotations such as transcripts, phoneme boundaries, lyrics, scores, and prompts. To demonstrate the utility and versatility of MRSAudio, we establish five foundational tasks: audio spatialization, and spatial text to speech, spatial singing voice synthesis, spatial music generation and sound event localization and detection. Results show that MRSAudio enables high-quality spatial modeling and supports a broad range of spatial audio research. Demos and dataset access are available at https://mrsaudio.github.io.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10396","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.702728","language":"en","tags":["computer-science","research","cssd","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Xintong Hu, Yu Zhang, Li Tang, Rui Yang, Han Wang, Zongbao Zhang, Yuhan Wang, Yixuan Chen, Hankun Xu, Ke Xu, Pengfei Fan, Zhetao Chen, Yanhao Yu, Qiange Huang, Fei Wu, Zhou Zhao","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["MRSSpeech","MRSMusic","MRSAudio"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["MRSAudio","arXiv251010396v1","Announce Type","new Abstract","Humans","multisensory integration","spatial environments","auditory cues","sound source localization","three-dimensional space"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MRSAudio":3.0,"arXiv251010396v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Humans":1.0,"multisensory integration":1.0,"spatial environments":1.0,"auditory cues":1.0,"sound source localization":1.0,"three-dimensional space":1.0}},"age_hours":2.7507008969444446,"is_recent":true,"quality_score":1.0,"sentiment_score":6.549,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3098,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8257,"joy":0.0242,"surprise":0.1042,"sadness":0.0125,"fear":0.0182,"anger":0.0115,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article introduces a large-scale multimodal spatial audio dataset, MRSAudio, designed to advance research in spatial audio understanding and generation. While the dataset itself doesn't directly impact climate change, it could indirectly contribute by improving the efficiency of VR/AR technologies, potentially reducing travel or energy consumption in certain applications. The project is in the applied research stage, with demos and dataset access available, but lacks concrete deployment or measurable environmental outcomes.","key_impact_metrics":[],"technology_tags":["Spatial Audio","Multimodal Dataset","VR/AR"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:20:03.469382Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_48af58d9d6ff","title":"STEAM: A Semantic","content":"arXiv:2510.10398v1 Announce Type: new Abstract: Large Language Models store extensive factual knowledge acquired during large-scale pre-training. However, this knowledge is inherently static, reflecting only the state of the world at the time of training. Knowledge editing has emerged as a promising solution for updating outdated or incorrect facts without full retraining. However, most existing locate-and-edit methods primarily focus on token-level likelihood optimization without addressing semantic coherence. Our analysis reveals that such edited knowledge is often encoded as isolated residual streams in the model's latent space, distinct from pre-existing knowledge and bypassing natural reasoning process. To address this, we propose \\textsc{Steam}, a semantic-level knowledge editing framework that enhances integration of updated knowledge into the model's knowledge structure. \\textsc{Steam} first identifies target representations as semantic anchors for the updated factual association, then guides the internal representation of the edited fact towards these anchors through an alignment loss during optimization. Experimental results demonstrate that \\textsc{Steam} improves model's ability to reason with edited knowledge and enhances semantic coherence, underscoring the importance of latent-space alignment for reliable and coherent knowledge editing. The code is available at https://github.com/GY-Jeong/STEAM.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10398","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.703541","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Geunyeong Jeong, Juoh Sun, Seonghee Lee, Harksoo Kim","raw_content_length":1434,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1433,"language_detected":"en","key_concepts":{"key_phrases":["training","arXiv251010398v1 Announce Type","new Abstract","Large Language Models","extensive factual knowledge","large-scale","this knowledge","only the state","the world","the time"],"filter_categories":{"ai_ml":["training","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"training":2.0,"arXiv251010398v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"extensive factual knowledge":1.0,"large-scale":1.0,"this knowledge":1.0,"only the state":1.0,"the world":1.0,"the time":1.0}},"age_hours":2.7507311619444446,"is_recent":true,"quality_score":0.7,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9327,"joy":0.005,"surprise":0.0335,"sadness":0.0054,"fear":0.0081,"anger":0.0086,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for knowledge editing in large language models. While it improves the model's ability to reason with edited knowledge, it's still in the research phase with no clear path to deployment or direct impact on climate change. The concrete action is the development of the STEAM framework, and the evidence is based on experimental results, but it remains theoretical at this stage.","key_impact_metrics":["Improved model reasoning ability","Enhanced semantic coherence"],"technology_tags":["Large Language Models","Knowledge Editing","Semantic Alignment"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:20:24.130235Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a7a5ef77cf72","title":"Controllable Graph Generation with Diffusion Models via Inference","content":"arXiv:2510.10402v1 Announce Type: new Abstract: Graph generation is a fundamental problem in graph learning with broad applications across Web-scale systems, knowledge graphs, and scientific domains such as drug and material discovery. Recent approaches leverage diffusion models for step-by-step generation, yet unconditional diffusion offers little control over desired properties, often leading to unstable quality and difficulty in incorporating new objectives. Inference-time guidance methods mitigate these issues by adjusting the sampling process without retraining, but they remain inherently local, heuristic, and limited in controllability. To overcome these limitations, we propose TreeDiff, a Monte Carlo Tree Search (MCTS) guided dual-space diffusion framework for controllable graph generation. TreeDiff is a plug-and-play inference-time method that expands the search space while keeping computation tractable. Specifically, TreeDiff introduces three key designs to make it practical and scalable: (1) a macro-step expansion strategy that groups multiple denoising updates into a single transition, reducing tree depth and enabling long-horizon exploration; (2) a dual-space denoising mechanism that couples efficient latent-space denoising with lightweight discrete correction in graph space, ensuring both scalability and structural fidelity; and (3) a dual-space verifier that predicts long-term rewards from partially denoised graphs, enabling early value estimation and removing the need for full rollouts. Extensive experiments on 2D and 3D molecular generation benchmarks, under both unconditional and conditional settings, demonstrate that TreeDiff achieves state-of-the-art performance. Notably, TreeDiff exhibits favorable inference-time scaling: it continues to improve with additional computation, while existing inference-time methods plateau early under limited resources.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10402","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.704400","language":"en","tags":["computer-science","cslg","csce","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Jiachi Zhao, Zehong Wang, Yamei Liao, Chuxu Zhang, Yanfang Ye","raw_content_length":1902,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["Diffusion Models","Monte Carlo Tree Search","TreeDiff"],"persons":[],"locations":[],"monetary":[]},"char_count":1901,"language_detected":"en","key_concepts":{"key_phrases":["Controllable Graph Generation","Diffusion Models","Inference","Announce Type","new Abstract","Graph generation","a fundamental problem","broad applications","Web-scale systems","knowledge graphs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Controllable Graph Generation":2.0,"Diffusion Models":2.0,"Inference":2.0,"Announce Type":1.0,"new Abstract":1.0,"Graph generation":1.0,"a fundamental problem":1.0,"broad applications":1.0,"Web-scale systems":1.0,"knowledge graphs":1.0}},"age_hours":2.7507609966666666,"is_recent":true,"quality_score":1.0,"sentiment_score":1.5155000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6969,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8445,"joy":0.0074,"surprise":0.043,"sadness":0.0143,"fear":0.0444,"anger":0.0264,"disgust":0.0199},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (TreeDiff) for controllable graph generation, specifically for molecular design. While it shows state-of-the-art performance on benchmarks, it is still in the research phase with no deployed applications or economic viability demonstrated. The potential climate impact is indirect, through the discovery of new materials or drugs, but not yet quantified.","key_impact_metrics":["State-of-the-art performance on 2D and 3D molecular generation benchmarks"],"technology_tags":["Graph generation","Diffusion models","Monte Carlo Tree Search","Molecular design"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:20:27.690145Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b3765622133a","title":"Mesh","content":"arXiv:2510.10406v1 Announce Type: new Abstract: Gait recognition, a fundamental biometric technology, leverages unique walking patterns for individual identification, typically using 2D representations such as silhouettes or skeletons. However, these methods often struggle with viewpoint variations, occlusions, and noise. Multi-modal approaches that incorporate 3D body shape information offer improved robustness but are computationally expensive, limiting their feasibility for real-time applications. To address these challenges, we introduce Mesh-Gait, a novel end-to-end multi-modal gait recognition framework that directly reconstructs 3D representations from 2D silhouettes, effectively combining the strengths of both modalities. Compared to existing methods, directly learning 3D features from 3D joints or meshes is complex and difficult to fuse with silhouette-based gait features. To overcome this, Mesh-Gait reconstructs 3D heatmaps as an intermediate representation, enabling the model to effectively capture 3D geometric information while maintaining simplicity and computational efficiency. During training, the intermediate 3D heatmaps are gradually reconstructed and become increasingly accurate under supervised learning, where the loss is calculated between the reconstructed 3D joints, virtual markers, and 3D meshes and their corresponding ground truth, ensuring precise spatial alignment and consistent 3D structure. Mesh-Gait extracts discriminative features from both silhouettes and reconstructed 3D heatmaps in a computationally efficient manner. This design enables the model to capture spatial and structural gait characteristics while avoiding the heavy overhead of direct 3D reconstruction from RGB videos, allowing the network to focus on motion dynamics rather than irrelevant visual details. Extensive experiments demonstrate that Mesh-Gait achieves state-of-the-art accuracy. The code will be released upon acceptance of the paper.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10406","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.704856","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Zhao-Yang Wang, Jieneng Chen, Jiang Liu, Yuxiang Guo, Rama Chellappa","raw_content_length":1969,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["Mesh-Gait","Mesh"],"persons":[],"locations":[],"monetary":[]},"char_count":1968,"language_detected":"en","key_concepts":{"key_phrases":["Mesh","arXiv251010406v1","Announce Type","new Abstract","Gait recognition","a fundamental biometric technology","unique walking patterns","individual identification","2D representations","silhouettes"],"filter_categories":{"ai_ml":["Gait recognition"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mesh":2.0,"arXiv251010406v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Gait recognition":1.0,"a fundamental biometric technology":1.0,"unique walking patterns":1.0,"individual identification":1.0,"2D representations":1.0,"silhouettes":1.0}},"age_hours":2.7507760597222224,"is_recent":true,"quality_score":0.7,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8565,"joy":0.0045,"surprise":0.0173,"sadness":0.0222,"fear":0.04,"anger":0.0314,"disgust":0.0282},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel gait recognition framework (Mesh-Gait). While it aims for computational efficiency, it is currently in the research stage with no deployed units or measurable outcomes related to sustainability. The potential climate impact is low as it's primarily focused on biometric technology.","key_impact_metrics":[],"technology_tags":["gait recognition","3D reconstruction","biometrics"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:20:44.474872Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a0fc3bde496","title":"PrediQL: Automated Testing of GraphQL APIs with LLMs","content":"arXiv:2510.10407v1 Announce Type: new Abstract: GraphQL's flexible query model and nested data dependencies expose APIs to complex, context-dependent vulnerabilities that are difficult to uncover using conventional testing tools. Existing fuzzers either rely on random payload generation or rigid mutation heuristics, failing to adapt to the dynamic structures of GraphQL schemas and responses. We present PrediQL, the first retrieval-augmented, LLM-guided fuzzer for GraphQL APIs. PrediQL combines large language model reasoning with adaptive feedback loops to generate semantically valid and diverse queries. It models the choice of fuzzing strategy as a multi-armed bandit problem, balancing exploration of new query structures with exploitation of past successes. To enhance efficiency, PrediQL retrieves and reuses execution traces, schema fragments, and prior errors, enabling self-correction and progressive learning across test iterations. Beyond input generation, PrediQL integrates a context-aware vulnerability detector that uses LLM reasoning to analyze responses, interpreting data values, error messages, and status codes to identify issues such as injection flaws, access-control bypasses, and information disclosure. Our evaluation across open-source and benchmark GraphQL APIs shows that PrediQL achieves significantly higher coverage and vulnerability discovery rates compared to state-of-the-art baselines. These results demonstrate that combining retrieval-augmented reasoning with adaptive fuzzing can transform API security testing from reactive enumeration to intelligent exploration.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10407","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.705267","language":"en","tags":["computer-science","preprints","cscr","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Shaolun Liu, Sina Marefat, Omar Tsai, Yu Chen, Zecheng Deng, Jia Wang, Mohammad A. Tayebi","raw_content_length":1608,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":["GraphQL","GraphQL schemas"],"monetary":[]},"char_count":1607,"language_detected":"en","key_concepts":{"key_phrases":["GraphQL APIs","Automated Testing","LLMs","arXiv251010407v1 Announce Type","new Abstract","GraphQLs flexible query model","nested data dependencies","APIs","complex context-dependent vulnerabilities","conventional testing tools"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GraphQL APIs":3.0,"Automated Testing":2.0,"LLMs":2.0,"arXiv251010407v1 Announce Type":1.0,"new Abstract":1.0,"GraphQLs flexible query model":1.0,"nested data dependencies":1.0,"APIs":1.0,"complex context-dependent vulnerabilities":1.0,"conventional testing tools":1.0}},"age_hours":2.7507920891666666,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9379999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6124,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7843,"joy":0.0037,"surprise":0.0249,"sadness":0.0258,"fear":0.1034,"anger":0.0352,"disgust":0.0226},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to API security testing using LLMs, potentially leading to more secure and efficient software systems. While the evaluation shows higher coverage and vulnerability discovery rates compared to baselines, it is still in the research phase with no deployed units or customer contracts. The impact on sustainability is indirect, as it could improve the energy efficiency of software by reducing vulnerabilities and improving resource utilization, but this is not directly measured or quantified.","key_impact_metrics":["Higher coverage compared to state-of-the-art baselines","Vulnerability discovery rates compared to state-of-the-art baselines"],"technology_tags":["GraphQL","API Security","LLM","Fuzzing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:03.507292Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6eeeb9b9198f","title":"Trace Length is a Simple Uncertainty Signal in Reasoning Models","content":"arXiv:2510.10409v1 Announce Type: new Abstract: Uncertainty quantification for LLMs is a key research direction towards addressing hallucination and other issues that limit their reliable deployment. In this work, we show that reasoning trace length is a simple and useful confidence estimator in large reasoning models. Through comprehensive experiments across multiple models, datasets, and prompts, we show that trace length performs in comparable but complementary ways to other zero-shot confidence estimators such as verbalized confidence. Our work reveals that reasoning post-training fundamentally alters the relationship between trace length and accuracy, going beyond prior work that had shown that post-training causes traces to grow longer in general (e.g., \"overthinking\"). We investigate the mechanisms behind trace length's performance as a confidence signal, observing that the effect remains even after adjusting for confounders such as problem difficulty and GRPO-induced length bias. We identify high-entropy or \"forking\" tokens as playing a key role in the mechanism. Our findings demonstrate that reasoning post-training enhances uncertainty quantification beyond verbal expressions, and establish trace length as a practical confidence measure for large reasoning models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10409","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.705683","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Siddartha Devic, Charlotte Peale, Arwen Bradley, Sinead Williamson, Preetum Nakkiran, Aravind Gollakota","raw_content_length":1294,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Simple Uncertainty Signal","Trace Length"],"persons":[],"locations":[],"monetary":[]},"char_count":1293,"language_detected":"en","key_concepts":{"key_phrases":["Trace Length","a Simple Uncertainty Signal","Reasoning Models","arXiv251010409v1 Announce Type","new Abstract","Uncertainty quantification","LLMs","a key research direction","addressing hallucination","other issues"],"filter_categories":{"ai_ml":["a Simple Uncertainty Signal"],"research_academic":["a key research direction"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Trace Length":2.0,"a Simple Uncertainty Signal":2.0,"Reasoning Models":2.0,"arXiv251010409v1 Announce Type":1.0,"new Abstract":1.0,"Uncertainty quantification":1.0,"LLMs":1.0,"a key research direction":1.0,"addressing hallucination":1.0,"other issues":1.0}},"age_hours":2.750807237222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7421,"joy":0.0273,"surprise":0.0218,"sadness":0.0063,"fear":0.1777,"anger":0.0146,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a novel method for uncertainty quantification in LLMs, which could indirectly support sustainability efforts by improving the reliability of AI systems used in climate modeling or resource management. However, the direct climate impact is minimal at this stage, as it's purely theoretical research. The technical credibility is relatively high due to comprehensive experiments and analysis of mechanisms, but deployment readiness is low as it's still in the basic research phase.","key_impact_metrics":["Trace length as confidence estimator","Performance comparable to verbalized confidence"],"technology_tags":["Large Language Models","Uncertainty Quantification","Reasoning Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:14.126005Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_517ab15d63a6","title":"Discovering interpretable piecewise nonlinear model predictive control laws via symbolic decision trees","content":"arXiv:2510.10411v1 Announce Type: new Abstract: In this paper, we propose symbolic decision trees as surrogate models for approximating model predictive control laws. The proposed approach learns simultaneously the partition of the input domain (splitting logic) as well as local nonlinear expressions for predicting the control action leading to interpretable piecewise nonlinear control laws. The local nonlinear expressions are determined by the learning problem and are modeled using a set of basis functions. The learning task is posed as a mixed integer optimization, which is solved to global optimality with state-of-the-art global optimization solvers. We apply the proposed approach to a case study regarding the control of an isothermal reactor. The results show that the proposed approach can learn the control law accurately, leading to closed-loop performance comparable to that of a standard model predictive controller. Finally, comparison with existing interpretable models shows that the symbolic trees achieve both lower prediction error and superior closed-loop performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10411","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.706429","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Ilias Mitrai","raw_content_length":1095,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1094,"language_detected":"en","key_concepts":{"key_phrases":["symbolic decision trees","arXiv251010411v1 Announce Type","new Abstract","this paper","surrogate models","approximating model predictive control laws","The proposed approach","the partition","the input domain","logic"],"filter_categories":{"ai_ml":["the input domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"symbolic decision trees":3.0,"arXiv251010411v1 Announce Type":1.0,"new Abstract":1.0,"this paper":1.0,"surrogate models":1.0,"approximating model predictive control laws":1.0,"The proposed approach":1.0,"the partition":1.0,"the input domain":1.0,"logic":1.0}},"age_hours":2.750834389444444,"is_recent":true,"quality_score":0.7,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8142,"joy":0.0826,"surprise":0.075,"sadness":0.0046,"fear":0.0078,"anger":0.0112,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to model predictive control using symbolic decision trees, demonstrating improved accuracy and performance compared to existing methods in a case study. While promising, it is still in the applied research stage, with no evidence of real-world deployment or economic viability beyond the case study. The potential climate impact is indirect, as it could optimize energy-intensive processes, but this is not quantified.","key_impact_metrics":["Lower prediction error","Superior closed-loop performance"],"technology_tags":["Model Predictive Control","Symbolic Decision Trees","Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:20.272037Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5457d532ef79","title":"Knowing Unknowns in an Age of Information Overload","content":"arXiv:2510.10413v1 Announce Type: new Abstract: The technological revolution of the Internet has digitized the social, economic, political, and cultural activities of billions of humans. While researchers have been paying due attention to concerns of misinformation and bias, these obscure a much less researched and equally insidious problem - that of uncritically consuming incomplete information. The problem of incomplete information consumption stems from the very nature of explicitly ranked information on digital platforms, where our limited mental capacities leave us with little choice but to consume the tip of a pre-ranked information iceberg. This study makes two chief contributions. First, we leverage the context of internet search to propose an innovative metric that quantifies information completeness. For a given search query, this refers to the extent of the information spectrum that is observed during web browsing. We then validate this metric using 6.5 trillion search results extracted from daily search trends across 48 nations for one year. Second, we find causal evidence that awareness of information completeness while browsing the Internet reduces resistance to factual information, hence paving the way towards an open-minded and tolerant mindset.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10413","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.706841","language":"en","tags":["cscy","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Saurabh Khanna","raw_content_length":1282,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Knowing Unknowns"],"persons":[],"locations":[],"monetary":[]},"char_count":1281,"language_detected":"en","key_concepts":{"key_phrases":["Unknowns","an Age","Information Overload","arXiv251010413v1 Announce Type","new Abstract","The technological revolution","the Internet","billions","humans","researchers"],"filter_categories":{"research_academic":["researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unknowns":2.0,"an Age":2.0,"Information Overload":2.0,"arXiv251010413v1 Announce Type":1.0,"new Abstract":1.0,"The technological revolution":1.0,"the Internet":1.0,"billions":1.0,"humans":1.0,"researchers":1.0}},"age_hours":2.750849498888889,"is_recent":true,"quality_score":1.0,"sentiment_score":0.6874999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8625,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3237,"joy":0.0038,"surprise":0.0273,"sadness":0.0574,"fear":0.1546,"anger":0.0897,"disgust":0.3436},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research proposes a metric to quantify information completeness in internet searches and finds a correlation between awareness of completeness and reduced resistance to factual information. While potentially beneficial for societal discourse and indirectly for climate action, it lacks direct, concrete actions or measurable outcomes related to GHG emissions or climate adaptation. The study is at an early research stage with no deployment or economic viability demonstrated.","key_impact_metrics":["6.5 trillion search results","48 nations"],"technology_tags":["Information completeness metric","Web browsing analysis"],"sdg_alignment":[4,16],"analyzed_at":"2025-10-29T11:21:26.870243Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_129a071d1828","title":"Guided Image Feature Matching using Feature Spatial Order","content":"arXiv:2510.10414v1 Announce Type: new Abstract: Image feature matching plays a vital role in many computer vision tasks. Although many image feature detection and matching techniques have been proposed over the past few decades, it is still time-consuming to match feature points in two images, especially for images with a large number of detected features. Feature spatial order can estimate the probability that a pair of features is correct. Since it is a completely independent concept from epipolar geometry, it can be used to complement epipolar geometry in guiding feature match in a target region so as to improve matching efficiency. In this paper, we integrate the concept of feature spatial order into a progressive matching framework. We use some of the initially matched features to build a computational model of feature spatial order and employs it to calculates the possible spatial range of subsequent feature matches, thus filtering out unnecessary feature matches. We also integrate it with epipolar geometry to further improve matching efficiency and accuracy. Since the spatial order of feature points is affected by image rotation, we propose a suitable image alignment method from the fundamental matrix of epipolar geometry to remove the effect of image rotation. To verify the feasibility of the proposed method, we conduct a series of experiments, including a standard benchmark dataset, self-generated simulated images, and real images. The results demonstrate that our proposed method is significantly more efficient and has more accurate feature matching than the traditional method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10414","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.707250","language":"en","tags":["eessiv","computer-science","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Chin-Hung Teng, Ben-Jian Dong","raw_content_length":1614,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["Feature Spatial Order"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1613,"language_detected":"en","key_concepts":{"key_phrases":["Guided Image Feature Matching","Feature Spatial Order","arXiv251010414v1","Announce Type","new Abstract","Image feature matching","a vital role","many computer vision tasks","many image feature detection","matching techniques"],"filter_categories":{"ai_ml":["many computer vision tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Guided Image Feature Matching":2.0,"Feature Spatial Order":2.0,"arXiv251010414v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Image feature matching":1.0,"a vital role":1.0,"many computer vision tasks":1.0,"many image feature detection":1.0,"matching techniques":1.0}},"age_hours":2.750864811111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9208,"joy":0.0182,"surprise":0.03,"sadness":0.0045,"fear":0.0066,"anger":0.0132,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a method to improve image feature matching efficiency, which could indirectly contribute to sustainability by optimizing computer vision tasks in areas like environmental monitoring or resource management. However, the impact is theoretical and not directly quantified. The method is in the applied research stage, with experiments conducted on benchmark datasets, simulated images, and real images, but no real-world deployment is mentioned.","key_impact_metrics":["Matching efficiency improvement","Feature matching accuracy improvement"],"technology_tags":["Image feature matching","Computer vision","Epipolar geometry"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:30.524653Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_474ad3c1ff75","title":"Combo","content":"arXiv:2510.10417v1 Announce Type: new Abstract: Gait recognition is an important biometric for human identification at a distance, particularly under low-resolution or unconstrained environments. Current works typically focus on either 2D representations (e.g., silhouettes and skeletons) or 3D representations (e.g., meshes and SMPLs), but relying on a single modality often fails to capture the full geometric and dynamic complexity of human walking patterns. In this paper, we propose a multi-modal and multi-task framework that combines 2D temporal silhouettes with 3D SMPL features for robust gait analysis. Beyond identification, we introduce a multitask learning strategy that jointly performs gait recognition and human attribute estimation, including age, body mass index (BMI), and gender. A unified transformer is employed to effectively fuse multi-modal gait features and better learn attribute-related representations, while preserving discriminative identity cues. Extensive experiments on the large-scale BRIAR datasets, collected under challenging conditions such as long-range distances (up to 1 km) and extreme pitch angles (up to 50{\\deg}), demonstrate that our approach outperforms state-of-the-art methods in gait recognition and provides accurate human attribute estimation. These results highlight the promise of multi-modal and multitask learning for advancing gait-based human understanding in real-world scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10417","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.708041","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Zhao-Yang Wang, Zhimin Shao, Jieneng Chen, Rama Chellappa","raw_content_length":1441,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["BMI","3D SMPL"],"persons":["Combo arXiv:2510.10417v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1440,"language_detected":"en","key_concepts":{"key_phrases":["Combo","arXiv251010417v1 Announce Type","new Abstract","Gait recognition","an important biometric","human identification","a distance","low-resolution or unconstrained environments","Current works","either 2D representations"],"filter_categories":{"ai_ml":["Gait recognition"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Combo":2.0,"arXiv251010417v1 Announce Type":1.0,"new Abstract":1.0,"Gait recognition":1.0,"an important biometric":1.0,"human identification":1.0,"a distance":1.0,"low-resolution or unconstrained environments":1.0,"Current works":1.0,"either 2D representations":1.0}},"age_hours":2.7508952511111113,"is_recent":true,"quality_score":0.7,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8681,"joy":0.0093,"surprise":0.0416,"sadness":0.0251,"fear":0.0134,"anger":0.0222,"disgust":0.0203},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel gait recognition framework. While the research demonstrates improved accuracy in gait recognition and human attribute estimation, it lacks direct connection to sustainability outcomes. It is at the basic research stage with no deployed technology or measurable environmental impact.","key_impact_metrics":["Accuracy in gait recognition","Accuracy in human attribute estimation"],"technology_tags":["Gait recognition","Multi-modal learning","Transformer networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:33.588511Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9aba41451666","title":"ZeroGR: A Generalizable and Scalable Framework for Zero","content":"arXiv:2510.10419v1 Announce Type: new Abstract: Generative retrieval (GR) reformulates information retrieval (IR) by framing it as the generation of document identifiers (docids), thereby enabling an end-to-end optimization and seamless integration with generative language models (LMs). Despite notable progress under supervised training, GR still struggles to generalize to zero-shot IR scenarios, which are prevalent in real-world applications. To tackle this challenge, we propose \\textsc{ZeroGR}, a zero-shot generative retrieval framework that leverages natural language instructions to extend GR across a wide range of IR tasks. Specifically, \\textsc{ZeroGR} is composed of three key components: (i) an LM-based docid generator that unifies heterogeneous documents (e.g., text, tables, code) into semantically meaningful docids; (ii) an instruction-tuned query generator that generates diverse types of queries from natural language task descriptions to enhance corpus indexing; and (iii) a reverse annealing decoding strategy to balance precision and recall during docid generation. We investigate the impact of instruction fine-tuning scale and find that performance consistently improves as the number of IR tasks encountered during training increases. Empirical results on the BEIR and MAIR benchmarks demonstrate that \\textsc{ZeroGR} outperforms strong dense retrieval and generative baselines in zero-shot settings, establishing a new state-of-the-art for instruction-driven GR.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10419","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.708442","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Weiwei Sun, Keyi Kong, Xinyu Ma, Shuaiqiang Wang, Dawei Yin, Maarten de Rijke, Zhaochun Ren, Yiming Yang","raw_content_length":1492,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1491,"language_detected":"en","key_concepts":{"key_phrases":["ZeroGR","A Generalizable and Scalable Framework","Zero","arXiv251010419v1 Announce Type","new Abstract","Generative retrieval","information retrieval","the generation","document identifiers","docids"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ZeroGR":2.0,"A Generalizable and Scalable Framework":2.0,"Zero":2.0,"arXiv251010419v1 Announce Type":1.0,"new Abstract":1.0,"Generative retrieval":1.0,"information retrieval":1.0,"the generation":1.0,"document identifiers":1.0,"docids":1.0}},"age_hours":2.7509116819444444,"is_recent":true,"quality_score":0.7,"sentiment_score":3.4845000000000006,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3031,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9346,"joy":0.0048,"surprise":0.0268,"sadness":0.0044,"fear":0.0047,"anger":0.015,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel framework for generative retrieval, but it is currently in the research phase with no deployed units or real-world data. The impact on climate is indirect, as improved information retrieval could potentially help accelerate the adoption of sustainable technologies, but this is not directly measurable at this stage. The article mentions performance improvements on BEIR and MAIR benchmarks, but these are not directly linked to environmental outcomes.","key_impact_metrics":["Performance on BEIR benchmark","Performance on MAIR benchmark"],"technology_tags":["Generative Retrieval","Information Retrieval"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:37.180702Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c9a4b9abbbc0","title":"Hierarchical Planning for Long","content":"arXiv:2510.10421v1 Announce Type: new Abstract: Achieving persistent tracking of multiple dynamic targets over a large spatial area poses significant challenges for a single-robot system with constrained sensing capabilities. As the robot moves to track different targets, the ones outside the field of view accumulate uncertainty, making them progressively harder to track. An effective path planning algorithm must manage uncertainty over a long horizon and account for the risk of permanently losing track of targets that remain unseen for too long. However, most existing approaches rely on short planning horizons and assume small, bounded environments, resulting in poor tracking performance and target loss in large-scale scenarios. In this paper, we present a hierarchical planner for tracking multiple moving targets with an aerial vehicle. To address the challenge of tracking non-static targets, our method incorporates motion models and uncertainty propagation during path execution, allowing for more informed decision-making. We decompose the multi-target tracking task into sub-tasks of single target search and detection, and our proposed pipeline consists a novel low-level coverage planner that enables searching for a target in an evolving belief area, and an estimation method to assess the likelihood of success for each sub-task, making it possible to convert the active target tracking task to a Markov decision process (MDP) that we solve with a tree-based algorithm to determine the sequence of sub-tasks. We validate our approach in simulation, demonstrating its effectiveness compared to existing planners for active target tracking tasks, and our proposed planner outperforms existing approaches, achieving a reduction of 11-70% in final uncertainty across different environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10421","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.708876","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":259,"author":"Junbin Yuan, Brady Moon, Muqing Cao, Sebastian Scherer","raw_content_length":1809,"priority":7,"update_frequency":1,"reading_time_minutes":1.295,"robust_parsing_used":true,"entities":{"organizations":["Hierarchical Planning for Long arXiv:2510.10421v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1808,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical Planning","Long","uncertainty","arXiv251010421v1 Announce Type","new Abstract","persistent tracking","multiple dynamic targets","a large spatial area","significant challenges","a single-robot system"],"filter_categories":{"ai_ml":["uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical Planning":2.0,"Long":2.0,"uncertainty":2.0,"arXiv251010421v1 Announce Type":1.0,"new Abstract":1.0,"persistent tracking":1.0,"multiple dynamic targets":1.0,"a large spatial area":1.0,"significant challenges":1.0,"a single-robot system":1.0}},"age_hours":2.750925838611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.4576,"joy":0.0071,"surprise":0.0127,"sadness":0.0169,"fear":0.4749,"anger":0.0218,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a hierarchical planner for tracking multiple moving targets with an aerial vehicle, showing a reduction of 11-70% in final uncertainty in simulation. This is an applied research project with potential for environmental monitoring, but it is currently in the simulation stage and lacks real-world deployment or economic viability data.","key_impact_metrics":["reduction of 11-70% in final uncertainty"],"technology_tags":["aerial vehicle","path planning","target tracking"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T11:21:40.141729Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bceea74cd692","title":"Towards Cybersickness Severity Classification from VR Gameplay Videos Using Transfer Learning and Temporal Modeling","content":"arXiv:2510.10422v1 Announce Type: new Abstract: With the rapid advancement of virtual reality (VR) technology, its adoption across domains such as healthcare, education, and entertainment has grown significantly. However, the persistent issue of cybersickness, marked by symptoms resembling motion sickness, continues to hinder widespread acceptance of VR. While recent research has explored multimodal deep learning approaches leveraging data from integrated VR sensors like eye and head tracking, there remains limited investigation into the use of video-based features for predicting cybersickness. In this study, we address this gap by utilizing transfer learning to extract high-level visual features from VR gameplay videos using the InceptionV3 model pretrained on the ImageNet dataset. These features are then passed to a Long Short-Term Memory (LSTM) network to capture the temporal dynamics of the VR experience and predict cybersickness severity over time. Our approach effectively leverages the time-series nature of video data, achieving a 68.4% classification accuracy for cybersickness severity. This surpasses the performance of existing models trained solely on video data, providing a practical tool for VR developers to evaluate and mitigate cybersickness in virtual environments. Furthermore, this work lays the foundation for future research on video-based temporal modeling for enhancing user comfort in VR applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10422","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.709273","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Jyotirmay Nag Setu, Kevin Desai, John Quarles","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["ImageNet"],"persons":["a Long Short-Term Memory"],"locations":[],"monetary":[]},"char_count":1442,"language_detected":"en","key_concepts":{"key_phrases":["Cybersickness Severity Classification","VR Gameplay Videos","Transfer Learning","Temporal Modeling","Announce Type","new Abstract","the rapid advancement","virtual reality VR technology","its adoption","domains"],"filter_categories":{"ai_ml":["domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cybersickness Severity Classification":2.0,"VR Gameplay Videos":2.0,"Transfer Learning":2.0,"Temporal Modeling":2.0,"Announce Type":1.0,"new Abstract":1.0,"the rapid advancement":1.0,"virtual reality VR technology":1.0,"its adoption":1.0,"domains":1.0}},"age_hours":2.7509406127777773,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6852,"joy":0.0058,"surprise":0.0177,"sadness":0.0756,"fear":0.1371,"anger":0.0117,"disgust":0.0669},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving VR user comfort by predicting cybersickness severity. While indirectly related to sustainability by potentially enabling more efficient training and collaboration in virtual environments, it does not directly address GHG emissions or environmental issues. The research achieves 68.4% classification accuracy, but is still in the applied research phase with no deployed units.","key_impact_metrics":["Classification accuracy 68.4%"],"technology_tags":["Virtual Reality","Cybersickness Prediction","Transfer Learning","LSTM"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T11:21:43.582205Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dab2ed09fafb","title":"Softmax $\\geq$ Linear: Transformers may learn to classify in","content":"arXiv:2510.10425v1 Announce Type: new Abstract: The remarkable ability of transformers to learn new concepts solely by reading examples within the input prompt, termed in-context learning (ICL), is a crucial aspect of intelligent behavior. Here, we focus on understanding the learning algorithm transformers use to learn from context. Existing theoretical work, often based on simplifying assumptions, has primarily focused on linear self-attention and continuous regression tasks, finding transformers can learn in-context by gradient descent. Given that transformers are typically trained on discrete and complex tasks, we bridge the gap from this existing work to the setting of classification, with non-linear (importantly, softmax) activation. We find that transformers still learn to do gradient descent in-context, though on functionals in the kernel feature space and with a context-adaptive learning rate in the case of softmax transformer. These theoretical findings suggest a greater adaptability to context for softmax attention, which we empirically verify and study through ablations. Overall, we hope this enhances theoretical understanding of in-context learning algorithms in more realistic settings, pushes forward our intuitions and enables further theory bridging to larger models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10425","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.710046","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Sara Dragutinovi\\'c, Andrew M. Saxe, Aaditya K. Singh","raw_content_length":1302,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["linear","Linear","ICL"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1301,"language_detected":"en","key_concepts":{"key_phrases":["geq Linear","Transformers","context","arXiv251010425v1 Announce Type","new Abstract","The remarkable ability","transformers","new concepts","examples","the input prompt"],"filter_categories":{"ai_ml":["Transformers","transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"geq Linear":2.0,"Transformers":2.0,"context":2.0,"arXiv251010425v1 Announce Type":1.0,"new Abstract":1.0,"The remarkable ability":1.0,"transformers":1.0,"new concepts":1.0,"examples":1.0,"the input prompt":1.0}},"age_hours":2.750969302777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4425,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8885,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6822,"joy":0.0426,"surprise":0.2315,"sadness":0.0046,"fear":0.0157,"anger":0.0167,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on theoretical understanding of in-context learning algorithms in transformers, specifically how they learn to classify. While potentially enabling more efficient AI models in the future, there are no concrete actions or measurable outcomes related to sustainability at this stage. The research is at a very early stage with no deployment.","key_impact_metrics":[],"technology_tags":["transformers","in-context learning","softmax attention"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:21:46.813211Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dccff0812b3b","title":"Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs","content":"arXiv:2510.10426v1 Announce Type: new Abstract: Multimodal large language models (MLLMs) often fail in fine-grained visual question answering, producing hallucinations about object identities, positions, and relations because textual queries are not explicitly anchored to visual referents. Retrieval-augmented generation (RAG) alleviates some errors, but it fails to align with human-like processing at both the retrieval and augmentation levels. Specifically, it focuses only on global-level image information but lacks local detail and limits reasoning about fine-grained interactions. To overcome this limitation, we present Human-Like Retrieval-Augmented Generation (HuLiRAG), a framework that stages multimodal reasoning as a ``what--where--reweight'' cascade. Queries are first anchored to candidate referents via open-vocabulary detection (what), then spatially resolved with SAM-derived masks to recover fine-grained precision (where), and adaptively prioritized through the trade-off between local and global alignment (reweight). Mask-guided fine-tuning further injects spatial evidence into the generation process, transforming grounding from a passive bias into an explicit constraint on answer formulation. Extensive experiments demonstrate that this human-like cascade improves grounding fidelity and factual consistency while reducing hallucinations, advancing multimodal question answering toward trustworthy reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10426","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.710439","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Suyang Xi, Chenxi Yang, Hong Ding, Yiqing Ni, Catherine C. Liu, Yunhao Liu, Chengqi Zhang","raw_content_length":1437,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["SAM"],"persons":[],"locations":[],"monetary":[]},"char_count":1436,"language_detected":"en","key_concepts":{"key_phrases":["MLLMs","a Retrieval Framework","Images","Humanlike Manner","Generation","arXiv251010426v1 Announce Type","new Abstract","Multimodal large language models","fine-grained visual question","hallucinations"],"filter_categories":{"ai_ml":["MLLMs","Multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MLLMs":3.0,"a Retrieval Framework":2.0,"Images":2.0,"Humanlike Manner":2.0,"Generation":2.0,"arXiv251010426v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal large language models":1.0,"fine-grained visual question":1.0,"hallucinations":1.0}},"age_hours":2.750985834166667,"is_recent":true,"quality_score":1.0,"sentiment_score":1.1580000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7684,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6482,"joy":0.002,"surprise":0.0444,"sadness":0.1092,"fear":0.0339,"anger":0.05,"disgust":0.1122},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (HuLiRAG) to improve the accuracy of multimodal large language models in visual question answering. The framework is currently in the research stage with no deployed units or measured outcomes related to sustainability. While it could potentially improve the efficiency of AI systems, the direct climate impact is minimal and unproven at this stage.","key_impact_metrics":[],"technology_tags":["AI","MLLM","Retrieval-Augmented Generation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:21:49.803910Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f4a758bba006","title":"Explicit Min","content":"arXiv:2510.10431v1 Announce Type: new Abstract: We study explicit constructions of min-wise hash families and their extension to $k$-min-wise hash families. Informally, a min-wise hash family guarantees that for any fixed subset $X\\subseteq[N]$, every element in $X$ has an equal chance to have the smallest value among all elements in $X$; a $k$-min-wise hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash is widely used in many areas of computer science such as sketching, web page detection, and $\\ell_0$ sampling. The classical works by Indyk and P\\u{a}tra\\c{s}cu and Thorup have shown $\\Theta(\\log(1/\\delta))$-wise independent families give min-wise hash of multiplicative (relative) error $\\delta$, resulting in a construction with $\\Theta(\\log(1/\\delta)\\log N)$ random bits. Based on a reduction from pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou and Zuckerman, Gopolan and Yehudayoff improved the number of bits to $O(\\log N\\log\\log N)$ for polynomially small errors $\\delta$. However, no construction with $O(\\log N)$ bits (polynomial size family) and sub-constant error was known before. In this work, we continue and extend the study of constructing ($k$-)min-wise hash families from pseudorandomness for combinatorial rectangles and read-once branching programs. Our main result gives the first explicit min-wise hash families that use an optimal (up to constant) number of random bits and achieve a sub-constant (in fact, almost polynomially small) error, specifically, an explicit family of $k$-min-wise hash with $O(k\\log N)$ bits and $2^{-O(\\log N/\\log\\log N)}$ error. This improves all previous results for any $k=\\log^{O(1)}N$ under $O(k \\log N)$ bits. Our main techniques involve several new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool min-wise hashing with a multiplicative error.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10431","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.711267","language":"en","tags":["computer-science","csds","csdm","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":269,"author":"Xue Chen, Shengtang Huang, Xin Li","raw_content_length":1898,"priority":7,"update_frequency":1,"reading_time_minutes":1.345,"robust_parsing_used":true,"entities":{"organizations":["Indyk","Saks"],"persons":["Zhou","Zuckerman","X\\subseteq[N]$","Gopolan","Yehudayoff"],"locations":["Srinivasan"],"monetary":["$\\ell_0$","\\Theta(\\log(1/\\delta)\\log","k$-min","X$."]},"char_count":1893,"language_detected":"en","key_concepts":{"key_phrases":["Explicit Min","arXiv251010431v1 Announce Type","new Abstract","explicit constructions","min-wise hash families","their extension","k-min-wise hash families","a min-wise hash family","every element","an equal chance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Explicit Min":2.0,"arXiv251010431v1 Announce Type":1.0,"new Abstract":1.0,"explicit constructions":1.0,"min-wise hash families":1.0,"their extension":1.0,"k-min-wise hash families":1.0,"a min-wise hash family":1.0,"every element":1.0,"an equal chance":1.0}},"age_hours":2.7510164274999998,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9191,"joy":0.0305,"surprise":0.0304,"sadness":0.003,"fear":0.0036,"anger":0.0087,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical improvement in min-wise hash families, reducing the number of random bits required while maintaining a sub-constant error rate. While this is a significant theoretical advancement, it is currently in the basic research stage and has no direct, measurable impact on climate change or sustainability. The potential impact is indirect, as improved hashing algorithms could lead to more efficient data processing in various applications, including those related to sustainability.","key_impact_metrics":["Error rate of 2^{-O(log N/loglog N)}","O(k log N) bits"],"technology_tags":["Hashing algorithms","Pseudorandomness","Data compression"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:52.979394Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b927d508bedc","title":"Hierarchical LoRA MoE for Efficient CTR Model Scaling","content":"arXiv:2510.10432v1 Announce Type: new Abstract: Deep models have driven significant advances in click-through rate (CTR) prediction. While vertical scaling via layer stacking improves model expressiveness, the layer-by-layer sequential computation poses challenges to efficient scaling. Conversely, horizontal scaling through Mixture of Experts (MoE) achieves efficient scaling by activating a small subset of experts in parallel, but flat MoE layers may struggle to capture the hierarchical structure inherent in recommendation tasks. To push the Return-On-Investment (ROI) boundary, we explore the complementary strengths of both directions and propose HiLoMoE, a hierarchical LoRA MoE framework that enables holistic scaling in a parameter-efficient manner. Specifically, HiLoMoE employs lightweight rank-1 experts for parameter-efficient horizontal scaling, and stacks multiple MoE layers with hierarchical routing to enable combinatorially diverse expert compositions. Unlike conventional stacking, HiLoMoE routes based on prior layer scores rather than outputs, allowing all layers to execute in parallel. A principled three-stage training framework ensures stable optimization and expert diversity. Experiments on four public datasets show that HiLoMoE achieving better performance-efficiency tradeoff, achieving an average AUC improvement of 0.20\\% in AUC and 18.5\\% reduction in FLOPs compared to the non-MoE baseline.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10432","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.711685","language":"en","tags":["cslg","csai","preprints","research","csir","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Zhichen Zeng, Mengyue Hang, Xiaolong Liu, Xiaoyi Liu, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Zhining Liu, Siyang Yuan, Chaofei Yang, Yiqun Liu, Hang Yin, Jiyan Yang, Hanghang Tong","raw_content_length":1428,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["CTR","Mixture of Experts (MoE","LoRA MoE"],"persons":[],"locations":[],"monetary":[]},"char_count":1427,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical LoRA MoE","Efficient CTR Model Scaling","efficient scaling","arXiv251010432v1 Announce Type","new Abstract","Deep models","significant advances","click-through rate CTR prediction","vertical scaling","layer stacking"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical LoRA MoE":2.0,"Efficient CTR Model Scaling":2.0,"efficient scaling":2.0,"arXiv251010432v1 Announce Type":1.0,"new Abstract":1.0,"Deep models":1.0,"significant advances":1.0,"click-through rate CTR prediction":1.0,"vertical scaling":1.0,"layer stacking":1.0}},"age_hours":2.7510311688888893,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6555,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7311,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9416,"joy":0.0056,"surprise":0.0161,"sadness":0.0048,"fear":0.0132,"anger":0.0099,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel model architecture (HiLoMoE) for CTR prediction, achieving a 0.20% AUC improvement and 18.5% FLOPs reduction compared to a baseline. The concrete action is the development and testing of this model on public datasets. While promising, it is still in the research phase and lacks real-world deployment data, hence the 'vaporware' flag.","key_impact_metrics":["0.20% AUC improvement","18.5% FLOPs reduction"],"technology_tags":["LoRA","Mixture of Experts","CTR prediction"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:21:55.993056Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7ae1385eb2b7","title":"MonoSE(3)-Diffusion: A Monocular SE(3) Diffusion Framework for Robust Camera","content":"arXiv:2510.10434v1 Announce Type: new Abstract: We propose MonoSE(3)-Diffusion, a monocular SE(3) diffusion framework that formulates markerless, image-based robot pose estimation as a conditional denoising diffusion process. The framework consists of two processes: a visibility-constrained diffusion process for diverse pose augmentation and a timestep-aware reverse process for progressive pose refinement. The diffusion process progressively perturbs ground-truth poses to noisy transformations for training a pose denoising network. Importantly, we integrate visibility constraints into the process, ensuring the transformations remain within the camera field of view. Compared to the fixed-scale perturbations used in current methods, the diffusion process generates in-view and diverse training poses, thereby improving the network generalization capability. Furthermore, the reverse process iteratively predicts the poses by the denoising network and refines pose estimates by sampling from the diffusion posterior of current timestep, following a scheduled coarse-to-fine procedure. Moreover, the timestep indicates the transformation scales, which guide the denoising network to achieve more accurate pose predictions. The reverse process demonstrates higher robustness than direct prediction, benefiting from its timestep-aware refinement scheme. Our approach demonstrates improvements across two benchmarks (DREAM and RoboKeyGen), achieving a notable AUC of 66.75 on the most challenging dataset, representing a 32.3% gain over the state-of-the-art.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10434","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.713017","language":"en","tags":["computer-science","preprints","cscv","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Kangjian Zhu, Haobo Jiang, Yigong Zhang, Jianjun Qian, Jian Yang, Jin Xie","raw_content_length":1562,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1561,"language_detected":"en","key_concepts":{"key_phrases":["A Monocular SE3 Diffusion Framework","Robust Camera","arXiv251010434v1 Announce Type","new Abstract","MonoSE3-Diffusion","a monocular SE3 diffusion framework","markerless image-based robot","estimation","a conditional denoising diffusion process","The framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Monocular SE3 Diffusion Framework":2.0,"Robust Camera":2.0,"arXiv251010434v1 Announce Type":1.0,"new Abstract":1.0,"MonoSE3-Diffusion":1.0,"a monocular SE3 diffusion framework":1.0,"markerless image-based robot":1.0,"estimation":1.0,"a conditional denoising diffusion process":1.0,"The framework":1.0}},"age_hours":2.751060152777778,"is_recent":true,"quality_score":0.7,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8673,"joy":0.0263,"surprise":0.0479,"sadness":0.0048,"fear":0.0174,"anger":0.0251,"disgust":0.0112},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for robot pose estimation, improving accuracy and robustness. While the technology shows promise with a 32.3% gain over the state-of-the-art on a challenging dataset, it is still in the applied research phase with no deployed units or economic viability data. The climate impact is indirect, potentially improving efficiency in robotics applications, but not directly reducing emissions.","key_impact_metrics":["AUC of 66.75","32.3% gain over state-of-the-art"],"technology_tags":["robot pose estimation","diffusion models","computer vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:21:59.001157Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d204b9d49ad7","title":"Does Weighting Improve Matrix Factorization for Recommender Systems?","content":"arXiv:2510.10440v1 Announce Type: new Abstract: Matrix factorization is a widely used approach for top-N recommendation and collaborative filtering. When implemented on implicit feedback data (such as clicks), a common heuristic is to upweight the observed interactions. This strategy has been shown to improve performance for certain algorithms. In this paper, we conduct a systematic study of various weighting schemes and matrix factorization algorithms. Somewhat surprisingly, we find that training with unweighted data can perform comparably to, and sometimes outperform, training with weighted data, especially for large models. This observation challenges the conventional wisdom. Nevertheless, we identify cases where weighting can be beneficial, particularly for models with lower capacity and specific regularization schemes. We also derive efficient algorithms for exactly minimizing several weighted objectives that were previously considered computationally intractable. Our work provides a comprehensive analysis of the interplay between weighting, regularization, and model capacity in matrix factorization for recommender systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10440","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.713913","language":"en","tags":["statml","cslg","preprints","research","csir","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Alex Ayoub, Samuel Robertson, Dawen Liang, Harald Steck, Nathan Kallus","raw_content_length":1147,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Recommender Systems"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1146,"language_detected":"en","key_concepts":{"key_phrases":["Does Weighting","Improve Matrix Factorization","Recommender Systems","arXiv251010440v1","Announce Type","new Abstract","Matrix factorization","a widely used approach","top-N recommendation","collaborative filtering"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Does Weighting":2.0,"Improve Matrix Factorization":2.0,"Recommender Systems":2.0,"arXiv251010440v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Matrix factorization":1.0,"a widely used approach":1.0,"top-N recommendation":1.0,"collaborative filtering":1.0}},"age_hours":2.7510916663888887,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7845,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8969,"joy":0.0272,"surprise":0.05,"sadness":0.0044,"fear":0.0035,"anger":0.011,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes the impact of weighting schemes on matrix factorization algorithms used in recommender systems. While it identifies cases where weighting can be beneficial, it primarily focuses on theoretical analysis and algorithm development, not on deployed technology or measured outcomes in a sustainability context. The potential climate impact is indirect, as improved recommender systems could influence consumption patterns, but this is not quantified or directly addressed.","key_impact_metrics":[],"technology_tags":["recommender systems","matrix factorization","machine learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:22:02.060530Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eb21bc36bba7","title":"Reverse Supervision at Scale: Exponential Search Meets the Economics of Annotation","content":"arXiv:2510.10446v1 Announce Type: new Abstract: We analyze a reversed-supervision strategy that searches over labelings of a large unlabeled set \\(B\\) to minimize error on a small labeled set \\(A\\). The search space is \\(2^n\\), and the resulting complexity remains exponential even under large constant-factor speedups (e.g., quantum or massively parallel hardware). Consequently, arbitrarily fast -- but not exponentially faster -- computation does not obviate the need for informative labels or priors. In practice, the machine learning pipeline still requires an initial human contribution: specifying the objective, defining classes, and providing a seed set of representative annotations that inject inductive bias and align models with task semantics. Synthetic labels from generative AI can partially substitute provided their quality is human-grade and anchored by a human-specified objective, seed supervision, and validation. In this view, generative models function as \\emph{label amplifiers}, leveraging small human-curated cores via active, semi-supervised, and self-training loops, while humans retain oversight for calibration, drift detection, and failure auditing. Thus, extreme computational speed reduces wall-clock time but not the fundamental supervision needs of learning; initial human (or human-grade) input remains necessary to ground the system in the intended task.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10446","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.715171","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Masoud Makrehchi","raw_content_length":1393,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["the Economics of Annotation","\\(A\\","\\(B\\"],"persons":[],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["Supervision","Scale","Exponential Search","the Economics","Annotation","Announce Type","new Abstract","a reversed-supervision strategy","labelings","a large unlabeled"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Supervision":2.0,"Scale":2.0,"Exponential Search":2.0,"the Economics":2.0,"Annotation":2.0,"Announce Type":1.0,"new Abstract":1.0,"a reversed-supervision strategy":1.0,"labelings":1.0,"a large unlabeled":1.0}},"age_hours":2.751139401111111,"is_recent":true,"quality_score":1.0,"sentiment_score":3.928,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2144,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7134,"joy":0.009,"surprise":0.2072,"sadness":0.0095,"fear":0.0133,"anger":0.0324,"disgust":0.0153},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article focuses on a theoretical approach to machine learning and label generation. While it discusses the potential for generative AI to act as 'label amplifiers,' it lacks concrete actions or deployed technology. The research is in its early stages and does not provide measurable outcomes related to climate impact or sustainability.","key_impact_metrics":[],"technology_tags":["machine learning","generative AI","reverse supervision"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:22:04.626024Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_283f593670bb","title":"RECON: Reasoning with Condensation for Efficient Retrieval","content":"arXiv:2510.10448v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) systems trained using reinforcement learning (RL) with reasoning are hampered by inefficient context management, where long, noisy retrieved documents increase costs and degrade performance. We introduce RECON (REasoning with CONdensation), a framework that integrates an explicit summarization module to compress evidence within the reasoning loop. Our summarizer is trained via a two-stage process: relevance pretraining on QA datasets, followed by multi-aspect distillation from proprietary LLMs to ensure factuality and clarity. Integrated into the Search-R1 pipeline, RECON reduces total context length by 35\\%, leading to improved training speed and inference latency, while simultaneously improving RAG performance on downstream QA benchmarks. Notably, it boosts the average EM score of the 3B model by 14.5\\% and the 7B model by 3.0\\%, showing particular strength in multi-hop QA. RECON demonstrates that learned context compression is essential for building practical, scalable, and performant RAG systems. Our code implementation is made available at https://github.com/allfornancy/RECON.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10448","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.715585","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Zhichao Xu, Minheng Wang, Yawei Wang, Wenqian Ye, Yuntao Du, Yunpu Ma, Yijun Tian","raw_content_length":1184,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Search-R1","RAG"],"persons":["arXiv:2510.10448v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1183,"language_detected":"en","key_concepts":{"key_phrases":["RECON","Condensation","Efficient Retrieval","arXiv251010448v1 Announce Type","new Abstract Retrieval-augmented generation RAG systems","reinforcement learning","reasoning","inefficient context management","documents","costs"],"filter_categories":{"ai_ml":["reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RECON":3.0,"Condensation":2.0,"Efficient Retrieval":2.0,"arXiv251010448v1 Announce Type":1.0,"new Abstract Retrieval-augmented generation RAG systems":1.0,"reinforcement learning":1.0,"reasoning":1.0,"inefficient context management":1.0,"documents":1.0,"costs":1.0}},"age_hours":2.7511545402777777,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7513,"joy":0.0043,"surprise":0.0273,"sadness":0.029,"fear":0.0226,"anger":0.0843,"disgust":0.0812},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (RECON) for improving the efficiency of retrieval-augmented generation (RAG) systems. The concrete action is the development of a summarization module that reduces context length by 35%, leading to improved training speed and inference latency. The evidence supporting the claims includes a 14.5% boost in the average EM score of a 3B model and a 3.0% boost for a 7B model on downstream QA benchmarks. This is currently in the applied research stage, with code implementation available but no large-scale deployment data.","key_impact_metrics":["Context length reduction by 35%","EM score increase of 14.5% for 3B model"],"technology_tags":["Retrieval-Augmented Generation","Reinforcement Learning","Context Compression","Summarization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:22:07.917387Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90803c7d3676","title":"Towards Dynamic Quadrupedal Gaits: A Symmetry","content":"arXiv:2510.10455v1 Announce Type: new Abstract: Quadrupedal robots exhibit a wide range of viable gaits, but generating specific footfall sequences often requires laborious expert tuning of numerous variables, such as touch-down and lift-off events and holonomic constraints for each leg. This paper presents a unified reinforcement learning framework for generating versatile quadrupedal gaits by leveraging the intrinsic symmetries and velocity-period relationship of dynamic legged systems. We propose a symmetry-guided reward function design that incorporates temporal, morphological, and time-reversal symmetries. By focusing on preserved symmetries and natural dynamics, our approach eliminates the need for predefined trajectories, enabling smooth transitions between diverse locomotion patterns such as trotting, bounding, half-bounding, and galloping. Implemented on the Unitree Go2 robot, our method demonstrates robust performance across a range of speeds in both simulations and hardware tests, significantly improving gait adaptability without extensive reward tuning or explicit foot placement control. This work provides insights into dynamic locomotion strategies and underscores the crucial role of symmetries in robotic gait design.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10455","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.717987","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Jiayu Ding, Xulin Chen, Garrett E. Katz, Zhenyu Gan","raw_content_length":1251,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Unitree"],"persons":[],"locations":[],"monetary":[]},"char_count":1250,"language_detected":"en","key_concepts":{"key_phrases":["Dynamic Quadrupedal Gaits","A Symmetry","arXiv251010455v1 Announce Type","new Abstract","Quadrupedal robots","a wide range","viable gaits","specific footfall sequences","laborious expert tuning","numerous variables"],"filter_categories":{"ai_ml":["Dynamic Quadrupedal Gaits"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dynamic Quadrupedal Gaits":2.0,"A Symmetry":2.0,"arXiv251010455v1 Announce Type":1.0,"new Abstract":1.0,"Quadrupedal robots":1.0,"a wide range":1.0,"viable gaits":1.0,"specific footfall sequences":1.0,"laborious expert tuning":1.0,"numerous variables":1.0}},"age_hours":2.7512447222222223,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6369,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9179,"joy":0.0194,"surprise":0.0393,"sadness":0.0051,"fear":0.0057,"anger":0.0085,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a reinforcement learning framework for quadrupedal robot gaits, demonstrating improved adaptability in simulations and hardware tests on the Unitree Go2 robot. The concrete action is the implementation and testing of the algorithm on a physical robot, showing improved gait adaptability. However, the sustainability impact is indirect, potentially reducing energy consumption in specific applications but lacking quantifiable GHG reduction or systemic impact at this stage.","key_impact_metrics":["Improved gait adaptability","Robust performance across a range of speeds"],"technology_tags":["Reinforcement Learning","Quadrupedal Robots","Robotics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:10.978210Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8cf902e3e0db","title":"On the Problem of Consistent Anomalies in Zero","content":"arXiv:2510.10456v1 Announce Type: new Abstract: Zero-shot image anomaly classification (AC) and segmentation (AS) are vital for industrial quality control, detecting defects without prior training data. Existing representation-based methods compare patch features with nearest neighbors in unlabeled test images but struggle with consistent anomalies -- similar defects recurring across multiple images -- resulting in poor AC/AS performance. We introduce Consistent-Anomaly Detection Graph (CoDeGraph), a novel algorithm that identifies and filters consistent anomalies from similarity computations. Our key insight is that normal patches in industrial images show stable, gradually increasing similarity to other test images, while consistent-anomaly patches exhibit abrupt similarity spikes after exhausting a limited set of similar matches, a phenomenon we term ``neighbor-burnout.'' CoDeGraph constructs an image-level graph, with images as nodes and edges connecting those with shared consistent-anomaly patterns, using community detection to filter these anomalies. We provide a theoretical foundation using Extreme Value Theory to explain the effectiveness of our approach. Experiments on MVTec AD with the ViT-L-14-336 backbone achieve 98.3% AUROC for AC and AS performance of 66.8% (+4.2%) F1 and 68.1% (+5.4%) AP over state-of-the-art zero-shot methods. Using the DINOv2 backbone further improves segmentation, yielding 69.1% (+6.5%) F1 and 71.9% (+9.2%) AP, demonstrating robustness across architectures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10456","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.718399","language":"en","tags":["computer-science","statap","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Tai Le-Gia, Ahn Jaehyun","raw_content_length":1517,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["the Problem of Consistent Anomalies","Consistent-Anomaly Detection Graph"],"persons":[],"locations":[],"monetary":[]},"char_count":1516,"language_detected":"en","key_concepts":{"key_phrases":["the Problem","Consistent Anomalies","arXiv251010456v1 Announce Type","new Abstract","Zero-shot image anomaly classification","segmentation","industrial quality control","defects","prior training data","Existing representation-based methods"],"filter_categories":{"ai_ml":["prior training data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Problem":2.0,"Consistent Anomalies":2.0,"arXiv251010456v1 Announce Type":1.0,"new Abstract":1.0,"Zero-shot image anomaly classification":1.0,"segmentation":1.0,"industrial quality control":1.0,"defects":1.0,"prior training data":1.0,"Existing representation-based methods":1.0}},"age_hours":2.751259625,"is_recent":true,"quality_score":1.0,"sentiment_score":0.42800000000000005,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9144,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8478,"joy":0.0036,"surprise":0.0218,"sadness":0.0572,"fear":0.0273,"anger":0.0256,"disgust":0.0168},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm for anomaly detection in industrial quality control, potentially reducing waste and energy consumption in manufacturing. The approach is validated with experiments on MVTec AD, achieving improved AUROC, F1, and AP scores compared to existing methods. However, it is still in the applied research stage with no deployed units or real-world operational data.","key_impact_metrics":["98.3% AUROC","69.1% F1"],"technology_tags":["image anomaly classification","machine vision"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:22:13.976466Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ec1cb9196a0c","title":"Rethinking LLM Evaluation: Can We Evaluate LLMs with 200x Less Data?","content":"arXiv:2510.10457v1 Announce Type: new Abstract: As the demand for comprehensive evaluations of diverse model capabilities steadily increases, benchmark suites have correspondingly grown significantly in scale. Despite notable advances in redundancy reduction and subset-level performance prediction, a systematic framework that effectively integrates these methods to ensure both prediction accuracy and ranking consistency is still largely elusive. In this paper, we first perform a sample-level analysis of benchmark redundancy and identify several highly similar samples that can be eliminated. Besides, we frame benchmark compression as an optimization problem with the aim of score reconstruction. Building on these, we then propose EssenceBench, a coarse-to-fine framework utilizing an iterative Genetic Algorithm (GA), which takes the advantages of fitness-based subset search and attribution-based sample search. Compared to previous methods, our approach yields superior compression results with lower reconstruction error and markedly higher efficiency. In particular, on the HellaSwag benchmark (10K samples), our method preserves the ranking of all models shifting within 5% using 25x fewer samples, and achieves 95% ranking preservation shifting within 5% using only 200x fewer samples.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10457","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.718819","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Shaobo Wang, Cong Wang, Wenjie Fu, Yue Min, Mingquan Feng, Isabel Guan, Xuming Hu, Conghui He, Cunxiang Wang, Kexin Yang, Xingzhang Ren, Fei Huang, Dayiheng Liu, Linfeng Zhang","raw_content_length":1300,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["EssenceBench"],"persons":[],"locations":[],"monetary":[]},"char_count":1299,"language_detected":"en","key_concepts":{"key_phrases":["LLM Evaluation","LLMs","200x Less Data","arXiv251010457v1 Announce Type","new Abstract","the demand","comprehensive evaluations","diverse model capabilities","benchmark suites","scale"],"filter_categories":{"ai_ml":["LLM Evaluation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM Evaluation":2.0,"LLMs":2.0,"200x Less Data":2.0,"arXiv251010457v1 Announce Type":1.0,"new Abstract":1.0,"the demand":1.0,"comprehensive evaluations":1.0,"diverse model capabilities":1.0,"benchmark suites":1.0,"scale":1.0}},"age_hours":2.7512742266666668,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8896,"joy":0.0179,"surprise":0.0421,"sadness":0.0067,"fear":0.0213,"anger":0.0149,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method for reducing the amount of data needed to evaluate LLMs, potentially leading to lower energy consumption for training and evaluation. The method is validated on the HellaSwag benchmark, demonstrating a reduction in data requirements while preserving model ranking. This is still in the research phase, with no deployed systems or economic viability data.","key_impact_metrics":["25x fewer samples","200x fewer samples"],"technology_tags":["LLM evaluation","Genetic Algorithm","Benchmark compression"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:22:16.989993Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ef3e282717ea","title":"Testing and Enhancing Multi","content":"arXiv:2510.10460v1 Announce Type: new Abstract: Multi-agent systems (MASs) have emerged as a promising paradigm for automated code generation, demonstrating impressive performance on established benchmarks by decomposing complex coding tasks across specialized agents with different roles. Despite their prosperous development and adoption, their robustness remains pressingly under-explored, raising critical concerns for real-world deployment. This paper presents the first comprehensive study examining the robustness of MASs for code generation through a fuzzing-based testing approach. By designing a fuzzing pipeline incorporating semantic-preserving mutation operators and a novel fitness function, we assess mainstream MASs across multiple datasets and LLMs. Our findings reveal substantial robustness flaws of various popular MASs: they fail to solve 7.9%-83.3% of problems they initially resolved successfully after applying the semantic-preserving mutations. Through comprehensive failure analysis, we identify a common yet largely overlooked cause of the robustness issue: miscommunications between planning and coding agents, where plans lack sufficient detail and coding agents misinterpret intricate logic, aligning with the challenges inherent in a multi-stage information transformation process. Accordingly, we also propose a repairing method that encompasses multi-prompt generation and introduces a new monitor agent to address this issue. Evaluation shows that our repairing method effectively enhances the robustness of MASs by solving 40.0%-88.9% of identified failures. Our work uncovers critical robustness flaws in MASs and provides effective mitigation strategies, contributing essential insights for developing more reliable MASs for code generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10460","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.719658","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Zongyi Lyu, Songqiang Chen, Zhenlan Ji, Liwen Wang, Shuai Wang, Daoyuan Wu, Wenxuan Wang, Shing-Chi Cheung","raw_content_length":1779,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1778,"language_detected":"en","key_concepts":{"key_phrases":["Testing","Enhancing","Multi","arXiv251010460v1 Announce Type","new Abstract","Multi-agent systems","MASs","a promising paradigm","automated code generation","impressive performance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Testing":2.0,"Enhancing":2.0,"Multi":2.0,"arXiv251010460v1 Announce Type":1.0,"new Abstract":1.0,"Multi-agent systems":1.0,"MASs":1.0,"a promising paradigm":1.0,"automated code generation":1.0,"impressive performance":1.0}},"age_hours":2.7513026047222224,"is_recent":true,"quality_score":0.7,"sentiment_score":6.4185,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2837,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7449,"joy":0.0274,"surprise":0.0521,"sadness":0.0094,"fear":0.1341,"anger":0.025,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the robustness of multi-agent systems for code generation, which could indirectly improve the efficiency of software development for climate-related technologies. The research is in the applied research stage, with a fuzzing-based testing approach used to identify and address robustness flaws. The paper quantifies the failure rate of existing systems (7.9%-83.3%) and the improvement achieved by the proposed repairing method (40.0%-88.9%).","key_impact_metrics":["failure rate 7.9%-83.3%","improvement rate 40.0%-88.9%"],"technology_tags":["multi-agent systems","code generation","fuzzing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:20.423997Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_54262fa7b682","title":"MedCoAct: Confidence","content":"arXiv:2510.10461v1 Announce Type: new Abstract: Autonomous agents utilizing Large Language Models (LLMs) have demonstrated remarkable capabilities in isolated medical tasks like diagnosis and image analysis, but struggle with integrated clinical workflows that connect diagnostic reasoning and medication decisions. We identify a core limitation: existing medical AI systems process tasks in isolation without the cross-validation and knowledge integration found in clinical teams, reducing their effectiveness in real-world healthcare scenarios. To transform the isolation paradigm into a collaborative approach, we propose MedCoAct, a confidence-aware multi-agent framework that simulates clinical collaboration by integrating specialized doctor and pharmacist agents, and present a benchmark, DrugCareQA, to evaluate medical AI capabilities in integrated diagnosis and treatment workflows. Our results demonstrate that MedCoAct achieves 67.58\\% diagnostic accuracy and 67.58\\% medication recommendation accuracy, outperforming single agent framework by 7.04\\% and 7.08\\% respectively. This collaborative approach generalizes well across diverse medical domains, proving especially effective for telemedicine consultations and routine clinical scenarios, while providing interpretable decision-making pathways.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10461","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.720053","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Hongjie Zheng, Zesheng Shi, Ping Yi","raw_content_length":1313,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["MedCoAct"],"persons":[],"locations":[],"monetary":[]},"char_count":1312,"language_detected":"en","key_concepts":{"key_phrases":["MedCoAct Confidence","arXiv251010461v1 Announce Type","new Abstract","Autonomous agents","Large Language Models","LLMs","remarkable capabilities","isolated medical tasks","diagnosis and image analysis","integrated clinical workflows"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MedCoAct Confidence":2.0,"arXiv251010461v1 Announce Type":1.0,"new Abstract":1.0,"Autonomous agents":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable capabilities":1.0,"isolated medical tasks":1.0,"diagnosis and image analysis":1.0,"integrated clinical workflows":1.0}},"age_hours":2.75131623,"is_recent":true,"quality_score":1.0,"sentiment_score":1.522,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6956,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7757,"joy":0.0096,"surprise":0.1195,"sadness":0.024,"fear":0.0439,"anger":0.0161,"disgust":0.0112},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework (MedCoAct) for medical diagnosis and treatment. While it demonstrates improved accuracy compared to single-agent systems (67.58% vs. 7.04% improvement), it is still in the research phase with no real-world deployment. The potential climate impact is indirect, through improved healthcare efficiency and reduced travel for telemedicine, but not directly quantified.","key_impact_metrics":["diagnostic accuracy 67.58%","medication recommendation accuracy 67.58%"],"technology_tags":["AI","Large Language Models","Medical Diagnosis","Telemedicine"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:22:24.029188Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_967e914e3436","title":"LightSAE: Parameter","content":"arXiv:2510.10465v1 Announce Type: new Abstract: Modern Internet of Things (IoT) systems generate massive, heterogeneous multivariate time series data. Accurate Multivariate Time Series Forecasting (MTSF) of such data is critical for numerous applications. However, existing methods almost universally employ a shared embedding layer that processes all channels identically, creating a representational bottleneck that obscures valuable channel-specific information. To address this challenge, we introduce a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into a shared base component capturing common patterns and channel-specific auxiliary components modeling unique deviations. Within this decomposition, we \\rev{empirically observe} that the auxiliary components tend to exhibit low-rank and clustering characteristics, a structural pattern that is significantly less apparent when using purely independent embeddings. Consequently, we design LightSAE, a parameter-efficient embedding module that operationalizes these observed characteristics through low-rank factorization and a shared, gated component pool. Extensive experiments across 9 IoT-related datasets and 4 backbone architectures demonstrate LightSAE's effectiveness, achieving MSE improvements of up to 22.8\\% with only 4.0\\% parameter increase.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10465","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.721267","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Yi Ren, Xinjie Yu","raw_content_length":1338,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["LightSAE","IoT","Accurate Multivariate Time Series Forecasting","SAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1337,"language_detected":"en","key_concepts":{"key_phrases":["LightSAE","Parameter","new Abstract","Things","massive heterogeneous multivariate time series data","Accurate Multivariate Time Series Forecasting","MTSF","such data","numerous applications","existing methods"],"filter_categories":{"engineering":["Things"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LightSAE":2.0,"Parameter":2.0,"new Abstract":1.0,"Things":1.0,"massive heterogeneous multivariate time series data":1.0,"Accurate Multivariate Time Series Forecasting":1.0,"MTSF":1.0,"such data":1.0,"numerous applications":1.0,"existing methods":1.0}},"age_hours":2.7513606425,"is_recent":true,"quality_score":1.0,"sentiment_score":8.49,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.698,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9209,"joy":0.0069,"surprise":0.0302,"sadness":0.0076,"fear":0.0086,"anger":0.0166,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (LightSAE) for improving the efficiency of multivariate time series forecasting in IoT systems, which could lead to energy savings in various applications. The method is validated with experiments across 9 IoT datasets, showing MSE improvements of up to 22.8% with a small parameter increase. However, it is still in the research phase with no deployed units or customer contracts.","key_impact_metrics":["MSE improvement 22.8%","Parameter increase 4.0%"],"technology_tags":["IoT","Multivariate Time Series Forecasting","Machine Learning","Energy Efficiency"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T11:22:27.354198Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9e57ec1425b8","title":"When Images Speak Louder: Mitigating Language Bias","content":"arXiv:2510.10466v1 Announce Type: new Abstract: Vision-Language Models (VLMs) have shown solid ability for multimodal understanding of both visual and language contexts. However, existing VLMs often face severe challenges of hallucinations, meaning that VLMs tend to generate responses that are only fluent in the language but irrelevant to images in previous contexts. To address this issue, we analyze how language bias contributes to hallucinations and then introduce Cross-Modal Guidance(CMG), a training-free decoding method that addresses the hallucinations by leveraging the difference between the output distributions of the original model and the one with degraded visual-language attention. In practice, we adaptively mask the attention weight of the most influential image tokens in selected transformer layers to corrupt the visual-language perception as a concrete type of degradation. Such a degradation-induced decoding emphasizes the perception of visual contexts and therefore significantly reduces language bias without harming the ability of VLMs. In experiment sections, we conduct comprehensive studies. All results demonstrate the superior advantages of CMG with neither additional conditions nor training costs. We also quantitatively show CMG can improve different VLM's performance on hallucination-specific benchmarks and generalize effectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10466","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.721683","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Jinjin Cao, Zhiyang Chen, Zijun Wang, Liyuan Ma, Weijian Luo, Guojun Qi","raw_content_length":1372,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Vision-Language Models","Cross-Modal Guidance(CMG"],"persons":["Speak Louder"],"locations":[],"monetary":[]},"char_count":1371,"language_detected":"en","key_concepts":{"key_phrases":["Images","Language Bias","VLMs","hallucinations","arXiv251010466v1 Announce Type","new Abstract","Vision-Language Models","solid ability","multimodal understanding","both visual and language contexts"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Images":2.0,"Language Bias":2.0,"VLMs":2.0,"hallucinations":2.0,"arXiv251010466v1 Announce Type":1.0,"new Abstract":1.0,"Vision-Language Models":1.0,"solid ability":1.0,"multimodal understanding":1.0,"both visual and language contexts":1.0}},"age_hours":2.7513751725,"is_recent":true,"quality_score":1.0,"sentiment_score":4.36,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5837,"joy":0.0033,"surprise":0.0347,"sadness":0.0293,"fear":0.2794,"anger":0.0338,"disgust":0.0357},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (CMG) to mitigate language bias in Vision-Language Models (VLMs), which could indirectly support sustainability efforts by improving the accuracy of AI systems used for environmental monitoring or analysis. However, the direct climate impact is minimal as it is a theoretical method with no current deployment. The article quantitatively shows CMG can improve different VLM's performance on hallucination-specific benchmarks.","key_impact_metrics":["Improvement on hallucination-specific benchmarks"],"technology_tags":["Vision-Language Models","AI","Cross-Modal Guidance"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:31.395729Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_65e028ed49aa","title":"AnyBCQ: Hardware Efficient Flexible Binary","content":"arXiv:2510.10467v1 Announce Type: new Abstract: The deployment of large language models (LLMs) is increasingly constrained by memory and latency bottlenecks, motivating the need for quantization techniques that flexibly balance accuracy and efficiency. Recent work has introduced multi-precision models, which enable inference at multiple precisions within a single model depending on runtime constraints. To support such flexibility, quantized weights are often stored as bit-planes, where hardware efficiency improves when the compute operates directly at the bit-plane level and activates only the precision required by each request. In this work, we present AnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded Quantization (BCQ) that supports direct bit-plane operations. By representing weights as binary bit-planes with corresponding scale factors, AnyBCQ enables bit-plane-level computation and maps naturally to accelerator-friendly, bit-parallel arithmetic. Our progressive precision expansion mechanism incrementally refines scaling factors while reusing previously assigned binary codes, yielding monotonic improvements in accuracy as additional bits are enabled. We further co-design a specialized kernel that exploits the BCQ structure to support dynamic per-request precision selection with negligible overhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly narrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains competitive at higher precision, and achieves throughput gains of up to 3.0x over half precision and 1.2x over state-of-the-art multi-precision methods. By aligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a practical foundation for multi-precision LLM deployment across diverse service-level objectives.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10467","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.722095","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Gunho Park, Jeongin Bae, Beomseok Kwon, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee","raw_content_length":1809,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Binary-Coded Quantization"],"persons":[],"locations":[],"monetary":[]},"char_count":1808,"language_detected":"en","key_concepts":{"key_phrases":["AnyBCQ","arXiv251010467v1 Announce Type","new Abstract","The deployment","large language models","LLMs","memory and latency bottlenecks","the need","quantization techniques","Recent work"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AnyBCQ":2.0,"arXiv251010467v1 Announce Type":1.0,"new Abstract":1.0,"The deployment":1.0,"large language models":1.0,"LLMs":1.0,"memory and latency bottlenecks":1.0,"the need":1.0,"quantization techniques":1.0,"Recent work":1.0}},"age_hours":2.751390273333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.685500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9371,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9164,"joy":0.0115,"surprise":0.0331,"sadness":0.0027,"fear":0.0133,"anger":0.0166,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel quantization technique (AnyBCQ) for LLMs that improves hardware efficiency and throughput. The concrete action is the development of a new algorithm and kernel. The evidence supporting claims are the throughput gains of up to 3.0x over half precision and 1.2x over state-of-the-art multi-precision methods. The innovation stage is applied research as it is demonstrated on recent LLMs, but not yet deployed in real-world applications.","key_impact_metrics":["throughput gains over half precision: 3.0x","throughput gains over state-of-the-art multi-precision methods: 1.2x"],"technology_tags":["quantization","large language models","hardware acceleration"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:34.754374Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_387496277da4","title":"Galilean Symmetry in Robotics","content":"arXiv:2510.10468v1 Announce Type: new Abstract: Galilean symmetry is the natural symmetry of inertial motion that underpins Newtonian physics. Although rigid-body symmetry is one of the most established and fundamental tools in robotics, there appears to be no comparable treatment of Galilean symmetry for a robotics audience. In this paper, we present a robotics-tailored exposition of Galilean symmetry that leverages the community's familiarity with and understanding of rigid-body transformations and pose representations. Our approach contrasts with common treatments in the physics literature that introduce Galilean symmetry as a stepping stone to Einstein's relativity. A key insight is that the Galilean matrix Lie group can be used to describe two different pose representations, Galilean frames, that use inertial velocity in the state definition, and extended poses, that use coordinate velocity. We provide three examples where applying the Galilean matrix Lie-group algebra to robotics problems is straightforward and yields significant insights: inertial navigation above the rotating Earth, manipulator kinematics, and sensor data fusion under temporal uncertainty. We believe that the time is right for the robotics community to benefit from rediscovering and extending this classical material and applying it to modern problems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10468","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.722502","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Robert Mahony, Jonathan Kelly, Stephan Weiss","raw_content_length":1348,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Galilean Symmetry"],"persons":["Lie","Einstein"],"locations":[],"monetary":[]},"char_count":1347,"language_detected":"en","key_concepts":{"key_phrases":["Galilean symmetry","Galilean Symmetry","Robotics","new Abstract","the natural symmetry","inertial motion","Newtonian physics","rigid-body symmetry","the most established and fundamental tools","robotics"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Galilean symmetry":3.0,"Galilean Symmetry":2.0,"Robotics":2.0,"new Abstract":1.0,"the natural symmetry":1.0,"inertial motion":1.0,"Newtonian physics":1.0,"rigid-body symmetry":1.0,"the most established and fundamental tools":1.0,"robotics":1.0}},"age_hours":2.751404895277778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9111,"joy":0.0221,"surprise":0.0472,"sadness":0.0032,"fear":0.0049,"anger":0.0055,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for applying Galilean symmetry to robotics. While the framework could potentially improve the efficiency or accuracy of robotic systems used in sustainable applications (e.g., precision agriculture, renewable energy maintenance), there are no concrete deployments or measurable outcomes presented in the article. The research is at a basic research stage, lacking evidence of economic viability or deployment readiness.","key_impact_metrics":[],"technology_tags":["robotics","inertial navigation","sensor fusion"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:22:38.443002Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a605a53b992e","title":"DAGLFNet:Deep Attention-Guided Global","content":"arXiv:2510.10471v1 Announce Type: new Abstract: Environmental perception systems play a critical role in high-precision mapping and autonomous navigation, with LiDAR serving as a core sensor that provides accurate 3D point cloud data. How to efficiently process unstructured point clouds while extracting structured semantic information remains a significant challenge, and in recent years, numerous pseudo-image-based representation methods have emerged to achieve a balance between efficiency and performance. However, they often overlook the structural and semantic details of point clouds, resulting in limited feature fusion and discriminability. In this work, we propose DAGLFNet, a pseudo-image-based semantic segmentation framework designed to extract discriminative features. First, the Global-Local Feature Fusion Encoding module is used to enhance the correlation among local features within a set and capture global contextual information. Second, the Multi-Branch Feature Extraction network is employed to capture more neighborhood information and enhance the discriminability of contour features. Finally, a Feature Fusion via Deep Feature-guided Attention mechanism is introduced to improve the precision of cross-channel feature fusion. Experimental evaluations show that DAGLFNet achieves 69.83\\% and 78.65\\% on the validation sets of SemanticKITTI and nuScenes, respectively. The method balances high performance with real-time capability, demonstrating great potential for LiDAR-based real-time applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10471","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.722905","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Chuang Chen, Wenyi Ge","raw_content_length":1528,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["the Global-Local Feature Fusion Encoding","Deep Attention-Guided Global arXiv:2510.10471v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1527,"language_detected":"en","key_concepts":{"key_phrases":["DAGLFNet","Deep Attention-Guided Global","arXiv251010471v1 Announce Type","new Abstract","Environmental perception systems","a critical role","high-precision mapping","autonomous navigation","LiDAR","a core sensor"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DAGLFNet":2.0,"Deep Attention-Guided Global":2.0,"arXiv251010471v1 Announce Type":1.0,"new Abstract":1.0,"Environmental perception systems":1.0,"a critical role":1.0,"high-precision mapping":1.0,"autonomous navigation":1.0,"LiDAR":1.0,"a core sensor":1.0}},"age_hours":2.7514196127777777,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9203,"joy":0.0142,"surprise":0.0391,"sadness":0.0039,"fear":0.0073,"anger":0.0118,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel deep learning architecture (DAGLFNet) for improving the accuracy of LiDAR-based semantic segmentation, which is crucial for autonomous navigation. While the reported performance metrics (69.83% and 78.65% on SemanticKITTI and nuScenes, respectively) are promising, it is still in the research phase with no evidence of real-world deployment or economic viability. The potential climate impact is indirect, through enabling more efficient autonomous vehicles, but this is not quantified.","key_impact_metrics":["SemanticKITTI validation set accuracy: 69.83%","nuScenes validation set accuracy: 78.65%"],"technology_tags":["LiDAR","Semantic Segmentation","Deep Learning","Autonomous Navigation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:41.617255Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8e562adf640f","title":"FML","content":"arXiv:2510.10472v1 Announce Type: new Abstract: Large language models (LLMs) have sparked growing interest in automatic machine learning research agents. Among them, agents capable of autonomously proposing ideas and conducting machine learning experiments are particularly promising, as they maximize research automation and accelerate scientific progress by iteratively refining ideas based on experimental results. However, comprehensively evaluating such agents remains challenging. Existing benchmarks tend to overemphasize engineering aspects while neglecting academic rigor, creating barriers that obscure a clear assessment of an agent's scientific capabilities in machine learning research. They also suffer from limited task diversity, an overemphasis on application-oriented tasks over fundamental research problems, and limited scalability to realistic research settings. To address these limitations, we introduce FML-bench, a benchmark designed to evaluate automatic machine learning research agents on 8 diverse and fundamental machine learning research problems. It reduces coding burden, emphasizes fundamental problems rather than specific use cases, offers high task diversity, and is extensible to real-world machine learning GitHub repositories. Furthermore, we present a unified evaluation framework with five complementary metrics, designed to comprehensively assess agent performance on our benchmark. We evaluate state-of-the-art automatic research agents on FML-bench, and find that agents employing broad research exploration strategies outperform those focusing on narrow but deep exploration. These findings suggest that emphasizing the breadth of exploration may lead to more effective research outcomes than focusing solely on incremental refinement. Our benchmark is available at https://github.com/qrzou/FML-bench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10472","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.723321","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Qiran Zou, Hou Hei Lam, Wenhao Zhao, Yiming Tang, Tingting Chen, Samson Yu, Tianyi Zhang, Chang Liu, Xiangyang Ji, Dianbo Liu","raw_content_length":1848,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["FML"],"persons":[],"locations":[],"monetary":[]},"char_count":1847,"language_detected":"en","key_concepts":{"key_phrases":["FML","ideas","Announce Type","Large language models","LLMs","growing interest","automatic machine learning research agents","them","agents","machine"],"filter_categories":{"ai_ml":["FML","Large language models","automatic machine learning research agents","machine"],"research_academic":["automatic machine learning research agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FML":2.0,"ideas":2.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"growing interest":1.0,"automatic machine learning research agents":1.0,"them":1.0,"agents":1.0,"machine":1.0}},"age_hours":2.751433012777778,"is_recent":true,"quality_score":0.7,"sentiment_score":9.567,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9134,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8002,"joy":0.0368,"surprise":0.0191,"sadness":0.0055,"fear":0.0829,"anger":0.0356,"disgust":0.0199},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a new benchmark, FML-bench, for evaluating automatic machine learning research agents. While it doesn't directly reduce GHG emissions, it aims to accelerate scientific progress in machine learning, which could indirectly lead to climate solutions. The benchmark itself is in the early stages of research and development, with no immediate deployment or economic viability.","key_impact_metrics":["8 diverse research problems","5 complementary metrics"],"technology_tags":["machine learning","artificial intelligence","automatic research agents"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:22:45.024257Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cbd7f031fd58","title":"When or What? Understanding Consumer Engagement on Digital Platforms","content":"arXiv:2510.10474v1 Announce Type: new Abstract: Understanding what drives popularity is critical in today's digital service economy, where content creators compete for consumer attention. Prior studies have primarily emphasized the role of content features, yet creators often misjudge what audiences actually value. This study applies Latent Dirichlet Allocation (LDA) modeling to a large corpus of TED Talks, treating the platform as a case of digital service provision in which creators (speakers) and consumers (audiences) interact. By comparing the thematic supply of creators with the demand expressed in audience engagement, we identify persistent mismatches between producer offerings and consumer preferences. Our longitudinal analysis further reveals that temporal dynamics exert a stronger influence on consumer engagement than thematic content, suggesting that when content is delivered may matter more than what is delivered. These findings challenge the dominant assumption that content features are the primary drivers of popularity and highlight the importance of timing and contextual factors in shaping consumer responses. The results provide new insights into consumer attention dynamics on digital platforms and carry practical implications for marketers, platform managers, and content creators seeking to optimize audience engagement strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10474","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.723735","language":"en","tags":["computer-science","cscy","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Jingyi Wu, Junying Liang","raw_content_length":1368,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Digital Platforms"],"persons":["TED Talks","Announce Type"],"locations":[],"monetary":[]},"char_count":1367,"language_detected":"en","key_concepts":{"key_phrases":["When or What","Consumer Engagement","Digital Platforms","what","Announce Type","new Abstract","popularity","todays digital service economy","content creators","consumer attention"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"When or What":2.0,"Consumer Engagement":2.0,"Digital Platforms":2.0,"what":2.0,"Announce Type":1.0,"new Abstract":1.0,"popularity":1.0,"todays digital service economy":1.0,"content creators":1.0,"consumer attention":1.0}},"age_hours":2.7514477455555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6868,"joy":0.004,"surprise":0.1547,"sadness":0.0088,"fear":0.0191,"anger":0.0927,"disgust":0.0339},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores consumer engagement on digital platforms, specifically TED Talks, using LDA modeling. While it identifies mismatches between content supply and demand and the importance of timing, it does not directly address climate change, GHG emissions, or other environmental sustainability issues. The research is at a basic research stage with peer-reviewed validation, but lacks concrete actions or measurable outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Latent Dirichlet Allocation","Digital Platform Analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:22:47.803751Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0b4af0ee2d9","title":"Assessing Large Language Models for Structured Medical Order Extraction","content":"arXiv:2510.10475v1 Announce Type: new Abstract: Medical order extraction is essential for structuring actionable clinical information, supporting decision-making, and enabling downstream applications such as documentation and workflow automation. Orders may be embedded in diverse sources, including electronic health records, discharge summaries, and multi-turn doctor-patient dialogues, and can span categories such as medications, laboratory tests, imaging studies, and follow-up actions. The MEDIQA-OE 2025 shared task focuses on extracting structured medical orders from extended conversational transcripts, requiring the identification of order type, description, reason, and provenance. We present the MasonNLP submission, which ranked 5th among 17 participating teams with 105 total submissions. Our approach uses a general-purpose, instruction-tuned LLaMA-4 17B model without domain-specific fine-tuning, guided by a single in-context example. This few-shot configuration achieved an average F1 score of 37.76, with notable improvements in reason and provenance accuracy. These results demonstrate that large, non-domain-specific LLMs, when paired with effective prompt engineering, can serve as strong, scalable baselines for specialized clinical NLP tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10475","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.724118","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"A H M Rezaul Karim, Ozlem Uzuner","raw_content_length":1268,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1267,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Structured Medical Order Extraction","new Abstract","Medical order extraction","actionable clinical information","decision-making","downstream applications","documentation","workflow automation","Orders"],"filter_categories":{"ai_ml":["Large Language Models"],"engineering":["workflow automation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":2.0,"Structured Medical Order Extraction":2.0,"new Abstract":1.0,"Medical order extraction":1.0,"actionable clinical information":1.0,"decision-making":1.0,"downstream applications":1.0,"documentation":1.0,"workflow automation":1.0,"Orders":1.0}},"age_hours":2.7514633633333334,"is_recent":true,"quality_score":0.7,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9255,"joy":0.0099,"surprise":0.0417,"sadness":0.0038,"fear":0.0075,"anger":0.0073,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research on using large language models for medical order extraction, achieving an average F1 score of 37.76 in a shared task. While this demonstrates potential for improving healthcare workflows, it's still in the research phase with no concrete deployment or measurable environmental impact. The vaporware flag is raised because it's a prototype with no deployed units or customer contracts.","key_impact_metrics":["F1 score 37.76"],"technology_tags":["Large Language Models","Medical Order Extraction"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:22:52.170145Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_31cb4e06b54c","title":"Anchor","content":"arXiv:2510.10477v1 Announce Type: new Abstract: The relative similarity testing aims to determine which of the distributions, P or Q, is closer to an anchor distribution U. Existing kernel-based approaches often test the relative similarity with a fixed kernel in a manually specified alternative hypothesis, e.g., Q is closer to U than P. Although kernel selection is known to be important to kernel-based testing methods, the manually specified hypothesis poses a significant challenge for kernel selection in relative similarity testing: Once the hypothesis is specified first, we can always find a kernel such that the hypothesis is rejected. This challenge makes relative similarity testing ill-defined when we want to select a good kernel after the hypothesis is specified. In this paper, we cope with this challenge via learning a proper hypothesis and a kernel simultaneously, instead of learning a kernel after manually specifying the hypothesis. We propose an anchor-based maximum discrepancy (AMD), which defines the relative similarity as the maximum discrepancy between the distances of (U, P) and (U, Q) in a space of deep kernels. Based on AMD, our testing incorporates two phases. In Phase I, we estimate the AMD over the deep kernel space and infer the potential hypothesis. In Phase II, we assess the statistical significance of the potential hypothesis, where we propose a unified testing framework to derive thresholds for tests over different possible hypotheses from Phase I. Lastly, we validate our method theoretically and demonstrate its effectiveness via extensive experiments on benchmark datasets. Codes are publicly available at: https://github.com/zhijianzhouml/AMD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10477","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.724539","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Zhijian Zhou, Liuhua Peng, Xunye Tian, Feng Liu","raw_content_length":1697,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1696,"language_detected":"en","key_concepts":{"key_phrases":["Anchor","arXiv251010477v1 Announce Type","new Abstract","The relative similarity testing","which","the distributions","an anchor distribution","U Existing kernel-based approaches","the relative similarity","a fixed kernel"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Anchor":2.0,"arXiv251010477v1 Announce Type":1.0,"new Abstract":1.0,"The relative similarity testing":1.0,"which":1.0,"the distributions":1.0,"an anchor distribution":1.0,"U Existing kernel-based approaches":1.0,"the relative similarity":1.0,"a fixed kernel":1.0}},"age_hours":2.7514783491666663,"is_recent":true,"quality_score":0.7,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8188,"joy":0.0193,"surprise":0.0716,"sadness":0.0158,"fear":0.0455,"anger":0.0213,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for relative similarity testing using deep kernels. While it could potentially be used to improve the efficiency of machine learning models used in sustainability applications (e.g., optimizing energy consumption), it is currently at the basic research stage with no concrete deployment or measurable impact on climate change or other sustainability dimensions. The code is available, suggesting potential for future development and application.","key_impact_metrics":[],"technology_tags":["machine learning","kernel methods","deep learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:56.448134Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f27e98a7dc9e","title":"MSF-Mamba: Motion","content":"arXiv:2510.10478v1 Announce Type: new Abstract: Micro-gesture recognition (MGR) targets the identification of subtle and fine-grained human motions and requires accurate modeling of both long-range and local spatiotemporal dependencies. While CNNs are effective at capturing local patterns, they struggle with long-range dependencies due to their limited receptive fields. Transformer-based models address this limitation through self-attention mechanisms but suffer from high computational costs. Recently, Mamba has shown promise as an efficient model, leveraging state space models (SSMs) to enable linear-time processing However, directly applying the vanilla Mamba to MGR may not be optimal. This is because Mamba processes inputs as 1D sequences, with state updates relying solely on the previous state, and thus lacks the ability to model local spatiotemporal dependencies. In addition, previous methods lack a design of motion-awareness, which is crucial in MGR. To overcome these limitations, we propose motion-aware state fusion mamba (MSF-Mamba), which enhances Mamba with local spatiotemporal modeling by fusing local contextual neighboring states. Our design introduces a motion-aware state fusion module based on central frame difference (CFD). Furthermore, a multiscale version named MSF-Mamba+ has been proposed. Specifically, MSF-Mamba supports multiscale motion-aware state fusion, as well as an adaptive scale weighting module that dynamically weighs the fused states across different scales. These enhancements explicitly address the limitations of vanilla Mamba by enabling motion-aware local spatiotemporal modeling, allowing MSF-Mamba and MSF-Mamba to effectively capture subtle motion cues for MGR. Experiments on two public MGR datasets demonstrate that even the lightweight version, namely, MSF-Mamba, achieves SoTA performance, outperforming existing CNN-, Transformer-, and SSM-based models while maintaining high efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10478","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.724958","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":259,"author":"Deng Li, Jun Shao, Bohao Xing, Rong Gao, Bihan Wen, Heikki K\\\"alvi\\\"ainen, Xin Liu","raw_content_length":1954,"priority":7,"update_frequency":1,"reading_time_minutes":1.295,"robust_parsing_used":true,"entities":{"organizations":["Mamba","MSF-Mamba: Motion arXiv:2510.10478v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1953,"language_detected":"en","key_concepts":{"key_phrases":["MSF-Mamba","Motion","Announce Type","new Abstract","Micro-gesture recognition","MGR","the identification","subtle and fine-grained human motions","accurate modeling","both long-range and local spatiotemporal dependencies"],"filter_categories":{"ai_ml":["subtle and fine-grained human motions"],"engineering":["both long-range and local spatiotemporal dependencies"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MSF-Mamba":2.0,"Motion":2.0,"Announce Type":1.0,"new Abstract":1.0,"Micro-gesture recognition":1.0,"MGR":1.0,"the identification":1.0,"subtle and fine-grained human motions":1.0,"accurate modeling":1.0,"both long-range and local spatiotemporal dependencies":1.0}},"age_hours":2.7514936861111114,"is_recent":true,"quality_score":1.0,"sentiment_score":1.1925000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7615,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8926,"joy":0.0036,"surprise":0.0293,"sadness":0.0362,"fear":0.0138,"anger":0.0106,"disgust":0.0139},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel micro-gesture recognition model (MSF-Mamba) that outperforms existing models in terms of efficiency and accuracy. While the technology itself doesn't directly address climate change, it could potentially improve the efficiency of human-computer interaction in various sectors, leading to indirect energy savings. The research is at the applied research stage, with experiments conducted on public datasets, but lacks real-world deployment data.","key_impact_metrics":["SoTA performance","High efficiency"],"technology_tags":["Micro-gesture recognition","State Space Models","Mamba"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:22:59.450027Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1ef3faf1f5fe","title":"Latent Retrieval Augmented Generation of Cross","content":"arXiv:2510.10480v1 Announce Type: new Abstract: Designing protein binders targeting specific sites, which requires to generate realistic and functional interaction patterns, is a fundamental challenge in drug discovery. Current structure-based generative models are limited in generating nterfaces with sufficient rationality and interpretability. In this paper, we propose Retrieval-Augmented Diffusion for Aligned interface (RADiAnce), a new framework that leverages known interfaces to guide the design of novel binders. By unifying retrieval and generation in a shared contrastive latent space, our model efficiently identifies relevant interfaces for a given binding site and seamlessly integrates them through a conditional latent diffusion generator, enabling cross-domain interface transfer. Extensive exeriments show that RADiAnce significantly outperforms baseline models across multiple metrics, including binding affinity and recovery of geometries and interactions. Additional experimental results validate cross-domain generalization, demonstrating that retrieving interfaces from diverse domains, such as peptides, antibodies, and protein fragments, enhances the generation performance of binders for other domains. Our work establishes a new paradigm for protein binder design that successfully bridges retrieval-based knowledge and generative AI, opening new possibilities for drug discovery.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10480","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.725344","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Zishen Zhang, Xiangzhe Kong, Wenbing Huang, Yang Liu","raw_content_length":1410,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Latent Retrieval Augmented Generation of Cross","Retrieval-Augmented Diffusion for Aligned"],"persons":[],"locations":[],"monetary":[]},"char_count":1409,"language_detected":"en","key_concepts":{"key_phrases":["Latent Retrieval Augmented Generation","Cross","arXiv251010480v1","Announce Type","new Abstract","Designing protein binders","specific sites","which","realistic and functional interaction patterns","a fundamental challenge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Latent Retrieval Augmented Generation":2.0,"Cross":2.0,"arXiv251010480v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Designing protein binders":1.0,"specific sites":1.0,"which":1.0,"realistic and functional interaction patterns":1.0,"a fundamental challenge":1.0}},"age_hours":2.7515083263888886,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8601,"joy":0.0229,"surprise":0.0633,"sadness":0.0053,"fear":0.018,"anger":0.0232,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new AI framework for protein binder design, potentially accelerating drug discovery. The model demonstrates improved binding affinity and recovery of geometries in experiments. However, it is still in the research phase with no deployed applications or economic viability demonstrated, thus limiting its immediate sustainability impact.","key_impact_metrics":["binding affinity","recovery of geometries and interactions"],"technology_tags":["AI","protein binder design","drug discovery"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:23:03.825062Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46ddc2848e44","title":"UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models","content":"arXiv:2510.10481v1 Announce Type: new Abstract: Diffusion LLMs have attracted growing interest, with plenty of recent work emphasizing their great potential in various downstream tasks; yet the long-context behavior of diffusion LLMs remains largely uncharted. We present a case study of post-training techniques for extending the context window of diffusion LLMs (i.e., LLaDA) without retraining from scratch. We show that a simple modification to the standard Rotary Positional Embeddings (RoPE) extension effectively accommodates the probabilistic modeling inherent in the diffusion process, enabling stable scaling to longer context ranges. We further compare masking strategies used during post-training and analyze their impact on optimization stability and long-range recall. Instantiating these insights, we introduce UltraLLaDA, a diffusion LLM with a 128K-token context window that, in our empirical evaluation on long-context tasks, significantly outperforms training-free baselines. Our experimental results highlight the special positional extension as a key lever for scaling diffusion LLMs to extended contexts and offer practical guidance for practitioners seeking 128K-scale context via efficient post-training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10481","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.725749","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Guangxin He, Shen Nie, Fengqi Zhu, Yuankang Zhao, Tianyi Bai, Ran Yan, Jie Fu, Chongxuan Li, Binhang Yuan","raw_content_length":1229,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["RoPE","Rotary Positional"],"persons":[],"locations":[],"monetary":[]},"char_count":1228,"language_detected":"en","key_concepts":{"key_phrases":["the Context Length","128K","Diffusion Large Language Models","diffusion LLMs","new Abstract","Diffusion LLMs","growing interest","plenty","recent work","their great potential"],"filter_categories":{"ai_ml":["Diffusion Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Context Length":2.0,"128K":2.0,"Diffusion Large Language Models":2.0,"diffusion LLMs":2.0,"new Abstract":1.0,"Diffusion LLMs":1.0,"growing interest":1.0,"plenty":1.0,"recent work":1.0,"their great potential":1.0}},"age_hours":2.7515244411111115,"is_recent":true,"quality_score":1.0,"sentiment_score":9.455,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.891,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8157,"joy":0.0525,"surprise":0.0915,"sadness":0.0042,"fear":0.0112,"anger":0.0176,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents research on extending the context window of diffusion LLMs. While the research shows promise in improving long-context tasks, it is still in the early stages of development with no deployed units or real-world data. The impact on climate is indirect, potentially enabling more efficient AI models, but not directly reducing emissions.","key_impact_metrics":["128K-token context window","Significant outperformance on long-context tasks"],"technology_tags":["Diffusion Large Language Models","Rotary Positional Embeddings"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:23:06.984689Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1afcda93057f","title":"Gradient Enhanced Self-Training Physics","content":"arXiv:2510.10483v1 Announce Type: new Abstract: Partial differential equations (PDEs) provide a mathematical foundation for simulating and understanding intricate behaviors in both physical sciences and engineering. With the growing capabilities of deep learning, data$-$driven approaches like Physics$-$Informed Neural Networks (PINNs) have been developed, offering a mesh$-$free, analytic type framework for efficiently solving PDEs across a wide range of applications. However, traditional PINNs often struggle with challenges such as limited precision, slow training dynamics, lack of labeled data availability, and inadequate handling of multi$-$physics interactions. To overcome these challenging issues of PINNs, we proposed a Gradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically introduces a gradient based pseudo point self$-$learning algorithm for solving PDEs. We tested the proposed method on three different types of PDE problems from various fields, each representing distinct scenarios. The effectiveness of the proposed method is evident, as the PINN approach for solving the Burgers$'$ equation attains a mean square error (MSE) on the order of $10^{-3}$, while the diffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after 12,500 iterations, with no further improvement as the iterations increase. In contrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease, demonstrating better generalization and reaching an MSE on the order of $10^{-5}$ after 18,500 iterations. Furthermore, the results show that the proposed purely semi$-$supervised gST$-$PINN consistently outperforms the standard PINN method in all cases, even when solution of the PDEs are unavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and can be effectively applied in scenarios prone to low accuracy and convergence issues, particularly in the absence of labeled data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10483","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.726179","language":"en","tags":["computer-science","cslg","physicscomp-ph","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":267,"author":"Narayan S Iyer, Bivas Bhaumik, Ram S Iyer, Satyasaran Changdar","raw_content_length":1943,"priority":7,"update_frequency":1,"reading_time_minutes":1.335,"robust_parsing_used":true,"entities":{"organizations":["Neural Networks","Gradient Enhanced Self$-$Training","PDE"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1942,"language_detected":"en","key_concepts":{"key_phrases":["Gradient Enhanced Self-Training Physics","PDEs","arXiv251010483v1 Announce Type","new Abstract Partial differential equations","a mathematical foundation","simulating","intricate behaviors","both physical sciences","engineering","the growing capabilities"],"filter_categories":{"ai_ml":["Gradient Enhanced Self-Training Physics"],"research_academic":["both physical sciences"],"engineering":["engineering"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gradient Enhanced Self-Training Physics":2.0,"PDEs":2.0,"arXiv251010483v1 Announce Type":1.0,"new Abstract Partial differential equations":1.0,"a mathematical foundation":1.0,"simulating":1.0,"intricate behaviors":1.0,"both physical sciences":1.0,"engineering":1.0,"the growing capabilities":1.0}},"age_hours":2.751538839722222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8939,"joy":0.0244,"surprise":0.0526,"sadness":0.0033,"fear":0.0084,"anger":0.0131,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method (gST-PINN) for solving PDEs, which are used in simulating physical systems. The method shows improved accuracy (MSE on the order of 10^-5) compared to standard PINNs, but is still in the research phase with no deployment or economic viability demonstrated. The potential climate impact is indirect, as it could improve simulations related to climate models or engineering of sustainable technologies.","key_impact_metrics":["MSE on the order of 10^-5"],"technology_tags":["Physics-Informed Neural Networks","Partial Differential Equations","Deep Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:23:10.523870Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_184479d337d9","title":"CAPSim: A Fast CPU Performance Simulator Using Attention","content":"arXiv:2510.10484v1 Announce Type: new Abstract: CPU simulators are vital for computer architecture research, primarily for estimating performance under different programs. This poses challenges for fast and accurate simulation of modern CPUs, especially in multi-core systems. Modern CPU peformance simulators such as GEM5 adopt the cycle-accurate and event-driven approach, which is timeconsuming to simulate the extensive microarchitectural behavior of a real benchmark running on out-of-order CPUs. Recently, machine leaning based approach has been proposed to improve simulation speed, but they are currently limited to estimating the cycles of basic blocks rather than the complete benchmark program. This paper introduces a novel ML-based CPU simulator named CAPSim, which uses an attention-based neural network performance predictor and instruction trace sampling method annotated with context. The attention mechanism effectively captures long-range influence within the instruction trace, emphasizing critical context information. This allows the model to improve performance prediction accuracy by focusing on important code instruction. CAPSim can predict the execution time of unseen benchmarks at a significantly fast speed compared with an accurate O3 simulator built with gem5. Our evaluation on a commercial Intel Xeon CPU demonstrates that CAPSim achieves a 2.2 - 8.3x speedup compared to using gem5 built simulator, which is superior to the cutting-edge deep learning approach","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10484","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.726590","language":"en","tags":["computer-science","research","cspf","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Buqing Xu, Jianfeng Zhu, Yichi Zhang, Qinyi Cai, Guanhua Li, Shaojun Wei, Leibo Liu","raw_content_length":1495,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["CPU"],"persons":[],"locations":[],"monetary":[]},"char_count":1494,"language_detected":"en","key_concepts":{"key_phrases":["CAPSim","A Fast CPU Performance Simulator","Attention","arXiv251010484v1 Announce Type","new Abstract","CPU simulators","computer architecture research","performance","different programs","challenges"],"filter_categories":{"research_academic":["computer architecture research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CAPSim":2.0,"A Fast CPU Performance Simulator":2.0,"Attention":2.0,"arXiv251010484v1 Announce Type":1.0,"new Abstract":1.0,"CPU simulators":1.0,"computer architecture research":1.0,"performance":1.0,"different programs":1.0,"challenges":1.0}},"age_hours":2.7515544008333332,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9043,"joy":0.0143,"surprise":0.0498,"sadness":0.0053,"fear":0.009,"anger":0.014,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel CPU simulator (CAPSim) that achieves a 2.2-8.3x speedup compared to gem5. This could lead to faster development and testing of energy-efficient hardware, potentially reducing energy consumption in data centers and other computing environments. However, it is currently in the applied research phase, with no deployed units.","key_impact_metrics":["2.2-8.3x speedup compared to gem5"],"technology_tags":["CPU simulation","machine learning","attention networks","computer architecture"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:23:13.530285Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_011b1eef76d4","title":"SASER: Stego attacks on open","content":"arXiv:2510.10486v1 Announce Type: new Abstract: Open-source large language models (LLMs) have demonstrated considerable dominance over proprietary LLMs in resolving neural processing tasks, thanks to the collaborative and sharing nature. Although full access to source codes, model parameters, and training data lays the groundwork for transparency, we argue that such a full-access manner is vulnerable to stego attacks, and their ill-effects are not fully understood. In this paper, we conduct a systematic formalization for stego attacks on open-source LLMs by enumerating all possible threat models associated with adversary objectives, knowledge, and capabilities. Therein, the threat posed by adversaries with internal knowledge, who inject payloads and triggers during the model sharing phase, is of practical interest. We go even further and propose the first stego attack on open-source LLMs, dubbed SASER, which wields impacts through identifying targeted parameters, embedding payloads, injecting triggers, and executing payloads sequentially. Particularly, SASER enhances the attack robustness against quantization-based local deployment by de-quantizing the embedded payloads. In addition, to achieve stealthiness, SASER devises the performance-aware importance metric to identify targeted parameters with the least degradation of model performance. Extensive experiments on LlaMA2-7B and ChatGLM3-6B, without quantization, show that the stealth rate of SASER outperforms existing stego attacks (for general DNNs) by up to 98.1%, while achieving the same attack success rate (ASR) of 100%. More importantly, SASER improves ASR on quantized models from 0 to 100% in all settings. We appeal for investigations on countermeasures against SASER in view of the significant attack effectiveness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10486","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.727002","language":"en","tags":["computer-science","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":247,"author":"Ming Tan, Wei Li, Hu Tao, Hailong Ma, Aodi Liu, Qian Chen, Zilong Wang","raw_content_length":1803,"priority":7,"update_frequency":1,"reading_time_minutes":1.235,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["Stego"],"monetary":[]},"char_count":1802,"language_detected":"en","key_concepts":{"key_phrases":["SASER","Stego attacks","arXiv251010486v1 Announce Type","new Abstract","Open-source large language models","LLMs","considerable dominance","proprietary LLMs","neural processing tasks","the collaborative"],"filter_categories":{"ai_ml":["Open-source large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SASER":2.0,"Stego attacks":2.0,"arXiv251010486v1 Announce Type":1.0,"new Abstract":1.0,"Open-source large language models":1.0,"LLMs":1.0,"considerable dominance":1.0,"proprietary LLMs":1.0,"neural processing tasks":1.0,"the collaborative":1.0}},"age_hours":2.751570506666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.377,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0754,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6482,"joy":0.0076,"surprise":0.0219,"sadness":0.0324,"fear":0.2044,"anger":0.0352,"disgust":0.0502},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel stego attack on open-source LLMs. While the research is technically sound and demonstrates measurable outcomes (stealth rate up to 98.1% and ASR of 100% on quantized models), it primarily focuses on security vulnerabilities and does not directly contribute to sustainability. The research is at an early stage and lacks deployment.","key_impact_metrics":["stealth rate 98.1%","ASR 100%"],"technology_tags":["steganography","large language models","security"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:23:16.567589Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1c17b931c6c0","title":"Towards Self","content":"arXiv:2510.10487v1 Announce Type: new Abstract: Vision-Language Models (VLMs) integrate visual knowledge with the analytical capabilities of Large Language Models (LLMs) through supervised visual instruction tuning, using image-question-answer triplets. However, the potential of VLMs trained without supervised instruction remains largely unexplored. This study validates that VLMs possess inherent self-refinement capabilities, enabling them to generate high-quality supervised data without external inputs and thereby learn autonomously. Specifically, to stimulate the self-refinement ability of VLMs, we propose a self-refinement framework based on a Triangular Consistency principle: within the image-query-answer triangle, any masked elements should be consistently and accurately reconstructed. The framework involves three steps: (1) We enable the instruction generation ability of VLMs by adding multi-task instruction tuning like image$\\rightarrow$question-answer or image-answer$\\rightarrow$question. (2) We generate image-query-answer triplets from unlabeled images and use the Triangular Consistency principle for filtering. (3) The model is further updated using the filtered synthetic data. To investigate the underlying mechanisms behind this self-refinement capability, we conduct a theoretical analysis from a causal perspective. Using the widely recognized LLaVA-1.5 as our baseline, our experiments reveal that the model can autonomously achieve consistent, though deliberately modest, improvements across multiple benchmarks without any external supervision, such as human annotations or environmental feedback. We expect that the insights of this study on the self-refinement ability of VLMs can inspire future research on the learning mechanism of VLMs. Code is available at https://github.com/dengyl20/SRF-LLaVA-1.5.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10487","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.727411","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Yunlong Deng, Guangyi Chen, Tianpei Gu, Lingjing Kong, Yan Li, Zeyu Tang, Kun Zhang","raw_content_length":1841,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Triangular","Vision-Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1840,"language_detected":"en","key_concepts":{"key_phrases":["VLMs","Self","Announce Type","new Abstract","Vision-Language Models","visual knowledge","the analytical capabilities","Large Language Models","LLMs","supervised visual instruction tuning"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VLMs":3.0,"Self":2.0,"Announce Type":1.0,"new Abstract":1.0,"Vision-Language Models":1.0,"visual knowledge":1.0,"the analytical capabilities":1.0,"Large Language Models":1.0,"LLMs":1.0,"supervised visual instruction tuning":1.0}},"age_hours":2.7515856191666668,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9193,"joy":0.02,"surprise":0.0288,"sadness":0.0072,"fear":0.0067,"anger":0.0112,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving VLMs' self-refinement capabilities. While the research is theoretically interesting and shows modest improvements across benchmarks, it is still in the basic research phase with no concrete deployment or measurable impact on sustainability. The potential climate impact is currently minimal and unproven.","key_impact_metrics":["Consistent improvements across multiple benchmarks"],"technology_tags":["Vision-Language Models","Self-Supervised Learning","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:23:19.414457Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c130b1c4d6a6","title":"Head","content":"arXiv:2510.10489v1 Announce Type: new Abstract: Transformers rely on explicit positional encoding to model structure in data. While Rotary Position Embedding (RoPE) excels in 1D domains, its application to image generation reveals significant limitations such as fine-grained spatial relation modeling, color cues, and object counting. This paper identifies key limitations of standard multi-dimensional RoPE-rigid frequency allocation, axis-wise independence, and uniform head treatment-in capturing the complex structural biases required for fine-grained image generation. We propose HARoPE, a head-wise adaptive extension that inserts a learnable linear transformation parameterized via singular value decomposition (SVD) before the rotary mapping. This lightweight modification enables dynamic frequency reallocation, semantic alignment of rotary planes, and head-specific positional receptive fields while rigorously preserving RoPE's relative-position property. Extensive experiments on class-conditional ImageNet and text-to-image generation (Flux and MMDiT) demonstrate that HARoPE consistently improves performance over strong RoPE baselines and other extensions. The method serves as an effective drop-in replacement, offering a principled and adaptable solution for enhancing positional awareness in transformer-based image generative models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10489","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.727816","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Jiaye Li, Baoyou Chen, Hui Li, Zilong Dong, Jingdong Wang, Siyu Zhu","raw_content_length":1354,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["RoPE","Rotary Position Embedding","SVD"],"persons":[],"locations":["HARoPE"],"monetary":[]},"char_count":1353,"language_detected":"en","key_concepts":{"key_phrases":["Head","new Abstract","Transformers","explicit positional encoding","structure","data","1D domains","its application","image generation","significant limitations"],"filter_categories":{"ai_ml":["Transformers","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Head":2.0,"new Abstract":1.0,"Transformers":1.0,"explicit positional encoding":1.0,"structure":1.0,"data":1.0,"1D domains":1.0,"its application":1.0,"image generation":1.0,"significant limitations":1.0}},"age_hours":2.7516007830555553,"is_recent":true,"quality_score":0.7,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.903,"joy":0.0128,"surprise":0.0572,"sadness":0.0074,"fear":0.0038,"anger":0.0088,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to positional encoding in transformer models for image generation, showing improved performance on ImageNet and text-to-image generation tasks. While the research is technically sound and demonstrates improvements over existing methods, it is still in the early stages of development with no deployed applications or quantified environmental benefits. The potential climate impact is indirect, relying on the assumption that improved image generation could lead to efficiencies in other sectors, but this is not explicitly addressed.","key_impact_metrics":["Performance improvement on ImageNet","Performance improvement on text-to-image generation"],"technology_tags":["Transformer models","Image generation","Positional encoding"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:23:22.530257Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae4332fc56af","title":"VOLTAGE: A Versatile Contrastive Learning based OCR Methodology for ultra low","content":"arXiv:2510.10490v1 Announce Type: new Abstract: UNESCO has classified 2500 out of 7000 languages spoken worldwide as endangered. Attrition of a language leads to loss of traditional wisdom, folk literature, and the essence of the community that uses it. It is therefore imperative to bring digital inclusion to these languages and avoid its extinction. Low resource languages are at a greater risk of extinction. Lack of unsupervised Optical Character Recognition(OCR) methodologies for low resource languages is one of the reasons impeding their digital inclusion. We propose VOLTAGE - a contrastive learning based OCR methodology, leveraging auto-glyph feature recommendation for cluster-based labelling. We augment the labelled data for diversity and volume using image transformations and Generative Adversarial Networks. Voltage has been designed using Takri - a family of scripts used in 16th to 20th century in the Himalayan regions of India. We present results for Takri along with other Indic scripts (both low and high resource) to substantiate the universal behavior of the methodology. An accuracy of 95% for machine printed and 87% for handwritten samples on Takri script has been achieved. We conduct baseline and ablation studies along with building downstream use cases for Takri, demonstrating the usefulness of our work.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10490","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.728201","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Prawaal Sharma, Poonam Goyal, Vidisha Sharma, Navneet Goyal","raw_content_length":1339,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["OCR Methodology","Takri","Versatile Contrastive Learning","UNESCO","Generative Adversarial Networks","OCR"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1338,"language_detected":"en","key_concepts":{"key_phrases":["VOLTAGE","A Versatile Contrastive Learning","OCR Methodology","arXiv251010490v1 Announce Type","new Abstract","UNESCO","7000 languages","Attrition","a language","loss"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"VOLTAGE":2.0,"A Versatile Contrastive Learning":2.0,"OCR Methodology":2.0,"arXiv251010490v1 Announce Type":1.0,"new Abstract":1.0,"UNESCO":1.0,"7000 languages":1.0,"Attrition":1.0,"a language":1.0,"loss":1.0}},"age_hours":2.751615853888889,"is_recent":true,"quality_score":1.0,"sentiment_score":1.8155,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6369,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.454,"joy":0.0063,"surprise":0.0168,"sadness":0.0408,"fear":0.4505,"anger":0.022,"disgust":0.0096},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new OCR methodology (VOLTAGE) for low-resource languages. While it addresses digital inclusion and preservation of endangered languages, its direct climate impact is minimal. The technology is at the applied research stage, with accuracy metrics reported but no deployment data available.","key_impact_metrics":["Accuracy of 95% for machine printed Takri","Accuracy of 87% for handwritten Takri"],"technology_tags":["Optical Character Recognition","Contrastive Learning","Generative Adversarial Networks"],"sdg_alignment":[4,10,16],"analyzed_at":"2025-10-29T11:23:25.729600Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
