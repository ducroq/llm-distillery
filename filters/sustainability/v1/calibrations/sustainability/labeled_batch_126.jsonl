{"id":"science_arxiv_cs_06c92d5fdaa1","title":"Bridging Memory Gaps: Scaling Federated Learning for Heterogeneous Clients","content":"arXiv:2408.10826v2 Announce Type: replace Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model while preserving data privacy. However, the high memory demand during model training severely limits the deployment of FL on resource-constrained clients. To this end, we propose \\our, a scalable and inclusive FL framework designed to overcome memory limitations through sequential block-wise training. The core idea of \\our is to partition the global model into blocks and train them sequentially, thereby reducing training memory requirements. To mitigate information loss during block-wise training, \\our introduces a Curriculum Mentor that crafts curriculum-aware training objectives for each block to steer their learning process. Moreover, \\our incorporates a Training Harmonizer that designs a parameter co-adaptation training scheme to coordinate block updates, effectively breaking inter-block information isolation. Extensive experiments on both simulation and hardware testbeds demonstrate that \\our significantly improves model performance by up to 84.2\\%, reduces peak memory usage by up to 50.4\\%, and accelerates training by up to 1.9$\\times$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2408.10826","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.097812","language":"en","tags":["preprints","csdc","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Yebo Wu, Jingguang Li, Chunlin Tian, Kahou Tam, Li Li, Chengzhong Xu","raw_content_length":1200,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Curriculum Mentor","Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1199,"language_detected":"en","key_concepts":{"key_phrases":["Federated Learning","Bridging Memory Gaps","Heterogeneous Clients","our","Announce Type","Abstract","multiple clients","a shared model","data privacy","the high memory demand"],"filter_categories":{"research_academic":["our"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Federated Learning":3.0,"Bridging Memory Gaps":2.0,"Heterogeneous Clients":2.0,"our":2.0,"Announce Type":1.0,"Abstract":1.0,"multiple clients":1.0,"a shared model":1.0,"data privacy":1.0,"the high memory demand":1.0}},"age_hours":2.7635901383333334,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9432,"joy":0.0114,"surprise":0.01,"sadness":0.0061,"fear":0.0088,"anger":0.0127,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a federated learning framework designed to reduce memory usage during model training, which could enable wider deployment on resource-constrained devices. This has the potential to improve the efficiency of machine learning models used in climate-related applications. The framework has been tested in simulation and hardware testbeds, showing improvements in model performance, memory usage, and training speed. However, it is still in the early stages of deployment.","key_impact_metrics":["model performance improved by 84.2%","peak memory usage reduced by 50.4%"],"technology_tags":["federated learning","machine learning","artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:21:37.965899Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_88dfb3643e55","title":"Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA","content":"arXiv:2502.01755v4 Announce Type: replace Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA) optimize federated training by reducing computational and communication costs. We propose RoLoRA, a federated framework using alternating optimization to fine-tune LoRA adapters. Our approach emphasizes the importance of learning up and down projection matrices to enhance expressiveness and robustness. We use both theoretical analysis and extensive experiments to demonstrate the advantages of RoLoRA over prior approaches that either generate imperfect model updates or limit expressiveness of the model. We provide a theoretical analysis on a linear model to highlight the importance of learning both the down-projection and up-projection matrices in LoRA. We validate the insights on a non-linear model and separately provide a convergence proof under general conditions. To bridge theory and practice, we conducted extensive experimental evaluations on language models including RoBERTa-Large, Llama-2-7B on diverse tasks and FL settings to demonstrate the advantages of RoLoRA over other methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.01755","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.122733","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Shuangyi Chen, Yuanxin Guo, Yue Ju, Harik Dalal, Zhongwen Zhu, Ashish Khisti","raw_content_length":1135,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["LoRA","Alternating Optimization of LoRA","Robust Federated Finetuning","Low-Rank Adaptation"],"persons":[],"locations":[],"monetary":[]},"char_count":1134,"language_detected":"en","key_concepts":{"key_phrases":["LoRA","Robust Federated Finetuning","LLMs","Optimization","arXiv250201755v4 Announce Type","Abstract","Parameter-Efficient Fine-Tuning PEFT methods","Low-Rank Adaptation","federated training","computational and communication costs"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LoRA":3.0,"Robust Federated Finetuning":2.0,"LLMs":2.0,"Optimization":2.0,"arXiv250201755v4 Announce Type":1.0,"Abstract":1.0,"Parameter-Efficient Fine-Tuning PEFT methods":1.0,"Low-Rank Adaptation":1.0,"federated training":1.0,"computational and communication costs":1.0}},"age_hours":2.7644996797222223,"is_recent":true,"quality_score":1.0,"sentiment_score":9.65,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.93,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.879,"joy":0.0139,"surprise":0.0095,"sadness":0.0041,"fear":0.033,"anger":0.0413,"disgust":0.0193},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a new federated learning framework (RoLoRA) for fine-tuning large language models. While it demonstrates advantages over prior approaches through theoretical analysis and experiments on language models, it is still in the applied research stage with no mention of deployed units or real-world applications. The impact is primarily theoretical at this point, focused on reducing computational and communication costs, which could indirectly contribute to sustainability if it enables more efficient AI development.","key_impact_metrics":["Reduced computational costs","Reduced communication costs"],"technology_tags":["Federated Learning","Parameter-Efficient Fine-Tuning","Low-Rank Adaptation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:21:41.947093Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2aae5df4ef1c","title":"Training and Evaluating with Human Label Variation: An Empirical Study","content":"arXiv:2502.01891v5 Announce Type: replace Abstract: Human label variation (HLV) challenges the standard assumption that a labelled instance has a single ground truth, instead embracing the natural variation in human annotation to train and evaluate models. While various training methods and metrics for HLV have been proposed, it is still unclear which methods and metrics perform best in what settings. We propose new evaluation metrics for HLV leveraging fuzzy set theory. Since these new proposed metrics are differentiable, we then in turn experiment with employing these metrics as training objectives. We conduct an extensive study over 6 HLV datasets testing 14 training methods and 6 evaluation metrics. We find that training on either disaggregated annotations or soft labels performs best across metrics, outperforming training using the proposed training objectives with differentiable metrics. We also show that our proposed soft micro F1 score is one of the best metrics for HLV data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.01891","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.123103","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Kemal Kurniawan, Meladel Mistica, Timothy Baldwin, Jey Han Lau","raw_content_length":999,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":998,"language_detected":"en","key_concepts":{"key_phrases":["HLV","Human Label Variation","metrics","arXiv250201891v5 Announce Type","Abstract","Human label variation","the standard assumption","a labelled instance","a single ground truth","the natural variation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"HLV":3.0,"Human Label Variation":2.0,"metrics":2.0,"arXiv250201891v5 Announce Type":1.0,"Abstract":1.0,"Human label variation":1.0,"the standard assumption":1.0,"a labelled instance":1.0,"a single ground truth":1.0,"the natural variation":1.0}},"age_hours":2.7645145144444445,"is_recent":true,"quality_score":0.7,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8817,"joy":0.0172,"surprise":0.0287,"sadness":0.0094,"fear":0.0406,"anger":0.0138,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving machine learning models by accounting for human label variation. While it proposes new evaluation metrics and training methods, it remains at the research stage with no deployed technology or measured climate outcomes. The impact on sustainability is indirect, potentially improving the accuracy of models used in climate-related applications.","key_impact_metrics":["Soft micro F1 score","Accuracy of HLV models"],"technology_tags":["Machine Learning","Fuzzy Set Theory","Human Label Variation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:21:45.897226Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dc87a2110916","title":"Exploring Relations among Fairness Notions in Discrete Fair Division","content":"arXiv:2502.02815v2 Announce Type: replace Abstract: Fair allocation of indivisible items among agents is a fundamental and extensively studied problem. However, fairness does not have a single universally accepted definition, leading to a variety of competing fairness notions. Some of these notions are considered stronger or more desirable, but they are also more difficult to guarantee. In this work, we examine 22 different notions of fairness and organize them into a hierarchy. Formally, we say that a fairness notion $F_1$ implies another notion $F_2$ if every $F_1$-fair allocation is also $F_2$-fair. We give a near-complete picture of implications among fairness notions: for almost every pair of notions, we either prove an implication or give a counterexample demonstrating that the implication does not hold. Although some of these results are already known, many are new. We examine multiple settings, including the allocation of goods, chores, and mixed manna. We believe this work clarifies the relative strengths and applicability of these notions, providing a foundation for future research in fair division. Moreover, we developed an inference engine to automate part of our work. It is available as a user-friendly web application and may have broader applications beyond fair division.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.02815","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.124261","language":"en","tags":["research","csgt","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Jugal Garg, Eklavya Sharma","raw_content_length":1307,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":["$F_2$","$F_1$"]},"char_count":1306,"language_detected":"en","key_concepts":{"key_phrases":["Relations","Fairness Notions","Discrete Fair Division","fairness","arXiv250202815v2 Announce Type","Abstract","Fair allocation","indivisible items","agents","a fundamental and extensively studied problem"],"filter_categories":{"ai_ml":["Fairness Notions"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Relations":2.0,"Fairness Notions":2.0,"Discrete Fair Division":2.0,"fairness":2.0,"arXiv250202815v2 Announce Type":1.0,"Abstract":1.0,"Fair allocation":1.0,"indivisible items":1.0,"agents":1.0,"a fundamental and extensively studied problem":1.0}},"age_hours":2.7645615094444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.109999999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.422,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9256,"joy":0.0108,"surprise":0.0145,"sadness":0.0088,"fear":0.007,"anger":0.0162,"disgust":0.0171},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores fairness notions in resource allocation, which is a theoretical contribution. While it doesn't directly address climate change, the developed inference engine could potentially be applied to optimize resource allocation in sustainable systems. The paper is academically rigorous, but lacks concrete deployment or measurable impact on sustainability.","key_impact_metrics":[],"technology_tags":["fair division algorithms","resource allocation","optimization"],"sdg_alignment":[12],"analyzed_at":"2025-10-29T12:21:51.188366Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_906206ea6108","title":"Rethinking the Residual Distribution of Locate","content":"arXiv:2502.03748v2 Announce Type: replace Abstract: Model editing enables targeted updates to the knowledge of large language models (LLMs) with minimal retraining. Among existing approaches, locate-then-edit methods constitute a prominent paradigm: they first identify critical layers, then compute residuals at the final critical layer based on the target edit, and finally apply least-squares-based multi-layer updates via $\\textbf{residual distribution}$. While empirically effective, we identify a counterintuitive failure mode: residual distribution, a core mechanism in these methods, introduces weight shift errors that undermine editing precision. Through theoretical and empirical analysis, we show that such errors increase with the distribution distance, batch size, and edit sequence length, ultimately leading to inaccurate or suboptimal edits. To address this, we propose the $\\textbf{B}$oundary $\\textbf{L}$ayer $\\textbf{U}$pdat$\\textbf{E (BLUE)}$ strategy to enhance locate-then-edit methods. Sequential batch editing experiments on three LLMs and two datasets demonstrate that BLUE not only delivers an average performance improvement of 35.59\\%, significantly advancing the state of the art in model editing, but also enhances the preservation of LLMs' general capabilities. Our code is available at https://github.com/xpq-tech/BLUE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.03748","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.124674","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Xiaopeng Li, Shanwen Wang, Shasha Li, Shezheng Song, Bin Ji, Jun Ma, Jie Yu","raw_content_length":1353,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":["\\textbf{U}$pdat$\\textbf","$\\textbf{B}$oundary $\\textbf{L}$ayer $"]},"char_count":1352,"language_detected":"en","key_concepts":{"key_phrases":["the Residual Distribution","Locate","arXiv250203748v2 Announce Type","Abstract","targeted updates","the knowledge","large language models","LLMs","minimal retraining","existing approaches"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Residual Distribution":2.0,"Locate":2.0,"arXiv250203748v2 Announce Type":1.0,"Abstract":1.0,"targeted updates":1.0,"the knowledge":1.0,"large language models":1.0,"LLMs":1.0,"minimal retraining":1.0,"existing approaches":1.0}},"age_hours":2.7645759958333334,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9197,"joy":0.0091,"surprise":0.0404,"sadness":0.0035,"fear":0.0079,"anger":0.0133,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (BLUE) for improving the efficiency of model editing in large language models. While the direct climate impact is limited, more efficient LLMs could indirectly reduce energy consumption associated with training and running these models. The research is supported by empirical analysis and performance improvements are quantified (35.59% average improvement).","key_impact_metrics":["Performance improvement 35.59%"],"technology_tags":["Large Language Models","Model Editing","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:21:54.280073Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5aa617deb123","title":"Beyond Scaling: Measuring and Predicting the Upper Bound of Knowledge Retention in Language Model Pre","content":"arXiv:2502.04066v5 Announce Type: replace Abstract: The GPT-4 technical report suggests that downstream performance can be predicted from pre-training signals, but offers little methodological detail on how to quantify this. This work address this gap by modeling knowledge retention, the capacity of a pre-trained language model to memorize factual information from its corpus, and introduce a principled method to estimate it prior to training. We propose Size-dependent Mutual Information (SMI), an information-theoretic predictor that integrates knowledge frequency, knowledge specificity, and model size to forecast closed-book question answering (QA) accuracy. SMI is validated through large-scale document retrieval over the disclosed pre-training corpora of 21 public and 3 custom models, combined with a robust multi-template QA evaluation. Experiments show that SMI significantly outperforms repetition-based baselines and achieves $R^2$ > 0.7 in predicting QA accuracy for models above 1B parameters, without additional training. The analysis further reveals diminishing returns from scaling data and model size and provides evidence for an intrinsic upper bound on knowledge retention achievable by pre-training alone, motivating retrieval and other augmentation strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.04066","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.125062","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Changhao Jiang, Ming Zhang, Yifei Cao, Junjie Ye, Xiaoran Fan, Shihan Dou, Zhiheng Xi, Jiajun Sun, Yi Dong, Yujiong Shen, Jingqi Tong, Baoyu Fan, Qi Zhang, Tao Gui, Xuanjing Huang","raw_content_length":1287,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["SMI","the Upper Bound of Knowledge Retention","Size","Mutual Information"],"persons":["GPT-4"],"locations":[],"monetary":[]},"char_count":1286,"language_detected":"en","key_concepts":{"key_phrases":["Scaling","the Upper Bound","Knowledge Retention","Language Model Pre","arXiv250204066v5 Announce Type","Abstract","The GPT-4 technical report","downstream performance","pre-training signals","little methodological detail"],"filter_categories":{"ai_ml":["The GPT-4 technical report"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scaling":2.0,"the Upper Bound":2.0,"Knowledge Retention":2.0,"Language Model Pre":2.0,"arXiv250204066v5 Announce Type":1.0,"Abstract":1.0,"The GPT-4 technical report":1.0,"downstream performance":1.0,"pre-training signals":1.0,"little methodological detail":1.0}},"age_hours":2.7645911763888886,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.927,"joy":0.0093,"surprise":0.0171,"sadness":0.0047,"fear":0.0098,"anger":0.019,"disgust":0.0131},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method (SMI) to predict knowledge retention in language models, validated through document retrieval and QA evaluation. It achieves R^2 > 0.7 in predicting QA accuracy for models above 1B parameters. While it identifies diminishing returns from scaling, it's still in the research phase with no deployed technology or direct climate impact, hence the low scores in those areas.","key_impact_metrics":["R^2 > 0.7 in predicting QA accuracy"],"technology_tags":["Language Models","Knowledge Retention","Information Theory"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:21:57.856918Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f2a3cdd33172","title":"Dynamic Optimizations of LLM Ensembles with Two","content":"arXiv:2502.04492v2 Announce Type: replace Abstract: The advancement of LLMs and their accessibility have triggered renewed interest in multi-agent reinforcement learning as robust and adaptive frameworks for dynamically changing environments. This paper introduces RL-Focal, a two-stage RL agent framework that routes and ensembles LLMs. First, we develop the Decider RL-agent, which learns to dynamically select an ensemble of small size ($m_i$) among $N$ LLMs ($m_i \\ll N$) for incoming queries from a user-defined downstream task $i$, by maximizing both error-diversity and reasoning-performance of the selected ensemble through iterative updates of task-adaptive rewards and policy. Second, to enable effective fusion of dynamically selected LLMs, we develop the stage-2 Fusion RL-agent, which learns to resolve reasoning conflicts from different LLMs and dynamically adapts to different ensemble teams composed by the Decider Agent for different downstream tasks. Third, we introduce the focal diversity metric to better model the error correlations among multiple LLMs, further improving the generalization performance of the Decider Agent, which actively prunes the ensemble combinations. By focal diversity, we enhance performance across tasks by effectively promoting reward-aware and policy-adaptive ensemble selection and inference fusion. Extensive evaluations on five benchmarks show that RL-Focal achieves the performance improvement of 8.48\\% with an ensemble of small size compared to the best individual LLM in a pool and offers stronger robustness. Code is available at https://github.com/sftekin/rl-focal","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.04492","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.125458","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Selim Furkan Tekin, Fatih Ilhan, Gaowen Liu, Ramana Rao Kompella, Ling Liu","raw_content_length":1624,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["RL-Focal"],"persons":["\\ll N$","Fusion RL-agent","m_i$"],"locations":[],"monetary":[]},"char_count":1623,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Dynamic Optimizations","LLM Ensembles","Announce Type","Abstract","The advancement","their accessibility","renewed interest","multi-agent reinforcement learning","robust and adaptive frameworks"],"filter_categories":{"ai_ml":["LLMs","multi-agent reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Dynamic Optimizations":2.0,"LLM Ensembles":2.0,"Announce Type":1.0,"Abstract":1.0,"The advancement":1.0,"their accessibility":1.0,"renewed interest":1.0,"multi-agent reinforcement learning":1.0,"robust and adaptive frameworks":1.0}},"age_hours":2.7646066238888887,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9169,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.877,"joy":0.0585,"surprise":0.0456,"sadness":0.003,"fear":0.0042,"anger":0.009,"disgust":0.0026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel approach to optimizing LLM ensembles using reinforcement learning. It demonstrates a performance improvement of 8.48% on benchmark tasks. However, it is still in the research phase, with no indication of real-world deployment or economic viability, limiting its immediate sustainability impact.","key_impact_metrics":["performance improvement of 8.48%"],"technology_tags":["LLM","Reinforcement Learning","Ensemble Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:06.155825Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_92f598a19538","title":"Evolving LLMs' Self","content":"arXiv:2502.05605v4 Announce Type: replace Abstract: Self-Refinement refers to a model's ability to revise its own responses to produce improved outputs. This capability can also serve as a fundamental mechanism for Self-Improvement, for example, by reconstructing datasets with refined results to enhance intrinsic model performance. However, our comprehensive experiments reveal that large language models (LLMs) show no clear evidence of inherent Self-Refinement and may even experience response quality degradation after Self-Refinement. To address this issue, we propose EVOLVE, a simple and effective framework for eliciting and tracking the evolution of Self-Refinement through iterative training. We first explore optimization methods during training to activate the model's Self-Refinement capability. Then, at inference, we investigate various generation strategies to further enhance and utilize Self-Refinement while supplying the necessary data for training. Through synergistic optimization of training and inference stages, we continually evolve the model's Self-Refinement ability, enabling it to better refine its own responses. Moreover, we demonstrate the potential of leveraging Self-Refinement to achieve broader Self-Improvement of intrinsic model abilities. Experiments show that the evolved Self-Refinement ability enables the Llama-3.1-8B base model to surpass GPT-4o, achieving 62.3% length-controlled and 63.3% raw win rates on AlpacaEval 2, and 50.3% on Arena-Hard. It also generalizes effectively to out-of-domain reasoning tasks, improving performance on mathematical reasoning benchmarks such as GSM8K and MATH.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.05605","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.126266","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Qirui Mi, Guoqing Liu, Zexu Sun, Mengyue Yang, Dong Li, Weiyu Ma, Ning Yang, Jian Zhao, Jianye Hao, Haifeng Zhang, Jun Wang","raw_content_length":1642,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["Self-Improvement","Self-Refinement","EVOLVE"],"persons":[],"locations":[],"monetary":[]},"char_count":1641,"language_detected":"en","key_concepts":{"key_phrases":["Evolving LLMs Self","arXiv250205605v4","Announce Type","Abstract","Self-Refinement","a models ability","its own responses","improved outputs","This capability","a fundamental mechanism"],"filter_categories":{"ai_ml":["Evolving LLMs Self"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Evolving LLMs Self":2.0,"arXiv250205605v4":1.0,"Announce Type":1.0,"Abstract":1.0,"Self-Refinement":1.0,"a models ability":1.0,"its own responses":1.0,"improved outputs":1.0,"This capability":1.0,"a fundamental mechanism":1.0}},"age_hours":2.7646360166666666,"is_recent":true,"quality_score":1.0,"sentiment_score":8.194,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6388,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9237,"joy":0.0115,"surprise":0.0152,"sadness":0.0137,"fear":0.0111,"anger":0.009,"disgust":0.0158},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving LLM self-refinement capabilities. While improved LLMs could potentially contribute to sustainability through more efficient resource use or better climate modeling, the paper itself doesn't present concrete actions or measurable outcomes related to sustainability. The research is in the applied research stage, with performance metrics reported on benchmarks, but no real-world deployment.","key_impact_metrics":["62.3% length-controlled win rates on AlpacaEval 2","63.3% raw win rates on AlpacaEval 2"],"technology_tags":["Large Language Models","Self-Refinement"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:10.778885Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4839e9738aea","title":"Contrastive Representation Distillation via Multi","content":"arXiv:2502.05835v3 Announce Type: replace Abstract: Knowledge distillation enhances the performance of compact student networks by transferring knowledge from more powerful teacher networks without introducing additional parameters. In the feature space, local regions within an individual global feature encode distinct yet interdependent semantic information. Previous feature-based distillation methods mainly emphasize global feature alignment while neglecting the decoupling of local regions within an individual global feature, which often results in semantic confusion and suboptimal performance. Moreover, conventional contrastive representation distillation suffers from low efficiency due to its reliance on a large memory buffer to store feature samples. To address these limitations, this work proposes MSDCRD, a model-agnostic distillation framework that systematically decouples global features into multi-scale local features and leverages the resulting semantically rich feature samples with tailored sample-wise and feature-wise contrastive losses. This design enables efficient distillation using only a single batch, eliminating the dependence on external memory. Extensive experiments demonstrate that MSDCRD achieves superior performance not only in homogeneous teacher-student settings but also in heterogeneous architectures where feature discrepancies are more pronounced, highlighting its strong generalization capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.05835","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.126678","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Cuipeng Wang, Haipeng Wang","raw_content_length":1448,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["Contrastive Representation Distillation","MSDCRD"],"persons":[],"locations":[],"monetary":[]},"char_count":1447,"language_detected":"en","key_concepts":{"key_phrases":["Contrastive Representation Distillation","Multi","arXiv250205835v3 Announce Type","Abstract","Knowledge distillation","the performance","compact student networks","knowledge","more powerful teacher networks","additional parameters"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contrastive Representation Distillation":2.0,"Multi":2.0,"arXiv250205835v3 Announce Type":1.0,"Abstract":1.0,"Knowledge distillation":1.0,"the performance":1.0,"compact student networks":1.0,"knowledge":1.0,"more powerful teacher networks":1.0,"additional parameters":1.0}},"age_hours":2.764649128611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.12,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.024,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9311,"joy":0.0166,"surprise":0.0277,"sadness":0.0065,"fear":0.0023,"anger":0.0084,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel knowledge distillation method (MSDCRD) to improve the performance of compact student networks. While the method aims to improve efficiency in machine learning models, its direct climate impact is currently theoretical and unquantified. The experiments demonstrate superior performance in homogeneous and heterogeneous architectures, but deployment readiness is still at the applied research stage.","key_impact_metrics":["Superior performance in distillation","Efficient distillation using only a single batch"],"technology_tags":["Knowledge Distillation","Contrastive Representation Learning","Machine Learning Efficiency"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:22:13.906116Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3ec60e67371","title":"FCVSR: A Frequency","content":"arXiv:2502.06431v2 Announce Type: replace Abstract: Compressed video super-resolution (SR) aims to generate high-resolution (HR) videos from the corresponding low-resolution (LR) compressed videos. Recently, some compressed video SR methods attempt to exploit the spatio-temporal information in the frequency domain, showing great promise in super-resolution performance. However, these methods do not differentiate various frequency subbands spatially or capture the temporal frequency dynamics, potentially leading to suboptimal results. In this paper, we propose a deep frequency-based compressed video SR model (FCVSR) consisting of a motion-guided adaptive alignment (MGAA) network and a multi-frequency feature refinement (MFFR) module. Additionally, a frequency-aware contrastive loss is proposed for training FCVSR, in order to reconstruct finer spatial details. The proposed model has been evaluated on three public compressed video super-resolution datasets, with results demonstrating its effectiveness when compared to existing works in terms of super-resolution performance (up to a 0.14dB gain in PSNR over the second-best model) and complexity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.06431","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.127054","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Qiang Zhu, Fan Zhang, Feiyu Chen, Shuyuan Zhu, David Bull, Bing Zeng","raw_content_length":1160,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["FCVSR","Frequency arXiv:2502.06431v2 Announce Type:","MFFR"],"persons":[],"locations":[],"monetary":[]},"char_count":1159,"language_detected":"en","key_concepts":{"key_phrases":["FCVSR","A Frequency","arXiv250206431v2 Announce Type","Abstract","Compressed video super","resolution","high-resolution HR videos","some compressed video SR methods","the spatio-temporal information","the frequency domain"],"filter_categories":{"ai_ml":["the frequency domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FCVSR":2.0,"A Frequency":2.0,"arXiv250206431v2 Announce Type":1.0,"Abstract":1.0,"Compressed video super":1.0,"resolution":1.0,"high-resolution HR videos":1.0,"some compressed video SR methods":1.0,"the spatio-temporal information":1.0,"the frequency domain":1.0}},"age_hours":2.764664701388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8932,"joy":0.008,"surprise":0.0631,"sadness":0.0109,"fear":0.0048,"anger":0.0114,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel compressed video super-resolution model (FCVSR) that improves super-resolution performance, measured by a 0.14dB gain in PSNR. While this improves video quality, its direct impact on sustainability is limited as it is still in the research phase and not deployed. The potential for reduced energy consumption through more efficient video processing is theoretical at this stage.","key_impact_metrics":["0.14dB gain in PSNR"],"technology_tags":["video compression","super-resolution","frequency domain processing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:17.010834Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38e6076b9d30","title":"The Minimal Search Space for Conditional Causal Bandits","content":"arXiv:2502.06577v2 Announce Type: replace Abstract: Causal knowledge can be used to support decision-making problems. This has been recognized in the causal bandits literature, where a causal (multi-armed) bandit is characterized by a causal graphical model and a target variable. The arms are then interventions on the causal model, and rewards are samples of the target variable. Causal bandits were originally studied with a focus on hard interventions. We focus instead on cases where the arms are conditional interventions, which more accurately model many real-world decision-making problems by allowing the value of the intervened variable to be chosen based on the observed values of other variables. This paper presents a graphical characterization of the minimal set of nodes guaranteed to contain the optimal conditional intervention, which maximizes the expected reward. We then propose an efficient algorithm with a time complexity of $O(|V| + |E|)$ to identify this minimal set of nodes. We prove that the graphical characterization and the proposed algorithm are correct. Finally, we empirically demonstrate that our algorithm significantly prunes the search space and substantially accelerates convergence rates when integrated into standard multi-armed bandit algorithms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.06577","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.127438","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Francisco N. F. Q. Simoes, Itai Feigenbaum, Mehdi Dastani, Thijs van Ommen","raw_content_length":1289,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["The Minimal Search Space for"],"persons":["Bandits arXiv:2502.06577v2 Announce Type"],"locations":[],"monetary":[]},"char_count":1288,"language_detected":"en","key_concepts":{"key_phrases":["The Minimal Search Space","Conditional Causal Bandits","arXiv250206577v2 Announce Type","Abstract","Causal knowledge","decision-making problems","the causal bandits literature","a causal multi-armed bandit","a causal graphical model","a target variable"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Minimal Search Space":2.0,"Conditional Causal Bandits":2.0,"arXiv250206577v2 Announce Type":1.0,"Abstract":1.0,"Causal knowledge":1.0,"decision-making problems":1.0,"the causal bandits literature":1.0,"a causal multi-armed bandit":1.0,"a causal graphical model":1.0,"a target variable":1.0}},"age_hours":2.7646794494444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9129,"joy":0.0243,"surprise":0.0339,"sadness":0.0041,"fear":0.0038,"anger":0.0142,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an algorithm to optimize decision-making in causal bandit problems, which could potentially be applied to various sustainability-related interventions. The algorithm's efficiency is demonstrated empirically, showing a reduction in the search space and faster convergence rates. However, it is still in the research phase with no concrete deployments or quantified environmental impact.","key_impact_metrics":["Time complexity of O(|V| + |E|)"],"technology_tags":["Causal bandits","Conditional interventions","Optimization algorithm"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:20.269112Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13f0f26a7a8f","title":"MGPATH: Vision-Language Model with Multi","content":"arXiv:2502.07409v4 Announce Type: replace Abstract: Whole slide pathology image classification presents challenges due to gigapixel image sizes and limited annotation labels, hindering model generalization. This paper introduces a prompt learning method to adapt large vision-language models for few-shot pathology classification. We first extend the Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathology image tiles, into a vision-language model by adding adaptors and aligning it with medical text encoders via contrastive learning on 923K image-text pairs. The model is then used to extract visual features and text embeddings from few-shot annotations and fine-tunes with learnable prompt embeddings. Unlike prior methods that combine prompts with frozen features using prefix embeddings or self-attention, we propose multi-granular attention that compares interactions between learnable prompts with individual image patches and groups of them. This approach improves the model's ability to capture both fine-grained details and broader context, enhancing its recognition of complex patterns across sub-regions. To further improve accuracy, we leverage (unbalanced) optimal transport-based visual-text distance to secure model robustness by mitigating perturbations that might occur during the data augmentation process. Empirical experiments on lung, kidney, and breast pathology modalities validate the effectiveness of our approach; thereby, we surpass several of the latest competitors and consistently improve performance across diverse architectures, including CLIP, PLIP, and Prov-GigaPath integrated PLIP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.07409","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.127868","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag, Hanibal Bohnenberger, Anne-Christin Hauschild","raw_content_length":1641,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Prov","Vision-Language Model"],"persons":[],"locations":[],"monetary":[]},"char_count":1640,"language_detected":"en","key_concepts":{"key_phrases":["MGPATH","Vision-Language Model","Multi","arXiv250207409v4 Announce Type","Abstract","Whole slide pathology image classification","challenges","gigapixel image sizes","limited annotation labels","model generalization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MGPATH":2.0,"Vision-Language Model":2.0,"Multi":2.0,"arXiv250207409v4 Announce Type":1.0,"Abstract":1.0,"Whole slide pathology image classification":1.0,"challenges":1.0,"gigapixel image sizes":1.0,"limited annotation labels":1.0,"model generalization":1.0}},"age_hours":2.7646943108333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9093,"joy":0.0156,"surprise":0.0338,"sadness":0.0025,"fear":0.0202,"anger":0.014,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel prompt learning method to adapt large vision-language models for few-shot pathology classification. The model is pre-trained on 1.3 billion pathology image tiles and aligned with medical text encoders using 923K image-text pairs. While promising, it is currently in the applied research stage with no deployed units or real-world data beyond the experimental validation.","key_impact_metrics":["1.3 billion pathology image tiles","923K image-text pairs"],"technology_tags":["vision-language model","prompt learning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:22:23.430323Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eea52688fb22","title":"Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech","content":"arXiv:2502.09004v2 Announce Type: replace Abstract: This paper makes three contributions. First, via a substantial corpus of 1,419,047 comments posted on 3,161 YouTube news videos of major US cable news outlets, we analyze how users engage with LGBTQ+ news content. Our analyses focus both on positive and negative content. In particular, we construct a fine-grained hope speech classifier that detects positive (hope speech), negative, neutral, and irrelevant content. Second, in consultation with a public health expert specializing on LGBTQ+ health, we conduct an annotation study with a balanced and diverse political representation and release a dataset of 3,750 instances with fine-grained labels and detailed annotator demographic information. Finally, beyond providing a vital resource for the LGBTQ+ community, our annotation study and subsequent in-the-wild assessments reveal (1) strong association between rater political beliefs and how they rate content relevant to a marginalized community; (2) models trained on individual political beliefs exhibit considerable in-the-wild disagreement; and (3) zero-shot large language models (LLMs) align more with liberal raters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.09004","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.129357","language":"en","tags":["computer-science","cslg","cscy","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Jonathan Pofcher, Christopher M. Homan, Randall Sell, Ashiqur R. KhudaBukhsh","raw_content_length":1183,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Mainstream US News Media","YouTube"],"persons":["Hate"],"locations":[],"monetary":[]},"char_count":1182,"language_detected":"en","key_concepts":{"key_phrases":["Hope","Hate","Understanding User Interactions","LGBTQ News Content","Mainstream US News Media","the Lens","arXiv250209004v2 Announce Type","Abstract","This paper","three contributions"],"filter_categories":{"ai_ml":["Mainstream US News Media"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hope":4.0,"Hate":2.0,"Understanding User Interactions":2.0,"LGBTQ News Content":2.0,"Mainstream US News Media":2.0,"the Lens":2.0,"arXiv250209004v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"three contributions":1.0}},"age_hours":2.7647546230555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8964,"joy":0.0088,"surprise":0.0085,"sadness":0.0041,"fear":0.01,"anger":0.0239,"disgust":0.0483},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":7,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes user engagement with LGBTQ+ news content, focusing on positive and negative sentiments. While it addresses social justice and equity by analyzing biases in online discourse, it has minimal direct impact on climate change or environmental sustainability. The research is in an early stage, focusing on data collection and analysis rather than deployed solutions.","key_impact_metrics":["3,750 instances with fine-grained labels","1,419,047 comments analyzed"],"technology_tags":["Natural Language Processing","Sentiment Analysis"],"sdg_alignment":[5,10,16],"analyzed_at":"2025-10-29T12:22:26.804980Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9ca2701df03","title":"Local Gibbs sampling beyond local uniformity","content":"arXiv:2502.10795v2 Announce Type: replace Abstract: Local samplers are algorithms that generate random samples based on local queries to high-dimensional distributions, ensuring the samples follow the correct induced distributions while maintaining time complexity that scales locally with the query size. These samplers have broad applications, including deterministic approximate counting [He, Wang, Yin, SODA '23; Feng et.al., FOCS '23], sampling from infinite or high-dimensional Gibbs distributions [Anand, Jerrum, SICOMP '22; He, Wang, Yin, FOCS '22], and providing local access to large random objects [Biswas, Rubinfield, Yodpinyanee, ITCS '20]. In this work, we present local samplers for Gibbs distributions of spin systems. Specifically, we design linear-time local samplers for: - permissive spin systems, including the first local sampler for the Ising model in near-critical regimes; - truly repulsive spin systems, represented by the first local sampler for uniform proper $q$-colorings, with $q=O(\\Delta)$ colors on graphs with maximum degree $\\Delta$. These local samplers are efficient beyond the \"local uniformity\" threshold, which imposes unconditional marginal lower bounds -- a key assumption required by all prior local samplers. Our results show that, in general, local sampling is not significantly harder than global sampling for spin systems. As an application, our results also imply local algorithms for probabilistic inference in the same near-critical regimes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.10795","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.130215","language":"en","tags":["preprints","research","computer-science","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Hongyang Liu, Chunyang Wang, Yitong Yin","raw_content_length":1500,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["Ising","Rubinfield","Biswas","FOCS"],"persons":["Yodpinyanee","Yin","Feng et.al","Wang","Announce Type"],"locations":["Gibbs","Jerrum","Anand"],"monetary":[]},"char_count":1491,"language_detected":"en","key_concepts":{"key_phrases":["local uniformity","arXiv250210795v2 Announce Type","Abstract","Local samplers","algorithms","random samples","local queries","high-dimensional distributions","the samples","the correct induced distributions"],"filter_categories":{"ai_ml":["algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"local uniformity":2.0,"arXiv250210795v2 Announce Type":1.0,"Abstract":1.0,"Local samplers":1.0,"algorithms":1.0,"random samples":1.0,"local queries":1.0,"high-dimensional distributions":1.0,"the samples":1.0,"the correct induced distributions":1.0}},"age_hours":2.764785649166667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9322,"joy":0.0136,"surprise":0.0308,"sadness":0.003,"fear":0.0029,"anger":0.0109,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents new local samplers for Gibbs distributions, potentially enabling more efficient algorithms for probabilistic inference. While the research is theoretically sound and peer-reviewed, it's currently in the basic research stage with no deployed applications or quantified climate impact. The vaporware flag is raised because it's an early-stage concept without deployment.","key_impact_metrics":[],"technology_tags":["local samplers","Gibbs distributions","spin systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:30.191052Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6dc3a418de9d","title":"DemonAgent: Dynamically Encrypted Multi","content":"arXiv:2502.12575v2 Announce Type: replace Abstract: As LLM-based agents become increasingly prevalent, backdoors can be implanted into agents through user queries or environment feedback, raising critical concerns regarding safety vulnerabilities. However, backdoor attacks are typically detectable by safety audits that analyze the reasoning process of agents. To this end, we propose a novel backdoor implantation strategy called \\textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}. Specifically, we introduce dynamic encryption, which maps the backdoor into benign content, effectively circumventing safety audits. To enhance stealthiness, we further decompose the backdoor into multiple sub-backdoor fragments. Based on these advancements, backdoors are allowed to bypass safety audits significantly. Additionally, we present AgentBackdoorEval, a dataset designed for the comprehensive evaluation of agent backdoor attacks. Experimental results across multiple datasets demonstrate that our method achieves an attack success rate nearing 100\\% while maintaining a detection rate of 0\\%, illustrating its effectiveness in evading safety audits. Our findings highlight the limitations of existing safety mechanisms in detecting advanced attacks, underscoring the urgent need for more robust defenses against backdoor threats. Code and data are available at https://github.com/whfeLingYu/DemonAgent.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.12575","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.131000","language":"en","tags":["computer-science","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su","raw_content_length":1415,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["Encrypted Multi-Backdoor Implantation Attack}."],"persons":[],"locations":[],"monetary":[]},"char_count":1414,"language_detected":"en","key_concepts":{"key_phrases":["DemonAgent","Dynamically Encrypted Multi","agents","arXiv250212575v2 Announce Type","Abstract","LLM-based agents","backdoors","user queries","environment feedback","critical concerns"],"filter_categories":{"ai_ml":["LLM-based agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DemonAgent":2.0,"Dynamically Encrypted Multi":2.0,"agents":2.0,"arXiv250212575v2 Announce Type":1.0,"Abstract":1.0,"LLM-based agents":1.0,"backdoors":1.0,"user queries":1.0,"environment feedback":1.0,"critical concerns":1.0}},"age_hours":2.7648151441666666,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8168,"joy":0.0066,"surprise":0.0222,"sadness":0.0099,"fear":0.1,"anger":0.0286,"disgust":0.0158},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on a novel method for backdoor implantation in LLM-based agents, demonstrating an attack success rate nearing 100% while maintaining a detection rate of 0%. While the research is technically sound and addresses a critical security vulnerability, it does not directly contribute to sustainability or climate change mitigation. The research is in the early stages, with code and data available but no deployed technology or measured environmental outcomes.","key_impact_metrics":["attack success rate nearing 100%","detection rate of 0%"],"technology_tags":["LLM","backdoor implantation","dynamic encryption","AI security"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:22:33.421394Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0148eb8a476e","title":"Cryptanalysis on Lightweight Verifiable Homomorphic Encryption","content":"arXiv:2502.12628v3 Announce Type: replace Abstract: Verifiable Homomorphic Encryption (VHE) is a cryptographic technique that integrates Homomorphic Encryption (HE) with Verifiable Computation (VC). It serves as a crucial technology for ensuring both privacy and integrity in outsourced computation, where a client sends input ciphertexts ct and a function f to a server and verifies the correctness of the evaluation upon receiving the evaluation result f(ct) from the server. At CCS, Chatel et al. introduced two lightweight VHE schemes: Replication Encoding (REP) and Polynomial Encoding (PE). A similar approach to REP was used by Albrecht et al. in Eurocrypt to develop a Verifiable Oblivious PRF scheme (vADDG). A key approach in these schemes is to embed specific secret information within HE ciphertexts to verify homomorphic evaluations. This paper presents efficient attacks that exploit the homomorphic properties of encryption schemes. The one strategy is to retrieve the secret information in encrypted state from the input ciphertexts and then leverage it to modify the resulting ciphertext without being detected by the verification algorithm. The other is to exploit the secret embedding structure to modify the evaluation function f into f' which works well on input values for verification purposes. Our forgery attack on vADDG demonstrates that the proposed 80-bit security parameters in fact offer less than 10-bits of concrete security. Our attack on REP and PE achieves a probability 1 attack with linear time complexity when using fully homomorphic encryption.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.12628","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.131400","language":"en","tags":["preprints","research","computer-science","cscr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Jung Hee Cheon, Daehyun Jang","raw_content_length":1584,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["REP","Verifiable Computation","Replication Encoding","Polynomial Encoding","Albrecht"],"persons":["Homomorphic Encryption","Chatel et al."],"locations":["CCS","Eurocrypt"],"monetary":[]},"char_count":1583,"language_detected":"en","key_concepts":{"key_phrases":["Cryptanalysis","Lightweight Verifiable Homomorphic Encryption","arXiv250212628v3","Announce Type","Abstract","Verifiable Homomorphic Encryption","VHE","a cryptographic technique","Homomorphic Encryption","Verifiable Computation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cryptanalysis":2.0,"Lightweight Verifiable Homomorphic Encryption":2.0,"arXiv250212628v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Verifiable Homomorphic Encryption":1.0,"VHE":1.0,"a cryptographic technique":1.0,"Homomorphic Encryption":1.0,"Verifiable Computation":1.0}},"age_hours":2.764830634444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8415,"joy":0.0162,"surprise":0.0118,"sadness":0.0043,"fear":0.0642,"anger":0.0385,"disgust":0.0236},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents attacks on verifiable homomorphic encryption schemes, demonstrating vulnerabilities in their security. While the research itself doesn't directly contribute to sustainability, it highlights the importance of robust security in technologies used for privacy-preserving computation, which can indirectly support sustainable applications by enabling secure data sharing and analysis. The paper quantifies the security flaws, such as reducing 80-bit security to less than 10-bits.","key_impact_metrics":["80-bit security parameters offer less than 10-bits of concrete security","Probability 1 attack with linear time complexity"],"technology_tags":["Verifiable Homomorphic Encryption","Cryptanalysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:37.091825Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03b4072bce4b","title":"Surrogate Modeling for Scalable Evaluation of Distributed Computing Systems for HEP Applications","content":"arXiv:2502.12741v2 Announce Type: replace Abstract: The Worldwide LHC Computing Grid (WLCG) provides the robust computing infrastructure essential for the LHC experiments by integrating global computing resources into a cohesive entity. Simulations of different compute models present a feasible approach for evaluating future adaptations that are able to cope with future increased demands. However, running these simulations incurs a trade-off between accuracy and scalability. For example, while the simulator DCSim can provide accurate results, it falls short on scaling with the size of the simulated platform. Using Generative Machine Learning as a surrogate presents a candidate for overcoming this challenge. In this work, we evaluate the usage of three different Machine Learning models for the simulation of distributed computing systems and assess their ability to generalize to unseen situations. We show that those models can predict central observables derived from execution traces of compute jobs with approximate accuracy but with orders of magnitude faster execution times. Furthermore, we identify potentials for improving the predictions towards better accuracy and generalizability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.12741","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.131806","language":"en","tags":["hep-ex","cspf","preprints","csdc","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Larissa Schmid, Maximilian Horzela, Valerii Zhyla, Manuel Giffels, G\\\"unter Quast, Anne Koziolek","raw_content_length":1206,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["LHC","Machine Learning","Surrogate Modeling for Scalable Evaluation of Distributed Computing Systems"],"persons":["DCSim"],"locations":[],"monetary":[]},"char_count":1203,"language_detected":"en","key_concepts":{"key_phrases":["Surrogate Modeling","Scalable Evaluation","Distributed Computing Systems","HEP Applications","Announce Type","Abstract","The Worldwide LHC Computing Grid","WLCG","the robust computing infrastructure","the LHC experiments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Surrogate Modeling":2.0,"Scalable Evaluation":2.0,"Distributed Computing Systems":2.0,"HEP Applications":2.0,"Announce Type":1.0,"Abstract":1.0,"The Worldwide LHC Computing Grid":1.0,"WLCG":1.0,"the robust computing infrastructure":1.0,"the LHC experiments":1.0}},"age_hours":2.764845233611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9338,"joy":0.0106,"surprise":0.0203,"sadness":0.0068,"fear":0.0068,"anger":0.0103,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes research into using machine learning to simulate distributed computing systems, specifically for high-energy physics applications. The concrete action is the evaluation of three ML models and their ability to predict observables. The evidence is the reported approximate accuracy and faster execution times, though it's still in the research phase with no deployed system.","key_impact_metrics":["orders of magnitude faster execution times","approximate accuracy"],"technology_tags":["machine learning","surrogate modeling","distributed computing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:40.295716Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b58d1b335e5b","title":"LIDDIA: Language","content":"arXiv:2502.13959v3 Announce Type: replace Abstract: Drug discovery is a long, expensive, and complex process, relying heavily on human medicinal chemists, who can spend years searching the vast space of potential therapies. Recent advances in artificial intelligence for chemistry have sought to expedite individual drug discovery tasks; however, there remains a critical need for an intelligent agent that can navigate the drug discovery process. Towards this end, we introduce LIDDIA, an autonomous agent capable of intelligently navigating the drug discovery process in silico. By leveraging the reasoning capabilities of large language models, LIDDIA serves as a low-cost and highly-adaptable tool for autonomous drug discovery. We comprehensively examine LIDDIA , demonstrating that (1) it can generate molecules meeting key pharmaceutical criteria on over 70% of 30 clinically relevant targets, (2) it intelligently balances exploration and exploitation in the chemical space, and (3) it identifies one promising novel candidate on AR/NR3C4, a critical target for both prostate and breast cancers. Code and dataset are available at https://github.com/ninglab/LIDDiA","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.13959","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.132183","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Reza Averly, Frazier N. Baker, Ian A. Watson, Xia Ning","raw_content_length":1172,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Language arXiv:2502.13959v3 Announce Type: replace Abstract"],"persons":["LIDDIA"],"locations":[],"monetary":[]},"char_count":1171,"language_detected":"en","key_concepts":{"key_phrases":["LIDDIA","Language","arXiv250213959v3 Announce Type","Abstract","Drug discovery","a long expensive and complex process","human medicinal chemists","who","years","the vast space"],"filter_categories":{"ai_ml":["Language"],"research_academic":["Drug discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LIDDIA":3.0,"Language":2.0,"arXiv250213959v3 Announce Type":1.0,"Abstract":1.0,"Drug discovery":1.0,"a long expensive and complex process":1.0,"human medicinal chemists":1.0,"who":1.0,"years":1.0,"the vast space":1.0}},"age_hours":2.7648601238888886,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9591,"joy":0.0049,"surprise":0.0191,"sadness":0.0032,"fear":0.0052,"anger":0.0052,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an AI agent (LIDDIA) for drug discovery. While it doesn't directly address climate change, it could indirectly reduce the environmental impact of drug development by accelerating the process and potentially reducing the need for extensive lab work and resource consumption. The claim that LIDDIA can generate molecules meeting key pharmaceutical criteria on over 70% of 30 clinically relevant targets provides some measurable outcome, but it's still in the early stages of development.","key_impact_metrics":["70% of 30 clinically relevant targets met pharmaceutical criteria"],"technology_tags":["AI","Drug Discovery","Large Language Models"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:22:44.341430Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_495de4cd8a98","title":"Precise Mobile Manipulation of Small Everyday Objects","content":"arXiv:2502.13964v2 Announce Type: replace Abstract: Many everyday mobile manipulation tasks require precise interaction with small objects, such as grasping a knob to open a cabinet or pressing a light switch. In this paper, we develop Servoing with Vision Models (SVM), a closed-loop framework that enables a mobile manipulator to tackle such precise tasks involving the manipulation of small objects. SVM uses state-of-the-art vision foundation models to generate 3D targets for visual servoing to enable diverse tasks in novel environments. Naively doing so fails because of occlusion by the end-effector. SVM mitigates this using vision models that out-paint the end-effector, thereby significantly enhancing target localization. We demonstrate that aided by out-painting methods, open-vocabulary object detectors can serve as a drop-in module for SVM to seek semantic targets (e.g. knobs) and point tracking methods can help SVM reliably pursue interaction sites indicated by user clicks. We conduct a large-scale evaluation spanning experiments in 10 novel environments across 6 buildings including 72 different object instances. SVM obtains a 71% zero-shot success rate on manipulating unseen objects in novel environments in the real world, outperforming an open-loop control method by an absolute 42% and an imitation learning baseline trained on 1000+ demonstrations also by an absolute success rate of 50%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.13964","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.132598","language":"en","tags":["cslg","csai","preprints","cscv","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Arjun Gupta, Rishik Sathua, Saurabh Gupta","raw_content_length":1418,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["SVM","Vision Models","Servoing with"],"persons":[],"locations":[],"monetary":[]},"char_count":1417,"language_detected":"en","key_concepts":{"key_phrases":["Precise Mobile Manipulation","Small Everyday Objects","small objects","SVM","arXiv250213964v2 Announce Type","Abstract","Many everyday mobile manipulation tasks","precise interaction","a knob","a cabinet"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Precise Mobile Manipulation":2.0,"Small Everyday Objects":2.0,"small objects":2.0,"SVM":2.0,"arXiv250213964v2 Announce Type":1.0,"Abstract":1.0,"Many everyday mobile manipulation tasks":1.0,"precise interaction":1.0,"a knob":1.0,"a cabinet":1.0}},"age_hours":2.7648760005555557,"is_recent":true,"quality_score":1.0,"sentiment_score":3.091,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3818,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8678,"joy":0.0175,"surprise":0.0204,"sadness":0.004,"fear":0.046,"anger":0.0309,"disgust":0.0134},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for mobile manipulation, achieving a 71% zero-shot success rate on manipulating unseen objects in novel environments. The technology is still in the applied research phase, with experiments conducted in controlled environments. While the technology itself doesn't directly address climate change, it could potentially contribute to more efficient automation in various sectors, indirectly reducing energy consumption.","key_impact_metrics":["71% zero-shot success rate","42% outperforming open-loop control"],"technology_tags":["mobile manipulation","visual servoing","vision foundation models","robotics"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:22:47.791591Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9d8fe3cfa8c0","title":"QMCPy: A Python Software for Randomized Low","content":"arXiv:2502.14256v2 Announce Type: replace Abstract: Low-discrepancy (LD) sequences have been extensively used as efficient experimental designs across many scientific disciplines. QMCPy (https://qmcsoftware.github.io/QMCSoftware/) is an accessible Python library which provides a unified implementation of randomized LD sequences, automatic variable transformations, adaptive Quasi-Monte Carlo error estimation algorithms, and fast kernel methods. This article focuses on recent updates to QMCPy which broaden support for randomized LD sequences and add new tools to enable fast kernel methods using LD sequences. Specifically, we give a unified description of the supported LD lattices, digital nets, and Halton point sets, along with randomization options including random permutations / shifts, linear matrix scrambling (LMS), and nested uniform scrambling (NUS). We also support higher-order digital nets, higher-order scrambling with LMS or NUS, and Halton scrambling with LMS or NUS. For fast kernel methods, we provide shift-invariant (SI) and digitally-shift-invariant (DSI) kernels, including a new set of higher-order smoothness DSI kernels. When SI and DSI kernels are respectively paired with n LD lattice and digital net points, the resulting Gram matrices permit multiplication and inversion at only O(n log n) cost. These fast operations utilize QMCPy's implementation of the fast Fourier transform in bit-reversed order (FFTBR), inverse FFTBR (IFFTBR), and fast Walsh--Hadamard transform (FWHT).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.14256","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.132998","language":"en","tags":["preprints","research","computer-science","csms","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Aleksei G Sorokin","raw_content_length":1512,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["Quasi-Monte Carlo","LMS","linear","QMCPy"],"persons":[],"locations":["Halton"],"monetary":[]},"char_count":1511,"language_detected":"en","key_concepts":{"key_phrases":["QMCPy","A Python Software","Randomized Low","Announce Type","Abstract","Low-discrepancy LD sequences","efficient experimental designs","many scientific disciplines","httpsqmcsoftwaregithubioQMCSoftware","an accessible Python library"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"QMCPy":3.0,"A Python Software":2.0,"Randomized Low":2.0,"Announce Type":1.0,"Abstract":1.0,"Low-discrepancy LD sequences":1.0,"efficient experimental designs":1.0,"many scientific disciplines":1.0,"httpsqmcsoftwaregithubioQMCSoftware":1.0,"an accessible Python library":1.0}},"age_hours":2.764890635833333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8011,"joy":0.1026,"surprise":0.079,"sadness":0.0048,"fear":0.0028,"anger":0.0076,"disgust":0.0022},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a Python library (QMCPy) for low-discrepancy sequences, which can improve the efficiency of simulations and optimization problems. While the library itself doesn't directly reduce emissions, it can potentially accelerate research in various fields, including climate modeling and materials discovery for sustainable technologies. The technical credibility is high due to the peer-reviewed nature of the article and the detailed description of the algorithms.","key_impact_metrics":[],"technology_tags":["Quasi-Monte Carlo methods","Low-discrepancy sequences","Python library"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:22:51.185211Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b8b7b16ac466","title":"Steering LLMs for Formal Theorem Proving","content":"arXiv:2502.15507v5 Announce Type: replace Abstract: Recent advances in automated theorem proving use Large Language Models (LLMs) to translate informal mathematical statements into formal proofs. However, informal cues are often ambiguous or lack strict logical structure, making it hard for models to interpret them precisely. While existing methods achieve strong performance, little is known about how LLMs internally represent informal cues, or how these influence proof generation. To address this, we explore \\textit{activation steering}, an inference-time intervention that identifies linear directions in residual activations associated with informal reasoning traces and adjusts them to improve proof construction without fine-tuning. This mechanism also yields interpretable information about how reasoning is internally encoded in the activation space of LLMs. We test our method for generating formal proofs from already-formalized theorems. Our contributions are twofold: (1) a novel activation-based intervention for guiding proof synthesis in LLMs; and (2) demonstration that this intervention improves performance under two decoding strategies (sampling and best-first search) without any further training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.15507","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.133377","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Shashank Kirtania, Arun Iyer","raw_content_length":1223,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1222,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Formal Theorem Proving","informal cues","arXiv250215507v5 Announce Type","Abstract","Recent advances","automated theorem proving","Large Language Models","informal mathematical statements","formal proofs"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Formal Theorem Proving":2.0,"informal cues":2.0,"arXiv250215507v5 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"automated theorem proving":1.0,"Large Language Models":1.0,"informal mathematical statements":1.0,"formal proofs":1.0}},"age_hours":2.7649049416666664,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.932,"joy":0.0071,"surprise":0.0164,"sadness":0.0051,"fear":0.0152,"anger":0.0144,"disgust":0.0099},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel method for improving LLMs in formal theorem proving using activation steering. While the research is interesting, it's currently in the applied research stage with no deployed units or measurable environmental outcomes. The potential climate impact is indirect and theoretical, as it could potentially improve efficiency in scientific research, but there are no concrete actions or quantified metrics to support a higher score.","key_impact_metrics":[],"technology_tags":["Large Language Models","Automated Theorem Proving","Activation Steering"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:22:54.955072Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3af433583a8b","title":"Unveiling Downstream Performance Scaling of LLMs: A Clustering","content":"arXiv:2502.17262v3 Announce Type: replace Abstract: The escalating scale and cost of Large Language Models (LLMs) training necessitate accurate pre-training prediction of downstream task performance for efficient resource allocation. This is challenged by: 1) the emergence phenomenon, where metrics become meaningful only after extensive training, hindering prediction by smaller models; and 2) uneven task difficulty and inconsistent performance scaling patterns, leading to high metric variability. Current prediction methods lack accuracy and reliability. We propose a Clustering-On-Difficulty (COD) framework for downstream performance prediction. The COD framework clusters tasks by their difficulty scaling features, thereby establishing a more stable and predictable support subset through the exclusion of tasks exhibiting non-emergent behavior or irregular scaling. We adopt a performance scaling law to predict cluster-wise performance with theoretical support. Predictable subset performance acts as an intermediate predictor for the full evaluation set. We further derive a mapping function to accurately extrapolate the performance of the subset to the full set. Applied to an LLM with 70B parameters, COD achieved a 1.36% average prediction error across eight key LLM benchmarks, offering actionable insights for resource allocation and training monitoring of LLMs pretraining.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.17262","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.134231","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li","raw_content_length":1393,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","COD"],"persons":[],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Downstream Performance","A Clustering","arXiv250217262v3 Announce Type","Abstract","The escalating scale","cost","Large Language Models","necessitate accurate pre-training prediction","downstream task performance"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Downstream Performance":2.0,"A Clustering":2.0,"arXiv250217262v3 Announce Type":1.0,"Abstract":1.0,"The escalating scale":1.0,"cost":1.0,"Large Language Models":1.0,"necessitate accurate pre-training prediction":1.0,"downstream task performance":1.0}},"age_hours":2.764919436388889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3218,"joy":0.0044,"surprise":0.0124,"sadness":0.015,"fear":0.4395,"anger":0.1021,"disgust":0.1049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (COD) for predicting the performance of LLMs, which could lead to more efficient resource allocation during training, potentially reducing energy consumption. The framework is tested on a 70B parameter LLM and achieves a 1.36% average prediction error across eight benchmarks. However, it is still in the applied research stage with no evidence of real-world deployment or independent verification.","key_impact_metrics":["1.36% average prediction error"],"technology_tags":["Large Language Models","Clustering","Performance Prediction"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:22:58.448124Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46267612a100","title":"Towards Thinking","content":"arXiv:2502.18080v2 Announce Type: replace Abstract: Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits of increasing test-time compute by extending the CoT lengths of Large Language Models (LLMs), we are concerned about a potential issue hidden behind the current pursuit of test-time scaling: Would excessively scaling the CoT length actually bring adverse effects to a model's reasoning performance? Our explorations on mathematical reasoning tasks reveal an unexpected finding that scaling with longer CoTs can indeed impair the reasoning performance of LLMs in certain domains. Moreover, we discover that there exists an optimal scaled length distribution that differs across different domains. Based on these insights, we propose a Thinking-Optimal Scaling strategy. Our method first uses a small set of seed data with varying response length distributions to teach the model to adopt different reasoning efforts for deep thinking. Then, the model selects its shortest correct response under different reasoning efforts on additional problems for self-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct outperform other distillation-based 32B o1-like models across various math benchmarks, and achieve performance on par with the teacher model QwQ-32B-Preview that produces the seed data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.18080","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.134660","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Wenkai Yang, Shuming Ma, Yankai Lin, Furu Wei","raw_content_length":1503,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","a Thinking-Optimal Scaling","Chain of Thoughts (","CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1502,"language_detected":"en","key_concepts":{"key_phrases":["Thinking","arXiv250218080v2 Announce Type","Abstract","Recent studies","a model","more time","longer Chain","Thoughts","CoTs","significant improvements"],"filter_categories":{"ai_ml":["longer Chain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Thinking":2.0,"arXiv250218080v2 Announce Type":1.0,"Abstract":1.0,"Recent studies":1.0,"a model":1.0,"more time":1.0,"longer Chain":1.0,"Thoughts":1.0,"CoTs":1.0,"significant improvements":1.0}},"age_hours":2.764934685,"is_recent":true,"quality_score":1.0,"sentiment_score":9.221,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8442,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5043,"joy":0.0124,"surprise":0.0172,"sadness":0.0169,"fear":0.3815,"anger":0.0545,"disgust":0.0132},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores improving the reasoning performance of LLMs, which could indirectly contribute to sustainability by optimizing resource use in computation. The concrete action is the development of a 'Thinking-Optimal Scaling' strategy, demonstrated on math benchmarks. While the research shows performance improvements, it's still in the early stages of development and lacks real-world deployment data.","key_impact_metrics":["Performance on math benchmarks","Response length distributions"],"technology_tags":["Large Language Models","Chain of Thought","Mathematical Reasoning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:23:01.550037Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9cd57403716e","title":"MathTutorBench: A Benchmark for Measuring Open","content":"arXiv:2502.18940v2 Announce Type: replace Abstract: Evaluating the pedagogical capabilities of AI-based tutoring models is critical for making guided progress in the field. Yet, we lack a reliable, easy-to-use, and simple-to-run evaluation that reflects the pedagogical abilities of models. To fill this gap, we present MathTutorBench, an open-source benchmark for holistic tutoring model evaluation. MathTutorBench contains a collection of datasets and metrics that broadly cover tutor abilities as defined by learning sciences research in dialog-based teaching. To score the pedagogical quality of open-ended teacher responses, we train a reward model and show it can discriminate expert from novice teacher responses with high accuracy. We evaluate a wide set of closed- and open-weight models on MathTutorBench and find that subject expertise, indicated by solving ability, does not immediately translate to good teaching. Rather, pedagogy and subject expertise appear to form a trade-off that is navigated by the degree of tutoring specialization of the model. Furthermore, tutoring appears to become more challenging in longer dialogs, where simpler questioning strategies begin to fail. We release the benchmark, code, and leaderboard openly to enable rapid benchmarking of future models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.18940","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.135059","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Jakub Macina, Nico Daheim, Ido Hakimi, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan","raw_content_length":1296,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["MathTutorBench"],"monetary":[]},"char_count":1295,"language_detected":"en","key_concepts":{"key_phrases":["MathTutorBench","A Benchmark","Measuring Open","arXiv250218940v2 Announce Type","Abstract","the pedagogical capabilities","AI-based tutoring models","guided progress","the field","use"],"filter_categories":{"ai_ml":["AI-based tutoring models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MathTutorBench":4.0,"A Benchmark":2.0,"Measuring Open":2.0,"arXiv250218940v2 Announce Type":1.0,"Abstract":1.0,"the pedagogical capabilities":1.0,"AI-based tutoring models":1.0,"guided progress":1.0,"the field":1.0,"use":1.0}},"age_hours":2.7649502416666665,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9128,"joy":0.0061,"surprise":0.0306,"sadness":0.0162,"fear":0.0153,"anger":0.0102,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":2,"justice_equity":1,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a benchmark for evaluating AI tutoring models. While the benchmark itself is open-source and includes datasets and metrics, it is in an early stage of development and does not have direct, measurable climate impact. The 'high accuracy' in discriminating expert vs novice teacher responses is a metric, but not related to sustainability.","key_impact_metrics":["Reward model accuracy"],"technology_tags":["AI","Education Technology","Machine Learning"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:23:04.983361Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6ec111158252","title":"Exploring the Generalizability of Factual Hallucination Mitigation via Enhancing Precise Knowledge Utilization","content":"arXiv:2502.19127v3 Announce Type: replace Abstract: Large Language Models (LLMs) often struggle to align their responses with objective facts, resulting in the issue of factual hallucinations, which can be difficult to detect and mislead users without relevant knowledge. Although post-training techniques have been employed to mitigate the issue, existing methods usually suffer from poor generalization and trade-offs in other different capabilities. In this paper, we propose to address these by directly augmenting LLM's fundamental ability to precisely leverage its knowledge and introduce PKUE (Precise Knowledge Utilization Enhancement), which fine-tunes the model on self-generated responses to precise and simple factual questions through preference optimization. Furthermore, we construct FactualBench, a comprehensive and precise factual QA dataset containing 181k Chinese data spanning 21 domains, to facilitate both evaluation and training. Extensive experiments demonstrate that PKUE significantly improves LLM overall performance, with consistent enhancement across factual tasks of various forms, general tasks beyond factuality, and tasks in different language.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.19127","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.135440","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Siyuan Zhang, Yichi Zhang, Yinpeng Dong, Hang Su","raw_content_length":1179,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["LLM","Enhancing Precise Knowledge Utilization arXiv:2502.19127v3","FactualBench"],"persons":[],"locations":[],"monetary":[]},"char_count":1178,"language_detected":"en","key_concepts":{"key_phrases":["the Generalizability","Factual Hallucination Mitigation","Precise Knowledge Utilization","the issue","arXiv250219127v3","Announce Type","Large Language Models","LLMs","their responses","objective facts"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Generalizability":2.0,"Factual Hallucination Mitigation":2.0,"Precise Knowledge Utilization":2.0,"the issue":2.0,"arXiv250219127v3":1.0,"Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"their responses":1.0,"objective facts":1.0}},"age_hours":2.764964806111111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.57,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.886,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7722,"joy":0.0024,"surprise":0.0127,"sadness":0.0647,"fear":0.0482,"anger":0.0378,"disgust":0.062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a method (PKUE) to mitigate factual hallucinations in LLMs, which could indirectly support sustainability by improving the accuracy of information related to climate change and other environmental issues. However, the direct impact on GHG emissions or other sustainability metrics is theoretical and unproven. The technology is in the applied research phase, with a new dataset (FactualBench) created for evaluation and training.","key_impact_metrics":["181k Chinese data points in FactualBench","Significant improvement in LLM overall performance"],"technology_tags":["Large Language Models","Factual Hallucination Mitigation","Preference Optimization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:23:08.851714Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7f93ca9bd53f","title":"Disentangling Feature Structure: A Mathematically Provable Two","content":"arXiv:2502.20681v2 Announce Type: replace Abstract: Transformers may exhibit two-stage training dynamics during the real-world training process. For instance, when training GPT-2 on the Counterfact dataset, the answers progress from syntactically incorrect to syntactically correct to semantically correct. However, existing theoretical analyses hardly account for this feature-level two-stage phenomenon, which originates from the disentangled two-type features like syntax and semantics. In this paper, we theoretically demonstrate how the two-stage training dynamics potentially occur in transformers. Specifically, we analyze the feature learning dynamics induced by the aforementioned disentangled two-type feature structure, grounding our analysis in a simplified yet illustrative setting that comprises a normalized ReLU self-attention layer and structured data. Such disentanglement of feature structure is general in practice, e.g., natural languages contain syntax and semantics, and proteins contain primary and secondary structures. To our best knowledge, this is the first rigorous result regarding a feature-level two-stage optimization process in transformers. Additionally, a corollary indicates that such a two-stage process is closely related to the spectral properties of the attention weights, which accords well with our empirical findings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2502.20681","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.135852","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Zixuan Gong, Shijia Li, Yong Liu, Jiaye Teng","raw_content_length":1362,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["ReLU"],"persons":["Counterfact"],"locations":[],"monetary":[]},"char_count":1361,"language_detected":"en","key_concepts":{"key_phrases":["Feature Structure","arXiv250220681v2 Announce Type","Abstract","Transformers","two-stage training dynamics","the real-world training process","instance","GPT-2","the Counterfact dataset","existing theoretical analyses"],"filter_categories":{"ai_ml":["Transformers","GPT-2"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Feature Structure":2.0,"arXiv250220681v2 Announce Type":1.0,"Abstract":1.0,"Transformers":1.0,"two-stage training dynamics":1.0,"the real-world training process":1.0,"instance":1.0,"GPT-2":1.0,"the Counterfact dataset":1.0,"existing theoretical analyses":1.0}},"age_hours":2.7649793666666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9103,"joy":0.0044,"surprise":0.0493,"sadness":0.0057,"fear":0.0063,"anger":0.0108,"disgust":0.0132},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical research on feature learning dynamics in transformers, specifically focusing on disentangled features like syntax and semantics. While the research is rigorous and potentially impactful for improving AI models used in various sustainability applications (e.g., climate modeling, materials discovery), it is currently at a very early stage of development with no concrete deployments or measurable outcomes related to sustainability. The impact is indirect and speculative at this point.","key_impact_metrics":[],"technology_tags":["Transformer models","Machine learning","Artificial intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:23:14.271169Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f79846c40438","title":"Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism Perspective on Focus Areas","content":"arXiv:2503.01773v3 Announce Type: replace Abstract: Large Vision Language Models (VLMs) have long struggled with spatial reasoning tasks. Surprisingly, even simple spatial reasoning tasks, such as recognizing \"under\" or \"behind\" relationships between only two objects, pose significant challenges for current VLMs. In this work, we study the spatial reasoning challenge from the lens of mechanistic interpretability, diving into the model's internal states to examine the interactions between image and text tokens. By tracing attention distribution over the image through out intermediate layers, we observe that successful spatial reasoning correlates strongly with the model's ability to align its attention distribution with actual object locations, particularly differing between familiar and unfamiliar spatial relationships. Motivated by these findings, we propose ADAPTVIS based on inference-time confidence scores to sharpen the attention on highly relevant regions when confident, while smoothing and broadening the attention window to consider a wider context when confidence is lower. This training-free decoding method shows significant improvement (e.g., up to a 50 absolute point improvement) on spatial reasoning benchmarks such as WhatsUp and VSR with negligible cost. We make code and data publicly available for research purposes at https://github.com/shiqichen17/AdaptVis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.01773","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.137022","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Shiqi Chen, Tongyao Zhu, Ruochen Zhou, Jinghan Zhang, Siyang Gao, Juan Carlos Niebles, Mor Geva, Junxian He, Jiajun Wu, Manling Li","raw_content_length":1393,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["ADAPTVIS","Focus Areas arXiv:2503.01773v3 Announce Type","An Attention Mechanism Perspective"],"persons":[],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["VLMs","Spatial Reasoning Hard","An Attention Mechanism Perspective","Focus Areas","arXiv250301773v3 Announce Type","Large Vision Language Models","spatial reasoning tasks","even simple spatial reasoning tasks","behind relationships","only two objects"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"VLMs":3.0,"Spatial Reasoning Hard":2.0,"An Attention Mechanism Perspective":2.0,"Focus Areas":2.0,"arXiv250301773v3 Announce Type":1.0,"Large Vision Language Models":1.0,"spatial reasoning tasks":1.0,"even simple spatial reasoning tasks":1.0,"behind relationships":1.0,"only two objects":1.0}},"age_hours":2.7650241394444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.1355,"joy":0.0046,"surprise":0.8162,"sadness":0.0059,"fear":0.0153,"anger":0.0158,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving spatial reasoning in VLMs, which could indirectly support sustainability applications by enhancing image analysis for tasks like monitoring deforestation or identifying pollution sources. The article presents a novel method (ADAPTVIS) and shows a 50-point improvement on spatial reasoning benchmarks, but it's currently in the applied research stage with no clear path to economic viability or large-scale deployment for sustainability purposes.","key_impact_metrics":["50 absolute point improvement on spatial reasoning benchmarks"],"technology_tags":["Vision Language Models","Attention Mechanisms","Spatial Reasoning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:23:19.628317Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38957d627e43","title":"Add-One","content":"arXiv:2503.02359v2 Announce Type: replace Abstract: Selecting high-quality and diverse training samples from extensive datasets plays a crucial role in reducing training overhead and enhancing the performance of Large Language Models (LLMs). However, existing studies fall short in assessing the overall value of selected data, focusing primarily on individual quality, and struggle to strike an effective balance between ensuring diversity and minimizing data point traversals. Therefore, this paper introduces a novel choice-based sample selection framework that shifts the focus from evaluating individual sample quality to comparing the contribution value of different samples when incorporated into the subset. Thanks to the advanced language understanding capabilities of LLMs, we utilize LLMs to evaluate the value of each option during the selection process. Furthermore, we design a greedy sampling process where samples are incrementally added to the subset, thereby improving efficiency by eliminating the need for exhaustive traversal of the entire dataset with the limited budget. Extensive experiments demonstrate that selected data from our method not only surpasses the performance of the full dataset but also achieves competitive results with recent powerful studies, while requiring fewer selections. Moreover, we validate our approach on a larger medical dataset, highlighting its practical applicability in real-world applications. Our code and data are available at https://github.com/BIRlz/comperative_sample_selection.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.02359","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.137417","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Zhuo Li, Yuhao Du, Xiaoqi Jiao, Yiwen Guo, Yuege Feng, Xiang Wan, Anningzhe Gao, Jinpeng Hu","raw_content_length":1543,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1542,"language_detected":"en","key_concepts":{"key_phrases":["Announce Type","Abstract","high-quality and diverse training samples","extensive datasets","a crucial role","the performance","Large Language Models","LLMs","existing studies","the overall value"],"filter_categories":{"ai_ml":["high-quality and diverse training samples","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Announce Type":1.0,"Abstract":1.0,"high-quality and diverse training samples":1.0,"extensive datasets":1.0,"a crucial role":1.0,"the performance":1.0,"Large Language Models":1.0,"LLMs":1.0,"existing studies":1.0,"the overall value":1.0}},"age_hours":2.7650385713888888,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8984,"joy":0.0186,"surprise":0.0178,"sadness":0.0374,"fear":0.007,"anger":0.0134,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for selecting training samples for LLMs, aiming to reduce training overhead and improve performance. The concrete action is the development and testing of a new sampling framework. The evidence supporting the claims comes from extensive experiments demonstrating improved performance with fewer selections. It is currently in the applied research stage, with code and data available but no real-world deployment data.","key_impact_metrics":["Fewer selections required","Performance surpasses full dataset"],"technology_tags":["Large Language Models","Sample Selection","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:23:23.285490Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c31980df340","title":"PolyVer: A Compositional Approach for Polyglot System Modeling and Verification","content":"arXiv:2503.03207v3 Announce Type: replace Abstract: Several software systems are polyglot; that is, they comprise programs implemented in a combination of programming languages. Verifiers that directly run on mainstream programming languages are currently customized for single languages. Thus, to verify polyglot systems, one usually translates them into a common verification language or formalism on which the verifier runs. In this paper, we present an alternative approach, PolyVer, which employs abstraction, compositional reasoning, and synthesis to directly perform polyglot verification. PolyVer constructs a formal model of the original polyglot system as a transition system where the update functions associated with transitions are implemented in target languages such as C or Rust. To perform verification, PolyVer then connects a model checker for transition systems with language-specific verifiers (e.g., for C or Rust) using pre/post-condition contracts for the update functions. These contracts are automatically generated by synthesis oracles based on syntax-guided synthesis or large language models (LLMs), and checked by the language-specific verifiers. The contracts form abstractions of the update functions using which the model checker verifies the overall system-level property on the polyglot system model. PolyVer iterates between counterexample-guided abstraction-refinement (CEGAR) and counterexample-guided inductive synthesis (CEGIS) until the property is verified or a true system-level counterexample is found. We demonstrate the utility of PolyVer for verifying programs in the Lingua Franca polyglot language using the UCLID5 model checker connected with the CBMC and Kani verifiers for C and Rust respectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.03207","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.138205","language":"en","tags":["research","cspl","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Pei-Wei Chen, Shaokai Lin, Adwait Godbole, Ramneet Singh, Elizabeth Polgreen, Edward A. Lee, Sanjit A. Seshia","raw_content_length":1750,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["PolyVer"],"persons":[],"locations":[],"monetary":[]},"char_count":1749,"language_detected":"en","key_concepts":{"key_phrases":["PolyVer","A Compositional Approach","Polyglot System Modeling","Verification","which","arXiv250303207v3 Announce Type","Abstract","Several software systems","programs","a combination"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PolyVer":3.0,"A Compositional Approach":2.0,"Polyglot System Modeling":2.0,"Verification":2.0,"which":2.0,"arXiv250303207v3 Announce Type":1.0,"Abstract":1.0,"Several software systems":1.0,"programs":1.0,"a combination":1.0}},"age_hours":2.7650692905555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9413,"joy":0.0065,"surprise":0.0098,"sadness":0.0034,"fear":0.0128,"anger":0.0149,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach (PolyVer) for verifying polyglot systems, which could potentially lead to more efficient and reliable software development. While the approach is demonstrated using specific verifiers and languages (UCLID5, CBMC, Kani, C, Rust, Lingua Franca), it is currently in the applied research stage with no deployed units or measurable outcomes in terms of reduced energy consumption or emissions. The vaporware flag is raised because it's a prototype with no indication of deployment.","key_impact_metrics":[],"technology_tags":["software verification","polyglot systems","formal methods"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:23:27.113095Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_de6bf181a908","title":"Adaptive UAV","content":"arXiv:2503.06145v3 Announce Type: replace Abstract: Hierarchical Federated Learning (HFL) extends conventional Federated Learning (FL) by introducing intermediate aggregation layers, enabling distributed learning in geographically dispersed environments, particularly relevant for smart IoT systems, such as remote monitoring and battlefield operations, where cellular connectivity is limited. In these scenarios, UAVs serve as mobile aggregators, dynamically connecting terrestrial IoT devices. This paper investigates an HFL architecture with energy-constrained, dynamically deployed UAVs prone to communication disruptions. We propose a novel approach to minimize global training costs by formulating a joint optimization problem that integrates learning configuration, bandwidth allocation, and device-to-UAV association, ensuring timely global aggregation before UAV disconnections and redeployments. The problem accounts for dynamic IoT devices and intermittent UAV connectivity and is NP-hard. To tackle this, we decompose it into three subproblems: \\textit{(i)} optimizing learning configuration and bandwidth allocation via an augmented Lagrangian to reduce training costs; \\textit{(ii)} introducing a device fitness score based on data heterogeneity (via Kullback-Leibler divergence), device-to-UAV proximity, and computational resources, using a TD3-based algorithm for adaptive device-to-UAV assignment; \\textit{(iii)} developing a low-complexity two-stage greedy strategy for UAV redeployment and global aggregator selection, ensuring efficient aggregation despite UAV disconnections. Experiments on diverse real-world datasets validate the approach, demonstrating cost reduction and robust performance under communication disruptions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.06145","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.138981","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Xiaohong Yang, Minghui Liwang, Liqun Fu, Yuhan Su, Seyyedali Hosseinalipour, Xianbin Wang, Yiguang Hong","raw_content_length":1749,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["UAVs","HFL","UAV","IoT","Federated Learning","Hierarchical Federated Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1748,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive UAV","arXiv250306145v3","Announce Type","Abstract","Hierarchical Federated Learning","HFL","conventional Federated Learning","intermediate aggregation layers","distributed learning","geographically dispersed environments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive UAV":2.0,"arXiv250306145v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Hierarchical Federated Learning":1.0,"HFL":1.0,"conventional Federated Learning":1.0,"intermediate aggregation layers":1.0,"distributed learning":1.0,"geographically dispersed environments":1.0}},"age_hours":2.76509576,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7675,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3535,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9193,"joy":0.0116,"surprise":0.0338,"sadness":0.0038,"fear":0.0104,"anger":0.0128,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to optimize energy consumption in UAV-assisted federated learning for IoT devices. It includes experiments on real-world datasets demonstrating cost reduction, but lacks information on actual deployment. The technical credibility is supported by the use of established methods like Kullback-Leibler divergence and TD3, and the presence of peer review.","key_impact_metrics":["cost reduction","robust performance under communication disruptions"],"technology_tags":["Federated Learning","UAV","IoT"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T12:23:30.941976Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ebf9ea1923e2","title":"OmniSAM: Omnidirectional Segment Anything Model for UDA in Panoramic Semantic Segmentation","content":"arXiv:2503.07098v3 Announce Type: replace Abstract: Segment Anything Model 2 (SAM2) has emerged as a strong base model in various pinhole imaging segmentation tasks. However, when applying it to $360^\\circ$ domain, the significant field-of-view (FoV) gap between pinhole ($70^\\circ \\times 70^\\circ$) and panoramic images ($180^\\circ \\times 360^\\circ$) poses unique challenges. Two major concerns for this application includes 1) inevitable distortion and object deformation brought by the large FoV disparity between domains; 2) the lack of pixel-level semantic understanding that the original SAM2 cannot provide. To address these issues, we propose a novel OmniSAM framework, which makes the first attempt to apply SAM2 for panoramic semantic segmentation. Specifically, to bridge the first gap, OmniSAM first divides the panorama into sequences of patches. These patches are then treated as image sequences in similar manners as in video segmentation tasks. We then leverage the SAM2's memory mechanism to extract cross-patch correspondences that embeds the cross-FoV dependencies, improving feature continuity and the prediction consistency along mask boundaries. For the second gap, OmniSAM fine-tunes the pretrained image encoder and reutilize the mask decoder for semantic prediction. An FoV-based prototypical adaptation module with dynamic pseudo label update mechanism is also introduced to facilitate the alignment of memory and backbone features, thereby improving model generalization ability across different sizes of source models. Extensive experimental results demonstrate that OmniSAM outperforms the state-of-the-art methods by large margins, e.g., 79.06% (+10.22%) on SPin8-to-SPan8, 62.46% (+6.58%) on CS13-to-DP13.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.07098","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.139383","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Ding Zhong, Xu Zheng, Chenfei Liao, Yuanhuiyi Lyu, Jialei Chen, Shengyang Wu, Linfeng Zhang, Xuming Hu","raw_content_length":1737,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["Panoramic Semantic Segmentation arXiv:2503.07098v3","FoV"],"persons":["SAM2"],"locations":[],"monetary":["360^\\circ$","70^\\circ","180^\\circ"]},"char_count":1736,"language_detected":"en","key_concepts":{"key_phrases":["OmniSAM","Omnidirectional Segment Anything Model","UDA","Panoramic Semantic Segmentation","Announce Type","Abstract","Segment Anything Model","SAM2","a strong base model","various pinhole imaging segmentation tasks"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"OmniSAM":2.0,"Omnidirectional Segment Anything Model":2.0,"UDA":2.0,"Panoramic Semantic Segmentation":2.0,"Announce Type":1.0,"Abstract":1.0,"Segment Anything Model":1.0,"SAM2":1.0,"a strong base model":1.0,"various pinhole imaging segmentation tasks":1.0}},"age_hours":2.765111602222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4334,"joy":0.0064,"surprise":0.0287,"sadness":0.0275,"fear":0.4564,"anger":0.037,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (OmniSAM) for panoramic semantic segmentation using SAM2. The concrete action is the development and testing of this framework, with measurable outcomes reported as performance improvements on specific datasets (e.g., 79.06% on SPin8-to-SPan8). However, it's still in the applied research stage, lacking real-world deployment and economic viability data.","key_impact_metrics":["79.06% (+10.22%) on SPin8-to-SPan8","62.46% (+6.58%) on CS13-to-DP13"],"technology_tags":["semantic segmentation","machine learning","computer vision"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:23:35.035972Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_22afcd73551e","title":"Hierarchical Balance Packing: Towards Efficient Supervised Fine","content":"arXiv:2503.07680v3 Announce Type: replace Abstract: Training Long-Context Large Language Models (LLMs) is challenging, as hybrid training with long-context and short-context data often leads to workload imbalances. Existing works mainly use data packing to alleviate this issue, but fail to consider imbalanced attention computation and wasted communication overhead. This paper proposes Hierarchical Balance Packing (HBP), which designs a novel batch-construction method and training recipe to address those inefficiencies. In particular, the HBP constructs multi-level data packing groups, each optimized with a distinct packing length. It assigns training samples to their optimal groups and configures each group with the most effective settings, including sequential parallelism degree and gradient checkpointing configuration. To effectively utilize multi-level groups of data, we design a dynamic training pipeline specifically tailored to HBP, including curriculum learning, adaptive sequential parallelism, and stable loss. Our extensive experiments demonstrate that our method significantly reduces training time over multiple datasets and open-source models while maintaining strong performance. For the largest DeepSeek-V2 (236B) MoE model, our method speeds up the training by 2.4$\\times$ with competitive performance. Codes will be released at https://github.com/ModelTC/HBP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.07680","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.140176","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Yongqiang Yao, Jingru Tan, Kaihuan Liang, Feizhao Zhang, Jiahao Hu, Shuo Wu, Yazhe Niu, Ruihao Gong, Dahua Lin, Ningyi Xu","raw_content_length":1390,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["HBP"],"persons":[],"locations":[],"monetary":[]},"char_count":1389,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical Balance Packing","Towards","Efficient Supervised Fine","arXiv250307680v3 Announce Type","Abstract","Training Long-Context Large Language Models","LLMs","hybrid training","long-context and short-context data","workload imbalances"],"filter_categories":{"ai_ml":["Training Long-Context Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical Balance Packing":3.0,"Towards":2.0,"Efficient Supervised Fine":2.0,"arXiv250307680v3 Announce Type":1.0,"Abstract":1.0,"Training Long-Context Large Language Models":1.0,"LLMs":1.0,"hybrid training":1.0,"long-context and short-context data":1.0,"workload imbalances":1.0}},"age_hours":2.7651408522222223,"is_recent":true,"quality_score":1.0,"sentiment_score":1.6475,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6705,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8875,"joy":0.0041,"surprise":0.0171,"sadness":0.0245,"fear":0.0083,"anger":0.0281,"disgust":0.0305},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (HBP) for training large language models more efficiently, reducing training time by 2.4x for the DeepSeek-V2 model. This efficiency gain translates to lower energy consumption during training, which has a positive, albeit indirect, climate impact. The research is supported by experimental results, but it is still in the applied research stage, lacking real-world deployment data.","key_impact_metrics":["2.4x training speedup"],"technology_tags":["Large Language Models","Training Efficiency","Hierarchical Balance Packing"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:23:38.182757Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ab169bf86caa","title":"Blind Video Super","content":"arXiv:2503.07856v2 Announce Type: replace Abstract: Blind video super-resolution (BVSR) is a low-level vision task which aims to generate high-resolution videos from low-resolution counterparts in unknown degradation scenarios. Existing approaches typically predict blur kernels that are spatially invariant in each video frame or even the entire video. These methods do not consider potential spatio-temporal varying degradations in videos, resulting in suboptimal BVSR performance. In this context, we propose a novel BVSR model based on Implicit Kernels, BVSR-IK, which constructs a multi-scale kernel dictionary parameterized by implicit neural representations. It also employs a newly designed recurrent Transformer to predict the coefficient weights for accurate filtering in both frame correction and feature alignment. Experimental results have demonstrated the effectiveness of the proposed BVSR-IK, when compared with four state-of-the-art BVSR models on three commonly used datasets, with BVSR-IK outperforming the second best approach, FMA-Net, by up to 0.59 dB in PSNR. Source code will be available at https://github.com/QZ1-boy/BVSR-IK.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.07856","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.140566","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Qiang Zhu, Yuxuan Jiang, Shuyuan Zhu, Fan Zhang, David Bull, Bing Zeng","raw_content_length":1152,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["BVSR","Blind Video Super arXiv:2503.07856v2 Announce Type","Implicit Kernels"],"persons":[],"locations":[],"monetary":[]},"char_count":1151,"language_detected":"en","key_concepts":{"key_phrases":["Blind Video Super","Announce Type","Abstract","Blind video super","resolution","BVSR","a low-level vision task","which","high-resolution videos","low-resolution counterparts"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Blind Video Super":2.0,"Announce Type":1.0,"Abstract":1.0,"Blind video super":1.0,"resolution":1.0,"BVSR":1.0,"a low-level vision task":1.0,"which":1.0,"high-resolution videos":1.0,"low-resolution counterparts":1.0}},"age_hours":2.7651559775,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9265,"joy":0.0046,"surprise":0.0296,"sadness":0.008,"fear":0.0076,"anger":0.0156,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to blind video super-resolution (BVSR) using implicit kernels. While the improved PSNR metric (0.59 dB improvement over FMA-Net) suggests potential for reducing energy consumption in video processing and transmission, there are no concrete deployments or quantified environmental benefits. It remains at the applied research stage, with source code available but no evidence of real-world application.","key_impact_metrics":["0.59 dB improvement in PSNR"],"technology_tags":["video super-resolution","implicit neural representations","recurrent Transformer"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:23:41.404456Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b7adbd04607","title":"Clustering by Nonparametric Smoothing","content":"arXiv:2503.09134v3 Announce Type: replace Abstract: A novel formulation of the clustering problem is introduced in which the task is expressed as an estimation problem, where the object to be estimated is a function which maps a point to its distribution of cluster membership. Unlike existing approaches which implicitly estimate such a function, like Gaussian Mixture Models (GMMs), the proposed approach bypasses any explicit modelling assumptions and exploits the flexible estimation potential of nonparametric smoothing. An intuitive approach for selecting the tuning parameters governing estimation is provided, which allows the proposed method to automatically determine both an appropriate level of flexibility and also the number of clusters to extract from a given data set. Experiments on a large collection of publicly available data sets are used to document the strong performance of the proposed approach, in comparison with relevant benchmarks from the literature. R code to implement the proposed approach is available from https://github.com/DavidHofmeyr/CNS","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.09134","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.140955","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"David P. Hofmeyr","raw_content_length":1077,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1076,"language_detected":"en","key_concepts":{"key_phrases":["which","Nonparametric Smoothing","arXiv250309134v3 Announce Type","Abstract","A novel formulation","the clustering problem","the task","an estimation problem","the object","a function"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"which":3.0,"Nonparametric Smoothing":2.0,"arXiv250309134v3 Announce Type":1.0,"Abstract":1.0,"A novel formulation":1.0,"the clustering problem":1.0,"the task":1.0,"an estimation problem":1.0,"the object":1.0,"a function":1.0}},"age_hours":2.7651703241666667,"is_recent":true,"quality_score":0.7,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8784,"joy":0.013,"surprise":0.0393,"sadness":0.0056,"fear":0.0108,"anger":0.0324,"disgust":0.0205},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper introduces a novel clustering method using nonparametric smoothing. While the method shows strong performance on publicly available datasets, its direct climate impact is currently theoretical. The availability of R code enhances reproducibility and potential for future application in climate-related datasets, but no concrete deployments or measured outcomes are presented.","key_impact_metrics":[],"technology_tags":["machine learning","clustering","nonparametric smoothing"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:23:44.572902Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_87f38c3622d4","title":"Isolated Channel Vision Transformers: From Single","content":"arXiv:2503.09826v2 Announce Type: replace Abstract: Vision Transformers (ViTs) have achieved remarkable success in standard RGB image processing tasks. However, applying ViTs to multi-channel imaging (MCI) data, e.g., for medical and remote sensing applications, remains a challenge. In particular, MCI data often consist of layers acquired from different modalities. Directly training ViTs on such data can obscure complementary information and impair the performance. In this paper, we introduce a simple yet effective pretraining framework for large-scale MCI datasets. Our method, named Isolated Channel ViT (IC-ViT), patchifies image channels individually and thereby enables pretraining for multimodal multi-channel tasks. We show that this channel-wise patchifying is a key technique for MCI processing. More importantly, one can pretrain the IC-ViT on single channels and finetune it on downstream multi-channel datasets. This pretraining framework captures dependencies between patches as well as channels and produces robust feature representation. Experiments on various tasks and benchmarks, including JUMP-CP and CHAMMI for cell microscopy imaging, and So2Sat-LCZ42 for satellite imaging, show that the proposed IC-ViT delivers 4-14 percentage points of performance improvement over existing channel-adaptive approaches. Further, its efficient training makes it a suitable candidate for large-scale pretraining of foundation models on heterogeneous data. Our code is available at https://github.com/shermanlian/IC-ViT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.09826","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.141347","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Wenyi Lian, Patrick Micke, Joakim Lindblad, Nata\\v{s}a Sladoje","raw_content_length":1532,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Vision Transformers","IC-ViT","Isolated Channel Vision Transformers:","Isolated Channel ViT","MCI","RGB"],"persons":[],"locations":[],"monetary":[]},"char_count":1531,"language_detected":"en","key_concepts":{"key_phrases":["ViTs","Isolated Channel Vision Transformers","arXiv250309826v2 Announce Type","Abstract","Vision Transformers","remarkable success","standard RGB image processing tasks","MCI","medical and remote sensing applications","a challenge"],"filter_categories":{"ai_ml":["Isolated Channel Vision Transformers","Vision Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ViTs":3.0,"Isolated Channel Vision Transformers":2.0,"arXiv250309826v2 Announce Type":1.0,"Abstract":1.0,"Vision Transformers":1.0,"remarkable success":1.0,"standard RGB image processing tasks":1.0,"MCI":1.0,"medical and remote sensing applications":1.0,"a challenge":1.0}},"age_hours":2.7651864530555557,"is_recent":true,"quality_score":1.0,"sentiment_score":9.259500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8519,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7208,"joy":0.0058,"surprise":0.0366,"sadness":0.0688,"fear":0.0677,"anger":0.0298,"disgust":0.0706},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel pretraining framework (IC-ViT) for multi-channel imaging data, showing performance improvements of 4-14 percentage points on benchmarks like JUMP-CP and So2Sat-LCZ42. While promising, it is still in the applied research stage with no clear path to economic viability or large-scale deployment. The impact on climate change is indirect, through improved remote sensing applications, but not directly quantified.","key_impact_metrics":["4-14 percentage points of performance improvement"],"technology_tags":["Vision Transformers","Multi-channel imaging","Remote sensing","Medical imaging"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:23:50.697436Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ffffca358fdd","title":"A Comprehensive Survey on Knowledge Distillation","content":"arXiv:2503.12067v2 Announce Type: replace Abstract: Deep Neural Networks (DNNs) have achieved notable performance in the fields of computer vision and natural language processing with various applications in both academia and industry. However, with recent advancements in DNNs and transformer models with a tremendous number of parameters, deploying these large models on edge devices causes serious issues such as high runtime and memory consumption. This is especially concerning with the recent large-scale foundation models, Vision-Language Models (VLMs), and Large Language Models (LLMs). Knowledge Distillation (KD) is one of the prominent techniques proposed to address the aforementioned problems using a teacher-student architecture. More specifically, a lightweight student model is trained using additional knowledge from a cumbersome teacher model. In this work, a comprehensive survey of knowledge distillation methods is proposed. This includes reviewing KD from different aspects: distillation sources, distillation schemes, distillation algorithms, distillation by modalities, applications of distillation, and comparison among existing methods. In contrast to most existing surveys, which are either outdated or simply update former surveys, this work proposes a comprehensive survey with a new point of view and representation structure that categorizes and investigates the most recent methods in knowledge distillation. This survey considers various critically important subcategories, including KD for diffusion models, 3D inputs, foundational models, transformers, and LLMs. Furthermore, existing challenges in KD and possible future research directions are discussed. Github page of the project: https://github.com/IPL-Sharif/KD_Survey","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.12067","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.141775","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Amir M. Mansourian, Rozhan Ahmadi, Masoud Ghafouri, Amir Mohammad Babaei, Elaheh Badali Golezani, Zeynab Yasamani Ghamchi, Vida Ramezanian, Alireza Taherian, Kimia Dinashi, Amirali Miri, Shohreh Kasaei","raw_content_length":1760,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["Deep Neural Networks","Vision-Language Models"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1759,"language_detected":"en","key_concepts":{"key_phrases":["A Comprehensive Survey","Knowledge Distillation","DNNs","arXiv250312067v2 Announce Type","Abstract","Deep Neural Networks","notable performance","the fields","computer vision","natural language processing"],"filter_categories":{"ai_ml":["Deep Neural Networks","computer vision","natural language processing"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Comprehensive Survey":2.0,"Knowledge Distillation":2.0,"DNNs":2.0,"arXiv250312067v2 Announce Type":1.0,"Abstract":1.0,"Deep Neural Networks":1.0,"notable performance":1.0,"the fields":1.0,"computer vision":1.0,"natural language processing":1.0}},"age_hours":2.7652009208333332,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6997,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.1565,"joy":0.0086,"surprise":0.0399,"sadness":0.3365,"fear":0.3285,"anger":0.1108,"disgust":0.0191},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":6,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article is a survey of knowledge distillation (KD) techniques, which aim to reduce the size and computational cost of deep learning models. While KD itself doesn't directly reduce GHG emissions, it enables the deployment of AI models on edge devices, potentially reducing the energy consumption associated with large data centers. The article is a survey, so deployment readiness is low, and economic viability is uncertain at this stage.","key_impact_metrics":[],"technology_tags":["knowledge distillation","deep learning","edge computing","AI efficiency"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T12:23:54.963138Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_db18d00cfed4","title":"Open Wireless Digital Twin: End","content":"arXiv:2503.12177v4 Announce Type: replace Abstract: This study presents an end-to-end wireless digital twin platform constructed using open-source software and open data to enhance the evaluation of mobile communication systems. The proposed open wireless digital twin (OWDT) integrates OpenAirInterface (OAI) for Fifth-Generation New Radio (5G NR) protocol stack emulation and NVIDIA Sionna RT for high-resolution ray-tracing-based radio propagation modeling. This integration enables the realistic emulation of 5G wireless communication in mobility scenarios on a CPU-based Linux system, leveraging real-world building data to bridge the gap between theoretical simulations and real-world deployments. The platform also incorporates OAI FlexRIC, which is an implementation aligned with the O-RAN near-real-time RAN Intelligent Controller (near-RT RIC), to dynamically monitor key performance indicators (KPIs). Through extensive evaluation in urban environments, this study demonstrated the validity of the emulation framework, revealing its capability to replicate real-world communication dynamics with high fidelity. The results underscore the potential of the OWDT to accelerate wireless system development, reduce experimental costs, and optimize network configurations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.12177","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.142154","language":"en","tags":["preprints","csni","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Tetsuya Iye, Masaya Sakamoto, Shohei Takaya, Eisaku Sato, Yuki Susukida, Yu Nagaoka, Kazuki Maruta, Jin Nakazato","raw_content_length":1278,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["OWDT","OAI","CPU","RAN","the O-RAN","Fifth-Generation New Radio"],"persons":[],"locations":[],"monetary":[]},"char_count":1277,"language_detected":"en","key_concepts":{"key_phrases":["Open Wireless Digital Twin End","Announce Type","Abstract","This study","end","open-source software","open data","the evaluation","mobile communication systems","The proposed open wireless digital twin"],"filter_categories":{"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Open Wireless Digital Twin End":2.0,"Announce Type":1.0,"Abstract":1.0,"This study":1.0,"end":1.0,"open-source software":1.0,"open data":1.0,"the evaluation":1.0,"mobile communication systems":1.0,"The proposed open wireless digital twin":1.0}},"age_hours":2.765216928333333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7945,"joy":0.0655,"surprise":0.1019,"sadness":0.0139,"fear":0.0098,"anger":0.0107,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a digital twin platform for 5G wireless communication, which could potentially reduce energy consumption by optimizing network configurations. The technical credibility is supported by the use of open-source software and real-world data, and the study demonstrates the framework's validity in replicating real-world communication dynamics. However, it is still in the applied research stage with no deployed units, limiting its current impact and economic viability.","key_impact_metrics":["High fidelity replication of real-world communication dynamics"],"technology_tags":["Digital Twin","5G","OpenAirInterface","Ray-tracing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:23:58.518516Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3b99da1c6a60","title":"Free","content":"arXiv:2503.14275v3 Announce Type: replace Abstract: Recent advances in Text-to-Image (T2I) diffusion models have transformed image generation, enabling significant progress in stylized generation using only a few style reference images. However, current diffusion-based methods struggle with fine-grained style customization due to challenges in controlling multiple style attributes, such as color and texture. This paper introduces the first tuning-free approach to achieve free-lunch color-texture disentanglement in stylized T2I generation, addressing the need for independently controlled style elements for the Disentangled Stylized Image Generation (DisIG) problem. Our approach leverages the Image-Prompt Additivity property in the CLIP image embedding space to develop techniques for separating and extracting Color-Texture Embeddings (CTE) from individual color and texture reference images. To ensure that the color palette of the generated image aligns closely with the color reference, we apply a whitening and coloring transformation to enhance color consistency. Additionally, to prevent texture loss due to the signal-leak bias inherent in diffusion training, we introduce a noise term that preserves textural fidelity during the Regularized Whitening and Coloring Transformation (RegWCT). Through these methods, our Style Attributes Disentanglement approach (SADis) delivers a more precise and customizable solution for stylized image generation. Experiments on images from the WikiArt and StyleDrop datasets demonstrate that, both qualitatively and quantitatively, SADis surpasses state-of-the-art stylization methods in the DisIG task.Code is released at https://deepffff.github.io/sadis.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.14275","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.142947","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Jiang Qin, Senmao Li, Alexandra Gomez-Villa, Shiqi Yang, Yaxing Wang, Kai Wang, Joost van de Weijer","raw_content_length":1719,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["CLIP","CTE","the Disentangled Stylized Image Generation"],"persons":["DisIG"],"locations":[],"monetary":[]},"char_count":1718,"language_detected":"en","key_concepts":{"key_phrases":["arXiv250314275v3","Announce Type","Abstract","Recent advances","Image","T2I","image generation","significant progress","stylized generation","only a few style reference images"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv250314275v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"Image":1.0,"T2I":1.0,"image generation":1.0,"significant progress":1.0,"stylized generation":1.0,"only a few style reference images":1.0}},"age_hours":2.7652451383333334,"is_recent":true,"quality_score":0.7,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8865,"joy":0.0341,"surprise":0.0447,"sadness":0.0102,"fear":0.0095,"anger":0.0103,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to disentangled stylized image generation. The concrete action is the development of a tuning-free method for controlling color and texture in T2I models. The evidence is based on experiments on WikiArt and StyleDrop datasets, but there are no real-world deployments or quantified environmental benefits.","key_impact_metrics":["Qualitative improvement in style disentanglement","Quantitative improvement in DisIG task"],"technology_tags":["Text-to-Image Generation","Diffusion Models","CLIP Embeddings"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:01.651200Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95bf4041c804","title":"Towards Unified and Lossless Latent Space for 3D Molecular Latent Diffusion Modeling","content":"arXiv:2503.15567v4 Announce Type: replace Abstract: 3D molecule generation is crucial for drug discovery and material science, requiring models to process complex multi-modalities, including atom types, chemical bonds, and 3D coordinates. A key challenge is integrating these modalities of different shapes while maintaining SE(3) equivariance for 3D coordinates. To achieve this, existing approaches typically maintain separate latent spaces for invariant and equivariant modalities, reducing efficiency in both training and sampling. In this work, we propose \\textbf{U}nified Variational \\textbf{A}uto-\\textbf{E}ncoder for \\textbf{3D} Molecular Latent Diffusion Modeling (\\textbf{UAE-3D}), a multi-modal VAE that compresses 3D molecules into latent sequences from a unified latent space, while maintaining near-zero reconstruction error. This unified latent space eliminates the complexities of handling multi-modality and equivariance when performing latent diffusion modeling. We demonstrate this by employing the Diffusion Transformer--a general-purpose diffusion model without any molecular inductive bias--for latent generation. Extensive experiments on GEOM-Drugs and QM9 datasets demonstrate that our method significantly establishes new benchmarks in both \\textit{de novo} and conditional 3D molecule generation, achieving leading efficiency and quality. On GEOM-Drugs, it reduces FCD by 72.6\\% over the previous best result, while achieving over 70\\% relative average improvements in geometric fidelity. Our code is released at https://github.com/lyc0930/UAE-3D/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.15567","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.143344","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Yanchen Luo, Zhiyuan Liu, Yi Zhao, Sihang Li, Hengxing Cai, Kenji Kawaguchi, Tat-Seng Chua, Yang Zhang, Xiang Wang","raw_content_length":1575,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["3D Molecular Latent Diffusion Modeling arXiv:2503.15567v4 Announce Type","VAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1574,"language_detected":"en","key_concepts":{"key_phrases":["Unified and Lossless Latent Space","3D Molecular Latent Diffusion Modeling","3D coordinates","Announce Type","3D molecule generation","drug discovery","material science","models","complex multi","modalities"],"filter_categories":{"research_academic":["drug discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unified and Lossless Latent Space":2.0,"3D Molecular Latent Diffusion Modeling":2.0,"3D coordinates":2.0,"Announce Type":1.0,"3D molecule generation":1.0,"drug discovery":1.0,"material science":1.0,"models":1.0,"complex multi":1.0,"modalities":1.0}},"age_hours":2.765259782777778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.932,"joy":0.0058,"surprise":0.0208,"sadness":0.0064,"fear":0.0122,"anger":0.0147,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for 3D molecule generation, which could accelerate drug discovery and material science. The method achieves significant improvements in efficiency and quality, as demonstrated by a 72.6% reduction in FCD on GEOM-Drugs. However, it is still in the research phase with no deployed applications or economic viability demonstrated.","key_impact_metrics":["FCD reduction by 72.6%","Geometric fidelity improvements over 70%"],"technology_tags":["3D molecule generation","latent diffusion modeling","variational autoencoder"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:24:05.051356Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_656f10b4dbb2","title":"Surface","content":"arXiv:2503.18254v2 Announce Type: replace Abstract: Many 3D tasks such as pose alignment, animation, motion transfer, and 3D reconstruction rely on establishing correspondences between 3D shapes. This challenge has recently been approached by pairwise matching of semantic features from pre-trained vision models. However, despite their power, these features struggle to differentiate instances of the same semantic class such as ``left hand'' versus ``right hand'' which leads to substantial mapping errors. To solve this, we learn a surface-aware embedding space that is robust to these ambiguities while facilitating shared mapping for an entire family of 3D shapes. Importantly, our approach is self-supervised and requires only a small number of unpaired training meshes to infer features for new possibly imperfect 3D shapes at test time. We achieve this by introducing a contrastive loss that preserves the semantic content of the features distilled from foundational models while disambiguating features located far apart on the shape's surface. We observe superior performance in correspondence matching benchmarks and enable downstream applications including 2D-to-3D and 3D-to-3D texture transfer, in-part segmentation, pose alignment, and motion transfer in low-data regimes. Unlike previous pairwise approaches, our solution constructs a joint embedding space, where both seen and unseen 3D shapes are implicitly aligned without further optimization. The code is available at https://graphics.tudelft.nl/SurfaceAware3DFeatures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.18254","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.143772","language":"en","tags":["computer-science","preprints","cscv","csgr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Lukas Uzolas, Elmar Eisemann, Petr Kellnhofer","raw_content_length":1541,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1540,"language_detected":"en","key_concepts":{"key_phrases":["Surface","Announce Type","Many 3D tasks","pose alignment","animation","motion transfer","3D reconstruction","correspondences","3D shapes","This challenge"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Surface":2.0,"Announce Type":1.0,"Many 3D tasks":1.0,"pose alignment":1.0,"animation":1.0,"motion transfer":1.0,"3D reconstruction":1.0,"correspondences":1.0,"3D shapes":1.0,"This challenge":1.0}},"age_hours":2.7652748705555554,"is_recent":true,"quality_score":0.7,"sentiment_score":9.0305,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8061,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8969,"joy":0.0083,"surprise":0.0526,"sadness":0.0113,"fear":0.01,"anger":0.0131,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel self-supervised method for 3D shape correspondence using surface-aware embeddings. While the method shows superior performance in benchmarks and enables downstream applications like texture transfer, it is still in the applied research phase with no concrete deployments or quantified environmental benefits. The code is available, suggesting potential for future development and application.","key_impact_metrics":[],"technology_tags":["3D shape correspondence","self-supervised learning","computer vision"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:24:08.033922Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4489d00a01f7","title":"Agents in the Sandbox: End","content":"arXiv:2503.20036v2 Announce Type: replace Abstract: Reproducing game bugs, particularly crash bugs in continuously evolving games like Minecraft, is a notoriously manual, time-consuming, and challenging process to automate; insights from a key decision maker from Minecraft we interviewed confirm this, highlighting that a substantial portion of crash reports necessitate manual scenario reconstruction. Despite the success of LLM-driven bug reproduction in other software domains, games, with their complex interactive environments, remain largely unaddressed. This paper introduces BugCraft, a novel end-to-end framework designed to automate the reproduction of crash bugs in Minecraft directly from user-submitted bug reports, addressing the critical gap in automated game bug reproduction. BugCraft employs a two-stage approach: first, a Step Synthesizer leverages LLMs and Minecraft Wiki knowledge to transform bug reports into high-quality, structured steps to reproduce (S2R). Second, an Action Model, powered by a vision-based LLM agent and a custom macro API, executes these S2R steps within Minecraft to trigger the reported crash. To facilitate evaluation, we introduce BugCraft-Bench, a curated dataset of Minecraft crash bug reports. On BugCraft-Bench, our framework end-to-end reproduced 34.9% of crash bugs with GPT-4.1, outperforming baseline computer-use models by 37%. BugCraft demonstrates the feasibility of automated reproduction of crash bugs in complex game environments using LLMs, opening promising avenues for game testing and development. Finally, we make our code open at https://bugcraft2025.github.io","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.20036","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.144184","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Eray Yapa\\u{g}c{\\i}, Yavuz Alp Sencer \\\"Ozt\\\"urk, Eray T\\\"uz\\\"un","raw_content_length":1631,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["BugCraft","Minecraft"],"persons":["Step Synthesizer","Minecraft Wiki"],"locations":[],"monetary":[]},"char_count":1630,"language_detected":"en","key_concepts":{"key_phrases":["the Sandbox","Minecraft","arXiv250320036v2 Announce Type","Abstract","game bugs","bugs","continuously evolving games","challenging process","insights","a key decision maker"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Sandbox":2.0,"Minecraft":2.0,"arXiv250320036v2 Announce Type":1.0,"Abstract":1.0,"game bugs":1.0,"bugs":1.0,"continuously evolving games":1.0,"challenging process":1.0,"insights":1.0,"a key decision maker":1.0}},"age_hours":2.7652897955555553,"is_recent":true,"quality_score":1.0,"sentiment_score":2.077,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5846,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9167,"joy":0.0032,"surprise":0.0168,"sadness":0.0214,"fear":0.0102,"anger":0.0141,"disgust":0.0175},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents BugCraft, a framework for automated bug reproduction in Minecraft. While the framework itself doesn't directly address climate change, it improves software development efficiency, which could indirectly contribute to sustainability by reducing resource consumption in software development. The framework reproduced 34.9% of crash bugs with GPT-4.1.","key_impact_metrics":["Reproduction rate of crash bugs: 34.9%","Outperformance of baseline models: 37%"],"technology_tags":["LLMs","Bug reproduction","Game testing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:13.212000Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e7a35ee7d30b","title":"Rethinking Graph Structure Learning in the Era of LLMs","content":"arXiv:2503.21223v4 Announce Type: replace Abstract: Recently, the emergence of LLMs has prompted researchers to integrate language descriptions into graphs, aiming to enhance model encoding capabilities from a data-centric perspective. This graph representation is called text-attributed graphs (TAGs). A review of prior advancements highlights that graph structure learning (GSL) is a pivotal technique for improving data utility, making it highly relevant to efficient TAG learning. However, most GSL methods are tailored for traditional graphs without textual information, underscoring the necessity of developing a new GSL paradigm. Despite clear motivations, it remains challenging: (1) How can we define a reasonable optimization objective for GSL in the era of LLMs, considering the massive parameters in LLM? (2) How can we design an efficient model architecture that enables seamless integration of LLM for this optimization objective? For Question 1, we reformulate existing GSL optimization objectives as a tree optimization framework, shifting the focus from obtaining a well-trained edge predictor to a language-aware tree sampler. For Question 2, we propose decoupled and training-free model design principles for LLM integration, shifting the focus from computation-intensive fine-tuning to more efficient inference. Based on this, we propose Large Language and Tree Assistant (LLaTA), which leverages tree-based LLM in-context learning to enhance the understanding of topology and text, enabling reliable inference and generating improved graph structure. Extensive experiments on 11 datasets demonstrate that LLaTA enjoys flexibility-incorporated with any backbone; scalability-outperforms other LLM-enhanced graph learning methods; effectiveness-achieves SOTA predictive performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.21223","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.144612","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Zhihan Zhang, Xunkai Li, Zhu Lei, Guang Zeng, Ronghua Li, Guoren Wang","raw_content_length":1802,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["LLM","GSL"],"persons":["Structure Learning"],"locations":[],"monetary":[]},"char_count":1801,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Graph Structure Learning","the Era","arXiv250321223v4 Announce Type","Abstract","the emergence","researchers","language descriptions","graphs","model"],"filter_categories":{"ai_ml":["LLMs","model"],"research_academic":["researchers"],"business_innovation":["model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Graph Structure Learning":2.0,"the Era":2.0,"arXiv250321223v4 Announce Type":1.0,"Abstract":1.0,"the emergence":1.0,"researchers":1.0,"language descriptions":1.0,"graphs":1.0,"model":1.0}},"age_hours":2.765305130833333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9043,"joy":0.0336,"surprise":0.0335,"sadness":0.0027,"fear":0.0074,"anger":0.0111,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method for graph structure learning using LLMs, which could potentially improve the efficiency of data processing in various applications. The research is still in the early stages, with no deployed units or real-world data on its impact on sustainability. The paper does present experimental results on 11 datasets, providing some evidence of its effectiveness.","key_impact_metrics":["SOTA predictive performance","Flexibility-incorporated with any backbone"],"technology_tags":["Graph Structure Learning","Large Language Models","Tree-based LLM"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:16.813067Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_294fb92d368d","title":"On the Mathematical Relationship Between Layer Normalization and Dynamic Activation Functions","content":"arXiv:2503.21708v3 Announce Type: replace Abstract: Layer normalization (LN) is an essential component of modern neural networks. While many alternative techniques have been proposed, none of them have succeeded in replacing LN so far. The latest suggestion in this line of research is a dynamic activation function called Dynamic Tanh (DyT). Although it is empirically well-motivated and appealing from a practical point of view, it lacks a theoretical foundation. In this work, we shed light on the mathematical relationship between LN and dynamic activation functions. In particular, we derive DyT from the LN variant RMSNorm, and show that a well-defined decoupling in derivative space as well as an approximation are needed to do so. By applying the same decoupling procedure directly in function space, we are able to omit the approximation and obtain the exact element-wise counterpart of RMSNorm, which we call Dynamic Inverse Square Root Unit (DyISRU). We demonstrate numerically that DyISRU reproduces the normalization effect on outliers more accurately than DyT does.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.21708","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.145000","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Felix Stollenwerk","raw_content_length":1080,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["RMSNorm","DyT"],"persons":["Dynamic Tanh"],"locations":["the Mathematical Relationship Between Layer Normalization"],"monetary":[]},"char_count":1079,"language_detected":"en","key_concepts":{"key_phrases":["the Mathematical Relationship","Layer Normalization","Dynamic Activation Functions","arXiv250321708v3 Announce Type","Abstract","Layer normalization","an essential component","modern neural networks","many alternative techniques","none"],"filter_categories":{"ai_ml":["modern neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Mathematical Relationship":2.0,"Layer Normalization":2.0,"Dynamic Activation Functions":2.0,"arXiv250321708v3 Announce Type":1.0,"Abstract":1.0,"Layer normalization":1.0,"an essential component":1.0,"modern neural networks":1.0,"many alternative techniques":1.0,"none":1.0}},"age_hours":2.765320793611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8625,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.889,"joy":0.0231,"surprise":0.0306,"sadness":0.0189,"fear":0.0097,"anger":0.013,"disgust":0.0158},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical improvement to layer normalization in neural networks, potentially leading to more efficient training. While the numerical demonstration shows improved outlier handling, there's no evidence of real-world deployment or quantified impact on energy consumption or GHG emissions. It remains at the basic research stage.","key_impact_metrics":["Normalization effect on outliers"],"technology_tags":["Layer Normalization","Dynamic Activation Functions","Neural Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:20.143285Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7214602455b9","title":"PartialLoading: User Scheduling and Bandwidth Allocation for Parameter","content":"arXiv:2503.22982v2 Announce Type: replace Abstract: By provisioning inference offloading services, edge inference drives the rapid growth of AI applications at network edge. However, how to reduce the inference latency remains a significant challenge. To address this issue, we develop a parameter-sharing AI model loading (PartialLoading) framework for multi-user edge inference, which exploits two key insights: 1) the majority of latency arises from loading AI models into server GPU memory, and 2) different AI models can share a significant number of parameters, for which redundant loading should be avoided. Towards this end, we formulate a joint multi-user scheduling and spectrum bandwidth allocation problem to maximize task throughput by exploiting shared parameter blocks across models. The intuition is to judiciously schedule user requests to reuse the shared parameter blocks between consecutively loaded models, thereby reducing model loading time substantially. To facilitate solution finding, we decouple the problem into two sub-problems, i.e., user scheduling and bandwidth allocation, showing that solving them sequentially leads to the solution to the original problem. Due to the NP-hardness of the problem, we first study an important special case called the \"backbone-sharing\" case, and design a dynamic programming-based algorithm to obtain the optimal solution in polynomial time. For the general case, we propose a greedy heuristic to obtain the sub-optimal solution efficiently. Simulation results demonstrate that the proposed framework significantly improves task throughput under deadline constraints compared with user scheduling without exploiting parameter sharing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.22982","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.146220","language":"en","tags":["computer-science","csai","preprints","csni","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Guanqiao Qu, Qian Chen, Xianhao Chen, Kaibin Huang, Yuguang Fang","raw_content_length":1701,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["Bandwidth Allocation"],"persons":["GPU"],"locations":[],"monetary":[]},"char_count":1700,"language_detected":"en","key_concepts":{"key_phrases":["PartialLoading","User Scheduling and Bandwidth Allocation","Parameter","Announce Type","Abstract","inference offloading services","edge inference","the rapid growth","AI applications","network edge"],"filter_categories":{"ai_ml":["AI applications"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PartialLoading":2.0,"User Scheduling and Bandwidth Allocation":2.0,"Parameter":2.0,"Announce Type":1.0,"Abstract":1.0,"inference offloading services":1.0,"edge inference":1.0,"the rapid growth":1.0,"AI applications":1.0,"network edge":1.0}},"age_hours":2.7653654216666665,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9418,"joy":0.0042,"surprise":0.0254,"sadness":0.0063,"fear":0.0051,"anger":0.0123,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (PartialLoading) to improve task throughput in edge inference by optimizing AI model loading and bandwidth allocation. It quantifies the improvement in task throughput through simulations, but lacks real-world deployment data. The technical credibility is supported by the problem formulation and algorithms, but it's still in the research phase.","key_impact_metrics":["task throughput improvement","reduction in model loading time"],"technology_tags":["edge inference","AI model loading","bandwidth allocation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:24.014493Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4371f5572015","title":"Joint Source","content":"arXiv:2503.23258v2 Announce Type: replace Abstract: Adapting pre-trained deep learning models to new and unknown environments remains a major challenge in underwater acoustic localization. We show that although the performance of pre-trained models suffers from mismatch between the training and test data, they generally exhibit a higher uncertainty in environments where there is more mismatch. Additionally, in the presence of environmental mismatch, spurious peaks can appear in the output of classification-based localization approaches, which inspires us to define and use a method to quantify the \"implied uncertainty\" based on the number of model output peaks. Leveraging this notion of implied uncertainty, we partition the test samples into sets with more certain and less certain samples, and implement a method to adapt the model to new environments by using the certain samples to improve the labeling for uncertain samples, which helps to adapt the model. Thus, using this efficient method for model uncertainty quantification, we showcase an innovative approach to adapt a pre-trained model to unseen underwater environments at test time. This eliminates the need for labeled data from the target environment or the original training data. This adaptation is enhanced by integrating an independent estimate based on the received signal energy. We validate the approach extensively using real experimental data, as well as synthetic data consisting of model-generated signals with real ocean noise. The results demonstrate significant improvements in model prediction accuracy, underscoring the potential of the method to enhance underwater acoustic localization in diverse, noisy, and unknown environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2503.23258","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.146655","language":"en","tags":["cslg","eesssp","eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":248,"author":"Dariush Kari, Hari Vishnu, Andrew C. Singer","raw_content_length":1722,"priority":7,"update_frequency":1,"reading_time_minutes":1.24,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1721,"language_detected":"en","key_concepts":{"key_phrases":["Joint Source","arXiv250323258v2 Announce Type","Abstract","Adapting pre-trained deep learning models","new and unknown environments","a major challenge","underwater acoustic localization","the performance","pre-trained models","mismatch"],"filter_categories":{"ai_ml":["Adapting pre-trained deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Joint Source":2.0,"arXiv250323258v2 Announce Type":1.0,"Abstract":1.0,"Adapting pre-trained deep learning models":1.0,"new and unknown environments":1.0,"a major challenge":1.0,"underwater acoustic localization":1.0,"the performance":1.0,"pre-trained models":1.0,"mismatch":1.0}},"age_hours":2.765380041111111,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9985000000000004,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6003,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7848,"joy":0.0053,"surprise":0.0355,"sadness":0.014,"fear":0.1186,"anger":0.0247,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for adapting pre-trained deep learning models to new underwater acoustic environments, improving localization accuracy. Validation is performed using real experimental data and synthetic data, indicating some level of testing, but it remains in the applied research stage with no mention of deployed units. The impact on climate is indirect, potentially enabling more efficient underwater monitoring, but not directly reducing emissions.","key_impact_metrics":["Significant improvements in model prediction accuracy","Quantified 'implied uncertainty'"],"technology_tags":["Underwater acoustics","Deep learning","Environmental monitoring"],"sdg_alignment":[9,14],"analyzed_at":"2025-10-29T12:24:29.360796Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d322df7bd7f4","title":"SAVeD: Learning to Denoise Low","content":"arXiv:2504.00161v2 Announce Type: replace Abstract: Low signal-to-noise ratio videos -- such as those from underwater sonar, ultrasound, and microscopy -- pose significant challenges for computer vision models, particularly when paired clean imagery is unavailable. We present Spatiotemporal Augmentations and denoising in Video for Downstream Tasks (SAVeD), a novel self-supervised method that denoises low-SNR sensor videos using only raw noisy data. By leveraging distinctions between foreground and background motion and exaggerating objects with stronger motion signal, SAVeD enhances foreground object visibility and reduces background and camera noise without requiring clean video. SAVeD has a set of architectural optimizations that lead to faster throughput, training, and inference than existing deep learning methods. We also introduce a new denoising metric, FBD, which indicates foreground-background divergence for detection datasets without requiring clean imagery. Our approach achieves state-of-the-art results for classification, detection, tracking, and counting tasks, and it does so with fewer training resource requirements than existing deep-learning-based denoising methods. Project page: https://suzanne-stathatos.github.io/SAVeD Code page: https://github.com/suzanne-stathatos/SAVeD","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.00161","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.147041","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Suzanne Stathatos, Michael Hobley, Pietro Perona, Markus Marks","raw_content_length":1310,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Video for Downstream Tasks","Spatiotemporal Augmentations"],"persons":[],"locations":[],"monetary":[]},"char_count":1309,"language_detected":"en","key_concepts":{"key_phrases":["SAVeD Learning to Denoise Low","arXiv250400161v2 Announce Type","Abstract","noise","those","underwater sonar","ultrasound","significant challenges","computer vision models","paired clean imagery"],"filter_categories":{"ai_ml":["computer vision models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SAVeD Learning to Denoise Low":2.0,"arXiv250400161v2 Announce Type":1.0,"Abstract":1.0,"noise":1.0,"those":1.0,"underwater sonar":1.0,"ultrasound":1.0,"significant challenges":1.0,"computer vision models":1.0,"paired clean imagery":1.0}},"age_hours":2.765394940833333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.214,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8428,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.757,"joy":0.0086,"surprise":0.0157,"sadness":0.0084,"fear":0.1499,"anger":0.0341,"disgust":0.0262},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel self-supervised method for denoising low-SNR sensor videos, which could have applications in environmental monitoring (e.g., underwater sonar). The method achieves state-of-the-art results on various tasks and requires fewer training resources than existing methods, suggesting potential energy savings in computation. However, it is still in the applied research stage, and there are no concrete deployments or quantified environmental benefits yet.","key_impact_metrics":["Fewer training resource requirements","Faster throughput, training, and inference"],"technology_tags":["Denoising","Self-supervised learning","Computer vision"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:24:32.905574Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
