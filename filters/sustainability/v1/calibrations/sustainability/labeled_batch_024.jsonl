{"id":"science_arxiv_cs_3c9d36dd5154","title":"Beyond Pass@k: Breadth","content":"arXiv:2510.08325v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm to improve Large Language Models on reasoning tasks such as coding, math or logic. To assess the reasoning boundary (the fraction of problems a model can solve) researchers often report Pass@k at large sampling budgets. Recent results reveal a crossover phenomenon: while RLVR models outperform the base model at small k values, the base model usually outperforms them when sampling a very large number of completions. This has been interpreted as evidence that base models have a larger reasoning boundary. We argue that on tasks with discrete answer spaces, such as math with numeric outputs, Pass@k at large k reflects the increasingly higher chance of success in the limit of the number of trials rather than genuine reasoning, and can therefore be misleading. We propose Cover@tau, which measures the fraction of problems that a model can solve for which at least a tau proportion of completions are correct. Unlike Pass@k, Cover@tau captures reasoning under an explicit reliability threshold: models that rely on random guessing degrade rapidly as tau increases. We evaluate several RLVR models using Cover@tau-based metrics and illustrate how the relative rankings of popular algorithms change compared to Pass@1, offering a different perspective on reasoning boundaries.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08325","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.293352","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Marius Dragoi, Ioana Pintilie, Florin Gogianu, Florin Brad","raw_content_length":1416,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning"],"persons":["Large Language Models"],"locations":["Cover@tau"],"monetary":[]},"char_count":1415,"language_detected":"en","key_concepts":{"key_phrases":["Passk","RLVR","the base model","arXiv251008325v1 Announce Type","new Abstract","Reinforcement Learning","Verifiable Rewards","a powerful paradigm","Large Language Models","reasoning tasks"],"filter_categories":{"ai_ml":["Reinforcement Learning","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Passk":3.0,"RLVR":2.0,"the base model":2.0,"arXiv251008325v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement Learning":1.0,"Verifiable Rewards":1.0,"a powerful paradigm":1.0,"Large Language Models":1.0,"reasoning tasks":1.0}},"age_hours":2.7753113888888885,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8625,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8042,"joy":0.0294,"surprise":0.147,"sadness":0.0042,"fear":0.0035,"anger":0.0076,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new metric, Cover@tau, to evaluate the reasoning capabilities of large language models. While the research itself does not directly address climate change or sustainability, improved AI reasoning could potentially lead to more efficient resource allocation or the development of climate-friendly technologies in the future. The research is at a very early stage and lacks concrete deployment or measurable outcomes related to sustainability.","key_impact_metrics":["Fraction of problems solved with tau proportion of correct completions"],"technology_tags":["Reinforcement Learning","Large Language Models","AI Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:43:33.537890Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_be60c7b2533e","title":"LacAIDes: Generative AI","content":"arXiv:2510.08326v1 Announce Type: new Abstract: Lacquerware, a representative craft of Chinese intangible cultural heritage, is renowned for its layered aesthetics and durability but faces declining engagement. While prior human-computer interaction research has explored embedding interactive circuits to transform lacquerware into responsive artifacts, most studies have focused on fabrication techniques rather than supporting makers in creatively designing such interactions at a low threshold. To address this gap, we present LacAIDes, a Generative AI powered creativity-support tool built on a multi-agent workflow aligned with the double diamond model of design thinking. LacAIDes enables exploration and creation of culturally grounded interactive circuits without requiring prior technical expertise. We evaluated LacAIDes in a longitudinal workshop with 34 participants using a mixed-method approach. Results show that LacAIDes demonstrated high usability, enhanced creative engagement in craft making, and encouraged critical reflection on the role of Generative AI in digital craft practices. This work contributes to human-computer interaction by introducing a novel creativity-support tool and providing empirical insights into revitalizing traditional craft making through Generative AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08326","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.293757","language":"en","tags":["cshc","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Yaning Li, Yutong Chen, Yihan Hou, Chenyi Chen, Yihan Han, Jingxuan Han, Wenxi Dai, Youyou Li, Xinke Tang, Meng Li, Qi Dong, Hongwei Li","raw_content_length":1303,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1302,"language_detected":"en","key_concepts":{"key_phrases":["LacAIDes","Generative AI","arXiv251008326v1 Announce Type","new Abstract","Lacquerware","a representative craft","Chinese intangible cultural heritage","its layered aesthetics","durability","declining engagement"],"filter_categories":{"ai_ml":["LacAIDes"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LacAIDes":2.0,"Generative AI":2.0,"arXiv251008326v1 Announce Type":1.0,"new Abstract":1.0,"Lacquerware":1.0,"a representative craft":1.0,"Chinese intangible cultural heritage":1.0,"its layered aesthetics":1.0,"durability":1.0,"declining engagement":1.0}},"age_hours":2.775324706388889,"is_recent":true,"quality_score":0.7,"sentiment_score":9.7385,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9477,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7424,"joy":0.018,"surprise":0.0601,"sadness":0.1112,"fear":0.0248,"anger":0.0219,"disgust":0.0216},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a generative AI tool to support the design of interactive lacquerware. While it enhances creative engagement, it has minimal direct climate impact and is in the early stages of development (pilot workshop). The usability metrics from the workshop provide some evidence strength.","key_impact_metrics":["High usability","Enhanced creative engagement"],"technology_tags":["Generative AI","Human-Computer Interaction"],"sdg_alignment":[4,8,9,12],"analyzed_at":"2025-10-28T20:43:36.561825Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_550aa083233c","title":"Motion Exploration of Articulated Product Concepts in Interactive Sketching Environment","content":"arXiv:2510.08328v1 Announce Type: new Abstract: In the early stages of engineering design, it is essential to know how a product behaves, especially how it moves. As designers must keep adjusting the motion until it meets the intended requirements, this process is often repetitive and time-consuming. Although the physics behind these motions is usually based on simple equations, manually working through them can be tedious and inefficient. To ease this burden, some tasks are now handled by computers. One common method involves converting hand-drawn sketches into models using CAD or CAE software. However, this approach can be time- and resource-intensive. Additionally, product sketches are usually best understood only by the designers who created them. Others may struggle to interpret them correctly, relying heavily on intuition and prior experience. Since sketches are static, they fail to show how a product moves, limiting their usefulness. This paper presents a new approach that addresses these issues by digitising the natural act of sketching. It allows designers to create, simulate, and test the motion of mechanical concepts in a more interactive way. An application was developed to evaluate this method, focusing on user satisfaction and mental workload during a design task. The results showed a 77% reduction in cognitive effort compared to traditional methods, with users reporting high satisfaction. Future work will focus on expanding this approach from 2D (planar) to full 3D (spatial) design environments, enabling more complex product concept development.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08328","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.294165","language":"en","tags":["cshc","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Kalyan Ramana Gattoz, Prasad S. Onkar","raw_content_length":1587,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["CAD","CAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1586,"language_detected":"en","key_concepts":{"key_phrases":["Motion Exploration","Articulated Product Concepts","Interactive Sketching Environment","arXiv251008328v1 Announce Type","new Abstract","the early stages","engineering design","a product","designers","the motion"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Motion Exploration":2.0,"Articulated Product Concepts":2.0,"Interactive Sketching Environment":2.0,"arXiv251008328v1 Announce Type":1.0,"new Abstract":1.0,"the early stages":1.0,"engineering design":1.0,"a product":1.0,"designers":1.0,"the motion":1.0}},"age_hours":2.775339872777778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8769,"joy":0.0069,"surprise":0.0496,"sadness":0.0228,"fear":0.0076,"anger":0.0205,"disgust":0.0157},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new interactive sketching environment for mechanical design, showing a 77% reduction in cognitive effort compared to traditional methods. This could lead to more efficient design of sustainable products, but it is still in the early stages of development with no deployed units. The impact on climate is indirect and theoretical at this stage.","key_impact_metrics":["77% reduction in cognitive effort"],"technology_tags":["interactive sketching","mechanical design","CAD/CAE"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:43:39.096173Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_64bd892d25b8","title":"AutoRed: A Free","content":"arXiv:2510.08329v1 Announce Type: new Abstract: The safety of Large Language Models (LLMs) is crucial for the development of trustworthy AI applications. Existing red teaming methods often rely on seed instructions, which limits the semantic diversity of the synthesized adversarial prompts. We propose AutoRed, a free-form adversarial prompt generation framework that removes the need for seed instructions. AutoRed operates in two stages: (1) persona-guided adversarial instruction generation, and (2) a reflection loop to iteratively refine low-quality prompts. To improve efficiency, we introduce a verifier to assess prompt harmfulness without querying the target models. Using AutoRed, we build two red teaming datasets -- AutoRed-Medium and AutoRed-Hard -- and evaluate eight state-of-the-art LLMs. AutoRed achieves higher attack success rates and better generalization than existing baselines. Our results highlight the limitations of seed-based approaches and demonstrate the potential of free-form red teaming for LLM safety evaluation. We will open source our datasets in the near future.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08329","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.294565","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Muxi Diao, Yutao Mou, Keqing He, Hanbo Song, Lulu Zhao, Shikun Zhang, Wei Ye, Kongming Liang, Zhanyu Ma","raw_content_length":1100,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","AutoRed"],"persons":[],"locations":[],"monetary":[]},"char_count":1099,"language_detected":"en","key_concepts":{"key_phrases":["AutoRed","seed instructions","arXiv251008329v1 Announce Type","new Abstract","The safety","Large Language Models","LLMs","the development","trustworthy AI applications","Existing red teaming methods"],"filter_categories":{"ai_ml":["Large Language Models"],"engineering":["the development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AutoRed":4.0,"seed instructions":2.0,"arXiv251008329v1 Announce Type":1.0,"new Abstract":1.0,"The safety":1.0,"Large Language Models":1.0,"LLMs":1.0,"the development":1.0,"trustworthy AI applications":1.0,"Existing red teaming methods":1.0}},"age_hours":2.7753544058333333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9425,"joy":0.0192,"surprise":0.0175,"sadness":0.0026,"fear":0.0044,"anger":0.0086,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new method for red teaming LLMs, which could indirectly contribute to sustainability by improving the safety and trustworthiness of AI systems used in climate modeling or other sustainability applications. However, there are no concrete actions or measurable outcomes related to direct GHG emissions reduction, carbon sequestration, or climate adaptation. The article mentions attack success rates as a metric.","key_impact_metrics":["Attack success rate","Generalization of adversarial prompts"],"technology_tags":["Large Language Models","AI Safety","Red Teaming"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:43:42.479387Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cd95db2db873","title":"What Makes a Visualization Complex?","content":"arXiv:2510.08332v1 Announce Type: new Abstract: We investigate the perceived visual complexity (VC) in data visualizations using objective image-based metrics. We collected VC scores through a large-scale crowdsourcing experiment involving 349 participants and 1,800 visualization images. We then examined how these scores align with 12 image-based metrics spanning information-theoretic, clutter, color, and our two object-based metrics. Our results show that both low-level image properties and the high-level elements affect perceived VC in visualization images; The number of corners and distinct colors are robust metrics across visualizations. Second, feature congestion, an information-theoretic metric capturing statistical patterns in color and texture, is the strongest predictor of perceived complexity in visualizations rich in the same stimuli; edge density effectively explains VC in node-link diagrams. Additionally, we observe a bell-curve effect for text annotations: increasing text-to-ink ratio (TiR) initially reduces complexity, reaching an optimal point, beyond which further text increases perceived complexity. Our quantification pipeline is also interpretable, enabling metric-based explanations, grounded in the VisComplexity2K dataset, bridging computational metrics with human perceptual responses. osf.io/5xe8a has the preregistration and osf.io/bdet6 has the VisComplexity2K dataset, source code, and all Apdx. and figures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08332","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.294959","language":"en","tags":["cshc","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Mengdi Chu, Zefeng Qiu, Meng Ling, Shuning Jiang, Robert S. Laramee, Michael Sedlmair, Jian Chen","raw_content_length":1454,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1453,"language_detected":"en","key_concepts":{"key_phrases":["What","a Visualization Complex","arXiv251008332v1 Announce Type","new Abstract","the perceived visual complexity","data visualizations","objective image-based metrics","VC scores","a large-scale crowdsourcing experiment","349 participants"],"filter_categories":{"business_innovation":["VC scores"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"a Visualization Complex":2.0,"arXiv251008332v1 Announce Type":1.0,"new Abstract":1.0,"the perceived visual complexity":1.0,"data visualizations":1.0,"objective image-based metrics":1.0,"VC scores":1.0,"a large-scale crowdsourcing experiment":1.0,"349 participants":1.0}},"age_hours":2.775369337777778,"is_recent":true,"quality_score":0.7,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8834,"joy":0.0085,"surprise":0.0571,"sadness":0.009,"fear":0.0053,"anger":0.0195,"disgust":0.0172},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on understanding and quantifying visual complexity in data visualizations. While it doesn't directly address climate change, it could indirectly support sustainability efforts by improving the communication and understanding of complex environmental data, leading to better decision-making. The research is in the early stages, focusing on data collection and analysis, with no immediate deployment or economic viability.","key_impact_metrics":["VC scores from 349 participants","1,800 visualization images"],"technology_tags":["data visualization","image-based metrics"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-28T20:43:45.304223Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8be8b333ec17","title":"New Machine Learning Approaches for Intrusion Detection in ADS","content":"arXiv:2510.08333v1 Announce Type: new Abstract: With the growing reliance on the vulnerable Automatic Dependent Surveillance-Broadcast (ADS-B) protocol in air traffic management (ATM), ensuring security is critical. This study investigates emerging machine learning models and training strategies to improve AI-based intrusion detection systems (IDS) for ADS-B. Focusing on ground-based ATM systems, we evaluate two deep learning IDS implementations: one using a transformer encoder and the other an extended Long Short-Term Memory (xLSTM) network, marking the first xLSTM-based IDS for ADS-B. A transfer learning strategy was employed, involving pre-training on benign ADS-B messages and fine-tuning with labeled data containing instances of tampered messages. Results show this approach outperforms existing methods, particularly in identifying subtle attacks that progressively undermine situational awareness. The xLSTM-based IDS achieves an F1-score of 98.9%, surpassing the transformer-based model at 94.3%. Tests on unseen attacks validated the generalization ability of the xLSTM model. Inference latency analysis shows that the 7.26-second delay introduced by the xLSTM-based IDS fits within the Secondary Surveillance Radar (SSR) refresh interval (5-12 s), although it may be restrictive for time-critical operations. While the transformer-based IDS achieves a 2.1-second latency, it does so at the cost of lower detection performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08333","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.295353","language":"en","tags":["computer-science","cslg","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Mika\\\"ela Ngambo\\'e, Jean-Simon Marrocco, Jean-Yves Ouattara, Jos\\'e M. Fernandez, Gabriela Nicolescu","raw_content_length":1446,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["ADS arXiv:2510.08333v1","New Machine Learning Approaches for Intrusion Detection","IDS","ADS","ATM","Automatic Dependent Surveillance-Broadcast"],"persons":[],"locations":[],"monetary":[]},"char_count":1445,"language_detected":"en","key_concepts":{"key_phrases":["New Machine Learning Approaches","Intrusion Detection","ADS","arXiv251008333v1 Announce Type","new Abstract","the growing reliance","ADS-B","air traffic management","ATM","security"],"filter_categories":{"ai_ml":["New Machine Learning Approaches"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"New Machine Learning Approaches":2.0,"Intrusion Detection":2.0,"ADS":2.0,"arXiv251008333v1 Announce Type":1.0,"new Abstract":1.0,"the growing reliance":1.0,"ADS-B":1.0,"air traffic management":1.0,"ATM":1.0,"security":1.0}},"age_hours":2.775384366388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8731,"joy":0.0071,"surprise":0.0319,"sadness":0.0091,"fear":0.0528,"anger":0.0168,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on improving intrusion detection in air traffic management using machine learning. While enhanced air traffic safety indirectly supports sustainability by improving efficiency and reducing potential accidents, the direct climate impact is minimal. The research is credible, with quantified performance metrics (F1-score, latency) and peer-reviewed publication, but it's still in the early stages of development with no deployed units.","key_impact_metrics":["F1-score of 98.9%","7.26-second latency"],"technology_tags":["Machine Learning","Intrusion Detection Systems","ADS-B Security"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-28T20:43:48.255335Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_338a653c46c3","title":"Learning What's Missing: Attention Dispersion and EMA Stabilization in Length Generalization","content":"arXiv:2510.08341v1 Announce Type: new Abstract: We study length generalization in transformers through the set complement task, where a model must predict a uniform distribution over tokens absent from an input sequence -- an ability central to board-game style reasoning. Our main theoretical result establishes two statements. First, we prove tight bounds on embedding and value dimensions for single-layer attention-only transformers. Second, we show that if such a model achieves balanced logit displacement at lengths 1 and 2, then it must generalize to longer sequences, though with reduced precision. A mechanistic reading of the proof explains this limitation: as more tokens are attended to, softmax compresses logit displacements, eroding separation between valid and invalid outputs. Training dynamics also suggest a second obstacle: when many next tokens are possible, updates become noisy. We hypothesize that dropout can counteract the first effect and Exponential Moving Average (EMA) the second. We validate these hypotheses through random hyperparameter search on the set complement task, which confirms both mechanisms. We then test OthelloGPT, a GPT-1 style model trained on random Othello moves, and find that EMA again improves length generalization in this more complex setting.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08341","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.296132","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"P\\'al Zs\\'amboki, Benjamin Levi, David Ansel Josef Smith, Mitansh Kagalwala, Arlington Kell, Samuel Liechty, Cong Wang","raw_content_length":1301,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["EMA Stabilization"],"persons":[],"locations":[],"monetary":[]},"char_count":1300,"language_detected":"en","key_concepts":{"key_phrases":["What","Attention Dispersion","EMA Stabilization","Length Generalization","new Abstract","length generalization","transformers","the set complement task","a model","a uniform distribution"],"filter_categories":{"ai_ml":["transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Attention Dispersion":2.0,"EMA Stabilization":2.0,"Length Generalization":2.0,"new Abstract":1.0,"length generalization":1.0,"transformers":1.0,"the set complement task":1.0,"a model":1.0,"a uniform distribution":1.0}},"age_hours":2.7754146058333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9147,"joy":0.0227,"surprise":0.0255,"sadness":0.0033,"fear":0.007,"anger":0.0171,"disgust":0.0099},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores improving length generalization in transformers, which is currently theoretical. While the research is sound, it is in the very early stages and has no direct, measurable impact on sustainability at this time. The work is focused on improving AI model performance, but the application to climate or sustainability is not explicitly mentioned or demonstrated.","key_impact_metrics":[],"technology_tags":["transformers","machine learning","artificial intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:43:50.748266Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ec1e77c465da","title":"A Haskell to FHE Transpiler","content":"arXiv:2510.08343v1 Announce Type: new Abstract: Fully Homomorphic Encryption (FHE) enables the evaluation of programs directly on encrypted data. However, because only basic operations can be performed on ciphertexts, programs must be expressed as boolean or arithmetic circuits. This low-level repre- sentation makes implementing applications for FHE significantly more cumbersome than writing code in a high-level language. To reduce this burden, several transpilers have been developed that translate high-level code into circuit representations. In this work, we extend the range of high-level languages that can tar- get FHE by introducing a transpiler for Haskell, which converts Haskell programs into Boolean circuits suitable for homomorphic evaluation. Our second contribution is the automatic parallelization of these generated circuits. We implement an evaluator that executes gates in parallel by parallelizing each layer of the circuit. We demonstrate the effectiveness of our approach on two key applications: Private Information Retrieval (PIR) and the AES encryption standard. Prior work has parallelized AES encryption manually. We demonstrate that the automated method outperforms some but not all manual parallelizations of AES evaluations under FHE. We achieve an eval- uation time of 28 seconds for a parallel execution with 16 threads and an evaluation time of 8 seconds for a parallel execution with 100 threads","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08343","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.296549","language":"en","tags":["research","cscr","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Anne M\\\"uller, Mohd Kashif, Nico D\\\"ottling","raw_content_length":1435,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["FHE","Haskell","FHE Transpiler arXiv:2510.08343v1"],"persons":[],"locations":[],"monetary":[]},"char_count":1434,"language_detected":"en","key_concepts":{"key_phrases":["A Haskell","FHE Transpiler","FHE","programs","arXiv251008343v1 Announce Type","new Abstract","Fully Homomorphic Encryption","the evaluation","encrypted data","only basic operations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Haskell":2.0,"FHE Transpiler":2.0,"FHE":2.0,"programs":2.0,"arXiv251008343v1 Announce Type":1.0,"new Abstract":1.0,"Fully Homomorphic Encryption":1.0,"the evaluation":1.0,"encrypted data":1.0,"only basic operations":1.0}},"age_hours":2.7754297597222224,"is_recent":true,"quality_score":1.0,"sentiment_score":2.3859999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5228,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8759,"joy":0.0174,"surprise":0.0279,"sadness":0.0205,"fear":0.019,"anger":0.0224,"disgust":0.0168},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a transpiler for Haskell to FHE, enabling computation on encrypted data. While it shows automated parallelization outperforms some manual methods for AES encryption under FHE, the technology is still in early stages with no real-world deployment. The climate impact is indirect, potentially enabling more secure and private data processing for climate-related applications, but this is theoretical.","key_impact_metrics":["evaluation time of 28 seconds with 16 threads","evaluation time of 8 seconds with 100 threads"],"technology_tags":["Fully Homomorphic Encryption","Haskell transpiler","Boolean circuits"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:43:57.306615Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d141f86f1ac","title":"DeepEN: Personalized Enteral Nutrition for Critically Ill Patients using Deep Reinforcement Learning","content":"arXiv:2510.08350v1 Announce Type: new Abstract: We introduce DeepEN, a deep reinforcement learning (RL) framework for personalized enteral nutrition (EN) in critically ill patients. Trained offline on over 11,000 ICU patients from the MIMIC-IV database, DeepEN generates 4-hourly recommendations for caloric, protein, and fluid intake tailored to each patient's evolving physiology. The model integrates a curated, clinically informed state space with a custom reward function that balances short-term physiological and nutrition-related goals with long-term survival outcomes. Using a dueling double deep Q-network with conservative Q-learning regularization, DeepEN learns clinically realistic policies that align with high-value clinician actions while discouraging unsafe deviations. Across various qualitative and quantitative metrics, DeepEN outperforms clinician-derived and guideline-based policies, achieving a 3.7 $\\pm$ 0.17 percentage-point reduction in estimated mortality (18.8% vs 22.5%) and improvements in key nutritional biomarkers. These findings highlight the potential of safe, data-driven personalization of EN therapy to improve outcomes beyond traditional guideline- or heuristic-based approaches.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08350","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.296928","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Daniel Jason Tan, Jiayang Chen, Dilruk Perera, Kay Choong See, Mengling Feng","raw_content_length":1221,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["ICU"],"persons":[],"locations":[],"monetary":[]},"char_count":1220,"language_detected":"en","key_concepts":{"key_phrases":["Personalized Enteral Nutrition","Critically Ill Patients","Deep Reinforcement Learning","arXiv251008350v1","Announce Type","new Abstract","DeepEN","a deep reinforcement learning RL framework","personalized enteral nutrition","critically ill patients"],"filter_categories":{"ai_ml":["Deep Reinforcement Learning","a deep reinforcement learning RL framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Personalized Enteral Nutrition":2.0,"Critically Ill Patients":2.0,"Deep Reinforcement Learning":2.0,"arXiv251008350v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"DeepEN":1.0,"a deep reinforcement learning RL framework":1.0,"personalized enteral nutrition":1.0,"critically ill patients":1.0}},"age_hours":2.775445010277778,"is_recent":true,"quality_score":1.0,"sentiment_score":1.3655,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7269,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9317,"joy":0.0071,"surprise":0.028,"sadness":0.0053,"fear":0.0082,"anger":0.0114,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a deep reinforcement learning framework (DeepEN) for personalized enteral nutrition. It is trained on a large dataset and shows promising results in reducing estimated mortality compared to clinician-derived policies. However, it is still in the applied research stage with no real-world deployment yet, hence the low deployment readiness score.","key_impact_metrics":["3.7 percentage-point reduction in estimated mortality","18.8% vs 22.5% mortality rate"],"technology_tags":["deep reinforcement learning","enteral nutrition","personalized medicine"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:44:00.482419Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_28a0fbcbfea7","title":"Evaluating Small Vision","content":"arXiv:2510.08352v1 Announce Type: new Abstract: Vision-Language Models (VLMs) are becoming increasingly powerful, demonstrating strong performance on a variety of tasks that require both visual and textual understanding. Their strong generalisation abilities make them a promising component for automated driving systems, which must handle unexpected corner cases. However, to be trusted in such safety-critical applications, a model must first possess a reliable perception system. Moreover, since critical objects and agents in traffic scenes are often at a distance, we require systems that are not \"shortsighted\", i.e., systems with strong perception capabilities at both close (up to 20 meters) and long (30+ meters) range. With this in mind, we introduce Distance-Annotated Traffic Perception Question Answering (DTPQA), the first Visual Question Answering (VQA) benchmark focused solely on perception-based questions in traffic scenes, enriched with distance annotations. By excluding questions that require reasoning, we ensure that model performance reflects perception capabilities alone. Since automated driving hardware has limited processing power and cannot support large VLMs, our study centers on smaller VLMs. More specifically, we evaluate several state-of-the-art (SOTA) small VLMs on DTPQA and show that, despite the simplicity of the questions, these models significantly underperform compared to humans (~60% average accuracy for the best-performing small VLM versus ~85% human performance). However, it is important to note that the human sample size was relatively small, which imposes statistical limitations. We also identify specific perception tasks, such as distinguishing left from right, that remain particularly challenging for these models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08352","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.297726","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Nikos Theodoridis, Tim Brophy, Reenu Mohandas, Ganesh Sistu, Fiachra Collins, Anthony Scanlan, Ciaran Eising","raw_content_length":1774,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["Distance-Annotated Traffic Perception Question Answering","Vision-Language Models","VQA"],"persons":[],"locations":[],"monetary":[]},"char_count":1773,"language_detected":"en","key_concepts":{"key_phrases":["Small Vision","Announce Type","new Abstract","Vision-Language Models","VLMs","strong performance","a variety","tasks","both visual and textual understanding","Their strong generalisation abilities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Small Vision":2.0,"Announce Type":1.0,"new Abstract":1.0,"Vision-Language Models":1.0,"VLMs":1.0,"strong performance":1.0,"a variety":1.0,"tasks":1.0,"both visual and textual understanding":1.0,"Their strong generalisation abilities":1.0}},"age_hours":2.7754745175,"is_recent":true,"quality_score":1.0,"sentiment_score":9.7655,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9531,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8772,"joy":0.0323,"surprise":0.0387,"sadness":0.003,"fear":0.0346,"anger":0.0092,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark for evaluating the perception capabilities of small vision-language models (VLMs) in traffic scenes. While the research aims to improve automated driving systems, which could indirectly reduce emissions by optimizing traffic flow, it's currently in the applied research stage with no deployed technology or measured emissions reductions. The study provides accuracy metrics (~60% for best VLM vs. ~85% human) but lacks economic viability or deployment readiness data.","key_impact_metrics":["~60% average accuracy for the best-performing small VLM","~85% human performance"],"technology_tags":["Vision-Language Models","Automated Driving Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:44:03.409514Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53fcc3293af8","title":"Underground Power Distribution System Restoration Using Inverter Based Resources","content":"arXiv:2510.08356v1 Announce Type: new Abstract: Underground power distribution systems (PDSs) are increasingly deployed in urban areas. The integration of smart devices including smart switchgears, pad-mounted distribution transformers and inverter-based resources (IBRs) enhance system resilience, however simultaneously introducing unique challenges. The challenges include inrush currents caused by trapped charges in underground cables, ferroresonance in distribution transformers during energization, and three-phase load imbalance resulting from single-phase underground laterals. To address these issues, this paper proposes an underground PDS restoration framework using IBRs. Firstly, an underground cable energization model is developed to quantify inrush current by analyzing voltage differences across both switchgear terminals. Secondly, a distribution transformer energization model is proposed to evaluate ferroresonance using Q-factor constraints based on underground cable capacitance and damping resistance. Thirdly, a phase-swapping model is proposed to improve load balancing by dynamically reassigning lateral-phase connections through smart switchgears. The proposed models are further integrated into a mixed-integer nonlinear programming (MINLP) formulation to maximize the total weighted restored load while constraining inrush currents, ferroresonance, and phase imbalance. To address the nonlinearity induced by impedance matrix reordering during phase swapping, a permutation-based linearization technique is proposed. Finally, case studies on an underground PDS established based on IEEE 123-Node Test Feeder validate the effectiveness of the proposed strategy in improving uderground PDS restoration performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08356","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.298509","language":"en","tags":["cssy","computer-science","eesssy","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Wenlong Shi, Hongyi Li, Zhaoyu Wang","raw_content_length":1743,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["Underground Power Distribution System Restoration Using Inverter Based Resources arXiv:2510.08356v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1742,"language_detected":"en","key_concepts":{"key_phrases":["Underground Power Distribution System Restoration","Inverter Based Resources","arXiv251008356v1 Announce Type","new Abstract","Underground power distribution systems","PDSs","urban areas","The integration","smart devices","smart switchgears"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Underground Power Distribution System Restoration":2.0,"Inverter Based Resources":2.0,"arXiv251008356v1 Announce Type":1.0,"new Abstract":1.0,"Underground power distribution systems":1.0,"PDSs":1.0,"urban areas":1.0,"The integration":1.0,"smart devices":1.0,"smart switchgears":1.0}},"age_hours":2.775504305277778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9001,"joy":0.0129,"surprise":0.0575,"sadness":0.0042,"fear":0.0117,"anger":0.0099,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper proposes a framework for restoring underground power distribution systems using IBRs, which can potentially reduce grid instability and improve the integration of renewable energy sources. The models are validated using the IEEE 123-Node Test Feeder, providing some evidence of effectiveness. However, it's still in the research phase with no real-world deployment data.","key_impact_metrics":["Total weighted restored load maximized","Inrush currents constrained"],"technology_tags":["Inverter Based Resources","Smart Switchgears","Underground Power Distribution Systems"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-28T20:44:06.112853Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae3bfd6096a9","title":"Learning to Mitigate Post","content":"arXiv:2510.08357v1 Announce Type: new Abstract: Electrification and decarbonization are transforming power system demand and recovery dynamics, yet their implications for post-outage load surges remain poorly understood. Here we analyze a metropolitan-scale heterogeneous dataset for Indianapolis comprising 30,046 feeder-level outages between 2020 and 2024, linked to smart meters and submetering, to quantify the causal impact of electric vehicles (EVs), heat pumps (HPs) and distributed energy resources (DERs) on restoration surges. Statistical analysis and causal forest inference demonstrate that rising penetrations of all three assets significantly increase surge ratios, with effects strongly modulated by restoration timing, outage duration and weather conditions. We develop a component-aware multi-task Transformer estimator that disaggregates EV, HP and DER contributions, and apply it to project historical outages under counterfactual 2035 adoption pathways. In a policy-aligned pathway, evening restorations emerge as the binding reliability constraint, with exceedance probabilities of 0.057 when 30\\% of system load is restored within the first 15 minutes. Mitigation measures, probabilistic EV restarts, short thermostat offsets and accelerated DER reconnection, reduce exceedance to 0.019 and eliminate it entirely when 20\\% or less of system load is restored. These results demonstrate that transition-era surges are asset-driven and causally linked to electrification and decarbonization, but can be effectively managed through integrated operational strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08357","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.298902","language":"en","tags":["cssy","computer-science","eesssy","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Wenlong Shi, Dingwei Wang, Liming Liu, Zhaoyu Wang","raw_content_length":1585,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["Transformer","DER"],"persons":["smart meters"],"locations":["Indianapolis"],"monetary":[]},"char_count":1584,"language_detected":"en","key_concepts":{"key_phrases":["Mitigate Post","arXiv251008357v1 Announce Type","new Abstract","Electrification","decarbonization","power system demand","recovery dynamics","their implications","post-outage load surges","a metropolitan-scale heterogeneous dataset"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mitigate Post":2.0,"arXiv251008357v1 Announce Type":1.0,"new Abstract":1.0,"Electrification":1.0,"decarbonization":1.0,"power system demand":1.0,"recovery dynamics":1.0,"their implications":1.0,"post-outage load surges":1.0,"a metropolitan-scale heterogeneous dataset":1.0}},"age_hours":2.775519176388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8854,"joy":0.0073,"surprise":0.0438,"sadness":0.0121,"fear":0.0259,"anger":0.0186,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes a real-world dataset of 30,046 feeder-level outages linked to smart meters to quantify the impact of EVs, HPs, and DERs on restoration surges. It uses statistical analysis and causal forest inference to demonstrate that these assets increase surge ratios. While it projects future scenarios, the core of the research is based on historical data and causal inference, making it applied research, but the lack of deployed mitigation strategies impacts deployment readiness.","key_impact_metrics":["exceedance probabilities of 0.057 with 30% system load restored in 15 minutes","exceedance reduced to 0.019 with mitigation measures"],"technology_tags":["electric vehicles","heat pumps","distributed energy resources"],"sdg_alignment":[7,9,11],"analyzed_at":"2025-10-28T20:44:09.787266Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4d6e5343057a","title":"Hyperspectral data augmentation with transformer","content":"arXiv:2510.08363v1 Announce Type: new Abstract: The introduction of new generation hyperspectral satellite sensors, combined with advancements in deep learning methodologies, has significantly enhanced the ability to discriminate detailed land-cover classes at medium-large scales. However, a significant challenge in deep learning methods is the risk of overfitting when training networks with small labeled datasets. In this work, we propose a data augmentation technique that leverages a guided diffusion model. To effectively train the model with a limited number of labeled samples and to capture complex patterns in the data, we implement a lightweight transformer network. Additionally, we introduce a modified weighted loss function and an optimized cosine variance scheduler, which facilitate fast and effective training on small datasets. We evaluate the effectiveness of the proposed method on a forest classification task with 10 different forest types using hyperspectral images acquired by the PRISMA satellite. The results demonstrate that the proposed method outperforms other data augmentation techniques in both average and weighted average accuracy. The effectiveness of the method is further highlighted by the stable training behavior of the model, which addresses a common limitation in the practical application of deep generative models for data augmentation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08363","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.299657","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Mattia Ferrari, Lorenzo Bruzzone","raw_content_length":1384,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1383,"language_detected":"en","key_concepts":{"key_phrases":["Hyperspectral data augmentation","transformer","Announce Type","new Abstract","The introduction","new generation hyperspectral satellite sensors","advancements","deep learning methodologies","the ability","detailed land-cover classes"],"filter_categories":{"ai_ml":["transformer","deep learning methodologies"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hyperspectral data augmentation":2.0,"transformer":2.0,"Announce Type":1.0,"new Abstract":1.0,"The introduction":1.0,"new generation hyperspectral satellite sensors":1.0,"advancements":1.0,"deep learning methodologies":1.0,"the ability":1.0,"detailed land-cover classes":1.0}},"age_hours":2.7755465247222224,"is_recent":true,"quality_score":0.7,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8549,"joy":0.0076,"surprise":0.0271,"sadness":0.006,"fear":0.0741,"anger":0.0194,"disgust":0.0109},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a data augmentation technique for hyperspectral image analysis, specifically for forest classification. The method is evaluated on PRISMA satellite data, showing improved accuracy compared to other techniques. However, it is still in the research phase with no clear path to economic viability or large-scale deployment, hence the lower scores for those dimensions.","key_impact_metrics":["average accuracy","weighted average accuracy"],"technology_tags":["hyperspectral imaging","data augmentation","deep learning","transformer networks"],"sdg_alignment":[15],"analyzed_at":"2025-10-28T20:44:12.721357Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6b6b2ac1b466","title":"Exponential Error Bounds for Information Bottleneck Source Coding Problems","content":"arXiv:2510.08364v1 Announce Type: new Abstract: We study the information bottleneck (IB) source coding problem, also known as remote lossy source coding under logarithmic loss. Based on a rate-limited description of noisy observations, the receiver produces a soft estimate for the remote source, i.e., a probability distribution, evaluated under the logarithmic loss. We focus on the excess distortion probability of IB source coding and investigate how fast it converges to 0 or 1, depending on whether the rate is above or below the rate-distortion function. The latter case is also known as the exponential strong converse. We establish both the exact error exponent and the exact strong converse exponent for IB source coding by deriving matching upper and lower exponential bounds. The obtained exponents involve optimizations over auxiliary random variables. The matching converse bounds are derived through non-trivial extensions of existing sphere packing and single-letterization techniques, which we adapt to incorporate auxiliary random variables. In the second part of this paper, we establish a code-level connection between IB source coding and source coding with a helper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem. We show that every code for the WAK problem is a code for IB source coding. This requires noticing that IB source coding, under the excess distortion criterion, is equivalent to source coding with a helper available at both the transmitter and the receiver; the latter in turn relates to the WAK problem. Through this connection, we re-derive the best known sphere packing exponent of the WAK problem, and provide it with an operational interpretation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08364","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.300065","language":"en","tags":["mathit","computer-science","preprints","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":257,"author":"Han Wu, Hamdi Joudeh","raw_content_length":1701,"priority":7,"update_frequency":1,"reading_time_minutes":1.285,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1698,"language_detected":"en","key_concepts":{"key_phrases":["Exponential Error Bounds","Information Bottleneck Source Coding Problems","arXiv251008364v1 Announce Type","new Abstract","the information bottleneck","IB source coding problem","remote lossy source","logarithmic loss","a rate-limited description","noisy observations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Exponential Error Bounds":2.0,"Information Bottleneck Source Coding Problems":2.0,"arXiv251008364v1 Announce Type":1.0,"new Abstract":1.0,"the information bottleneck":1.0,"IB source coding problem":1.0,"remote lossy source":1.0,"logarithmic loss":1.0,"a rate-limited description":1.0,"noisy observations":1.0}},"age_hours":2.7755619647222223,"is_recent":true,"quality_score":0.7,"sentiment_score":0.363,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9274,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8676,"joy":0.0047,"surprise":0.0602,"sadness":0.0144,"fear":0.017,"anger":0.0206,"disgust":0.0156},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents theoretical research on information bottleneck source coding, focusing on error bounds and connections to other coding problems. While the research is technically sound and peer-reviewed, it is at a very early stage (basic research) and lacks concrete actions or measurable outcomes related to sustainability. The potential climate impact is minimal at this stage, as it's theoretical work without deployment.","key_impact_metrics":[],"technology_tags":["information theory","source coding"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:15.108470Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03560149a634","title":"On the Relationship Between the Choice of Representation and In","content":"arXiv:2510.08372v1 Announce Type: new Abstract: In-context learning (ICL) is the ability of a large language model (LLM) to learn a new task from a few demonstrations presented as part of the context. Past studies have attributed a large portion of the success of ICL to the way these in-context demonstrations are represented, particularly to how labels are represented in classification tasks. On the other hand, observations of the learning capacity of ICL (i.e., the extent to which more in-context demonstrations can lead to higher performance) have been mixed, and ICL is often thought to occur only under specific conditions. The interaction between these two aspects in ICL, representation and learning, has not been studied in depth until now. We hypothesize that they are largely independent of one another, such that the representation of demonstrations determines the baseline accuracy of ICL, while learning from additional demonstrations improves only on top of this baseline. We validate this hypothesis by developing an optimization algorithm that can enumerate a spectrum of possible label sets (representations) varying in semantic relevance. We then perform ICL with varying numbers of in-context demonstrations for each of these label sets. We observed that learning happens regardless of the quality of the label set itself, although its efficiency, measured by the slope of improvement over in-context demonstrations, is conditioned on both the label set quality and the parameter count of the underlying language model. Despite the emergence of learning, the relative quality (accuracy) of the choice of a label set (representation) is largely maintained throughout learning, confirming our hypothesis and implying their orthogonality. Our work reveals a previously underexplored aspect of ICL: the independent effects of learning from demonstrations and their representations on ICL performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08372","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.301663","language":"en","tags":["cscl","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":285,"author":"Ioana Marinescu, Kyunghyun Cho, Eric Karl Oermann","raw_content_length":1920,"priority":7,"update_frequency":1,"reading_time_minutes":1.425,"robust_parsing_used":true,"entities":{"organizations":["ICL"],"persons":[],"locations":[],"monetary":[]},"char_count":1919,"language_detected":"en","key_concepts":{"key_phrases":["ICL","the Relationship","the Choice","Representation","Announce Type","new Abstract","In-context learning","the ability","a large language model","LLM"],"filter_categories":{"ai_ml":["a large language model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ICL":3.0,"the Relationship":2.0,"the Choice":2.0,"Representation":2.0,"Announce Type":1.0,"new Abstract":1.0,"In-context learning":1.0,"the ability":1.0,"a large language model":1.0,"LLM":1.0}},"age_hours":2.7756226108333335,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2405,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8481,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8722,"joy":0.0189,"surprise":0.0556,"sadness":0.0073,"fear":0.0062,"anger":0.0176,"disgust":0.022},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents research on in-context learning (ICL) in large language models, specifically focusing on the relationship between representation and learning. While the research is technically credible and innovative, it is at a very early stage and does not have direct, measurable outcomes related to climate impact or sustainability. The research is theoretical and does not involve deployed technology or real-world data related to climate change.","key_impact_metrics":["Accuracy of ICL with varying label sets","Efficiency of learning over in-context demonstrations"],"technology_tags":["Large Language Models","In-Context Learning","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:17.932511Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0ecbc95e4161","title":"Contrastive Self","content":"arXiv:2510.08374v1 Announce Type: new Abstract: While contrastive learning (CL) shows considerable promise in self-supervised representation learning, its deployment on resource-constrained devices remains largely underexplored. The substantial computational demands required for training conventional CL frameworks pose a set of challenges, particularly in terms of energy consumption, data availability, and memory usage. We conduct an evaluation of four widely used CL frameworks: SimCLR, MoCo, SimSiam, and Barlow Twins. We focus on the practical feasibility of these CL frameworks for edge and fog deployment, and introduce a systematic benchmarking strategy that includes energy profiling and reduced training data conditions. Our findings reveal that SimCLR, contrary to its perceived computational cost, demonstrates the lowest energy consumption across various data regimes. Finally, we also extend our analysis by evaluating lightweight neural architectures when paired with CL frameworks. Our study aims to provide insights into the resource implications of deploying CL in edge/fog environments with limited processing capabilities and opens several research directions for its future optimization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08374","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.302155","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Fernanda Fam\\'a, Roberto Pereira, Charalampos Kalalas, Paolo Dini, Lorena Qendro, Fahim Kawsar, Mohammad Malekzadeh","raw_content_length":1211,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["SimSiam","MoCo"],"persons":["Contrastive Self arXiv:2510.08374v1","Barlow Twins"],"locations":[],"monetary":[]},"char_count":1210,"language_detected":"en","key_concepts":{"key_phrases":["Contrastive Self","arXiv251008374v1","Announce Type","new Abstract","contrastive learning","considerable promise","self-supervised representation learning","its deployment","resource-constrained devices","The substantial computational demands"],"filter_categories":{"ai_ml":["resource-constrained devices"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contrastive Self":2.0,"arXiv251008374v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"contrastive learning":1.0,"considerable promise":1.0,"self-supervised representation learning":1.0,"its deployment":1.0,"resource-constrained devices":1.0,"The substantial computational demands":1.0}},"age_hours":2.775636738611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6997,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9134,"joy":0.0107,"surprise":0.034,"sadness":0.0146,"fear":0.0106,"anger":0.0116,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research benchmarks contrastive learning frameworks for edge/fog deployment, focusing on energy consumption. While it identifies SimCLR as having the lowest energy consumption, it's still in the research phase with no deployed units. The study provides energy profiling metrics but lacks real-world operational data.","key_impact_metrics":["Lowest energy consumption for SimCLR","Energy profiling across data regimes"],"technology_tags":["Contrastive Learning","Edge Computing","Energy Efficiency"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-28T20:44:20.925280Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7941b42c3740","title":"UniVideo: Unified Understanding, Generation, and Editing for Videos","content":"arXiv:2510.08377v1 Announce Type: new Abstract: Unified multimodal models have shown promising results in multimodal content generation and editing but remain largely limited to the image domain. In this work, we present UniVideo, a versatile framework that extends unified modeling to the video domain. UniVideo adopts a dual-stream design, combining a Multimodal Large Language Model (MLLM) for instruction understanding with a Multimodal DiT (MMDiT) for video generation. This design enables accurate interpretation of complex multimodal instructions while preserving visual consistency. Built on this architecture, UniVideo unifies diverse video generation and editing tasks under a single multimodal instruction paradigm and is jointly trained across them. Extensive experiments demonstrate that UniVideo matches or surpasses state-of-the-art task-specific baselines in text/image-to-video generation, in-context video generation and in-context video editing. Notably, the unified design of UniVideo enables two forms of generalization. First, UniVideo supports task composition, such as combining editing with style transfer, by integrating multiple capabilities within a single instruction. Second, even without explicit training on free-form video editing, UniVideo transfers its editing capability from large-scale image editing data to this setting, handling unseen instructions such as green-screening characters or changing materials within a video. Beyond these core capabilities, UniVideo also supports visual-prompt-based video generation, where the MLLM interprets visual prompts and guides the MMDiT during synthesis. To foster future research, we will release our model and code.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08377","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.302616","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Cong Wei, Quande Liu, Zixuan Ye, Qiulin Wang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhu Chen","raw_content_length":1698,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["Videos arXiv:2510.08377v1 Announce Type","UniVideo"],"persons":[],"locations":["generati"],"monetary":[]},"char_count":1697,"language_detected":"en","key_concepts":{"key_phrases":["UniVideo","Unified Understanding","Generation","Videos","arXiv251008377v1 Announce Type","new Abstract","Unified multimodal models","promising results","multimodal content generation","the image domain"],"filter_categories":{"ai_ml":["the image domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"UniVideo":4.0,"Unified Understanding":2.0,"Generation":2.0,"Videos":2.0,"arXiv251008377v1 Announce Type":1.0,"new Abstract":1.0,"Unified multimodal models":1.0,"promising results":1.0,"multimodal content generation":1.0,"the image domain":1.0}},"age_hours":2.775651600277778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.812,"joy":0.0841,"surprise":0.0767,"sadness":0.0056,"fear":0.0061,"anger":0.011,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":8,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for video generation and editing. While the technology itself doesn't directly address climate change, it could indirectly contribute to sustainability efforts by improving communication and education around environmental issues. The research is at an early stage, with no deployed units or measurable environmental outcomes.","key_impact_metrics":[],"technology_tags":["AI","Video Generation","Multimodal Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:23.505662Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2524c1efa2b2","title":"QAgent: A modular Search Agent with Interactive Query Understanding","content":"arXiv:2510.08383v1 Announce Type: new Abstract: Large language models (LLMs) excel at natural language tasks but are limited by their static parametric knowledge, especially in knowledge-intensive task. Retrieval-augmented generation (RAG) mitigates this by integrating external information. However, (1) traditional RAG struggles with complex query understanding, and (2) even search agents trained with reinforcement learning (RL), despite their promise, still face generalization and deployment challenges. To address these limitations, we propose QAgent, a unified agentic RAG framework that employs a search agent for adaptive retrieval. This agent optimizes its understanding of the query through interactive reasoning and retrieval. To facilitate real-world application, we focus on modular search agent for query understanding that are plug-and-play in complex systems. Secifically, the agent follows a multi-step decision process trained with RL to maximize retrieval quality and support accurate downstream answers. We further analyze the strengths and weaknesses of end-to-end RL and propose a strategy that focuses on effective retrieval, thereby enhancing generalization in LLM applications. Experiments show QAgent excels at QA and serves as a plug-and-play module for real-world deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08383","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.304167","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Yi Jiang, Lei Shen, Lujie Niu, Sendong Zhao, Wenbo Su, Bo Zheng","raw_content_length":1306,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["RAG","QAgent","Interactive Query Understanding"],"persons":["RAG","Announce Type"],"locations":[],"monetary":[]},"char_count":1305,"language_detected":"en","key_concepts":{"key_phrases":["QAgent","A modular Search Agent","Interactive Query Understanding","arXiv251008383v1 Announce Type","new Abstract","Large language models","LLMs","natural language tasks","their static parametric knowledge","knowledge-intensive task"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"QAgent":2.0,"A modular Search Agent":2.0,"Interactive Query Understanding":2.0,"arXiv251008383v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"natural language tasks":1.0,"their static parametric knowledge":1.0,"knowledge-intensive task":1.0}},"age_hours":2.775709485833333,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8449999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.431,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8814,"joy":0.0058,"surprise":0.0387,"sadness":0.028,"fear":0.0166,"anger":0.0156,"disgust":0.0139},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel approach to retrieval-augmented generation using a reinforcement learning trained search agent. While the experiments show promise, it is still in the early stages of development with no deployed units or real-world operational data. The potential climate impact is indirect, as improved information retrieval could lead to better decision-making in climate-related fields.","key_impact_metrics":["Retrieval quality","Accuracy of downstream answers"],"technology_tags":["Large Language Models","Reinforcement Learning","Retrieval-Augmented Generation"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-28T20:44:26.785247Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_45f0dd3e7e3d","title":"If Probable, Then Acceptable? Understanding Conditional Acceptability Judgments in Large Language Models","content":"arXiv:2510.08388v1 Announce Type: new Abstract: Conditional acceptability refers to how plausible a conditional statement is perceived to be. It plays an important role in communication and reasoning, as it influences how individuals interpret implications, assess arguments, and make decisions based on hypothetical scenarios. When humans evaluate how acceptable a conditional \"If A, then B\" is, their judgments are influenced by two main factors: the $\\textit{conditional probability}$ of $B$ given $A$, and the $\\textit{semantic relevance}$ of the antecedent $A$ given the consequent $B$ (i.e., whether $A$ meaningfully supports $B$). While prior work has examined how large language models (LLMs) draw inferences about conditional statements, it remains unclear how these models judge the $\\textit{acceptability}$ of such statements. To address this gap, we present a comprehensive study of LLMs' conditional acceptability judgments across different model families, sizes, and prompting strategies. Using linear mixed-effects models and ANOVA tests, we find that models are sensitive to both conditional probability and semantic relevance-though to varying degrees depending on architecture and prompting style. A comparison with human data reveals that while LLMs incorporate probabilistic and semantic cues, they do so less consistently than humans. Notably, larger models do not necessarily align more closely with human judgments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08388","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.304969","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Jasmin Orth, Philipp Mondorf, Barbara Plank","raw_content_length":1439,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":["$\\textit{conditional probability}$"]},"char_count":1438,"language_detected":"en","key_concepts":{"key_phrases":["If Probable Then Acceptable","Conditional Acceptability Judgments","Large Language Models","arXiv251008388v1 Announce Type","new Abstract","Conditional acceptability","a conditional statement","an important role","communication","reasoning"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"If Probable Then Acceptable":2.0,"Conditional Acceptability Judgments":2.0,"Large Language Models":2.0,"arXiv251008388v1 Announce Type":1.0,"new Abstract":1.0,"Conditional acceptability":1.0,"a conditional statement":1.0,"an important role":1.0,"communication":1.0,"reasoning":1.0}},"age_hours":2.775738767777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7845,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7985,"joy":0.0336,"surprise":0.0226,"sadness":0.0041,"fear":0.028,"anger":0.0463,"disgust":0.067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores how LLMs judge the acceptability of conditional statements, focusing on conditional probability and semantic relevance. While it's a study of AI reasoning, it doesn't directly translate into concrete climate action or measurable environmental outcomes. The research is at a basic research stage, with no deployment or direct impact on sustainability.","key_impact_metrics":[],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:29.167064Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_21128d8b15ca","title":"Revisiting Hallucination Detection with Effective Rank","content":"arXiv:2510.08389v1 Announce Type: new Abstract: Detecting hallucinations in large language models (LLMs) remains a fundamental challenge for their trustworthy deployment. Going beyond basic uncertainty-driven hallucination detection frameworks, we propose a simple yet powerful method that quantifies uncertainty by measuring the effective rank of hidden states derived from multiple model outputs and different layers. Grounded in the spectral analysis of representations, our approach provides interpretable insights into the model's internal reasoning process through semantic variations, while requiring no extra knowledge or additional modules, thus offering a combination of theoretical elegance and practical efficiency. Meanwhile, we theoretically demonstrate the necessity of quantifying uncertainty both internally (representations of a single response) and externally (different responses), providing a justification for using representations among different layers and responses from LLMs to detect hallucinations. Extensive experiments demonstrate that our method effectively detects hallucinations and generalizes robustly across various scenarios, contributing to a new paradigm of hallucination detection for LLM truthfulness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08389","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.305353","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Rui Wang, Zeming Wei, Guanzhang Yue, Meng Sun","raw_content_length":1243,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1242,"language_detected":"en","key_concepts":{"key_phrases":["Hallucination Detection","Effective Rank","arXiv251008389v1 Announce Type","new Abstract","hallucinations","large language models","LLMs","a fundamental challenge","their trustworthy deployment","a simple yet powerful method"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hallucination Detection":2.0,"Effective Rank":2.0,"arXiv251008389v1 Announce Type":1.0,"new Abstract":1.0,"hallucinations":1.0,"large language models":1.0,"LLMs":1.0,"a fundamental challenge":1.0,"their trustworthy deployment":1.0,"a simple yet powerful method":1.0}},"age_hours":2.775751893611111,"is_recent":true,"quality_score":0.7,"sentiment_score":9.4425,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8885,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.822,"joy":0.0196,"surprise":0.0251,"sadness":0.0044,"fear":0.1045,"anger":0.0151,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the trustworthiness of LLMs by detecting hallucinations, which is a theoretical advancement. While improved LLMs could indirectly support sustainability efforts by improving efficiency in various sectors, there are no concrete actions or measurable outcomes related to climate impact or other sustainability dimensions at this stage. The research is at a basic research stage with peer-reviewed validation, but lacks deployment or economic viability.","key_impact_metrics":[],"technology_tags":["Large Language Models","Hallucination Detection","Uncertainty Quantification"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:44:31.927091Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b64ce5c6bfed","title":"Robust Source","content":"arXiv:2510.08393v1 Announce Type: new Abstract: Recent studies have uncovered a new research line, namely source-free domain adaptation, which adapts a model to target domains without using the source data. Such a setting can address the concerns on data privacy and security issues of medical images. However, current source-free domain adaptation frameworks mainly focus on the pseudo label refinement for target data without the consideration of learning procedure. Indeed, a progressive learning process from source to target domain will benefit the knowledge transfer during model adaptation. To this end, we propose a curriculum-based framework, namely learning from curriculum (LFC), for source-free domain adaptation, which consists of easy-to-hard and source-to-target curricula. Concretely, the former curriculum enables the framework to start learning with `easy' samples and gradually tune the optimization direction of model adaption by increasing the sample difficulty. While, the latter can stablize the adaptation process, which ensures smooth transfer of the model from the source domain to the target. We evaluate the proposed source-free domain adaptation approach on the public cross-domain datasets for fundus segmentation and polyp segmentation. The extensive experimental results show that our framework surpasses the existing approaches and achieves a new state-of-the-art.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08393","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.305775","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Ziqi Zhang, Yuexiang Li, Yawen Huang, Nanjun He, Tao Xu, Liwei Lin, Yefeng Zheng, Shaoxin Li, Feiyue Huang","raw_content_length":1398,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["LFC"],"persons":[],"locations":[],"monetary":[]},"char_count":1397,"language_detected":"en","key_concepts":{"key_phrases":["Robust Source","arXiv251008393v1 Announce Type","new Abstract","Recent studies","a new research line","namely source-free domain adaptation","which","a model","domains","the source data"],"filter_categories":{"research_academic":["a new research line"],"ai_ml":["namely source-free domain adaptation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Source":2.0,"arXiv251008393v1 Announce Type":1.0,"new Abstract":1.0,"Recent studies":1.0,"a new research line":1.0,"namely source-free domain adaptation":1.0,"which":1.0,"a model":1.0,"domains":1.0,"the source data":1.0}},"age_hours":2.7757662569444443,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8995,"joy":0.0091,"surprise":0.0208,"sadness":0.0089,"fear":0.0266,"anger":0.0192,"disgust":0.0159},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel source-free domain adaptation framework for medical image segmentation. While the research shows improved performance on public datasets, it's still in the early stages of development with no deployed units or real-world impact demonstrated. The potential climate impact is indirect, related to improved resource utilization in medical imaging, but not directly quantified.","key_impact_metrics":["State-of-the-art performance on fundus segmentation","State-of-the-art performance on polyp segmentation"],"technology_tags":["Source-free domain adaptation","Medical image segmentation","Curriculum learning"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-28T20:44:34.727012Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d672ff118899","title":"FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture","content":"arXiv:2510.08396v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) is a widely used parameter-efficient fine-tuning method for foundation models, but it suffers from parameter interference, resulting in suboptimal performance. Although Mixture-of-Experts (MoE)-based LoRA variants show promise in mitigating intra-task correlations in single-task instruction tuning, they introduce additional router parameters and remain ineffective in multi-task model merging where inter-task interference arises. Inspired by the fly olfactory circuit, we propose FlyLoRA, an implicit MoE-based LoRA variant that introduces: (1) rank-wise expert activation in the up-projection matrix, and (2) an implicit router that unifies expert routing and down-projection, where a frozen sparse random projection matrix replaces the traditional dense trainable version. This design resolves the trade-off between intra-task decorrelation and computational efficiency by eliminating the need for an explicit router, while inherently mitigating inter-task interference due to the orthogonality property of random matrices. Extensive experiments across four domains -- general knowledge understanding, scientific question answering, mathematical reasoning, and code generation -- demonstrate consistent performance improvements over existing methods. Beyond empirical gains, FlyLoRA highlights how biological structures can inspire innovations in AI technologies. Code is available at https://github.com/gfyddha/FlyLoRA.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08396","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.306959","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Heming Zou, Yunliang Zang, Wutong Xu, Yao Zhu, Xiangyang Ji","raw_content_length":1501,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["LoRA","FlyLoRA","Implicit Rank-Wise Mixture arXiv:2510.08396v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1500,"language_detected":"en","key_concepts":{"key_phrases":["Task Decoupling","Parameter Efficiency","Implicit Rank-Wise Mixture","arXiv251008396v1 Announce Type","new Abstract","Low-Rank Adaptation","LoRA","a widely used parameter-efficient fine-tuning method","foundation models","parameter interference"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Task Decoupling":2.0,"Parameter Efficiency":2.0,"Implicit Rank-Wise Mixture":2.0,"arXiv251008396v1 Announce Type":1.0,"new Abstract":1.0,"Low-Rank Adaptation":1.0,"LoRA":1.0,"a widely used parameter-efficient fine-tuning method":1.0,"foundation models":1.0,"parameter interference":1.0}},"age_hours":2.775810493333333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.322,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0644,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9282,"joy":0.0075,"surprise":0.0197,"sadness":0.0117,"fear":0.0085,"anger":0.0149,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (FlyLoRA) for improving the efficiency of fine-tuning foundation models. While it demonstrates performance improvements across several domains, its direct impact on climate change is indirect, potentially reducing energy consumption in AI training. The research is at an early stage with no deployed units, but the claims are supported by experimental results and a publicly available code repository.","key_impact_metrics":["Performance improvements over existing methods"],"technology_tags":["Low-Rank Adaptation","Mixture-of-Experts","Parameter-efficient fine-tuning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:44:37.474352Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b876ee29d19d","title":"VideoVerse: How Far is Your T2V Generator from a World Model?","content":"arXiv:2510.08398v1 Announce Type: new Abstract: The recent rapid advancement of Text-to-Video (T2V) generation technologies, which are critical to build ``world models'', makes the existing benchmarks increasingly insufficient to evaluate state-of-the-art T2V models. First, current evaluation dimensions, such as per-frame aesthetic quality and temporal consistency, are no longer able to differentiate state-of-the-art T2V models. Second, event-level temporal causality, which not only distinguishes video from other modalities but also constitutes a crucial component of world models, is severely underexplored in existing benchmarks. Third, existing benchmarks lack a systematic assessment of world knowledge, which are essential capabilities for building world models. To address these issues, we introduce VideoVerse, a comprehensive benchmark that focuses on evaluating whether a T2V model could understand complex temporal causality and world knowledge in the real world. We collect representative videos across diverse domains (e.g., natural landscapes, sports, indoor scenes, science fiction, chemical and physical experiments) and extract their event-level descriptions with inherent temporal causality, which are then rewritten into text-to-video prompts by independent annotators. For each prompt, we design a suite of binary evaluation questions from the perspective of dynamic and static properties, with a total of ten carefully defined evaluation dimensions. In total, our VideoVerse comprises 300 carefully curated prompts, involving 815 events and 793 binary evaluation questions. Consequently, a human preference aligned QA-based evaluation pipeline is developed by using modern vision-language models. Finally, we perform a systematic evaluation of state-of-the-art open-source and closed-source T2V models on VideoVerse, providing in-depth analysis on how far the current T2V generators are from world models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08398","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.307371","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Zeqing Wang, Xinyu Wei, Bairui Li, Zhen Guo, Jinrui Zhang, Hongyang Wei, Keze Wang, Lei Zhang","raw_content_length":1932,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["VideoVerse"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1931,"language_detected":"en","key_concepts":{"key_phrases":["VideoVerse","Your T2V Generator","a World Model","which","the-art","arXiv251008398v1 Announce Type","new Abstract","The recent rapid advancement","Video","world models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"VideoVerse":2.0,"Your T2V Generator":2.0,"a World Model":2.0,"which":2.0,"the-art":2.0,"arXiv251008398v1 Announce Type":1.0,"new Abstract":1.0,"The recent rapid advancement":1.0,"Video":1.0,"world models":1.0}},"age_hours":2.775826091388889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7716,"joy":0.0049,"surprise":0.1149,"sadness":0.022,"fear":0.0244,"anger":0.0315,"disgust":0.0307},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new benchmark for evaluating text-to-video models, focusing on temporal causality and world knowledge. While the research aims to improve AI's understanding of the real world, it is currently in the applied research stage with no concrete deployment or measurable climate impact. The benchmark uses 300 prompts, 815 events, and 793 binary evaluation questions.","key_impact_metrics":["300 prompts","815 events"],"technology_tags":["Text-to-Video Generation","World Models","AI Evaluation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:44:40.356548Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9d480836880b","title":"Biology","content":"arXiv:2510.08407v1 Announce Type: new Abstract: The mechanosensory system of teeth is currently believed to partly rely on Odontoblast cells stimulation by fluid flow through a porosity network extending through dentin. Visualizing the smallest sub-microscopic porosity vessels therefore requires the highest achievable resolution from confocal fluorescence microscopy, the current gold standard. This considerably limits the extent of the field of view to very small sample regions. To overcome this limitation, we tested different deep learning (DL) super-resolution (SR) models to allow faster experimental acquisitions of lower resolution images and restore optimal image quality by post-processing. Three supervised 2D SR models (RCAN, pix2pix, FSRCNN) and one unsupervised (CycleGAN) were applied to a unique set of experimentally paired high- and low-resolution confocal images acquired with different sampling schemes, resulting in a pixel size increase of x2, x4, x8. Model performance was quantified using a broad set of similarity and distribution-based image quality assessment (IQA) metrics, which yielded inconsistent results that mostly contradicted our visual perception. This raises the question of the relevance of such generic metrics to efficiently target the specific structure of dental porosity. To resolve this conflicting information, the generated SR images were segmented taking into account the specific scales and morphology of the porosity network and analysed by comparing connected components. Additionally, the capacity of the SR models to preserve 3D porosity connectivity throughout the confocal image stacks was evaluated using graph analysis. This biology-driven assessment allowed a far better mechanistic interpretation of SR performance, highlighting differences in model sensitivity to weak intensity features and the impact of non-linearity in image generation, which explains the failure of standard IQA metrics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08407","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.308601","language":"en","tags":["q-bioto","computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":270,"author":"Lauren Anderson, Lucas Chatelain, Nicolas Tremblay, Kathryn Grandfield, David Rousseau, Aur\\'elien Gourrier","raw_content_length":1956,"priority":7,"update_frequency":1,"reading_time_minutes":1.35,"robust_parsing_used":true,"entities":{"organizations":["FSRCNN"],"persons":[],"locations":["Odontoblast"],"monetary":[]},"char_count":1955,"language_detected":"en","key_concepts":{"key_phrases":["Biology","arXiv251008407v1 Announce Type","new Abstract","The mechanosensory system","teeth","Odontoblast cells stimulation","fluid flow","a porosity network","dentin","the smallest sub-microscopic porosity vessels"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Biology":2.0,"arXiv251008407v1 Announce Type":1.0,"new Abstract":1.0,"The mechanosensory system":1.0,"teeth":1.0,"Odontoblast cells stimulation":1.0,"fluid flow":1.0,"a porosity network":1.0,"dentin":1.0,"the smallest sub-microscopic porosity vessels":1.0}},"age_hours":2.7758721575000003,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8241,"joy":0.0207,"surprise":0.1,"sadness":0.0099,"fear":0.0211,"anger":0.0119,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes research into improving image resolution using deep learning models for visualizing dental porosity. While the research is technically sound and uses metrics to quantify performance, it is in the early stages of development and has no immediate or direct impact on climate change or sustainability. The work is primarily focused on improving scientific understanding and methodology.","key_impact_metrics":["pixel size increase of x2, x4, x8","similarity and distribution-based image quality assessment (IQA) metrics"],"technology_tags":["deep learning","super-resolution imaging","confocal microscopy"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-28T20:44:43.478976Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e7ece3c167d0","title":"Compression for Coinductive Infinitary Rewriting: A Generic Approach, with Applications to Cut","content":"arXiv:2510.08420v1 Announce Type: new Abstract: Infinitary rewriting, i.e. rewriting featuring possibly infinite terms and sequences of reduction, is a convenient framework for describing the dynamics of non-terminating but productive rewriting systems. In its original definition based on metric convergence of ordinal-indexed sequences of rewriting steps, a highly desirable property of an infinitary rewriting system is Compression, i.e. the fact that rewriting sequences of arbitrary ordinal length can always be 'compressed' to equivalent sequences of length at most {\\omega}. Since then, the standard examples of infinitary rewriting systems have been given another equivalent presentation based on coinduction. In this work, we extend this presentation to the rewriting of arbitrary non-wellfounded derivations and we investigate compression in this setting. We design a generic proof of compression, relying on a characterisation factorising most of the proof and identifying the key property a compressible infinitary rewriting system should enjoy. As running examples, we discuss first-order rewriting and infinitary {\\lambda}-calculi. For the latter, compression can in particular be seen as a justification of its coinductive presentation in the literature. As a more advanced example, we also address compression of cut-elimination sequences in the non-wellfounded proof system {\\mu}MALL{\\infty} for multiplicative-additive linear logics with fixed points, which is a key lemma of several cut-elimination results for similar proof systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08420","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.309765","language":"en","tags":["research","cslo","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"R\\'emy Cerda, Alexis Saurin","raw_content_length":1557,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["Applications"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1552,"language_detected":"en","key_concepts":{"key_phrases":["Compression","Coinductive Infinitary Rewriting","A Generic Approach","Applications","arXiv251008420v1","Announce Type","new Abstract","Infinitary rewriting","terms","sequences"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Compression":3.0,"Coinductive Infinitary Rewriting":2.0,"A Generic Approach":2.0,"Applications":2.0,"arXiv251008420v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Infinitary rewriting":1.0,"terms":1.0,"sequences":1.0}},"age_hours":2.775916413611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7305,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7461,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7803,"joy":0.1454,"surprise":0.0408,"sadness":0.0031,"fear":0.0037,"anger":0.0149,"disgust":0.0119},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on theoretical computer science related to infinitary rewriting and compression, with applications to cut-elimination in linear logic. While the research is mathematically rigorous and potentially impactful in the field of logic and computation, it has no direct or measurable impact on climate change, sustainability, or social justice in its current form. The research is at a very early stage (basic research) and lacks concrete actions or measurable outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["infinitary rewriting","coinduction","cut-elimination"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:46.154725Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a37b95adca87","title":"Reinforcing Diffusion Models by Direct Group Preference Optimization","content":"arXiv:2510.08425v1 Announce Type: new Abstract: While reinforcement learning methods such as Group Relative Preference Optimization (GRPO) have significantly enhanced Large Language Models, adapting them to diffusion models remains challenging. In particular, GRPO demands a stochastic policy, yet the most cost-effective diffusion samplers are based on deterministic ODEs. Recent work addresses this issue by using inefficient SDE-based samplers to induce stochasticity, but this reliance on model-agnostic Gaussian noise leads to slow convergence. To resolve this conflict, we propose Direct Group Preference Optimization (DGPO), a new online RL algorithm that dispenses with the policy-gradient framework entirely. DGPO learns directly from group-level preferences, which utilize relative information of samples within groups. This design eliminates the need for inefficient stochastic policies, unlocking the use of efficient deterministic ODE samplers and faster training. Extensive results show that DGPO trains around 20 times faster than existing state-of-the-art methods and achieves superior performance on both in-domain and out-of-domain reward metrics. Code is available at https://github.com/Luo-Yihong/DGPO.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08425","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.310143","language":"en","tags":["computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Yihong Luo, Tianyang Hu, Jing Tang","raw_content_length":1223,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["GRPO","Group Relative Preference Optimization","Reinforcing Diffusion Models","Direct Group Preference Optimization arXiv:2510.08425v1 Announce Type","Direct Group Preference Optimization"],"persons":["Gaussian","DGPO","Large Language Models"],"locations":[],"monetary":[]},"char_count":1222,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Models","Direct Group Preference Optimization","GRPO","arXiv251008425v1 Announce Type","new Abstract","reinforcement learning methods","Group Relative Preference Optimization","Large Language Models","them","diffusion models"],"filter_categories":{"ai_ml":["reinforcement learning methods","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Models":2.0,"Direct Group Preference Optimization":2.0,"GRPO":2.0,"arXiv251008425v1 Announce Type":1.0,"new Abstract":1.0,"reinforcement learning methods":1.0,"Group Relative Preference Optimization":1.0,"Large Language Models":1.0,"them":1.0,"diffusion models":1.0}},"age_hours":2.775931206944444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8902,"joy":0.011,"surprise":0.0375,"sadness":0.0109,"fear":0.0123,"anger":0.0243,"disgust":0.0139},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new algorithm (DGPO) that improves the training speed of diffusion models, potentially leading to more efficient generation of images and other data. The concrete action is the development of a new algorithm and its validation through experiments, showing a 20x speed improvement. However, it's still in the research phase with no deployment.","key_impact_metrics":["20 times faster training"],"technology_tags":["Diffusion Models","Reinforcement Learning","Machine Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:44:48.851692Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d4a99d4eccad","title":"ClauseLens: Clause","content":"arXiv:2510.08429v1 Announce Type: new Abstract: Reinsurance treaty pricing must satisfy stringent regulatory standards, yet current quoting practices remain opaque and difficult to audit. We introduce ClauseLens, a clause-grounded reinforcement learning framework that produces transparent, regulation-compliant, and risk-aware treaty quotes. ClauseLens models the quoting task as a Risk-Aware Constrained Markov Decision Process (RA-CMDP). Statutory and policy clauses are retrieved from legal and underwriting corpora, embedded into the agent's observations, and used both to constrain feasible actions and to generate clause-grounded natural language justifications. Evaluated in a multi-agent treaty simulator calibrated to industry data, ClauseLens reduces solvency violations by 51%, improves tail-risk performance by 27.9% (CVaR_0.10), and achieves 88.2% accuracy in clause-grounded explanations with retrieval precision of 87.4% and recall of 91.1%. These findings demonstrate that embedding legal context into both decision and explanation pathways yields interpretable, auditable, and regulation-aligned quoting behavior consistent with Solvency II, NAIC RBC, and the EU AI Act.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08429","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.310538","language":"en","tags":["statml","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Stella C. Dong, James R. Finlay","raw_content_length":1195,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["ClauseLens","a Risk-Aware Constrained Markov Decision Process"],"persons":[],"locations":[],"monetary":[]},"char_count":1188,"language_detected":"en","key_concepts":{"key_phrases":["ClauseLens Clause","ClauseLens","arXiv251008429v1 Announce Type","new Abstract","Reinsurance treaty pricing","stringent regulatory standards","current quoting practices","a clause-grounded reinforcement learning framework","the quoting task","a Risk-Aware Constrained Markov Decision Process"],"filter_categories":{"ai_ml":["a clause-grounded reinforcement learning framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ClauseLens Clause":2.0,"ClauseLens":2.0,"arXiv251008429v1 Announce Type":1.0,"new Abstract":1.0,"Reinsurance treaty pricing":1.0,"stringent regulatory standards":1.0,"current quoting practices":1.0,"a clause-grounded reinforcement learning framework":1.0,"the quoting task":1.0,"a Risk-Aware Constrained Markov Decision Process":1.0}},"age_hours":2.775946129722222,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1290000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9219,"joy":0.0067,"surprise":0.0246,"sadness":0.0053,"fear":0.0224,"anger":0.012,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":true},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"ClauseLens is a clause-grounded reinforcement learning framework that aims to improve reinsurance treaty pricing. It reduces solvency violations by 51% and improves tail-risk performance by 27.9% (CVaR_0.10) in a multi-agent treaty simulator. While promising, it's currently in a simulated environment, limiting its immediate real-world climate impact.","key_impact_metrics":["solvency violations reduced by 51%","tail-risk performance improved by 27.9%"],"technology_tags":["reinforcement learning","risk management","financial modeling"],"sdg_alignment":[8,9],"analyzed_at":"2025-10-28T20:44:52.788521Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1e96eefae294","title":"Large Scale Diffusion Distillation via Score","content":"arXiv:2510.08431v1 Announce Type: new Abstract: This work represents the first effort to scale up continuous-time consistency distillation to general application-level image and video diffusion models. Although continuous-time consistency model (sCM) is theoretically principled and empirically powerful for accelerating academic-scale diffusion, its applicability to large-scale text-to-image and video tasks remains unclear due to infrastructure challenges in Jacobian-vector product (JVP) computation and the limitations of standard evaluation benchmarks. We first develop a parallelism-compatible FlashAttention-2 JVP kernel, enabling sCM training on models with over 10 billion parameters and high-dimensional video tasks. Our investigation reveals fundamental quality limitations of sCM in fine-detail generation, which we attribute to error accumulation and the \"mode-covering\" nature of its forward-divergence objective. To remedy this, we propose the score-regularized continuous-time consistency model (rCM), which incorporates score distillation as a long-skip regularizer. This integration complements sCM with the \"mode-seeking\" reverse divergence, effectively improving visual quality while maintaining high generation diversity. Validated on large-scale models (Cosmos-Predict2, Wan2.1) up to 14B parameters and 5-second videos, rCM matches or surpasses the state-of-the-art distillation method DMD2 on quality metrics while offering notable advantages in diversity, all without GAN tuning or extensive hyperparameter searches. The distilled models generate high-fidelity samples in only $1\\sim4$ steps, accelerating diffusion sampling by $15\\times\\sim50\\times$. These results position rCM as a practical and theoretically grounded framework for advancing large-scale diffusion distillation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08431","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.310940","language":"en","tags":["computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Kaiwen Zheng, Yuji Wang, Qianli Ma, Huayu Chen, Jintao Zhang, Yogesh Balaji, Jianfei Chen, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang","raw_content_length":1807,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["JVP kernel"],"locations":[],"monetary":[]},"char_count":1806,"language_detected":"en","key_concepts":{"key_phrases":["Large Scale Diffusion Distillation","Score","Announce Type","new Abstract","This work","the first effort","continuous-time consistency distillation","general application-level image","video diffusion models","continuous-time consistency model"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Scale Diffusion Distillation":2.0,"Score":2.0,"Announce Type":1.0,"new Abstract":1.0,"This work":1.0,"the first effort":1.0,"continuous-time consistency distillation":1.0,"general application-level image":1.0,"video diffusion models":1.0,"continuous-time consistency model":1.0}},"age_hours":2.7759610713888887,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8678,"joy":0.0286,"surprise":0.0554,"sadness":0.005,"fear":0.0166,"anger":0.0197,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (rCM) for accelerating diffusion sampling in image and video generation, achieving 15x-50x speedups. While this could indirectly reduce energy consumption in AI model training and inference, the actual climate impact is theoretical and not quantified. The technical credibility is supported by the methodology and performance metrics, but it's still in the applied research phase with no deployed units.","key_impact_metrics":["15x-50x acceleration of diffusion sampling"],"technology_tags":["Diffusion models","Consistency distillation","Machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:44:55.597243Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5bfc90ba7071","title":"xRouter: Training Cost","content":"arXiv:2510.08439v1 Announce Type: new Abstract: Modern LLM deployments confront a widening cost-performance spectrum: premium models deliver strong reasoning but are expensive, while lightweight models are economical yet brittle on complex tasks. Static escalation rules and keyword heuristics under-utilize this spectrum and fail to adapt across task types. We present xRouter, a tool-calling-based routing system in which a learned router can either answer directly or invoke one or more external models. The router is trained end-to-end with reinforcement learning using an explicit, cost-aware reward that encodes cost-performance trade-offs, eliminating the need for hand-engineered routing rules. Our implementation encompasses the full reinforcement learning framework, including reward and cost accounting, as well as the deployment and evaluation pipelines. Across diverse benchmarks, xRouter achieves strong cost-performance trade-offs (e.g., substantial cost reductions at comparable task completion rates), and provides empirical insights into what reliably helps learned routing and what does not, ranging from model trainability to the difficulty of eliciting sophisticated orchestration behaviors in small open models. We hope these findings and our open implementation will serve as a practical substrate for advancing learned, cost-aware LLM orchestration.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08439","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.311323","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Cheng Qian, Zuxin Liu, Shirley Kokane, Akshara Prabhakar, Jielin Qiu, Haolin Chen, Zhiwei Liu, Heng Ji, Weiran Yao, Shelby Heinecke, Silvio Savarese, Caiming Xiong, Huan Wang","raw_content_length":1374,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["xRouter"],"locations":[],"monetary":[]},"char_count":1373,"language_detected":"en","key_concepts":{"key_phrases":["xRouter","Training Cost","arXiv251008439v1 Announce Type","new Abstract","Modern LLM deployments","a widening cost-performance spectrum","premium models","strong reasoning","lightweight models","complex tasks"],"filter_categories":{"ai_ml":["Training Cost"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"xRouter":3.0,"Training Cost":2.0,"arXiv251008439v1 Announce Type":1.0,"new Abstract":1.0,"Modern LLM deployments":1.0,"a widening cost-performance spectrum":1.0,"premium models":1.0,"strong reasoning":1.0,"lightweight models":1.0,"complex tasks":1.0}},"age_hours":2.775975736388889,"is_recent":true,"quality_score":1.0,"sentiment_score":1.9705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6059,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8624,"joy":0.0055,"surprise":0.0409,"sadness":0.0161,"fear":0.0217,"anger":0.0385,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents xRouter, a system that reduces the computational cost of LLMs by intelligently routing tasks to different models. This has the potential to reduce the energy consumption associated with LLM usage. The system is in the applied research stage, with empirical insights and an open implementation, but no large-scale deployment is mentioned.","key_impact_metrics":["substantial cost reductions at comparable task completion rates"],"technology_tags":["LLM routing","reinforcement learning","cost-aware AI"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-28T20:44:58.520379Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_419e7ae2e501","title":"Gaze on the Prize: Shaping Visual Attention with Return","content":"arXiv:2510.08442v1 Announce Type: new Abstract: Visual Reinforcement Learning (RL) agents must learn to act based on high-dimensional image data where only a small fraction of the pixels is task-relevant. This forces agents to waste exploration and computational resources on irrelevant features, leading to sample-inefficient and unstable learning. To address this, inspired by human visual foveation, we introduce Gaze on the Prize. This framework augments visual RL with a learnable foveal attention mechanism (Gaze), guided by a self-supervised signal derived from the agent's experience pursuing higher returns (the Prize). Our key insight is that return differences reveal what matters most: If two similar representations produce different outcomes, their distinguishing features are likely task-relevant, and the gaze should focus on them accordingly. This is realized through return-guided contrastive learning that trains the attention to distinguish between the features relevant to success and failure. We group similar visual representations into positives and negatives based on their return differences and use the resulting labels to construct contrastive triplets. These triplets provide the training signal that teaches the attention mechanism to produce distinguishable representations for states associated with different outcomes. Our method achieves up to 2.4x improvement in sample efficiency and can solve tasks that the baseline fails to learn, demonstrated across a suite of manipulation tasks from the ManiSkill3 benchmark, all without modifying the underlying algorithm or hyperparameters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08442","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.311750","language":"en","tags":["csro","computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Andrew Lee, Ian Chuang, Dechen Gao, Kai Fukazawa, Iman Soltani","raw_content_length":1618,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["Gaze","Prize","Visual Reinforcement Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1617,"language_detected":"en","key_concepts":{"key_phrases":["Gaze","the Prize","Visual Attention","Return","arXiv251008442v1 Announce Type","new Abstract","Visual Reinforcement Learning RL agents","high-dimensional image data","only a small fraction","the pixels"],"filter_categories":{"ai_ml":["Visual Reinforcement Learning RL agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gaze":3.0,"the Prize":3.0,"Visual Attention":2.0,"Return":2.0,"arXiv251008442v1 Announce Type":1.0,"new Abstract":1.0,"Visual Reinforcement Learning RL agents":1.0,"high-dimensional image data":1.0,"only a small fraction":1.0,"the pixels":1.0}},"age_hours":2.7759906355555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.937999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7876,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8973,"joy":0.0142,"surprise":0.0188,"sadness":0.0071,"fear":0.0081,"anger":0.0367,"disgust":0.0178},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to visual reinforcement learning, improving sample efficiency by up to 2.4x on manipulation tasks. The method is still in the research phase, with no deployed units or real-world applications yet. While the increased efficiency could potentially reduce energy consumption in robotic systems, the impact is currently theoretical and depends on the specific application.","key_impact_metrics":["2.4x improvement in sample efficiency"],"technology_tags":["Reinforcement Learning","Visual Attention","Robotics"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:02.295943Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0547ed186503","title":"Hierarchical Spatial Algorithms for High","content":"arXiv:2510.08449v1 Announce Type: new Abstract: This study introduces a modular framework for spatial image processing, integrating grayscale quantization, color and brightness enhancement, image sharpening, bidirectional transformation pipelines, and geometric feature extraction. A stepwise intensity transformation quantizes grayscale images into eight discrete levels, producing a posterization effect that simplifies representation while preserving structural detail. Color enhancement is achieved via histogram equalization in both RGB and YCrCb color spaces, with the latter improving contrast while maintaining chrominance fidelity. Brightness adjustment is implemented through HSV value-channel manipulation, and image sharpening is performed using a 3 * 3 convolution kernel to enhance high-frequency details. A bidirectional transformation pipeline that integrates unsharp masking, gamma correction, and noise amplification achieved accuracy levels of 76.10% and 74.80% for the forward and reverse processes, respectively. Geometric feature extraction employed Canny edge detection, Hough-based line estimation (e.g., 51.50{\\deg} for billiard cue alignment), Harris corner detection, and morphological window localization. Cue isolation further yielded 81.87\\% similarity against ground truth images. Experimental evaluation across diverse datasets demonstrates robust and deterministic performance, highlighting its potential for real-time image analysis and computer vision.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08449","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.312873","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Noor Islam S. Mohammad","raw_content_length":1488,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["RGB","HSV"],"persons":[],"locations":[],"monetary":[]},"char_count":1487,"language_detected":"en","key_concepts":{"key_phrases":["Hierarchical Spatial Algorithms","arXiv251008449v1 Announce Type","new Abstract","This study","a modular framework","spatial image processing","grayscale quantization","color","brightness","enhancement"],"filter_categories":{"ai_ml":["Hierarchical Spatial Algorithms"],"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hierarchical Spatial Algorithms":2.0,"arXiv251008449v1 Announce Type":1.0,"new Abstract":1.0,"This study":1.0,"a modular framework":1.0,"spatial image processing":1.0,"grayscale quantization":1.0,"color":1.0,"brightness":1.0,"enhancement":1.0}},"age_hours":2.7760294494444446,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8874,"joy":0.0336,"surprise":0.0483,"sadness":0.0062,"fear":0.0052,"anger":0.0115,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a modular framework for spatial image processing. While it demonstrates accuracy levels for image transformation and feature extraction (e.g., 76.10% forward process accuracy), it lacks concrete application to sustainability challenges or quantified environmental benefits. It's vaporware because it's an early-stage concept without deployed units or operational data.","key_impact_metrics":["76.10% forward process accuracy","81.87% similarity against ground truth images"],"technology_tags":["image processing","computer vision","spatial algorithms"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:45:05.286068Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d3d74cb8e337","title":"gLSTM: Mitigating Over","content":"arXiv:2510.08450v1 Announce Type: new Abstract: Graph Neural Networks (GNNs) leverage the graph structure to transmit information between nodes, typically through the message-passing mechanism. While these models have found a wide variety of applications, they are known to suffer from over-squashing, where information from a large receptive field of node representations is collapsed into a single fixed sized vector, resulting in an information bottleneck. In this paper, we re-examine the over-squashing phenomenon through the lens of model storage and retrieval capacity, which we define as the amount of information that can be stored in a node's representation for later use. We study some of the limitations of existing tasks used to measure over-squashing and introduce a new synthetic task to demonstrate that an information bottleneck can saturate this capacity. Furthermore, we adapt ideas from the sequence modeling literature on associative memories, fast weight programmers, and the xLSTM model to develop a novel GNN architecture with improved capacity. We demonstrate strong performance of this architecture both on our capacity synthetic task, as well as a range of real-world graph benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08450","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.313257","language":"en","tags":["statml","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Hugh Blayney, \\'Alvaro Arroyo, Xiaowen Dong, Michael M. Bronstein","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Graph Neural Networks"],"persons":[],"locations":["node"],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["information","arXiv251008450v1 Announce Type","new Abstract","Graph Neural Networks","GNNs","the graph structure","nodes","the message-passing mechanism","these models","a wide variety"],"filter_categories":{"ai_ml":["Graph Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"information":2.0,"arXiv251008450v1 Announce Type":1.0,"new Abstract":1.0,"Graph Neural Networks":1.0,"GNNs":1.0,"the graph structure":1.0,"nodes":1.0,"the message-passing mechanism":1.0,"these models":1.0,"a wide variety":1.0}},"age_hours":2.7760439180555556,"is_recent":true,"quality_score":1.0,"sentiment_score":1.596,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6808,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7959,"joy":0.0044,"surprise":0.0439,"sadness":0.0422,"fear":0.052,"anger":0.0253,"disgust":0.0362},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel GNN architecture (gLSTM) to address the over-squashing problem in graph neural networks. While the research demonstrates improved performance on synthetic and real-world graph benchmarks, it is currently in the basic research stage with no deployed technology or measured real-world outcomes related to climate impact. The potential for climate impact is theoretical and depends on future applications of GNNs to sustainability-related problems.","key_impact_metrics":["Improved capacity on synthetic task","Strong performance on real-world graph benchmarks"],"technology_tags":["Graph Neural Networks","Machine Learning","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:08.031157Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_83f458fa2f72","title":"Integral Signatures of Activation Functions: A 9","content":"arXiv:2510.08456v1 Announce Type: new Abstract: Activation functions govern the expressivity and stability of neural networks, yet existing comparisons remain largely heuristic. We propose a rigorous framework for their classification via a nine-dimensional integral signature S_sigma(phi), combining Gaussian propagation statistics (m1, g1, g2, m2, eta), asymptotic slopes (alpha_plus, alpha_minus), and regularity measures (TV(phi'), C(phi)). This taxonomy establishes well-posedness, affine reparameterization laws with bias, and closure under bounded slope variation. Dynamical analysis yields Lyapunov theorems with explicit descent constants and identifies variance stability regions through (m2', g2). From a kernel perspective, we derive dimension-free Hessian bounds and connect smoothness to bounded variation of phi'. Applying the framework, we classify eight standard activations (ReLU, leaky-ReLU, tanh, sigmoid, Swish, GELU, Mish, TeLU), proving sharp distinctions between saturating, linear-growth, and smooth families. Numerical Gauss-Hermite and Monte Carlo validation confirms theoretical predictions. Our framework provides principled design guidance, moving activation choice from trial-and-error to provable stability and kernel conditioning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08456","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.314020","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Ankur Mali, Lawrence Hall, Jake Williams, Gordon Richards","raw_content_length":1264,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["GELU","ReLU","TeLU","Mish","Integral Signatures of Activation Functions"],"persons":["Lyapunov"],"locations":[],"monetary":[]},"char_count":1263,"language_detected":"en","key_concepts":{"key_phrases":["Integral Signatures","Activation Functions","arXiv251008456v1 Announce Type","new Abstract","Activation functions","the expressivity","stability","neural networks","existing comparisons","a rigorous framework"],"filter_categories":{"ai_ml":["neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Integral Signatures":2.0,"Activation Functions":2.0,"arXiv251008456v1 Announce Type":1.0,"new Abstract":1.0,"Activation functions":1.0,"the expressivity":1.0,"stability":1.0,"neural networks":1.0,"existing comparisons":1.0,"a rigorous framework":1.0}},"age_hours":2.77607311,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8741,"joy":0.0265,"surprise":0.0663,"sadness":0.0063,"fear":0.0069,"anger":0.0144,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for classifying activation functions in neural networks, which could indirectly contribute to sustainability by improving the efficiency and stability of AI models used in climate modeling or renewable energy optimization. However, the impact is highly speculative and depends on future applications; there are no deployed technologies or measured outcomes at this stage. The paper provides specific metrics related to Gaussian propagation statistics and asymptotic slopes, enhancing technical credibility.","key_impact_metrics":["m1, g1, g2, m2, eta","alpha_plus, alpha_minus"],"technology_tags":["neural networks","activation functions","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:10.845243Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9018822dd918","title":"ARES: Multimodal Adaptive Reasoning via Difficulty","content":"arXiv:2510.08457v1 Announce Type: new Abstract: Recent advances in multimodal large reasoning models (MLRMs) have substantially improved their ability to solve complex textual and visual tasks. However, these models tend to overthink on simple problems, producing unnecessarily lengthy reasoning traces, while under-exploring on challenging ones, leading to missed solutions. To address this imbalance, we propose ARES, a unified open-source framework for adaptive reasoning that dynamically allocates exploration effort based on task difficulty. Our approach is motivated by two key empirical findings: (i) while single-token entropy is noisy, high window-entropy (HWE) tokens (token-level entropies averaged under a sliding window) can reliably capture reasoning-critical moments; and (ii) reducing HWE usage benefits easy problems, while increasing it is essential for solving hard ones. Building on these insights, ARES introduces a two-stage training pipeline. In the Adaptive Cold-Start stage, we curate multimodal and textual data paired with reasoning traces of length proportional to problem difficulty, equipping the model with initial difficulty awareness. In the second stage, we develop Adaptive Entropy Policy Optimization (AEPO), which uses HWE tokens as exploration triggers to decide when to explore, and a hierarchical entropy reward with dynamic KL control to decide how much to explore. Extensive experiments demonstrate that ARES achieves superior performance and reasoning efficiency across diverse mathematical, logical, and multimodal benchmarks, while closing the gap to leading commercial systems under significantly lower inference costs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08457","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.314429","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Shuang Chen, Yue Guo, Yimeng Ye, Shijue Huang, Wenbo Hu, Haoxi Li, Manyuan Zhang, Jiayu Chen, Song Guo, Nanyun Peng","raw_content_length":1666,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["ARES","HWE"],"persons":[],"locations":[],"monetary":[]},"char_count":1665,"language_detected":"en","key_concepts":{"key_phrases":["ARES","Multimodal Adaptive Reasoning","Difficulty","new Abstract","Recent advances","multimodal large reasoning models","MLRMs","their ability","complex textual and visual tasks","these models"],"filter_categories":{"ai_ml":["MLRMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ARES":3.0,"Multimodal Adaptive Reasoning":2.0,"Difficulty":2.0,"new Abstract":1.0,"Recent advances":1.0,"multimodal large reasoning models":1.0,"MLRMs":1.0,"their ability":1.0,"complex textual and visual tasks":1.0,"these models":1.0}},"age_hours":2.776088042777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2745,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6549,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.782,"joy":0.0054,"surprise":0.0424,"sadness":0.0464,"fear":0.0106,"anger":0.0705,"disgust":0.0427},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (ARES) that improves reasoning efficiency and performance in multimodal tasks. While the framework itself doesn't directly address climate change, its potential to optimize resource allocation and reduce computational costs could indirectly contribute to sustainability by lowering energy consumption in AI applications. The evidence is based on experiments and benchmarks, but deployment is still at the research stage.","key_impact_metrics":["Lower inference costs","Improved reasoning efficiency"],"technology_tags":["Artificial Intelligence","Machine Learning","Multimodal Reasoning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:45:13.536556Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b111f11d188a","title":"SummDiff: Generative Modeling of Video Summarization with Diffusion","content":"arXiv:2510.08458v1 Announce Type: new Abstract: Video summarization is a task of shortening a video by choosing a subset of frames while preserving its essential moments. Despite the innate subjectivity of the task, previous works have deterministically regressed to an averaged frame score over multiple raters, ignoring the inherent subjectivity of what constitutes a good summary. We propose a novel problem formulation by framing video summarization as a conditional generation task, allowing a model to learn the distribution of good summaries and to generate multiple plausible summaries that better reflect varying human perspectives. Adopting diffusion models for the first time in video summarization, our proposed method, SummDiff, dynamically adapts to visual contexts and generates multiple candidate summaries conditioned on the input video. Extensive experiments demonstrate that SummDiff not only achieves the state-of-the-art performance on various benchmarks but also produces summaries that closely align with individual annotator preferences. Moreover, we provide a deeper insight with novel metrics from an analysis of the knapsack, which is an important last step of generating summaries but has been overlooked in evaluation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08458","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.314812","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Kwanseok Kim, Jaehoon Hahm, Sumin Kim, Jinhwan Sul, Byunghak Kim, Joonseok Lee","raw_content_length":1248,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Video Summarization with Diffusion arXiv:2510.08458v1 Announce Type","SummDiff"],"persons":[],"locations":[],"monetary":[]},"char_count":1247,"language_detected":"en","key_concepts":{"key_phrases":["SummDiff","Generative Modeling","Video Summarization","Diffusion","arXiv251008458v1 Announce Type","new Abstract","Video summarization","a task","a video","a subset"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SummDiff":2.0,"Generative Modeling":2.0,"Video Summarization":2.0,"Diffusion":2.0,"arXiv251008458v1 Announce Type":1.0,"new Abstract":1.0,"Video summarization":1.0,"a task":1.0,"a video":1.0,"a subset":1.0}},"age_hours":2.776101994722222,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9126,"joy":0.0079,"surprise":0.035,"sadness":0.0052,"fear":0.0059,"anger":0.0195,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for video summarization using diffusion models. While it achieves state-of-the-art performance on benchmarks and aligns with annotator preferences, it's still in the research phase with no clear path to deployment or quantified climate impact. The impact is theoretical as it could potentially reduce the energy consumption of video processing, but this is not quantified.","key_impact_metrics":["State-of-the-art performance on various benchmarks","Alignment with individual annotator preferences"],"technology_tags":["Video Summarization","Diffusion Models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:45:16.263911Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_443e316689a9","title":"LeWiDi","content":"arXiv:2510.08460v1 Announce Type: new Abstract: Many researchers have reached the conclusion that AI models should be trained to be aware of the possibility of variation and disagreement in human judgments, and evaluated as per their ability to recognize such variation. The LEWIDI series of shared tasks on Learning With Disagreements was established to promote this approach to training and evaluating AI models, by making suitable datasets more accessible and by developing evaluation methods. The third edition of the task builds on this goal by extending the LEWIDI benchmark to four datasets spanning paraphrase identification, irony detection, sarcasm detection, and natural language inference, with labeling schemes that include not only categorical judgments as in previous editions, but ordinal judgments as well. Another novelty is that we adopt two complementary paradigms to evaluate disagreement-aware systems: the soft-label approach, in which models predict population-level distributions of judgments, and the perspectivist approach, in which models predict the interpretations of individual annotators. Crucially, we moved beyond standard metrics such as cross-entropy, and tested new evaluation metrics for the two paradigms. The task attracted diverse participation, and the results provide insights into the strengths and limitations of methods to modeling variation. Together, these contributions strengthen LEWIDI as a framework and provide new resources, benchmarks, and findings to support the development of disagreement-aware technologies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08460","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.315208","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Elisa Leonardelli, Silvia Casola, Siyao Peng, Giulia Rizzi, Valerio Basile, Elisabetta Fersini, Diego Frassinelli, Hyewon Jang, Maja Pavlovic, Barbara Plank, Massimo Poesio","raw_content_length":1567,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["LeWiDi arXiv:2510.08460v1 Announce Type: new","LEWIDI"],"persons":[],"locations":[],"monetary":[]},"char_count":1566,"language_detected":"en","key_concepts":{"key_phrases":["LeWiDi","AI models","arXiv251008460v1","Announce Type","new Abstract","Many researchers","the conclusion","the possibility","variation","disagreement"],"filter_categories":{"ai_ml":["AI models"],"research_academic":["Many researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LeWiDi":2.0,"AI models":2.0,"arXiv251008460v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Many researchers":1.0,"the conclusion":1.0,"the possibility":1.0,"variation":1.0,"disagreement":1.0}},"age_hours":2.776115750555556,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7512,"joy":0.1409,"surprise":0.0551,"sadness":0.0067,"fear":0.0128,"anger":0.0273,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a benchmark dataset and evaluation methods for AI models to understand human disagreement. While it's about improving AI, there's no direct or measurable impact on climate change or sustainability. It's still in the research and development phase, with no deployed technology or quantifiable environmental benefits.","key_impact_metrics":["None"],"technology_tags":["Artificial Intelligence","Natural Language Processing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:45:18.819471Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_80854cf659a0","title":"Refinement","content":"arXiv:2510.08461v1 Announce Type: new Abstract: We introduce a refinement-based Christoffel sampling (RCS) algorithm for least squares approximation in the span of a given, generally non-orthogonal set of functions $\\Phi_n = \\{\\phi_1, \\dots, \\phi_n\\}$. A standard sampling strategy for this problem is Christoffel sampling, which achieves near-best approximations in probability using only $\\mathcal{O}(n \\log(n))$ samples. However, it requires i.i.d.\\ sampling from a distribution whose density is proportional to the inverse Christoffel function $k_n$, the computation of which requires an orthonormal basis. As a result, existing approaches for non-orthogonal bases $\\Phi_n$ typically rely on costly discrete orthogonalization. We propose a new iterative algorithm, inspired by recent advances in approximate leverage score sampling, that avoids this bottleneck. Crucially, while the computational cost of discrete orthogonalization grows proportionally with $\\|k_n\\|_{L^\\infty(X)}$, the cost of our approach increases only logarithmically in $\\|k_n\\|_{L^\\infty(X)}$. In addition, we account for finite-precision effects by considering a numerical variant of the Christoffel function, ensuring that the algorithm relies only on computable quantities. Alongside a convergence proof, we present extensive numerical experiments demonstrating the efficiency and robustness of the proposed method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08461","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.315621","language":"en","tags":["csna","computer-science","preprints","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Astird Herremans, Ben Adcock","raw_content_length":1396,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Christoffel","\\dots"],"persons":["k_n$"],"locations":[],"monetary":["only $","\\Phi_n"]},"char_count":1395,"language_detected":"en","key_concepts":{"key_phrases":["Refinement","arXiv251008461v1 Announce Type","new Abstract","RCS","squares approximation","the span","a given generally non-orthogonal set","functions","Phi_n phi_1","dots"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Refinement":2.0,"arXiv251008461v1 Announce Type":1.0,"new Abstract":1.0,"RCS":1.0,"squares approximation":1.0,"the span":1.0,"a given generally non-orthogonal set":1.0,"functions":1.0,"Phi_n phi_1":1.0,"dots":1.0}},"age_hours":2.7761297016666666,"is_recent":true,"quality_score":1.0,"sentiment_score":2.595,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.481,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8514,"joy":0.0431,"surprise":0.0853,"sadness":0.0075,"fear":0.0021,"anger":0.0077,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm for least squares approximation, potentially improving computational efficiency in various fields. While the algorithm itself doesn't directly reduce GHG emissions, its application in optimizing energy systems or climate models could indirectly contribute to sustainability. The technical credibility is supported by a convergence proof and numerical experiments, but deployment readiness is low as it's still in the research phase.","key_impact_metrics":["Computational cost increases logarithmically in ||k_n||_{L^\\infty(X)}","Achieves near-best approximations in probability using only O(n log(n)) samples"],"technology_tags":["Algorithm optimization","Least squares approximation","Christoffel sampling"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:21.799392Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0d3ed649b42","title":"Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered","content":"arXiv:2510.08464v1 Announce Type: new Abstract: Vision-Language-Action (VLA) models have advanced robotic capabilities but remain challenging to deploy on resource-limited hardware. Pruning has enabled efficient compression of large language models (LLMs), yet it is largely understudied in robotics. Surprisingly, we observe that pruning VLA models leads to drastic degradation and increased safety violations. We introduce GLUESTICK, a post-pruning recovery method that restores much of the original model's functionality while retaining sparsity benefits. Our method performs a one-time interpolation between the dense and pruned models in weight-space to compute a corrective term. This correction is used during inference by each pruned layer to recover lost capabilities with minimal overhead. GLUESTICK requires no additional training, is agnostic to the pruning algorithm, and introduces a single hyperparameter that controls the tradeoff between efficiency and accuracy. Across diverse VLA architectures and tasks in manipulation and navigation, GLUESTICK achieves competitive memory efficiency while substantially recovering success rates and reducing safety violations. Additional material can be found at: https://gluestick-vla.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08464","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.316007","language":"en","tags":["csro","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Jason Jabbour, Dong-Ki Kim, Max Smith, Jay Patrikar, Radhika Ghosal, Youhui Wang, Ali Agha, Vijay Janapa Reddi, Shayegan Omidshafiei","raw_content_length":1252,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["VLA","Vision-Language-Action"],"persons":[],"locations":[],"monetary":[]},"char_count":1251,"language_detected":"en","key_concepts":{"key_phrases":["Scissors","Pruning Breaks VLA Models","Announce Type","new Abstract","VLA","robotic capabilities","resource-limited hardware","Pruning","efficient compression","large language models"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scissors":2.0,"Pruning Breaks VLA Models":2.0,"Announce Type":1.0,"new Abstract":1.0,"VLA":1.0,"robotic capabilities":1.0,"resource-limited hardware":1.0,"Pruning":1.0,"efficient compression":1.0,"large language models":1.0}},"age_hours":2.776144882222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6135,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7227,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.1439,"joy":0.0027,"surprise":0.7788,"sadness":0.016,"fear":0.0078,"anger":0.0246,"disgust":0.0261},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method (GLUESTICK) to improve the efficiency of Vision-Language-Action models by pruning them and then recovering functionality. While the method demonstrates improved memory efficiency and recovery of success rates, it is currently in the applied research stage with no deployment data. The climate impact is indirect, potentially reducing energy consumption of robotic systems, but not quantified.","key_impact_metrics":["memory efficiency","success rates"],"technology_tags":["VLA models","pruning","model compression"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:24.266943Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a738a7b788e5","title":"Dynamic Automated Deduction by Contradiction Separation: The Standard Extension Algorithm","content":"arXiv:2510.08468v1 Announce Type: new Abstract: Automated deduction seeks to enable machines to reason with mathematical precision and logical completeness. Classical resolution-based systems, such as Prover9, E, and Vampire, rely on binary inference, which inherently limits multi-clause synergy during proof search. The Contradiction Separation Extension (CSE) framework, introduced by Xu et al. (2018), overcame this theoretical limitation by extending deduction beyond binary inference. However, the original work did not specify how contradictions are algorithmically constructed and extended in practice. This paper presents the Standard Extension algorithm, the first explicit procedural realization of contradiction separation reasoning. The proposed method dynamically constructs contradictions through complementary literal extension, thereby operationalizing the CSE theory within a unified algorithm for satisfiability and unsatisfiability checking. The algorithm's soundness and completeness are formally proven, and its effectiveness is supported indirectly through the performance of CSE-based systems, including CSE, CSE-E, CSI-E, and CSI-Enig in major automated reasoning competitions (CASC) in the last few years. These results confirm that the Standard Extension mechanism constitutes a robust and practically validated foundation for dynamic, multi-clause automated deduction.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08468","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.316783","language":"en","tags":["research","cslo","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Yang Xu, Xingxing He, Shuwei Chen, Jun Liu, Xiaomei Zhong","raw_content_length":1397,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Standard Extension","CSE","The Contradiction Separation Extension"],"persons":["Vampire","Xu et al."],"locations":[],"monetary":[]},"char_count":1396,"language_detected":"en","key_concepts":{"key_phrases":["Dynamic Automated Deduction","Contradiction Separation","The Standard Extension Algorithm","binary inference","arXiv251008468v1 Announce Type","new Abstract","Automated deduction","machines","mathematical precision","logical completeness"],"filter_categories":{"ai_ml":["The Standard Extension Algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dynamic Automated Deduction":2.0,"Contradiction Separation":2.0,"The Standard Extension Algorithm":2.0,"binary inference":2.0,"arXiv251008468v1 Announce Type":1.0,"new Abstract":1.0,"Automated deduction":1.0,"machines":1.0,"mathematical precision":1.0,"logical completeness":1.0}},"age_hours":2.7761722549999996,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9,"joy":0.0133,"surprise":0.0582,"sadness":0.0042,"fear":0.0086,"anger":0.0114,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm for automated deduction, which could potentially improve the efficiency of various applications, including those related to sustainability. However, the direct climate impact is currently minimal as it is still in the applied research stage and lacks concrete deployment. The effectiveness is supported by the performance of CSE-based systems in competitions, but there's no direct quantification of environmental benefits.","key_impact_metrics":["Performance in CASC competitions","Soundness and completeness formally proven"],"technology_tags":["Automated Deduction","Contradiction Separation","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:27.367474Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_16a200a16daf","title":"Looking to Learn: Token-wise Dynamic Gating for Low","content":"arXiv:2510.08470v1 Announce Type: new Abstract: Training vision-language models on cognitively-plausible amounts of data requires rethinking how models integrate multimodal information. Within the constraints of the Vision track for the BabyLM Challenge 2025, we propose a lightweight decoder-based architecture with (1) token-wise dynamic gating for adaptive fusion of linguistic and visual cues, (2) feature modulation and channel attention to maximise the utility of limited visual information and (3) auxiliary contrastive objectives for visual grounding. Evaluation on five benchmarks (BLiMP, BLiMP Supplement, EWoK, Winoground and VQA) shows competitive or superior performance to multimodal baselines. More notably, our dynamic gate discovers interpretable patterns without explicit supervision, favouring visual cues for content words and linguistic cues for function words. While we identify limitations in the Challenge constraints, such as the information bottleneck created by global image embeddings and training instability from the dataset split, our findings establish dynamic gating as a powerful tool for efficient multimodal learning, offering both interpretability and performance even under severe constraints.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08470","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.317167","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Bianca-Mihaela Ganescu, Suchir Salhan, Andrew Caines, Paula Buttery","raw_content_length":1232,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["VQA"],"persons":["Learn","Winoground"],"locations":[],"monetary":[]},"char_count":1231,"language_detected":"en","key_concepts":{"key_phrases":["Token-wise Dynamic Gating","Low","Announce Type","new Abstract","Training vision-language models","cognitively-plausible amounts","data","models","multimodal information","the constraints"],"filter_categories":{"ai_ml":["Training vision-language models","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Token-wise Dynamic Gating":2.0,"Low":2.0,"Announce Type":1.0,"new Abstract":1.0,"Training vision-language models":1.0,"cognitively-plausible amounts":1.0,"data":1.0,"models":1.0,"multimodal information":1.0,"the constraints":1.0}},"age_hours":2.7761866875,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8527,"joy":0.0133,"surprise":0.0154,"sadness":0.005,"fear":0.071,"anger":0.0256,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI architecture for vision-language models, demonstrating competitive performance on several benchmarks. While the research shows promise in efficient multimodal learning, it is still in the early stages of development with no deployed units or real-world data on energy consumption. The impact on climate change is indirect and currently unquantifiable.","key_impact_metrics":["Competitive performance on BLiMP, BLiMP Supplement, EWoK, Winoground and VQA"],"technology_tags":["Vision-Language Models","Dynamic Gating","AI"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:45:30.241864Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a4f04432d486","title":"DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos","content":"arXiv:2510.08475v1 Announce Type: new Abstract: We present DexMan, an automated framework that converts human visual demonstrations into bimanual dexterous manipulation skills for humanoid robots in simulation. Operating directly on third-person videos of humans manipulating rigid objects, DexMan eliminates the need for camera calibration, depth sensors, scanned 3D object assets, or ground-truth hand and object motion annotations. Unlike prior approaches that consider only simplified floating hands, it directly controls a humanoid robot and leverages novel contact-based rewards to improve policy learning from noisy hand-object poses estimated from in-the-wild videos. DexMan achieves state-of-the-art performance in object pose estimation on the TACO benchmark, with absolute gains of 0.08 and 0.12 in ADD-S and VSD. Meanwhile, its reinforcement learning policy surpasses previous methods by 19% in success rate on OakInk-v2. Furthermore, DexMan can generate skills from both real and synthetic videos, without the need for manual data collection and costly motion capture, and enabling the creation of large-scale, diverse datasets for training generalist dexterous manipulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08475","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.317570","language":"en","tags":["csro","computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Jhen Hsieh, Kuan-Hsun Tu, Kuo-Han Hung, Tsung-Wei Ke","raw_content_length":1191,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["VSD","TACO"],"persons":["Generated Videos"],"locations":[],"monetary":[]},"char_count":1188,"language_detected":"en","key_concepts":{"key_phrases":["DexMan","Bimanual Dexterous Manipulation","Human and Generated Videos","arXiv251008475v1 Announce Type","new Abstract","an automated framework","human visual demonstrations","bimanual dexterous manipulation skills","humanoid robots","simulation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DexMan":4.0,"Bimanual Dexterous Manipulation":2.0,"Human and Generated Videos":2.0,"arXiv251008475v1 Announce Type":1.0,"new Abstract":1.0,"an automated framework":1.0,"human visual demonstrations":1.0,"bimanual dexterous manipulation skills":1.0,"humanoid robots":1.0,"simulation":1.0}},"age_hours":2.776201387777778,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9172,"joy":0.0282,"surprise":0.0318,"sadness":0.0019,"fear":0.0034,"anger":0.0105,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (DexMan) for learning bimanual dexterous manipulation from videos, improving object pose estimation and reinforcement learning policy success rates. While the technology is promising, it is still in the applied research stage, with no evidence of real-world deployment. The climate impact is indirect, potentially reducing the need for physical prototypes and experiments, but not directly addressing GHG emissions.","key_impact_metrics":["ADD-S gain of 0.08","VSD gain of 0.12"],"technology_tags":["Robotics","Machine Learning","Dexterous Manipulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:33.404093Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d6de7bdf6d92","title":"Rethinking Provenance Completeness with a Learning","content":"arXiv:2510.08479v1 Announce Type: new Abstract: Provenance plays a critical role in maintaining traceability of a system's actions for root cause analysis of security threats and impacts. Provenance collection is often incorporated into the reference monitor of systems to ensure that an audit trail exists of all events, that events are completely captured, and that logging of such events cannot be bypassed. However, recent research has questioned whether existing state-of-the-art provenance collection systems fail to ensure the security guarantees of a true reference monitor due to the 'super producer threat' in which provenance generation can overload a system to force the system to drop security-relevant events and allow an attacker to hide their actions. One approach towards solving this threat is to enforce resource isolation, but that does not fully solve the problems resulting from hardware dependencies and performance limitations. In this paper, we show how an operating system's kernel scheduler can mitigate this threat, and we introduce Venus, a learned scheduler for Linux specifically designed for provenance. Unlike conventional schedulers that ignore provenance completeness requirements, Venus leverages reinforcement learning to learn provenance task behavior and to dynamically optimize resource allocation. We evaluate Venus's efficacy and show that Venus significantly improves both the completeness and efficiency of provenance collection systems compared to traditional scheduling, while maintaining reasonable overheads and even improving overall runtime in certain cases compared to the default Linux scheduler.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08479","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.317970","language":"en","tags":["csos","computer-science","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Jinsong Mao, Benjamin E. Ujcich, Shiqing Ma","raw_content_length":1651,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1648,"language_detected":"en","key_concepts":{"key_phrases":["Provenance Completeness","a Learning","arXiv251008479v1 Announce Type","new Abstract","Provenance","a critical role","traceability","a systems actions","root cause analysis","security threats"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Provenance Completeness":2.0,"a Learning":2.0,"arXiv251008479v1 Announce Type":1.0,"new Abstract":1.0,"Provenance":1.0,"a critical role":1.0,"traceability":1.0,"a systems actions":1.0,"root cause analysis":1.0,"security threats":1.0}},"age_hours":2.7762159558333335,"is_recent":true,"quality_score":0.7,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7237,"joy":0.0172,"surprise":0.0318,"sadness":0.0109,"fear":0.1707,"anger":0.0353,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to provenance collection using a learned scheduler (Venus) to improve completeness and efficiency. The evaluation shows significant improvements compared to traditional scheduling, but it's still in the research phase without real-world deployment. The impact on climate is indirect, as it improves system security and reliability, potentially reducing resource waste from compromised systems.","key_impact_metrics":["Improved completeness of provenance collection","Improved efficiency of provenance collection systems"],"technology_tags":["Reinforcement Learning","Operating System Scheduler","Provenance Collection"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-28T20:45:36.267377Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6912d3512759","title":"Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning","content":"arXiv:2510.08481v1 Announce Type: new Abstract: Hashtag trends ignite campaigns, shift public opinion, and steer millions of dollars in advertising spend, yet forecasting which tag goes viral is elusive. Classical regressors digest surface features but ignore context, while large language models (LLMs) excel at contextual reasoning but misestimate numbers. We present BuzzProphet, a reasoning-augmented hashtag popularity prediction framework that (1) instructs an LLM to articulate a hashtag's topical virality, audience reach, and timing advantage; (2) utilizes these popularity-oriented rationales to enrich the input features; and (3) regresses on these inputs. To facilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated from social media. Across diverse regressor-LLM combinations, BuzzProphet reduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while producing human-readable rationales. Results demonstrate that using LLMs as context reasoners rather than numeric predictors injects domain insight into tabular models, yielding an interpretable and deployable solution for social media trend forecasting.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08481","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.318741","language":"en","tags":["cssi","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Yifei Xu, Jiaying Wu, Herun Wan, Yang Li, Zhen Hou, Min-Yen Kan","raw_content_length":1157,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["LLM","BuzzProphet"],"persons":[],"locations":["HashView"],"monetary":["millions of dollars"]},"char_count":1156,"language_detected":"en","key_concepts":{"key_phrases":["the Buzz","Hashtag Popularity Prediction","LLM Reasoning","arXiv251008481v1 Announce Type","new Abstract","campaigns","public opinion","millions","dollars","advertising spend"],"filter_categories":{"ai_ml":["LLM Reasoning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Buzz":2.0,"Hashtag Popularity Prediction":2.0,"LLM Reasoning":2.0,"arXiv251008481v1 Announce Type":1.0,"new Abstract":1.0,"campaigns":1.0,"public opinion":1.0,"millions":1.0,"dollars":1.0,"advertising spend":1.0}},"age_hours":2.776246,"is_recent":true,"quality_score":1.0,"sentiment_score":8.937999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7876,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8666,"joy":0.022,"surprise":0.0661,"sadness":0.0029,"fear":0.0177,"anger":0.0215,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework (BuzzProphet) for predicting hashtag popularity using LLMs. While it shows a 2.8% reduction in RMSE and a 30% boost in correlation over baselines, it's still in the research phase with no actual deployment or measurable environmental impact. The focus is on improving prediction accuracy, not directly addressing climate change or other sustainability issues.","key_impact_metrics":["RMSE reduced by 2.8%","Correlation boosted by 30%"],"technology_tags":["Large Language Models","Social Media Analysis"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-28T20:45:39.054613Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_759fb35e5f1b","title":"The Visual Iconicity Challenge: Evaluating Vision","content":"arXiv:2510.08482v1 Announce Type: new Abstract: Iconicity, the resemblance between linguistic form and meaning, is pervasive in signed languages, offering a natural testbed for visual grounding. For vision-language models (VLMs), the challenge is to recover such essential mappings from dynamic human motion rather than static context. We introduce the \\textit{Visual Iconicity Challenge}, a novel video-based benchmark that adapts psycholinguistic measures to evaluate VLMs on three tasks: (i) phonological sign-form prediction (e.g., handshape, location), (ii) transparency (inferring meaning from visual form), and (iii) graded iconicity ratings. We assess $13$ state-of-the-art VLMs in zero- and few-shot settings on Sign Language of the Netherlands and compare them to human baselines. On \\textit{phonological form prediction}, VLMs recover some handshape and location detail but remain below human performance; on \\textit{transparency}, they are far from human baselines; and only top models correlate moderately with human \\textit{iconicity ratings}. Interestingly, \\textit{models with stronger phonological form prediction correlate better with human iconicity judgment}, indicating shared sensitivity to visually grounded structure. Our findings validate these diagnostic tasks and motivate human-centric signals and embodied learning methods for modelling iconicity and improving visual grounding in multimodal models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08482","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.319452","language":"en","tags":["cscl","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Onur Kele\\c{s}, Asl{\\i} \\\"Ozy\\\"urek, Gerardo Ortega, Kadir G\\\"okg\\\"o, Esam Ghaleb","raw_content_length":1429,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":["Netherlands"],"monetary":["$13$"]},"char_count":1428,"language_detected":"en","key_concepts":{"key_phrases":["The Visual Iconicity Challenge","Vision","VLMs","arXiv251008482v1 Announce Type","new Abstract","Iconicity","the resemblance","linguistic form","meaning","signed languages"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Visual Iconicity Challenge":2.0,"Vision":2.0,"VLMs":2.0,"arXiv251008482v1 Announce Type":1.0,"new Abstract":1.0,"Iconicity":1.0,"the resemblance":1.0,"linguistic form":1.0,"meaning":1.0,"signed languages":1.0}},"age_hours":2.7762612583333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.259500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8519,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7682,"joy":0.034,"surprise":0.0284,"sadness":0.0043,"fear":0.1118,"anger":0.0365,"disgust":0.0168},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel video-based benchmark to evaluate VLMs on sign language understanding. While it doesn't directly address climate change, it could indirectly contribute to sustainability by improving communication accessibility and potentially enabling more efficient resource management in the future. The evidence strength is moderate, based on the performance of 13 VLMs on the benchmark.","key_impact_metrics":["Correlation with human iconicity ratings","Performance on phonological form prediction"],"technology_tags":["Vision-Language Models","Sign Language Processing"],"sdg_alignment":[4,10],"analyzed_at":"2025-10-28T20:45:41.763788Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1e71785aed3c","title":"DeepPrune: Parallel Scaling without Inter","content":"arXiv:2510.08483v1 Announce Type: new Abstract: Parallel scaling has emerged as a powerful paradigm to enhance reasoning capabilities in large language models (LLMs) by generating multiple Chain-of-Thought (CoT) traces simultaneously. However, this approach introduces significant computational inefficiency due to inter-trace redundancy -- our analysis reveals that over 80% of parallel reasoning traces yield identical final answers, representing substantial wasted computation. To address this critical efficiency bottleneck, we propose DeepPrune, a novel framework that enables efficient parallel scaling through dynamic pruning. Our method features a specialized judge model trained with focal loss and oversampling techniques to accurately predict answer equivalence from partial reasoning traces which realizes 0.87 AUROC on equivalence prediction, combined with an online greedy clustering algorithm that dynamically prunes redundant paths while preserving answer diversity. Comprehensive evaluations across three challenging benchmarks (AIME 2024, AIME 2025, and GPQA) and multiple reasoning models demonstrate that DeepPrune achieves remarkable token reduction by over 80% compared to conventional consensus sampling on most cases, while maintaining competitive accuracy within 3 percentage points. Our work establishes a new standard for efficient parallel reasoning, making high-performance reasoning more efficient. Our code and data are here: https://deepprune.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08483","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.319860","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Shangqing Tu, Yaxuan Li, Yushi Bai, Lei Hou, Juanzi Li","raw_content_length":1486,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["CoT","DeepPrune"],"persons":[],"locations":[],"monetary":[]},"char_count":1485,"language_detected":"en","key_concepts":{"key_phrases":["DeepPrune","Parallel Scaling","Inter","arXiv251008483v1 Announce Type","new Abstract","Parallel scaling","a powerful paradigm","reasoning capabilities","large language models","LLMs"],"filter_categories":{"engineering":["Inter"],"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepPrune":2.0,"Parallel Scaling":2.0,"Inter":2.0,"arXiv251008483v1 Announce Type":1.0,"new Abstract":1.0,"Parallel scaling":1.0,"a powerful paradigm":1.0,"reasoning capabilities":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.776274991666667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7053,"joy":0.0138,"surprise":0.0731,"sadness":0.0797,"fear":0.0052,"anger":0.0581,"disgust":0.0648},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework, DeepPrune, for reducing computational inefficiency in large language models, leading to potential energy savings. The framework achieves over 80% token reduction compared to conventional methods while maintaining competitive accuracy. This is currently in the applied research stage, with evaluations on benchmarks but no real-world deployment data.","key_impact_metrics":["80% token reduction","0.87 AUROC on equivalence prediction"],"technology_tags":["Deep Learning","Large Language Models","Energy Efficiency"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-28T20:45:44.717557Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eec94de63f9b","title":"InstructX: Towards Unified Visual Editing with MLLM Guidance","content":"arXiv:2510.08485v1 Announce Type: new Abstract: With recent advances in Multimodal Large Language Models (MLLMs) showing strong visual understanding and reasoning, interest is growing in using them to improve the editing performance of diffusion models. Despite rapid progress, most studies lack an in-depth analysis of MLLM design choices. Moreover, the integration of MLLMs and diffusion models remains an open challenge in some difficult tasks, such as video editing. In this paper, we present InstructX, a unified framework for image and video editing. Specifically, we conduct a comprehensive study on integrating MLLMs and diffusion models for instruction-driven editing across diverse tasks. Building on this study, we analyze the cooperation and distinction between images and videos in unified modeling. (1) We show that training on image data can lead to emergent video editing capabilities without explicit supervision, thereby alleviating the constraints imposed by scarce video training data. (2) By incorporating modality-specific MLLM features, our approach effectively unifies image and video editing tasks within a single model. Extensive experiments demonstrate that our method can handle a broad range of image and video editing tasks and achieves state-of-the-art performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08485","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.320250","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Chong Mou, Qichao Sun, Yanze Wu, Pengze Zhang, Xinghui Li, Fulong Ye, Songtao Zhao, Qian He","raw_content_length":1297,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Large Language Models"],"persons":["Guidance arXiv:2510.08485v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1296,"language_detected":"en","key_concepts":{"key_phrases":["Unified Visual Editing","MLLM Guidance","MLLMs","diffusion models","new Abstract","recent advances","Multimodal Large Language Models","strong visual understanding","reasoning","interest"],"filter_categories":{"ai_ml":["MLLM Guidance","Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unified Visual Editing":2.0,"MLLM Guidance":2.0,"MLLMs":2.0,"diffusion models":2.0,"new Abstract":1.0,"recent advances":1.0,"Multimodal Large Language Models":1.0,"strong visual understanding":1.0,"reasoning":1.0,"interest":1.0}},"age_hours":2.7762897475,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7495,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7499,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8475,"joy":0.0379,"surprise":0.042,"sadness":0.0096,"fear":0.0232,"anger":0.0277,"disgust":0.0122},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (InstructX) for image and video editing using MLLMs and diffusion models. The concrete action is the development and testing of this framework, showing emergent video editing capabilities from image data training. However, it's still in the research phase with no deployed units or real-world data beyond experimental results, hence the low deployment readiness.","key_impact_metrics":["State-of-the-art performance in image and video editing"],"technology_tags":["Multimodal Large Language Models","Diffusion Models","Image Editing","Video Editing"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:45:47.484710Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a624ebdc2961","title":"A Rate","content":"arXiv:2510.08487v1 Announce Type: new Abstract: This paper addresses the fundamental performance limits of Integrated Sensing and Communication (ISAC) systems by introducing a novel converse bound based on rate-distortion theory. This rate-distortion bound (RDB) overcomes the restrictive regularity conditions of classical estimation theory, such as the Bayesian Cram\\'er-Rao Bound (BCRB). The proposed framework is broadly applicable, holding for arbitrary parameter distributions and distortion measures, including mean-squared error and probability of error. The bound is proved to be tight in the high sensing noise regime and can be strictly tighter than the BCRB in the low sensing noise regime. The RDB's utility is demonstrated on two challenging scenarios: Nakagami fading channel estimation, where it provides a valid bound even when the BCRB is inapplicable, and a binary occupancy detection task, showcasing its versatility for discrete sensing problems. This work provides a powerful and general tool for characterizing the ultimate performance tradeoffs in ISAC systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08487","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.320663","language":"en","tags":["mathit","computer-science","preprints","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Mohammadreza Bakhshizadeh Mohajer, Alex Dytso, Daniela Tuninetti, Luca Barletta","raw_content_length":1086,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["Integrated Sensing and Communication","RDB"],"persons":["Nakagami"],"locations":[],"monetary":[]},"char_count":1085,"language_detected":"en","key_concepts":{"key_phrases":["A Rate","Announce Type","new Abstract","This paper","the fundamental performance limits","Integrated Sensing and Communication ISAC systems","a novel converse","rate-distortion theory","This rate-distortion","RDB"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Rate":2.0,"Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"the fundamental performance limits":1.0,"Integrated Sensing and Communication ISAC systems":1.0,"a novel converse":1.0,"rate-distortion theory":1.0,"This rate-distortion":1.0,"RDB":1.0}},"age_hours":2.7763040519444444,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8174,"joy":0.0576,"surprise":0.0939,"sadness":0.0052,"fear":0.0056,"anger":0.0141,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for optimizing Integrated Sensing and Communication (ISAC) systems. While it offers a novel approach to performance limits, it remains at the theoretical stage with no concrete deployment or measured outcomes. The impact on climate is indirect, potentially improving resource allocation in future communication systems, but without quantification.","key_impact_metrics":[],"technology_tags":["Integrated Sensing and Communication","Rate-Distortion Theory"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:50.226114Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_57a1843fc195","title":"Implementing Semantic Join Operators Efficiently","content":"arXiv:2510.08489v1 Announce Type: new Abstract: Semantic query processing engines often support semantic joins, enabling users to match rows that satisfy conditions specified in natural language. Such join conditions can be evaluated using large language models (LLMs) that solve novel tasks without task-specific training. Currently, many semantic query processing engines implement semantic joins via nested loops, invoking the LLM to evaluate the join condition on row pairs. Instead, this paper proposes a novel algorithm, inspired by the block nested loops join operator implementation in traditional database systems. The proposed algorithm integrates batches of rows from both input tables into a single prompt. The goal of the LLM invocation is to identify all matching row pairs in the current input. The paper introduces formulas that can be used to optimize the size of the row batches, taking into account constraints on the size of the LLM context window (limiting both input and output size). An adaptive variant of the proposed algorithm refers to cases in which the size of the output is difficult to estimate. A formal analysis of asymptotic processing costs, as well as empirical results, demonstrates that the proposed approach reduces costs significantly and performs well compared to join implementations used by recent semantic query processing engines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08489","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.321070","language":"en","tags":["csdb","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Immanuel Trummer","raw_content_length":1378,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["LLM","Implementing Semantic Join Operators"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Semantic Join Operators","semantic joins","arXiv251008489v1 Announce Type","new Abstract","Semantic query processing engines","users","rows","that satisfy conditions","natural language","Such join conditions"],"filter_categories":{"ai_ml":["natural language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Semantic Join Operators":2.0,"semantic joins":2.0,"arXiv251008489v1 Announce Type":1.0,"new Abstract":1.0,"Semantic query processing engines":1.0,"users":1.0,"rows":1.0,"that satisfy conditions":1.0,"natural language":1.0,"Such join conditions":1.0}},"age_hours":2.776318325833333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.7795,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9559,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9123,"joy":0.0325,"surprise":0.0303,"sadness":0.0033,"fear":0.0029,"anger":0.0118,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel algorithm to improve the efficiency of semantic joins using LLMs, potentially reducing computational costs. The paper includes a formal analysis of asymptotic processing costs and empirical results demonstrating significant cost reductions compared to existing implementations. However, it's still in the research phase with no deployed technology or real-world data available.","key_impact_metrics":["Processing cost reduction","LLM context window size optimization"],"technology_tags":["Large Language Models","Semantic Query Processing","Database Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:53.580182Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_791f5f71a554","title":"Splat the Net: Radiance Fields with Splattable Neural Primitives","content":"arXiv:2510.08491v1 Announce Type: new Abstract: Radiance fields have emerged as a predominant representation for modeling 3D scene appearance. Neural formulations such as Neural Radiance Fields provide high expressivity but require costly ray marching for rendering, whereas primitive-based methods such as 3D Gaussian Splatting offer real-time efficiency through splatting, yet at the expense of representational power. Inspired by advances in both these directions, we introduce splattable neural primitives, a new volumetric representation that reconciles the expressivity of neural models with the efficiency of primitive-based splatting. Each primitive encodes a bounded neural density field parameterized by a shallow neural network. Our formulation admits an exact analytical solution for line integrals, enabling efficient computation of perspectively accurate splatting kernels. As a result, our representation supports integration along view rays without the need for costly ray marching. The primitives flexibly adapt to scene geometry and, being larger than prior analytic primitives, reduce the number required per scene. On novel-view synthesis benchmarks, our approach matches the quality and speed of 3D Gaussian Splatting while using $10\\times$ fewer primitives and $6\\times$ fewer parameters. These advantages arise directly from the representation itself, without reliance on complex control or adaptation frameworks. The project page is https://vcai.mpi-inf.mpg.de/projects/SplatNet/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08491","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.321493","language":"en","tags":["csgr","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Xilong Zhou, Bao-Huy Nguyen, Lo\\\"ic Magne, Vladislav Golyanik, Thomas Leimk\\\"uhler, Christian Theobalt","raw_content_length":1505,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":["Splattable Neural Primitives arXiv:2510.08491v1 Announce Type"],"persons":["Radiance Fields","Gaussian Splatting"],"locations":[],"monetary":[]},"char_count":1504,"language_detected":"en","key_concepts":{"key_phrases":["Splat","the Net","Radiance Fields","Splattable Neural Primitives","arXiv251008491v1 Announce Type","new Abstract","Radiance fields","a predominant representation","modeling 3D scene appearance","Neural formulations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Splat":2.0,"the Net":2.0,"Radiance Fields":2.0,"Splattable Neural Primitives":2.0,"arXiv251008491v1 Announce Type":1.0,"new Abstract":1.0,"Radiance fields":1.0,"a predominant representation":1.0,"modeling 3D scene appearance":1.0,"Neural formulations":1.0}},"age_hours":2.776332531111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3825,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8893,"joy":0.0174,"surprise":0.0473,"sadness":0.0058,"fear":0.0065,"anger":0.0203,"disgust":0.0133},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for 3D scene rendering. While it claims to reduce computational resource usage by 6x fewer parameters and 10x fewer primitives, the connection to direct GHG emission reduction is theoretical at this stage. It is currently in the basic research stage with no deployment.","key_impact_metrics":["6x fewer parameters","10x fewer primitives"],"technology_tags":["neural radiance fields","3D Gaussian Splatting","neural networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:56.679977Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7c83a668c146","title":"Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models","content":"arXiv:2510.08492v1 Announce Type: new Abstract: Traditional multimodal learners find unified representations for tasks like visual question answering, but rely heavily on paired datasets. However, an overlooked yet potentially powerful question is: can one leverage auxiliary unpaired multimodal data to directly enhance representation learning in a target modality? We introduce UML: Unpaired Multimodal Learner, a modality-agnostic training paradigm in which a single model alternately processes inputs from different modalities while sharing parameters across them. This design exploits the assumption that different modalities are projections of a shared underlying reality, allowing the model to benefit from cross-modal structure without requiring explicit pairs. Theoretically, under linear data-generating assumptions, we show that unpaired auxiliary data can yield representations strictly more informative about the data-generating process than unimodal training. Empirically, we show that using unpaired data from auxiliary modalities -- such as text, audio, or images -- consistently improves downstream performance across diverse unimodal targets such as image and audio. Our project page: https://unpaired-multimodal.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.08492","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.321887","language":"en","tags":["computer-science","cslg","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Sharut Gupta, Shobhita Sundaram, Chenyu Wang, Stefanie Jegelka, Phillip Isola","raw_content_length":1242,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["linear","UML"],"persons":[],"locations":[],"monetary":[]},"char_count":1241,"language_detected":"en","key_concepts":{"key_phrases":["Unpaired Multimodal Data","Stronger Unimodal Models","Announce Type","new Abstract","Traditional multimodal learners","unified representations","tasks","visual question","paired datasets","an overlooked yet potentially powerful question"],"filter_categories":{"ai_ml":["Unpaired Multimodal Data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unpaired Multimodal Data":2.0,"Stronger Unimodal Models":2.0,"Announce Type":1.0,"new Abstract":1.0,"Traditional multimodal learners":1.0,"unified representations":1.0,"tasks":1.0,"visual question":1.0,"paired datasets":1.0,"an overlooked yet potentially powerful question":1.0}},"age_hours":2.776346458611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.169,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8338,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8923,"joy":0.0134,"surprise":0.0422,"sadness":0.0072,"fear":0.0148,"anger":0.0178,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning approach to improve unimodal models using unpaired multimodal data. While the theoretical results and empirical improvements are promising, it is still in the early stages of research and lacks concrete deployment or quantified climate impact. The vaporware flag is raised due to the lack of deployed units or operational data.","key_impact_metrics":["Downstream performance improvement across unimodal targets"],"technology_tags":["Machine Learning","Multimodal Learning","Representation Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:45:59.063937Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
