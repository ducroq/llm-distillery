{"id":"science_arxiv_cs_1756af5a9806","title":"LLM$\\times$MapReduce-V3: Enabling Interactive In","content":"arXiv:2510.10890v1 Announce Type: new Abstract: We introduce LLM x MapReduce-V3, a hierarchically modular agent system designed for long-form survey generation. Building on the prior work, LLM x MapReduce-V2, this version incorporates a multi-agent architecture where individual functional components, such as skeleton initialization, digest construction, and skeleton refinement, are implemented as independent model-context-protocol (MCP) servers. These atomic servers can be aggregated into higher-level servers, creating a hierarchically structured system. A high-level planner agent dynamically orchestrates the workflow by selecting appropriate modules based on their MCP tool descriptions and the execution history. This modular decomposition facilitates human-in-the-loop intervention, affording users greater control and customization over the research process. Through a multi-turn interaction, the system precisely captures the intended research perspectives to generate a comprehensive skeleton, which is then developed into an in-depth survey. Human evaluations demonstrate that our system surpasses representative baselines in both content depth and length, highlighting the strength of MCP-based modular planning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10890","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.812681","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Yu Chao, Siyu Lin, xiaorong wang, Zhu Zhang, Zihan Zhou, Haoyu Wang, Shuo Wang, Jie Zhou, Zhiyuan Liu, Maosong Sun","raw_content_length":1229,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["MCP"],"persons":["Announce Type","LLM$\\times$MapReduce-V3"],"locations":[],"monetary":[]},"char_count":1228,"language_detected":"en","key_concepts":{"key_phrases":["LLMtimesMapReduce-V3","Enabling Interactive","arXiv251010890v1 Announce Type","new Abstract","LLM x MapReduce-V3","a hierarchically modular agent system","long-form survey generation","the prior work","this version","a multi-agent architecture"],"filter_categories":{"ai_ml":["LLMtimesMapReduce-V3"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMtimesMapReduce-V3":2.0,"Enabling Interactive":2.0,"arXiv251010890v1 Announce Type":1.0,"new Abstract":1.0,"LLM x MapReduce-V3":1.0,"a hierarchically modular agent system":1.0,"long-form survey generation":1.0,"the prior work":1.0,"this version":1.0,"a multi-agent architecture":1.0}},"age_hours":2.754600811388889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8644,"joy":0.0438,"surprise":0.0682,"sadness":0.0041,"fear":0.0055,"anger":0.0107,"disgust":0.0032},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI system for survey generation. While it demonstrates improved content depth and length compared to baselines, there are no concrete actions or measurable outcomes related to sustainability. The system is in the early stages of research and lacks deployment or quantifiable environmental benefits.","key_impact_metrics":[],"technology_tags":["LLM","MapReduce","Multi-Agent Systems"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:41:54.975465Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f54f84daba4","title":"Observability and parameter estimation of a generic model for aggregated distributed energy resources","content":"arXiv:2510.10892v1 Announce Type: new Abstract: We propose a novel framework for estimating the parameters of an aggregated distributed energy resources (der_a) model. First, we introduce a rigorous method to determine whether all model parameters are estimable. When they are not, our approach identifies the subset of parameters that can be estimated. The proposed framework offers new insights into the number and specific parameters that can be reliably estimated based on commonly available measurements. It also highlights the limitations of calibrating such models. Second, we introduce a Kalman filtering method to calibrate the der_a model. Since we account for nonlinear effects such as saturation and deadbands, we develop a specific mechanism to handle smoothing functions within the Kalman filter. Specifically, we consider the extended and the unscented Kalman filter. We demonstrate the effectiveness of the proposed framework on a modified IEEE 34-node distribution feeder with inverter-based resources. Our findings align with the North American Electric Reliability Corporation's parameterization guideline and underscore the importance of model calibration in accurately capturing the collective dynamics of distributed energy resources installed on distribution systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10892","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.813067","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Bukunmi Gabriel Odunlami, Marcos Netto","raw_content_length":1291,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1290,"language_detected":"en","key_concepts":{"key_phrases":["Observability and parameter estimation","a generic model","aggregated distributed energy resources","arXiv251010892v1 Announce Type","new Abstract","a novel framework","the parameters","an aggregated distributed energy resources","der_a model","a rigorous method"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Observability and parameter estimation":2.0,"a generic model":2.0,"aggregated distributed energy resources":2.0,"arXiv251010892v1 Announce Type":1.0,"new Abstract":1.0,"a novel framework":1.0,"the parameters":1.0,"an aggregated distributed energy resources":1.0,"der_a model":1.0,"a rigorous method":1.0}},"age_hours":2.754615481388889,"is_recent":true,"quality_score":0.7,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8685,"joy":0.0273,"surprise":0.0496,"sadness":0.0046,"fear":0.0103,"anger":0.0279,"disgust":0.0118},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":6,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework for estimating parameters of aggregated distributed energy resources (DERs), which can improve grid stability and integration of renewables. The framework is tested on a modified IEEE 34-node distribution feeder, providing some evidence of effectiveness. However, it is still in the applied research phase with no mention of real-world deployment or economic viability.","key_impact_metrics":["IEEE 34-node distribution feeder","Parameter estimation accuracy"],"technology_tags":["Distributed Energy Resources","Kalman Filtering","Parameter Estimation"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:41:57.911175Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4709cd228ec2","title":"An Adaptive Transition Framework for Game","content":"arXiv:2510.10893v1 Announce Type: new Abstract: The transition of control from autonomous systems to human drivers is critical in automated driving systems, particularly due to the out-of-the-loop (OOTL) circumstances that reduce driver readiness and increase reaction times. Existing takeover strategies are based on fixed time-based transitions, which fail to account for real-time driver performance variations. This paper proposes an adaptive transition strategy that dynamically adjusts the control authority based on both the time and tracking ability of the driver trajectory. Shared control is modeled as a cooperative differential game, where control authority is modulated through time-varying objective functions instead of blending control torques directly. To ensure a more natural takeover, a driver-specific state-tracking matrix is introduced, allowing the transition to align with individual control preferences. Multiple transition strategies are evaluated using a cumulative trajectory error metric. Human-in-the-loop control scenarios of the standardized ISO lane change maneuvers demonstrate that adaptive transitions reduce trajectory deviations and driver control effort compared to conventional strategies. Experiments also confirm that continuously adjusting control authority based on real-time deviations enhances vehicle stability while reducing driver effort during takeover.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10893","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.813460","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Dikshant Shehmar, Matthew E. Taylor, Ehsan Hashemi","raw_content_length":1405,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["OOTL"],"persons":[],"locations":[],"monetary":[]},"char_count":1404,"language_detected":"en","key_concepts":{"key_phrases":["An Adaptive Transition Framework","Game","arXiv251010893v1 Announce Type","new Abstract","The transition","control","autonomous systems","human drivers","automated driving systems","the-loop"],"filter_categories":{"engineering":["control"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Adaptive Transition Framework":2.0,"Game":2.0,"arXiv251010893v1 Announce Type":1.0,"new Abstract":1.0,"The transition":1.0,"control":1.0,"autonomous systems":1.0,"human drivers":1.0,"automated driving systems":1.0,"the-loop":1.0}},"age_hours":2.754629799444445,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8442,"joy":0.0056,"surprise":0.0283,"sadness":0.0131,"fear":0.0505,"anger":0.0346,"disgust":0.0235},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents an adaptive transition strategy for autonomous driving, showing reduced trajectory deviations and driver control effort in simulations. The research is peer-reviewed and uses a cumulative trajectory error metric, but it's still in the early stages of development with no deployed units or real-world validation. The impact on climate is indirect, potentially reducing fuel consumption through optimized driving, but not directly measured.","key_impact_metrics":["trajectory deviations reduction","driver control effort reduction"],"technology_tags":["autonomous driving","adaptive control","shared control"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T11:42:01.677585Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b84c92c71ced","title":"Multiscale Graph Reduction for Heterogeneous and Anisotropic Discrete Diffusion Processes","content":"arXiv:2510.10894v1 Announce Type: new Abstract: We present multiscale graph-based reduction algorithms for upscaling heterogeneous and anisotropic diffusion problems. The proposed coarsening approaches begin by constructing a partitioning of the computational domain into a set of balanced local subdomains, resulting in a standard type of domain decomposition. Given this initial decomposition, general coarsening techniques based on spectral clustering are applied within each subgraph in order to accurately identify the key microscopic features of a given system. The spectral clustering algorithm is based on local generalized eigen-decompositions applied to the signed graph Laplacian. The resulting coarse-fine splittings are combined with two variants of energy-minimizing strategies for constructing coarse bases for diffusion problems. The first is an unconstrained minimization formulation in which local harmonic extensions are applied column-wise to construct multi-vector preserving interpolation in each region, whereas the second approach is a variant of the constrained energy minimization formulations derived in the context of non-local multi-continua upscaling techniques. We apply the resulting upscaling algorithms to a variety of tests coming from the graph Laplacian, including diffusion in the perforated domain, channelized media, highly anisotropic settings, and discrete pore network models to demonstrate the potential and robustness of the proposed coarsening approaches. We show numerically and theoretically that the proposed approaches lead to accurate coarse-scale models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10894","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.813964","language":"en","tags":["computer-science","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Maria Vasilyeva, James Brannick, Ben S. Southworth","raw_content_length":1607,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Multiscale Graph Reduction"],"locations":[],"monetary":[]},"char_count":1606,"language_detected":"en","key_concepts":{"key_phrases":["Multiscale Graph Reduction","Heterogeneous and Anisotropic Discrete Diffusion Processes","arXiv251010894v1 Announce Type","new Abstract","multiscale graph-based reduction algorithms","heterogeneous and anisotropic diffusion problems","The proposed coarsening approaches","a partitioning","the computational domain","a set"],"filter_categories":{"ai_ml":["multiscale graph-based reduction algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multiscale Graph Reduction":2.0,"Heterogeneous and Anisotropic Discrete Diffusion Processes":2.0,"arXiv251010894v1 Announce Type":1.0,"new Abstract":1.0,"multiscale graph-based reduction algorithms":1.0,"heterogeneous and anisotropic diffusion problems":1.0,"The proposed coarsening approaches":1.0,"a partitioning":1.0,"the computational domain":1.0,"a set":1.0}},"age_hours":2.754643884722222,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8903,"joy":0.0208,"surprise":0.0429,"sadness":0.0057,"fear":0.0146,"anger":0.0168,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents algorithms for upscaling diffusion problems, potentially leading to more efficient simulations of various systems, including those relevant to climate modeling and resource management. The technical credibility is supported by numerical and theoretical validation, but economic viability and deployment readiness are low as it's still in the applied research phase. The impact is limited by the lack of real-world deployment and quantified environmental benefits.","key_impact_metrics":["Accurate coarse-scale models","Reduced computational cost"],"technology_tags":["Multiscale graph reduction","Spectral clustering","Domain decomposition"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:42:04.638890Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c188fed23f6c","title":"A Symmetric","content":"arXiv:2510.10901v1 Announce Type: new Abstract: Classical linear ciphers, such as the Hill cipher, operate on fixed, finite-dimensional modules and are therefore vulnerable to straightforward known-plaintext attacks that recover the key as a fully determined linear operator. We propose a symmetric-key cryptosystem whose linear action takes place instead in the Burnside ring $A(G)$ of a compact Lie group $G$, with emphasis on the case $G=O(2)$. The secret key consists of (i) a compact Lie group $G$; (ii) a secret total ordering of the subgroup orbit-basis of $A(G)$; and (iii) a finite set $S$ of indices of irreducible $G$-representations, whose associated basic degrees define an involutory multiplier $k\\in A(G)$. Messages of arbitrary finite length are encoded as finitely supported elements of $A(G)$ and encrypted via the Burnside product with $k$. For $G=O(2)$ we prove that encryption preserves plaintext support among the generators $\\{(D_1),\\dots,(D_L),(SO(2)),(O(2))\\}$, avoiding ciphertext expansion and security leakage. We then analyze security in passive models, showing that any finite set of observations constrains the action only on a finite-rank submodule $W_L\\subset A(O(2))$, and we show information-theoretic non-identifiability of the key from such data. Finally, we prove the scheme is \\emph{not} IND-CPA secure, by presenting a one-query chosen-plaintext distinguisher based on dihedral probes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10901","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.814940","language":"en","tags":["computer-science","mathra","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Ziad Ghanem","raw_content_length":1426,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Lie","Hill"],"persons":["A(G)$"],"locations":["Burnside"],"monetary":["$k$."]},"char_count":1425,"language_detected":"en","key_concepts":{"key_phrases":["A Symmetric","a compact Lie group","arXiv251010901v1 Announce Type","new Abstract","Classical linear ciphers","the Hill cipher","fixed finite-dimensional modules","straightforward known-plaintext attacks","the key","a fully determined linear operator"],"filter_categories":{"ai_ml":["straightforward known-plaintext attacks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Symmetric":2.0,"a compact Lie group":2.0,"arXiv251010901v1 Announce Type":1.0,"new Abstract":1.0,"Classical linear ciphers":1.0,"the Hill cipher":1.0,"fixed finite-dimensional modules":1.0,"straightforward known-plaintext attacks":1.0,"the key":1.0,"a fully determined linear operator":1.0}},"age_hours":2.754676024722222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.6260000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2748,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4822,"joy":0.009,"surprise":0.0184,"sadness":0.0195,"fear":0.4098,"anger":0.0306,"disgust":0.0305},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new symmetric-key cryptosystem. While cybersecurity is important, the direct impact on climate change or sustainability is minimal at this stage. The research is theoretical and has not been deployed.","key_impact_metrics":[],"technology_tags":["cryptography","symmetric-key cryptosystem"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:42:07.257966Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cb56c29e5716","title":"Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey","content":"arXiv:2510.10903v1 Announce Type: new Abstract: Embodied intelligence has witnessed remarkable progress in recent years, driven by advances in computer vision, natural language processing, and the rise of large-scale multimodal models. Among its core challenges, robot manipulation stands out as a fundamental yet intricate problem, requiring the seamless integration of perception, planning, and control to enable interaction within diverse and unstructured environments. This survey presents a comprehensive overview of robotic manipulation, encompassing foundational background, task-organized benchmarks and datasets, and a unified taxonomy of existing methods. We extend the classical division between high-level planning and low-level control by broadening high-level planning to include language, code, motion, affordance, and 3D representations, while introducing a new taxonomy of low-level learning-based control grounded in training paradigms such as input modeling, latent learning, and policy learning. Furthermore, we provide the first dedicated taxonomy of key bottlenecks, focusing on data collection, utilization, and generalization, and conclude with an extensive review of real-world applications. Compared with prior surveys, our work offers both a broader scope and deeper insight, serving as an accessible roadmap for newcomers and a structured reference for experienced researchers. All related resources, including research papers, open-source datasets, and projects, are curated for the community at https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10903","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.815758","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Shuanghao Bai, Wenxuan Song, Jiayi Chen, Yuheng Ji, Zhide Zhong, Jin Yang, Han Zhao, Wanqi Zhou, Wei Zhao, Zhe Li, Pengxiang Ding, Cheng Chi, Haoang Li, Chang Xu, Xiaolong Zheng, Donglin Wang, Shanghang Zhang, Badong Chen","raw_content_length":1588,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1587,"language_detected":"en","key_concepts":{"key_phrases":["a Unified Understanding","Robot Manipulation","A Comprehensive Survey","Announce Type","new Abstract","Embodied intelligence","remarkable progress","recent years","advances","computer vision"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"a Unified Understanding":2.0,"Robot Manipulation":2.0,"A Comprehensive Survey":2.0,"Announce Type":1.0,"new Abstract":1.0,"Embodied intelligence":1.0,"remarkable progress":1.0,"recent years":1.0,"advances":1.0,"computer vision":1.0}},"age_hours":2.754706484444444,"is_recent":true,"quality_score":0.7,"sentiment_score":9.540500000000002,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9081,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7485,"joy":0.0224,"surprise":0.1526,"sadness":0.0067,"fear":0.048,"anger":0.0147,"disgust":0.0072},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article is a survey of robotic manipulation, focusing on foundational background, benchmarks, datasets, and taxonomies. While it doesn't present deployed technology or measured outcomes, it does offer a structured reference for researchers, potentially accelerating advancements in robotics. The impact on sustainability is indirect, as it depends on how the developed robotic manipulation techniques are applied in real-world scenarios.","key_impact_metrics":[],"technology_tags":["robotics","manipulation","embodied intelligence","computer vision","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:42:11.031587Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a1be665f982","title":"PaperArena: An Evaluation Benchmark for Tool","content":"arXiv:2510.10909v1 Announce Type: new Abstract: Understanding and reasoning on the web-scale scientific literature is a crucial touchstone for large language model (LLM) based agents designed to support complex knowledge-intensive tasks. However, existing works are mainly restricted to tool-free tasks within isolated papers, largely due to the lack of a benchmark for cross-paper reasoning and multi-tool orchestration in real research scenarios. In this work, we propose PaperArena, an evaluation benchmark for agents to address real-world research questions that typically require integrating information across multiple papers with the assistance of external tools. Given a research question, agents should integrate diverse formats across multiple papers through reasoning and interacting with appropriate tools, thereby producing a well-grounded answer. To support standardized evaluation, we provide a modular and extensible platform for agent execution, offering tools such as multimodal parsing, context retrieval, and programmatic computation. Experimental results reveal that even the most advanced LLM powering a well-established agent system achieves merely 38.78% average accuracy. On the hard subset, accuracy drops to only 18.47%, highlighting great potential for improvement. We also present several empirical findings, including that all agents tested exhibit inefficient tool usage, often invoking more tools than necessary to solve a task. We invite the community to adopt PaperArena to develop and evaluate more capable agents for scientific discovery. Our code and data are available https://github.com/Melmaphother/PaperArena.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10909","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.816170","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Daoyu Wang, Mingyue Cheng, Qi Liu, Shuo Yu, Zirui Liu, Ze Guo","raw_content_length":1651,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["LLM","PaperArena"],"persons":[],"locations":[],"monetary":[]},"char_count":1650,"language_detected":"en","key_concepts":{"key_phrases":["PaperArena","An Evaluation Benchmark","Tool","arXiv251010909v1","Announce Type","new Abstract","Understanding","reasoning","the web-scale scientific literature","a crucial touchstone"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PaperArena":3.0,"An Evaluation Benchmark":2.0,"Tool":2.0,"arXiv251010909v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Understanding":1.0,"reasoning":1.0,"the web-scale scientific literature":1.0,"a crucial touchstone":1.0}},"age_hours":2.754721395555556,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7857,"joy":0.0133,"surprise":0.0207,"sadness":0.0087,"fear":0.0994,"anger":0.0477,"disgust":0.0245},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a benchmark for evaluating LLM agents in scientific research. While it aims to improve the efficiency of research, it doesn't directly address climate change or sustainability. The benchmark is in the early stages of development, with no deployed applications or measurable environmental outcomes.","key_impact_metrics":["Average accuracy 38.78%","Accuracy on hard subset 18.47%"],"technology_tags":["Large Language Models","Scientific Literature Analysis"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:42:14.098247Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f160d28156d","title":"SceneTextStylizer: A Training","content":"arXiv:2510.10910v1 Announce Type: new Abstract: With the rapid development of diffusion models, style transfer has made remarkable progress. However, flexible and localized style editing for scene text remains an unsolved challenge. Although existing scene text editing methods have achieved text region editing, they are typically limited to content replacement and simple styles, which lack the ability of free-style transfer. In this paper, we introduce SceneTextStylizer, a novel training-free diffusion-based framework for flexible and high-fidelity style transfer of text in scene images. Unlike prior approaches that either perform global style transfer or focus solely on textual content modification, our method enables prompt-guided style transformation specifically for text regions, while preserving both text readability and stylistic consistency. To achieve this, we design a feature injection module that leverages diffusion model inversion and self-attention to transfer style features effectively. Additionally, a region control mechanism is introduced by applying a distance-based changing mask at each denoising step, enabling precise spatial control. To further enhance visual quality, we incorporate a style enhancement module based on the Fourier transform to reinforce stylistic richness. Extensive experiments demonstrate that our method achieves superior performance in scene text style transformation, outperforming existing state-of-the-art methods in both visual fidelity and text preservation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10910","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.816594","language":"en","tags":["eessiv","computer-science","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Honghui Yuan, Keiji Yanai","raw_content_length":1523,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1522,"language_detected":"en","key_concepts":{"key_phrases":["SceneTextStylizer","A Training","arXiv251010910v1 Announce Type","new Abstract","the rapid development","diffusion models","style transfer","remarkable progress","flexible and localized style editing","scene text"],"filter_categories":{"ai_ml":["A Training"],"engineering":["the rapid development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SceneTextStylizer":3.0,"A Training":2.0,"arXiv251010910v1 Announce Type":1.0,"new Abstract":1.0,"the rapid development":1.0,"diffusion models":1.0,"style transfer":1.0,"remarkable progress":1.0,"flexible and localized style editing":1.0,"scene text":1.0}},"age_hours":2.7547360530555554,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8473,"joy":0.056,"surprise":0.0701,"sadness":0.0057,"fear":0.0092,"anger":0.0083,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for style transfer in scene text using diffusion models. While it improves visual fidelity and text preservation, its direct climate impact is minimal as it's primarily an image processing technique. The research is still in the early stages and lacks deployment or economic viability data.","key_impact_metrics":["Visual fidelity improvement","Text preservation rate"],"technology_tags":["Diffusion models","Style transfer","Image processing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:42:18.744646Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2d4eb2f95d4b","title":"Optimal Multi","content":"arXiv:2510.10914v1 Announce Type: new Abstract: The electrification of transportation represents a critical challenge in the global transition toward net-zero emissions, as the sector often accounts for more than one-quarter of national energy consumption. Achieving this transformation requires not only widespread adoption of electric vehicles (EVs) but also their seamless integration into interdependent infrastructure systems-specifically, the transportation-electricity nexus (TEN). This paper develops an optimal multi-modal transportation and electric power flow (OMTEPF) model to evaluate the benefits of coordinated, dynamic system operation. Building on recent advances in hetero-functional graph theory, the framework enables joint optimization of five key operational decisions in intelligent TEN management: vehicle dispatch, route choice, charging station queuing, coordinated charging, and vehicle-to-grid stabilization. The mesoscopic, dynamic model explicitly represents individual EVs and their state-of-charge trajectories, thereby extending beyond the prevailing literature's focus on static, macroscopic traffic assignment. It further captures the full scope of the TEN as a system-of-systems, incorporating five distinct charging modalities: private residential, private commercial, wired public commercial, inductive public, and discharging. On the power system side, an IV-ACOPF formulation ensures globally optimal solutions to the electrical subproblems. Comparative analysis demonstrates the substantial value of coordinated TEN operation relative to the status quo of siloed, uncoordinated infrastructure management. This work provides both a novel methodological contribution and actionable insights for the co-design and operation of next-generation sustainable mobility-energy systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10914","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.817775","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Jiajie Qiu, Dakota Thompson, Kamal Youcef-Toumi, Amro M. Farid","raw_content_length":1818,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["TEN"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1817,"language_detected":"en","key_concepts":{"key_phrases":["Optimal Multi","arXiv251010914v1 Announce Type","new Abstract","The electrification","transportation","a critical challenge","the global transition","net-zero emissions","the sector","national energy consumption"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Optimal Multi":2.0,"arXiv251010914v1 Announce Type":1.0,"new Abstract":1.0,"The electrification":1.0,"transportation":1.0,"a critical challenge":1.0,"the global transition":1.0,"net-zero emissions":1.0,"the sector":1.0,"national energy consumption":1.0}},"age_hours":2.754780147777778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8818,"joy":0.025,"surprise":0.0736,"sadness":0.0049,"fear":0.0064,"anger":0.006,"disgust":0.0023},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":6,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel model for optimizing transportation and electricity flow, aiming to reduce emissions through coordinated EV charging and grid stabilization. While the model is promising and builds on hetero-functional graph theory, it is still in the research phase with no mention of deployed units or real-world data. The vaporware flag is set because it is a model and not a deployed technology.","key_impact_metrics":[],"technology_tags":["electric vehicles","vehicle-to-grid","power flow optimization"],"sdg_alignment":[7,9,11,13],"analyzed_at":"2025-10-29T11:42:22.674454Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a9d990475ac9","title":"Find Your Optimal Teacher: Personalized Data Synthesis via Router","content":"arXiv:2510.10925v1 Announce Type: new Abstract: Training student models on synthetic data generated by strong teacher models is a promising way to distilling the capabilities of teachers. However, recent studies show that stronger models are not always optimal teachers, revealing a mismatch between teacher outputs and student learnability. To address this issue, we propose PerSyn (Personalized data Synthesis), a novel synthesis strategy that operates under a new ``Route then Generate'' paradigm to create data tailored to each student model, enabling it to learn more effectively. Specifically, PerSyn first assigns each prompt to its optimal teacher via a query-level router that jointly considers student learnability and teacher response quality. Each teacher then synthesizes data only for its assigned prompts, making the process more efficient than the conventional ``Generate then Select'' paradigm, where all teachers must generate parallel responses for the entire prompt set before constructing the final dataset. Extensive experiments across different model families and scales demonstrate that PerSyn consistently achieves superior or comparable performance to all baselines in instruct tuning and math reasoning settings. Further analysis verifies the effectiveness of PerSyn and offers extra insights to propel future research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10925","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.824978","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Hengyuan Zhang, Shiping Yang, Xiao Liang, Chenming Shang, Yuxuan Jiang, Chaofan Tao, Jing Xiong, Hayden Kwok-Hay So, Ruobing Xie, Angel X. Chang, Ngai Wong","raw_content_length":1347,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["Router arXiv:2510.10925v1 Announce Type: new Abstract","PerSyn","Synthesis"],"persons":["Generate"],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["Your Optimal Teacher","Personalized Data Synthesis","Router","arXiv251010925v1 Announce Type","new Abstract","Training student models","synthetic data","strong teacher models","a promising way","the capabilities"],"filter_categories":{"ai_ml":["Training student models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Your Optimal Teacher":2.0,"Personalized Data Synthesis":2.0,"Router":2.0,"arXiv251010925v1 Announce Type":1.0,"new Abstract":1.0,"Training student models":1.0,"synthetic data":1.0,"strong teacher models":1.0,"a promising way":1.0,"the capabilities":1.0}},"age_hours":2.7548540138888886,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4155,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8831,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9155,"joy":0.0155,"surprise":0.0263,"sadness":0.01,"fear":0.0132,"anger":0.0133,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a new method for training student models using synthetic data. While it demonstrates improved performance in instruct tuning and math reasoning settings, it's currently in the research phase with no deployed technology or measurable environmental outcomes. The potential climate impact is indirect, relying on the assumption that improved AI models could eventually contribute to sustainability efforts.","key_impact_metrics":["Superior performance compared to baselines in instruct tuning","Superior performance compared to baselines in math reasoning"],"technology_tags":["Personalized Data Synthesis","Machine Learning","AI Model Training"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:42:25.728996Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_32c13385b216","title":"GapDNER: A Gap","content":"arXiv:2510.10927v1 Announce Type: new Abstract: In biomedical fields, one named entity may consist of a series of non-adjacent tokens and overlap with other entities. Previous methods recognize discontinuous entities by connecting entity fragments or internal tokens, which face challenges of error propagation and decoding ambiguity due to the wide variety of span or word combinations. To address these issues, we deeply explore discontinuous entity structures and propose an effective Gap-aware grid tagging model for Discontinuous Named Entity Recognition, named GapDNER. Our GapDNER innovatively applies representation learning on the context gaps between entity fragments to resolve decoding ambiguity and enhance discontinuous NER performance. Specifically, we treat the context gap as an additional type of span and convert span classification into a token-pair grid tagging task. Subsequently, we design two interactive components to comprehensively model token-pair grid features from both intra- and inter-span perspectives. The intra-span regularity extraction module employs the biaffine mechanism along with linear attention to capture the internal regularity of each span, while the inter-span relation enhancement module utilizes criss-cross attention to obtain semantic relations among different spans. At the inference stage of entity decoding, we assign a directed edge to each entity fragment and context gap, then use the BFS algorithm to search for all valid paths from the head to tail of grids with entity tags. Experimental results on three datasets demonstrate that our GapDNER achieves new state-of-the-art performance on discontinuous NER and exhibits remarkable advantages in recognizing complex entity structures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10927","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.825402","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Yawen Yang, Fukun Ma, Shiao Meng, Aiwei Liu, Lijie Wen","raw_content_length":1744,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":["NER"],"persons":["GapDNER"],"locations":[],"monetary":[]},"char_count":1743,"language_detected":"en","key_concepts":{"key_phrases":["GapDNER","A Gap","arXiv251010927v1 Announce Type","new Abstract","biomedical fields","entity","a series","non-adjacent tokens","other entities","Previous methods"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GapDNER":2.0,"A Gap":2.0,"arXiv251010927v1 Announce Type":1.0,"new Abstract":1.0,"biomedical fields":1.0,"entity":1.0,"a series":1.0,"non-adjacent tokens":1.0,"other entities":1.0,"Previous methods":1.0}},"age_hours":2.7548685930555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9125,"joy":0.0038,"surprise":0.0258,"sadness":0.0106,"fear":0.0209,"anger":0.0156,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel method (GapDNER) for discontinuous named entity recognition in biomedical fields. While the research is technically sound and published on arXiv, it is still in the basic research phase with no deployed applications or measurable environmental outcomes. The impact on sustainability is indirect and currently theoretical.","key_impact_metrics":["State-of-the-art performance on discontinuous NER","Advantage in recognizing complex entity structures"],"technology_tags":["Named Entity Recognition","Machine Learning","Natural Language Processing"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:42:28.671051Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4a8ef151b300","title":"Achieving Coordination in Non","content":"arXiv:2510.10929v1 Announce Type: new Abstract: We analyze an infinite-horizon deterministic joint replenishment model from a non-cooperative game-theoretical approach. In this model, a group of retailers can choose to jointly place an order, which incurs a major setup cost independent of the group, and a minor setup cost for each retailer. Additionally, each retailer is associated with a holding cost. Our objective is to design cost allocation rules that minimize the long-run average system cost while accounting for the fact that each retailer independently selects its replenishment interval to minimize its own cost. We introduce a class of cost allocation rules that distribute the major setup cost among the associated retailers in proportion to their predefined weights. For these rules, we establish a monotonicity property of agent better responses, which enables us to prove the existence of a payoff dominant pure Nash equilibrium that can also be computed efficiently. We then analyze the efficiency of these equilibria by examining the price of stability (PoS), the ratio of the best Nash equilibrium's system cost to the social optimum, across different information settings. In particular, our analysis reveals that one rule, which leverages retailers' own holding cost rates, achieves a near-optimal PoS of 1.25, while another rule that does not require access to retailers' private information also yields a favorable PoS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10929","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.825833","language":"en","tags":["research","csgt","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Junjie Luo, Changjun Wang","raw_content_length":1445,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1444,"language_detected":"en","key_concepts":{"key_phrases":["Coordination","Non","each retailer","Announce Type","new Abstract","an infinite-horizon deterministic joint replenishment model","a non-cooperative game-theoretical approach","this model","a group","retailers"],"filter_categories":{"ai_ml":["each retailer"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Coordination":2.0,"Non":2.0,"each retailer":2.0,"Announce Type":1.0,"new Abstract":1.0,"an infinite-horizon deterministic joint replenishment model":1.0,"a non-cooperative game-theoretical approach":1.0,"this model":1.0,"a group":1.0,"retailers":1.0}},"age_hours":2.754883776111111,"is_recent":true,"quality_score":0.7,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.914,"joy":0.0218,"surprise":0.0363,"sadness":0.0058,"fear":0.0057,"anger":0.0115,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes a joint replenishment model, aiming to minimize long-run average system cost through optimized cost allocation rules. While the research could potentially lead to more efficient supply chains and reduced waste, it is currently theoretical and lacks concrete deployment or quantified environmental impact. The analysis is based on a deterministic model and does not provide real-world data or validation.","key_impact_metrics":[],"technology_tags":["supply chain optimization","game theory","cost allocation"],"sdg_alignment":[12],"analyzed_at":"2025-10-29T11:42:31.450487Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d7a8246a1d4a","title":"Evaluating Language Models' Evaluations of Games","content":"arXiv:2510.10930v1 Announce Type: new Abstract: Reasoning is not just about solving problems -- it is also about evaluating which problems are worth solving at all. Evaluations of artificial intelligence (AI) systems primarily focused on problem solving, historically by studying how models play games such as chess and Go. In this paper, we advocate for a new paradigm that assesses AI systems' evaluation of games. First, we introduce a formalism for evaluating such evaluations. We then leverage a large-scale dataset of over $100$ novel board games and over 450 human judgments to compare evaluations produced by modern language and reasoning models against those of people and symbolic computational agents. We consider two kinds of evaluative queries: assessing the payoff (or fairness) and the funness of games. These queries span two dimensions relevant to the design of evaluations of AI evaluations: how complex a query is to compute and how difficult a query is to quantify. Our results show that reasoning models are generally more aligned to people in their evaluations of games than non-reasoning language models. However, we observe a non-monotonic relationship: as models get closer to game-theoretic optimal, their fit to human data weakens. We also observe more \"jaggedness\" across models for assessing funness, in line with the greater difficulty of quantifying this query. Across queries and games, reasoning models show highly variable and unpredictable resource usage when assessing queries, pointing to the importance of imbuing more resource-rational meta-reasoning in language and reasoning models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10930","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.826251","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":244,"author":"Katherine M. Collins, Cedegao E. Zhang, Graham Todd, Lance Ying, Mauricio Barba da Costa, Ryan Liu, Prafull Sharma, Adrian Weller, Ionatan Kuperwajs, Lionel Wong, Joshua B. Tenenbaum, Thomas L. Griffiths","raw_content_length":1624,"priority":7,"update_frequency":1,"reading_time_minutes":1.22,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":["over $100$"]},"char_count":1623,"language_detected":"en","key_concepts":{"key_phrases":["Evaluating Language Models Evaluations","Games","games","arXiv251010930v1","Announce Type","new Abstract","Reasoning","problems","which problems","Evaluations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Evaluating Language Models Evaluations":2.0,"Games":2.0,"games":2.0,"arXiv251010930v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Reasoning":1.0,"problems":1.0,"which problems":1.0,"Evaluations":1.0}},"age_hours":2.754899368611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.8335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5667,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9078,"joy":0.0197,"surprise":0.0161,"sadness":0.0043,"fear":0.0149,"anger":0.0243,"disgust":0.0129},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on evaluating language models' ability to evaluate games, including fairness and funness. The concrete action is the comparison of language model evaluations against human judgments using a dataset of 100 novel board games and 450 human judgments. The evidence is based on a large-scale dataset and comparison with symbolic computational agents, but it is still in the basic research stage with no direct deployment or measurable environmental impact.","key_impact_metrics":["100 novel board games","450 human judgments"],"technology_tags":["Language Models","AI Evaluation","Reasoning Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:42:34.287220Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1c260bcaca2a","title":"PoU: Proof-of","content":"arXiv:2510.10931v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) agents, such as recent DeepResearch-style systems, extend large language models (LLMs) with autonomous information-seeking capabilities through external tools. While reinforcement learning (RL) has enabled impressive multi-step reasoning, we identify a previously overlooked failure mode, Tool-Call Hacking, where agents inflate reward signals by issuing superficially correct tool calls without genuinely leveraging the retrieved evidence. This results in (i) mode collapse into repetitive reliance on a single source and (ii) spurious grounding, where answers are only weakly supported by cited content. To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL framework that enforces verifiable causal links between retrieved evidence, reasoning traces, and final answers. PoU operationalizes this through a unified step-wise contract combining syntactic citation validation, perturbation-based sensitivity rewards, and answer-evidence alignment objectives, ensuring that tool usage remains both interpretable and functionally grounded. Across seven QA benchmarks spanning in-domain, out-of-domain, and out-of-tool-distribution settings, PoU consistently outperforms strong DeepResearch baselines in factual accuracy, evidence faithfulness, and tool-routing balance. These findings highlight the necessity of grounding RL-trained agents not merely in task outcomes but in the causal use of retrieved information, offering a principled path toward trustworthy retrieval-augmented reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10931","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.826683","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"SHengjie Ma, Chenlong Deng, Jiaxin Mao, Jiadeng Huang, Teng Wang, Junjie Wu, Changwang Zhang, Jun wang","raw_content_length":1597,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["Tool-Call Hacking","PoU"],"persons":[],"locations":[],"monetary":[]},"char_count":1592,"language_detected":"en","key_concepts":{"key_phrases":["PoU","Proof","arXiv251010931v1 Announce Type","new Abstract Retrieval-augmented generation RAG agents","recent DeepResearch-style systems","large language models","LLMs","autonomous information-seeking capabilities","external tools","reinforcement learning"],"filter_categories":{"research_academic":["recent DeepResearch-style systems"],"ai_ml":["large language models","reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PoU":2.0,"Proof":2.0,"arXiv251010931v1 Announce Type":1.0,"new Abstract Retrieval-augmented generation RAG agents":1.0,"recent DeepResearch-style systems":1.0,"large language models":1.0,"LLMs":1.0,"autonomous information-seeking capabilities":1.0,"external tools":1.0,"reinforcement learning":1.0}},"age_hours":2.7549147633333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8673,"joy":0.0096,"surprise":0.0636,"sadness":0.0117,"fear":0.0187,"anger":0.0197,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel method (PoU) to improve the reliability of retrieval-augmented generation agents, which could indirectly contribute to sustainability by improving the accuracy and trustworthiness of information used in decision-making processes related to climate change and resource management. The evidence is based on benchmark testing and the approach is at the research stage, with no current deployment. The 'factual accuracy, evidence faithfulness, and tool-routing balance' are the key metrics.","key_impact_metrics":["factual accuracy","evidence faithfulness"],"technology_tags":["retrieval-augmented generation","reinforcement learning","large language models"],"sdg_alignment":[9,13,17],"analyzed_at":"2025-10-29T11:42:37.905891Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eae20fb7cc91","title":"TabVLA: Targeted Backdoor Attacks on Vision","content":"arXiv:2510.10932v1 Announce Type: new Abstract: With the growing deployment of Vision-Language-Action (VLA) models in real-world embodied AI systems, their increasing vulnerability to backdoor attacks poses a serious safety threat. A backdoored VLA agent can be covertly triggered by a pre-injected backdoor to execute adversarial actions, potentially causing system failures or even physical harm. Although backdoor attacks on VLA models have been explored, prior work has focused only on untargeted attacks, leaving the more practically threatening scenario of targeted manipulation unexamined. In this paper, we study targeted backdoor attacks on VLA models and introduce TabVLA, a novel framework that enables such attacks via black-box fine-tuning. TabVLA explores two deployment-relevant inference-time threat models: input-stream editing and in-scene triggering. It formulates poisoned data generation as an optimization problem to improve attack effectivess. Experiments with OpenVLA-7B on the LIBERO benchmark reveal that the vision channel is the principal attack surface: targeted backdoors succeed with minimal poisoning, remain robust across variations in trigger design, and are degraded only by positional mismatches between fine-tuning and inference triggers. We also investigate a potential detection-based defense against TabVLA, which reconstructs latent visual triggers from the input stream to flag activation-conditioned backdoor samples. Our work highlights the vulnerability of VLA models to targeted backdoor manipulation and underscores the need for more advanced defenses.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10932","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.827102","language":"en","tags":["computer-science","csai","preprints","cscr","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Zonghuan Xu, Xiang Zheng, Xingjun Ma, Yu-Gang Jiang","raw_content_length":1600,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["TabVLA","Vision-Language-Action","VLA"],"persons":[],"locations":[],"monetary":[]},"char_count":1599,"language_detected":"en","key_concepts":{"key_phrases":["Targeted Backdoor Attacks","Vision","backdoor attacks","Announce Type","new Abstract","the growing deployment","VLA","real-world embodied AI systems","their increasing vulnerability","a serious safety threat"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Targeted Backdoor Attacks":2.0,"Vision":2.0,"backdoor attacks":2.0,"Announce Type":1.0,"new Abstract":1.0,"the growing deployment":1.0,"VLA":1.0,"real-world embodied AI systems":1.0,"their increasing vulnerability":1.0,"a serious safety threat":1.0}},"age_hours":2.7549303711111115,"is_recent":true,"quality_score":1.0,"sentiment_score":0.24950000000000028,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9501,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0646,"joy":0.0023,"surprise":0.0045,"sadness":0.0151,"fear":0.8388,"anger":0.0614,"disgust":0.0132},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores vulnerabilities in Vision-Language-Action models, specifically targeted backdoor attacks. While it highlights a potential safety threat in embodied AI systems, it doesn't directly address sustainability. The research is at an early stage, focusing on identifying vulnerabilities rather than deploying solutions for climate change or other sustainability issues.","key_impact_metrics":["Minimal poisoning required for successful attacks","Degradation of attacks due to positional mismatches"],"technology_tags":["Vision-Language-Action Models","Backdoor Attacks","AI Security"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T11:42:41.140181Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_da9f0a031756","title":"Neutral Agent","content":"arXiv:2510.10937v1 Announce Type: new Abstract: Reinforcement learning (RL) has been an important machine learning paradigm for solving long-horizon sequential decision-making problems under uncertainty. By integrating deep neural networks (DNNs) into the RL framework, deep reinforcement learning (DRL) has emerged, which achieved significant success in various domains. However, the integration of DNNs also makes it vulnerable to adversarial attacks. Existing adversarial attack techniques mainly focus on either directly manipulating the environment with which a victim agent interacts or deploying an adversarial agent that interacts with the victim agent to induce abnormal behaviors. While these techniques achieve promising results, their adoption in multi-party open systems remains limited due to two major reasons: impractical assumption of full control over the environment and dependent on interactions with victim agents. To enable adversarial attacks in multi-party open systems, in this paper, we redesigned an adversarial policy learning approach that can mislead well-trained victim agents without requiring direct interactions with these agents or full control over their environments. Particularly, we propose a neutral agent-based approach across various task scenarios in multi-party open systems. While the neutral agents seemingly are detached from the victim agents, indirectly influence them through the shared environment. We evaluate our proposed method on the SMAC platform based on Starcraft II and the autonomous driving simulation platform Highway-env. The experimental results demonstrate that our method can launch general and effective adversarial attacks in multi-party open systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10937","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.828304","language":"en","tags":["computer-science","cslg","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Qizhou Peng, Yang Zheng, Yu Wen, Yanna Wu, Yingying Du","raw_content_length":1722,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["DRL","Neutral"],"persons":[],"locations":[],"monetary":[]},"char_count":1719,"language_detected":"en","key_concepts":{"key_phrases":["Neutral Agent","DNNs","arXiv251010937v1 Announce Type","new Abstract","Reinforcement learning","an important machine learning paradigm","long-horizon sequential decision-making problems","uncertainty","deep neural networks","the RL framework"],"filter_categories":{"ai_ml":["Reinforcement learning","an important machine learning paradigm","deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neutral Agent":2.0,"DNNs":2.0,"arXiv251010937v1 Announce Type":1.0,"new Abstract":1.0,"Reinforcement learning":1.0,"an important machine learning paradigm":1.0,"long-horizon sequential decision-making problems":1.0,"uncertainty":1.0,"deep neural networks":1.0,"the RL framework":1.0}},"age_hours":2.754977028611111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.963,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8074,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4792,"joy":0.0139,"surprise":0.0129,"sadness":0.0145,"fear":0.4367,"anger":0.0261,"disgust":0.0168},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to adversarial attacks on reinforcement learning agents. While the research is interesting from a cybersecurity perspective, it does not directly address climate change or sustainability, and its impact on these areas is currently negligible. The research is in the applied research stage, with evaluations on simulation platforms.","key_impact_metrics":["None"],"technology_tags":["Reinforcement Learning","Adversarial Attacks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:42:43.602158Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cdb71ff830e9","title":"Redundancy as a Structural Information Principle for Learning and Generalization","content":"arXiv:2510.10938v1 Announce Type: new Abstract: We present a theoretical framework that extends classical information theory to finite and structured systems by redefining redundancy as a fundamental property of information organization rather than inefficiency. In this framework, redundancy is expressed as a general family of informational divergences that unifies multiple classical measures, such as mutual information, chi-squared dependence, and spectral redundancy, under a single geometric principle. This reveals that these traditional quantities are not isolated heuristics but projections of a shared redundancy geometry. The theory further predicts that redundancy is bounded both above and below, giving rise to an optimal equilibrium that balances over-compression (loss of structure) and over-coupling (collapse). While classical communication theory favors minimal redundancy for transmission efficiency, finite and structured systems, such as those underlying real-world learning, achieve maximal stability and generalization near this equilibrium. Experiments with masked autoencoders are used to illustrate and verify this principle: the model exhibits a stable redundancy level where generalization peaks. Together, these results establish redundancy as a measurable and tunable quantity that bridges the asymptotic world of communication and the finite world of learning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10938","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.828728","language":"en","tags":["statml","cslg","csai","preprints","research","mathit","csit","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Yuda Bi, Ying Zhu, Vince D Calhoun","raw_content_length":1394,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1393,"language_detected":"en","key_concepts":{"key_phrases":["Redundancy","a Structural Information Principle","Learning","Generalization","redundancy","arXiv251010938v1 Announce Type","new Abstract","a theoretical framework","classical information theory","a fundamental property"],"filter_categories":{"ai_ml":["Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Redundancy":2.0,"a Structural Information Principle":2.0,"Learning":2.0,"Generalization":2.0,"redundancy":2.0,"arXiv251010938v1 Announce Type":1.0,"new Abstract":1.0,"a theoretical framework":1.0,"classical information theory":1.0,"a fundamental property":1.0}},"age_hours":2.7549911877777777,"is_recent":true,"quality_score":0.7,"sentiment_score":5.640000000000001,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.128,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8488,"joy":0.0219,"surprise":0.0459,"sadness":0.0114,"fear":0.0086,"anger":0.039,"disgust":0.0244},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a theoretical framework for understanding redundancy in information systems and its impact on learning and generalization. While the research uses masked autoencoders to illustrate the principle and shows a correlation between redundancy levels and generalization performance, it's currently at the basic research stage with no clear path to direct climate impact or economic viability. The potential systemic impact is limited as it's a theoretical framework, not a deployed technology.","key_impact_metrics":["stable redundancy level where generalization peaks"],"technology_tags":["information theory","machine learning","masked autoencoders"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:42:46.936015Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4898bd9d3ec6","title":"Scalable and Explainable Enterprise Knowledge Discovery Using Graph","content":"arXiv:2510.10942v1 Announce Type: new Abstract: Modern enterprises manage vast knowledge distributed across heterogeneous systems such as Jira, Git repositories, Confluence, and wikis. Conventional retrieval methods based on keyword search or static embeddings often fail to answer complex queries that require contextual reasoning and multi-hop inference across artifacts. We present a modular hybrid retrieval framework for adaptive enterprise information access that integrates Knowledge Base Language-Augmented Models (KBLam), DeepGraph representations, and embedding-driven semantic search. The framework builds a unified knowledge graph from parsed repositories including code, pull requests, and commit histories, enabling semantic similarity search, structural inference, and multi-hop reasoning. Query analysis dynamically determines the optimal retrieval strategy, supporting both structured and unstructured data sources through independent or fused processing. An interactive interface provides graph visualizations, subgraph exploration, and context-aware query routing to generate concise and explainable answers. Experiments on large-scale Git repositories show that the unified reasoning layer improves answer relevance by up to 80 percent compared with standalone GPT-based retrieval pipelines. By combining graph construction, hybrid reasoning, and interactive visualization, the proposed framework offers a scalable, explainable, and user-centric foundation for intelligent knowledge assistants in enterprise environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10942","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.835293","language":"en","tags":["csai","preprints","research","csdb","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Nilima Rao, Jagriti Srivastava, Pradeep Kumar Sharma, Hritvik Shrivastava","raw_content_length":1542,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["DeepGraph","KBLam","Confluence"],"persons":["Jira","Knowledge Base Language-Augmented Models"],"locations":[],"monetary":[]},"char_count":1541,"language_detected":"en","key_concepts":{"key_phrases":["Scalable and Explainable Enterprise Knowledge Discovery","Using Graph","Announce Type","new Abstract","Modern enterprises","vast knowledge","heterogeneous systems","Jira","Git repositories","Confluence"],"filter_categories":{"ai_ml":["Scalable and Explainable Enterprise Knowledge Discovery"],"research_academic":["Scalable and Explainable Enterprise Knowledge Discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Scalable and Explainable Enterprise Knowledge Discovery":2.0,"Using Graph":2.0,"Announce Type":1.0,"new Abstract":1.0,"Modern enterprises":1.0,"vast knowledge":1.0,"heterogeneous systems":1.0,"Jira":1.0,"Git repositories":1.0,"Confluence":1.0}},"age_hours":2.7550190019444445,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8641,"joy":0.0083,"surprise":0.0496,"sadness":0.0213,"fear":0.0214,"anger":0.0175,"disgust":0.0179},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework for enterprise knowledge discovery using graph-based methods. While it shows a performance improvement of 80% in answer relevance compared to GPT-based retrieval, it's still in the research phase with no deployed units or customer contracts. The climate impact is indirect, potentially improving efficiency in organizations, but not directly reducing emissions.","key_impact_metrics":["answer relevance improvement 80%"],"technology_tags":["knowledge graph","semantic search","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:42:49.888111Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_449308e27b68","title":"The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi","content":"arXiv:2510.10943v1 Announce Type: new Abstract: Bias in large language models (LLMs) remains a persistent challenge, manifesting in stereotyping and unfair treatment across social groups. While prior research has primarily focused on individual models, the rise of multi-agent systems (MAS), where multiple LLMs collaborate and communicate, introduces new and largely unexplored dynamics in bias emergence and propagation. In this work, we present a comprehensive study of stereotypical bias in MAS, examining how internal specialization, underlying LLMs and inter-agent communication protocols influence bias robustness, propagation, and amplification. We simulate social contexts where agents represent different social groups and evaluate system behavior under various interaction and adversarial scenarios. Experiments on three bias benchmarks reveal that MAS are generally less robust than single-agent systems, with bias often emerging early through in-group favoritism. However, cooperative and debate-based communication can mitigate bias amplification, while more robust underlying LLMs improve overall system stability. Our findings highlight critical factors shaping fairness and resilience in multi-agent LLM systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10943","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.835753","language":"en","tags":["computer-science","csma","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Thi-Nhung Nguyen, Linhao Luo, Thuy-Trang Vu, Dinh Phung","raw_content_length":1230,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["MAS","The Social Cost of Intelligence: Emergence, Propagation"],"persons":["Bias"],"locations":["MAS","Multi"],"monetary":[]},"char_count":1229,"language_detected":"en","key_concepts":{"key_phrases":["The Social Cost","Intelligence","Emergence","Propagation","Amplification","Stereotypical Bias","Multi","MAS","arXiv251010943v1 Announce Type","new Abstract"],"filter_categories":{"ai_ml":["Intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Social Cost":2.0,"Intelligence":2.0,"Emergence":2.0,"Propagation":2.0,"Amplification":2.0,"Stereotypical Bias":2.0,"Multi":2.0,"MAS":2.0,"arXiv251010943v1 Announce Type":1.0,"new Abstract":1.0}},"age_hours":2.7550343147222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5722,"joy":0.0052,"surprise":0.0457,"sadness":0.0167,"fear":0.0133,"anger":0.2802,"disgust":0.0667},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":7,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores bias in multi-agent LLM systems, highlighting the potential for in-group favoritism and the impact of communication protocols. While it doesn't directly address climate change, it has implications for fairness and equity in AI systems used for sustainability applications. The study uses simulations and bias benchmarks, but lacks real-world deployment data.","key_impact_metrics":["Bias robustness","Bias amplification"],"technology_tags":["Large Language Models","Multi-Agent Systems","AI Fairness"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T11:42:53.000142Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_19bc56889d9c","title":"Throughput Maximization for Multiuser Communications with Flexible","content":"arXiv:2510.10944v1 Announce Type: new Abstract: This paper presents a cost-effective and easily-deployable flexible-sector six-dimensional movable antenna (6DMA) architecture for future wireless communication networks, which enables flexible antenna configurations to match users' spatial distribution for capacity enhancement. Different from conventional sectorized base station (BS) with fixed-position antennas (FPAs), the flexible-sector 6DMA-enabled BS employs multiple directional sector antenna arrays that can flexibly move along a common circular track. By properly moving antennas across sectors and rotating all sector antenna arrays synchronously, the flexible-sector BS can adjust the coverage regions of all sectors with flexible antenna allocations over them. In particular, we consider the multiuser downlink communication employing the orthogonal multiple access (OMA) to serve users in each sector. Under this setup, we jointly optimize the sector rotation and the antenna allocation at the flexible-sector BS to maximize the average common throughput achievable for all users based on their spatial distribution. We solve this non-convex optimization problem by deriving closed-form solutions and thereby analyze the effect of users' spatial distribution on the achievable common throughput. It is shown that equal user distribution over sectors is optimal for maximizing the common throughput. Motivated by this result, we further develop a low-complexity suboptimal solution for the sector rotation that minimizes the variance of user numbers across sectors. Finally, we provide simulation results to verify our analytical results and validate the performance of our proposed solutions. It is demonstrated that the flexible-sector BS significantly improves the network throughput as compared to other benchmark schemes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10944","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.836198","language":"en","tags":["computer-science","preprints","mathit","csit","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":248,"author":"Xiaoming Shi, Yunli Li, Xiaodan Shao, Jie Xu, Rui Zhang","raw_content_length":1841,"priority":7,"update_frequency":1,"reading_time_minutes":1.24,"robust_parsing_used":true,"entities":{"organizations":["6DMA","antennas"],"persons":["antennas","antenna"],"locations":[],"monetary":[]},"char_count":1840,"language_detected":"en","key_concepts":{"key_phrases":["Throughput Maximization","Multiuser Communications","Flexible","arXiv251010944v1 Announce Type","new Abstract","This paper","future wireless communication networks","which","flexible antenna configurations","users spatial distribution"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Throughput Maximization":2.0,"Multiuser Communications":2.0,"Flexible":2.0,"arXiv251010944v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"future wireless communication networks":1.0,"which":1.0,"flexible antenna configurations":1.0,"users spatial distribution":1.0}},"age_hours":2.7550494186111107,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8366,"joy":0.0632,"surprise":0.0774,"sadness":0.0045,"fear":0.0044,"anger":0.0102,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel antenna architecture to improve network throughput. While the simulation results show improved throughput, there is no mention of deployed units or real-world data. The economic viability is uncertain as there is no cost analysis provided.","key_impact_metrics":["average common throughput achievable for all users"],"technology_tags":["6DMA","flexible-sector antenna","wireless communication"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:42:55.955572Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e64360e2a392","title":"Towards Distribution","content":"arXiv:2510.10947v1 Announce Type: new Abstract: Generative models have shown strong potential as data-driven priors for solving inverse problems such as reconstructing medical images from undersampled measurements. While these priors improve reconstruction quality with fewer measurements, they risk hallucinating features when test images lie outside the training distribution. Existing uncertainty quantification methods in this setting (i) require an in-distribution calibration dataset, which may not be available, (ii) provide heuristic rather than statistical estimates, or (iii) quantify uncertainty from model capacity or limited measurements rather than distribution shift. We propose an instance-level, calibration-free uncertainty indicator that is sensitive to distribution shift, requires no knowledge of the training distribution, and incurs no retraining cost. Our key hypothesis is that reconstructions of in-distribution images remain stable under random measurement variations, while reconstructions of out-of-distribution (OOD) images exhibit greater instability. We use this stability as a proxy for detecting distribution shift. Our proposed OOD indicator is efficiently computable for any computational imaging inverse problem; we demonstrate it on tomographic reconstruction of MNIST digits, where a learned proximal network trained only on digit \"0\" is evaluated on all ten digits. Reconstructions of OOD digits show higher variability and correspondingly higher reconstruction error, validating this indicator. These results suggest a deployment strategy that pairs generative priors with lightweight guardrails, enabling aggressive measurement reduction for in-distribution cases while automatically warning when priors are applied out of distribution.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10947","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.836644","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Namhoon Kim, Sara Fridovich-Keil","raw_content_length":1779,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1778,"language_detected":"en","key_concepts":{"key_phrases":["Distribution","arXiv251010947v1 Announce Type","new Abstract","Generative models","strong potential","data-driven priors","inverse problems","medical images","undersampled measurements","these priors"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Distribution":2.0,"arXiv251010947v1 Announce Type":1.0,"new Abstract":1.0,"Generative models":1.0,"strong potential":1.0,"data-driven priors":1.0,"inverse problems":1.0,"medical images":1.0,"undersampled measurements":1.0,"these priors":1.0}},"age_hours":2.755063472222222,"is_recent":true,"quality_score":0.7,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.384,"joy":0.0122,"surprise":0.0169,"sadness":0.0144,"fear":0.4904,"anger":0.0194,"disgust":0.0627},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for detecting out-of-distribution data in generative models used for inverse problems. While the method is demonstrated on a tomographic reconstruction of MNIST digits, it is still in the applied research phase with no real-world deployments. The potential climate impact is indirect, as it could improve resource efficiency in applications like medical imaging, but this is not quantified.","key_impact_metrics":["Reconstruction error increase for OOD digits"],"technology_tags":["Generative models","Uncertainty quantification","Distribution shift detection"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:42:58.478549Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3650a3c344bc","title":"Unify Variables in Neural Scaling Laws for General Audio Representations via Embedding Effective Rank","content":"arXiv:2510.10948v1 Announce Type: new Abstract: Scaling laws have profoundly shaped our understanding of model performance in computer vision and natural language processing, yet their application to general audio representation learning remains underexplored. A key challenge lies in the multifactorial nature of general audio representation-representation quality is jointly influenced by variables such as audio length, embedding dimensionality, model depth, model architecture, data volume, etc., many of which are difficult to isolate or express analytically. In this work, we present a systematic study of scaling laws for general audio representations by utilizing embedding effective rank (RankMe) as a unifying metric that encapsulates the impact of diverse variables on representation quality. RankMe enables a label-free, information-theoretic quantification of audio embeddings, allowing us to examine scaling behaviors across a wide hyper-parameter space, including model size, training data volume, computational budget, architectural configurations, etc. Our empirical findings reveal a consistent power-law relationship between RankMe and representation quality, suggesting that embedding effective rank serves as a reliable proxy for assessing and predicting model performance in audio representation learning. This work not only validates the applicability of classical scaling principles to the general audio domain but also offers a theoretically grounded and empirically robust framework for guiding future model scaling strategies in audio foundation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10948","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.837059","language":"en","tags":["csai","eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Xuyao Deng, Yanjie Sun, Yong Dou, Kele Xu","raw_content_length":1581,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Embedding Effective Rank"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1580,"language_detected":"en","key_concepts":{"key_phrases":["Variables","Neural Scaling Laws","General Audio Representations","Embedding Effective Rank","arXiv251010948v1 Announce Type","new Abstract","Scaling laws","our understanding","model performance","computer vision"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Variables":2.0,"Neural Scaling Laws":2.0,"General Audio Representations":2.0,"Embedding Effective Rank":2.0,"arXiv251010948v1 Announce Type":1.0,"new Abstract":1.0,"Scaling laws":1.0,"our understanding":1.0,"model performance":1.0,"computer vision":1.0}},"age_hours":2.755078111111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7924,"joy":0.0082,"surprise":0.0228,"sadness":0.0083,"fear":0.1071,"anger":0.0416,"disgust":0.0196},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for improving audio representation learning, but it is still in the research phase with no deployed technology or measured outcomes. The 'RankMe' metric is proposed, but its real-world impact on reducing energy consumption or enabling specific climate solutions is not demonstrated. It remains a concept without concrete action.","key_impact_metrics":["RankMe and representation quality","Power-law relationship between RankMe and representation quality"],"technology_tags":["Audio representation learning","Neural scaling laws","Embedding effective rank"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:43:01.420537Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b91e1e97e549","title":"Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant","content":"arXiv:2510.10952v1 Announce Type: new Abstract: Early detection of Alzheimer's disease (AD) is crucial because its neurodegenerative effects are irreversible, and neuropathologic and social-behavioral risk factors accumulate years before diagnosis. Identifying higher-risk individuals earlier enables prevention, timely care, and equitable resource allocation. We predict cognitive performance from social determinants of health (SDOH) using the NIH NIA-supported PREPARE Challenge Phase 2 dataset derived from the nationally representative Mex-Cog cohort of the 2003 and 2012 Mexican Health and Aging Study (MHAS). Data: The target is a validated composite cognitive score across seven domains-orientation, memory, attention, language, constructional praxis, and executive function-derived from the 2016 and 2021 MHAS waves. Predictors span demographic, socioeconomic, health, lifestyle, psychosocial, and healthcare access factors. Methodology: Missingness was addressed with a singular value decomposition (SVD)-based imputation pipeline treating continuous and categorical variables separately. This approach leverages latent feature correlations to recover missing values while balancing reliability and scalability. After evaluating multiple methods, XGBoost was chosen for its superior predictive performance. Results and Discussion: The framework outperformed existing methods and the data challenge leaderboard, demonstrating high accuracy, robustness, and interpretability. SHAP-based post hoc analysis identified top contributing SDOH factors and age-specific feature patterns. Notably, flooring material emerged as a strong predictor, reflecting socioeconomic and environmental disparities. Other influential factors, age, SES, lifestyle, social interaction, sleep, stress, and BMI, underscore the multifactorial nature of cognitive aging and the value of interpretable, data-driven SDOH modeling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10952","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.837875","language":"en","tags":["computer-science","cslg","statap","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":233,"author":"Xi Mao, Zhendong Wang, Jingyu Li, Lingchao Mao, Utibe Essien, Hairong Wang, Xuelei Sherry Ni","raw_content_length":1916,"priority":7,"update_frequency":1,"reading_time_minutes":1.165,"robust_parsing_used":true,"entities":{"organizations":["NIH","Mexican Health and Aging Study","Handling Missing Data"],"persons":["Mex-Cog"],"locations":[],"monetary":[]},"char_count":1909,"language_detected":"en","key_concepts":{"key_phrases":["Interpretable Machine Learning","Cognitive Aging","Missing Data","Uncovering","arXiv251010952v1","Announce Type","new Abstract","Early detection","Alzheimers disease","its neurodegenerative effects"],"filter_categories":{"ai_ml":["Interpretable Machine Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Interpretable Machine Learning":2.0,"Cognitive Aging":2.0,"Missing Data":2.0,"Uncovering":2.0,"arXiv251010952v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Early detection":1.0,"Alzheimers disease":1.0,"its neurodegenerative effects":1.0}},"age_hours":2.755108019722222,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8121,"joy":0.0072,"surprise":0.0278,"sadness":0.0224,"fear":0.1078,"anger":0.0128,"disgust":0.0098},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":6,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":true,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research uses machine learning to predict cognitive performance based on social determinants of health. While it identifies factors like flooring material as predictors, it's primarily focused on data analysis and prediction rather than direct climate action. The study uses the PREPARE Challenge Phase 2 dataset and demonstrates high accuracy, but it's still in the applied research phase with no deployed interventions.","key_impact_metrics":["High accuracy prediction","Identified top contributing SDOH factors"],"technology_tags":["Machine Learning","XGBoost","SHAP analysis"],"sdg_alignment":[3,10],"analyzed_at":"2025-10-29T11:43:04.539620Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fba2cac9b8ea","title":"Comparative Evaluation of Neural Network Architectures for Generalizable Human Spatial Preference Prediction in Unseen Built Environments","content":"arXiv:2510.10954v1 Announce Type: new Abstract: The capacity to predict human spatial preferences within built environments is instrumental for developing Cyber-Physical-Social Infrastructure Systems (CPSIS). A significant challenge in this domain is the generalizability of preference models, particularly their efficacy in predicting preferences within environmental configurations not encountered during training. While deep learning models have shown promise in learning complex spatial and contextual dependencies, it remains unclear which neural network architectures are most effective at generalizing to unseen layouts. To address this, we conduct a comparative study of Graph Neural Networks, Convolutional Neural Networks, and standard feedforward Neural Networks using synthetic data generated from a simplified and synthetic pocket park environment. Beginning with this illustrative case study, allows for controlled analysis of each model's ability to transfer learned preference patterns to unseen spatial scenarios. The models are evaluated based on their capacity to predict preferences influenced by heterogeneous physical, environmental, and social features. Generalizability score is calculated using the area under the precision-recall curve for the seen and unseen layouts. This generalizability score is appropriate for imbalanced data, providing insights into the suitability of each neural network architecture for preference-aware human behavior modeling in unseen built environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10954","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.838285","language":"en","tags":["cslg","csce","csma","preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Maral Doctorarastoo, Katherine A. Flanigan, Mario Berg\\'es, Christopher McComb","raw_content_length":1510,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["CPSIS","Neural Networks","Cyber-Physical-Social Infrastructure Systems","Convolutional Neural Networks","Graph Neural Networks"],"persons":[],"locations":[],"monetary":[]},"char_count":1509,"language_detected":"en","key_concepts":{"key_phrases":["Comparative Evaluation","Neural Network Architectures","Generalizable Human Spatial Preference Prediction","Unseen Built Environments","arXiv251010954v1 Announce Type","new Abstract","The capacity","human spatial preferences","built environments","Cyber-Physical-Social Infrastructure Systems"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Comparative Evaluation":2.0,"Neural Network Architectures":2.0,"Generalizable Human Spatial Preference Prediction":2.0,"Unseen Built Environments":2.0,"arXiv251010954v1 Announce Type":1.0,"new Abstract":1.0,"The capacity":1.0,"human spatial preferences":1.0,"built environments":1.0,"Cyber-Physical-Social Infrastructure Systems":1.0}},"age_hours":2.7551220127777776,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8372,"joy":0.0181,"surprise":0.0688,"sadness":0.0081,"fear":0.0333,"anger":0.0239,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article focuses on comparing neural network architectures for predicting human spatial preferences in built environments. While the research could potentially inform the design of more sustainable and equitable urban spaces, it is currently in the early stages of development using synthetic data. There are no concrete deployments or measured outcomes related to climate impact or other sustainability dimensions at this point.","key_impact_metrics":["Generalizability score using area under the precision-recall curve"],"technology_tags":["Graph Neural Networks","Convolutional Neural Networks","Feedforward Neural Networks","Cyber-Physical-Social Infrastructure Systems (CPSIS)"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T11:43:08.143693Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_470139f5c1cc","title":"HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM","content":"arXiv:2510.10955v1 Announce Type: new Abstract: Recent years have witnessed a surge of research on leveraging large language models (LLMs) for sequential recommendation. LLMs have demonstrated remarkable potential in inferring users' nuanced preferences through fine-grained semantic reasoning. However, they also exhibit a notable limitation in effectively modeling collaborative signals, i.e., behavioral correlations inherent in users' historical interactions. Our empirical analysis further reveals that the attention mechanisms in LLMs tend to disproportionately focus on tokens within the same item, thereby impeding the capture of cross-item correlations. To address this limitation, we propose a novel hierarchical attention masking strategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow layers, HatLLM masks attention between tokens from different items, facilitating intra-item semantic understanding; in contrast, in deep layers, HatLLM masks attention within items, thereby compelling the model to capture cross-item correlations. This progressive, layer-wise approach enables LLMs to jointly model both token-level and item-level dependencies. Extensive experiments on three real-world datasets demonstrate that HatLLM achieves significant performance gains (9.13% on average) over existing LLM-based methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10955","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.838698","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Yu Cui, Feng Liu, Jiawei Chen, Canghong Jin, Xingyu Lou, Changwang Zhang, Jun Wang, Yuegang Sun, Can Wang","raw_content_length":1349,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["Enhanced Collaborative Modeling","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["HatLLM Hierarchical Attention Masking","Enhanced Collaborative Modeling","LLM","LLMs","arXiv251010955v1 Announce Type","new Abstract","Recent years","a surge","research","large language models"],"filter_categories":{"ai_ml":["HatLLM Hierarchical Attention Masking","large language models"],"healthcare_tech":["research"],"research_academic":["research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HatLLM Hierarchical Attention Masking":2.0,"Enhanced Collaborative Modeling":2.0,"LLM":2.0,"LLMs":2.0,"arXiv251010955v1 Announce Type":1.0,"new Abstract":1.0,"Recent years":1.0,"a surge":1.0,"research":1.0,"large language models":1.0}},"age_hours":2.755136315,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7788,"joy":0.0252,"surprise":0.0702,"sadness":0.0048,"fear":0.0586,"anger":0.0346,"disgust":0.0278},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel hierarchical attention masking strategy (HatLLM) to improve collaborative modeling in LLMs for sequential recommendation. The concrete action is the development and testing of this new masking strategy. The evidence supporting the claims comes from experiments on three real-world datasets, demonstrating a 9.13% average performance gain. The stage of deployment is basic research, as it is a proposed method tested on datasets, not a deployed technology.","key_impact_metrics":["Performance gain 9.13%"],"technology_tags":["Large Language Models","Recommendation Systems","Attention Mechanisms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:43:10.929454Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fc7183194ff1","title":"Project-Level C","content":"arXiv:2510.10956v1 Announce Type: new Abstract: Translating C code into safe Rust is an effective way to ensure its memory safety. Compared to rule-based translation which produces Rust code that remains largely unsafe, LLM-based methods can generate more idiomatic and safer Rust code because LLMs have been trained on vast amount of human-written idiomatic code. Although promising, existing LLM-based methods still struggle with project-level C-to-Rust translation. They typically partition a C project into smaller units (\\eg{} functions) based on call graphs and translate them bottom-up to resolve program dependencies. However, this bottom-up, unit-by-unit paradigm often fails to translate pointers due to the lack of a global perspective on their usage. To address this problem, we propose a novel C-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph with two types of pointer semantics: (i) pointer-usage information which record global behaviors such as points-to flows and map lower-level struct usage to higher-level units; and (ii) Rust-oriented annotations which encode ownership, mutability, nullability, and lifetime. Synthesizing the \\kg{} with LLMs, we further propose \\ourtool{}, which implements a project-level C-to-Rust translation technique. In \\ourtool{}, the \\kg{} provides LLMs with comprehensive pointer semantics from a global perspective, thus guiding LLMs towards generating safe and idiomatic Rust code from a given C project. Our experiments show that \\ourtool{} reduces unsafe usages in translated Rust by 99.9\\% compared to both rule-based translation and traditional LLM-based rewriting, while achieving an average 29.3\\% higher functional correctness than those fuzzing-enhanced LLM methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10956","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.839111","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Zhiqiang Yuan, Wenjun Mao, Zhuo Chen, Xiyue Shang, Chong Wang, Yiling Lou, Xin Peng","raw_content_length":1750,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["Project-Level C arXiv:2510.10956v1 Announce Type","LLM","C-Rust Pointer Knowledge Graph","\\eg"],"persons":[],"locations":[],"monetary":[]},"char_count":1749,"language_detected":"en","key_concepts":{"key_phrases":["Project-Level C","arXiv251010956v1","Announce Type","new Abstract","C code","safe Rust","an effective way","its memory safety","rule-based translation","which"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Project-Level C":2.0,"arXiv251010956v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"C code":1.0,"safe Rust":1.0,"an effective way":1.0,"its memory safety":1.0,"rule-based translation":1.0,"which":1.0}},"age_hours":2.7551526466666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.654,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9308,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.945,"joy":0.0205,"surprise":0.0091,"sadness":0.0058,"fear":0.0086,"anger":0.0048,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for translating C code to Rust, aiming to improve memory safety and reduce unsafe usages. The key concrete action is the development of a C-Rust Pointer Knowledge Graph to guide LLMs in generating safer Rust code. Evidence includes a 99.9% reduction in unsafe usages and a 29.3% higher functional correctness compared to other methods, but it's still in the applied research stage.","key_impact_metrics":["99.9% reduction in unsafe usages","29.3% higher functional correctness"],"technology_tags":["C-to-Rust translation","LLM","Memory Safety"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:43:22.438059Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cb74f5cb3507","title":"Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning","content":"arXiv:2510.10959v1 Announce Type: new Abstract: Reasoning ability has become a defining capability of Large Language Models (LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as a key paradigm to enhance it. However, RLVR training often suffers from policy entropy collapse, where the policy becomes overly deterministic, hindering exploration and limiting reasoning performance. While entropy regularization is a common remedy, its effectiveness is highly sensitive to the fixed coefficient, making it unstable across tasks and models. In this work, we revisit entropy regularization in RLVR and argue that its potential has been largely underestimated. Our analysis shows that (i) tasks of varying difficulty demand distinct exploration intensities, and (ii) balanced exploration may require the policy entropy to be maintained within a moderate range below its initial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a framework that dynamically balances exploration and exploitation via three components: difficulty-aware coefficient allocation, initial-anchored target entropy, and dynamic global coefficient adjustment. Experiments on multiple mathematical reasoning benchmarks show that AER consistently outperforms baselines, improving both reasoning accuracy and exploration capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10959","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.839520","language":"en","tags":["statml","cslg","csai","preprints","research","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Xiaoyun Zhang, Xiaojian Yuan, Di Huang, Wang You, Chen Hu, Jingqing Ruan, Kejiang Chen, Xing Hu","raw_content_length":1341,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Reinforcement Learning with Verifiable Rewards"],"persons":[],"locations":[],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["Rediscovering Entropy Regularization","Adaptive Coefficient","Its Potential","LLM Reinforcement Learning","RLVR","arXiv251010959v1 Announce Type","new Abstract","Reasoning ability","a defining capability","Large Language Models"],"filter_categories":{"ai_ml":["LLM Reinforcement Learning","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Rediscovering Entropy Regularization":2.0,"Adaptive Coefficient":2.0,"Its Potential":2.0,"LLM Reinforcement Learning":2.0,"RLVR":2.0,"arXiv251010959v1 Announce Type":1.0,"new Abstract":1.0,"Reasoning ability":1.0,"a defining capability":1.0,"Large Language Models":1.0}},"age_hours":2.755167825277778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7769,"joy":0.0132,"surprise":0.0443,"sadness":0.0355,"fear":0.0514,"anger":0.0441,"disgust":0.0344},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (AER) to improve the reasoning accuracy and exploration capability of LLMs in reinforcement learning. The concrete action is the development and testing of this algorithm on mathematical reasoning benchmarks, showing improved performance. However, this is currently at the research stage, with no real-world deployment or quantified environmental impact.","key_impact_metrics":["reasoning accuracy improvement","exploration capability improvement"],"technology_tags":["Large Language Models","Reinforcement Learning","Entropy Regularization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:43:25.353947Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f9f0d7c5fecc","title":"KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification","content":"arXiv:2510.10961v1 Announce Type: new Abstract: Toxic content has become an increasingly critical social issue with the rapid expansion of online communication. While numerous studies explored methods for detecting and detoxifying such content, most have focused primarily on English, leaving low-resource language underrepresented. Consequently, Large Language Models~(LLMs) often struggle to identify and neutralize toxic expressions in these languages. This challenge becomes even more pronounced when user employ obfuscation techniques to evade detection systems. Therefore, we propose a \\textbf{KOTOX: Korean Toxic Dataset} for deobfuscation and detoxicification to address this issue. We categorize various obfuscation approaches based on linguistic characteristics of Korean and define a set of transformation rules grounded in real-word examples. Using these rules, we construct three dataset versions (easy, normal, and hard) representing different levels of obfuscation difficulty. This is the first dataset that simultaneously supports deobfuscation and detoxification for the Korean language. We expect it to facilitate better understanding and mitigating of obfuscated toxic content in LLM for low-resource languages. Our code and data are available at https://github.com/leeyejin1231/KOTOX.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10961","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.840698","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Yejin Lee, Su-Hyeon Kim, Hyundong Jin, Dayoung Kim, Yeonsoo Kim, Yo-Sub Han","raw_content_length":1305,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Language Models~(LLMs"],"locations":[],"monetary":[]},"char_count":1304,"language_detected":"en","key_concepts":{"key_phrases":["A Korean Toxic Dataset","Deobfuscation","Detoxification","arXiv251010961v1 Announce Type","new Abstract","Toxic content","an increasingly critical social issue","the rapid expansion","online communication","numerous studies"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Korean Toxic Dataset":2.0,"Deobfuscation":2.0,"Detoxification":2.0,"arXiv251010961v1 Announce Type":1.0,"new Abstract":1.0,"Toxic content":1.0,"an increasingly critical social issue":1.0,"the rapid expansion":1.0,"online communication":1.0,"numerous studies":1.0}},"age_hours":2.7551961552777775,"is_recent":true,"quality_score":1.0,"sentiment_score":4.084,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1832,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7678,"joy":0.0073,"surprise":0.0323,"sadness":0.0288,"fear":0.0482,"anger":0.0373,"disgust":0.0784},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a dataset for deobfuscating and detoxifying Korean toxic content. While it addresses a social issue exacerbated by online communication, its direct climate impact is minimal. The dataset is available on Github, suggesting applied research, but lacks deployment or real-world impact data.","key_impact_metrics":[],"technology_tags":["Natural Language Processing","Toxic Content Detection"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T11:43:28.210266Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1068cebfdf37","title":"MC#: Mixture Compressor for Mixture","content":"arXiv:2510.10962v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and vision-language models (VLMs) by increasing capacity through sparse activation. However, preloading all experts into memory and activating multiple experts per input introduces significant computational and memory overhead, making the expert module a major contributor to model size and inference cost. To address this, we propose MC# (Mixture-Compressor-sharp), a framework that combines static quantization and dynamic expert pruning by leveraging the significance of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce storage and loading costs, we introduce Pre-Loading Mixed-Precision Quantization (PMQ), which optimizes bit allocation via linear programming, balancing expert importance and quantization error for a Pareto-optimal trade-off between size and performance. To reduce runtime computation, Online Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a subset of experts per token, enabling fine-grained control over activation. By combining PMQ's static bit-width optimization with OTP's dynamic routing, MC# achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC# achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7% accuracy drop across five multimodal benchmarks. Additionally, OTP reduces expert activation over 20% with less than 1% performance degradation, demonstrating strong potential for efficient MoE-based model deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10962","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.841116","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":204,"author":"Wei Huang, Yue Liao, Yukang Chen, Jianhui Liu, Haoru Tan, Si Liu, Shiming Zhang, Shuicheng Yan, Xiaojuan Qi","raw_content_length":1566,"priority":7,"update_frequency":1,"reading_time_minutes":1.02,"robust_parsing_used":true,"entities":{"organizations":["linear programming","Mixture Compressor for Mixture arXiv:2510.10962v1 Announce Type: new Abstract","Pre-Loading Mixed-Precision Quantization","Mixture-Compressor-sharp"],"persons":[],"locations":[],"monetary":[]},"char_count":1565,"language_detected":"en","key_concepts":{"key_phrases":["Mixture","MC Mixture Compressor","arXiv251010962v1 Announce Type","new Abstract","Experts","MoE","large language models","LLMs","vision-language models","VLMs"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Mixture":3.0,"MC Mixture Compressor":2.0,"arXiv251010962v1 Announce Type":1.0,"new Abstract":1.0,"Experts":1.0,"MoE":1.0,"large language models":1.0,"LLMs":1.0,"vision-language models":1.0,"VLMs":1.0}},"age_hours":2.755212074166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9095,"joy":0.0068,"surprise":0.0324,"sadness":0.0122,"fear":0.0092,"anger":0.0214,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (MC#) for compressing large language models, which can lead to reduced energy consumption during training and inference. The paper quantifies the weight reduction (6.2x) and bit reduction (2.57 average bits) achieved with minimal accuracy loss (1.7%). However, it is still in the research phase with no deployed units.","key_impact_metrics":["6.2 times weight reduction","2.57 average bits"],"technology_tags":["model compression","quantization","mixture of experts"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:43:37.499319Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2a40ca0adb73","title":"APLOT: Robust Reward Modeling via Adaptive Preference Learning with Optimal Transport","content":"arXiv:2510.10963v1 Announce Type: new Abstract: The reward model (RM) plays a crucial role in aligning Large Language Models (LLMs) with human preferences through Reinforcement Learning, where the Bradley-Terry (BT) objective has been recognized as simple yet powerful, specifically for pairwise preference learning. However, BT-based RMs often struggle to effectively distinguish between similar preference responses, leading to insufficient separation between preferred and non-preferred outputs. Consequently, they may easily overfit easy samples and cannot generalize well to Out-Of-Distribution (OOD) samples, resulting in suboptimal performance. To address these challenges, this paper introduces an effective enhancement to BT-based RMs through an adaptive margin mechanism. Specifically, we design to dynamically adjust the RM focus on more challenging samples through margins, based on both semantic similarity and model-predicted reward differences, which is approached from a distributional perspective solvable with Optimal Transport (OT). By incorporating these factors into a principled OT cost matrix design, our adaptive margin enables the RM to better capture distributional differences between chosen and rejected responses, yielding significant improvements in performance, convergence speed, and generalization capabilities. Experimental results across multiple benchmarks demonstrate that our method outperforms several existing RM techniques, showcasing enhanced performance in both In-Distribution (ID) and OOD settings. Moreover, RLHF experiments support our practical effectiveness in better aligning LLMs with human preferences. Our code is available at https://github.com/BIRlz/APLOT","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10963","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.841558","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":217,"author":"Zhuo Li, Yuege Feng, Dandan Guo, Jinpeng Hu, Anningzhe Gao, Xiang Wan","raw_content_length":1711,"priority":7,"update_frequency":1,"reading_time_minutes":1.085,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Adaptive Preference Learning","Optimal Transport arXiv:2510.10963v1 Announce Type","Reinforcement Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1710,"language_detected":"en","key_concepts":{"key_phrases":["APLOT","Robust Reward Modeling","Adaptive Preference Learning","Optimal Transport","arXiv251010963v1 Announce Type","new Abstract","The reward model","a crucial role","Large Language Models","LLMs"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"APLOT":2.0,"Robust Reward Modeling":2.0,"Adaptive Preference Learning":2.0,"Optimal Transport":2.0,"arXiv251010963v1 Announce Type":1.0,"new Abstract":1.0,"The reward model":1.0,"a crucial role":1.0,"Large Language Models":1.0,"LLMs":1.0}},"age_hours":2.755227459166667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.746500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9493,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8811,"joy":0.0147,"surprise":0.064,"sadness":0.0057,"fear":0.0091,"anger":0.0194,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel method (APLOT) for improving reward models in LLMs, which indirectly supports sustainability by potentially improving the efficiency and accuracy of LLMs used in climate modeling or other sustainability-related applications. The method is validated through experiments and benchmarks, showing improved performance and generalization. However, it is still in the applied research phase with no deployed units or direct climate impact metrics.","key_impact_metrics":["significant improvements in performance","enhanced performance in both In-Distribution (ID) and OOD settings"],"technology_tags":["Large Language Models","Reinforcement Learning","Optimal Transport"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:43:40.725152Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_de70bd795586","title":"Not All Bits Are Equal: Scale","content":"arXiv:2510.10964v1 Announce Type: new Abstract: While 4-bit quantization has emerged as a memory-optimal choice for non-reasoning models and zero-shot tasks across scales, we show that this universal prescription fails for reasoning models, where the KV cache rather than model size can dominate memory. Through systematic experiments across 1,700 inference scenarios on AIME25 and GPQA-Diamond, we find a scale-dependent trade-off: models with an effective size below 8-bit 4B parameters achieve better accuracy by allocating memory to more weights rather than longer generation, while larger models achieve better accuracy by allocating memory to longer generations. This scale threshold also determines when parallel scaling becomes memory-efficient and whether KV cache eviction outperforms KV quantization. Our findings show that memory optimization for LLMs cannot be scale-agnostic, while providing principled guidelines: for small reasoning models, prioritize model capacity over test-time compute, while for larger ones, maximize test-time compute. Our results suggest that optimizing reasoning models for deployment requires fundamentally different strategies from those established for non-reasoning models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10964","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.841960","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Junhyuck Kim, Ethan Ewer, Taehong Moon, Jongho Park, Dimitris Papailiopoulos","raw_content_length":1219,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["GPQA-Diamond"],"persons":[],"locations":[],"monetary":[]},"char_count":1218,"language_detected":"en","key_concepts":{"key_phrases":["Not All Bits"," Scale","Announce Type","new Abstract","4-bit quantization","a memory-optimal choice","non-reasoning models","zero-shot tasks","scales","this universal prescription"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Not All Bits":2.0," Scale":2.0,"Announce Type":1.0,"new Abstract":1.0,"4-bit quantization":1.0,"a memory-optimal choice":1.0,"non-reasoning models":1.0,"zero-shot tasks":1.0,"scales":1.0,"this universal prescription":1.0}},"age_hours":2.7552428477777777,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7061,"joy":0.0107,"surprise":0.0982,"sadness":0.067,"fear":0.014,"anger":0.0436,"disgust":0.0604},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the trade-offs in memory optimization for large language models (LLMs), specifically focusing on quantization levels (4-bit vs. 8-bit). The concrete action is systematic experimentation across 1,700 inference scenarios, providing data on accuracy and memory usage. While not directly deploying a technology, it provides insights that could lead to more efficient LLM deployment, potentially reducing energy consumption in data centers.","key_impact_metrics":["4-bit quantization","8-bit quantization"],"technology_tags":["Quantization","Large Language Models","Memory Optimization"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:43:45.022421Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9c86508fc09b","title":"Judge Before Answer: Can MLLM Discern the False Premise in Question?","content":"arXiv:2510.10965v1 Announce Type: new Abstract: Multimodal large language models (MLLMs) have witnessed astonishing advancements in recent years. Despite these successes, MLLMs remain vulnerable to flase premise problems. However, existing benchmarks targeting this issue are limited in scope: they often lack fine-grained categorization, exhibit insufficient coverage, and thus fail to provide a rigorous evaluation of the ability of models to recognize false premises. To bridge this gap, we introduce a fully automated pipeline for constructing a comprehensive benchmark of false premise questions. Our method systematically categorizes the premises into three main types and thirteen subtypes according to the abilities required to identify the premises, resulting in the JBA dataset.Results show current MLLMs still struggle with false premise recognition. Building upon this benchmark, we further propose a recognition enhancement framework tailored to strengthen the robustness of MLLMs to detect false premises. Extensive experiments demonstrate that models trained with our framework achieve significant improvements in false premise recognition.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10965","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.842352","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Jidong Li, Lingyong Fang, Haodong Zhao, Sufeng Duan, Gongshen Liu","raw_content_length":1156,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["JBA"],"persons":[],"locations":[],"monetary":[]},"char_count":1155,"language_detected":"en","key_concepts":{"key_phrases":["Answer","MLLM","the False Premise","Question","MLLMs","arXiv251010965v1 Announce Type","new Abstract","Multimodal large language models","astonishing advancements","recent years"],"filter_categories":{"ai_ml":["MLLM","Multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Answer":2.0,"MLLM":2.0,"the False Premise":2.0,"Question":2.0,"MLLMs":2.0,"arXiv251010965v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal large language models":1.0,"astonishing advancements":1.0,"recent years":1.0}},"age_hours":2.7552580525,"is_recent":true,"quality_score":1.0,"sentiment_score":0.40549999999999975,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9189,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4439,"joy":0.0028,"surprise":0.0223,"sadness":0.0261,"fear":0.4062,"anger":0.0511,"disgust":0.0476},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a new benchmark (JBA dataset) and a recognition enhancement framework for MLLMs to detect false premises. While this could indirectly improve sustainability-related decision-making by filtering out misinformation, there's no direct, concrete action happening that demonstrably reduces GHG emissions or promotes climate justice. The framework is still in the applied research stage, with results showing improvements in false premise recognition but no deployment in real-world sustainability applications.","key_impact_metrics":["Improvement in false premise recognition","Categorization into 13 subtypes"],"technology_tags":["Multimodal Large Language Models","False Premise Detection"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:43:49.668693Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_91cc3f583aef","title":"IUT-Plug: A Plug","content":"arXiv:2510.10969v1 Announce Type: new Abstract: Existing vision language models (VLMs), including GPT-4 and DALL-E, often struggle to preserve logic, object identity, and style in multimodal image-text generation. This limitation significantly hinders the generalization capability of VLMs in complex image-text input-output scenarios. To address this issue, we propose IUT-Plug, a module grounded in an Image Understanding Tree (IUT), which enhances existing interleaved VLMs through explicit structured reasoning, thereby mitigating context drift in logic, entity identity, and style. The proposed framework operates in two stages. (1) A dynamic IUT-Plug extraction module parses visual scenes into hierarchical symbolic structures. (2) A coordinated narrative-flow and image synthesis mechanism ensures cross-modal consistency. To evaluate our approach, we construct a novel benchmark based on 3,000 real human-generated question-answer pairs over fine-tuned large models, introducing a dynamic evaluation protocol for quantifying context drift in interleaved VLMs. Experimental results demonstrate that IUT-Plug not only improves accuracy on established benchmarks but also effectively alleviates the three critical forms of context drift across diverse multimodal question answering (QA) scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10969","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.843144","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Zeteng Lin, Xingxing Li, Wen You, Xiaoyang Li, Zehan Lu, Yujun Cai, Jing Tang","raw_content_length":1304,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["an Image Understanding Tree","IUT-Plug","IUT"],"persons":["GPT-4"],"locations":[],"monetary":[]},"char_count":1303,"language_detected":"en","key_concepts":{"key_phrases":["IUT-Plug","A Plug","VLMs","arXiv251010969v1 Announce Type","new Abstract","Existing vision language models","GPT-4","DALL-E","logic","object identity"],"filter_categories":{"ai_ml":["GPT-4"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"IUT-Plug":3.0,"A Plug":2.0,"VLMs":2.0,"arXiv251010969v1 Announce Type":1.0,"new Abstract":1.0,"Existing vision language models":1.0,"GPT-4":1.0,"DALL-E":1.0,"logic":1.0,"object identity":1.0}},"age_hours":2.755287407777778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.772,"joy":0.0052,"surprise":0.012,"sadness":0.024,"fear":0.0941,"anger":0.0546,"disgust":0.0381},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new module (IUT-Plug) to improve the consistency of vision language models. While the technology aims to improve AI, there is no direct concrete action or measurable outcome related to climate change or sustainability. The paper mentions a novel benchmark based on 3,000 question-answer pairs, but this is for evaluation of the AI model, not a sustainability impact.","key_impact_metrics":[],"technology_tags":["vision language models","image understanding","artificial intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:43:52.785029Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a44d23fc75fe","title":"Chart","content":"arXiv:2510.10973v1 Announce Type: new Abstract: The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10973","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.843968","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Sanchit Sinha, Oana Frunza, Kashif Rasul, Yuriy Nevmyvaka, Aidong Zhang","raw_content_length":1397,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Large Vision-Language Models","SFT","CoT","Group Relative Policy Optimization","GRPO","Chart"],"persons":["Chart-RVR","Announce Type"],"locations":[],"monetary":["3-billion"]},"char_count":1396,"language_detected":"en","key_concepts":{"key_phrases":["Chart","arXiv251010973v1 Announce Type","new Abstract","The capabilities","Large Vision-Language Models","LVLMs","state","the-art","many visual reasoning tasks","chart reasoning"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chart":2.0,"arXiv251010973v1 Announce Type":1.0,"new Abstract":1.0,"The capabilities":1.0,"Large Vision-Language Models":1.0,"LVLMs":1.0,"state":1.0,"the-art":1.0,"many visual reasoning tasks":1.0,"chart reasoning":1.0}},"age_hours":2.755318243888889,"is_recent":true,"quality_score":0.7,"sentiment_score":5.2490000000000006,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0498,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8414,"joy":0.0043,"surprise":0.0441,"sadness":0.0226,"fear":0.0271,"anger":0.0378,"disgust":0.0227},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (Chart-RVR) to improve the robustness and explainability of Large Vision-Language Models for chart reasoning. While it improves model performance on chart reasoning tasks and rationale fidelity, it doesn't directly address climate change or environmental sustainability. The research is in the applied research stage, with no mention of deployment or commercialization.","key_impact_metrics":["OOD performance gap closing","Improved rationale fidelity"],"technology_tags":["Large Vision-Language Models","Chart Reasoning","Group Relative Policy Optimization"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:43:56.004350Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7beb99d424e6","title":"Enhancing Large Language Model Reasoning via Selective Critical Token Fine","content":"arXiv:2510.10974v1 Announce Type: new Abstract: Large language models (LLMs) primarily rely on supervised fine-tuning (SFT) as a key method to adapt pre-trained models to domain-specific tasks such as mathematical reasoning. However, standard SFT uniformly penalizes all tokens, neglecting that only a small subset of critical tokens determines reasoning correctness. This uniform supervision often causes reduced output diversity and limited generalization. We propose Critical Token Fine-tuning (CFT), a simple yet effective approach that updates only tokens identified as functionally indispensable via counterfactual perturbations. By focusing gradient signals on these decisive reasoning steps while preserving the diversity of non-critical tokens, CFT can enhance both generation and diversity. Extensive experiments on five models across three families (Qwen, OLMo, LLaMA) and eleven mathematical reasoning benchmarks show that CFT, despite fine-tuning on less than 12% of tokens, consistently outperforms standard SFT. Moreover, CFT enables test-time scaling through improved sampling diversity and provides a stronger initialization for reinforcement learning, sustaining performance gains in later training stages while maintaining higher entropy for better exploration. These results highlight CFT as a practical and general framework for efficient and robust LLM fine-tuning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10974","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.844362","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Zhiwen Ruan, Yixia Li, He Zhu, Yun Chen, Peng Li, Yang Liu, Guanhua Chen","raw_content_length":1388,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["CFT","SFT"],"persons":["Qwen"],"locations":[],"monetary":[]},"char_count":1387,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Model Reasoning","Selective Critical Token Fine","arXiv251010974v1 Announce Type","new Abstract","Large language models","LLMs","supervised fine-tuning SFT","a key method","pre-trained models","domain-specific tasks"],"filter_categories":{"ai_ml":["Large Language Model Reasoning","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Model Reasoning":2.0,"Selective Critical Token Fine":2.0,"arXiv251010974v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"supervised fine-tuning SFT":1.0,"a key method":1.0,"pre-trained models":1.0,"domain-specific tasks":1.0}},"age_hours":2.7553335447222222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7432,"joy":0.0047,"surprise":0.0126,"sadness":0.0369,"fear":0.0052,"anger":0.1174,"disgust":0.08},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel fine-tuning method (CFT) for LLMs that improves reasoning and diversity by focusing on critical tokens. The concrete action is the development and testing of this new fine-tuning approach. Evidence comes from experiments on five models across eleven benchmarks, showing CFT outperforms standard SFT while fine-tuning on less than 12% of tokens. The technology is at the basic research stage, with no deployment mentioned.","key_impact_metrics":["less than 12% of tokens fine-tuned","outperforms standard SFT"],"technology_tags":["large language models","fine-tuning","mathematical reasoning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:44:00.141908Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2223633b55db","title":"RoVer: Robot Reward Model as Test-Time Verifier for Vision","content":"arXiv:2510.10975v1 Announce Type: new Abstract: Vision-Language-Action (VLA) models have become a prominent paradigm for embodied intelligence, yet further performance improvements typically rely on scaling up training data and model size -- an approach that is prohibitively expensive for robotics and fundamentally limited by data collection costs.We address this limitation with $\\mathbf{RoVer}$, an embodied test-time scaling framework that uses a $\\mathbf{Ro}$bot Process Reward Model (PRM) as a Test-Time $\\mathbf{Ver}$ifier to enhance the capabilities of existing VLA models without modifying their architectures or weights. Specifically, RoVer (i) assigns scalar-based process rewards to evaluate the reliability of candidate actions, and (ii) predicts an action-space direction for candidate expansion/refinement. During inference, RoVer generates multiple candidate actions concurrently from the base policy, expands them along PRM-predicted directions, and then scores all candidates with PRM to select the optimal action for execution. Notably, by caching shared perception features, it can amortize perception cost and evaluate more candidates under the same test-time computational budget. Essentially, our approach effectively transforms available computing resources into better action decision-making, realizing the benefits of test-time scaling without extra training overhead. Our contributions are threefold: (1) a general, plug-and-play test-time scaling framework for VLAs; (2) a PRM that jointly provides scalar process rewards and an action-space direction to guide exploration; and (3) an efficient direction-guided sampling strategy that leverages a shared perception cache to enable scalable candidate generation and selection during inference.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10975","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.844802","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Mingtong Dai, Lingbo Liu, Yongjie Bai, Yang Liu, Zhouxia Wang, Rui SU, Chunjie Chen, Liang Lin, Xinyu Wu","raw_content_length":1772,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["PRM","Vision-Language-Action"],"persons":[],"locations":[],"monetary":["\\mathbf{Ro}$bot"]},"char_count":1771,"language_detected":"en","key_concepts":{"key_phrases":["RoVer","Robot Reward Model","Test-Time Verifier","Vision","arXiv251010975v1 Announce Type","new Abstract","VLA","a prominent paradigm","embodied intelligence","further performance improvements"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RoVer":2.0,"Robot Reward Model":2.0,"Test-Time Verifier":2.0,"Vision":2.0,"arXiv251010975v1 Announce Type":1.0,"new Abstract":1.0,"VLA":1.0,"a prominent paradigm":1.0,"embodied intelligence":1.0,"further performance improvements":1.0}},"age_hours":2.7553489733333336,"is_recent":true,"quality_score":1.0,"sentiment_score":9.200999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7857,"joy":0.0072,"surprise":0.0227,"sadness":0.0106,"fear":0.0799,"anger":0.0553,"disgust":0.0386},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to improving the efficiency of vision-language-action models in robotics. The concrete action is the development of a Robot Process Reward Model (PRM) used as a test-time verifier. The evidence is based on the proposed framework and algorithms, but there are no deployed units or real-world data presented, placing it at the basic research stage.","key_impact_metrics":[],"technology_tags":["robotics","machine learning","embodied intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:44:03.620103Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_db0d6082fa99","title":"Does LLM Focus on the Right Words? Diagnosing Language Bias in LLM","content":"arXiv:2510.10978v1 Announce Type: new Abstract: Large language models (LLMs), owing to their extensive open-domain knowledge and semantic reasoning capabilities, have been increasingly integrated into recommender systems (RS). However, a substantial gap remains between the pre-training objectives of LLMs and the specific requirements of recommendation tasks. To address this gap, supervised fine-tuning (SFT) is commonly performed on specially curated recommendation datasets to further enhance their predictive ability. Despite its success, SFT exhibits a critical limitation: it induces Language Bias, whereby the model over-relies on auxiliary tokens-such as task descriptions and prefix-generated tokens-while underutilizing core user interaction tokens that encode user-specific preferences. This bias not only undermines recommendation accuracy but also raises unfairness concerns. To address this issue, we propose Group Distributionally Robust Optimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces consistent model performance across token groups with varying degrees of relevance to auxiliary tokens. By adaptively upweighting underperforming groups, typically those weakly correlated with auxiliary tokens, GDRT shifts the model's attention from superficial auxiliary cues to informative user interaction tokens, thereby mitigating language bias. Extensive experiments conducted on three public datasets demonstrate that GDRT effectively mitigates language bias, yielding substantial improvements in recommendation accuracy (with an average NDCG@10 gain of 24.29%) and significantly enhancing recommendation fairness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10978","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.846292","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Bohao Wang, Jiawei Chen, Feng Liu, Changwang Zhang, Jun Wang, Canghong Jin, Chun Chen, Can Wang","raw_content_length":1655,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["SFT","Group Dis"],"persons":["Language Bias"],"locations":[],"monetary":[]},"char_count":1652,"language_detected":"en","key_concepts":{"key_phrases":["Does LLM Focus","the Right Words","Language Bias","LLM","LLMs","arXiv251010978v1 Announce Type","new Abstract","Large language models","their extensive open-domain knowledge","semantic reasoning capabilities"],"filter_categories":{"ai_ml":["Does LLM Focus","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Does LLM Focus":2.0,"the Right Words":2.0,"Language Bias":2.0,"LLM":2.0,"LLMs":2.0,"arXiv251010978v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"their extensive open-domain knowledge":1.0,"semantic reasoning capabilities":1.0}},"age_hours":2.7553923291666664,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9222,"joy":0.0045,"surprise":0.0438,"sadness":0.0073,"fear":0.009,"anger":0.0076,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel fine-tuning paradigm (GDRT) to mitigate language bias in LLMs used for recommender systems. The concrete action is the development and testing of this new algorithm. The evidence supporting the claims comes from experiments on three public datasets, showing an average NDCG@10 gain of 24.29%. This is currently in the basic research stage, with no deployment mentioned.","key_impact_metrics":["NDCG@10 gain of 24.29%"],"technology_tags":["Large Language Models","Recommender Systems","Fairness","Distributionally Robust Optimization"],"sdg_alignment":[9,10],"analyzed_at":"2025-10-29T11:44:07.215023Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1dea8348685a","title":"AMO","content":"arXiv:2510.10979v1 Announce Type: new Abstract: Accurate and robust heading estimation is crucial for unmanned aerial vehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered nature of indoor environments often introduces severe magnetic disturbances, which can significantly degrade heading accuracy. To address this challenge, this paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation approach for UAVs operating in magnetically disturbed environments. AMO-HEAD is a lightweight and computationally efficient Extended Kalman Filter (EKF) framework that leverages inertial and magnetic sensors to achieve reliable heading estimation. In the proposed approach, gyroscope angular rate measurements are integrated to propagate the quaternion state, which is subsequently corrected using accelerometer and magnetometer data. The corrected quaternion is then used to compute the UAV's heading. An adaptive process noise covariance method is introduced to model and compensate for gyroscope measurement noise, bias drift, and discretization errors arising from the Euler method integration. To mitigate the effects of external magnetic disturbances, a scaling factor is applied based on real-time magnetic deviation detection. A theoretical observability analysis of the proposed AMO-HEAD is performed using the Lie derivative. Extensive experiments were conducted in real world indoor environments with customized UAV platforms. The results demonstrate the effectiveness of the proposed algorithm in providing precise heading estimation under magnetically disturbed conditions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10979","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.846738","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Qizhi Guo, Siyuan Yang, Junning Lyu, Jianjun Sun, Defu Lin, Shaoming He","raw_content_length":1611,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["UAVs","UAV"],"persons":["AMO arXiv:2510.10979v1 Announce Type","Extended Kalman Filter"],"locations":[],"monetary":[]},"char_count":1610,"language_detected":"en","key_concepts":{"key_phrases":["AMO","UAVs","AMO-HEAD","arXiv251010979v1 Announce Type","new Abstract","Accurate and robust heading estimation","unmanned aerial vehicles","indoor inspection tasks","the cluttered nature","indoor environments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"AMO":2.0,"UAVs":2.0,"AMO-HEAD":2.0,"arXiv251010979v1 Announce Type":1.0,"new Abstract":1.0,"Accurate and robust heading estimation":1.0,"unmanned aerial vehicles":1.0,"indoor inspection tasks":1.0,"the cluttered nature":1.0,"indoor environments":1.0}},"age_hours":2.7554076605555555,"is_recent":true,"quality_score":0.7,"sentiment_score":2.1229999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5754,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7803,"joy":0.0078,"surprise":0.0214,"sadness":0.0254,"fear":0.1195,"anger":0.0284,"disgust":0.0173},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new algorithm (AMO-HEAD) for UAV heading estimation, improving accuracy in magnetically disturbed environments. While this could indirectly contribute to sustainability by enabling more efficient UAV operations (e.g., inspections), the direct climate impact is minimal and unquantified. The algorithm's effectiveness is demonstrated through experiments, but it's still in the applied research phase with no deployed units or commercial applications mentioned.","key_impact_metrics":["heading accuracy improvement","computational efficiency"],"technology_tags":["UAV","heading estimation","inertial sensors","magnetic sensors","Extended Kalman Filter"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:44:10.769813Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e523db93142","title":"Catch-Only-One: Non","content":"arXiv:2510.10982v1 Announce Type: new Abstract: Recent AI regulations call for data that remain useful for innovation while resistant to misuse, balancing utility with protection at the model level. Existing approaches either perturb data to make it unlearnable or retrain models to suppress transfer, but neither governs inference by unknown models, and both typically require control over training. We propose non-transferable examples (NEs), a training-free and data-agnostic input-side usage-control mechanism. We recode inputs within a model-specific low-sensitivity subspace, preserving outputs for the authorized model while reducing performance on unauthorized models through subspace misalignment. We establish formal bounds that guarantee utility for the authorized model and quantify deviation for unauthorized ones, with the Hoffman-Wielandt inequality linking degradation to spectral differences. Empirically, NEs retain performance on diverse vision backbones and state-of-the-art vision-language models under common preprocessing, whereas non-target models collapse even with reconstruction attempts. These results establish NEs as a practical means to preserve intended data utility while preventing unauthorized exploitation. Our project is available at https://trusted-system-lab.github.io/model-specificity","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10982","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.847572","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Zihan Wang, Zhiyong Ma, Zhongkui Ma, Shuofeng Liu, Akide Liu, Derui Wang, Minhui Xue, Guangdong Bai","raw_content_length":1326,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Hoffman"],"locations":[],"monetary":[]},"char_count":1325,"language_detected":"en","key_concepts":{"key_phrases":["Catch-Only-One Non","Announce Type","new Abstract","Recent AI regulations","data","innovation","misuse","utility","protection","the model level"],"filter_categories":{"ai_ml":["Recent AI regulations","data"],"business_innovation":["innovation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Catch-Only-One Non":2.0,"Announce Type":1.0,"new Abstract":1.0,"Recent AI regulations":1.0,"data":1.0,"innovation":1.0,"misuse":1.0,"utility":1.0,"protection":1.0,"the model level":1.0}},"age_hours":2.7554372394444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.058999999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4118,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9562,"joy":0.0073,"surprise":0.0137,"sadness":0.0031,"fear":0.0041,"anger":0.0105,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a method to control data usage in AI models, preventing unauthorized exploitation. While it has potential implications for responsible AI development and data governance, its direct impact on climate change or sustainability is minimal. The technical credibility is relatively high due to formal bounds and empirical results, but deployment readiness is low as it's still in the research phase.","key_impact_metrics":["Performance retention on authorized models","Performance degradation on unauthorized models"],"technology_tags":["AI security","Data governance","Model specificity"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T11:44:23.621536Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_edaed3c1994d","title":"A Constrained Multi","content":"arXiv:2510.10984v1 Announce Type: new Abstract: Recently, multi-fidelity Bayesian optimization (MFBO) has been successfully applied to many engineering design optimization problems, where the cost of high-fidelity simulations and experiments can be prohibitive. However, challenges remain for constrained optimization problems using the MFBO framework, particularly in efficiently identifying the feasible region defined by the constraints. In this paper, we propose a constrained multi-fidelity Bayesian optimization (CMFBO) method with novel acquisition functions. Specifically, we design efficient acquisition functions that 1) have analytically closed-form expressions; 2) are straightforward to implement; and 3) do not require feasible initial samples, an important feature often missing in commonly used acquisition functions such as expected constrained improvement (ECI). We demonstrate the effectiveness of our algorithms on synthetic test problems using different combinations of acquisition functions. Then, we apply the proposed method to a data-driven inertial confinement fusion (ICF) design problem, and a high-current joint design problem using finite element simulations with computational contact mechanics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10984","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.847971","language":"en","tags":["statml","computer-science","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Jingyi Wang, Nai-Yuan Chiang, Tucker Hartland, J. Luc Peterson, Jerome Solberg, Cosmin G. Petra","raw_content_length":1227,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["ECI","MFBO"],"persons":[],"locations":[],"monetary":[]},"char_count":1226,"language_detected":"en","key_concepts":{"key_phrases":["A Constrained Multi","arXiv251010984v1 Announce Type","new Abstract","multi-fidelity Bayesian optimization","MFBO","many engineering design optimization problems","the cost","high-fidelity simulations","experiments","challenges"],"filter_categories":{"ai_ml":["A Constrained Multi"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Constrained Multi":2.0,"arXiv251010984v1 Announce Type":1.0,"new Abstract":1.0,"multi-fidelity Bayesian optimization":1.0,"MFBO":1.0,"many engineering design optimization problems":1.0,"the cost":1.0,"high-fidelity simulations":1.0,"experiments":1.0,"challenges":1.0}},"age_hours":2.7554510725,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8515,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7703,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8147,"joy":0.0676,"surprise":0.0698,"sadness":0.0062,"fear":0.0151,"anger":0.0213,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a new method (CMFBO) for constrained multi-fidelity Bayesian optimization, which is applied to engineering design problems. The concrete action is the development of new acquisition functions and their testing on synthetic problems and two specific design problems (ICF and high-current joint design). The evidence is based on simulations, but there is no mention of deployed technology or measured outcomes in real-world settings, hence the low deployment readiness.","key_impact_metrics":[],"technology_tags":["Bayesian Optimization","Multi-fidelity Simulation","Engineering Design"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:44:26.903219Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06179a9f32ec","title":"DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation","content":"arXiv:2510.10987v1 Announce Type: new Abstract: The promise of LLM watermarking rests on a core assumption that a specific watermark proves authorship by a specific model. We demonstrate that this assumption is dangerously flawed. We introduce the threat of watermark spoofing, a sophisticated attack that allows a malicious model to generate text containing the authentic-looking watermark of a trusted, victim model. This enables the seamless misattribution of harmful content, such as disinformation, to reputable sources. The key to our attack is repurposing watermark radioactivity, the unintended inheritance of data patterns during fine-tuning, from a discoverable trait into an attack vector. By distilling knowledge from a watermarked teacher model, our framework allows an attacker to steal and replicate the watermarking signal of the victim model. This work reveals a critical security gap in text authorship verification and calls for a paradigm shift towards technologies capable of distinguishing authentic watermarks from expertly imitated ones. Our code is available at https://github.com/hsannn/ditto.git.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10987","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.848765","language":"en","tags":["computer-science","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Hyeseon Ahn, Shinwoo Park, Yo-Sub Han","raw_content_length":1124,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["LLM","Knowledge Distillation arXiv:2510.10987v1"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1123,"language_detected":"en","key_concepts":{"key_phrases":["DITTO","A Spoofing Attack Framework","Watermarked LLMs","Knowledge Distillation","arXiv251010987v1 Announce Type","new Abstract","The promise","LLM watermarking","a core assumption","a specific watermark"],"filter_categories":{"ai_ml":["Watermarked LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DITTO":2.0,"A Spoofing Attack Framework":2.0,"Watermarked LLMs":2.0,"Knowledge Distillation":2.0,"arXiv251010987v1 Announce Type":1.0,"new Abstract":1.0,"The promise":1.0,"LLM watermarking":1.0,"a core assumption":1.0,"a specific watermark":1.0}},"age_hours":2.75548004,"is_recent":true,"quality_score":1.0,"sentiment_score":0.842,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8316,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0739,"joy":0.0033,"surprise":0.009,"sadness":0.0064,"fear":0.7708,"anger":0.1149,"disgust":0.0217},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework to attack watermarking in LLMs. While the research is technically sound and peer-reviewed, it does not directly contribute to reducing GHG emissions or promoting sustainability. It focuses on cybersecurity aspects of AI, which could indirectly impact sustainability efforts if AI is used for climate modeling or resource management.","key_impact_metrics":[],"technology_tags":["AI","LLM","watermarking","security"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T11:44:30.294365Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_369d07760951","title":"Crane Scheduling Problem with Energy Saving","content":"arXiv:2510.10989v1 Announce Type: new Abstract: During loading and unloading steps, energy is consumed when cranes lift containers, while energy is often wasted when cranes drop containers. By optimizing the scheduling of cranes, it is possible to reduce energy consumption, thereby lowering operational costs and environmental impacts. In this paper, we introduce a single-crane scheduling problem with energy savings, focusing on reusing the energy from containers that have already been lifted and reducing the total energy consumption of the entire scheduling plan. We establish a basic model considering a one-dimensional storage area and provide a systematic complexity analysis of the problem. First, we investigate the connection between our problem and the semi-Eulerization problem and propose an additive approximation algorithm. Then, we present a polynomial-time Dynamic Programming (DP) algorithm for the case of bounded energy buffer and processing lengths. Next, adopting a Hamiltonian perspective, we address the general case with arbitrary energy buffer and processing lengths. We propose an exact DP algorithm and show that the variation of the problem is polynomially solvable when it can be transformed into a path cover problem on acyclic interval digraphs. We introduce a paradigm that integrates both the Eulerian and Hamiltonian perspectives, providing a robust framework for addressing the problem.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10989","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.849164","language":"en","tags":["preprints","research","computer-science","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Yixiong Gao, Florian Jaehn, Minming Li, Wenhao Ma, Xinbo Zhang","raw_content_length":1425,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Energy Saving arXiv:2510.10989v1 Announce Type","Crane Scheduling Problem"],"persons":[],"locations":[],"monetary":[]},"char_count":1424,"language_detected":"en","key_concepts":{"key_phrases":["cranes","containers","Crane Scheduling Problem","Energy Saving","energy","arXiv251010989v1 Announce Type","new Abstract","loading and unloading steps","the scheduling","energy consumption"],"filter_categories":{"ai_ml":["containers"],"hydrogen_energy":["energy"],"renewable_energy":["energy"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"cranes":3.0,"containers":3.0,"Crane Scheduling Problem":2.0,"Energy Saving":2.0,"energy":2.0,"arXiv251010989v1 Announce Type":1.0,"new Abstract":1.0,"loading and unloading steps":1.0,"the scheduling":1.0,"energy consumption":1.0}},"age_hours":2.7554950069444444,"is_recent":true,"quality_score":1.0,"sentiment_score":6.1315,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2263,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6928,"joy":0.0105,"surprise":0.0105,"sadness":0.0189,"fear":0.0204,"anger":0.1121,"disgust":0.1348},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents algorithms for optimizing crane scheduling to reduce energy consumption. While the research has technical merit and is peer-reviewed, it is still in the basic research phase with no deployed technology or measured outcomes. The economic viability is unclear as there is no cost analysis or demonstration of demand.","key_impact_metrics":[],"technology_tags":["crane scheduling","energy optimization","dynamic programming"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T11:44:33.681110Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1402e1917bec","title":"A Survey on Agentic Multimodal Large Language Models","content":"arXiv:2510.10991v1 Announce Type: new Abstract: With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10991","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.849997","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Huanjin Yao, Ruifei Zhang, Jiaxing Huang, Jingyi Zhang, Yibo Wang, Bo Fang, Ruolin Zhu, Yongcheng Jing, Shunyu Liu, Guanbin Li, Dacheng Tao","raw_content_length":1788,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["AGI","Agentic Multimodal Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1787,"language_detected":"en","key_concepts":{"key_phrases":["Agentic Multimodal Large Language Models","A Survey","arXiv251010991v1 Announce Type","new Abstract","the recent emergence","revolutionary autonomous agentic systems","research community","a significant shift","passive and domain-specific AI agents","the growing interest"],"filter_categories":{"ai_ml":["Agentic Multimodal Large Language Models"],"research_academic":["research community"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Agentic Multimodal Large Language Models":3.0,"A Survey":2.0,"arXiv251010991v1 Announce Type":1.0,"new Abstract":1.0,"the recent emergence":1.0,"revolutionary autonomous agentic systems":1.0,"research community":1.0,"a significant shift":1.0,"passive and domain-specific AI agents":1.0,"the growing interest":1.0}},"age_hours":2.755524418611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.7285,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9457,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5903,"joy":0.044,"surprise":0.0442,"sadness":0.005,"fear":0.2358,"anger":0.0551,"disgust":0.0255},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article is a survey of research on agentic multimodal large language models. While AI could potentially be used to optimize resource usage and reduce emissions in the future, this survey is at a very early stage and does not present any concrete actions or measurable outcomes related to sustainability. It is primarily a literature review and compilation of resources.","key_impact_metrics":[],"technology_tags":["AI","Large Language Models","Multimodal Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:44:36.836079Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_285982a60d5e","title":"Perspective","content":"arXiv:2510.10993v1 Announce Type: new Abstract: 3D Gaussian inpainting, a critical technique for numerous applications in virtual reality and multimedia, has made significant progress with pretrained diffusion models. However, ensuring multi-view consistency, an essential requirement for high-quality inpainting, remains a key challenge. In this work, we present PAInpainter, a novel approach designed to advance 3D Gaussian inpainting by leveraging perspective-aware content propagation and consistency verification across multi-view inpainted images. Our method iteratively refines inpainting and optimizes the 3D Gaussian representation with multiple views adaptively sampled from a perspective graph. By propagating inpainted images as prior information and verifying consistency across neighboring views, PAInpainter substantially enhances global consistency and texture fidelity in restored 3D scenes. Extensive experiments demonstrate the superiority of PAInpainter over existing methods. Our approach achieves superior 3D inpainting quality, with PSNR scores of 26.03 dB and 29.51 dB on the SPIn-NeRF and NeRFiller datasets, respectively, highlighting its effectiveness and generalization capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10993","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.850858","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Yuxin Cheng, Binxiao Huang, Taiqiang Wu, Wenyong Zhou, Chenchen Ding, Zhengwu Liu, Graziano Chesi, Ngai Wong","raw_content_length":1210,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["PAInpainter"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1209,"language_detected":"en","key_concepts":{"key_phrases":["Perspective","arXiv251010993v1 Announce Type","new Abstract","a critical technique","numerous applications","virtual reality","multimedia","significant progress","pretrained diffusion models","multi-view consistency"],"filter_categories":{"ai_ml":["pretrained diffusion models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Perspective":2.0,"arXiv251010993v1 Announce Type":1.0,"new Abstract":1.0,"a critical technique":1.0,"numerous applications":1.0,"virtual reality":1.0,"multimedia":1.0,"significant progress":1.0,"pretrained diffusion models":1.0,"multi-view consistency":1.0}},"age_hours":2.7555385319444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8829,"joy":0.0535,"surprise":0.0353,"sadness":0.0056,"fear":0.0044,"anger":0.0129,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to 3D Gaussian inpainting. While the technology shows promise with improved PSNR scores (26.03 dB and 29.51 dB), it is still in the applied research stage with no evidence of real-world deployment or economic viability. The climate impact is minimal as it primarily focuses on virtual reality applications.","key_impact_metrics":["PSNR score of 26.03 dB","PSNR score of 29.51 dB"],"technology_tags":["3D Gaussian inpainting","diffusion models","virtual reality"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:44:39.925637Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a39e4ebccc4a","title":"DeepResearchGuard: Deep Research with Open","content":"arXiv:2510.10994v1 Announce Type: new Abstract: Deep research frameworks have shown promising capabilities in synthesizing comprehensive reports from web sources. While deep research possesses significant potential to address complex issues through planning and research cycles, existing frameworks are deficient in sufficient evaluation procedures and stage-specific protections. They typically treat evaluation as exact match accuracy of question-answering, but overlook crucial aspects of report quality such as credibility, coherence, breadth, depth, and safety. This oversight may result in hazardous or malicious sources being integrated into the final report. To address these issues, we introduce DEEPRESEARCHGUARD, a comprehensive framework featuring four-stage safeguards with open-domain evaluation of references and reports. We assess performance across multiple metrics, e.g., defense success rate and over-refusal rate, and five key report dimensions. In the absence of a suitable safety benchmark, we introduce DRSAFEBENCH, a stage-wise benchmark for deep research safety. Our evaluation spans diverse state-of-the-art LLMs, including GPT-4o, Gemini-2.5-flash, DeepSeek-v3, and o4-mini. DEEPRESEARCHGUARD achieves an average defense success rate improvement of 18.16% while reducing over-refusal rate by 6%. The input guard provides the most substantial early-stage protection by filtering out obvious risks, while the plan and research guards enhance citation discipline and source credibility. Through extensive experiments, we show that DEEPRESEARCHGUARD enables comprehensive open-domain evaluation and stage-aware defenses that effectively block harmful content propagation, while systematically improving report quality without excessive over-refusal rates. The code can be found via https://github.com/Jasonya/DeepResearchGuard.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10994","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.851306","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Wei-Chieh Huang, Henry Peng Zou, Yaozu Wu, Dongyuan Li, Yankai Chen, Weizhi Zhang, Yangning Li, Angelo Zangari, Jizhou Guo, Chunyu Miao, Liancheng Fang, Langzhou He, Renhe Jiang, Philip S. Yu","raw_content_length":1851,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":["DEEPRESEARCHGUARD"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1850,"language_detected":"en","key_concepts":{"key_phrases":["DeepResearchGuard","Deep Research","Open","arXiv251010994v1 Announce Type","new Abstract","Deep research frameworks","promising capabilities","comprehensive reports","web sources","deep research"],"filter_categories":{"research_academic":["DeepResearchGuard","Deep Research","Deep research frameworks","deep research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepResearchGuard":2.0,"Deep Research":2.0,"Open":2.0,"arXiv251010994v1 Announce Type":1.0,"new Abstract":1.0,"Deep research frameworks":1.0,"promising capabilities":1.0,"comprehensive reports":1.0,"web sources":1.0,"deep research":1.0}},"age_hours":2.7555529269444445,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8841,"joy":0.0065,"surprise":0.025,"sadness":0.0183,"fear":0.0124,"anger":0.0329,"disgust":0.0208},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the safety and quality of deep research frameworks, which indirectly supports sustainability by ensuring information used for decision-making is credible and reliable. The framework is in the applied research stage, with performance metrics like defense success rate and over-refusal rate being measured. However, there are no deployed units or direct economic viability data.","key_impact_metrics":["defense success rate improvement with 18.16%","over-refusal rate reduction with 6%"],"technology_tags":["AI safety","LLM","Deep Research"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T11:44:42.868227Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bf3606db632f","title":"MSRBench: A Benchmarking Dataset for Music Source Restoration","content":"arXiv:2510.10995v1 Announce Type: new Abstract: Music Source Restoration (MSR) extends source separation to realistic settings where signals undergo production effects (equalization, compression, reverb) and real-world degradations, with the goal of recovering the original unprocessed sources. Existing benchmarks cannot measure restoration fidelity: synthetic datasets use unprocessed stems but unrealistic mixtures, while real production datasets provide only already-processed stems without clean references. We present MSRBench, the first benchmark explicitly designed for MSR evaluation. MSRBench contains raw stem-mixture pairs across eight instrument classes, where mixtures are produced by professional mixing engineers. These raw-processed pairs enable direct evaluation of both separation accuracy and restoration fidelity. Beyond controlled studio conditions, the mixtures are augmented with twelve real-world degradations spanning analog artifacts, acoustic environments, and lossy codecs. Baseline experiments with U-Net and BSRNN achieve SI-SNR of -37.8 dB and -23.4 dB respectively, with perceptual quality (FAD CLAP) around 0.7-0.8, demonstrating substantial room for improvement and the need for restoration-specific architectures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10995","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.851740","language":"en","tags":["computer-science","research","cssd","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Yongyi Zang, Jiarui Hai, Wanying Ge, Qiuqiang Kong, Zheqi Dai, Helin Wang, Yuki Mitsufuji, Mark D. Plumbley","raw_content_length":1250,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["MSR"],"persons":[],"locations":[],"monetary":[]},"char_count":1249,"language_detected":"en","key_concepts":{"key_phrases":["Music Source Restoration","MSRBench","A Benchmarking Dataset","arXiv251010995v1 Announce Type","new Abstract","MSR","source separation","realistic settings","signals","production effects"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Music Source Restoration":3.0,"MSRBench":2.0,"A Benchmarking Dataset":2.0,"arXiv251010995v1 Announce Type":1.0,"new Abstract":1.0,"MSR":1.0,"source separation":1.0,"realistic settings":1.0,"signals":1.0,"production effects":1.0}},"age_hours":2.7555671425000003,"is_recent":true,"quality_score":1.0,"sentiment_score":5.1935,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0387,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8966,"joy":0.0086,"surprise":0.0661,"sadness":0.0064,"fear":0.0035,"anger":0.0124,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark dataset for music source restoration, which could indirectly support sustainability by improving the efficiency of audio production and reducing waste. However, the direct climate impact is minimal as it's primarily focused on improving audio processing algorithms. The technical credibility is relatively high due to the use of professional mixing engineers and real-world degradations in the dataset, along with baseline experiments providing measurable outcomes (SI-SNR, FAD CLAP).","key_impact_metrics":["SI-SNR of -37.8 dB","FAD CLAP around 0.7-0.8"],"technology_tags":["Music Source Separation","Audio Restoration","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:44:46.491217Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
