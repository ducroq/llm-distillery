{"id":"science_arxiv_cs_c129d1e4b213","title":"Pad\\'e Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data","content":"arXiv:2507.02599v2 Announce Type: replace Abstract: Purpose: The primary aim of this study is to enhance fault diagnosis in induction machines by leveraging the Pad\\'e Approximant Neuron (PAON) model. While accelerometers and microphones are standard in motor condition monitoring, deep learning models with nonlinear neuron architectures offer promising improvements in diagnostic performance. This research investigates whether Pad\\'e Approximant Neural Networks (Pad\\'eNets) can outperform conventional Convolutional Neural Networks (CNNs) and Self-Organized Operational Neural Networks (Self-ONNs) in the diagnosis of electrical and mechanical faults from vibration and acoustic data. Methods: We evaluate and compare the diagnostic capabilities of three deep learning architectures: one-dimensional CNNs, Self-ONNs, and Pad\\'eNets. These models are tested on the University of Ottawa's publicly available constant-speed induction motor datasets, which include both vibration and acoustic sensor data. The Pad\\'eNet model is designed to introduce enhanced nonlinearity and is compatible with unbounded activation functions such as LeakyReLU. Results and Conclusion: Pad\\'eNets consistently outperformed the baseline models, achieving diagnostic accuracies of 99.96%, 98.26%, 97.61%, and 98.33% for accelerometers 1, 2, 3, and the acoustic sensor, respectively. The enhanced nonlinearity of Pad\\'eNets, together with their compatibility with unbounded activation functions, significantly improves fault diagnosis performance in induction motor condition monitoring.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.02599","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.614110","language":"en","tags":["preprints","eesssy","computer-science","cslg","research","cssy","cssd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Sertac Kilickaya, Levent Eren","raw_content_length":1573,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["PAON","Self-Organized Operational Neural Networks","Convolutional Neural Networks","the University of Ottaw","Pad\\'e Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data arXiv:2507.02599v2","Pad\\'e Approximant Neural Networks"],"persons":[],"locations":[],"monetary":[]},"char_count":1568,"language_detected":"en","key_concepts":{"key_phrases":["Pade Approximant Neural Networks","Enhanced Electric Motor Fault Diagnosis","Vibration","Acoustic Data","Announce Type","Abstract","Purpose","The primary aim","this study","fault diagnosis"],"filter_categories":{"ai_ml":["Pade Approximant Neural Networks"],"research_academic":["this study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Pade Approximant Neural Networks":3.0,"Enhanced Electric Motor Fault Diagnosis":2.0,"Vibration":2.0,"Acoustic Data":2.0,"Announce Type":1.0,"Abstract":1.0,"Purpose":1.0,"The primary aim":1.0,"this study":1.0,"fault diagnosis":1.0}},"age_hours":2.7477575302777777,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8853,"joy":0.013,"surprise":0.0429,"sadness":0.0073,"fear":0.027,"anger":0.0152,"disgust":0.0092},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural network architecture for improved fault diagnosis in electric motors, potentially leading to increased efficiency and reduced downtime. The research provides specific diagnostic accuracy metrics (99.96%, 98.26%, 97.61%, and 98.33%) but is still in the applied research phase, lacking real-world deployment data and economic viability analysis. It is flagged as vaporware because it is a prototype tested on existing datasets, not yet deployed.","key_impact_metrics":["Diagnostic accuracies of 99.96%","Diagnostic accuracies of 98.26%"],"technology_tags":["Pad√© Approximant Neural Networks","Fault Diagnosis"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T16:47:31.172739Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d694ba7dd447","title":"Globally Stable Discrete Time PID Passivity","content":"arXiv:2508.18719v2 Announce Type: replace Abstract: The key idea behind PID Passivity-based Control (PID-PBC) is to leverage the passivity property of PIDs (for all positive gains) and wrap the PID controller around a passive output to ensure global stability in closed-loop. However, the practical applicability of PID-PBC is stymied by two key facts: (i) the vast majority of practical implementations of PIDs is carried-out in discrete time -- discretizing the continuous time dynamical system of the PID; (ii) the well-known problem that passivity is not preserved upon discretization, even with small sampling times. Therefore, two aspects of the PID-PBC must be revisited for its safe practical application. First, we propose a discretization of the PID that ensures its passivity. Second, since the output that is identified as passive for the continuous time system is not necessarily passive for its discrete time version, we construct a new output that ensures the passivity property for the discretization of the system. In this paper, we provide a constructive answer to both issues for the case of power converter models. Instrumental to achieve this objective is the use of the implicit midpoint discretization method -- which is a symplectic integration technique that preserves system invariants. Since the reference value for the output to be regulated in power converters is non-zero, we are henceforth interested in the property of passivity of the incremental model -- currently known as shifted passivity. Therefore, we demonstrate that the resulting discrete-time PID-PBC defines a passive map for the incremental model and establish shifted passivity for the discretized power converter model. Combining these properties, we prove global stability for the feedback interconnection of the power converter with the discretized PID-PBC. The paper also presents simulations and experiments that demonstrate the performance of the proposed discretization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18719","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.646319","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":294,"author":"Alessio Moreschini, Wei He, Romeo Ortega, Yiheng Lu, Tao Li","raw_content_length":1974,"priority":7,"update_frequency":1,"reading_time_minutes":1.47,"robust_parsing_used":true,"entities":{"organizations":["PID","PID Passivity","Control (PID-PBC"],"persons":[],"locations":[],"monetary":[]},"char_count":1973,"language_detected":"en","key_concepts":{"key_phrases":["Globally Stable Discrete Time PID Passivity","PID-PBC","PIDs","Announce Type","Abstract","The key idea","PID Passivity-based Control","the passivity property","all positive gains","the PID controller"],"filter_categories":{"ai_ml":["all positive gains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Globally Stable Discrete Time PID Passivity":2.0,"PID-PBC":2.0,"PIDs":2.0,"Announce Type":1.0,"Abstract":1.0,"The key idea":1.0,"PID Passivity-based Control":1.0,"the passivity property":1.0,"all positive gains":1.0,"the PID controller":1.0}},"age_hours":2.7483272519444446,"is_recent":true,"quality_score":1.0,"sentiment_score":9.455,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.891,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9044,"joy":0.0071,"surprise":0.0219,"sadness":0.019,"fear":0.0101,"anger":0.017,"disgust":0.0205},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel discretization method for PID controllers in power converters, aiming to improve stability and efficiency. The concrete action is the development of a new discretization technique and its validation through simulations and experiments. While promising, the technology is still in the applied research phase, lacking real-world deployment data and economic viability analysis.","key_impact_metrics":["Passivity of the incremental model","Global stability for the feedback interconnection"],"technology_tags":["PID control","Power converters","Discrete-time systems","Passivity-based control"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:47:35.183119Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_49b04f4c8ff3","title":"Constraint Matters: Multi","content":"arXiv:2508.18742v2 Announce Type: replace Abstract: Model reduction, which aims to learn a simpler model of the original mixed integer linear programming (MILP), can solve large-scale MILP problems much faster. Most existing model reduction methods are based on variable reduction, which predicts a solution value for a subset of variables. From a dual perspective, constraint reduction that transforms a subset of inequality constraints into equalities can also reduce the complexity of MILP, but has been largely ignored. Therefore, this paper proposes a novel constraint-based model reduction approach for the MILP. Constraint-based MILP reduction has two challenges: 1) which inequality constraints are critical such that reducing them can accelerate MILP solving while preserving feasibility, and 2) how to predict these critical constraints efficiently. To identify critical constraints, we first label these tight-constraints at the optimal solution as potential critical constraints and design a heuristic rule to select a subset of critical tight-constraints. To learn the critical tight-constraints, we propose a multi-modal representation technique that leverages information from both instance-level and abstract-level MILP formulations. The experimental results show that, compared to the state-of-the-art methods, our method improves the quality of the solution by over 50\\% and reduces the computation time by 17.47\\%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.18742","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.646747","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Jiajun Li, Ran Hou, Yu Ding, Yixuan Li, Shisi Guan, Jiahui Duan, Xiongwei Han, Tao Zhong, Vincent Chau, Weiwei Wu, Wanyuan Wang","raw_content_length":1434,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":["integer linear programming","Constraint Matters"],"persons":[],"locations":[],"monetary":[]},"char_count":1433,"language_detected":"en","key_concepts":{"key_phrases":["Constraint Matters","Multi","which","MILP","a subset","Announce Type","Abstract","Model reduction","a simpler model","the original mixed integer linear programming"],"filter_categories":{"ai_ml":["Constraint Matters"],"engineering":["the original mixed integer linear programming"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Constraint Matters":2.0,"Multi":2.0,"which":2.0,"MILP":2.0,"a subset":2.0,"Announce Type":1.0,"Abstract":1.0,"Model reduction":1.0,"a simpler model":1.0,"the original mixed integer linear programming":1.0}},"age_hours":2.7483419552777777,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6369,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.935,"joy":0.0142,"surprise":0.0155,"sadness":0.0032,"fear":0.0101,"anger":0.0142,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel constraint-based model reduction approach for MILP, aiming to solve large-scale problems faster. The experimental results show a 50% improvement in solution quality and a 17.47% reduction in computation time compared to state-of-the-art methods. However, it is still in the research phase with no deployed units or customer contracts.","key_impact_metrics":["50% improvement in solution quality","17.47% reduction in computation time"],"technology_tags":["Model Reduction","Mixed Integer Linear Programming"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:47:38.158225Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8f66215f7a79","title":"Diffusion Language Models Know the Answer Before Decoding","content":"arXiv:2508.19982v3 Announce Type: replace Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go \"all-in\" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at https://github.com/pixeli99/Prophet.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.19982","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.652322","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Pengxiang Li, Yefan Zhou, Dilxat Muhtar, Lu Yin, Shilin Yan, Li Shen, Yi Liang, Soroush Vosoughi, Shiwei Liu","raw_content_length":1802,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["the Answer Before Decoding arXiv:2508.19982v3","GSM8K"],"persons":["Announce Type","Prophet"],"locations":[],"monetary":[]},"char_count":1801,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Language Models","the Answer","DLMs","arXiv250819982v3 Announce Type","Abstract","Diffusion language models","an alternative","autoregressive approaches","parallel sequence generation","flexible token orders"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Language Models":2.0,"the Answer":2.0,"DLMs":2.0,"arXiv250819982v3 Announce Type":1.0,"Abstract":1.0,"Diffusion language models":1.0,"an alternative":1.0,"autoregressive approaches":1.0,"parallel sequence generation":1.0,"flexible token orders":1.0}},"age_hours":2.7483570247222224,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9424,"joy":0.0066,"surprise":0.0299,"sadness":0.0078,"fear":0.0026,"anger":0.0057,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new method (Prophet) to accelerate diffusion language model inference, reducing decoding steps by up to 3.4x while maintaining generation quality. This could indirectly reduce energy consumption associated with large language model usage, although the actual energy savings are not quantified. The research is in the applied research stage, with code publicly available but no large-scale deployment data.","key_impact_metrics":["decoding steps reduced by up to 3.4x","97% of GSM8K instances decoded correctly with half steps"],"technology_tags":["diffusion language models","machine learning","artificial intelligence"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:47:41.368129Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c9d0507bdf1","title":"DFAMS: Dynamic","content":"arXiv:2508.20353v2 Announce Type: replace Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge sources, to mitigate hallucinations of LLMs, when necessary external knowledge is distributed. However, existing methods struggle to retrieve high-quality and relevant documents for ambiguous queries, especially in cross-domain scenarios, which significantly limits their effectiveness in supporting downstream generation tasks. Inspired by Dynamic Information Flow (DIF), we propose DFAMS, a novel framework that leverages DIF to identify latent query intents and construct semantically aligned knowledge partitions for accurate retrieval across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by leveraging gradient signals from a few annotated queries and employing Shapley value-based attribution to trace neuron activation paths associated with intent recognition and subdomain boundary detection. Then, DFAMS leverages DIF to train an alignment module via multi-prototype contrastive learning, enabling fine-grained intra-source modeling and inter-source semantic alignment across knowledge bases. Experimental results across five benchmarks show that DFAMS outperforms advanced FR methods by up to 14.37\\% in knowledge classification accuracy, 5.38\\% in retrieval recall, and 6.45\\% in downstream QA accuracy, demonstrating its effectiveness in complex FR scenarios. Our code are anonymous available at https://anonymous.4open.science/r/DFAMS/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.20353","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.652810","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Zhibang Yang, Xinke Jiang, Rihong Qiu, Ruiqing Li, Yihang Zhang, Yue Fang, Yongxin Xu, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang","raw_content_length":1496,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["DIF","Shapley","Federated Retrieval","DFAMS"],"persons":[],"locations":[],"monetary":[]},"char_count":1495,"language_detected":"en","key_concepts":{"key_phrases":["arXiv250820353v2","Announce Type","Abstract","Federated Retrieval","routes","multiple external knowledge sources","hallucinations","LLMs","necessary external knowledge","existing methods"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv250820353v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Federated Retrieval":1.0,"routes":1.0,"multiple external knowledge sources":1.0,"hallucinations":1.0,"LLMs":1.0,"necessary external knowledge":1.0,"existing methods":1.0}},"age_hours":2.7483711544444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.200999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8346,"joy":0.0078,"surprise":0.0188,"sadness":0.0146,"fear":0.045,"anger":0.0477,"disgust":0.0315},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (DFAMS) for federated retrieval, aiming to improve the accuracy of information retrieval across heterogeneous sources. The concrete action is the development and testing of this framework, with measurable outcomes reported in terms of knowledge classification accuracy, retrieval recall, and downstream QA accuracy. However, it is still in the applied research stage, lacking deployment and economic viability data.","key_impact_metrics":["knowledge classification accuracy 14.37%","retrieval recall 5.38%"],"technology_tags":["federated retrieval","dynamic information flow"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:47:44.198651Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1441c2c6b6c5","title":"ChatThero: An LLM","content":"arXiv:2508.20996v2 Announce Type: replace Abstract: Substance use disorders (SUDs) affect millions of people, and relapses are common, requiring multi-session treatments. Access to care is limited, which contributes to the challenge of recovery support. We present \\textbf{ChatThero}, an innovative low-cost, multi-session, stressor-aware, and memory-persistent autonomous \\emph{language agent} designed to facilitate long-term behavior change and therapeutic support in addiction recovery. Unlike existing work that mostly finetuned large language models (LLMs) on patient-therapist conversation data, ChatThero was trained in a multi-agent simulated environment that mirrors real therapy. We created anonymized patient profiles from recovery communities (e.g., Reddit). We classify patients as \\texttt{easy}, \\texttt{medium}, and \\texttt{difficult}, three scales representing their resistance to recovery. We created an external environment by introducing stressors (e.g., social determinants of health) to simulate real-world situations. We dynamically inject clinically-grounded therapeutic strategies (motivational interview and cognitive behavioral therapy). Our evaluation, conducted by both human (blinded clinicians) and LLM-as-Judge, shows that ChatThero is superior in empathy and clinical relevance. We show that stressor simulation improves robustness of ChatThero. Explicit stressors increase relapse-like setbacks, matching real-world patterns. We evaluate ChatThero with behavioral change metrics. On a 1--5 scale, ChatThero raises \\texttt{motivation} by $+1.71$ points (from $2.39$ to $4.10$) and \\texttt{confidence} by $+1.67$ points (from $1.52$ to $3.19$), substantially outperforming GPT-5. On \\texttt{difficult} patients, ChatThero reaches the success milestone with $26\\%$ fewer turns than GPT-5.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2508.20996","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.653252","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Junda Wang, Zonghai Yao, Lingxi Li, Junhui Qian, Zhichao Yang, Hong Yu","raw_content_length":1820,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["ChatThero"],"persons":[],"locations":["Reddit"],"monetary":[]},"char_count":1819,"language_detected":"en","key_concepts":{"key_phrases":["ChatThero","An LLM","arXiv250820996v2","Announce Type","Abstract","SUDs","millions","people","relapses","multi-session treatments"],"filter_categories":{"ai_ml":["An LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ChatThero":2.0,"An LLM":2.0,"arXiv250820996v2":1.0,"Announce Type":1.0,"Abstract":1.0,"SUDs":1.0,"millions":1.0,"people":1.0,"relapses":1.0,"multi-session treatments":1.0}},"age_hours":2.7483864727777774,"is_recent":true,"quality_score":1.0,"sentiment_score":9.36,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.872,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9062,"joy":0.0131,"surprise":0.0421,"sadness":0.018,"fear":0.0114,"anger":0.0058,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":7,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on an LLM for addiction recovery. The concrete action is the development and evaluation of ChatThero in a simulated environment, showing improvements in motivation and confidence. The evidence is based on blinded clinician evaluations and LLM-as-Judge assessments, but it remains in the applied research stage without real-world deployment.","key_impact_metrics":["motivation +1.71","confidence +1.67"],"technology_tags":["LLM","AI Therapy","Behavioral Change"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:47:47.741639Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_428be46a214f","title":"Context","content":"arXiv:2509.00648v2 Announce Type: replace Abstract: We consider off-policy evaluation (OPE) in contextual bandits with finite action space. Inverse Propensity Score (IPS) weighting is a widely used method for OPE due to its unbiased, but it suffers from significant variance when the action space is large or when some parts of the context-action space are underexplored. Recently introduced Marginalized IPS (MIPS) estimators mitigate this issue by leveraging action embeddings. However, these embeddings do not minimize the mean squared error (MSE) of the estimators and do not consider context information. To address these limitations, we introduce Context-Action Embedding Learning for MIPS, or CAEL-MIPS, which learns context-action embeddings from offline data to minimize the MSE of the MIPS estimator. Building on the theoretical analysis of bias and variance of MIPS, we present an MSE-minimizing objective for CAEL-MIPS. In the empirical studies on a synthetic dataset and a real-world dataset, we demonstrate that our estimator outperforms baselines in terms of MSE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.00648","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.653674","language":"en","tags":["preprints","statml","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Kushagra Chandak, Vincent Liu, Haanvid Lee","raw_content_length":1079,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["Inverse Propensity Score","Context-Action Embedding Learning","MIPS","OPE","CAEL-MIPS","IPS"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1078,"language_detected":"en","key_concepts":{"key_phrases":["Context","OPE","Announce Type","-policy","contextual bandits","finite action space","Inverse Propensity Score","IPS","weighting","a widely used method"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Context":2.0,"OPE":2.0,"Announce Type":1.0,"-policy":1.0,"contextual bandits":1.0,"finite action space":1.0,"Inverse Propensity Score":1.0,"IPS":1.0,"weighting":1.0,"a widely used method":1.0}},"age_hours":2.748401271666667,"is_recent":true,"quality_score":1.0,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9446,"joy":0.003,"surprise":0.016,"sadness":0.0136,"fear":0.0067,"anger":0.0077,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new algorithm (CAEL-MIPS) to improve off-policy evaluation in contextual bandits, which could potentially lead to more efficient decision-making in various applications. The paper demonstrates improved MSE on synthetic and real-world datasets, but there is no deployment or concrete action towards sustainability yet. It is still in the research phase.","key_impact_metrics":["MSE reduction","Bias and variance of MIPS"],"technology_tags":["Off-policy evaluation","Contextual bandits","Machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:47:51.831961Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3603307fb25a","title":"UrbanTwin: Building High","content":"arXiv:2509.02903v2 Announce Type: replace Abstract: LiDAR-based perception in intelligent transportation systems (ITS) relies on deep neural networks trained with large-scale labeled datasets. However, creating such datasets is expensive, time-consuming, and labor-intensive, limiting the scalability of perception systems. Sim2Real learning offers a scalable alternative, but its success depends on the simulation's fidelity to real-world environments, dynamics, and sensors. This tutorial introduces a reproducible workflow for building high-fidelity digital twins (HiFi DTs) to generate realistic synthetic datasets. We outline practical steps for modeling static geometry, road infrastructure, and dynamic traffic using open-source resources such as satellite imagery, OpenStreetMap, and sensor specifications. The resulting environments support scalable and cost-effective data generation for robust Sim2Real learning. Using this workflow, we have released three synthetic LiDAR datasets, namely UT-LUMPI, UT-V2X-Real, and UT-TUMTraf-I, which closely replicate real locations and outperform real-data-trained baselines in perception tasks. This guide enables broader adoption of HiFi DTs in ITS research and deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.02903","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.654464","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Muhammad Shahbaz, Shaurya Agarwal","raw_content_length":1225,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":["OpenStreetMap"],"persons":["HiFi","Announce Type"],"locations":[],"monetary":[]},"char_count":1224,"language_detected":"en","key_concepts":{"key_phrases":["UrbanTwin","arXiv250902903v2 Announce Type","Abstract","LiDAR-based perception","intelligent transportation systems","ITS","deep neural networks","large-scale labeled datasets","such datasets","the scalability"],"filter_categories":{"ai_ml":["deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"UrbanTwin":2.0,"arXiv250902903v2 Announce Type":1.0,"Abstract":1.0,"LiDAR-based perception":1.0,"intelligent transportation systems":1.0,"ITS":1.0,"deep neural networks":1.0,"large-scale labeled datasets":1.0,"such datasets":1.0,"the scalability":1.0}},"age_hours":2.748430075,"is_recent":true,"quality_score":1.0,"sentiment_score":9.417,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8834,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9348,"joy":0.0092,"surprise":0.019,"sadness":0.0187,"fear":0.0044,"anger":0.0077,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a workflow for creating high-fidelity digital twins for training AI in intelligent transportation systems. The concrete action is the release of three synthetic LiDAR datasets. The evidence comes from the claim that these datasets outperform real-data-trained baselines in perception tasks, suggesting improved efficiency and safety in transportation, but it is still in the research/prototype phase.","key_impact_metrics":["Outperform real-data-trained baselines"],"technology_tags":["Digital Twins","LiDAR","Sim2Real Learning","Intelligent Transportation Systems"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:47:54.783377Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1a27889c7e5b","title":"Attention as an Adaptive Filter","content":"arXiv:2509.04154v3 Announce Type: replace Abstract: We introduce Adaptive Filter Attention (AFA), a novel attention mechanism that incorporates a learnable dynamics model directly into the computation of attention weights. Rather than comparing queries and keys directly, we model the input sequence as discrete observations of a linear stochastic differential equation (SDE). By assuming a continuous-time linear time-invariant system with simultaneously-diagonalizable state matrices and noise covariances, we can make use of a closed-form solution of the differential Lyapunov equation to efficiently propagate uncertainties through the dynamics from keys to queries. A generalization of attention naturally arises as the maximum likelihood solution for filtering the trajectory of this linear SDE, with attention weights corresponding to robust residual-based reweightings of the propagated query-key precisions. We further constrain the system dynamics and noise in order to obtain a simplified variant with the same computational and memory complexity as standard attention. In the limit of zero decay and process noise, and using a small-angle approximation, we recover a complex-valued generalization of ordinary dot-product attention with rotary positional encodings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.04154","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.654878","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Peter Racioppo","raw_content_length":1277,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Filter Attention"],"persons":["Announce Type","Lyapunov"],"locations":[],"monetary":[]},"char_count":1276,"language_detected":"en","key_concepts":{"key_phrases":["Attention","an Adaptive Filter","Announce Type","Adaptive Filter Attention","AFA","a novel attention mechanism","a learnable dynamics model","the computation","attention weights","queries"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Attention":2.0,"an Adaptive Filter":2.0,"Announce Type":1.0,"Adaptive Filter Attention":1.0,"AFA":1.0,"a novel attention mechanism":1.0,"a learnable dynamics model":1.0,"the computation":1.0,"attention weights":1.0,"queries":1.0}},"age_hours":2.7484442408333334,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8803,"joy":0.0135,"surprise":0.0671,"sadness":0.0053,"fear":0.0086,"anger":0.0177,"disgust":0.0076},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel attention mechanism (AFA) for sequence modeling. While the research is theoretically sound and published on arXiv, it is currently in the basic research stage with no deployed technology or measured outcomes. The climate impact potential is low at this stage, as it's unclear how this attention mechanism will directly reduce GHG emissions or contribute to climate change adaptation.","key_impact_metrics":[],"technology_tags":["attention mechanism","machine learning","stochastic differential equation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:47:58.137944Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aa2c92fb4f79","title":"MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration","content":"arXiv:2509.05933v2 Announce Type: replace Abstract: Agentic AI has significantly extended the capabilities of large language models (LLMs) by enabling complex reasoning and tool use. However, most existing frameworks are tailored to domains such as mathematics, coding, or web automation, and fall short on geospatial tasks that require spatial reasoning, multi-hop planning, and real-time map interaction. To address these challenges, we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with customized toolsets and agentic scaffolds for map-integrated geospatial reasoning. Unlike existing flat agent-based approaches that treat tools uniformly-often overwhelming the LLM when handling similar but subtly different geospatial APIs-MapAgent decouples planning from execution. A high-level planner decomposes complex queries into subgoals, which are routed to specialized modules. For tool-heavy modules-such as map-based services-we then design a dedicated map-tool agent that efficiently orchestrates related APIs adaptively in parallel to effectively fetch geospatial data relevant for the query, while simpler modules (e.g., solution generation or answer extraction) operate without additional agent overhead. This hierarchical design reduces cognitive load, improves tool selection accuracy, and enables precise coordination across similar APIs. We evaluate MapAgent on four diverse geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented and agentic baselines. We open-source our framwork at https://github.com/Hasebul/MapAgent.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.05933","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.655283","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Md Hasebul Hasan, Mahir Labib Dihan, Tanzima Hashem, Mohammed Eunus Ali, Md Rizwan Parvez","raw_content_length":1650,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["MapAgent","LLM"],"persons":["Agentic AI"],"locations":[],"monetary":[]},"char_count":1649,"language_detected":"en","key_concepts":{"key_phrases":["MapAgent","A Hierarchical Agent","Geospatial Reasoning","Dynamic Map Tool Integration","arXiv250905933v2 Announce Type","Abstract","Agentic AI","the capabilities","large language models","LLMs"],"filter_categories":{"ai_ml":["Agentic AI","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MapAgent":3.0,"A Hierarchical Agent":2.0,"Geospatial Reasoning":2.0,"Dynamic Map Tool Integration":2.0,"arXiv250905933v2 Announce Type":1.0,"Abstract":1.0,"Agentic AI":1.0,"the capabilities":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7484596669444445,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9147,"joy":0.0063,"surprise":0.0479,"sadness":0.0107,"fear":0.0075,"anger":0.0092,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (MapAgent) for geospatial reasoning, which could potentially improve the efficiency of tasks related to sustainable development. The framework is evaluated on geospatial benchmarks, showing performance gains. However, it is still in the applied research stage with no real-world deployment, and the direct climate impact is theoretical.","key_impact_metrics":["Substantial gains over state-of-the-art tool-augmented and agentic baselines on MapEval benchmarks"],"technology_tags":["AI","Geospatial Reasoning","Large Language Models","Map-based Services"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T16:48:01.545995Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1278fb2c1aed","title":"General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases and Populations","content":"arXiv:2509.07330v2 Announce Type: replace Abstract: Demographic attributes are universally present in electronic health records. They are the most widespread information across populations and diseases, and serve as vital predictors in clinical risk stratification and treatment decisions. Despite their significance, these attributes are often treated as auxiliaries in model design, with limited attention being paid to learning their representations. This study explored the development of a General Demographic Pre-trained (GDP) model as a foundational model tailored to demographic attributes, focusing on age and gender. The model is pre-trained and evaluated using datasets with diverse diseases and populations compositions from different geographic regions. The composition of GDP architecture was explored through examining combinations of ordering approaches and encoding methods to transform tabular demographic inputs into effective latent embeddings. Results demonstrate the feasibility of GDP to generalize across task, diseases, and populations. In detailed composition, the sequential ordering substantially improves model performance in discrimination, calibration, and the corresponding information gain at each decision tree split, particularly in diseases where age and gender contribute significantly to risk stratification. Even in datasets where demographic attributes hold relatively low predictive value, GDP enhances the representational importance, increasing their influence in downstream gradient boosting models. The findings suggest that foundation models for tabular demographic attributes offer a promising direction for improving predictive performance in healthcare applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.07330","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.655713","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Li-Chin Chen, Ji-Tian Sheu, Yuh-Jue Chuang","raw_content_length":1716,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases"],"persons":["Demographic","Demographic Pre-"],"locations":[],"monetary":[]},"char_count":1715,"language_detected":"en","key_concepts":{"key_phrases":["General Demographic Foundation Models","Predictive Performance","Diseases","Populations","arXiv250907330v2 Announce Type","Abstract","Demographic attributes","electronic health records","the most widespread information","populations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"General Demographic Foundation Models":2.0,"Predictive Performance":2.0,"Diseases":2.0,"Populations":2.0,"arXiv250907330v2 Announce Type":1.0,"Abstract":1.0,"Demographic attributes":1.0,"electronic health records":1.0,"the most widespread information":1.0,"populations":1.0}},"age_hours":2.7484734738888887,"is_recent":true,"quality_score":1.0,"sentiment_score":3.0765,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3847,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9052,"joy":0.0081,"surprise":0.0331,"sadness":0.0131,"fear":0.0105,"anger":0.0183,"disgust":0.0117},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes the development of a pre-trained model for demographic attributes in healthcare. While improved healthcare can indirectly contribute to sustainability by improving human well-being, there are no direct or measurable climate or environmental impacts mentioned. The technology is still in the applied research stage.","key_impact_metrics":["Information gain at each decision tree split","Improvement in discrimination and calibration"],"technology_tags":["Machine Learning","Predictive Modeling"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:48:04.944690Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ac043e94e1ce","title":"In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze","content":"arXiv:2509.07447v2 Announce Type: replace Abstract: The emergence of advanced multimodal large language models (MLLMs) has significantly enhanced AI assistants' ability to process complex information across modalities. Recently, egocentric videos, by directly capturing user focus, actions, and context in an unified coordinate, offer an exciting opportunity to enable proactive and personalized AI user experiences with MLLMs. However, existing benchmarks overlook the crucial role of gaze as an indicator of user intent. To address this gap, we introduce EgoGazeVQA, an egocentric gaze-guided video question answering benchmark that leverages gaze information to improve the understanding of longer daily-life videos. EgoGazeVQA consists of gaze-based QA pairs generated by MLLMs and refined by human annotators. Our experiments reveal that existing MLLMs struggle to accurately interpret user intentions. In contrast, our gaze-guided intent prompting methods significantly enhance performance by integrating spatial, temporal, and intent-related cues. We further conduct experiments on gaze-related fine-tuning and analyze how gaze estimation accuracy impacts prompting effectiveness. These results underscore the value of gaze for more personalized and effective AI assistants in egocentric settings. Project page: https://taiyi98.github.io/projects/EgoGazeVQA","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.07447","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.656105","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Taiying Peng, Jiacheng Hua, Miao Liu, Feng Lu","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Benchmarking Egocentric Video Intent"],"persons":["Gaze arXiv:2509.07447v2 Announce Type"],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["the Eye","MLLM","Gaze","MLLMs","arXiv250907447v2 Announce Type","Abstract","The emergence","advanced multimodal large language models","AI assistants ability","complex information"],"filter_categories":{"ai_ml":["MLLM","advanced multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Eye":2.0,"MLLM":2.0,"Gaze":2.0,"MLLMs":2.0,"arXiv250907447v2 Announce Type":1.0,"Abstract":1.0,"The emergence":1.0,"advanced multimodal large language models":1.0,"AI assistants ability":1.0,"complex information":1.0}},"age_hours":2.748488055277778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6435,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9287,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8668,"joy":0.0378,"surprise":0.0639,"sadness":0.0029,"fear":0.0091,"anger":0.0149,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving AI understanding of user intent through gaze tracking in egocentric videos. While it aims to enhance AI assistants, it doesn't directly address climate change or sustainability. The research is in the applied research stage, demonstrating improved performance with gaze-guided intent prompting, but lacks deployment or economic viability data.","key_impact_metrics":["Improved performance in interpreting user intentions with gaze information","Enhanced accuracy in gaze estimation"],"technology_tags":["Multimodal Large Language Models","Egocentric Video Analysis","Gaze Tracking"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:48:08.147200Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_94ed08ca602b","title":"Qubit","content":"arXiv:2509.08080v2 Announce Type: replace Abstract: Quantum computing has emerged as a promising alternative for solving combinatorial optimization problems. The standard approach for encoding optimization problems on quantum processing units (QPUs) involves transforming them into their Quadratic Unconstrained Binary Optimization (QUBO) representation. However, encoding constraints of optimization problems, particularly inequality constraints, into QUBO requires additional variables, which results in more qubits. Considering the limited availability of qubits in NISQ machines, existing encoding methods fail to scale due to their reliance on large numbers of qubits. We propose a generalized exponential penalty framework for QUBO inequality constraints inspired by a class of exponential functions, which we call exponential penalization. This paper presents an encoding strategy for inequality constraints in combinatorial optimization problems, inspired by a class of exponential functions, which we call exponential penalization. The initial idea of using exponential penalties for QUBO formulation was introduced by Montanez-Barrera et al. by applying a specific exponential function to reduce qubit requirements. In this work, we extend that approach by conducting a comprehensive study on a broader class of exponential functions, analyzing their theoretical properties and empirical performance. Our experimental results demonstrate that an exponential penalization achieves 57%, 83% qubit number reduction for Bin Packing Problem (BPP) and Traveling Salesman Problem (TSP), respectively. And we demonstrate comparable solution quality to classical with a probability of 6% and 21% accuracy for BPP with 8 and TSP with 12 qubits, respectively.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.08080","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.656531","language":"en","tags":["preprints","computer-science","research","cset","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Meerzhan Kanatbekova, Vincenzo De Maio, Ivona Brandic","raw_content_length":1759,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["Qubit arXiv:2509.08080v2 Announce Type:","Quantum","QUBO","Quadratic Unconstrained Binary Optimization","NISQ"],"persons":[],"locations":[],"monetary":[]},"char_count":1758,"language_detected":"en","key_concepts":{"key_phrases":["Qubit","optimization problems","QUBO","arXiv250908080v2 Announce Type","Abstract","Quantum computing","a promising alternative","combinatorial optimization problems","The standard approach","quantum processing units"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Qubit":2.0,"optimization problems":2.0,"QUBO":2.0,"arXiv250908080v2 Announce Type":1.0,"Abstract":1.0,"Quantum computing":1.0,"a promising alternative":1.0,"combinatorial optimization problems":1.0,"The standard approach":1.0,"quantum processing units":1.0}},"age_hours":2.748501687222222,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8447,"joy":0.0315,"surprise":0.0997,"sadness":0.0082,"fear":0.004,"anger":0.0089,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to encoding optimization problems for quantum computing, specifically reducing qubit requirements. It demonstrates a 57% and 83% qubit reduction for Bin Packing Problem (BPP) and Traveling Salesman Problem (TSP), respectively. However, it's still in the research phase with limited deployment readiness and unclear economic viability.","key_impact_metrics":["57% qubit number reduction for BPP","83% qubit number reduction for TSP"],"technology_tags":["quantum computing","optimization","qubit reduction"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:48:11.811395Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b28d6f6562db","title":"Strategic Tradeoffs Between Humans and AI in Multi","content":"arXiv:2509.09071v3 Announce Type: replace Abstract: As large language models (LLMs) are increasingly embedded in collaborative human activities such as business negotiations and group coordination, it becomes critical to evaluate both the performance gains they can achieve and how they interact in dynamic, multi-agent environments. Unlike traditional statistical agents such as Bayesian models, which may excel under well-specified conditions, large language models (LLMs) can generalize across diverse, real-world scenarios, raising new questions about how their strategies and behaviors compare to those of humans and other agent types. In this work, we compare outcomes and behavioral dynamics across humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting under identical conditions. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks. By establishing foundational behavioral baselines under matched conditions, this work provides a baseline for future studies in more applied, variable-rich environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.09071","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.656959","language":"en","tags":["preprints","cshc","csai","csgt","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Crystal Qian, Kehang Zhu, John Horton, Benjamin S. Manning, Vivian Tsai, James Wexler, Nithum Thain","raw_content_length":1578,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Gemini"],"locations":["Multi"],"monetary":[]},"char_count":1577,"language_detected":"en","key_concepts":{"key_phrases":["Strategic Tradeoffs","Humans","Multi","large language models","LLMs","arXiv250909071v3 Announce Type","Abstract","collaborative human activities","business negotiations","group coordination"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Strategic Tradeoffs":2.0,"Humans":2.0,"Multi":2.0,"large language models":2.0,"LLMs":2.0,"arXiv250909071v3 Announce Type":1.0,"Abstract":1.0,"collaborative human activities":1.0,"business negotiations":1.0,"group coordination":1.0}},"age_hours":2.7485164269444446,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9132,"joy":0.0152,"surprise":0.0376,"sadness":0.0038,"fear":0.0098,"anger":0.014,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research compares human, LLM, and Bayesian agent negotiation strategies. While it identifies behavioral differences and performance parity, it doesn't directly translate to concrete climate action or measurable environmental outcomes. The research is at an early stage, focusing on understanding agent behavior in a controlled setting.","key_impact_metrics":["Surplus achieved by agents","Number of trade rejections"],"technology_tags":["Large Language Models","Artificial Intelligence","Negotiation Algorithms"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T16:48:14.691902Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5a7d1589d0da","title":"A Taxonomy of Response Strategies to Toxic Online Content: Evaluating the Evidence","content":"arXiv:2509.09921v2 Announce Type: replace Abstract: Toxic Online Content (TOC) includes messages on digital platforms that are harmful, hostile, or damaging to constructive public discourse. Individuals, organizations, and LLMs respond to TOC through counterspeech or counternarrative initiatives. There is a wide variation in their goals, terminology, response strategies, and methods of evaluating impact. This paper identifies a taxonomy of online response strategies, which we call Online Discourse Engagement (ODE), to include any type of online speech to build healthier online public discourse. The literature on ODE makes contradictory assumptions about ODE goals and rarely distinguishes between them or rigorously evaluates their effectiveness. This paper categorizes 25 distinct ODE strategies, from humor and distraction to empathy, solidarity, and fact-based rebuttals, and groups these into a taxonomy of five response categories: defusing and distracting, engaging the speaker's perspective, identifying shared values, upstanding for victims, and information and fact-building. The paper then systematically reviews the evidence base for each of these categories. By clarifying definitions, cataloging response strategies, and providing a meta-analysis of research papers on these strategies, this article aims to bring coherence to the study of ODE and to strengthen evidence-informed approaches for fostering constructive ODE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.09921","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.663059","language":"en","tags":["preprints","computer-science","research","cscy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Lisa Schirch, Kristina Radivojevic, Cathy Buerger","raw_content_length":1444,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["ODE","TOC"],"persons":[],"locations":[],"monetary":[]},"char_count":1443,"language_detected":"en","key_concepts":{"key_phrases":["Toxic Online Content","A Taxonomy","Response Strategies","the Evidence","TOC","arXiv250909921v2 Announce Type","Abstract","messages","digital platforms","public discourse"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Toxic Online Content":3.0,"A Taxonomy":2.0,"Response Strategies":2.0,"the Evidence":2.0,"TOC":2.0,"arXiv250909921v2 Announce Type":1.0,"Abstract":1.0,"messages":1.0,"digital platforms":1.0,"public discourse":1.0}},"age_hours":2.7485444027777777,"is_recent":true,"quality_score":1.0,"sentiment_score":1.452,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7096,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.0927,"joy":0.0019,"surprise":0.0034,"sadness":0.0098,"fear":0.0215,"anger":0.4785,"disgust":0.3923},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":5,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a taxonomy of online discourse engagement strategies to combat toxic online content. While it reviews the evidence base for each category, it doesn't involve deployed technology or measured outcomes in a real-world setting, keeping it at the research stage. It has potential systemic impact by improving online discourse, but lacks economic viability and deployment readiness at this stage.","key_impact_metrics":[],"technology_tags":["online discourse analysis","toxicity detection","social media analysis"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:48:17.763090Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c60793dcfbbe","title":"DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi","content":"arXiv:2509.10446v2 Announce Type: replace Abstract: Augmenting large language models (LLMs) with browsing tools substantially improves their potential as deep search agents to solve complex, real-world tasks. Yet, open LLMs still perform poorly in such settings due to limited long-horizon reasoning capacity with browsing tools and the lack of sufficiently difficult supervised data. To address these challenges, we present DeepDive to advance deep search agents. First, we propose a strategy to automatically synthesize complex, difficult, and hard-to-find questions from open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement learning (RL) to enhance LLMs' long-horizon reasoning with deep search. To encourage diversity and reduce redundancy, we design a redundancy penalty that discourages repeated similar queries. Experiments show that DeepDive-32B achieves a new open-source competitive result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and Search-o1. We demonstrate that multi-turn RL training improves deep search ability and significantly contributes to the performance improvements across multiple benchmarks. We observe that DeepDive enables test-time scaling of tool calls and parallel sampling. All datasets, models, and code are publicly available at https://github.com/THUDM/DeepDive.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.10446","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.663606","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li, Shi Feng, Jie Tang, Yuxiao Dong","raw_content_length":1340,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Multi arXiv:2509.10446v2 Announce Type","DeepDive-32B"],"persons":["Knowledge Graphs"],"locations":[],"monetary":[]},"char_count":1339,"language_detected":"en","key_concepts":{"key_phrases":["DeepDive","Deep Search Agents","Knowledge Graphs","browsing tools","deep search agents","Announce Type","Abstract","large language models","LLMs","their potential"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepDive":3.0,"Deep Search Agents":2.0,"Knowledge Graphs":2.0,"browsing tools":2.0,"deep search agents":2.0,"Announce Type":1.0,"Abstract":1.0,"large language models":1.0,"LLMs":1.0,"their potential":1.0}},"age_hours":2.7485595752777776,"is_recent":true,"quality_score":1.0,"sentiment_score":4.351,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1298,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8147,"joy":0.0113,"surprise":0.0171,"sadness":0.0274,"fear":0.1,"anger":0.0214,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to improve deep search agents using knowledge graphs and reinforcement learning. While the research is promising and shows improved performance on benchmarks, it is still in the applied research stage with no deployed units or real-world impact data available. The potential climate impact is indirect, relying on the downstream applications of improved search agents to contribute to sustainability efforts.","key_impact_metrics":["BrowseComp performance improvement","Redundancy penalty effectiveness"],"technology_tags":["Large Language Models","Reinforcement Learning","Knowledge Graphs","Deep Search Agents"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:48:21.366406Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_030a29487397","title":"InternScenes: A Large","content":"arXiv:2509.10813v2 Announce Type: replace Abstract: The advancement of Embodied AI heavily relies on large-scale, simulatable 3D scene datasets characterized by scene diversity and realistic layouts. However, existing datasets typically suffer from limitations in data scale or diversity, sanitized layouts lacking small items, and severe object collisions. To address these shortcomings, we introduce \\textbf{InternScenes}, a novel large-scale simulatable indoor scene dataset comprising approximately 40,000 diverse scenes by integrating three disparate scene sources, real-world scans, procedurally generated scenes, and designer-created scenes, including 1.96M 3D objects and covering 15 common scene types and 288 object classes. We particularly preserve massive small items in the scenes, resulting in realistic and complex layouts with an average of 41.5 objects per region. Our comprehensive data processing pipeline ensures simulatability by creating real-to-sim replicas for real-world scans, enhances interactivity by incorporating interactive objects into these scenes, and resolves object collisions by physical simulations. We demonstrate the value of InternScenes with two benchmark applications: scene layout generation and point-goal navigation. Both show the new challenges posed by the complex and realistic layouts. More importantly, InternScenes paves the way for scaling up the model training for both tasks, making the generation and navigation in such complex scenes possible. We commit to open-sourcing the data, models, and benchmarks to benefit the whole community.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.10813","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.664054","language":"en","tags":["preprints","computer-science","research","csro","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Weipeng Zhong, Peizhou Cao, Yichen Jin, Li Luo, Wenzhe Cai, Jingli Lin, Hanqing Wang, Zhaoyang Lyu, Tai Wang, Bo Dai, Xudong Xu, Jiangmiao Pang","raw_content_length":1593,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["Embodied AI"],"persons":[],"locations":[],"monetary":[]},"char_count":1592,"language_detected":"en","key_concepts":{"key_phrases":["InternScenes","Announce Type","Abstract","The advancement","Embodied AI","large-scale simulatable 3D scene datasets","scene diversity","realistic layouts","existing datasets","limitations"],"filter_categories":{"ai_ml":["Embodied AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"InternScenes":2.0,"Announce Type":1.0,"Abstract":1.0,"The advancement":1.0,"Embodied AI":1.0,"large-scale simulatable 3D scene datasets":1.0,"scene diversity":1.0,"realistic layouts":1.0,"existing datasets":1.0,"limitations":1.0}},"age_hours":2.748573865,"is_recent":true,"quality_score":1.0,"sentiment_score":1.452,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7096,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7529,"joy":0.0098,"surprise":0.0112,"sadness":0.0233,"fear":0.0692,"anger":0.0635,"disgust":0.0701},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new dataset for embodied AI research. While the dataset itself doesn't directly address climate change, it could indirectly contribute by enabling more efficient simulations and potentially reducing the need for real-world experiments, saving energy. The dataset includes 'approximately 40,000 diverse scenes' and '1.96M 3D objects'.","key_impact_metrics":["40,000 diverse scenes","1.96M 3D objects"],"technology_tags":["Embodied AI","3D scene dataset","Simulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:48:27.266434Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8d55f925e93b","title":"StegOT: Trade","content":"arXiv:2509.11178v2 Announce Type: replace Abstract: Image hiding is often referred to as steganography, which aims to hide a secret image in a cover image of the same resolution. Many steganography models are based on genera-tive adversarial networks (GANs) and variational autoencoders (VAEs). However, most existing models suffer from mode collapse. Mode collapse will lead to an information imbalance between the cover and secret images in the stego image and further affect the subsequent extraction. To address these challenges, this paper proposes StegOT, an autoencoder-based steganography model incorporating optimal transport theory. We designed the multiple channel optimal transport (MCOT) module to transform the feature distribution, which exhibits multiple peaks, into a single peak to achieve the trade-off of information. Experiments demonstrate that we not only achieve a trade-off between the cover and secret images but also enhance the quality of both the stego and recovery images. The source code will be released on https://github.com/Rss1124/StegOT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.11178","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.664453","language":"en","tags":["preprints","csai","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Chengde Lin, Xuezhu Gong, Shuxue Ding, Mingzhe Yang, Xijun Lu, Chengjun Mo","raw_content_length":1074,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Mode"],"locations":[],"monetary":[]},"char_count":1073,"language_detected":"en","key_concepts":{"key_phrases":["StegOT","Trade","Announce Type","Abstract","Image hiding","steganography","which","a secret image","a cover image","the same resolution"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"StegOT":2.0,"Trade":2.0,"Announce Type":1.0,"Abstract":1.0,"Image hiding":1.0,"steganography":1.0,"which":1.0,"a secret image":1.0,"a cover image":1.0,"the same resolution":1.0}},"age_hours":2.7485888358333335,"is_recent":true,"quality_score":1.0,"sentiment_score":0.3055000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9389,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.795,"joy":0.0047,"surprise":0.0394,"sadness":0.0831,"fear":0.034,"anger":0.0225,"disgust":0.0212},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new steganography model (StegOT) to improve image hiding. While the technology itself doesn't directly address climate change, it could potentially contribute to more secure data transfer for environmental monitoring or climate research, but this is speculative. The model is currently in the research phase, with no deployment or measurable environmental outcomes.","key_impact_metrics":[],"technology_tags":["steganography","autoencoders","optimal transport"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:48:31.983879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_67b747529261","title":"Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation","content":"arXiv:2509.14032v2 Announce Type: replace Abstract: We study the existence and computation of Nash equilibria in continuous static games where the players' admissible strategies are subject to shared coupling constraints, i.e., constraints that depend on their \\emph{joint} strategies. Specifically, we focus on a class of games characterized by playerwise concave utilities and playerwise concave constraints. Prior results on the existence of Nash equilibria are not applicable to this class, as they rely on strong assumptions such as joint convexity of the feasible set. By leveraging topological fixed point theory and novel structural insights into the contractibility of feasible sets under playerwise concave constraints, we give an existence proof for Nash equilibria under weaker conditions. Having established existence, we then focus on the computation of Nash equilibria via independent gradient methods under the additional assumption that the utilities admit a potential function. To account for the possibly nonconvex feasible region, we employ a log barrier regularized gradient ascent with adaptive stepsizes. Starting from an initial feasible strategy profile and under exact gradient feedback, the proposed method converges to an $\\epsilon$-approximate constrained Nash equilibrium within $\\mathcal{O}(\\epsilon^{-3})$ iterations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.14032","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.664885","language":"en","tags":["preprints","csgt","computer-science","cslg","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Philip Jordan, Maryam Kamgarpour","raw_content_length":1350,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Playerwise Concave Coupling Constraints: Existence and"],"persons":["Nash Equilibria"],"locations":["Nash"],"monetary":[]},"char_count":1349,"language_detected":"en","key_concepts":{"key_phrases":["Nash Equilibria","Games","Playerwise Concave Coupling Constraints","Existence","Computation","the existence","Nash equilibria","Announce Type","Abstract","computation"],"filter_categories":{"ai_ml":["Playerwise Concave Coupling Constraints"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Nash Equilibria":2.0,"Games":2.0,"Playerwise Concave Coupling Constraints":2.0,"Existence":2.0,"Computation":2.0,"the existence":2.0,"Nash equilibria":2.0,"Announce Type":1.0,"Abstract":1.0,"computation":1.0}},"age_hours":2.748603383611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.854,"joy":0.0493,"surprise":0.0668,"sadness":0.0089,"fear":0.0048,"anger":0.0118,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical method for computing Nash equilibria in games with coupling constraints, which could potentially be applied to optimize resource allocation in sustainable systems. The paper provides a convergence rate of $\\mathcal{O}(\\epsilon^{-3})$ iterations for finding an $\\epsilon$-approximate constrained Nash equilibrium. However, it is currently at a basic research stage with no deployed technology or real-world validation.","key_impact_metrics":["$\\mathcal{O}(\\epsilon^{-3})$ iterations"],"technology_tags":["Game Theory","Optimization","Nash Equilibrium"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:48:40.236965Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c2bffd3948dc","title":"Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real","content":"arXiv:2509.15380v2 Announce Type: replace Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a significant gap remains between research and practical deployment. Many studies assess MLIR performance in isolated settings, limiting their applicability to real-world scenarios. In this work, we leverage the unique characteristics of the Quranic multilingual corpus to examine the optimal strategies to develop an ad-hoc IR system for the Islamic domain that is designed to satisfy users' information needs in multiple languages. We prepared eleven retrieval models employing four training approaches: monolingual, cross-lingual, translate-train-all, and a novel mixed method combining cross-lingual and monolingual techniques. Evaluation on an in-domain dataset demonstrates that the mixed approach achieves promising results across diverse retrieval scenarios. Furthermore, we provide a detailed analysis of how different training configurations affect the embedding space and their implications for multilingual retrieval effectiveness. Finally, we discuss deployment considerations, emphasizing the cost-efficiency of deploying a single versatile, lightweight model for real-world MLIR applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.15380","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.665688","language":"en","tags":["preprints","csai","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Vera Pavlova, Mohammed Makhlouf","raw_content_length":1234,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["Multilingual Information Retrieval","Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real arXiv:2509.15380v2 Announce Type"],"persons":[],"locations":["Quranic"],"monetary":[]},"char_count":1233,"language_detected":"en","key_concepts":{"key_phrases":["Multilingual Information Retrieval","Versatile Model","Islamic Text","Development","Deployment","arXiv250915380v2 Announce Type","Abstract","recent advancements","MLIR","a significant gap"],"filter_categories":{"engineering":["Development"],"ai_ml":["MLIR"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multilingual Information Retrieval":3.0,"Versatile Model":2.0,"Islamic Text":2.0,"Development":2.0,"Deployment":2.0,"arXiv250915380v2 Announce Type":1.0,"Abstract":1.0,"recent advancements":1.0,"MLIR":1.0,"a significant gap":1.0}},"age_hours":2.7486328883333333,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9172,"joy":0.0167,"surprise":0.0294,"sadness":0.0086,"fear":0.008,"anger":0.0127,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes the development of a multilingual information retrieval system. While it mentions deployment considerations and cost-efficiency, it lacks concrete details about actual deployment or measurable environmental impact beyond the theoretical reduction in computational resources compared to multiple monolingual models. The system is still in the research/prototype phase, limiting its immediate sustainability impact.","key_impact_metrics":["Promising results across diverse retrieval scenarios","Cost-efficiency of deploying a single versatile, lightweight model"],"technology_tags":["Multilingual Information Retrieval","Natural Language Processing"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:48:43.739034Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90d893c99a53","title":"SCAN: Self","content":"arXiv:2509.16548v2 Announce Type: replace Abstract: Process reward models (PRMs) offer fine-grained, step-level evaluations that facilitate deeper reasoning processes in large language models (LLMs), proving effective in complex tasks like mathematical reasoning. However, developing PRMs is challenging due to the high cost and limited scalability of human-annotated data. Synthetic data from Monte Carlo (MC) estimation is a promising alternative but suffers from a high noise ratio, which can cause overfitting and hinder large-scale training. In this work, we conduct a preliminary study on the noise distribution in synthetic data from MC estimation, identifying that annotation models tend to both underestimate and overestimate step correctness due to limitations in their annotation capabilities. Building on these insights, we propose Self-Denoising Monte Carlo Annotation (SCAN), an efficient data synthesis and noise-tolerant learning framework. Our key findings indicate that: (1) Even lightweight models (e.g., 1.5B parameters) can produce high-quality annotations through a self-denoising strategy, enabling PRMs to achieve superior performance with only 6% the inference cost required by vanilla MC estimation. (2) With our robust learning strategy, PRMs can effectively learn from this weak supervision, achieving a 39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench. Despite using only a compact synthetic dataset, our models surpass strong baselines, including those trained on large-scale human-annotated datasets such as PRM800K. Furthermore, performance continues to improve as we scale up the synthetic data, highlighting the potential of SCAN for scalable, cost-efficient, and robust PRM training.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.16548","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.666526","language":"en","tags":["preprints","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":238,"author":"Yuyang Ding, Xinyu Shi, Juntao Li, Xiaobo Liang, Zhaopeng Tu, Min Zhang","raw_content_length":1732,"priority":7,"update_frequency":1,"reading_time_minutes":1.19,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Monte Carlo"],"locations":[],"monetary":[]},"char_count":1731,"language_detected":"en","key_concepts":{"key_phrases":["SCAN","Announce Type","Abstract","Process reward models","PRMs","fine-grained step-level evaluations","deeper reasoning processes","large language models","LLMs","complex tasks"],"filter_categories":{"ai_ml":["fine-grained step-level evaluations","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SCAN":2.0,"Announce Type":1.0,"Abstract":1.0,"Process reward models":1.0,"PRMs":1.0,"fine-grained step-level evaluations":1.0,"deeper reasoning processes":1.0,"large language models":1.0,"LLMs":1.0,"complex tasks":1.0}},"age_hours":2.7486628722222224,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9186,"joy":0.0067,"surprise":0.0325,"sadness":0.0155,"fear":0.0104,"anger":0.0106,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel method (SCAN) for improving the efficiency of training large language models, specifically for process reward models. While the direct climate impact is limited, the potential for reducing computational costs (6% inference cost) associated with training these models could lead to energy savings. The research is still in the early stages (applied research) and lacks deployment data.","key_impact_metrics":["6% inference cost reduction","39.2 F1 score improvement"],"technology_tags":["Large Language Models","Process Reward Models","Monte Carlo Estimation","Self-Denoising"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:48:47.234972Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_72afbf8724d7","title":"Uncertainty","content":"arXiv:2509.17098v2 Announce Type: replace Abstract: Uncertainty estimation has been widely studied in medical image segmentation as a tool to provide reliability, particularly in deep learning approaches. However, previous methods generally lack effective supervision in uncertainty estimation, leading to low interpretability and robustness of the predictions. In this work, we propose a self-supervised approach to guide the learning of uncertainty. Specifically, we introduce three principles about the relationships between the uncertainty and the image gradients around boundaries and noise. Based on these principles, two uncertainty supervision losses are designed. These losses enhance the alignment between model predictions and human interpretation. Accordingly, we introduce novel quantitative metrics for evaluating the interpretability and robustness of uncertainty. Experimental results demonstrate that compared to state-of-the-art approaches, the proposed method can achieve competitive segmentation performance and superior results in out-of-distribution (OOD) scenarios while significantly improving the interpretability and robustness of uncertainty estimation. Code is available via https://github.com/suiannaius/SURE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.17098","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.666952","language":"en","tags":["preprints","computer-science","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Yuzhu Li, An Sui, Fuping Wu, Xiahai Zhuang","raw_content_length":1239,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1238,"language_detected":"en","key_concepts":{"key_phrases":["Uncertainty","Announce Type","Uncertainty estimation","medical image segmentation","a tool","reliability","deep learning approaches","previous methods","effective supervision","uncertainty estimation"],"filter_categories":{"ai_ml":["Uncertainty","deep learning approaches"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Uncertainty":2.0,"Announce Type":1.0,"Uncertainty estimation":1.0,"medical image segmentation":1.0,"a tool":1.0,"reliability":1.0,"deep learning approaches":1.0,"previous methods":1.0,"effective supervision":1.0,"uncertainty estimation":1.0}},"age_hours":2.7486766411111114,"is_recent":true,"quality_score":0.7,"sentiment_score":0.8200000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.836,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7787,"joy":0.0152,"surprise":0.0154,"sadness":0.011,"fear":0.1514,"anger":0.0175,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a self-supervised approach to improve uncertainty estimation in medical image segmentation. The concrete action is the development of new uncertainty supervision losses and quantitative metrics. The evidence supporting the claims comes from experimental results demonstrating competitive segmentation performance and superior results in out-of-distribution scenarios. The technology is at the applied research stage, with code available but no mention of real-world deployment.","key_impact_metrics":["Competitive segmentation performance","Superior results in OOD scenarios"],"technology_tags":["Medical image segmentation","Uncertainty estimation","Deep learning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:48:50.616411Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fb2ff0a46a52","title":"MoEs Are Stronger than You Think: Hyper","content":"arXiv:2509.17238v2 Announce Type: replace Abstract: The generation quality of large language models (LLMs) is often improved by utilizing inference-time sequence-level scaling methods (e.g., Chain-of-Thought). We introduce hyper-parallel scaling, a complementary framework that improves prediction quality at the token level. Hyper-parallel scaling computes and aggregates multiple output proposals for a single token from the model. We implement this concept in Mixture-of-Experts (MoE) models, which we refer to as Roster of Experts (RoE). RoE is a training-free inference algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects controlled stochasticity into the expert routing mechanism, enabling it to sample multiple diverse experts for each token and aggregate their outputs for a more accurate final prediction. To overcome the computational cost, we introduce an efficient batching strategy and a specialized KV-caching mechanism that minimizes compute and memory overhead. For example, RoE enables a 7B MoE model to match the performance of a 10.5B MoE model while using 30% less compute for inference. These gains are achieved without any fine-tuning of model parameters.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.17238","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.672985","language":"en","tags":["preprints","csai","computer-science","cslg","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Soheil Zibakhsh, Mohammad Samragh, Kumari Nishu, Lauren Hannah, Arnav Kundu, Minsik Cho","raw_content_length":1205,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["MoEs","Roster of Experts"],"persons":["RoE","Announce Type"],"locations":[],"monetary":[]},"char_count":1204,"language_detected":"en","key_concepts":{"key_phrases":["MoEs","You","arXiv250917238v2 Announce Type","Abstract","The generation quality","large language models","LLMs","inference-time sequence-level scaling methods","eg Chain","Thought"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MoEs":2.0,"You":2.0,"arXiv250917238v2 Announce Type":1.0,"Abstract":1.0,"The generation quality":1.0,"large language models":1.0,"LLMs":1.0,"inference-time sequence-level scaling methods":1.0,"eg Chain":1.0,"Thought":1.0}},"age_hours":2.748703913888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8389,"joy":0.0426,"surprise":0.0979,"sadness":0.0039,"fear":0.0046,"anger":0.0092,"disgust":0.0029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel algorithm (RoE) that improves the efficiency of MoE models, resulting in a 30% reduction in compute for inference while matching the performance of larger models. This has the potential to reduce the energy consumption of large language model inference. However, it is still in the research phase and lacks deployment data.","key_impact_metrics":["30% less compute for inference"],"technology_tags":["Mixture-of-Experts","Large Language Models","Hyper-parallel scaling"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T16:48:53.746111Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_91b782be8b2d","title":"Similarity Field Theory: A Mathematical Framework for Intelligence","content":"arXiv:2509.18218v3 Announce Type: replace Abstract: We posit that persisting and transforming similarity relations form the structural basis of any comprehensible dynamic system. This paper introduces Similarity Field Theory, a mathematical framework that formalizes the principles governing similarity values among entities and their evolution. We define: (1) a similarity field $S: U \\times U \\to [0,1]$ over a universe of entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed relational field (asymmetry and non-transitivity are allowed); (2) the evolution of a system through a sequence $Z_p=(X_p,S^{(p)})$ indexed by $p=0,1,2,\\ldots$; (3) concepts $K$ as entities that induce fibers $F_{\\alpha}(K)={E\\in U \\mid S(E,K)\\ge \\alpha}$, i.e., superlevel sets of the unary map $S_K(E):=S(E,K)$; and (4) a generative operator $G$ that produces new entities. Within this framework, we formalize a generative definition of intelligence: an operator $G$ is intelligent with respect to a concept $K$ if, given a system containing entities belonging to the fiber of $K$, it generates new entities that also belong to that fiber. Similarity Field Theory thus offers a foundational language for characterizing, comparing, and constructing intelligent systems. At a high level, this framework reframes intelligence and interpretability as geometric problems on similarity fields -- preserving and composing level-set fibers -- rather than purely statistical ones. We prove two theorems: (i) asymmetry blocks mutual inclusion; and (ii) stability requires either an anchor coordinate or eventual confinement within a level set. These results ensure that the evolution of similarity fields is both constrained and interpretable, culminating in a framework that not only interprets large language models but also introduces a novel way of using them as experimental probes of societal cognition, supported by preliminary evidence across diverse consumer categories.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.18218","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.673904","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":278,"author":"Kei-Sing Ng","raw_content_length":1971,"priority":7,"update_frequency":1,"reading_time_minutes":1.39,"robust_parsing_used":true,"entities":{"organizations":["S^{(p)})$","Similarity Field Theory"],"persons":[],"locations":[],"monetary":["S_K(E):=S(E","a sequence $Z_p=(X_p"]},"char_count":1970,"language_detected":"en","key_concepts":{"key_phrases":["Similarity Field Theory","A Mathematical Framework","Intelligence","entities","Announce Type","similarity relations","the structural basis","any comprehensible dynamic system","This paper","a mathematical framework"],"filter_categories":{"ai_ml":["Intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Similarity Field Theory":3.0,"A Mathematical Framework":2.0,"Intelligence":2.0,"entities":2.0,"Announce Type":1.0,"similarity relations":1.0,"the structural basis":1.0,"any comprehensible dynamic system":1.0,"This paper":1.0,"a mathematical framework":1.0}},"age_hours":2.7487349727777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.063,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8126,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8094,"joy":0.0789,"surprise":0.073,"sadness":0.0045,"fear":0.0084,"anger":0.0196,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":1,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for understanding intelligence and its application to societal cognition using large language models. While the framework is novel and potentially impactful, it is currently in the basic research stage with no concrete deployments or measurable outcomes related to sustainability. The preliminary evidence across diverse consumer categories is not directly tied to environmental impact.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Machine Learning","Similarity Field Theory"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:48:56.329143Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aa2a4e8ebdd8","title":"A Longitudinal Randomized Control Study of Companion Chatbot Use: Anthropomorphism and Its Mediating Role on Social Impacts","content":"arXiv:2509.19515v3 Announce Type: replace Abstract: Many Large Language Model (LLM) chatbots are designed and used for companionship, and people have reported forming friendships, mentorships, and romantic partnerships with them. Concerns that companion chatbots may harm or replace real human relationships have been raised, but whether and how these social consequences occur remains unclear. In the present longitudinal study ($N = 183$), participants were randomly assigned to a chatbot condition (text chat with a companion chatbot) or to a control condition (text-based word games) for 10 minutes a day for 21 days. Participants also completed four surveys during the 21 days and engaged in audio recorded interviews on day 1 and 21. Overall, social health and relationships were not significantly impacted by companion chatbot interactions across 21 days of use. However, a detailed analysis showed a different story. People who had a higher desire to socially connect also tended to anthropomorphize the chatbot more, attributing humanlike properties to it; and those who anthropomorphized the chatbot more also reported that talking to the chatbot had a greater impact on their social interactions and relationships with family and friends. Via a mediation analysis, our results suggest a key mechanism at work: the impact of human-AI interaction on human-human social outcomes is mediated by the extent to which people anthropomorphize the AI agent, which is in turn motivated by a desire to socially connect. In a world where the desire to socially connect is on the rise, this finding may be cause for concern.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.19515","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.675107","language":"en","tags":["preprints","cshc","csai","computer-science","research","cscy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Rose E. Guingrich, Michael S. A. Graziano","raw_content_length":1623,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["Longitudinal Randomized Control Study of Companion"],"persons":[],"locations":[],"monetary":["183$"]},"char_count":1622,"language_detected":"en","key_concepts":{"key_phrases":["A Longitudinal Randomized Control Study","Companion Chatbot Use","Anthropomorphism","Its Mediating Role","Social Impacts","arXiv250919515v3 Announce Type","Abstract","Many Large Language Model LLM chatbots","companionship","people"],"filter_categories":{"research_academic":["A Longitudinal Randomized Control Study"],"ai_ml":["Many Large Language Model LLM chatbots"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Longitudinal Randomized Control Study":2.0,"Companion Chatbot Use":2.0,"Anthropomorphism":2.0,"Its Mediating Role":2.0,"Social Impacts":2.0,"arXiv250919515v3 Announce Type":1.0,"Abstract":1.0,"Many Large Language Model LLM chatbots":1.0,"companionship":1.0,"people":1.0}},"age_hours":2.7487781305555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.1078,"joy":0.0048,"surprise":0.0059,"sadness":0.0258,"fear":0.8153,"anger":0.028,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":0,"technical_credibility":7,"economic_viability":0,"deployment_readiness":3,"systemic_impact":0,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This study investigates the social impact of companion chatbots through a randomized controlled trial. While it provides measurable outcomes related to social interaction and anthropomorphism, it does not directly address climate change or environmental sustainability. The study is in the pilot stage, involving a 21-day experiment with participants.","key_impact_metrics":["N = 183","21 days of use"],"technology_tags":["Large Language Model","Chatbot"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T16:48:59.167519Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_917bcc2cf8ee","title":"LLMs4All: A Systematic Review of Large Language Models Across Academic Disciplines","content":"arXiv:2509.19580v4 Announce Type: replace Abstract: Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view of the world. For example, Large Language Models (LLMs) based applications such as ChatGPT have shown the capability of generating human-like conversation on extensive topics. Due to the impressive performance on a variety of language-related tasks (e.g., open-domain question answering, translation, and document summarization), one can envision the far-reaching impacts that can be brought by the LLMs with broader real-world applications (e.g., customer service, education and accessibility, and scientific discovery). Inspired by their success, this paper will offer an overview of state-of-the-art LLMs and their integration into a wide range of academic disciplines, including: (1) arts, letters, and law (e.g., history, philosophy, political science, arts and architecture, law), (2) economics and business (e.g., finance, economics, accounting, marketing), and (3) science and engineering (e.g., mathematics, physics and mechanical engineering, chemistry and chemical engineering, life sciences and bioengineering, earth sciences and civil engineering, computer science and electrical engineering). Integrating humanity and technology, in this paper, we will explore how LLMs are shaping research and practice in these fields, while also discussing key limitations, open challenges, and future directions in the era of generative AI. The review of how LLMs are engaged across disciplines-along with key observations and insights-can help researchers and practitioners interested in exploiting LLMs to advance their works in diverse real-world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.19580","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.675522","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Yanfang Ye, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Yiyang Li, Shifu Hou, Weixiang Sun, Kaiwen Shi, Yijun Ma, Wei Song, Ahmed Abbasi, Ying Cheng, Jane Cleland-Huang, Steven Corcelli, Robert Goulding, Ming Hu, Ting Hua, John Lalor, Fang Liu, Tengfei Luo, Ed Maginn, Nuno Moniz, Jason Rohr, Brett Savoie, Daniel Slate, Matthew Webber, Olaf Wiest, Johnny Zhang, Nitesh V. Chawla","raw_content_length":1694,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["A Systematic Review of Large Language Models Across Academic","Artificial Intelligence (AI"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1693,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","LLMs4All","A Systematic Review","Academic Disciplines","Announce Type","Abstract","our view","the world","example","LLMs"],"filter_categories":{"ai_ml":["Large Language Models"],"research_academic":["Academic Disciplines"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"LLMs4All":2.0,"A Systematic Review":2.0,"Academic Disciplines":2.0,"Announce Type":1.0,"Abstract":1.0,"our view":1.0,"the world":1.0,"example":1.0,"LLMs":1.0}},"age_hours":2.7487943094444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6201,"joy":0.1221,"surprise":0.2173,"sadness":0.0044,"fear":0.0147,"anger":0.016,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper reviews the integration of LLMs across academic disciplines. While LLMs could potentially contribute to sustainability efforts in various fields (e.g., optimizing energy consumption, accelerating materials discovery), this paper is primarily a review and does not present concrete actions or measurable outcomes related to sustainability. The vaporware risk is flagged because the paper discusses potential applications without evidence of deployment or validation.","key_impact_metrics":[],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:49:02.556613Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b3a62068e324","title":"LUMINA: Detecting Hallucinations in RAG System with Context","content":"arXiv:2509.21875v2 Announce Type: replace Abstract: Retrieval-Augmented Generation (RAG) aims to mitigate hallucinations in large language models (LLMs) by grounding responses in retrieved documents. Yet, RAG-based LLMs still hallucinate even when provided with correct and sufficient context. A growing line of work suggests that this stems from an imbalance between how models use external context and their internal knowledge, and several approaches have attempted to quantify these signals for hallucination detection. However, existing methods require extensive hyperparameter tuning, limiting their generalizability. We propose LUMINA, a novel framework that detects hallucinations in RAG systems through context-knowledge signals: external context utilization is quantified via distributional distance, while internal knowledge utilization is measured by tracking how predicted tokens evolve across transformer layers. We further introduce a framework for statistically validating these measurements. Experiments on common RAG hallucination benchmarks and four open-source LLMs show that LUMINA achieves consistently high AUROC and AUPRC scores, outperforming prior utilization-based methods by up to +13% AUROC on HalluRAG. Moreover, LUMINA remains robust under relaxed assumptions about retrieval quality and model matching, offering both effectiveness and practicality.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.21875","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.677477","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Samuel Yeh, Sharon Li, Tanwi Mallick","raw_content_length":1380,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["Context arXiv:2509.21875v2 Announce Type","RAG","Retrieval-Augmented Generation"],"persons":["RAG"],"locations":[],"monetary":[]},"char_count":1379,"language_detected":"en","key_concepts":{"key_phrases":["LUMINA","Hallucinations","RAG System","Context","arXiv250921875v2 Announce Type","Retrieval-Augmented Generation","RAG","hallucinations","large language models","LLMs"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LUMINA":2.0,"Hallucinations":2.0,"RAG System":2.0,"Context":2.0,"arXiv250921875v2 Announce Type":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0,"hallucinations":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7488644180555557,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8214,"joy":0.0023,"surprise":0.0297,"sadness":0.0252,"fear":0.0281,"anger":0.0317,"disgust":0.0616},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (LUMINA) for detecting hallucinations in RAG systems, which could indirectly improve the reliability of LLMs used in climate modeling or sustainability analysis. The framework achieves consistently high AUROC and AUPRC scores, outperforming prior methods by up to +13% AUROC on HalluRAG, but it's currently in the research stage with no deployed applications or economic viability demonstrated.","key_impact_metrics":["+13% AUROC on HalluRAG","High AUROC and AUPRC scores"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","Hallucination Detection"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:49:05.472428Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c71e6981c06b","title":"NanoTag: Systems Support for Efficient Byte","content":"arXiv:2509.22027v2 Announce Type: replace Abstract: Memory safety bugs, such as buffer overflows and use-after-frees, are the leading causes of software safety issues in production. Software-based approaches, e.g., Address Sanitizer (ASAN), can detect such bugs with high precision, but with prohibitively high overhead. ARM's Memory Tagging Extension (MTE) offers a promising alternative to detect these bugs in hardware with a much lower overhead. However, in this paper, we perform a thorough investigation of Google Pixel 8, the first production implementation of ARM MTE, and show that MTE can only achieve coarse precision in bug detection compared with software-based approaches such as ASAN, mainly due to its 16-byte tag granularity. To address this issue, we present NanoTag, a system to detect memory safety bugs in unmodified binaries at byte granularity with ARM MTE. NanoTag detects intra-granule buffer overflows by setting up a tripwire for tag granules that may require intra-granule overflow detection. The memory access to the tripwire causes additional overflow detection in the software while using MTE's hardware to detect bugs for the rest of the accesses. We implement NanoTag based on the Scudo Hardened Allocator, the default memory allocator on Android since Android 11. Our evaluation results across popular benchmarks and real-world case studies show that NanoTag detects nearly as many memory safety bugs as ASAN while incurring similar run-time overhead to Scudo Hardened Allocator in MTE SYNC mode.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22027","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.683127","language":"en","tags":["preprints","computer-science","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Mingkai Li, Hang Ye, Joseph Devietti, Suman Jana, Tanvir Ahmed Khan","raw_content_length":1531,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":["NanoTag","byte"],"persons":["Address Sanitizer"],"locations":[],"monetary":[]},"char_count":1530,"language_detected":"en","key_concepts":{"key_phrases":["NanoTag","Systems Support","Efficient Byte","arXiv250922027v2 Announce Type","Memory safety bugs","buffer","use","frees","the leading causes","software safety issues"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"NanoTag":2.0,"Systems Support":2.0,"Efficient Byte":2.0,"arXiv250922027v2 Announce Type":1.0,"Memory safety bugs":1.0,"buffer":1.0,"use":1.0,"frees":1.0,"the leading causes":1.0,"software safety issues":1.0}},"age_hours":2.7488805177777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7491,"joy":0.0037,"surprise":0.0092,"sadness":0.0236,"fear":0.1055,"anger":0.0516,"disgust":0.0573},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents NanoTag, a system for detecting memory safety bugs with byte granularity using ARM MTE. While it shows improved bug detection compared to existing hardware solutions and similar runtime overhead to Scudo, it is still in the applied research phase with evaluation results across benchmarks and case studies but no real-world deployment data. The potential climate impact is indirect, stemming from potentially reducing energy consumption by improving software efficiency, but this is not quantified.","key_impact_metrics":["Overhead similar to Scudo Hardened Allocator","Detects nearly as many memory safety bugs as ASAN"],"technology_tags":["Memory Tagging Extension","Software Security","Hardware Security"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:08.539983Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1585ef2708f4","title":"One Prompt Fits All: Universal Graph Adaptation for Pretrained Models","content":"arXiv:2509.22416v2 Announce Type: replace Abstract: Graph Prompt Learning (GPL) has emerged as a promising paradigm that bridges graph pretraining models and downstream scenarios, mitigating label dependency and the misalignment between upstream pretraining and downstream tasks. Although existing GPL studies explore various prompt strategies, their effectiveness and underlying principles remain unclear. We identify two critical limitations: (1) Lack of consensus on underlying mechanisms: Despite current GPLs have advanced the field, there is no consensus on how prompts interact with pretrained models, as different strategies intervene at varying spaces within the model, i.e., input-level, layer-wise, and representation-level prompts. (2) Limited scenario adaptability: Most methods fail to generalize across diverse downstream scenarios, especially under data distribution shifts (e.g., homophilic-to-heterophilic graphs). To address these issues, we theoretically analyze existing GPL approaches and reveal that representation-level prompts essentially function as fine-tuning a simple downstream classifier, proposing that graph prompt learning should focus on unleashing the capability of pretrained models, and the classifier should adapt to downstream scenarios. Based on our findings, we propose UniPrompt, a novel GPL method that adapts any pretrained models, unleashing the capability of pretrained models while preserving the input graph. Extensive experiments demonstrate that our method can effectively integrate with various pretrained models and achieve strong performance across in-domain and cross-domain scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22416","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.684056","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Yongqi Huang, Jitao Zhao, Dongxiao He, Xiaobao Wang, Yawen Li, Yuxiao Huang, Di Jin, Zhiyong Feng","raw_content_length":1641,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["GPL"],"persons":[],"locations":[],"monetary":[]},"char_count":1640,"language_detected":"en","key_concepts":{"key_phrases":["All","Universal Graph Adaptation","Pretrained Models","Announce Type","Abstract","Graph Prompt Learning","GPL","a promising paradigm","bridges","pretraining models"],"filter_categories":{"ai_ml":["Pretrained Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"All":2.0,"Universal Graph Adaptation":2.0,"Pretrained Models":2.0,"Announce Type":1.0,"Abstract":1.0,"Graph Prompt Learning":1.0,"GPL":1.0,"a promising paradigm":1.0,"bridges":1.0,"pretraining models":1.0}},"age_hours":2.748910360277778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9479,"joy":0.0101,"surprise":0.0129,"sadness":0.0041,"fear":0.0056,"anger":0.013,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel graph prompt learning method (UniPrompt) to improve the adaptability of pretrained models across different downstream scenarios. While the research shows promise in integrating with various pretrained models, it is still in the applied research stage with no concrete deployments or quantified environmental impact. The technical credibility is moderate, supported by experimental results, but lacks independent verification and real-world data.","key_impact_metrics":[],"technology_tags":["Graph Prompt Learning","Pretrained Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:14.885963Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_acbd2579c617","title":"LongLive: Real","content":"arXiv:2509.22622v2 Announce Type: replace Abstract: We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal quality loss.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22622","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.684492","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Shuai Yang, Wei Huang, Ruihang Chu, Yicheng Xiao, Yuyang Zhao, Xianbang Wang, Muyang Li, Enze Xie, Yingcong Chen, Yao Lu, Song Han, Yukang Chen","raw_content_length":1776,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["LongLive"],"persons":[],"locations":[],"monetary":[]},"char_count":1775,"language_detected":"en","key_concepts":{"key_phrases":["LongLive","quality","Announce Type","Abstract","a frame-level autoregressive AR framework","real-time","interactive long video generation","Long video generation","challenges","both efficiency"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LongLive":3.0,"quality":2.0,"Announce Type":1.0,"Abstract":1.0,"a frame-level autoregressive AR framework":1.0,"real-time":1.0,"interactive long video generation":1.0,"Long video generation":1.0,"challenges":1.0,"both efficiency":1.0}},"age_hours":2.7489253594444447,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2504999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5499,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8292,"joy":0.0074,"surprise":0.0381,"sadness":0.0864,"fear":0.0087,"anger":0.0159,"disgust":0.0142},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for long video generation. The concrete action is the development of a new architecture (LongLive) that achieves 20.7 FPS inference on an H100 GPU and can generate up to 240-second videos. While promising, it is still in the applied research stage with no deployment data, hence the vaporware flag.","key_impact_metrics":["20.7 FPS on a single NVIDIA H100","240-second videos on a single H100 GPU"],"technology_tags":["AI","Video Generation","Autoregressive Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:23.016470Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d713f6ed1dfb","title":"Large language models management of medications: three performance analyses","content":"arXiv:2509.22926v2 Announce Type: replace Abstract: Purpose: Large language models (LLMs) have proven performance for certain diagnostic tasks, however limited studies have evaluated their consistency in recommending appropriate medication regimens for a given diagnosis. Medication management is a complex task that requires synthesis of drug formulation and complete order instructions for safe use. Here, the performance of GPT 4o, an LLM available with ChatGPT, was tested for three medication management tasks. Methods: GPT-4o performance was tested using three medication tasks: identifying available formulations for a given generic drug name, identifying drug-drug interactions (DDI) for a given medication regimen, and preparing a medication order for a given generic drug name. For each experiment, the models raw text response was captured exactly as returned and evaluated using clinician evaluation in addition to standard LLM metrics, including Term Frequency-Inverse Document Frequency (TF IDF) vectors, normalized Levenshtein similarity, and Recall-Oriented Understudy for Gisting Evaluation (ROUGE 1/ROUGE L F1) between each response and its reference string. Results: For the first task of drug-formulation matching, GPT-4o had 49% accuracy for generic medications being matched to all available formulations, with an average of 1.23 omissions per medication and 1.14 hallucinations per medication. For the second task of drug-drug interaction identification, the accuracy was 54.7% for identifying the DDI pair. For the third task, GPT-4o generated order sentences containing no medication or abbreviation errors in 65.8% of cases. Conclusions: Model performance for basic medication tasks was consistently poor. This evaluation highlights the need for domain-specific training through clinician-annotated datasets and a comprehensive evaluation framework for benchmarking performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.22926","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.684955","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":258,"author":"Kelli Henry, Steven Xu, Kaitlin Blotske, Moriah Cargile, Erin F. Barreto, Brian Murray, Susan Smith, Seth R. Bauer, Xingmeng Zhao, Adeleine Tilley, Yanjun Gao, Tianming Liu, Sunghwan Sohn, Andrea Sikora","raw_content_length":1905,"priority":7,"update_frequency":1,"reading_time_minutes":1.29,"robust_parsing_used":true,"entities":{"organizations":["GPT","LLM"],"persons":["arXiv:2509.22926v2 Announce Type"],"locations":[],"monetary":[]},"char_count":1904,"language_detected":"en","key_concepts":{"key_phrases":["medications","three performance","Announce Type","Abstract","Purpose","Large language models","LLMs","performance","certain diagnostic tasks","however limited studies"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"medications":2.0,"three performance":2.0,"Announce Type":1.0,"Abstract":1.0,"Purpose":1.0,"Large language models":1.0,"LLMs":1.0,"performance":1.0,"certain diagnostic tasks":1.0,"however limited studies":1.0}},"age_hours":2.7489401158333333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8691,"joy":0.0159,"surprise":0.0205,"sadness":0.0062,"fear":0.0397,"anger":0.0325,"disgust":0.0161},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article evaluates the performance of a large language model (GPT-4o) on medication management tasks. The study uses clinician evaluation and standard LLM metrics to assess accuracy, identifying specific errors such as omissions and hallucinations. While the research is valuable, it's in an early stage and doesn't directly contribute to climate action, economic viability, or deployment readiness.","key_impact_metrics":["Accuracy for drug-formulation matching: 49%","Accuracy for drug-drug interaction identification: 54.7%"],"technology_tags":["Large Language Models","Medication Management"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:49:26.451015Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9bb6fffe2288","title":"Understanding Language Prior of LVLMs by Contrasting Chain","content":"arXiv:2509.23050v2 Announce Type: replace Abstract: Large vision-language models (LVLMs) achieve strong performance on multimodal tasks, yet they often default to their language prior (LP) -- memorized textual patterns from pre-training while under-utilizing visual evidence. Prior analyses of LP mostly rely on input-output probing, which fails to reveal the internal mechanisms governing when and how vision influences model behavior. To address this gap, we present the first systematic analysis of language prior through the lens of chain-of-embedding, which examines the layer-wise representation dynamics within LVLMs. Our analysis reveals a universal phenomenon: each model exhibits a Visual Integration Point (VIP), a critical layer at which visual information begins to meaningfully reshape hidden representations and influence decoding. Building on this observation, we introduce the Total Visual Integration (TVI) estimator, which aggregates representation distance beyond the VIP to quantify how strongly visual query influences response generation. Across 54 model-dataset combinations spanning 9 contemporary LVLMs and 6 benchmarks, we demonstrate that VIP consistently emerges, and that TVI reliably predicts the strength of language prior. This offers a principled toolkit for diagnosing and understanding language prior in LVLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23050","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.685364","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Lin Long, Changdae Oh, Seongheon Park, Sharon Li","raw_content_length":1347,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Contrasting Chain arXiv:2509.23050v2 Announce Type:","Visual Integration Point","the Total Visual Integration"],"persons":["Language Prior"],"locations":[],"monetary":[]},"char_count":1346,"language_detected":"en","key_concepts":{"key_phrases":["LVLMs","Language","Contrasting Chain","arXiv250923050v2 Announce Type","Abstract","Large vision-language models","strong performance","multimodal tasks","their language","memorized textual patterns"],"filter_categories":{"ai_ml":["Language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LVLMs":3.0,"Language":2.0,"Contrasting Chain":2.0,"arXiv250923050v2 Announce Type":1.0,"Abstract":1.0,"Large vision-language models":1.0,"strong performance":1.0,"multimodal tasks":1.0,"their language":1.0,"memorized textual patterns":1.0}},"age_hours":2.748955304722222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8403,"joy":0.0024,"surprise":0.064,"sadness":0.0255,"fear":0.0084,"anger":0.0227,"disgust":0.0367},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research analyzes language prior in large vision-language models (LVLMs) and introduces the Total Visual Integration (TVI) estimator. While it offers a principled toolkit for diagnosing and understanding language prior, it's in the early stages of research with no immediate deployment or measurable impact on climate change or sustainability. The article presents a systematic analysis and demonstrates the emergence of Visual Integration Point (VIP) across 54 model-dataset combinations, indicating some level of validation.","key_impact_metrics":["54 model-dataset combinations","9 contemporary LVLMs"],"technology_tags":["Large Vision-Language Models","Chain-of-Embedding"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:49:33.907771Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a1db2eb8dd93","title":"New Synthetic Goldmine: Hand Joint Angle","content":"arXiv:2509.23359v2 Announce Type: replace Abstract: Electromyography (EMG)-based gesture recognition has emerged as a promising approach for human-computer interaction. However, its performance is often limited by the scarcity of labeled EMG data, significant cross-user variability, and poor generalization to unseen gestures. To address these challenges, we propose SeqEMG-GAN, a conditional, sequence-driven generative framework that synthesizes high-fidelity EMG signals from hand joint angle sequences. Our method introduces a context-aware architecture composed of an angle encoder, a dual-layer context encoder featuring the novel Ang2Gist unit, a deep convolutional EMG generator, and a discriminator, all jointly optimized via adversarial learning. By conditioning on joint kinematic trajectories, SeqEMG-GAN is capable of generating semantically consistent EMG sequences, even for previously unseen gestures, thereby enhancing data diversity and physiological plausibility. Experimental results show that classifiers trained solely on synthetic data experience only a slight accuracy drop (from 57.77% to 55.71%). In contrast, training with a combination of real and synthetic data significantly improves accuracy to 60.53%, outperforming real-only training by 2.76%. These findings demonstrate the effectiveness of our framework,also achieves the state-of-art performance in augmenting EMG datasets and enhancing gesture recognition performance for applications such as neural robotic hand control, AI/AR glasses, and gesture-based virtual gaming systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23359","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.685806","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Nana Wang, Suli Wang, Gen Li, Pengfei Ren, Hao Su","raw_content_length":1567,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["SeqEMG-GAN","EMG"],"persons":[],"locations":[],"monetary":[]},"char_count":1566,"language_detected":"en","key_concepts":{"key_phrases":["New Synthetic Goldmine","Hand Joint Angle","arXiv250923359v2 Announce Type","Abstract","Electromyography","EMG-based gesture recognition","a promising approach","human-computer interaction","its performance","the scarcity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"New Synthetic Goldmine":2.0,"Hand Joint Angle":2.0,"arXiv250923359v2 Announce Type":1.0,"Abstract":1.0,"Electromyography":1.0,"EMG-based gesture recognition":1.0,"a promising approach":1.0,"human-computer interaction":1.0,"its performance":1.0,"the scarcity":1.0}},"age_hours":2.748970036666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9143,"joy":0.009,"surprise":0.0324,"sadness":0.0121,"fear":0.0127,"anger":0.0121,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for generating EMG data, improving gesture recognition accuracy. While the technology itself doesn't directly impact climate change, it could enable more efficient human-computer interaction, potentially reducing energy consumption in certain applications. The research is peer-reviewed and presents measurable outcomes in terms of accuracy improvement (2.76%), but it is still in the early stages of deployment.","key_impact_metrics":["Accuracy improvement: 2.76%","Accuracy with synthetic data: 55.71%"],"technology_tags":["Electromyography","Gesture Recognition","Generative Adversarial Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:37.039951Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2c797b2e26f2","title":"Cognition-of","content":"arXiv:2509.23441v2 Announce Type: replace Abstract: Large language models (LLMs) excel at complex reasoning but can still exhibit harmful behaviors. Current alignment strategies typically embed safety into model weights, making these controls implicit, static, and difficult to modify. This paper introduces Cognition-of-Thought (CooT), a novel decoding-time framework that equips LLMs with an explicit cognitive self-monitoring loop. CooT couples a standard text Generator with a cognitive Perceiver that continuously monitors the unfolding sequence. The Perceiver uses a structured, precedence-based hierarchy of principles (e.g., safety over obedience) to detect potential misalignments as they arise. When violations are flagged, CooT intervenes by rolling back the generation to the point of error and regenerating under injected guidance that combines universal social priors with context-specific warnings. CooT thus transforms alignment from a fixed property into an explicit, dynamic, and auditable process active during inference, allowing for flexible policy updates without retraining the model. Extensive experiments across multiple benchmarks and model families confirm that CooT consistently improves safety and social reasoning performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23441","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.686201","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Xuanming Zhang, Yuxuan Chen, Samuel Yeh, Sharon Li","raw_content_length":1257,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["CooT"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1256,"language_detected":"en","key_concepts":{"key_phrases":["Cognition","LLMs","arXiv250923441v2 Announce Type","Large language models","complex reasoning","harmful behaviors","Current alignment strategies","safety","model weights","these controls"],"filter_categories":{"ai_ml":["LLMs","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cognition":2.0,"LLMs":2.0,"arXiv250923441v2 Announce Type":1.0,"Large language models":1.0,"complex reasoning":1.0,"harmful behaviors":1.0,"Current alignment strategies":1.0,"safety":1.0,"model weights":1.0,"these controls":1.0}},"age_hours":2.748985237222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6983,"joy":0.0121,"surprise":0.0191,"sadness":0.0371,"fear":0.072,"anger":0.0706,"disgust":0.0908},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel decoding-time framework (CooT) for LLMs that aims to improve safety and social reasoning. The concrete action is the development of a cognitive self-monitoring loop. The evidence supporting the claims comes from experiments across multiple benchmarks and model families. However, it is still in the applied research stage, with no indication of real-world deployment.","key_impact_metrics":["Improved safety performance","Improved social reasoning performance"],"technology_tags":["Large Language Models","AI Safety","Cognitive Monitoring"],"sdg_alignment":[4,16],"analyzed_at":"2025-10-29T16:49:42.404005Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cb39304d1325","title":"Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment","content":"arXiv:2509.23564v2 Announce Type: replace Abstract: Human feedback plays a pivotal role in aligning large language models (LLMs) with human preferences. However, such feedback is often noisy or inconsistent, which can degrade the quality of reward models and hinder alignment. While various automated data cleaning methods have been proposed to mitigate this issue, a systematic evaluation of their effectiveness and generalizability remains lacking. To bridge this gap, we introduce the first comprehensive benchmark for evaluating 13 preference data cleaning methods in the context of LLM alignment. PrefCleanBench offers a standardized protocol to assess cleaning strategies in terms of alignment performance and generalizability across diverse datasets, model architectures, and optimization algorithms. By unifying disparate methods and rigorously comparing them, we uncover key factors that determine the success of data cleaning in alignment tasks. This benchmark lays the groundwork for principled and reproducible approaches to improving LLM alignment through better data quality-highlighting the crucial but underexplored role of data preprocessing in responsible AI development. We release modular implementations of all methods to catalyze further research: https://github.com/deeplearning-wisc/PrefCleanBench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23564","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.686619","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Samuel Yeh, Sharon Li","raw_content_length":1323,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment arXiv:2509.23564v2","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1322,"language_detected":"en","key_concepts":{"key_phrases":["Clean First","Preference Data Cleaning","Reliable LLM Alignment","arXiv250923564v2","Announce Type","Abstract","Human feedback","a pivotal role","large language models","LLMs"],"filter_categories":{"ai_ml":["Reliable LLM Alignment","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Clean First":2.0,"Preference Data Cleaning":2.0,"Reliable LLM Alignment":2.0,"arXiv250923564v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Human feedback":1.0,"a pivotal role":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7489996672222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.879,"joy":0.0036,"surprise":0.0105,"sadness":0.0159,"fear":0.0143,"anger":0.0369,"disgust":0.0398},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for evaluating data cleaning methods to improve LLM alignment with human preferences. While it doesn't directly reduce GHG emissions, it aims to improve the reliability of AI systems that could be used in climate-related applications. The benchmark includes 13 data cleaning methods and is evaluated across diverse datasets, model architectures, and optimization algorithms, increasing technical credibility.","key_impact_metrics":["Alignment performance","Generalizability across datasets"],"technology_tags":["Large Language Models","Data Cleaning","AI Alignment"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:45.312345Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8825b2f63a50","title":"SIG","content":"arXiv:2509.23852v2 Announce Type: replace Abstract: The accompanying actions and gestures in dialogue are often closely linked to interactions with the environment, such as looking toward the interlocutor or using gestures to point to the described target at appropriate moments. Speech and semantics guide the production of gestures by determining their timing (WHEN) and style (HOW), while the spatial locations of interactive objects dictate their directional execution (WHERE). Existing approaches either rely solely on descriptive language to generate motions or utilize audio to produce non-interactive gestures, thereby lacking the characterization of interactive timing and spatial intent. This significantly limits the applicability of conversational gesture generation, whether in robotics or in the fields of game and animation production. To address this gap, we present a full-stack solution. We first established a unique data collection method to simultaneously capture high-precision human motion and spatial intent. We then developed a generation model driven by audio, language, and spatial data, alongside dedicated metrics for evaluating interaction timing and spatial accuracy. Finally, we deployed the solution on a humanoid robot, enabling rich, context-aware physical interactions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.23852","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.687027","language":"en","tags":["preprints","csmm","computer-science","research","csgr","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Yiheng Huang, Junran Peng, Silei Shen, Jingwei Yang, ZeJi Wei, ChenCheng Bai, Yonghao He, Wei Sui, Muyi Sun, Yan Liu, Xu-Cheng Yin, Man Zhang, Zhaoxiang Zhang, Chuanchen Luo","raw_content_length":1306,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Speech","SIG"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1305,"language_detected":"en","key_concepts":{"key_phrases":["gestures","Announce Type","Abstract","The accompanying actions","dialogue","interactions","the environment","the interlocutor","the described target","appropriate moments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"gestures":3.0,"Announce Type":1.0,"Abstract":1.0,"The accompanying actions":1.0,"dialogue":1.0,"interactions":1.0,"the environment":1.0,"the interlocutor":1.0,"the described target":1.0,"appropriate moments":1.0}},"age_hours":2.7490136336111113,"is_recent":true,"quality_score":0.7,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9324,"joy":0.012,"surprise":0.0347,"sadness":0.0036,"fear":0.0042,"anger":0.0095,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"pilot","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed solution on a humanoid robot, enabling context-aware physical interactions. The solution includes data collection methods, a generation model, and dedicated metrics for evaluating interaction timing and spatial accuracy. While it's a full-stack solution, the climate impact is indirect and theoretical, as it primarily focuses on improving human-robot interaction.","key_impact_metrics":["interaction timing accuracy","spatial accuracy"],"technology_tags":["robotics","human-robot interaction","gesture generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:50.611329Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_776f28cf823d","title":"Unified Multi","content":"arXiv:2509.24099v2 Announce Type: replace Abstract: Generating realistic, context-aware two-person motion conditioned on diverse modalities remains a central challenge in computer graphics, animation, and human-computer interaction. We introduce DualFlow, a unified and efficient framework for multi-modal two-person motion generation. DualFlow conditions 3D motion synthesis on diverse inputs, including text, music, and prior motion sequences. Leveraging rectified flow, it achieves deterministic straight-line sampling paths between noise and data, reducing inference time and mitigating error accumulation common in diffusion-based models. To enhance semantic grounding, DualFlow employs a Retrieval-Augmented Generation (RAG) module that retrieves motion exemplars using music features and LLM-based text decompositions of spatial relations, body movements, and rhythmic patterns. We use contrastive objective that further strengthens alignment with conditioning signals and introduce synchronization loss that improves inter-person coordination. Extensive evaluations across text-to-motion, music-to-motion, and multi-modal interactive benchmarks show consistent gains in motion quality, responsiveness, and efficiency. DualFlow produces temporally coherent and rhythmically synchronized motions, setting state-of-the-art in multi-modal human motion generation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24099","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.687426","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Prerit Gupta, Shourya Verma, Ananth Grama, Aniket Bera","raw_content_length":1368,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["DualFlow"],"persons":[],"locations":[],"monetary":[]},"char_count":1367,"language_detected":"en","key_concepts":{"key_phrases":["Unified Multi","arXiv250924099v2 Announce Type","Abstract","realistic context-aware two-person motion","diverse modalities","a central challenge","computer graphics","animation","human-computer interaction","DualFlow"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unified Multi":2.0,"arXiv250924099v2 Announce Type":1.0,"Abstract":1.0,"realistic context-aware two-person motion":1.0,"diverse modalities":1.0,"a central challenge":1.0,"computer graphics":1.0,"animation":1.0,"human-computer interaction":1.0,"DualFlow":1.0}},"age_hours":2.7490280825,"is_recent":true,"quality_score":1.0,"sentiment_score":9.036999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8074,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8915,"joy":0.0425,"surprise":0.0418,"sadness":0.0036,"fear":0.0054,"anger":0.011,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for multi-modal two-person motion generation. While it improves efficiency and quality in motion synthesis, it doesn't directly address climate change or environmental sustainability. The technology is in the early stages of development with no clear path to economic viability or deployment.","key_impact_metrics":["Reduced inference time","Improved motion quality"],"technology_tags":["AI","Motion Generation","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:53.518429Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_da08e0d072f1","title":"IWR","content":"arXiv:2509.24709v2 Announce Type: replace Abstract: The webpage-to-code task requires models to understand visual representations of webpages and generate corresponding code. However, existing benchmarks primarily focus on static screenshot-to-code tasks, thereby overlooking the dynamic interactions fundamental to real-world web applications. To address this limitation, this paper introduces IWR-Bench, a novel benchmark for evaluating the capabilities of Large Vision-Language Models (LVLMs) in interactive webpage reconstruction from video. IWR-Bench comprises 113 meticulously curated tasks from 100 real-world websites, with 1,001 actions and featuring diverse interaction complexities (e.g., web games), visual styles, and domains. Aligning with standard web development practices, each task includes not only user interaction videos but also all crawled static assets (e.g., images, videos). This benchmark evaluates models on two fundamental challenges: comprehensive multi-modal reasoning to infer interaction logic from video and assets, and advanced code generation to translate this logic into functional code. An agent-as-a-judge framework with a comprehensive metric system automatically assesses the functional correctness and visual fidelity of generated webpages. Extensive experiments on 28 LVLMs reveal a significant challenge: the best model achieves an overall score of only 36.35%, as functional correctness (24.39% IFS) lags significantly behind visual fidelity (64.25% VFS). These results highlight critical limitations in current models' ability to reason about temporal dynamics and synthesize event-driven logic, establishing IWR-Bench as a challenging frontier for vision-language research. The benchmark and evaluation code will be made publicly available at https://github.com/L-O-I/IWR-Bench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.24709","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.691969","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Yang Chen, Minghao Liu, Yufan Shen, Yunwen Li, Tianyuan Huang, Xinyu Fang, Tianyu Zheng, Wenxuan Huang, Cheng Yang, Daocheng Fu, Jianbiao Mei, Rong Wu, Yunfei Zhao, Licheng Wen, Xuemeng Yang, Song Mao, Qunshu Lin, Zhi Yu, Yongliang Shen, Yu Qiao, Botian Shi","raw_content_length":1826,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["Large Vision-Language Models","IWR"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1825,"language_detected":"en","key_concepts":{"key_phrases":["IWR","code","Announce Type","Abstract","models","visual representations","webpages","corresponding code","existing benchmarks","the dynamic interactions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IWR":2.0,"code":2.0,"Announce Type":1.0,"Abstract":1.0,"models":1.0,"visual representations":1.0,"webpages":1.0,"corresponding code":1.0,"existing benchmarks":1.0,"the dynamic interactions":1.0}},"age_hours":2.749057673888889,"is_recent":true,"quality_score":0.7,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8578,"joy":0.0175,"surprise":0.0944,"sadness":0.0082,"fear":0.0059,"anger":0.0119,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (IWR-Bench) for evaluating Large Vision-Language Models (LVLMs) in interactive webpage reconstruction. The benchmark uses real-world websites and evaluates models on functional correctness and visual fidelity, with the best model achieving only 36.35% overall score. This is basic research, not deployment, and its climate impact is indirect, potentially enabling more efficient web development, but not directly reducing emissions.","key_impact_metrics":["overall score of 36.35%","functional correctness (24.39% IFS)","visual fidelity (64.25% VFS)"],"technology_tags":["Large Vision-Language Models","webpage reconstruction","interactive webpage"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:49:56.577637Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_db6119dcd004","title":"Understanding the Mixture-of","content":"arXiv:2509.25913v2 Announce Type: replace Abstract: Mixture-of-Experts (MoE) has become a cornerstone in recent state-of-the-art large language models (LLMs). Traditionally, MoE relies on $\\mathrm{Softmax}$ as the router score function to aggregate expert output, a designed choice that has persisted from the earliest MoE models to modern LLMs, and is now widely regarded as standard practice. However, the necessity of using $\\mathrm{Softmax}$ to project router weights into a probability simplex remains an unchallenged assumption rather than a principled design choice. In this work, we first revisit the classical Nadaraya-Watson regression and observe that MoE shares the same mathematical formulation as Nadaraya-Watson regression. Furthermore, we show that both feed-forward neural network (FFN) and MoE can be interpreted as a special case of Nadaraya-Watson regression, where the kernel function corresponds to the input neurons of the output layer. Motivated by these insights, we propose the \\textbf{zero-additional-cost} Kernel Inspired Router with Normalization (KERN), an FFN-style router function, as an alternative to $\\mathrm{Softmax}$. We demonstrate that this router generalizes both $\\mathrm{Sigmoid}$- and $\\mathrm{Softmax}$-based routers. \\textbf{Based on empirical observations and established practices in FFN implementation, we recommend the use of $\\mathrm{ReLU}$ activation and $\\ell_2$-normalization in $\\mathrm{KERN}$ router function.} Comprehensive experiments in MoE and LLM validate the effectiveness of the proposed FFN-style router function \\methodNorm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.25913","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.693276","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Chuanyang Zheng, Jiankai Sun, Yihang Gao, Enze Xie, Yuehao Wang, Peihao Wang, Ting Xu, Matthew Chang, Liliang Ren, Jingyao Li, Jing Xiong, Kashif Rasul, Mac Schwager, Anderson Schneider, Zhangyang Wang, Yuriy Nevmyvaka","raw_content_length":1589,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["FFN","MoE"],"persons":["\\mathrm{Softmax}$"],"locations":[],"monetary":[]},"char_count":1588,"language_detected":"en","key_concepts":{"key_phrases":["the Mixture","MoE","mathrmSoftmax","Announce Type","Abstract","Mixture","Experts","a cornerstone","the-art","LLMs"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Mixture":2.0,"MoE":2.0,"mathrmSoftmax":2.0,"Announce Type":1.0,"Abstract":1.0,"Mixture":1.0,"Experts":1.0,"a cornerstone":1.0,"the-art":1.0,"LLMs":1.0}},"age_hours":2.749101329444444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9315,"joy":0.0097,"surprise":0.034,"sadness":0.0057,"fear":0.0054,"anger":0.0077,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new router function for Mixture-of-Experts models, potentially improving the efficiency of large language models. While the research is promising and backed by empirical observations, it is still in the early stages of development with no deployed units or real-world data available to assess its actual impact on energy consumption of LLMs.","key_impact_metrics":["Reduced computational cost (unspecified)","Improved model performance (unspecified)"],"technology_tags":["Mixture-of-Experts","Large Language Models","Router Function","ReLU Activation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:49:59.928501Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_efa81c780e75","title":"Unspoken Hints: Accuracy Without Acknowledgement in LLM Reasoning","content":"arXiv:2509.26041v2 Announce Type: replace Abstract: Large language models (LLMs) increasingly rely on chain-of-thought (CoT) prompting to solve mathematical and logical reasoning tasks. Yet, a central question remains: to what extent are these generated rationales \\emph{faithful} to the underlying computations, rather than post-hoc narratives shaped by hints that function as answer shortcuts embedded in the prompt? Following prior work on hinted vs.\\ unhinted prompting, we present a systematic study of CoT faithfulness under controlled hint manipulations. Our experimental design spans four datasets (AIME, GSM-Hard, MATH-500, UniADILR), two state-of-the-art models (GPT-4o and Gemini-2-Flash), and a structured set of hint conditions varying in correctness (correct and incorrect), presentation style (sycophancy and data leak), and complexity (raw answers, two-operator expressions, four-operator expressions). We evaluate both task accuracy and whether hints are explicitly acknowledged in the reasoning. Our results reveal three key findings. First, correct hints substantially improve accuracy, especially on harder benchmarks and logical reasoning, while incorrect hints sharply reduce accuracy in tasks with lower baseline competence. Second, acknowledgement of hints is highly uneven: equation-based hints are frequently referenced, whereas raw hints are often adopted silently, indicating that more complex hints push models toward verbalizing their reliance in the reasoning process. Third, presentation style matters: sycophancy prompts encourage overt acknowledgement, while leak-style prompts increase accuracy but promote hidden reliance. This may reflect RLHF-related effects, as sycophancy exploits the human-pleasing side and data leak triggers the self-censoring side. Together, these results demonstrate that LLM reasoning is systematically shaped by shortcuts in ways that obscure faithfulness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26041","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.693737","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Arash Marioriyad, Shaygan Adim, Nima Alighardashi, Mahdieh Soleymani Banghshah, Mohammad Hossein Rohban","raw_content_length":1921,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["AIME","CoT","GSM-Hard"],"persons":["UniADILR","Accuracy Without Acknowledgement","Unspoken Hints"],"locations":[],"monetary":[]},"char_count":1920,"language_detected":"en","key_concepts":{"key_phrases":["Unspoken Hints","Accuracy","Acknowledgement","LLM Reasoning","arXiv250926041v2","Announce Type","Large language models","LLMs","thought","mathematical and logical reasoning tasks"],"filter_categories":{"ai_ml":["LLM Reasoning","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Unspoken Hints":2.0,"Accuracy":2.0,"Acknowledgement":2.0,"LLM Reasoning":2.0,"arXiv250926041v2":1.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"thought":1.0,"mathematical and logical reasoning tasks":1.0}},"age_hours":2.7491165883333335,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9421,"joy":0.003,"surprise":0.0174,"sadness":0.006,"fear":0.0116,"anger":0.0103,"disgust":0.0096},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research investigates the faithfulness of LLM reasoning, specifically in the context of chain-of-thought prompting. While the research itself doesn't directly impact climate change, understanding the limitations and biases of LLMs is crucial for their responsible development and application in various domains, including climate modeling and sustainability planning. The study uses established datasets and models, providing a level of technical credibility.","key_impact_metrics":["Accuracy improvement with correct hints","Accuracy reduction with incorrect hints"],"technology_tags":["Large Language Models","Chain-of-Thought Prompting","AI Reasoning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:50:03.040105Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f461da8e2e13","title":"The Silent Judge: Unacknowledged Shortcut Bias in LLM-as","content":"arXiv:2509.26072v2 Announce Type: replace Abstract: Large language models (LLMs) are increasingly deployed as automatic judges to evaluate system outputs in tasks such as summarization, dialogue, and creative writing. A faithful judge should base its verdicts solely on response quality and explicitly acknowledge the factors shaping its decision. We show that current LLM judges fail on both counts by relying on shortcuts introduced in the prompt. Our study uses two evaluation datasets: ELI5, a benchmark for long-form question answering, and LitBench, a recent benchmark for creative writing. Both datasets provide pairwise comparisons, where the evaluator must choose which of two responses is better. From each dataset we construct 100 pairwise judgment tasks and employ two widely used models, GPT-4o and Gemini-2.5-Flash, as evaluators in the role of LLM-as-a-judge. For each pair, we assign superficial cues to the responses, provenance cues indicating source identity (Human, Expert, LLM, or Unknown) and recency cues indicating temporal origin (Old, 1950 vs. New, 2025), while keeping the rest of the prompt fixed. Results reveal consistent verdict shifts: both models exhibit a strong recency bias, systematically favoring new responses over old, as well as a clear provenance hierarchy (Expert > Human > LLM > Unknown). These biases are especially pronounced in GPT-4o and in the more subjective and open-ended LitBench domain. Crucially, cue acknowledgment is rare: justifications almost never reference the injected cues, instead rationalizing decisions in terms of content qualities. These findings demonstrate that current LLM-as-a-judge systems are shortcut-prone and unfaithful, undermining their reliability as evaluators in both research and deployment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26072","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.694174","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Arash Marioriyad, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah","raw_content_length":1775,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["LitBench","LLM"],"persons":["Unacknowledged Shortcut Bias"],"locations":[],"monetary":[]},"char_count":1774,"language_detected":"en","key_concepts":{"key_phrases":["The Silent Judge","Unacknowledged Shortcut Bias","LLM","arXiv250926072v2","Announce Type","Large language models","LLMs","automatic judges","system outputs","tasks"],"filter_categories":{"ai_ml":["LLM","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Silent Judge":2.0,"Unacknowledged Shortcut Bias":2.0,"LLM":2.0,"arXiv250926072v2":1.0,"Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"automatic judges":1.0,"system outputs":1.0,"tasks":1.0}},"age_hours":2.749131993611111,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5373,"joy":0.0032,"surprise":0.0113,"sadness":0.0698,"fear":0.0701,"anger":0.1257,"disgust":0.1827},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies biases in LLM judges, showing they are shortcut-prone and unfaithful. The concrete action is the testing of GPT-4o and Gemini-2.5-Flash on evaluation datasets. The evidence is the consistent verdict shifts observed, favoring new responses and exhibiting a provenance hierarchy. This is currently at the pilot stage, as it involves testing and analysis, but not yet deployed in real-world applications.","key_impact_metrics":["Recency bias favoring new responses","Provenance hierarchy (Expert > Human > LLM > Unknown)"],"technology_tags":["Large Language Models","AI Evaluation","Bias Detection"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:50:06.763239Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_989c00af528e","title":"Limited Preference Data? Learning Better Reward Model with Latent Space Synthesis","content":"arXiv:2509.26074v2 Announce Type: replace Abstract: Reward modeling, crucial for aligning large language models (LLMs) with human preferences, is often bottlenecked by the high cost of preference data. Existing textual data synthesis methods are computationally expensive. We propose a novel framework LENS for synthesizing preference data directly in the LLM's latent embedding space. Our method employs a Variational Autoencoder (VAE) to learn a structured latent representation of response embeddings. By performing controlled perturbations in this latent space and decoding back to the embedding space, we efficiently generate diverse, semantically consistent synthetic preference pairs, bypassing costly text generation and annotation. We provide theoretical guarantees that our synthesized pairs approximately preserve original preference ordering and improve reward model generalization. Empirically, our latent-space synthesis significantly outperforms text-based augmentation on standard benchmarks, achieving superior results while being 18x faster in generation and using a 16,000x smaller model. Our work offers a scalable and effective alternative for enhancing reward modeling through efficient data augmentation. Code is publicly available at https://github.com/deeplearning-wisc/lens","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26074","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.694598","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Leitian Tao, Xuefeng Du, Sharon Li","raw_content_length":1300,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Learning Better Reward Model with Latent Space Synthesis","Limited Preference Data","LLM","VAE"],"persons":[],"locations":[],"monetary":[]},"char_count":1299,"language_detected":"en","key_concepts":{"key_phrases":["Limited Preference Data","Better Reward Model","Latent Space Synthesis","preference data","arXiv250926074v2","Announce Type","Abstract","modeling","large language models","LLMs"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Limited Preference Data":2.0,"Better Reward Model":2.0,"Latent Space Synthesis":2.0,"preference data":2.0,"arXiv250926074v2":1.0,"Announce Type":1.0,"Abstract":1.0,"modeling":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.749146017222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.467,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8934,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8713,"joy":0.0052,"surprise":0.038,"sadness":0.0148,"fear":0.0164,"anger":0.0373,"disgust":0.0169},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of reward modeling for LLMs, which indirectly supports sustainability by potentially reducing the computational resources needed for training and deploying these models. The method achieves 18x faster generation and uses a 16,000x smaller model compared to text-based augmentation, indicating a significant reduction in energy consumption. However, it is still in the applied research stage, with no deployed units or real-world operational data available.","key_impact_metrics":["18x faster generation","16,000x smaller model"],"technology_tags":["Reward Modeling","Latent Space Synthesis"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-29T16:50:11.476231Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5509aca2aa8c","title":"A Generalized Information Bottleneck Theory of Deep Learning","content":"arXiv:2509.26327v2 Announce Type: replace Abstract: The Information Bottleneck (IB) principle offers a compelling theoretical framework to understand how neural networks (NNs) learn. However, its practical utility has been constrained by unresolved theoretical ambiguities and significant challenges in accurate estimation. In this paper, we present a \\textit{Generalized Information Bottleneck (GIB)} framework that reformulates the original IB principle through the lens of synergy, i.e., the information obtainable only through joint processing of features. We provide theoretical and empirical evidence demonstrating that synergistic functions achieve superior generalization compared to their non-synergistic counterparts. Building on these foundations we re-formulate the IB using a computable definition of synergy based on the average interaction information (II) of each feature with those remaining. We demonstrate that the original IB objective is upper bounded by our GIB in the case of perfect estimation, ensuring compatibility with existing IB theory while addressing its limitations. Our experimental results demonstrate that GIB consistently exhibits compression phases across a wide range of architectures (including those with \\textit{ReLU} activations where the standard IB fails), while yielding interpretable dynamics in both CNNs and Transformers and aligning more closely with our understanding of adversarial robustness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2509.26327","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.695449","language":"en","tags":["preprints","csit","computer-science","cslg","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Charles Westphal, Stephen Hailes, Mirco Musolesi","raw_content_length":1446,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Generalized Information Bottleneck Theory of","The Information Bottleneck"],"persons":[],"locations":[],"monetary":[]},"char_count":1445,"language_detected":"en","key_concepts":{"key_phrases":["A Generalized Information Bottleneck Theory","Deep Learning","arXiv250926327v2 Announce Type","Abstract","The Information Bottleneck","IB principle","a compelling theoretical framework","neural networks","NNs","its practical utility"],"filter_categories":{"ai_ml":["Deep Learning","neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Generalized Information Bottleneck Theory":2.0,"Deep Learning":2.0,"arXiv250926327v2 Announce Type":1.0,"Abstract":1.0,"The Information Bottleneck":1.0,"IB principle":1.0,"a compelling theoretical framework":1.0,"neural networks":1.0,"NNs":1.0,"its practical utility":1.0}},"age_hours":2.7491743008333334,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8973,"joy":0.0185,"surprise":0.0345,"sadness":0.0068,"fear":0.0134,"anger":0.0185,"disgust":0.0111},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework (Generalized Information Bottleneck) to improve the efficiency and generalization of deep learning models. While potentially impactful for reducing computational resources required for AI, which could indirectly lower energy consumption, it is currently at the basic research stage with no deployed technology or measured outcomes related to sustainability. The paper focuses on theoretical advancements and empirical validation within the AI/ML domain.","key_impact_metrics":[],"technology_tags":["Deep Learning","Information Bottleneck","Synergy"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:50:14.322797Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_75a53292d304","title":"Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs","content":"arXiv:2510.00507v2 Announce Type: replace Abstract: As multimodal LLM-driven agents continue to advance in autonomy and generalization, evaluation based on static datasets can no longer adequately assess their true capabilities in dynamic environments and diverse tasks. Existing LLM-based synthetic data methods are largely designed for LLM training and evaluation, and thus cannot be directly applied to agent tasks that require tool use and interactive capabilities. While recent studies have explored automatic agent task generation with LLMs, most efforts remain limited to text or image analysis, without systematically modeling multi-step interactions in web environments. To address these challenges, we propose Graph2Eval, a knowledge graph-based framework that automatically generates both multimodal document comprehension tasks and web interaction tasks, enabling comprehensive evaluation of agents' reasoning, collaboration, and interactive capabilities. In our approach, knowledge graphs constructed from multi-source external data serve as the task space, where we translate semantic relations into structured multimodal tasks using subgraph sampling, task templates, and meta-paths. A multi-stage filtering pipeline based on node reachability, LLM scoring, and similarity analysis is applied to guarantee the quality and executability of the generated tasks. Furthermore, Graph2Eval supports end-to-end evaluation of multiple agent types (Single-Agent, Multi-Agent, Web Agent) and measures reasoning, collaboration, and interaction capabilities. We instantiate the framework with Graph2Eval-Bench, a curated dataset of 1,319 tasks spanning document comprehension and web interaction scenarios. Experiments show that Graph2Eval efficiently generates tasks that differentiate agent and model performance, revealing gaps in reasoning, collaboration, and web interaction across different settings and offering a new perspective for agent evaluation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.00507","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.696666","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Yurun Chen, Xavier Hu, Yuhan Liu, Ziqi Wang, Zeyi Liao, Lin Chen, Feng Wei, Yuxi Qian, Bo Zheng, Keting Yin, Shengyu Zhang","raw_content_length":1962,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Knowledge Graphs arXiv:2510.00507v2 Announce Type"],"locations":[],"monetary":[]},"char_count":1961,"language_detected":"en","key_concepts":{"key_phrases":["Graph2Eval","Automatic Multimodal Task Generation","Agents","Knowledge Graphs","evaluation","arXiv251000507v2 Announce Type","Abstract","multimodal LLM-driven agents","autonomy","generalization"],"filter_categories":{"hydrogen_energy":["Graph2Eval"],"ai_ml":["multimodal LLM-driven agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Graph2Eval":2.0,"Automatic Multimodal Task Generation":2.0,"Agents":2.0,"Knowledge Graphs":2.0,"evaluation":2.0,"arXiv251000507v2 Announce Type":1.0,"Abstract":1.0,"multimodal LLM-driven agents":1.0,"autonomy":1.0,"generalization":1.0}},"age_hours":2.7492028824999997,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8914,"joy":0.0076,"surprise":0.0524,"sadness":0.0124,"fear":0.0147,"anger":0.0143,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a framework (Graph2Eval) for automatically generating tasks to evaluate AI agents. While this could indirectly support sustainability efforts by improving the capabilities of AI used in those fields, there are no concrete actions or measurable outcomes related to climate change or other sustainability dimensions. The framework is currently in the applied research stage, with a curated dataset of 1,319 tasks.","key_impact_metrics":["1,319 tasks generated"],"technology_tags":["AI","Knowledge Graphs","Multimodal Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:50:17.652405Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0df75dc913c5","title":"Asymmetric Proximal Policy Optimization: mini","content":"arXiv:2510.01656v2 Announce Type: replace Abstract: Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacing them with average advantage baselines. This shift is largely pragmatic: conventional value functions are computationally expensive to train at LLM scale and often fail under sparse rewards and long reasoning horizons. We revisit this bottleneck from an architectural perspective and introduce Asymmetric Proximal Policy Optimization (AsyPPO), a simple and scalable framework that restores the critics role while remaining efficient in large-model settings. AsyPPO employs a set of lightweight mini-critics, each trained on disjoint prompt shards. This design encourages diversity while preserving calibration, reducing value-estimation bias. Beyond robust estimation, AsyPPO leverages inter-critic uncertainty to refine the policy update: (i) masking advantages in states where critics agree and gradients add little learning signal, and (ii) filtering high-divergence states from entropy regularization, suppressing spurious exploration. After training on open-source data with only 5,000 samples, AsyPPO consistently improves learning stability and performance across multiple benchmarks over strong baselines, such as GRPO, achieving performance gains of more than six percent on Qwen3-4b-Base and about three percent on Qwen3-8b-Base and Qwen3-14b-Base over classic PPO, without additional tricks. These results highlight the importance of architectural innovations for scalable, efficient algorithms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.01656","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.697616","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Jiashun Liu, Johan Obando-Ceron, Han Lu, Yancheng He, Weixun Wang, Wenbo Su, Bo Zheng, Pablo Samuel Castro, Aaron Courville, Ling Pan","raw_content_length":1533,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":["Asymmetric Proximal Policy Optimization","Asymmetric Proximal Policy Optimization (AsyPPO","LLM"],"persons":["AsyPPO leverages inter-critic","Announce Type"],"locations":[],"monetary":[]},"char_count":1532,"language_detected":"en","key_concepts":{"key_phrases":["Asymmetric Proximal Policy Optimization","mini","Announce Type","Abstract","LLMs","explicit critics","them","average advantage baselines","This shift","conventional value functions"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Asymmetric Proximal Policy Optimization":3.0,"mini":2.0,"Announce Type":1.0,"Abstract":1.0,"LLMs":1.0,"explicit critics":1.0,"them":1.0,"average advantage baselines":1.0,"This shift":1.0,"conventional value functions":1.0}},"age_hours":2.7492324222222226,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9055,"joy":0.0068,"surprise":0.0295,"sadness":0.0181,"fear":0.0117,"anger":0.0187,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm (AsyPPO) for improving the efficiency of reinforcement learning for large language models. While the algorithm demonstrates performance gains (6% on Qwen3-4b-Base), its direct climate impact is indirect, potentially reducing the computational resources needed for training LLMs, which could lead to energy savings. The research is in an early stage, with no deployed applications or economic viability data.","key_impact_metrics":["performance gains of more than six percent on Qwen3-4b-Base","about three percent on Qwen3-8b-Base and Qwen3-14b-Base"],"technology_tags":["reinforcement learning","large language models","algorithm optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T16:50:23.953654Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3f7691b43035","title":"PolySim: Bridging the Sim-to","content":"arXiv:2510.01708v3 Announce Type: replace Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer from the sim-to-real gap, which fundamentally arises from simulator inductive bias, the inherent assumptions and limitations of any single simulator. These biases lead to nontrivial discrepancies both across simulators and between simulation and the real world. To mitigate the effect of simulator inductive bias, the key idea is to train policies jointly across multiple simulators, encouraging the learned controller to capture dynamics that generalize beyond any single simulator's assumptions. We thus introduce PolySim, a WBC training platform that integrates multiple heterogeneous simulators. PolySim can launch parallel environments from different engines simultaneously within a single training run, thereby realizing dynamics-level domain randomization. Theoretically, we show that PolySim yields a tighter upper bound on simulator inductive bias than single-simulator training. In experiments, PolySim substantially reduces motion-tracking error in sim-to-sim evaluations; for example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim baseline. PolySim further enables zero-shot deployment on a real Unitree G1 without additional fine-tuning, showing effective transfer from simulation to the real world. We will release the PolySim code upon acceptance of this work.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.01708","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.698040","language":"en","tags":["preprints","csai","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Zixing Lei, Zibo Zhou, Sheng Yin, Yueru Chen, Qingyao Xu, Weixin Li, Yunhong Wang, Bowei Tang, Wei Jing, Siheng Chen","raw_content_length":1426,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["PolySim","WBC"],"persons":["PolySim"],"locations":[],"monetary":[]},"char_count":1425,"language_detected":"en","key_concepts":{"key_phrases":["the Sim","simulation","simulator inductive bias","Announce Type","Humanoid whole-body control WBC policies","the sim-to-real gap","which","the inherent assumptions","limitations","any single simulator"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Sim":2.0,"simulation":2.0,"simulator inductive bias":2.0,"Announce Type":1.0,"Humanoid whole-body control WBC policies":1.0,"the sim-to-real gap":1.0,"which":1.0,"the inherent assumptions":1.0,"limitations":1.0,"any single simulator":1.0}},"age_hours":2.749246619444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8481,"joy":0.0057,"surprise":0.0213,"sadness":0.059,"fear":0.0371,"anger":0.0147,"disgust":0.0141},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new platform, PolySim, that improves sim-to-real transfer for robot control. While it doesn't directly address climate change, improved robot control could potentially lead to more efficient automation in various sectors, including those relevant to sustainability. The claim of a 52.8% improvement in execution success is a concrete metric, but the technology is still in the early stages of deployment.","key_impact_metrics":["execution success improvement 52.8%"],"technology_tags":["robotics","simulation","machine learning","control systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:50:28.943016Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ffdb8d807082","title":"KnowledgeSmith: Uncovering Knowledge Updating in LLMs with Model Editing and Unlearning","content":"arXiv:2510.02392v2 Announce Type: replace Abstract: Knowledge editing and machine unlearning are two popular approaches for large language models (LLMs) to stay up-to-date. However, the knowledge updating mechanism of LLMs remains largely unexplored due to insufficient, isolated, and small-scale evaluation. For instance, are LLMs similar to humans in modifying certain knowledge? What differs editing and unlearning as training data increases? This paper proposes KnowledgeSmith, a unified framework to systematically understand the updating mechanism of LLMs. We first cast editing and unlearning as instances of one constrained optimization problem. Then, we propose an automatic dataset generator that provides structured interventions across multiple graph levels and data scales, enabling controlled studies of how different modification strategies propagate through model knowledge. Extensive experiments demonstrate nuanced insights over knowledge propagation, plasticity scaling, consistency, and robustness. For instance, our results show that LLMs do not exhibit similar updating as humans for different levels of knowledge, and there exists consistency-capacity trade-off. We hope our findings can offer suggestions to the design of more reliable and scalable strategies. Code: https://github.com/AIFrontierLab/KnowledgeSmith.git","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02392","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.698438","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Yinyi Luo, Zhexian Zhou, Hao Chen, Kai Qiu, Marios Savvides, Sharon Li, Jindong Wang","raw_content_length":1343,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["KnowledgeSmith"],"persons":["Unlearning arXiv:2510.02392v2"],"locations":[],"monetary":[]},"char_count":1342,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","KnowledgeSmith","Knowledge Updating","Model Editing","Unlearning","arXiv251002392v2","Announce Type","Abstract","Knowledge editing","machine"],"filter_categories":{"ai_ml":["LLMs","machine"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":5.0,"KnowledgeSmith":3.0,"Knowledge Updating":2.0,"Model Editing":2.0,"Unlearning":2.0,"arXiv251002392v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Knowledge editing":1.0,"machine":1.0}},"age_hours":2.7492608369444445,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8592,"joy":0.0043,"surprise":0.0722,"sadness":0.0216,"fear":0.0137,"anger":0.017,"disgust":0.012},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework for understanding how LLMs update knowledge, focusing on editing and unlearning. While the research is scientifically sound and provides nuanced insights, it is currently in the basic research stage with no deployed technology or measurable climate impact. The potential for future climate impact is indirect, as improved LLMs could potentially contribute to climate modeling or other applications, but this is highly speculative at this stage.","key_impact_metrics":["Consistency-capacity trade-off","Knowledge propagation"],"technology_tags":["Large Language Models","Machine Unlearning","Knowledge Editing"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:50:32.397190Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c95d14153af9","title":"Engineering Emergence","content":"arXiv:2510.02649v2 Announce Type: replace Abstract: A defining property of complex systems is that they have multiscale structure. How does this multiscale structure come about? We argue that within systems there emerges a hierarchy of scales that contribute to a system's causal workings. An intuitive example is how a computer can be described at the level of its hardware circuitry (its microscale) but also its machine code (a mesoscale) and all the way up at its operating system (its macroscale). Here we show that even simple systems possess this kind of emergent hierarchy, which usually forms over only a small subset of the super-exponentially many possible scales of description. To capture this formally, we extend the theory of causal emergence (version 2.0) so as to analyze how causal contributions span the full multiscale structure of a system. Our analysis reveals that systems can be classified along a taxonomy of emergence, such as being either top-heavy or bottom-heavy in their causal workings. From this new taxonomy of emergence, we derive a measure of complexity based on a literal notion of scale-freeness (here, when causation is spread equally across the scales of a system) and compare this to the standard network science definition of scale-freeness based on degree distribution, showing the two are closely related. Finally, we demonstrate the ability to engineer not just the degree of emergence in a system, but to control it with pinpoint precision.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.02649","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.698872","language":"en","tags":["preprints","csit","computer-science","research","mathit","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Abel Jansma, Erik Hoel","raw_content_length":1486,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1485,"language_detected":"en","key_concepts":{"key_phrases":["Engineering Emergence","Announce Type","A defining property","complex systems","multiscale structure","this multiscale structure","systems","a hierarchy","scales","a systems causal workings"],"filter_categories":{"engineering":["systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Engineering Emergence":2.0,"Announce Type":1.0,"A defining property":1.0,"complex systems":1.0,"multiscale structure":1.0,"this multiscale structure":1.0,"systems":1.0,"a hierarchy":1.0,"scales":1.0,"a systems causal workings":1.0}},"age_hours":2.749275803333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8238,"joy":0.008,"surprise":0.1252,"sadness":0.0049,"fear":0.0101,"anger":0.016,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for understanding and engineering emergence in complex systems. While the research is published on arXiv and thus likely peer-reviewed, it's still in the basic research stage with no concrete deployments or measurable outcomes related to sustainability. The potential impact is theoretical and requires further development to translate into tangible climate action.","key_impact_metrics":[],"technology_tags":["complex systems","causal emergence","multiscale analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:50:37.237050Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_39c94a61b917","title":"Model-Based Ranking of Source Languages for Zero","content":"arXiv:2510.03202v2 Announce Type: replace Abstract: We present NN-Rank, an algorithm for ranking source languages for cross-lingual transfer, which leverages hidden representations from multilingual models and unlabeled target-language data. We experiment with two pretrained multilingual models and two tasks: part-of-speech tagging (POS) and named entity recognition (NER). We consider 51 source languages and evaluate on 56 and 72 target languages for POS and NER, respectively. When using in-domain data, NN-Rank beats state-of-the-art baselines that leverage lexical and linguistic features, with average improvements of up to 35.56 NDCG for POS and 18.14 NDCG for NER. As prior approaches can fall back to language-level features if target language data is not available, we show that NN-Rank remains competitive using only the Bible, an out-of-domain corpus available for a large number of languages. Ablations on the amount of unlabeled target data show that, for subsets consisting of as few as 25 examples, NN-Rank produces high-quality rankings which achieve 92.8% of the NDCG achieved using all available target data for ranking.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.03202","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.699273","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Abteen Ebrahimi, Adam Wiemerslage, Katharina von der Wense","raw_content_length":1142,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["NN-Rank","NER","Model-Based Ranking of Source Languages for Zero arXiv:2510.03202v2"],"persons":[],"locations":[],"monetary":[]},"char_count":1141,"language_detected":"en","key_concepts":{"key_phrases":["Model-Based Ranking","Source Languages","POS","NER","arXiv251003202v2 Announce Type","Abstract","NN-Rank","an algorithm","source languages","cross-lingual transfer"],"filter_categories":{"hydrogen_energy":["NER"],"renewable_energy":["NER"],"ai_ml":["an algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Model-Based Ranking":2.0,"Source Languages":2.0,"POS":2.0,"NER":2.0,"arXiv251003202v2 Announce Type":1.0,"Abstract":1.0,"NN-Rank":1.0,"an algorithm":1.0,"source languages":1.0,"cross-lingual transfer":1.0}},"age_hours":2.7492917616666666,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9,"joy":0.0146,"surprise":0.05,"sadness":0.0064,"fear":0.0055,"anger":0.0158,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents an algorithm (NN-Rank) for ranking source languages for cross-lingual transfer learning, improving the efficiency of training AI models. While this could indirectly support sustainability efforts by making AI development more efficient, there's no direct climate impact or deployment of the technology in a sustainability context. The algorithm's performance is measured using NDCG, with improvements of up to 35.56 for POS and 18.14 for NER.","key_impact_metrics":["35.56 NDCG for POS","18.14 NDCG for NER"],"technology_tags":["cross-lingual transfer learning","natural language processing","machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:50:40.627144Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
