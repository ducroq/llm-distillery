{"id":"science_arxiv_cs_34555ae82738","title":"Convergence Rate for the Last Iterate of Stochastic Gradient Descent Schemes","content":"arXiv:2507.07281v3 Announce Type: replace-cross Abstract: We study the convergence rate for the last iterate of stochastic gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric setting when the objective function $F$ is globally convex or non-convex whose gradient is $\\gamma$-H\\\"{o}lder. Using only discrete Gronwall's inequality without Robbins-Siegmund theorem, we recover results for both SGD and SHB: $\\min_{s\\leq t} \\|\\nabla F(w_s)\\|^2 = o(t^{p-1})$ for non-convex objectives and $F(w_{\\tau \\wedge t}) - F_* = o(t^{2\\gamma/(1+\\gamma) \\cdot \\max(p-1,-2p+1)-\\eps})$ for $\\beta \\in (0, 1)$, $\\tau := \\inf \\{ t > 0 : F(w_t) = F_*\\}$, and $\\min_{s \\leq t} F(w_s) - F_* = o(t^{p-1})$ for convex objectives $F$ whose minimum is $F_*$. In addition, we proved that SHB with constant momentum parameter $\\beta \\in (0, 1)$ attains a convergence rate of $F(w_t) - F_* = O(t^{\\max(p-1,-2p+1)} \\log^2 \\frac{t}{\\delta})$ with probability at least $1-\\delta$ when $F$ is convex and $\\gamma = 1$ and step size $\\alpha_t = \\Theta(t^{-p})$ with $p \\in (\\frac{1}{2}, 1)$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.07281","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.972493","language":"en","tags":["research","preprints","cslg","computer-science","mathoc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Marcel Hudiani","raw_content_length":1077,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["SHB","\\frac{t}{\\d","the Last Iterate of Stochastic Gradient Descent Schemes arXiv:2507.07281v3 Announce Type","SGD","Gronwall"],"persons":["F(w_{\\tau","\\min_{s\\leq","Convergence Rate","\\beta"],"locations":["\\log^2","Robbins-Siegmund"],"monetary":["\\gamma$-H\\\"{o}lder"]},"char_count":1076,"language_detected":"en","key_concepts":{"key_phrases":["Convergence Rate","the Last Iterate","Stochastic Gradient Descent Schemes","SHB","arXiv250707281v3 Announce Type","replace-cross Abstract","the convergence rate","the last iterate","stochastic gradient descent","SGD"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Convergence Rate":2.0,"the Last Iterate":2.0,"Stochastic Gradient Descent Schemes":2.0,"SHB":2.0,"arXiv250707281v3 Announce Type":1.0,"replace-cross Abstract":1.0,"the convergence rate":1.0,"the last iterate":1.0,"stochastic gradient descent":1.0,"SGD":1.0}},"age_hours":2.775322255555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8441,"joy":0.029,"surprise":0.0977,"sadness":0.0092,"fear":0.0055,"anger":0.0112,"disgust":0.0033},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on improving the convergence rate of stochastic gradient descent algorithms, which are used in machine learning models. While improved algorithms can indirectly contribute to sustainability by making AI models more efficient and potentially reducing energy consumption during training, the direct climate impact is minimal and unproven. The research is theoretical and at the basic research stage.","key_impact_metrics":["Convergence rate of algorithms","Reduction in computational time"],"technology_tags":["Stochastic Gradient Descent","Machine Learning","Optimization Algorithms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:33:34.477215Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f12035fc9964","title":"Lightweight and Interpretable Transformer via Mixed Graph Algorithm Unrolling for Traffic Forecast","content":"arXiv:2505.13102v2 Announce Type: replace Abstract: Unlike conventional \"black-box\" transformers with classical self-attention mechanism, we build a lightweight and interpretable transformer-like neural net by unrolling a mixed-graph-based optimization algorithm to forecast traffic with spatial and temporal dimensions. We construct two graphs: an undirected graph $\\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\\mathcal{G}^d$ capturing sequential relationships over time. We predict future samples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both $\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and $\\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We design an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We insert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$ that play the role of self-attention. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically. Our code is available in https://github.com/SingularityUndefined/Unrolling-GSP-STForecast .","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13102","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.173951","language":"en","tags":["cslg","eesssp","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Ji Qi, Tam Thuc Do, Mingxiao Liu, Zhuoshi Pan, Yuzhe Li, Gene Cheung, H. Vicky Zhao","raw_content_length":1358,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Interpretable Transformer"],"persons":["Mixed Graph Algorithm Unrolling"],"locations":[],"monetary":["$\\ell_2$ and $","\\mathcal{G}^d$","\\mathcal{G}^u$"]},"char_count":1357,"language_detected":"en","key_concepts":{"key_phrases":["Interpretable Transformer","Mixed Graph Algorithm","Traffic Forecast","Announce Type","Abstract","conventional black-box transformers","classical self-attention mechanism","a mixed-graph-based optimization algorithm","traffic","spatial and temporal dimensions"],"filter_categories":{"ai_ml":["Mixed Graph Algorithm","conventional black-box transformers","a mixed-graph-based optimization algorithm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Interpretable Transformer":2.0,"Mixed Graph Algorithm":2.0,"Traffic Forecast":2.0,"Announce Type":1.0,"Abstract":1.0,"conventional black-box transformers":1.0,"classical self-attention mechanism":1.0,"a mixed-graph-based optimization algorithm":1.0,"traffic":1.0,"spatial and temporal dimensions":1.0}},"age_hours":2.766377057222222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9337,"joy":0.0155,"surprise":0.028,"sadness":0.0044,"fear":0.0048,"anger":0.0085,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel neural network architecture for traffic forecasting that reduces parameter counts compared to state-of-the-art methods. While the code is available, there is no mention of real-world deployment or operational data, placing it in the applied research stage. The potential climate impact is related to optimizing traffic flow, which could reduce emissions, but this is not directly quantified.","key_impact_metrics":["reduced parameter counts","competitive traffic forecast performance"],"technology_tags":["neural networks","traffic forecasting","graph signal processing"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:34:42.095207Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f295edef595a","title":"Seg2Any: Open-set Segmentation-Mask","content":"arXiv:2506.00596v2 Announce Type: replace Abstract: Despite recent advances in diffusion models, top-tier text-to-image (T2I) models still struggle to achieve precise spatial layout control, i.e. accurately generating entities with specified attributes and locations. Segmentation-mask-to-image (S2I) generation has emerged as a promising solution by incorporating pixel-level spatial guidance and regional text prompts. However, existing S2I methods fail to simultaneously ensure semantic consistency and shape consistency. To address these challenges, we propose Seg2Any, a novel S2I framework built upon advanced multimodal diffusion transformers (e.g. FLUX). First, to achieve both semantic and shape consistency, we decouple segmentation mask conditions into regional semantic and high-frequency shape components. The regional semantic condition is introduced by a Semantic Alignment Attention Mask, ensuring that generated entities adhere to their assigned text prompts. The high-frequency shape condition, representing entity boundaries, is encoded as an Entity Contour Map and then introduced as an additional modality via multi-modal attention to guide image spatial structure. Second, to prevent attribute leakage across entities in multi-entity scenarios, we introduce an Attribute Isolation Attention Mask mechanism, which constrains each entity's image tokens to attend exclusively to themselves during image self-attention. To support open-set S2I generation, we construct SACap-1M, a large-scale dataset containing 1 million images with 5.9 million segmented entities and detailed regional captions, along with a SACap-Eval benchmark for comprehensive S2I evaluation. Extensive experiments demonstrate that Seg2Any achieves state-of-the-art performance on both open-set and closed-set S2I benchmarks, particularly in fine-grained spatial and attribute control of entities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00596","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.196681","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Danfeng li, Hui Zhang, Sheng Wang, Jiacheng Li, Zuxuan Wu","raw_content_length":1888,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["a Semantic Alignment Attention Mask"],"persons":[],"locations":[],"monetary":[]},"char_count":1887,"language_detected":"en","key_concepts":{"key_phrases":["Seg2Any","Open-set Segmentation-Mask","image","Announce Type","Abstract","recent advances","diffusion models","precise spatial layout control","entities","specified attributes"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Seg2Any":2.0,"Open-set Segmentation-Mask":2.0,"image":2.0,"Announce Type":1.0,"Abstract":1.0,"recent advances":1.0,"diffusion models":1.0,"precise spatial layout control":1.0,"entities":1.0,"specified attributes":1.0}},"age_hours":2.767214800833333,"is_recent":true,"quality_score":1.0,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7629,"joy":0.0082,"surprise":0.0369,"sadness":0.0876,"fear":0.0442,"anger":0.0351,"disgust":0.0251},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel image generation framework (Seg2Any) that improves spatial layout control and semantic consistency. It includes a large-scale dataset (SACap-1M) for training and evaluation. While the technology itself doesn't directly reduce GHG emissions, it could indirectly contribute by improving the efficiency of AI models used in various sustainability applications, but this is theoretical at this stage.","key_impact_metrics":["1 million images","5.9 million segmented entities"],"technology_tags":["image generation","diffusion models","segmentation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:34:58.578120Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8511a10192a1","title":"SatDreamer360: Multiview","content":"arXiv:2506.00600v2 Announce Type: replace Abstract: Generating multiview-consistent $360^\\circ$ ground-level scenes from satellite imagery is a challenging task with broad applications in simulation, autonomous navigation, and digital twin cities. Existing approaches primarily focus on synthesizing individual ground-view panoramas, often relying on auxiliary inputs like height maps or handcrafted projections, and struggle to produce multiview consistent sequences. In this paper, we propose SatDreamer360, a framework that generates geometrically consistent multi-view ground-level panoramas from a single satellite image, given a predefined pose trajectory. To address the large viewpoint discrepancy between ground and satellite images, we adopt a triplane representation to encode scene features and design a ray-based pixel attention mechanism that retrieves view-specific features from the triplane. To maintain multi-frame consistency, we introduce a panoramic epipolar-constrained attention module that aligns features across frames based on known relative poses. To support the evaluation, we introduce {VIGOR++}, a large-scale dataset for generating multi-view ground panoramas from a satellite image, by augmenting the original VIGOR dataset with more ground-view images and their pose annotations. Experiments show that SatDreamer360 outperforms existing methods in both satellite-to-ground alignment and multiview consistency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00600","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.197068","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Xianghui Ze, Beiyi Zhu, Zhenbo Song, Jianfeng Lu, Yujiao Shi","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["SatDreamer360","Multiview arXiv:2506.00600v2 Announce Type:"],"persons":[],"locations":[],"monetary":["360^\\circ$"]},"char_count":1442,"language_detected":"en","key_concepts":{"key_phrases":["SatDreamer360","Multiview","arXiv250600600v2 Announce Type","Abstract","multiview-consistent 360circ ground-level scenes","satellite imagery","a challenging task","broad applications","simulation","autonomous navigation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SatDreamer360":2.0,"Multiview":2.0,"arXiv250600600v2 Announce Type":1.0,"Abstract":1.0,"multiview-consistent 360circ ground-level scenes":1.0,"satellite imagery":1.0,"a challenging task":1.0,"broad applications":1.0,"simulation":1.0,"autonomous navigation":1.0}},"age_hours":2.767229072222222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8295,"joy":0.0119,"surprise":0.0303,"sadness":0.0282,"fear":0.052,"anger":0.0394,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for generating multi-view ground-level panoramas from satellite imagery. While the technology could potentially aid in autonomous navigation and digital twin cities, its direct climate impact is theoretical at this stage. The research is supported by a new dataset and outperforms existing methods, but lacks real-world deployment data.","key_impact_metrics":[],"technology_tags":["satellite imagery","computer vision","machine learning","triplane representation"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:35:03.578285Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fa21587cd500","title":"GRAM: Spatial general","content":"arXiv:2506.00934v3 Announce Type: replace Abstract: Although audio foundations models have seen great progress on a wide variety of tasks, their application in real-world acoustic environments with reverberation and noise has been less successful. Moreover, as audio foundation models are typically trained on dry, single-channel audio clips, the inherent spatial nature of real-world sound scenes is overlooked and tasks involving sound localization ruled out. To address these limitations, we propose GRAM: a General-purpose Real-world Audio Model utilizing a multi-channel masked auto-encoder approach to efficiently learn spatial audio representations from high-quality simulated real-world scenes. To evaluate the performance of GRAM and other audio foundation models in real-world sound scenes, we release Nat-HEAR: A naturalistic version of the HEAR benchmark suite comprising a simulated real-world version, as well as two new sound localization tasks. We show that the performance of GRAM surpasses all state-of-the-art self-supervised audio foundation models and speech models on both HEAR and Nat-HEAR, while using only a fraction of the training data. GRAM also showcases state-of-the-art localization performance, surpassing even supervised sound localization approaches, and can be flexibly applied either to a two-channel, binaural sound format or a four-channel, Ambisonics format. Validating GRAM's performance on real-world sound recordings demonstrates robust transfer to real-world scenes. Taken together, GRAM presents a significant advancement towards robust, spatial audio foundation models for real-world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00934","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.197865","language":"en","tags":["csai","eessas","preprints","research","cssd","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden","raw_content_length":1643,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["GRAM"],"persons":["Nat"],"locations":[],"monetary":[]},"char_count":1642,"language_detected":"en","key_concepts":{"key_phrases":["GRAM","Spatial general","tasks","Announce Type","Abstract","audio foundations models","great progress","a wide variety","their application","real-world acoustic environments"],"filter_categories":{"engineering":["GRAM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GRAM":2.0,"Spatial general":2.0,"tasks":2.0,"Announce Type":1.0,"Abstract":1.0,"audio foundations models":1.0,"great progress":1.0,"a wide variety":1.0,"their application":1.0,"real-world acoustic environments":1.0}},"age_hours":2.7672576127777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8445,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8394,"joy":0.0072,"surprise":0.0385,"sadness":0.0503,"fear":0.01,"anger":0.0251,"disgust":0.0296},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new audio model (GRAM) that learns spatial audio representations. While it shows improved performance on sound localization tasks, its direct climate impact is minimal. The model is currently in the applied research stage, with validation on simulated and real-world recordings, but lacks deployment data.","key_impact_metrics":["Fraction of training data used compared to SOTA","Performance on HEAR and Nat-HEAR benchmarks"],"technology_tags":["Audio Foundation Models","Spatial Audio Processing","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:35:21.585300Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4263b37fef5c","title":"Robust and Safe Multi","content":"arXiv:2506.00982v2 Announce Type: replace Abstract: Deep multi-agent reinforcement learning (MARL) has been demonstrated effectively in simulations for multi-robot problems. For autonomous vehicles, the development of vehicle-to-vehicle (V2V) communication technologies provide opportunities to further enhance system safety. However, zero-shot transfer of simulator-trained MARL policies to dynamic hardware systems remains challenging, and how to leverage communication and shared information for MARL has limited demonstrations on hardware. This problem is challenged by discrepancies between simulated and physical states, system state and model uncertainties, practical shared information design, and the need for safety guarantees in both simulation and hardware. This paper designs RSR-RSMARL, a novel Robust and Safe MARL framework that supports Real-Sim-Real (RSR) policy adaptation for multi-agent systems with communication among agents, with both simulation and hardware demonstrations. RSR-RSMARL leverages state (includes shared state information among agents) and action representations considering real system complexities for MARL formulation. The MARL policy is trained with robust MARL algorithm to enable zero-shot transfer to hardware considering the sim-to-real gap. A safety shield module using Control Barrier Functions (CBFs) provides safety guarantee for each individual agent. Experimental results on 1/10th-scale autonomous vehicles with V2V communication demonstrate the ability of RSR-RSMARL framework to enhance driving safety and coordination across multiple configurations. These findings emphasize the importance of jointly designing robust policy representations and modular safety architectures to enable scalable, generalizable RSR transfer in multi-agent autonomy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00982","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.198272","language":"en","tags":["computer-science","csma","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Keshawn Smith, Zhili Zhang, H M Sabbir Ahmad, Ehsan Sabouni, Maniak Mondal, Song Han, Wenchao Li, Fei Miao","raw_content_length":1803,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["MARL","Safe Multi arXiv:2506.00982v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1802,"language_detected":"en","key_concepts":{"key_phrases":["Robust and Safe Multi","Announce Type","Abstract","Deep multi-agent reinforcement learning","MARL","simulations","multi-robot problems","autonomous vehicles","the development","vehicle"],"filter_categories":{"ai_ml":["Deep multi-agent reinforcement learning"],"engineering":["the development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust and Safe Multi":2.0,"Announce Type":1.0,"Abstract":1.0,"Deep multi-agent reinforcement learning":1.0,"MARL":1.0,"simulations":1.0,"multi-robot problems":1.0,"autonomous vehicles":1.0,"the development":1.0,"vehicle":1.0}},"age_hours":2.7672720508333337,"is_recent":true,"quality_score":1.0,"sentiment_score":9.691,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9382,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9376,"joy":0.0186,"surprise":0.0135,"sadness":0.0039,"fear":0.0145,"anger":0.0072,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a robust and safe MARL framework (RSR-RSMARL) for autonomous vehicles with V2V communication. It demonstrates the ability to enhance driving safety and coordination across multiple configurations on 1/10th-scale autonomous vehicles. The framework uses Control Barrier Functions (CBFs) for safety guarantees and has been tested in both simulation and hardware, providing some evidence of deployment.","key_impact_metrics":["Driving safety enhancement","Coordination across multiple configurations"],"technology_tags":["Multi-Agent Reinforcement Learning","Autonomous Vehicles","V2V Communication","Control Barrier Functions"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:35:28.874270Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a0643416ee34","title":"HoMeR: Learning In-the","content":"arXiv:2506.01185v2 Announce Type: replace Abstract: We introduce HoMeR, an imitation learning framework for mobile manipulation that combines whole-body control with hybrid action modes that handle both long-range and fine-grained motion, enabling effective performance on realistic in-the-wild tasks. At its core is a fast, kinematics-based whole-body controller that maps desired end-effector poses to coordinated motion across the mobile base and arm. Within this reduced end-effector action space, HoMeR learns to switch between absolute pose predictions for long-range movement and relative pose predictions for fine-grained manipulation, offloading low-level coordination to the controller and focusing learning on task-level decisions. We deploy HoMeR on a holonomic mobile manipulator with a 7-DoF arm in a real home. We compare HoMeR to baselines without hybrid actions or whole-body control across 3 simulated and 3 real household tasks such as opening cabinets, sweeping trash, and rearranging pillows. Across tasks, HoMeR achieves an overall success rate of 79.17% using just 20 demonstrations per task, outperforming the next best baseline by 29.17 on average. HoMeR is also compatible with vision-language models and can leverage their internet-scale priors to better generalize to novel object appearances, layouts, and cluttered scenes. In summary, HoMeR moves beyond tabletop settings and demonstrates a scalable path toward sample-efficient, generalizable manipulation in everyday indoor spaces. Code, videos, and supplementary material are available at: http://homer-manip.github.io","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01185","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.198686","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Priya Sundaresan, Rhea Malhotra, Phillip Miao, Jingyun Yang, Jimmy Wu, Hengyuan Hu, Rika Antonova, Francis Engelmann, Dorsa Sadigh, Jeannette Bohg","raw_content_length":1602,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1601,"language_detected":"en","key_concepts":{"key_phrases":["HoMeR","arXiv250601185v2 Announce Type","Abstract","an imitation learning framework","mobile manipulation","whole-body control","hybrid action modes","both long-range and fine-grained motion","effective performance","realistic in-the-wild tasks"],"filter_categories":{"ai_ml":["both long-range and fine-grained motion"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HoMeR":3.0,"arXiv250601185v2 Announce Type":1.0,"Abstract":1.0,"an imitation learning framework":1.0,"mobile manipulation":1.0,"whole-body control":1.0,"hybrid action modes":1.0,"both long-range and fine-grained motion":1.0,"effective performance":1.0,"realistic in-the-wild tasks":1.0}},"age_hours":2.767287440833333,"is_recent":true,"quality_score":0.7,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8793,"joy":0.0299,"surprise":0.025,"sadness":0.0038,"fear":0.0345,"anger":0.0204,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed robotic system (HoMeR) tested in a real home environment, achieving a 79.17% success rate across several household tasks. While it doesn't directly address climate change, it could indirectly contribute by improving energy efficiency in homes through automation, but this is not explicitly quantified. The technical credibility is supported by the reported success rate and comparison to baselines.","key_impact_metrics":["Success rate of 79.17%","20 demonstrations per task"],"technology_tags":["Robotics","Imitation Learning","Mobile Manipulation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:35:45.412519Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_31af105b4b6b","title":"SysLLMatic: Large Language Models are Software System Optimizers","content":"arXiv:2506.01249v2 Announce Type: replace Abstract: Automatic software system optimization can improve software speed and save energy. Traditional approaches to optimization rely on manual tuning and compiler heuristics, limiting their ability to generalize across diverse codebases. Recent methods using LLMs introduce automation, but they do not scale effectively to the complexity and size of real-world software systems, leaving a gap in practical applicability. We present SysLLMatic, a system that integrates LLMs with performance diagnostics feedback and a curated catalog of 43 optimization patterns to automatically optimize software code. Our approach builds on recent advances in LLM-based code optimization and specifically targets the limitations of existing systems in handling real-world software applications. We evaluate it on three benchmark suites: HumanEval_CPP (competitive programming in C++), SciMark2 (scientific kernels in Java), and DaCapoBench (large-scale software systems in Java). Results show that SysLLMatic can improve software system performance, including latency, throughput, energy efficiency, memory usage, and CPU utilization. It consistently outperforms state-of-the-art LLM baselines on microbenchmarks. On large-scale application codes, to which prior LLM approaches have not scaled, it surpasses compiler optimizations, achieving average relative improvements of 1.5x in latency (vs. 1.01x for the compiler) and 1.76x in throughput (vs. 1.02x for the compiler). Our findings demonstrate that LLMs, guided by principled system thinking through the optimization pattern catalog and appropriate performance diagnostics, can serve as viable software system optimizers. We further identify limitations of our approach and the challenges involved in handling complex applications. This work provides a foundation for generating optimized code across various languages, benchmarks, and program sizes in a principled manner.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01249","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.199102","language":"en","tags":["cspf","preprints","research","csse","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":260,"author":"Huiyun Peng, Arjun Gupte, Ryan Hasler, Nicholas John Eliopoulos, Chien-Chou Ho, Rishi Mantri, Leo Deng, Konstantin L\\\"aufer, George K. Thiruvathukal, James C. Davis","raw_content_length":1960,"priority":7,"update_frequency":1,"reading_time_minutes":1.3,"robust_parsing_used":true,"entities":{"organizations":["LLM","HumanEval_CPP"],"persons":["Announce Type"],"locations":["C++"],"monetary":[]},"char_count":1959,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Software System Optimizers","arXiv250601249v2 Announce Type","Abstract","Automatic software system optimization","software speed","energy","Traditional approaches","optimization","manual tuning"],"filter_categories":{"ai_ml":["Large Language Models"],"hydrogen_energy":["energy"],"renewable_energy":["energy"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":2.0,"Software System Optimizers":2.0,"arXiv250601249v2 Announce Type":1.0,"Abstract":1.0,"Automatic software system optimization":1.0,"software speed":1.0,"energy":1.0,"Traditional approaches":1.0,"optimization":1.0,"manual tuning":1.0}},"age_hours":2.7673017533333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.4975,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6995,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.847,"joy":0.0062,"surprise":0.0798,"sadness":0.0322,"fear":0.0089,"anger":0.015,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"SysLLMatic improves software system performance, including energy efficiency, by automatically optimizing code. The research provides performance improvements on benchmark suites, including 1.5x latency improvement and 1.76x throughput improvement compared to compiler optimizations. This is applied research, not yet deployed in commercial systems.","key_impact_metrics":["1.5x improvement in latency","1.76x improvement in throughput"],"technology_tags":["LLM-based code optimization","Software system optimization"],"sdg_alignment":[7,9,13],"analyzed_at":"2025-10-29T12:36:01.102161Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_822f43c391b6","title":"Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine","content":"arXiv:2506.01339v2 Announce Type: replace Abstract: Machine unlearning offers a promising solution to privacy and safety concerns in large language models (LLMs) by selectively removing targeted knowledge while preserving utility. However, current methods are highly sensitive to downstream fine-tuning, which can quickly recover forgotten information-even from unrelated tasks. To address this, we introduce invariance into unlearning for the first time, inspired by invariant risk minimization (IRM). Building on this principle, we propose invariant LLM unlearning (ILU), a regularization-based framework that enhances robustness. Notably, ILU generalizes well to diverse fine-tuning tasks, even when trained using a single dataset. A task vector analysis is also provided to further elucidate the rationale behind ILU's effectiveness. Extensive experiments on the WMDP and MUSE benchmark, reveal that ILU significantly outperforms state-of-the-art unlearning methods, including negative preference optimization (NPO) and representation misdirection for unlearning (RMU). Notably, ILU achieves superior unlearning robustness across diverse downstream fine-tuning scenarios (e.g., math, paraphrase detection, and sentiment analysis) while preserving the fine-tuning performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01339","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.199491","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Changsheng Wang, Yihua Zhang, Jinghan Jia, Parikshit Ram, Dennis Wei, Yuguang Yao, Soumyadeep Pal, Nathalie Baracaldo, Sijia Liu","raw_content_length":1280,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["LLM","ILU","MUSE","WMDP"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1279,"language_detected":"en","key_concepts":{"key_phrases":["Invariance","LLM","Resilient","Unanticipated Downstream Fine","Announce Type","Abstract","Machine","a promising solution","privacy and safety concerns","large language models"],"filter_categories":{"ai_ml":["LLM","Machine","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Invariance":2.0,"LLM":2.0,"Resilient":2.0,"Unanticipated Downstream Fine":2.0,"Announce Type":1.0,"Abstract":1.0,"Machine":1.0,"a promising solution":1.0,"privacy and safety concerns":1.0,"large language models":1.0}},"age_hours":2.7673163727777776,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9408,"joy":0.0042,"surprise":0.0122,"sadness":0.0059,"fear":0.0158,"anger":0.0118,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (ILU) for improving the robustness of LLM unlearning against downstream fine-tuning. While the research shows promising results on benchmarks (WMDP and MUSE), it is still in the applied research phase with no real-world deployments. The potential climate impact is indirect, as it could improve the safety and reliability of LLMs used in climate modeling or other sustainability-related applications, but this is not explicitly quantified.","key_impact_metrics":["Superior unlearning robustness across diverse downstream fine-tuning scenarios","Preserving the fine-tuning performance"],"technology_tags":["LLM unlearning","Invariant Risk Minimization","Regularization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:36:04.554753Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_21242d6e1929","title":"Towards Unsupervised Training of Matching","content":"arXiv:2506.01977v2 Announce Type: replace Abstract: Graph Edit Distance (GED) is a fundamental graph similarity metric widely used in various applications. However, computing GED is an NP-hard problem. Recent state-of-the-art hybrid GED solver has shown promising performance by formulating GED as a bipartite graph matching problem, then leveraging a generative diffusion model to predict node matching between two graphs, from which both the GED and its corresponding edit path can be extracted using a traditional algorithm. However, such methods typically rely heavily on ground-truth supervision, where the ground-truth node matchings are often costly to obtain in real-world scenarios. In this paper, we propose GEDRanker, a novel unsupervised GAN-based framework for GED computation. Specifically, GEDRanker consists of a matching-based GED solver and introduces an interpretable preference-aware discriminator. By leveraging preference signals over different node matchings derived from edit path lengths, the discriminator can guide the matching-based solver toward generating high-quality node matching without the need for ground-truth supervision. Extensive experiments on benchmark datasets demonstrate that our GEDRanker enables the matching-based GED solver to achieve near-optimal solution quality without any ground-truth supervision.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01977","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.200661","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Wei Huang, Hanchen Wang, Dong Wen, Shaozhen Ma, Wenjie Zhang, Xuemin Lin","raw_content_length":1352,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["GEDRanker","GED","Graph Edit Distance","GAN"],"persons":[],"locations":[],"monetary":[]},"char_count":1351,"language_detected":"en","key_concepts":{"key_phrases":["GED","Unsupervised Training","Matching","arXiv250601977v2 Announce Type","Abstract","Graph Edit Distance","a fundamental graph similarity metric","various applications","an NP-hard problem","the-art"],"filter_categories":{"ai_ml":["Unsupervised Training"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GED":3.0,"Unsupervised Training":2.0,"Matching":2.0,"arXiv250601977v2 Announce Type":1.0,"Abstract":1.0,"Graph Edit Distance":1.0,"a fundamental graph similarity metric":1.0,"various applications":1.0,"an NP-hard problem":1.0,"the-art":1.0}},"age_hours":2.7673627069444446,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8598,"joy":0.0148,"surprise":0.026,"sadness":0.0275,"fear":0.0477,"anger":0.012,"disgust":0.0121},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel unsupervised GAN-based framework for Graph Edit Distance (GED) computation, which could potentially improve the efficiency of graph matching algorithms. While the research shows promising results on benchmark datasets, it is still in the early stages of development (basic research) and lacks real-world deployment or quantified climate impact. The technical credibility is supported by experiments on benchmark datasets.","key_impact_metrics":["near-optimal solution quality without any ground-truth supervision"],"technology_tags":["Graph Edit Distance","GAN","Unsupervised Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:36:24.326420Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dce2369bec56","title":"Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification","content":"arXiv:2506.03227v2 Announce Type: replace Abstract: A neural ordinary differential equation (neural ODE) is a machine learning model that is commonly described as a continuous-depth generalization of a residual network (ResNet) with a single residual block, or conversely, the ResNet can be seen as the Euler discretization of the neural ODE. These two models are therefore strongly related in a way that the behaviors of either model are considered to be an approximation of the behaviors of the other. In this work, we establish a more formal relationship between these two models by bounding the approximation error between two such related models. The obtained error bound then allows us to use one of the models as a verification proxy for the other, without running the verification tools twice: if the reachable output set expanded by the error bound satisfies a safety property on one of the models, this safety property is then guaranteed to be also satisfied on the other model. This feature is fully reversible, and the initial safety verification can be run indifferently on either of the two models. This novel approach is illustrated on a numerical example of a fixed-point attractor system modeled as a neural ODE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.03227","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.201419","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":199,"author":"Abdelrahman Sayed Sayed, Pierre-Jean Meyer, Mohamed Ghazel","raw_content_length":1230,"priority":7,"update_frequency":1,"reading_time_minutes":0.995,"robust_parsing_used":true,"entities":{"organizations":["ResNet","Bridging Neural ODE"],"persons":["Euler"],"locations":[],"monetary":[]},"char_count":1229,"language_detected":"en","key_concepts":{"key_phrases":["ResNet","Neural ODE","A Formal Error Bound","Safety Verification","the behaviors","arXiv250603227v2 Announce Type","Abstract","A neural ordinary differential equation","neural ODE","a machine learning model"],"filter_categories":{"ai_ml":["a machine learning model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ResNet":3.0,"Neural ODE":2.0,"A Formal Error Bound":2.0,"Safety Verification":2.0,"the behaviors":2.0,"arXiv250603227v2 Announce Type":1.0,"Abstract":1.0,"A neural ordinary differential equation":1.0,"neural ODE":1.0,"a machine learning model":1.0}},"age_hours":2.767393652777778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8612,"joy":0.0024,"surprise":0.0214,"sadness":0.0324,"fear":0.0306,"anger":0.0234,"disgust":0.0285},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical error bound between neural ODEs and ResNets, which could potentially improve the safety verification of machine learning models used in climate-related applications. However, it's currently at the basic research stage with no deployed technology or measured outcomes. The economic viability is unclear, as it's a theoretical advancement.","key_impact_metrics":[],"technology_tags":["neural networks","machine learning","safety verification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:36:30.066879Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_41241c9d73f8","title":"MoodAngels: A Retrieval","content":"arXiv:2506.03750v2 Announce Type: replace Abstract: The application of AI in psychiatric diagnosis faces significant challenges, including the subjective nature of mental health assessments, symptom overlap across disorders, and privacy constraints limiting data availability. To address these issues, we present MoodAngels, the first specialized multi-agent framework for mood disorder diagnosis. Our approach combines granular-scale analysis of clinical assessments with a structured verification process, enabling more accurate interpretation of complex psychiatric data. Complementing this framework, we introduce MoodSyn, an open-source dataset of 1,173 synthetic psychiatric cases that preserves clinical validity while ensuring patient privacy. Experimental results demonstrate that MoodAngels outperforms conventional methods, with our baseline agent achieving 12.3% higher accuracy than GPT-4o on real-world cases, and our full multi-agent system delivering further improvements. Evaluation in the MoodSyn dataset demonstrates exceptional fidelity, accurately reproducing both the core statistical patterns and complex relationships present in the original data while maintaining strong utility for machine learning applications. Together, these contributions provide both an advanced diagnostic tool and a critical research resource for computational psychiatry, bridging important gaps in AI-assisted mental health assessment.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.03750","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.201829","language":"en","tags":["computer-science","csai","preprints","research","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Mengxi Xiao, Ben Liu, He Li, Jimin Huang, Qianqian Xie, Xiaofen Zong, Mang Ye, Min Peng","raw_content_length":1438,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["A Retrieval arXiv:2506.03750v2 Announce Type: replace Abstract","MoodSyn","MoodAngels"],"persons":[],"locations":[],"monetary":[]},"char_count":1437,"language_detected":"en","key_concepts":{"key_phrases":["MoodAngels","A Retrieval","arXiv250603750v2 Announce Type","Abstract","The application","psychiatric diagnosis","significant challenges","the subjective nature","mental health assessments","disorders"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MoodAngels":3.0,"A Retrieval":2.0,"arXiv250603750v2 Announce Type":1.0,"Abstract":1.0,"The application":1.0,"psychiatric diagnosis":1.0,"significant challenges":1.0,"the subjective nature":1.0,"mental health assessments":1.0,"disorders":1.0}},"age_hours":2.7674075777777776,"is_recent":true,"quality_score":1.0,"sentiment_score":4.2345,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8336,"joy":0.0115,"surprise":0.0425,"sadness":0.0153,"fear":0.0807,"anger":0.0121,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":5,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI framework for mental health diagnosis, demonstrating a 12.3% accuracy improvement over GPT-4o on real-world cases. However, it is still in the early stages of development and deployment, lacking concrete evidence of widespread adoption or economic viability. The impact on climate change is indirect, potentially improving mental health outcomes, which could lead to more sustainable behaviors, but this is not directly addressed.","key_impact_metrics":["12.3% higher accuracy than GPT-4o"],"technology_tags":["AI","Mental Health Diagnosis","Multi-agent Framework"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:36:59.313714Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ecd5633cf9f8","title":"Understanding the Impact of Sampling Quality in Direct Preference Optimization","content":"arXiv:2506.04272v2 Announce Type: replace Abstract: We study how data of higher quality can be leveraged to improve performance in Direct Preference Optimization (DPO), aiming to understand its impact on DPO training dynamics. Our analyses show that both the solution space and the convergence behavior of DPO depend on the support and quality of the data-generating distribution. We first analyze how data and reference policy influence policy updates during gradient descent, and how a practical phenomenon known as likelihood displacement can interfere with the desired dynamics. We then design a simplified yet well-structured alignment model as a proxy that preserves most of the beneficial properties of RLHF while avoiding likelihood displacement. Based on this model, we develop quantitative results showing how more frequent high-quality responses amplify the gradient signal and improve the optimization landscape, leading to more effective policy learning. Our theoretical findings are supported by empirical experiments and provide a principled justification for the online DPO framework in practice.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04272","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.202209","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Kyung Rok Kim, Yumo Bai, Chonghuan Wang, Guanting Chen","raw_content_length":1113,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["Direct Preference Optimization","RLHF","the Impact of Sampling Quality","DPO"],"persons":[],"locations":[],"monetary":[]},"char_count":1112,"language_detected":"en","key_concepts":{"key_phrases":["Direct Preference Optimization","the Impact","Sampling Quality","DPO","arXiv250604272v2","Announce Type","Abstract","data","higher quality","performance"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Direct Preference Optimization":3.0,"the Impact":2.0,"Sampling Quality":2.0,"DPO":2.0,"arXiv250604272v2":1.0,"Announce Type":1.0,"Abstract":1.0,"data":1.0,"higher quality":1.0,"performance":1.0}},"age_hours":2.7674226766666665,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6085,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9217,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9044,"joy":0.0281,"surprise":0.0336,"sadness":0.0042,"fear":0.0068,"anger":0.015,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the efficiency of Direct Preference Optimization (DPO) through higher quality data. While the research aims to improve AI models, there are no concrete actions or deployments mentioned that directly translate to reduced GHG emissions or other sustainability benefits. The research is theoretical and in the early stages.","key_impact_metrics":["gradient signal amplification","optimization landscape improvement"],"technology_tags":["Direct Preference Optimization","Reinforcement Learning from Human Feedback","AI alignment"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:37:02.661465Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_60aa7ceeec76","title":"Agents of Change: Self","content":"arXiv:2506.04651v2 Announce Type: replace Abstract: We address the long-horizon gap in large language model (LLM) agents by enabling them to sustain coherent strategies in adversarial, stochastic environments. Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Prompt-centric LLM agents (e.g., ReAct, Reflexion) must re-interpret large, evolving game states each turn, quickly saturating context windows and losing strategic consistency. We propose HexMachina, a continual learning multi-agent system that separates environment discovery (inducing an adapter layer without documentation) from strategy improvement (evolving a compiled player through code refinement and simulation). This design preserves executable artifacts, allowing the LLM to focus on high-level strategy rather than per-turn reasoning. In controlled Catanatron experiments, HexMachina learns from scratch and evolves players that outperform the strongest human-crafted baseline (AlphaBeta), achieving a 54% win rate and surpassing prompt-driven and no-discovery baselines. Ablations confirm that isolating pure strategy learning improves performance. Overall, artifact-centric continual learning transforms LLMs from brittle stepwise deciders into stable strategy designers, advancing long-horizon autonomy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04651","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.202636","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Nikolas Belle, Dakota Barnes, Alfonso Amayuelas, Ivan Bercovich, Xin Eric Wang, William Wang","raw_content_length":1388,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["HexMachina","Catanatron","Catan","LLM","ReAct, Reflexion"],"persons":[],"locations":[],"monetary":[]},"char_count":1387,"language_detected":"en","key_concepts":{"key_phrases":["Agents","Change","Self","arXiv250604651v2 Announce Type","Abstract","the long-horizon gap","large language model LLM agents","them","coherent strategies","adversarial stochastic environments"],"filter_categories":{"ai_ml":["large language model LLM agents"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Agents":2.0,"Change":2.0,"Self":2.0,"arXiv250604651v2 Announce Type":1.0,"Abstract":1.0,"the long-horizon gap":1.0,"large language model LLM agents":1.0,"them":1.0,"coherent strategies":1.0,"adversarial stochastic environments":1.0}},"age_hours":2.767438455555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8954,"joy":0.0166,"surprise":0.0326,"sadness":0.0049,"fear":0.0336,"anger":0.0127,"disgust":0.0043},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI agent (HexMachina) that learns and improves strategies in a simulated environment (Settlers of Catan). While the AI demonstrates improved performance compared to baselines (54% win rate), there is no direct climate impact or deployment in a real-world sustainability context. The technology is currently in the applied research stage, with potential for future applications in optimizing resource allocation or energy management, but this is speculative.","key_impact_metrics":["Win rate 54%"],"technology_tags":["Artificial Intelligence","Machine Learning","Agent-based Modeling"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:37:19.918378Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f997a777b90f","title":"Superior Molecular Representations from Intermediate Encoder Layers","content":"arXiv:2506.06443v2 Announce Type: replace Abstract: Pretrained molecular encoders have become indispensable in computational chemistry for tasks such as property prediction and molecular generation. However, the standard practice of relying solely on final-layer embeddings for downstream tasks may discard valuable information. In this work, we first analyze the information flow in five diverse molecular encoders and find that intermediate layers retain more general-purpose features, whereas the final-layer specializes and compresses information. We then perform an empirical layer-wise evaluation across 22 property prediction tasks. We find that using frozen embeddings from optimal intermediate layers improves downstream performance by an average of 5.4%, up to 28.6%, compared to the final-layer. Furthermore, finetuning encoders truncated at intermediate depths achieves even greater average improvements of 8.5%, with increases as high as 40.8%, obtaining new state-of-the-art results on several benchmarks. These findings highlight the importance of exploring the full representational depth of molecular encoders to achieve substantial performance improvements and computational efficiency. The code will be made publicly available.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.06443","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.203031","language":"en","tags":["cslg","csai","q-biobm","preprints","physicschem-ph","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Luis Pinto","raw_content_length":1247,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1246,"language_detected":"en","key_concepts":{"key_phrases":["Superior Molecular Representations","Intermediate Encoder Layers","Announce Type","Abstract","Pretrained molecular encoders","computational chemistry","tasks","property prediction","molecular generation","the standard practice"],"filter_categories":{"ai_ml":["Pretrained molecular encoders"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Superior Molecular Representations":2.0,"Intermediate Encoder Layers":2.0,"Announce Type":1.0,"Abstract":1.0,"Pretrained molecular encoders":1.0,"computational chemistry":1.0,"tasks":1.0,"property prediction":1.0,"molecular generation":1.0,"the standard practice":1.0}},"age_hours":2.7674524983333333,"is_recent":true,"quality_score":0.7,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8262,"joy":0.0074,"surprise":0.0153,"sadness":0.01,"fear":0.0393,"anger":0.0476,"disgust":0.0542},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of molecular encoders, which could indirectly contribute to sustainability by accelerating the discovery of new materials for clean energy technologies. The article presents empirical results showing performance improvements in property prediction tasks, but it's still in the research phase with no deployed applications yet. The vaporware flag is raised because it is an early-stage concept.","key_impact_metrics":["5.4% improvement in downstream performance","8.5% average improvements with finetuning"],"technology_tags":["molecular encoders","machine learning","computational chemistry"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T12:37:23.508051Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53c0c931c739","title":"Boosting Adversarial Transferability via Commonality","content":"arXiv:2506.06992v2 Announce Type: replace Abstract: Exploring effective and transferable adversarial examples is vital for understanding the characteristics and mechanisms of Vision Transformers (ViTs). However, adversarial examples generated from surrogate models often exhibit weak transferability in black-box settings due to overfitting. Existing methods improve transferability by diversifying perturbation inputs or applying uniform gradient regularization within surrogate models, yet they have not fully leveraged the shared and unique features of surrogate models trained on the same task, leading to suboptimal transfer performance. Therefore, enhancing perturbations of common information shared by surrogate models and suppressing those tied to individual characteristics offers an effective way to improve transferability. Accordingly, we propose a commonality-oriented gradient optimization strategy (COGO) consisting of two components: Commonality Enhancement (CE) and Individuality Suppression (IS). CE perturbs the mid-to-low frequency regions, leveraging the fact that ViTs trained on the same dataset tend to rely more on mid-to-low frequency information for classification. IS employs adaptive thresholds to evaluate the correlation between backpropagated gradients and model individuality, assigning weights to gradients accordingly. Extensive experiments demonstrate that COGO significantly improves the transfer success rates of adversarial attacks, outperforming current state-of-the-art methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.06992","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.203577","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Yanting Gao, Yepeng Liu, Junming Liu, Qi Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao","raw_content_length":1521,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Commonality arXiv:2506.06992v2","Vision Transformers"],"persons":[],"locations":[],"monetary":[]},"char_count":1520,"language_detected":"en","key_concepts":{"key_phrases":["Adversarial Transferability","Commonality","surrogate models","Announce Type","Abstract","effective and transferable adversarial examples","the characteristics","mechanisms","Vision Transformers","ViTs"],"filter_categories":{"ai_ml":["Vision Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adversarial Transferability":2.0,"Commonality":2.0,"surrogate models":2.0,"Announce Type":1.0,"Abstract":1.0,"effective and transferable adversarial examples":1.0,"the characteristics":1.0,"mechanisms":1.0,"Vision Transformers":1.0,"ViTs":1.0}},"age_hours":2.7674656725,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9349,"joy":0.0177,"surprise":0.016,"sadness":0.0063,"fear":0.0041,"anger":0.0098,"disgust":0.0112},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (COGO) to improve the transferability of adversarial attacks on Vision Transformers (ViTs). While the research demonstrates improved transfer success rates in experiments, it remains in the early stages of research with no deployed applications or quantified environmental benefits. The impact is theoretical at this stage.","key_impact_metrics":["Transfer success rates","Outperforming current state-of-the-art methods"],"technology_tags":["Adversarial attacks","Vision Transformers","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:37:28.428934Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4b12cebce0ef","title":"Monotone and Conservative Policy Iteration Beyond the Tabular Case","content":"arXiv:2506.07134v2 Announce Type: replace Abstract: We introduce Reliable Policy Iteration (RPI) and Conservative RPI (CRPI), variants of Policy Iteration (PI) and Conservative PI (CPI), that retain tabular guarantees under function approximation. RPI uses a novel Bellman-constrained optimization for policy evaluation. We show that RPI restores the textbook \\textit{monotonicity} of value estimates and that these estimates provably \\textit{lower-bound} the true return; moreover, their limit partially satisfies the \\textit{unprojected} Bellman equation. CRPI shares RPI's evaluation, but updates policies conservatively by maximizing a new performance-difference \\textit{lower bound} that explicitly accounts for function-approximation-induced errors. CRPI inherits RPI's guarantees and, crucially, admits per-step improvement bounds. In initial simulations, RPI and CRPI outperform PI and its variants. Our work addresses a foundational gap in RL: popular algorithms such as TRPO and PPO derive from tabular CPI yet are deployed with function approximation, where CPI's guarantees often fail-leading to divergence, oscillations, or convergence to suboptimal policies. By restoring PI/CPI-style guarantees for \\textit{arbitrary} function classes, RPI and CRPI provide a principled basis for next-generation RL.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.07134","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.203980","language":"en","tags":["computer-science","cslg","csai","preprints","mathoc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"S. R. Eshwar, Gugan Thoppe, Ananyabrata Barua, Aditya Gopalan, Gal Dalal","raw_content_length":1315,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["Conservative PI","Bellman","Policy Iteration (PI","RPI","the \\textit{unprojected} Bellman","CRPI","Conservative RPI"],"persons":[],"locations":[],"monetary":[]},"char_count":1314,"language_detected":"en","key_concepts":{"key_phrases":["RPI","Monotone","Conservative Policy Iteration","the Tabular Case","arXiv250607134v2 Announce Type","Abstract","CRPI","Policy Iteration","Conservative PI","CPI"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"RPI":3.0,"Monotone":2.0,"Conservative Policy Iteration":2.0,"the Tabular Case":2.0,"arXiv250607134v2 Announce Type":1.0,"Abstract":1.0,"CRPI":1.0,"Policy Iteration":1.0,"Conservative PI":1.0,"CPI":1.0}},"age_hours":2.767480868333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.088000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8176,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8408,"joy":0.0749,"surprise":0.0664,"sadness":0.005,"fear":0.0027,"anger":0.0077,"disgust":0.0025},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces new reinforcement learning algorithms (RPI and CRPI) that improve the stability and performance of policy iteration with function approximation. While the algorithms show promise in simulations, there is no evidence of real-world deployment or quantified impact on GHG emissions. The algorithms are still in the applied research stage.","key_impact_metrics":["performance-difference lower bound","monotonicity of value estimates"],"technology_tags":["reinforcement learning","policy iteration","function approximation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:37:40.655585Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce5de5f0a23f","title":"Safety-Aligned Weights Are Not Enough: Refusal","content":"arXiv:2506.07356v2 Announce Type: replace Abstract: Recently, major AI providers such as Google and OpenAI have introduced Finetuning-as-a-Service (FaaS), which allows users to customize Large Language Models (LLMs) using their own data. However, this service is vulnerable to safety degradation when user data includes harmful prompts, a threat known as harmful finetuning attacks. Prior works attempt to mitigate this issue by first constructing safety-aligned model and then finetuning the model on user data. However, we observe that the safety-aligned weights provide weak initialization for downstream task learning, leading to suboptimal safety-alignment and downstream task performance. To address this, we propose a Refusal-Teacher (Ref-Teacher)-guided finetuning framework. Instead of finetuning a safety-aligned model on user data, our approach directly finetunes the base model under the guidance of a safety-aligned Ref-Teacher, which filters harmful prompts from user data and distills safety-alignment knowledge into the base model. Extensive experiments demonstrate that our Ref-Teacher-guided finetuning strategy effectively minimizes harmful outputs and enhances finetuning accuracy for user-specific tasks, offering a practical solution for secure and reliable deployment of LLMs in FaaS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.07356","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.204362","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":174,"author":"Seokil Ham, Yubin Choi, Yujin Yang, Seungju Cho, Younghun Kim, Changick Kim","raw_content_length":1308,"priority":7,"update_frequency":1,"reading_time_minutes":0.87,"robust_parsing_used":true,"entities":{"organizations":["Ref-Teacher","OpenAI","Google"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1307,"language_detected":"en","key_concepts":{"key_phrases":["Safety-Aligned Weights","Refusal","Announce Type","Abstract","major AI providers","Google","OpenAI","Finetuning","a-Service","FaaS"],"filter_categories":{"ai_ml":["major AI providers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Safety-Aligned Weights":2.0,"Refusal":2.0,"Announce Type":1.0,"Abstract":1.0,"major AI providers":1.0,"Google":1.0,"OpenAI":1.0,"Finetuning":1.0,"a-Service":1.0,"FaaS":1.0}},"age_hours":2.767497083611111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.842,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8316,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6422,"joy":0.0044,"surprise":0.0107,"sadness":0.0516,"fear":0.1831,"anger":0.0569,"disgust":0.0512},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to improving the safety and reliability of LLMs in FaaS. The concrete action is the development of a Refusal-Teacher-guided finetuning framework. The evidence supporting the claims comes from 'extensive experiments' which demonstrate minimization of harmful outputs and enhanced finetuning accuracy, but there is no mention of real-world deployment, placing it at the applied research stage.","key_impact_metrics":["Minimizes harmful outputs","Enhances finetuning accuracy"],"technology_tags":["Large Language Models","Finetuning-as-a-Service"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T12:37:53.252549Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d78e4cf74cad","title":"From Static to Adaptive Defense: Federated Multi","content":"arXiv:2506.07392v3 Announce Type: replace Abstract: The proliferation of UAVs has enabled a wide range of mission-critical applications and is becoming a cornerstone of low-altitude networks, supporting smart cities, emergency response, and more. However, the open wireless environment, dynamic topology, and resource constraints of UAVs expose low-altitude networks to severe DoS threats. Traditional defense approaches, which rely on fixed configurations or centralized decision-making, cannot effectively respond to the rapidly changing conditions in UAV swarm environments. To address these challenges, we propose a novel federated multi-agent deep reinforcement learning (FMADRL)-driven moving target defense (MTD) framework for proactive DoS mitigation in low-altitude networks. Specifically, we design lightweight and coordinated MTD mechanisms, including leader switching, route mutation, and frequency hopping, to disrupt attacker efforts and enhance network resilience. The defense problem is formulated as a multi-agent partially observable Markov decision process, capturing the uncertain nature of UAV swarms under attack. Each UAV is equipped with a policy agent that autonomously selects MTD actions based on partial observations and local experiences. By employing a policy gradient-based algorithm, UAVs collaboratively optimize their policies via reward-weighted aggregation. Extensive simulations demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving up to a 34.6% improvement in attack mitigation rate, a reduction in average recovery time of up to 94.6%, and decreases in energy consumption and defense cost by as much as 29.3% and 98.3%, respectively, under various DoS attack strategies. These results highlight the potential of intelligent, distributed defense mechanisms to protect low-altitude networks, paving the way for reliable and scalable low-altitude economy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.07392","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.204801","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Tian Qin, Yuyu Zhao","raw_content_length":1933,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["UAVs","UAV","DoS"],"persons":[],"locations":[],"monetary":[]},"char_count":1932,"language_detected":"en","key_concepts":{"key_phrases":["Static","Adaptive Defense","UAVs","low-altitude networks","arXiv250607392v3","Announce Type","Abstract","The proliferation","a wide range","mission-critical applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Static":2.0,"Adaptive Defense":2.0,"UAVs":2.0,"low-altitude networks":2.0,"arXiv250607392v3":1.0,"Announce Type":1.0,"Abstract":1.0,"The proliferation":1.0,"a wide range":1.0,"mission-critical applications":1.0}},"age_hours":2.767512215833333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5669,"joy":0.0083,"surprise":0.0276,"sadness":0.0202,"fear":0.3183,"anger":0.0498,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a federated multi-agent deep reinforcement learning framework for proactive DoS mitigation in low-altitude networks. The concrete action is the design of lightweight and coordinated MTD mechanisms. Evidence is provided through extensive simulations, showing improvements in attack mitigation rate, recovery time, energy consumption, and defense cost. However, this is still in the simulation stage, limiting deployment readiness.","key_impact_metrics":["34.6% improvement in attack mitigation rate","94.6% reduction in average recovery time"],"technology_tags":["Federated Multi-Agent Deep Reinforcement Learning","Moving Target Defense"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:38:00.043720Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_af3d7dcd1fc9","title":"LLM-as-a","content":"arXiv:2506.09147v3 Announce Type: replace Abstract: Prompting large language models (LLMs) to evaluate generated text, known as LLM-as-a-judge, has become a standard evaluation approach in natural language generation (NLG), but is primarily used as a quantitative tool, i.e. with numerical scores as main outputs. In this work, we propose LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main output being a structured report of common issue types in the NLG system outputs. Our approach is targeted at providing developers with meaningful insights on what improvements can be done to a given NLG system and consists of two main steps, namely open-ended per-instance issue analysis and clustering of the discovered issues using an intuitive cumulative algorithm. We also introduce a strategy for evaluating the proposed approach, coupled with ~300 annotations of issues in instances from 12 NLG datasets. Our results show that instance-specific issues output by LLM-as-a-qualitative-judge match those annotated by humans in 2/3 cases, and that LLM-as-a-qualitative-judge is capable of producing error type reports resembling the reports composed by human annotators. We also demonstrate in a case study how the use of LLM-as-a-qualitative-judge can substantially improve NLG systems performance. Our code and data are publicly available at https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.09147","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.205940","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Nadezhda Chirkova, Tunde Oluwaseyi Ajayi, Seth Aycock, Zain Muhammad Mujahid, Vladana Perli\\'c, Ekaterina Borisova, Markarit Vartampetian","raw_content_length":1420,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1419,"language_detected":"en","key_concepts":{"key_phrases":["LLM","arXiv250609147v3","Announce Type","Abstract","large language models","LLMs","generated text","a-judge","a standard evaluation approach","natural language generation"],"filter_categories":{"ai_ml":["LLM","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLM":2.0,"arXiv250609147v3":1.0,"Announce Type":1.0,"Abstract":1.0,"large language models":1.0,"LLMs":1.0,"generated text":1.0,"a-judge":1.0,"a standard evaluation approach":1.0,"natural language generation":1.0}},"age_hours":2.7675567416666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.9505,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1901,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8949,"joy":0.0359,"surprise":0.0253,"sadness":0.0069,"fear":0.0099,"anger":0.0197,"disgust":0.0074},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method for evaluating NLG systems using LLMs, focusing on qualitative analysis of errors. While it shows promise in improving NLG performance, it's currently in the applied research stage with no deployed technology or measured climate outcomes. The impact on sustainability is indirect and theoretical at this point.","key_impact_metrics":["Issue match rate with humans: 2/3"],"technology_tags":["Large Language Models","Natural Language Generation","AI Evaluation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:38:03.426244Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e465b9eabcae","title":"Revisit What You See: Disclose Language Prior in Vision Tokens for LVLM Decoding","content":"arXiv:2506.09522v2 Announce Type: replace Abstract: Large Vision-Language Models (LVLMs) achieve strong performance across multimodal tasks by integrating visual perception with language understanding. However, how vision information contributes to the model's decoding process remains under-explored, as reflected in frequent hallucinations. Through a series of analyses, we found that (i) vision tokens provide meaningful visual information even when hallucinations occur, and (ii) their semantics are encoded in the textual space and become explicit under appropriate vocabulary constraints. Building on these observations, we propose ReVisiT, a simple training-free decoding method that references vision tokens to guide text generation. Our approach leverages the semantic information embedded within vision tokens by projecting them into the text token distribution. Specifically, ReVisiT dynamically selects the most relevant vision token at each decoding step via context-aware constrained divergence minimization, and using its constrained projection to refine the output distribution to better incorporate visual semantics. Across five benchmarks on recent LVLMs, ReVisiT consistently enhances visual grounding with minimal computational overhead, and achieves competitive or superior results to state-of-the-art decoding baselines while reducing computational cost by up to $2\\times$.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.09522","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.206333","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Beomsik Cho, Jaehyung Kim","raw_content_length":1396,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["ReVisiT"],"locations":[],"monetary":[]},"char_count":1395,"language_detected":"en","key_concepts":{"key_phrases":["What","You","Vision Tokens","arXiv250609522v2 Announce Type","Large Vision-Language Models","LVLMs","strong performance","multimodal tasks","visual perception","language understanding"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"You":2.0,"Vision Tokens":2.0,"arXiv250609522v2 Announce Type":1.0,"Large Vision-Language Models":1.0,"LVLMs":1.0,"strong performance":1.0,"multimodal tasks":1.0,"visual perception":1.0,"language understanding":1.0}},"age_hours":2.7675713644444446,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8625,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8614,"joy":0.0083,"surprise":0.0801,"sadness":0.0118,"fear":0.0092,"anger":0.0135,"disgust":0.0156},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new method (ReVisiT) for improving the visual grounding of Large Vision-Language Models (LVLMs). The concrete action is a training-free decoding method that refines the output distribution using vision tokens. The evidence supporting the claims comes from benchmarks on recent LVLMs, showing enhanced visual grounding and reduced computational cost by up to 2x. The innovation stage is basic research, as it is a proposed method evaluated on benchmarks.","key_impact_metrics":["computational cost reduction by up to 2x"],"technology_tags":["Large Vision-Language Models","Visual Grounding","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:38:11.122296Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d357d8264e2f","title":"Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning","content":"arXiv:2506.09674v2 Announce Type: replace Abstract: Federated Learning (FL) enables the training of machine learning models across decentralized clients while preserving data privacy. However, the presence of anomalous or corrupted clients - such as those with faulty sensors or non representative data distributions - can significantly degrade model performance. Detecting such clients without accessing raw data remains a key challenge. We propose WAFFLE (Wavelet and Fourier representations for Federated Learning) a detection algorithm that labels malicious clients {\\it before training}, using locally computed compressed representations derived from either the Wavelet Scattering Transform (WST) or the Fourier Transform. Both approaches provide low-dimensional, task-agnostic embeddings suitable for unsupervised client separation. A lightweight detector, trained on a distillated public dataset, performs the labeling with minimal communication and computational overhead. While both transforms enable effective detection, WST offers theoretical advantages, such as non-invertibility and stability to local deformations, that make it particularly well-suited to federated scenarios. Experiments on benchmark datasets show that our method improves detection accuracy and downstream classification performance compared to existing FL anomaly detection algorithms, validating its effectiveness as a pre-training alternative to online detection strategies.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.09674","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.206742","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Alessandro Licciardi, Davide Leo, Davide Carbone","raw_content_length":1461,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["the Fourier Transform","WAFFLE","the Wavelet Scattering Transform","Federated Learning","Fourier Representation for Offline Detection of Malicious Clients"],"persons":["Fourier"],"locations":[],"monetary":[]},"char_count":1460,"language_detected":"en","key_concepts":{"key_phrases":["Federated Learning","Wavelet Scattering Transform","Fourier Representation","Offline Detection","Malicious Clients","arXiv250609674v2","Announce Type","Abstract","the training","machine learning models"],"filter_categories":{"ai_ml":["the training","machine learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Federated Learning":3.0,"Wavelet Scattering Transform":2.0,"Fourier Representation":2.0,"Offline Detection":2.0,"Malicious Clients":2.0,"arXiv250609674v2":1.0,"Announce Type":1.0,"Abstract":1.0,"the training":1.0,"machine learning models":1.0}},"age_hours":2.767585618611111,"is_recent":true,"quality_score":1.0,"sentiment_score":1.5460000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6908,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2745,"joy":0.0041,"surprise":0.0107,"sadness":0.0322,"fear":0.45,"anger":0.1116,"disgust":0.1168},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new algorithm (WAFFLE) for detecting malicious clients in federated learning, which could improve the reliability of machine learning models trained on decentralized data. While the algorithm shows promise in benchmark datasets, it is still in the early stages of development and lacks real-world deployment data. The impact on climate is indirect, as it improves the integrity of data used for climate-related models, but there are no concrete actions or measurable outcomes yet.","key_impact_metrics":["detection accuracy","downstream classification performance"],"technology_tags":["federated learning","anomaly detection","wavelet scattering transform","fourier transform"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:38:14.941106Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4d75147ed1a5","title":"VITA: Zero-Shot Value Functions via Test","content":"arXiv:2506.10085v3 Announce Type: replace Abstract: Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.10085","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.207132","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Christos Ziakas, Alessandra Russo","raw_content_length":1354,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["Zero-Shot Value Functions","VITA","Vision-Language Models"],"persons":[],"locations":["enviro"],"monetary":[]},"char_count":1353,"language_detected":"en","key_concepts":{"key_phrases":["VITA","Zero-Shot Value Functions","Test","arXiv250610085v3 Announce Type","Abstract","Vision-Language Models","VLMs","show promise","zero-shot goal-conditioned value functions","their frozen pre-trained representations"],"filter_categories":{"ai_ml":["their frozen pre-trained representations"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VITA":3.0,"Zero-Shot Value Functions":2.0,"Test":2.0,"arXiv250610085v3 Announce Type":1.0,"Abstract":1.0,"Vision-Language Models":1.0,"VLMs":1.0,"show promise":1.0,"zero-shot goal-conditioned value functions":1.0,"their frozen pre-trained representations":1.0}},"age_hours":2.767601710277778,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8658,"joy":0.0055,"surprise":0.033,"sadness":0.0388,"fear":0.0101,"anger":0.0246,"disgust":0.0222},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (VITA) for improving zero-shot value function learning in robotic manipulation. While it demonstrates improved performance in simulation and real-world robotic tasks, it's still in the early stages of development and lacks concrete deployment or economic viability data. The impact on climate is indirect, potentially enabling more efficient robotic automation in various sectors.","key_impact_metrics":["Outperforming state-of-the-art zero-shot method","Exceeding performance of simulation's fuzzy-logic dense rewards"],"technology_tags":["Vision-Language Models","Robotic Manipulation","Reinforcement Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:38:27.736538Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eabfb9d5b4fa","title":"Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity","content":"arXiv:2506.11035v2 Announce Type: replace Abstract: Work in psychology has highlighted that the geometric model of similarity standard in deep learning is not psychologically plausible because its metric properties such as symmetry do not align with human perception of similarity. In contrast, Tversky (1977) proposed an axiomatic theory of similarity with psychological plausibility based on a representation of objects as sets of features, and their similarity as a function of their common and distinctive features. This model of similarity has not been used in deep learning before, in part because of the challenge of incorporating discrete set operations. In this paper, we develop a differentiable parameterization of Tversky's similarity that is learnable through gradient descent, and derive basic neural network building blocks such as the Tversky projection layer, which unlike the linear projection layer can model non-linear functions such as XOR. Through experiments with image recognition and language modeling neural networks, we show that the Tversky projection layer is a beneficial replacement for the linear projection layer. For instance, on the NABirds image classification task, a frozen ResNet-50 adapted with a Tversky projection layer achieves a 24.7% relative accuracy improvement over the linear layer adapter baseline. With Tversky projection layers, GPT-2's perplexity on PTB decreases by 7.8%, and its parameter count by 34.8%. Finally, we propose a unified interpretation of both types of projection layers as computing similarities of input stimuli to learned prototypes for which we also propose a novel visualization technique highlighting the interpretability of Tversky projection layers. Our work offers a new paradigm for thinking about the similarity model implicit in modern deep learning, and designing neural networks that are interpretable under an established theory of psychological similarity.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11035","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.207573","language":"en","tags":["cslg","csai","preprints","cscv","research","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":280,"author":"Moussa Koulako Bala Doumbouya, Dan Jurafsky, Christopher D. Manning","raw_content_length":1942,"priority":7,"update_frequency":1,"reading_time_minutes":1.4,"robust_parsing_used":true,"entities":{"organizations":["Tversky Neural Networks: Psychologically Plausible Deep Learning"],"persons":["Tversky"],"locations":[],"monetary":[]},"char_count":1941,"language_detected":"en","key_concepts":{"key_phrases":["Tversky Neural Networks","Psychologically Plausible Deep Learning","Differentiable Tversky Similarity","similarity","arXiv250611035v2 Announce Type","Abstract","Work","psychology","the geometric model","similarity standard"],"filter_categories":{"ai_ml":["Tversky Neural Networks","Psychologically Plausible Deep Learning","Work"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tversky Neural Networks":2.0,"Psychologically Plausible Deep Learning":2.0,"Differentiable Tversky Similarity":2.0,"similarity":2.0,"arXiv250611035v2 Announce Type":1.0,"Abstract":1.0,"Work":1.0,"psychology":1.0,"the geometric model":1.0,"similarity standard":1.0}},"age_hours":2.7676161274999997,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7433,"joy":0.0393,"surprise":0.0949,"sadness":0.0234,"fear":0.0524,"anger":0.0249,"disgust":0.0218},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel neural network architecture with improved performance on image recognition and language modeling tasks. The concrete action is the development and testing of a new type of projection layer. The evidence supporting claims is the reported accuracy improvement on NABirds and perplexity decrease on PTB. This is currently in the applied research stage, with no deployments mentioned.","key_impact_metrics":["24.7% relative accuracy improvement on NABirds","7.8% perplexity decrease on PTB"],"technology_tags":["Neural Networks","Deep Learning","Image Recognition","Language Modeling"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:38:45.633042Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_49274d44a738","title":"Capsule: Efficient Player Isolation for Datacenters","content":"arXiv:2506.11483v2 Announce Type: replace Abstract: Cloud gaming is increasingly popular. A challenge for cloud provider is to keep datacenter utilization high: a non-trivial task due to application variety. These applications come in different shapes and sizes. So do cloud datacenter resources, e.g., CPUs, GPUs, NPUs. Part of the challenge stems from game engines being predominantly designed to run only one player. For example, one player in a lightweight game might utilize only a fraction of the cloud server GPU. The remaining GPU capacity will be left underutilized, an undesired outcome for the cloud provider. We introduce Capsule, a mechanism to seamlessly share one GPU, and other cloud servers resources, across multiple players. Sharing makes the cost of multiple players sublinear. We implemented Capsule in O3DE, a popular open source game engine. Our evaluations show that Capsule increases datacenter resource utilization by accommodating up to 2.25x more players, without degrading player gaming experience. This is the product of Capsule using up to 1.43x less GPU, 3.11x less VRAM, 3.7x less CPU, and 3.87x less RAM compared to the baseline. Capsule is also application agnostic. We ran four applications on Capsule-based O3DE with no application changes. Our experiences with four applications, three servers with different hardware specifications, including the one with four GPUs, and multi-server cluster show that Capsule design can be adopted by other game engines to increase datacenter utilization across cloud providers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11483","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.207976","language":"en","tags":["computer-science","preprints","csdc","csgr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Zhouheng Du, Nima Davari, Li Li, Wei Sen Loi, Nodir Kodirov","raw_content_length":1554,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["GPU"],"persons":["Capsule","GPU"],"locations":[],"monetary":[]},"char_count":1551,"language_detected":"en","key_concepts":{"key_phrases":["Capsule","Efficient Player Isolation","Datacenters","arXiv250611483v2","Announce Type","Abstract","Cloud gaming","A challenge","cloud provider","datacenter utilization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Capsule":2.0,"Efficient Player Isolation":2.0,"Datacenters":2.0,"arXiv250611483v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Cloud gaming":1.0,"A challenge":1.0,"cloud provider":1.0,"datacenter utilization":1.0}},"age_hours":2.7676324105555556,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9192,"joy":0.0109,"surprise":0.0449,"sadness":0.0048,"fear":0.0046,"anger":0.0101,"disgust":0.0055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a mechanism (Capsule) to increase datacenter resource utilization by sharing resources across multiple players in cloud gaming. The evidence supporting this claim includes evaluations showing increased resource utilization (e.g., up to 2.25x more players) and reduced resource consumption (e.g., up to 1.43x less GPU). The innovation stage is applied research, as it has been implemented in a game engine and tested, but not yet commercially deployed.","key_impact_metrics":["2.25x more players","1.43x less GPU"],"technology_tags":["GPU virtualization","datacenter efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:38:54.608623Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4769bf1462d1","title":"Wide-Horizon Thinking and Simulation","content":"arXiv:2506.12421v2 Announce Type: replace Abstract: Unlike reasoning, which often entails a deep sequence of deductive steps, complex real-world planning is characterized by the need to synthesize a broad spectrum of parallel and potentially conflicting information and constraints. For example, in travel planning scenarios, it requires the integration of diverse real-world information and user preferences. While LLMs show promise, existing methods with long-horizon thinking struggle with handling multifaceted constraints, leading to suboptimal solutions. Motivated by the challenges of real-world travel planning, this paper introduces the Multiple Aspects of Planning (MAoP), empowering LLMs with \"wide-horizon thinking\" to solve planning problems with multifaceted constraints. Instead of direct planning, MAoP leverages the strategist to conduct pre-planning from various aspects and provide the planning blueprint for planners, enabling strong inference-time scalability by scaling aspects to consider various constraints. In addition, existing benchmarks for multi-constraint planning are flawed because they assess constraints in isolation, ignoring causal dependencies within the constraints, e.g, travel planning, where past activities dictate future itinerary. To address this, we propose Travel-Sim, an agent-based benchmark assessing plans via real-world simulation, thereby inherently resolving these causal dependencies. This paper advances LLM capabilities in complex planning and offers novel insights for evaluating sophisticated scenarios through simulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12421","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.208756","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Dongjie Yang, Chengqiang Lu, Qimeng Wang, Xinbei Ma, Yan Gao, Yao Hu, Hai Zhao","raw_content_length":1582,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["MAoP","Wide-Horizon Thinking and Simulation arXiv:2506.12421v2","the Multiple Aspects of Planning"],"persons":[],"locations":[],"monetary":[]},"char_count":1581,"language_detected":"en","key_concepts":{"key_phrases":["Wide-Horizon Thinking","Simulation","arXiv250612421v2","Announce Type","Abstract","reasoning","which","a deep sequence","deductive steps","complex real-world planning"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Wide-Horizon Thinking":2.0,"Simulation":2.0,"arXiv250612421v2":1.0,"Announce Type":1.0,"Abstract":1.0,"reasoning":1.0,"which":1.0,"a deep sequence":1.0,"deductive steps":1.0,"complex real-world planning":1.0}},"age_hours":2.7676616291666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9409,"joy":0.005,"surprise":0.0258,"sadness":0.005,"fear":0.0123,"anger":0.0062,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article introduces a new method (MAoP) for LLMs to improve planning with multifaceted constraints, specifically in travel planning. It also proposes a new benchmark (Travel-Sim) for assessing plans via real-world simulation. While promising, it's still in the applied research stage with no concrete deployment or measured outcomes yet, hence the lower scores for impact and readiness.","key_impact_metrics":[],"technology_tags":["Large Language Models","Travel Planning","Agent-Based Simulation"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T12:39:00.334194Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4bce43bf5384","title":"Reasoning Model Unlearning: Forgetting Traces, Not Just Answers, While Preserving Reasoning Skills","content":"arXiv:2506.12963v2 Announce Type: replace Abstract: Recent advances in large reasoning models (LRMs) have enabled strong chain-of-thought (CoT) generation through test-time computation. While these multi-step reasoning capabilities represent a major milestone in language model performance, they also introduce new safety risks. In this work, we present the first systematic study to revisit the problem of machine unlearning in the context of LRMs. Machine unlearning refers to the process of removing the influence of sensitive, harmful, or undesired data or knowledge from a trained model without full retraining. We show that conventional unlearning algorithms, originally designed for non-reasoning models, are inadequate for LRMs. In particular, even when final answers are successfully erased, sensitive information often persists within the intermediate reasoning steps, i.e., CoT trajectories. To address this challenge, we extend conventional unlearning and propose Reasoning-aware Representation Misdirection for Unlearning ($R^2MU$), a novel method that effectively suppresses sensitive reasoning traces and prevents the generation of associated final answers, while preserving the model's reasoning ability. Our experiments demonstrate that $R^2MU$ significantly reduces sensitive information leakage within reasoning traces and achieves strong performance across both safety and reasoning benchmarks, evaluated on state-of-the-art models such as DeepSeek-R1-Distill-LLaMA-8B and DeepSeek-R1-Distill-Qwen-14B.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12963","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.209905","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Changsheng Wang, Chongyu Fan, Yihua Zhang, Jinghan Jia, Dennis Wei, Parikshit Ram, Nathalie Baracaldo, Sijia Liu","raw_content_length":1523,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["CoT"],"persons":[],"locations":["LRMs"],"monetary":[]},"char_count":1522,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning Model Unlearning","Forgetting Traces","Not Just Answers","LRMs","arXiv250612963v2 Announce Type","Abstract","Recent advances","large reasoning models","thought","test-time computation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning Model Unlearning":2.0,"Forgetting Traces":2.0,"Not Just Answers":2.0,"LRMs":2.0,"arXiv250612963v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"large reasoning models":1.0,"thought":1.0,"test-time computation":1.0}},"age_hours":2.7677040919444447,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5776,"joy":0.0176,"surprise":0.0262,"sadness":0.0116,"fear":0.3392,"anger":0.0185,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel method for unlearning sensitive information in large reasoning models. While the research shows promise in mitigating safety risks associated with these models, it is still in the applied research stage with no concrete deployment or measurable climate impact. The article focuses on improving the safety and reliability of AI systems, which could indirectly support sustainability efforts by preventing misuse or bias in climate-related applications.","key_impact_metrics":["Sensitive information leakage reduction within reasoning traces","Performance on safety and reasoning benchmarks"],"technology_tags":["Machine Unlearning","Large Reasoning Models","AI Safety"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:39:06.618057Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_bfbe00facded","title":"MultiFinBen: Benchmarking Large Language Models for Multilingual and Multimodal Financial Application","content":"arXiv:2506.14028v3 Announce Type: replace Abstract: Real-world financial analysis involves information across multiple languages and modalities, from reports and news to scanned filings and meeting recordings. Yet most existing evaluations of LLMs in finance remain text-only, monolingual, and largely saturated by current models. To bridge these gaps, we present MultiFinBen, the first expert-annotated multilingual (five languages) and multimodal (text, vision, audio) benchmark for evaluating LLMs in realistic financial contexts. MultiFinBen introduces two new task families: multilingual financial reasoning, which tests cross-lingual evidence integration from filings and news, and financial OCR, which extracts structured text from scanned documents containing tables and charts. Rather than aggregating all available datasets, we apply a structured, difficulty-aware selection based on advanced model performance, ensuring balanced challenge and removing redundant tasks. Evaluating 21 leading LLMs shows that even frontier multimodal models like GPT-4o achieve only 46.01% overall, stronger on vision and audio but dropping sharply in multilingual settings. These findings expose persistent limitations in multilingual, multimodal, and expert-level financial reasoning. All datasets, evaluation scripts, and leaderboards are publicly released.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14028","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.210284","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Xueqing Peng, Lingfei Qian, Yan Wang, Ruoyu Xiang, Yueru He, Yang Ren, Mingyang Jiang, Vincent Jim Zhang, Yuqing Guo, Jeff Zhao, Huan He, Yi Han, Yun Feng, Yuechen Jiang, Yupeng Cao, Haohang Li, Yangyang Yu, Xiaoyu Wang, Penglei Gao, Shengyuan Lin, Keyi Wang, Shanshan Yang, Yilun Zhao, Zhiwei Liu, Peng Lu, Jerry Huang, Suyuchen Wang, Triantafillos Papadopoulos, Polydoros Giannouris, Efstathia Soufleri, Nuo Chen, Zhiyang Deng, Heming Fu, Yijia Zhao, Mingquan Lin, Meikang Qiu, Kaleb E Smith, Arman Cohan, Xiao-Yang Liu, Jimin Huang, Guojun Xiong, Alejandro Lopez-Lira, Xi Chen, Junichi Tsujii, Jian-Yun Nie, Sophia Ananiadou, Qianqian Xie","raw_content_length":1353,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["MultiFinBen","OCR","Multimodal Financial Application arXiv:2506.14028v3 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1352,"language_detected":"en","key_concepts":{"key_phrases":["MultiFinBen","Large Language Models","Multilingual and Multimodal Financial Application","LLMs","Announce Type","Abstract","Real-world financial analysis","information","multiple languages","modalities"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MultiFinBen":3.0,"Large Language Models":2.0,"Multilingual and Multimodal Financial Application":2.0,"LLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"Real-world financial analysis":1.0,"information":1.0,"multiple languages":1.0,"modalities":1.0}},"age_hours":2.767719266666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9184,"joy":0.0063,"surprise":0.0486,"sadness":0.0081,"fear":0.0067,"anger":0.0074,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on developing a benchmark for evaluating LLMs in financial analysis, specifically in multilingual and multimodal contexts. While it doesn't directly reduce GHG emissions, it could indirectly improve the efficiency and accuracy of financial analysis related to sustainable investments. The benchmark itself is in the applied research stage, with datasets and evaluation scripts publicly released but no deployed technology.","key_impact_metrics":["Overall model performance 46.01%"],"technology_tags":["Large Language Models","Multilingual Processing","Multimodal Analysis","Financial OCR"],"sdg_alignment":[8,9],"analyzed_at":"2025-10-29T12:39:22.405926Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5d09d881b17c","title":"Load Balancing Mixture of Experts with Similarity Preserving Routers","content":"arXiv:2506.14038v2 Announce Type: replace Abstract: Sparse Mixture of Experts (MoE) models offer a scalable and efficient architecture for training large neural networks by activating only a subset of parameters (\"experts\") for each input. A learned router computes a distribution over these experts, and assigns input tokens to a small subset. However, without auxiliary balancing mechanisms, routers often converge to using only a few experts, severely limiting model capacity and degrading performance. Most current load balancing mechanisms encourage a distribution over experts that resembles a roughly uniform distribution of experts per token. During training, this can result in inconsistent routing behavior, resulting in the model spending its capacity to learn redundant knowledge. We address this by introducing a novel load balancing loss that preserves token-wise relational structure, encouraging consistent expert choices for similar inputs during training. Our experimental results show that applying our loss to the router results in 36% faster convergence and lower redundancy compared to a popular load balancing loss.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14038","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.210678","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Nabil Omi, Siddhartha Sen, Ali Farhadi","raw_content_length":1139,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1138,"language_detected":"en","key_concepts":{"key_phrases":["Load Balancing Mixture","Experts","Similarity Preserving Routers","Announce Type","Sparse Mixture","MoE","a scalable and efficient architecture","large neural networks","only a subset","parameters"],"filter_categories":{"ai_ml":["large neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Load Balancing Mixture":2.0,"Experts":2.0,"Similarity Preserving Routers":2.0,"Announce Type":1.0,"Sparse Mixture":1.0,"MoE":1.0,"a scalable and efficient architecture":1.0,"large neural networks":1.0,"only a subset":1.0,"parameters":1.0}},"age_hours":2.7677340980555556,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9322,"joy":0.0064,"surprise":0.0372,"sadness":0.0069,"fear":0.0036,"anger":0.0073,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel load balancing loss for Mixture of Experts models, achieving 36% faster convergence and lower redundancy compared to existing methods. This could indirectly reduce energy consumption in training large AI models. However, it is still in the research phase with no deployed technology or real-world data.","key_impact_metrics":["36% faster convergence","lower redundancy"],"technology_tags":["mixture of experts","load balancing","neural networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:39:31.090567Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ded5c4bc84df","title":"Online Selective Generation with Adversarial Bandit Feedback","content":"arXiv:2506.14067v2 Announce Type: replace Abstract: Large language generative models increasingly interact with humans, while their falsified responses raise concerns. To mitigate this hallucination effect, selectively abstaining from answering, called selective generation, provides an effective way for generators to control the hallucination when uncertain about their answers. However, as selective generators interact under adversarial environments and receive partial feedback from users on selected generation (e.g., thumbs up or down on the selected answer), learning methods for selective generation under such practical setups are crucial but currently missing. To address this limitation, we propose an online learning algorithm for selective generation with partial feedback under an adaptive adversary. In particular, we re-purpose an adversarial bandit algorithm to design an online selective generation method with controllable false discovery rates (FDR), which measures the rate of hallucination. The key building blocks include a novel conversion lemma from regret of any bandit algorithm to the FDR, and the exploitation of a unique structure of selective generation to reuse partial feedback, which we call feedback unlocking. We empirically evaluate the efficacy of the proposed online selective generation algorithm with partial feedback over diverse learning environments, demonstrating its ability to control the FDR, while maintaining reasonable selection efficiency, i.e., the ratio of non-abstaining answers, compared to baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14067","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.211068","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Minjae Lee, Yoonjae Jung, Sangdon Park","raw_content_length":1559,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1558,"language_detected":"en","key_concepts":{"key_phrases":["Online Selective Generation","Adversarial Bandit Feedback","arXiv250614067v2 Announce Type","Abstract","Large language generative models","humans","their falsified responses","concerns","this hallucination effect","selective generation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Online Selective Generation":2.0,"Adversarial Bandit Feedback":2.0,"arXiv250614067v2 Announce Type":1.0,"Abstract":1.0,"Large language generative models":1.0,"humans":1.0,"their falsified responses":1.0,"concerns":1.0,"this hallucination effect":1.0,"selective generation":1.0}},"age_hours":2.767747998055556,"is_recent":true,"quality_score":0.7,"sentiment_score":1.5460000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6908,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4202,"joy":0.0065,"surprise":0.0121,"sadness":0.0171,"fear":0.4827,"anger":0.0327,"disgust":0.0287},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents an online learning algorithm to mitigate hallucination in large language models. The algorithm aims to control the false discovery rate (FDR), which measures the rate of hallucination. Empirical evaluations demonstrate the algorithm's ability to control the FDR, but it is still in the research phase with no real-world deployment data.","key_impact_metrics":["Controllable false discovery rates (FDR)","Reasonable selection efficiency (ratio of non-abstaining answers)"],"technology_tags":["Large Language Models","Adversarial Bandit Algorithms","Online Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:39:34.488446Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_10cc3a8179db","title":"Structured Generative Modeling with the Thermodynamic Kolmogorov","content":"arXiv:2506.14167v4 Announce Type: replace Abstract: Learning an energy-based model (EBM) in the latent space of a top-down generative model offers a versatile framework for generation across multiple data modalities. However, it remains unclear how its interpretability can be used to guide model design, improve generative quality, and reduce training time. Moreover, the reliance on Langevin Monte Carlo (LMC) sampling presents challenges in efficiency and sampling multimodal latent distributions. In this work, we propose a novel adaptation of the Kolmogorov-Arnold representation theorem for generative modeling and introduce the Thermodynamic Kolmogorov-Arnold Model (T-KAM) to take advantage of structural and inductive biases. By constraining the prior to univariate relationships, T-KAM enables fast and exact inference via the inverse transform method. With the low dimensionality of the latent space and suitable inductive biases encoded, we demonstrate that importance sampling (IS) becomes a viable, unbiased, and highly efficient posterior sampler. For situations where IS fails, we investigate a novel strategy using population-based LMC, which decomposes posterior sampling into a sequence of annealed distributions to improve multimodal sampling. T-KAM elegantly balances common trade-offs in generative modeling, offering fast inference, interpretability, and stable training, while being naturally suited to upcoming Zettascale Computing Corp. hardware.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14167","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.211458","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Prithvi Raj","raw_content_length":1473,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["EBM","LMC","the Thermodynamic Kolmogorov arXiv:2506.14167v4 Announce Type: replace Abstract"],"persons":["Langevin Monte Carlo"],"locations":[],"monetary":[]},"char_count":1472,"language_detected":"en","key_concepts":{"key_phrases":["Structured Generative Modeling","the Thermodynamic Kolmogorov","Announce Type","an energy-based model","EBM","the latent space","a top-down generative model","a versatile framework","generation","multiple data modalities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Structured Generative Modeling":2.0,"the Thermodynamic Kolmogorov":2.0,"Announce Type":1.0,"an energy-based model":1.0,"EBM":1.0,"the latent space":1.0,"a top-down generative model":1.0,"a versatile framework":1.0,"generation":1.0,"multiple data modalities":1.0}},"age_hours":2.7677635491666663,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9261,"joy":0.0156,"surprise":0.0205,"sadness":0.0056,"fear":0.0175,"anger":0.0088,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel generative modeling approach (T-KAM) that could potentially improve the efficiency of AI models used in various applications, including those relevant to sustainability. However, it is currently in the basic research phase with no deployed units or measured outcomes. The potential climate impact is theoretical and depends on the specific applications of the model.","key_impact_metrics":[],"technology_tags":["generative modeling","energy-based model","machine learning","AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:39:37.436854Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_75ce39560d29","title":"Higher","content":"arXiv:2506.14424v3 Announce Type: replace Abstract: This article investigates matrix-free higher-order discontinuous Galerkin discretizations of the Navier--Stokes equations for incompressible flows with variable viscosity. The viscosity field may be prescribed analytically or governed by a rheological law, as often found in biomedical or industrial applications. The DG discretization of the adapted second-order viscous terms is carried out via the symmetric interior penalty Galerkin method, obviating auxiliary variables. Based on this spatial discretization, we compare several linearized variants of saddle point block systems and projection-based splitting time integration schemes in terms of their computational performance. Compared to the velocity-pressure block-system for the former, the splitting scheme allows solving a sequence of simple problems such as mass, convection-diffusion and Poisson equations. We investigate under which conditions the improved temporal stability of fully implicit schemes and resulting expensive nonlinear solves outperform the splitting schemes and linearized variants that are stable under hyperbolic time step restrictions. The key aspects of this work are i) a higher-order DG discretization for incompressible flows with variable viscosity, ii) accelerated nonlinear solver variants and suitable linearizations adopting a matrix-free $hp$-multigrid solver, and iii) a detailed comparison of the monolithic and projection-based solvers in terms of their (non-)linear solver performance. The presented schemes are evaluated in a series of numerical examples verifying their spatial and temporal accuracy, and the preconditioner performance under increasing viscosity contrasts, while their efficiency is showcased in the backward-facing step benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14424","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.211890","language":"en","tags":["physicsflu-dyn","physicscomp-ph","csce","preprints","research","math-ph","mathmp","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Richard Schussnig, Niklas Fehn, Douglas Ramalho Queiroz Pacheco, Martin Kronbichler","raw_content_length":1807,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["Poisson","Navier"],"persons":["Galerkin","Announce Type"],"locations":[],"monetary":[]},"char_count":1802,"language_detected":"en","key_concepts":{"key_phrases":["arXiv250614424v3 Announce Type","Abstract","This article","matrix-free higher-order discontinuous Galerkin discretizations","the Navier","Stokes equations","incompressible flows","variable viscosity","The viscosity field","a rheological law"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv250614424v3 Announce Type":1.0,"Abstract":1.0,"This article":1.0,"matrix-free higher-order discontinuous Galerkin discretizations":1.0,"the Navier":1.0,"Stokes equations":1.0,"incompressible flows":1.0,"variable viscosity":1.0,"The viscosity field":1.0,"a rheological law":1.0}},"age_hours":2.7677777005555555,"is_recent":true,"quality_score":1.0,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8652,"joy":0.0338,"surprise":0.0533,"sadness":0.0129,"fear":0.0076,"anger":0.0156,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents research on a numerical method for simulating fluid dynamics, specifically focusing on incompressible flows with variable viscosity. While the research aims to improve computational performance, its direct climate impact is currently theoretical and depends on its application in fields like biomedical or industrial processes. The article includes metrics related to solver performance and accuracy, but lacks information on real-world deployment or specific environmental benefits.","key_impact_metrics":["spatial and temporal accuracy","preconditioner performance under increasing viscosity contrasts"],"technology_tags":["computational fluid dynamics","numerical simulation","discontinuous Galerkin method"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:39:40.590562Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_157abc86cbc6","title":"Revisiting Chain-of-Thought Prompting: Zero","content":"arXiv:2506.14641v2 Announce Type: replace Abstract: In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \\texttt{Qwen2.5-Max} and \\texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14641","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.212277","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Xiang Cheng, Chengyan Pan, Minjun Zhao, Deyang Li, Fangchao Liu, Xinyu Zhang, Xiao Zhang, Yong Liu","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","CoT","ICL"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["Thought","ICL","arXiv250614641v2 Announce Type","Abstract","Context Learning","an essential emergent ability","Large Language Models","LLMs","recent studies","exemplars"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Thought":3.0,"ICL":2.0,"arXiv250614641v2 Announce Type":1.0,"Abstract":1.0,"Context Learning":1.0,"an essential emergent ability":1.0,"Large Language Models":1.0,"LLMs":1.0,"recent studies":1.0,"exemplars":1.0}},"age_hours":2.767793135833333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.548,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7096,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9336,"joy":0.0102,"surprise":0.0262,"sadness":0.0054,"fear":0.0103,"anger":0.0105,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper investigates the effectiveness of Chain-of-Thought prompting for Large Language Models in mathematical reasoning. The concrete action is systematic experimentation with different CoT exemplars. The evidence is the experimental results showing that enhanced exemplars fail to improve model reasoning performance, indicating limitations of the current ICL+CoT framework. This is basic research, not deployment.","key_impact_metrics":["No observable gain in reasoning ability"],"technology_tags":["Large Language Models","Chain-of-Thought prompting","In-Context Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:39:43.333073Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d678201a7d7b","title":"StreetLens: Enabling Human","content":"arXiv:2506.14670v2 Announce Type: replace Abstract: Traditionally, neighborhood studies have used interviews, surveys, and manual image annotation guided by detailed protocols to identify environmental characteristics, including physical disorder, decay, street safety, and sociocultural symbols, and to examine their impact on developmental and health outcomes. Although these methods yield rich insights, they are time-consuming and require intensive expert intervention. Recent technological advances, including vision language models (VLMs), have begun to automate parts of this process; however, existing efforts are often ad hoc and lack adaptability across research designs and geographic contexts. In this paper, we present StreetLens, a user-configurable human-centered workflow that integrates relevant social science expertise into a VLM for scalable neighborhood environmental assessments. StreetLens mimics the process of trained human coders by focusing the analysis on questions derived from established interview protocols, retrieving relevant street view imagery (SVI), and generating a wide spectrum of semantic annotations from objective features (e.g., the number of cars) to subjective perceptions (e.g., the sense of disorder in an image). By enabling researchers to define the VLM's role through domain-informed prompting, StreetLens places domain knowledge at the core of the analysis process. It also supports the integration of prior survey data to enhance robustness and expand the range of characteristics assessed in diverse settings. StreetLens represents a shift toward flexible and agentic AI systems that work closely with researchers to accelerate and scale neighborhood studies. StreetLens is publicly available at https://knowledge-computing.github.io/projects/streetlens.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14670","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.212704","language":"en","tags":["computer-science","csai","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Jina Kim, Leeje Jang, Yao-Yi Chiang, Guanyu Wang, Michelle C. Pasco","raw_content_length":1809,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["StreetLens","VLM"],"persons":["StreetLens"],"locations":[],"monetary":[]},"char_count":1808,"language_detected":"en","key_concepts":{"key_phrases":["StreetLens","Enabling Human","arXiv250614670v2 Announce Type","Abstract","neighborhood studies","interviews","surveys","manual image annotation","detailed protocols","environmental characteristics"],"filter_categories":{"ai_ml":["detailed protocols"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"StreetLens":2.0,"Enabling Human":2.0,"arXiv250614670v2 Announce Type":1.0,"Abstract":1.0,"neighborhood studies":1.0,"interviews":1.0,"surveys":1.0,"manual image annotation":1.0,"detailed protocols":1.0,"environmental characteristics":1.0}},"age_hours":2.7678077183333336,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9181,"joy":0.0182,"surprise":0.0162,"sadness":0.0104,"fear":0.0167,"anger":0.0102,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"StreetLens is a workflow that integrates social science expertise into a VLM for scalable neighborhood environmental assessments. It is currently in the applied research stage, mimicking human coders to analyze street view imagery. While promising, there are no deployed units or quantified environmental impact metrics provided, limiting its current sustainability impact.","key_impact_metrics":[],"technology_tags":["vision language models","environmental assessment"],"sdg_alignment":[11],"analyzed_at":"2025-10-29T12:39:46.236253Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_99a3eafc9fd8","title":"DualTHOR: A Dual","content":"arXiv:2506.16012v2 Announce Type: replace Abstract: Developing embodied agents capable of performing complex interactive tasks in real-world scenarios remains a fundamental challenge in embodied AI. Although recent advances in simulation platforms have greatly enhanced task diversity to train embodied Vision Language Models (VLMs), most platforms rely on simplified robot morphologies and bypass the stochastic nature of low-level execution, which limits their transferability to real-world robots. To address these issues, we present a physics-based simulation platform DualTHOR for complex dual-arm humanoid robots, built upon an extended version of AI2-THOR. Our simulator includes real-world robot assets, a task suite for dual-arm collaboration, and inverse kinematics solvers for humanoid robots. We also introduce a contingency mechanism that incorporates potential failures through physics-based low-level execution, bridging the gap to real-world scenarios. Our simulator enables a more comprehensive evaluation of the robustness and generalization of VLMs in household environments. Extensive evaluations reveal that current VLMs struggle with dual-arm coordination and exhibit limited robustness in realistic environments with contingencies, highlighting the importance of using our simulator to develop more capable VLMs for embodied tasks. The code is available at https://github.com/ds199895/DualTHOR.git.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.16012","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.213923","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Boyu Li, Siyuan He, Hang Xu, Haoqi Yuan, Yu Zang, Liwei Hu, Junpeng Yue, Zhenxiong Jiang, Pengbo Hu, B\\\"orje F. Karlsson, Yehui Tang, Zongqing Lu","raw_content_length":1422,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["Vision Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1421,"language_detected":"en","key_concepts":{"key_phrases":["DualTHOR","A Dual","Announce Type","Abstract","embodied agents","complex interactive tasks","real-world scenarios","a fundamental challenge","embodied AI","recent advances"],"filter_categories":{"ai_ml":["embodied AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DualTHOR":2.0,"A Dual":2.0,"Announce Type":1.0,"Abstract":1.0,"embodied agents":1.0,"complex interactive tasks":1.0,"real-world scenarios":1.0,"a fundamental challenge":1.0,"embodied AI":1.0,"recent advances":1.0}},"age_hours":2.767852739166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.906,"joy":0.0144,"surprise":0.0421,"sadness":0.0061,"fear":0.0127,"anger":0.0139,"disgust":0.0049},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a new simulation platform for training embodied AI agents. While it aims to improve the robustness of VLMs in household environments, it does not directly address GHG emissions or other environmental concerns. The platform is in the applied research stage, with no deployed units or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["AI","Simulation","Robotics"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:39:48.700130Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_18d521a42a5b","title":"A Community","content":"arXiv:2506.16596v3 Announce Type: replace Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.16596","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.214324","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Vinay K Chaudhri, Chaitan Baru, Brandon Bennett, Mehul Bhatt, Darion Cassel, Anthony G Cohn, Rina Dechter, Esra Erdem, Dave Ferrucci, Ken Forbus, Gregory Gelfond, Michael Genesereth, Andrew S. Gordon, Benjamin Grosof, Gopal Gupta, Jim Hendler, Sharat Israni, Tyler R. Josephson, Patrick Kyllonen, Yuliya Lierler, Vladimir Lifschitz, Clifton McFate, Hande K. McGinty, Leora Morgenstern, Alessandro Oltramari, Praveen Paritosh, Dan Roth, Blake Shepard, Cogan Shimzu, Denny Vrande\\v{c}i\\'c, Mark Whiting, Michael Witbrock","raw_content_length":1286,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["ConceptNet","WordNet"],"persons":[],"locations":[],"monetary":[]},"char_count":1285,"language_detected":"en","key_concepts":{"key_phrases":["A Community","arXiv250616596v3","Announce Type","Abstract","The long-standing goal","a comprehensive multi-purpose knowledge resource","the 1984 Cyc project","the success","knowledge resources","WordNet"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Community":2.0,"arXiv250616596v3":1.0,"Announce Type":1.0,"Abstract":1.0,"The long-standing goal":1.0,"a comprehensive multi-purpose knowledge resource":1.0,"the 1984 Cyc project":1.0,"the success":1.0,"knowledge resources":1.0,"WordNet":1.0}},"age_hours":2.7678674288888887,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8705,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2259,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8086,"joy":0.0139,"surprise":0.0572,"sadness":0.0747,"fear":0.0222,"anger":0.012,"disgust":0.0113},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper synthesizes findings from a workshop about creating a comprehensive knowledge resource for AI. While it addresses a critical deficiency in AI infrastructure, it lacks concrete actions or measurable outcomes related to sustainability. It is still in the conceptual stage, with no deployed technology or quantified impact data.","key_impact_metrics":[],"technology_tags":["knowledge representation","reasoning","AI infrastructure"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:39:51.262741Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c616d01a9cb7","title":"SAFEx: Analyzing Vulnerabilities of MoE","content":"arXiv:2506.17368v2 Announce Type: replace Abstract: Large language models with Mixture-of-Experts (MoE) architectures achieve efficiency and scalability, yet their routing mechanisms introduce safety alignment challenges insufficiently addressed by techniques developed for dense models. In this work, the MoE-specific safety risk of positional vulnerability-that safety-aligned behaviors rely on specific expert modules-is formalized and systematically analyzed. An analytical framework, SAFEx, is presented to robustly identify, characterize, and validate safety-critical experts via a stability-based expert selection procedure, and to decompose them into two functional groups: the Harmful Content Detection Group (HCDG), which specializes in identifying and recognizing harmful content within user inputs, and the Harmful Response Control Group (HRCG), which specializes in controlling and enforcing model behaviors to generate appropriate safety responses. Expert-level interventions are conducted to probe causality and to test mitigation. Targeted masking of SAFEx-selected experts reveals that safety behavior is highly concentrated. On Qwen3-30B-A3B, configured with 48 MoE-FFN layers and 128 experts per layer under top-8 routing (48x128=6,144 experts in total), disabling 12 selected experts reduces the refusal rate by 22%. In addition, lightweight adaptation is performed using LoRA under three configurations-the HRCG, the union of HCDG and HRCG, and all experts-and the resulting updates are composed through negative weight merging targeted at the HRCG, leading to improved refusal under adversarial prompts without full-model retraining. These results establish positional vulnerability as a distinct MoE-specific safety challenge and provide a practical, compute-efficient pathway for expert-level safety interventions within routed architectures.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.17368","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.214759","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":238,"author":"Zhenglin Lai, Mengyao Liao, Bingzhe Wu, Dong Xu, Zebin Zhao, Zhihang Yuan, Chao Fan, Jianqiang Li","raw_content_length":1867,"priority":7,"update_frequency":1,"reading_time_minutes":1.19,"robust_parsing_used":true,"entities":{"organizations":["Analyzing Vulnerabilities of MoE arXiv:2506.17368v2","the Harmful Response Control Group","the Harmful Content Detection Group"],"persons":[],"locations":["SAFEx"],"monetary":[]},"char_count":1866,"language_detected":"en","key_concepts":{"key_phrases":["SAFEx","MoE","Vulnerabilities","Announce Type","Abstract","Large language models","Experts","efficiency","scalability","their routing mechanisms"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SAFEx":3.0,"MoE":3.0,"Vulnerabilities":2.0,"Announce Type":1.0,"Abstract":1.0,"Large language models":1.0,"Experts":1.0,"efficiency":1.0,"scalability":1.0,"their routing mechanisms":1.0}},"age_hours":2.7678820133333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.884,"joy":0.0076,"surprise":0.0268,"sadness":0.0165,"fear":0.0322,"anger":0.0211,"disgust":0.0119},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the safety alignment of large language models, which could indirectly contribute to sustainability by preventing the spread of misinformation or harmful content related to climate change. The article presents a framework (SAFEx) and demonstrates that disabling 12 selected experts reduces the refusal rate by 22% on a specific model. However, the direct climate impact is theoretical and the technology is still in the applied research stage.","key_impact_metrics":["refusal rate reduction 22%"],"technology_tags":["mixture-of-experts","large language models","safety alignment"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:39:54.485401Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_99e48415724e","title":"Beyond Parameters: Exploring Virtual Logic Depth for Scaling Laws","content":"arXiv:2506.18233v3 Announce Type: replace Abstract: Scaling large language models typically involves three dimensions: depth, width, and parameter count. In this work, we explore a fourth dimension, \\textbf{virtual logical depth} (VLD), which increases effective algorithmic depth without changing parameter count by reusing weights. While parameter reuse is not new, its role in scaling has been underexplored. Unlike recent test-time methods that scale token-wise, VLD alters the internal computation graph during training and inference. Through controlled experiments, we obtain three key insights. (1) \\textit{Knowledge capacity vs. parameters}: at fixed parameter count, VLD leaves knowledge capacity nearly unchanged, while across models capacity still scales with parameters. (2) \\textit{Reasoning vs. reuse}: properly implemented VLD substantially improves reasoning ability \\emph{without} more parameters, decoupling reasoning from size. This suggests a new scaling path beyond token-wise test-time methods. (3) \\textit{Robustness and generality}: reasoning gains persist across architectures and reuse schedules, showing VLD captures a general scaling behavior. These results provide insight into future scaling strategies and raise a deeper question: does superintelligence require ever-larger models, or can it be achieved by reusing parameters and increasing logical depth? We argue many unknown dynamics in scaling remain to be explored. Code is available at https://anonymous.4open.science/r/virtual_logical_depth-8024/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.18233","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.215144","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Ruike Zhu, Hanwen Zhang, Kevin Li, Tianyu Shi, Yiqun Duan, Chi Wang, Tianyi Zhou, Arindam Banerjee, Zengyi Qin","raw_content_length":1536,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["VLD"],"persons":[],"locations":[],"monetary":[]},"char_count":1535,"language_detected":"en","key_concepts":{"key_phrases":["Parameters","Virtual Logic Depth","Scaling Laws","parameter count","Announce Type","Abstract","large language models","three dimensions","depth","width"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Parameters":2.0,"Virtual Logic Depth":2.0,"Scaling Laws":2.0,"parameter count":2.0,"Announce Type":1.0,"Abstract":1.0,"large language models":1.0,"three dimensions":1.0,"depth":1.0,"width":1.0}},"age_hours":2.767897143888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9336,"joy":0.0093,"surprise":0.0325,"sadness":0.0044,"fear":0.0056,"anger":0.007,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a novel approach to scaling large language models by increasing virtual logical depth (VLD) without increasing parameter count. The research shows improvements in reasoning ability without more parameters. The work is currently in the basic research stage, with code available but no deployed systems or quantified environmental impact.","key_impact_metrics":["Reasoning ability improvement","Parameter count reduction"],"technology_tags":["Large Language Models","Artificial Intelligence","Virtual Logical Depth"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:39:57.787307Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cec88927a6ba","title":"Structured Kolmogorov","content":"arXiv:2506.18339v2 Announce Type: replace Abstract: Understanding and modeling nonlinear dynamical systems is a fundamental challenge across science and engineering. Deep learning has shown remarkable potential for capturing complex system behavior, yet achieving models that are both accurate and physically interpretable remains difficult. To address this, we propose Structured Kolmogorov-Arnold Neural ODEs (SKANODEs), a framework that integrates structured state-space modeling with Kolmogorov-Arnold Networks (KANs). Within a Neural ODE architecture, SKANODE employs a fully trainable KAN as a universal function approximator to perform virtual sensing, recovering latent states that correspond to interpretable physical quantities such as displacements and velocities. Leveraging KAN's symbolic regression capability, SKANODE then extracts compact, interpretable expressions for the system's governing dynamics. Extensive experiments on simulated and real-world systems demonstrate that SKANODE achieves superior predictive accuracy, discovers physics-consistent dynamics, and reveals complex nonlinear behavior. Notably, it identifies hysteretic behavior in an F-16 aircraft and recovers a concise symbolic equation describing this phenomenon. SKANODE thus enables interpretable, data-driven discovery of physically grounded models for complex nonlinear dynamical systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.18339","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.215547","language":"en","tags":["cslg","nlincd","csai","preprints","research","physicsdata-an","cssc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Wei Liu, Kiran Bacsa, Loon Ching Tang, Eleni Chatzi","raw_content_length":1381,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["Kolmogorov-Arnold Networks","KAN"],"persons":["Structured Kolmogorov arXiv:2506.18339v2","Structured Kolmogorov-Arnold Neural"],"locations":[],"monetary":[]},"char_count":1380,"language_detected":"en","key_concepts":{"key_phrases":["Structured Kolmogorov","Announce Type","Understanding","nonlinear dynamical systems","a fundamental challenge","science","engineering","Deep learning","remarkable potential","complex system behavior"],"filter_categories":{"ai_ml":["science","Deep learning"],"research_academic":["science"],"engineering":["engineering"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Structured Kolmogorov":2.0,"Announce Type":1.0,"Understanding":1.0,"nonlinear dynamical systems":1.0,"a fundamental challenge":1.0,"science":1.0,"engineering":1.0,"Deep learning":1.0,"remarkable potential":1.0,"complex system behavior":1.0}},"age_hours":2.7679109266666666,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8352,"joy":0.0166,"surprise":0.0951,"sadness":0.0065,"fear":0.0266,"anger":0.014,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (SKANODE) for modeling nonlinear dynamical systems, potentially leading to more efficient and accurate simulations. While it demonstrates superior predictive accuracy and discovers physics-consistent dynamics on simulated and real-world systems (F-16 aircraft), it remains in the applied research stage with no deployed units or quantified climate impact. The vaporware flag is raised due to the lack of deployment data.","key_impact_metrics":["Superior predictive accuracy","Discovers physics-consistent dynamics"],"technology_tags":["Neural ODEs","Kolmogorov-Arnold Networks","Symbolic Regression"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:40:01.341086Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae3c23a950e9","title":"Breakthrough Asymmetries across Disciplines and Countries: A Network approach to Structural Complexity of Scientific Progress","content":"arXiv:2506.18804v2 Announce Type: replace Abstract: Science is driven by community endeavors across diverse fields and specializations, forming a complex structure that renders conventional performance evaluation methods inadequate. Using established indicators, the network-based normalized citation score and the disruptive index, combined with the GENEPY algorithm, we evaluate the complexity rank of countries based on their breakthrough performance across 89 subfields of physical sciences, drawing on nearly 60 million articles (1900-2023). This quality-focused integrated approach reveals pronounced asymmetries: while countries such as the United States, Israel, and several in Europe sustain long-term structural advantages, emerging nations show rapid gains in later decades. A power-law relationship between aggregated breakthrough performance and countries' R&D expenditure underscores the unequal and scale-dependent nature of global science. These results demonstrate that scientific advancement arises not from uniform growth but from asymmetric complexity, offering actionable insights for policymakers and funding agencies aiming to foster sustainable, high-quality research ecosystems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.18804","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.215946","language":"en","tags":["physicssoc-ph","csdl","preprints","research","physicsdata-an","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Adarsh Raghuvanshi, Hrishidev Unni,  Vinayak, Anirban Chakraborti","raw_content_length":1208,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Network","Structural Complexity of Scientific Progress arXiv:2506.18804v2","Disciplines","Breakthrough Asymmetries"],"persons":[],"locations":["Israel","Europe","the United States"],"monetary":[]},"char_count":1203,"language_detected":"en","key_concepts":{"key_phrases":["Breakthrough Asymmetries","Disciplines","Countries","A Network approach","Structural Complexity","Scientific Progress","Announce Type","Abstract","Science","community endeavors"],"filter_categories":{"research_academic":["Breakthrough Asymmetries"],"ai_ml":["Science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Breakthrough Asymmetries":2.0,"Disciplines":2.0,"Countries":2.0,"A Network approach":2.0,"Structural Complexity":2.0,"Scientific Progress":2.0,"Announce Type":1.0,"Abstract":1.0,"Science":1.0,"community endeavors":1.0}},"age_hours":2.7679259524999997,"is_recent":true,"quality_score":1.0,"sentiment_score":3.5199999999999996,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.296,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6801,"joy":0.015,"surprise":0.0355,"sadness":0.0086,"fear":0.139,"anger":0.0813,"disgust":0.0405},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research analyzes scientific progress and its impact on countries, using citation scores and a disruptive index. While it identifies asymmetries in scientific advancement and highlights the importance of R&D expenditure, it doesn't directly translate into concrete climate action or measurable environmental outcomes. The research is at an early stage, focusing on analysis rather than deployment of specific technologies.","key_impact_metrics":["60 million articles","89 subfields"],"technology_tags":["network analysis","citation analysis"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T12:40:04.069370Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_26d959f04dd1","title":"MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Multi","content":"arXiv:2506.19073v4 Announce Type: replace Abstract: Ensuring the moral reasoning capabilities of Large Language Models (LLMs) is a growing concern as these systems are used in socially sensitive tasks. Nevertheless, current evaluation benchmarks present two major shortcomings: a lack of annotations that justify moral classifications, which limits transparency and interpretability; and a predominant focus on English, which constrains the assessment of moral reasoning across diverse cultural settings. In this paper, we introduce MFTCXplain, a multilingual benchmark dataset for evaluating the moral reasoning of LLMs via multi-hop hate speech explanation using the Moral Foundations Theory. MFTCXplain comprises 3,000 tweets across Portuguese, Italian, Persian, and English, annotated with binary hate speech labels, moral categories, and text span-level rationales. Our results show a misalignment between LLM outputs and human annotations in moral reasoning tasks. While LLMs perform well in hate speech detection (F1 up to 0.836), their ability to predict moral sentiments is notably weak (F1 < 0.35). Furthermore, rationale alignment remains limited mainly in underrepresented languages. Our findings show the limited capacity of current LLMs to internalize and reflect human moral reasoning","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.19073","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.216336","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Jackson Trager, Francielle Vargas, Diego Alves, Matteo Guida, Mikel K. Ngueajio, Ameeta Agrawal, Yalda Daryani, Farzan Karimi-Malekabadi, Flor Miriam Plaza-del-Arco","raw_content_length":1300,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","MFTCXplain","Multi arXiv:2506.19073v4 Announce Type:","the Moral Foundations Theory"],"persons":[],"locations":[],"monetary":[]},"char_count":1299,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","MFTCXplain","A Multilingual Benchmark Dataset","the Moral Reasoning","Multi","which","arXiv250619073v4 Announce Type","Abstract","the moral reasoning capabilities","Large Language Models"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"MFTCXplain":2.0,"A Multilingual Benchmark Dataset":2.0,"the Moral Reasoning":2.0,"Multi":2.0,"which":2.0,"arXiv250619073v4 Announce Type":1.0,"Abstract":1.0,"the moral reasoning capabilities":1.0,"Large Language Models":1.0}},"age_hours":2.7679407508333336,"is_recent":true,"quality_score":1.0,"sentiment_score":5.3045,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0609,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.664,"joy":0.0109,"surprise":0.0095,"sadness":0.0391,"fear":0.1626,"anger":0.0623,"disgust":0.0517},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":3,"justice_equity":5,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a multilingual benchmark dataset (MFTCXplain) for evaluating the moral reasoning of LLMs. While the research itself doesn't directly reduce GHG emissions, it contributes to the responsible development of AI, which could indirectly influence sustainability-related applications. The dataset includes metrics like F1 scores for hate speech detection and moral sentiment prediction, and is based on peer-reviewed research.","key_impact_metrics":["F1 for hate speech detection: 0.836","F1 for moral sentiments: <0.35"],"technology_tags":["Large Language Models","Moral Reasoning","Hate Speech Detection"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:40:08.358444Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f336843a7e77","title":"On Convolutions, Intrinsic Dimension, and Diffusion Models","content":"arXiv:2506.20705v2 Announce Type: replace Abstract: The manifold hypothesis asserts that data of interest in high-dimensional ambient spaces, such as image data, lies on unknown low-dimensional submanifolds. Diffusion models (DMs) -- which operate by convolving data with progressively larger amounts of Gaussian noise and then learning to revert this process -- have risen to prominence as the most performant generative models, and are known to be able to learn distributions with low-dimensional support. For a given datum in one of these submanifolds, we should thus intuitively expect DMs to have implicitly learned its corresponding local intrinsic dimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari et al. (2024b) recently showed that this is indeed the case by linking this LID to the rate of change of the log marginal densities of the DM with respect to the amount of added noise, resulting in an LID estimator known as FLIPD. LID estimators such as FLIPD have a plethora of uses, among others they quantify the complexity of a given datum, and can be used to detect outliers, adversarial examples and AI-generated text. FLIPD achieves state-of-the-art performance at LID estimation, yet its theoretical underpinnings are incomplete since Kamkari et al. (2024b) only proved its correctness under the highly unrealistic assumption of affine submanifolds. In this work we bridge this gap by formally proving the correctness of FLIPD under realistic assumptions. Additionally, we show that an analogous result holds when Gaussian convolutions are replaced with uniform ones, and discuss the relevance of this result.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.20705","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.216770","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Kin Kwan Leung, Rasa Hosseinzadeh, Gabriel Loaiza-Ganem","raw_content_length":1651,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["Kamkari","Convolutions, Intrinsic Dimension","Diffusion Models arXiv:2506.20705v2 Announce Type","LID"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1650,"language_detected":"en","key_concepts":{"key_phrases":["Convolutions","Intrinsic Dimension","Diffusion Models","data","arXiv250620705v2 Announce Type","Abstract","The manifold hypothesis","interest","high-dimensional ambient spaces","image data"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Convolutions":2.0,"Intrinsic Dimension":2.0,"Diffusion Models":2.0,"data":2.0,"arXiv250620705v2 Announce Type":1.0,"Abstract":1.0,"The manifold hypothesis":1.0,"interest":1.0,"high-dimensional ambient spaces":1.0,"image data":1.0}},"age_hours":2.767956526666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8719,"joy":0.0146,"surprise":0.0503,"sadness":0.0056,"fear":0.0163,"anger":0.0195,"disgust":0.0219},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on theoretical improvements to Local Intrinsic Dimension (LID) estimation within diffusion models. While diffusion models have potential for generative tasks that could indirectly support sustainability (e.g., materials discovery), this research is at a very early stage and does not have concrete actions or measurable outcomes related to climate impact or deployment. The paper improves the theoretical understanding of existing LID estimators.","key_impact_metrics":[],"technology_tags":["diffusion models","machine learning","intrinsic dimension estimation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:40:11.182870Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fdc1195b0862","title":"Doc2SAR: A Synergistic Framework for High","content":"arXiv:2506.21625v2 Announce Type: replace Abstract: Extracting molecular structure-activity relationships (SARs) from scientific literature and patents is essential for drug discovery and materials research. However, this task remains challenging due to heterogeneous document formats and limitations of existing methods. Specifically, rule-based approaches relying on rigid templates fail to generalize across diverse document layouts, while general-purpose multimodal large language models (MLLMs) lack sufficient accuracy and reliability for specialized tasks, such as layout detection and optical chemical structure recognition (OCSR). To address these challenges, we introduce DocSAR-200, a rigorously annotated benchmark of 200 scientific documents designed specifically for evaluating SAR extraction methods. Additionally, we propose Doc2SAR, a novel synergistic framework that integrates domain-specific tools with MLLMs enhanced via supervised fine-tuning (SFT). Extensive experiments demonstrate that Doc2SAR achieves state-of-the-art performance across various document types, significantly outperforming leading end-to-end baselines. Specifically, Doc2SAR attains an overall Table Recall of 80.78% on DocSAR-200, exceeding end2end GPT-4o by 51.48%. Furthermore, Doc2SAR demonstrates practical usability through efficient inference and is accompanied by a web app.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.21625","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.217937","language":"en","tags":["computer-science","csai","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Jiaxi Zhuang, Kangning Li, Jue Hou, Mingjun Xu, Zhifeng Gao, Hengxing Cai","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Doc2SAR","A Synergistic Framework","arXiv250621625v2 Announce Type","Abstract","molecular structure-activity relationships","SARs","scientific literature","patents","drug discovery","materials research"],"filter_categories":{"research_academic":["drug discovery","materials research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Doc2SAR":2.0,"A Synergistic Framework":2.0,"arXiv250621625v2 Announce Type":1.0,"Abstract":1.0,"molecular structure-activity relationships":1.0,"SARs":1.0,"scientific literature":1.0,"patents":1.0,"drug discovery":1.0,"materials research":1.0}},"age_hours":2.7680005283333333,"is_recent":true,"quality_score":0.7,"sentiment_score":2.3665000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5267,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8333,"joy":0.0069,"surprise":0.0407,"sadness":0.0436,"fear":0.0191,"anger":0.0263,"disgust":0.0301},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the extraction of molecular structure-activity relationships (SARs) from scientific literature, which can accelerate drug discovery and materials research. While this could indirectly contribute to sustainability by enabling faster development of sustainable materials, the direct climate impact is currently theoretical and not quantified. The technical credibility is relatively high due to the rigorously annotated benchmark and demonstrated performance improvements, but it remains at the applied research stage with no clear path to economic viability or deployment.","key_impact_metrics":["Table Recall of 80.78%","51.48% exceeding end2end GPT-4o"],"technology_tags":["Machine Learning","SAR extraction"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:40:14.882706Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_80d4fd445b5e","title":"ViFusionTST: Deep Fusion of Time","content":"arXiv:2506.22498v3 Announce Type: replace Abstract: Bed-related falls remain a major source of injury in hospitals and long-term care facilities, yet many commercial alarms trigger only after a patient has already left the bed. We show that early bed-exit intent can be predicted using only one low-cost load cell mounted under a bed leg. The resulting load signals are first converted into a compact set of complementary images: an RGB line plot that preserves raw waveforms and three texture maps-recurrence plot, Markov transition field, and Gramian angular field-that expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin Transformer that processes the line plot and texture maps in parallel and fuses them through cross-attention to learn data-driven modality weights. To provide a realistic benchmark, we collected six months of continuous data from 95 beds in a long-term-care facility. On this real-world dataset ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC. The results demonstrate that image-based fusion of load-sensor signals for time series classification is a practical and effective solution for real-time, privacy-preserving fall prevention.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.22498","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.218326","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Hao Liu, Yu Hu, Rakiba Rayhana, Ling Bai, Zheng Liu","raw_content_length":1290,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Deep Fusion of Time arXiv:2506.22498v3","RGB"],"persons":["Markov","Swin Transformer"],"locations":[],"monetary":[]},"char_count":1289,"language_detected":"en","key_concepts":{"key_phrases":["ViFusionTST","Deep Fusion","Time","Announce Type","Abstract","Bed-related falls","a major source","injury","hospitals","long-term care facilities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ViFusionTST":2.0,"Deep Fusion":2.0,"Time":2.0,"Announce Type":1.0,"Abstract":1.0,"Bed-related falls":1.0,"a major source":1.0,"injury":1.0,"hospitals":1.0,"long-term care facilities":1.0}},"age_hours":2.768017152222222,"is_recent":true,"quality_score":1.0,"sentiment_score":3.7924999999999995,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2415,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8915,"joy":0.0052,"surprise":0.0557,"sadness":0.007,"fear":0.029,"anger":0.009,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed system in a long-term care facility with measured outcomes (accuracy of 0.885 and F1 score of 0.794). While the direct climate impact is minimal, preventing falls can reduce hospital resource usage and potentially lower indirect emissions from healthcare. The technical credibility is supported by a real-world dataset and comparison to baselines.","key_impact_metrics":["Accuracy of 0.885","F1 score of 0.794"],"technology_tags":["Fall prevention","Load cell sensors","Time series classification","Swin Transformer"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:40:18.339714Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce858d7ff028","title":"The Hidden Link Between RLHF and Contrastive Learning","content":"arXiv:2506.22578v2 Announce Type: replace Abstract: Alignment of large language models (LLMs) with human values has recently garnered significant attention, with prominent examples including the canonical yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple Direct Preference Optimization (DPO). In this work, we demonstrate that both RLHF and DPO can be interpreted from the perspective of mutual information (MI) maximization, uncovering a profound connection to contrastive learning. Within this framework, both RLHF and DPO can be interpreted as methods that performing contrastive learning based on the positive and negative samples derived from base model, leveraging the Donsker-Varadhan (DV) lower bound on MI (equivalently, the MINE estimator). Such paradigm further illuminates why RLHF may not intrinsically incentivize reasoning capacities in LLMs beyond what is already present in the base model. Building on the perspective, we replace the DV/MINE bound with the Jensen-Shannon (JS) MI estimator and propose the Mutual Information Optimization (MIO). Comprehensive theoretical analysis and extensive empirical evaluations demonstrate that MIO mitigates the late-stage decline in chosen-likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.22578","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.218738","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Xufei Lv, Kehai Chen, Haoyuan Sun, Xuefeng Bai, Min Zhang, Houde Liu, Kehai Chen","raw_content_length":1363,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":["the Donsker-Varadhan","Reinforcement Learning","DPO","Contrastive Learning arXiv:2506.22578v2 Announce Type","RLHF","Direct Preference Optimization"],"persons":[],"locations":[],"monetary":[]},"char_count":1362,"language_detected":"en","key_concepts":{"key_phrases":["RLHF","The Hidden Link","Contrastive Learning","DPO","arXiv250622578v2 Announce Type","Abstract","Alignment","large language models","LLMs","human values"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RLHF":3.0,"The Hidden Link":2.0,"Contrastive Learning":2.0,"DPO":2.0,"arXiv250622578v2 Announce Type":1.0,"Abstract":1.0,"Alignment":1.0,"large language models":1.0,"LLMs":1.0,"human values":1.0}},"age_hours":2.7680324224999997,"is_recent":true,"quality_score":1.0,"sentiment_score":8.953,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7906,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8654,"joy":0.0391,"surprise":0.0591,"sadness":0.0043,"fear":0.0055,"anger":0.0175,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (MIO) for training LLMs that aims to improve reasoning and mathematical capabilities. The concrete action is the development of a new algorithm and its evaluation on benchmarks. The evidence is based on theoretical analysis and empirical evaluations, but there is no deployment or real-world impact yet.","key_impact_metrics":[],"technology_tags":["Reinforcement Learning","Contrastive Learning","Large Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:40:23.285663Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_193af58bdb81","title":"A Practical and Secure Byzantine Robust Aggregator","content":"arXiv:2506.23183v5 Announce Type: replace Abstract: In machine learning security, one is often faced with the problem of removing outliers from a given set of high-dimensional vectors when computing their average. For example, many variants of data poisoning attacks produce gradient vectors during training that are outliers in the distribution of clean gradients, which bias the computed average used to derive the ML model. Filtering them out before averaging serves as a generic defense strategy. Byzantine robust aggregation is an algorithmic primitive which computes a robust average of vectors, in the presence of an $\\epsilon$ fraction of vectors which may have been arbitrarily and adaptively corrupted, such that the resulting bias in the final average is provably bounded. In this paper, we give the first robust aggregator that runs in quasi-linear time in the size of input vectors and provably has near-optimal bias bounds. Our algorithm also does not assume any knowledge of the distribution of clean vectors, nor does it require pre-computing any filtering thresholds from it. This makes it practical to use directly in standard neural network training procedures. We empirically confirm its expected runtime efficiency and its effectiveness in nullifying 10 different ML poisoning attacks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.23183","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.219118","language":"en","tags":["preprints","research","computer-science","cscr","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"De Zhang Lee, Aashish Kolluri, Prateek Saxena, Ee-Chien Chang","raw_content_length":1309,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":["$\\epsilon$ fraction"]},"char_count":1306,"language_detected":"en","key_concepts":{"key_phrases":["outliers","arXiv250623183v5 Announce Type","Abstract","machine","security","one","the problem","a given set","high-dimensional vectors","their average"],"filter_categories":{"ai_ml":["machine"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"outliers":2.0,"arXiv250623183v5 Announce Type":1.0,"Abstract":1.0,"machine":1.0,"security":1.0,"one":1.0,"the problem":1.0,"a given set":1.0,"high-dimensional vectors":1.0,"their average":1.0}},"age_hours":2.7680479369444444,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8271,"joy":0.0035,"surprise":0.0181,"sadness":0.0123,"fear":0.0601,"anger":0.0358,"disgust":0.0432},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for robust aggregation, which can be used to improve the security of machine learning models. While it has potential to indirectly improve the efficiency of resource use by making ML models more robust and reliable, it is still in the research phase and lacks concrete deployment or quantified environmental benefits. The algorithm is empirically validated, increasing technical credibility.","key_impact_metrics":["Runtime efficiency","Effectiveness in nullifying 10 ML poisoning attacks"],"technology_tags":["Byzantine robust aggregation","Machine learning security"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:40:28.626687Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aa09d56908cd","title":"OmniVCus: Feedforward Subject","content":"arXiv:2506.23361v2 Announce Type: replace Abstract: Existing feedforward subject-driven video customization methods mainly study single-subject scenarios due to the difficulty of constructing multi-subject training data pairs. Another challenging problem that how to use the signals such as depth, mask, camera, and text prompts to control and edit the subject in the customized video is still less explored. In this paper, we first propose a data construction pipeline, VideoCus-Factory, to produce training data pairs for multi-subject customization from raw videos without labels and control signals such as depth-to-video and mask-to-video pairs. Based on our constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with image editing data to enable instructive editing for the subject in the customized video. Then we propose a diffusion Transformer framework, OmniVCus, with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned Embedding (TAE). LE enables inference with more subjects by using the training subjects to activate more frame embeddings. TAE encourages the generation process to extract guidance from temporally aligned control signals by assigning the same frame embeddings to the control and noise tokens. Experiments demonstrate that our method significantly surpasses state-of-the-art methods in both quantitative and qualitative evaluations. Video demos are at our project page: https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released at https://github.com/caiyuanhao1998/Open-OmniVCus","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.23361","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.219523","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Yuanhao Cai, He Zhang, Xi Chen, Jinbo Xing, Yiwei Hu, Yuqian Zhou, Kai Zhang, Zhifei Zhang, Soo Ye Kim, Tianyu Wang, Yulun Zhang, Xiaokang Yang, Zhe Lin, Alan Yuille","raw_content_length":1570,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Image-Video Transfer Mixed","VideoCus-Factory"],"persons":["Lottery Embedding","Temporally Aligne","Feedforward Subject"],"locations":[],"monetary":[]},"char_count":1569,"language_detected":"en","key_concepts":{"key_phrases":["OmniVCus","Feedforward Subject","arXiv250623361v2","Announce Type","Abstract","Existing feedforward subject-driven video customization methods","single-subject scenarios","the difficulty","multi-subject training data pairs","Another challenging problem"],"filter_categories":{"business_innovation":["OmniVCus"],"ai_ml":["multi-subject training data pairs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"OmniVCus":2.0,"Feedforward Subject":2.0,"arXiv250623361v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Existing feedforward subject-driven video customization methods":1.0,"single-subject scenarios":1.0,"the difficulty":1.0,"multi-subject training data pairs":1.0,"Another challenging problem":1.0}},"age_hours":2.7680634200000003,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8908,"joy":0.0071,"surprise":0.0287,"sadness":0.0165,"fear":0.0314,"anger":0.0168,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for subject-driven video customization. While the method demonstrates improvements over existing techniques, it is currently in the applied research stage with no concrete deployment or measurable environmental impact. The technical credibility is moderate due to the experimental results, but economic viability and deployment readiness are low.","key_impact_metrics":["Quantitative evaluation surpassing state-of-the-art methods","Qualitative evaluation surpassing state-of-the-art methods"],"technology_tags":["Diffusion Transformer","Video Customization","Image-Video Transfer Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:40:31.570556Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
