{"id":"science_arxiv_cs_03745a46c17f","title":"OrbitZoo: Multi","content":"arXiv:2504.04160v2 Announce Type: replace Abstract: The increasing number of satellites and orbital debris has made space congestion a critical issue, threatening satellite safety and sustainability. Challenges such as collision avoidance, station-keeping, and orbital maneuvering require advanced techniques to handle dynamic uncertainties and multi-agent interactions. Reinforcement learning (RL) has shown promise in this domain, enabling adaptive, autonomous policies for space operations; however, many existing RL frameworks rely on custom-built environments developed from scratch, which often use simplified models and require significant time to implement and validate the orbital dynamics, limiting their ability to fully capture real-world complexities. To address this, we introduce OrbitZoo, a versatile multi-agent RL environment built on a high-fidelity industry standard library, that enables realistic data generation, supports scenarios like collision avoidance and cooperative maneuvers, and ensures robust and accurate orbital dynamics. The environment is validated against a real satellite constellation, Starlink, achieving a Mean Absolute Percentage Error (MAPE) of 0.16% compared to real-world data. This validation ensures reliability for generating high-fidelity simulations and enabling autonomous and independent satellite operations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.04160","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.147827","language":"en","tags":["cslg","csma","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Alexandre Oliveira, Katarina Dyreby, Francisco Caldas, Cl\\'audia Soares","raw_content_length":1363,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["OrbitZoo"],"persons":[],"locations":[],"monetary":[]},"char_count":1362,"language_detected":"en","key_concepts":{"key_phrases":["OrbitZoo","Multi","arXiv250404160v2 Announce Type","Abstract","The increasing number","satellites","orbital debris","space congestion","a critical issue","satellite safety"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"OrbitZoo":2.0,"Multi":2.0,"arXiv250404160v2 Announce Type":1.0,"Abstract":1.0,"The increasing number":1.0,"satellites":1.0,"orbital debris":1.0,"space congestion":1.0,"a critical issue":1.0,"satellite safety":1.0}},"age_hours":2.7654253841666665,"is_recent":true,"quality_score":1.0,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.134,"joy":0.0045,"surprise":0.0089,"sadness":0.007,"fear":0.823,"anger":0.0188,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a multi-agent RL environment (OrbitZoo) for satellite operations, validated against Starlink data with a MAPE of 0.16%. This high-fidelity simulation environment aims to improve satellite safety and sustainability by enabling autonomous collision avoidance and cooperative maneuvers. While promising, it's still in the applied research phase with no deployed units or customer contracts.","key_impact_metrics":["MAPE of 0.16%"],"technology_tags":["Reinforcement Learning","Satellite Operations","Collision Avoidance"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:25:29.656908Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_251eeecfeefe","title":"Simulating Persuasive Dialogues on Meat Reduction with Generative Agents","content":"arXiv:2504.04872v2 Announce Type: replace Abstract: Meat reduction benefits human and planetary health, but social norms keep meat central in shared meals. To date, the development of communication strategies that promote meat reduction while minimizing social costs has required the costly involvement of human participants at each stage of the process. We present work in progress on simulating multi-round dialogues on meat reduction between Generative Agents based on large language models (LLMs). We measure our main outcome using established psychological questionnaires based on the Theory of Planned Behavior and additionally investigate Social Costs. We find evidence that our preliminary simulations produce outcomes that are (i) consistent with theoretical expectations; and (ii) valid when compared to data from previous studies with human participants. Generative agent-based models are a promising tool for identifying novel communication strategies on meat reduction -- tailored to highly specific participant groups -- to then be tested in subsequent studies with human participants.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.04872","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.148202","language":"en","tags":["computer-science","cscy","csma","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Georg Ahnert, Elena Wurth, Markus Strohmaier, Jutta Mata","raw_content_length":1100,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["the Theory of Planned Behavior","Generative Agents","Social Costs"],"persons":[],"locations":[],"monetary":[]},"char_count":1099,"language_detected":"en","key_concepts":{"key_phrases":["Generative Agents","Simulating Persuasive Dialogues","Meat Reduction","meat reduction","arXiv250404872v2 Announce Type","social norms","meat","shared meals","date","the development"],"filter_categories":{"engineering":["the development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative Agents":3.0,"Simulating Persuasive Dialogues":2.0,"Meat Reduction":2.0,"meat reduction":2.0,"arXiv250404872v2 Announce Type":1.0,"social norms":1.0,"meat":1.0,"shared meals":1.0,"date":1.0,"the development":1.0}},"age_hours":2.7654405597222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.43,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.886,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9399,"joy":0.019,"surprise":0.0077,"sadness":0.0086,"fear":0.0047,"anger":0.0116,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes work in progress on simulating dialogues to promote meat reduction. The concrete action is the development of generative agents, but it's still in the simulation phase. Evidence is based on comparing simulation results to previous human studies, but there are no real-world deployments yet, placing it in the applied research stage.","key_impact_metrics":["Psychological questionnaires based on the Theory of Planned Behavior","Social Costs"],"technology_tags":["Generative Agents","Large Language Models","Behavioral Science"],"sdg_alignment":[2,3,12,13],"analyzed_at":"2025-10-29T12:25:32.876043Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53c0c105dd61","title":"Topology optimization of decoupling feeding networks for antenna arrays","content":"arXiv:2504.07551v2 Announce Type: replace Abstract: Near-field and radiation coupling between nearby radiating elements is unavoidable, and it is considered a limiting factor for applications in wireless communications and active sensing. This article proposes a density-based topology optimization approach to design decoupling networks for such systems. The decoupling networks are designed based on a multi-objective optimization problem with the radiating elements replaced by their time-domain impulse response for efficient computations and to enable the solution of the design problem using gradient-based optimization methods. We use the adjoint-field method to compute the gradients of the optimization objectives. Additionally, nonlinear filters are applied during the optimization procedure to impose minimum-size control on the optimized designs. We demonstrate the concept by designing the decoupling network for a two-element planar antenna array; the antenna is designed in a separate optimization problem. The optimized decoupling networks provide a signal path that destructively interferes with the coupling between the radiating elements while preserving their individual matching to the feeding ports. Compact decoupling networks capable of suppressing the mutual coupling by more than 10 dB between two closely separated planar antennas operating around 2.45 GHz are presented and validated experimentally.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.07551","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.149356","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Pan Lu, Eddie Wadbro, Jonas Starck, Martin Berggren, Emadeldeen Hassan","raw_content_length":1428,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["antenna"],"locations":[],"monetary":[]},"char_count":1427,"language_detected":"en","key_concepts":{"key_phrases":["Topology optimization","feeding networks","antenna arrays","Announce Type","Abstract","Near-field and radiation coupling","nearby radiating elements","a limiting factor","applications","wireless communications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Topology optimization":2.0,"feeding networks":2.0,"antenna arrays":2.0,"Announce Type":1.0,"Abstract":1.0,"Near-field and radiation coupling":1.0,"nearby radiating elements":1.0,"a limiting factor":1.0,"applications":1.0,"wireless communications":1.0}},"age_hours":2.765488043055556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2955,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8591,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7782,"joy":0.0131,"surprise":0.0134,"sadness":0.0644,"fear":0.0512,"anger":0.0252,"disgust":0.0545},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a topology optimization approach for designing decoupling networks in antenna arrays, demonstrating a 10 dB suppression of mutual coupling. This is currently at the applied research stage, with experimental validation but no deployed units. The climate impact is indirect, potentially enabling more efficient wireless communication, but not directly reducing emissions.","key_impact_metrics":["Mutual coupling suppression: 10 dB","Operating frequency: 2.45 GHz"],"technology_tags":["Topology Optimization","Antenna Array","Decoupling Network"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:25:35.994559Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_eess_dac1d77b69cf","title":"Deep Learning","content":"arXiv:2507.10063v2 Announce Type: replace Abstract: This paper proposes a deep learning-based beamforming design framework that directly maps a target beam pattern to optimal beamforming vectors across multiple antenna array architectures, including digital, analog, and hybrid beamforming. The proposed method employs a lightweight encoder-decoder network where the encoder compresses the complex beam pattern into a low-dimensional feature vector and the decoder reconstructs the beamforming vector while satisfying hardware constraints. To address training challenges under diverse and limited channel station information (CSI) conditions, a two-stage training process is introduced, which consists of an offline pre-training for robust feature extraction using an auxiliary module, followed by online training of the decoder with a composite loss function that ensures alignment between the synthesized and target beam patterns in terms of the main lobe shape and side lobe suppression. Simulation results based on NYUSIM-generated channels show that the proposed method can achieve spectral efficiency close to that of fully digital beamforming under limited CSI and outperforms representative existing methods.","source":"science_arxiv_eess","source_type":"rss","url":"https://arxiv.org/abs/2507.10063","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:49.740543","language":"en","tags":["systems","research","eesssp","science"],"metadata":{"feed_title":"eess updates on arXiv.org","source_category":"science","word_count":164,"author":"Hongpu Zhang, Shu Sun, Hangsong Yan, Jianhua Mo","raw_content_length":1217,"priority":6,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["CSI"],"persons":["Deep Learning"],"locations":[],"monetary":[]},"char_count":1216,"language_detected":"en","key_concepts":{"key_phrases":["Deep Learning","arXiv250710063v2 Announce Type","Abstract","This paper","a deep learning-based beamforming design framework","a target beam pattern","optimal beamforming vectors","multiple antenna array architectures","analog","hybrid beamforming"],"filter_categories":{"ai_ml":["Deep Learning","a deep learning-based beamforming design framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deep Learning":2.0,"arXiv250710063v2 Announce Type":1.0,"Abstract":1.0,"This paper":1.0,"a deep learning-based beamforming design framework":1.0,"a target beam pattern":1.0,"optimal beamforming vectors":1.0,"multiple antenna array architectures":1.0,"analog":1.0,"hybrid beamforming":1.0}},"age_hours":2.779382170555556,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8978,"joy":0.0249,"surprise":0.0506,"sadness":0.0048,"fear":0.0044,"anger":0.0114,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a deep learning method for beamforming design, aiming to improve spectral efficiency in wireless communication. Simulation results show performance close to fully digital beamforming, suggesting potential for energy savings in communication networks. However, it is still in the research phase with no deployed units or economic viability data.","key_impact_metrics":["spectral efficiency close to that of fully digital beamforming"],"technology_tags":["deep learning","beamforming","wireless communication"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:25:39.102631Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c4b1aae7a0cf","title":"Constructing Witnesses for Lower Bounds on Behavioural Distances","content":"arXiv:2504.08639v2 Announce Type: replace Abstract: Behavioural distances provide a robust alternative to notions of equivalence such as bisimilarity in the context of probabilistic transition systems. They can be defined as least fixed points, whose universal property allows us to exhibit upper bounds on the distance between states, showing them to be at most some distance apart. In this paper, we instead consider the problem of bounding distances from below, showing states to be at least some distance apart. Contrary to upper bounds, it is possible to reason about lower bounds inductively. We exploit this by giving an inductive derivation system for lower bounds on an existing definition of behavioural distance for labelled Markov chains. This is inspired by recent work on apartness as an inductive counterpart to bisimilarity. Proofs in our system will be shown to closely match the behavioural distance by soundness and (approximate) completeness results. We further provide a constructive correspondence between our derivation system and formulas in a modal logic with quantitative semantics. This logic was used in recent work of Rady and van Breugel to construct evidence for lower bounds on behavioural distances. Our constructions provide smaller witnessing formulas in many examples.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.08639","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.150145","language":"en","tags":["preprints","research","computer-science","cslo","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Ruben Turkenburg, Harsh Beohar, Franck van Breugel, Clemens Kupke, Jurriaan Rot","raw_content_length":1305,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Markov"],"locations":[],"monetary":[]},"char_count":1304,"language_detected":"en","key_concepts":{"key_phrases":["Witnesses","Lower Bounds","Behavioural Distances","states","Announce Type","Abstract","Behavioural distances","a robust alternative","notions","equivalence"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Witnesses":2.0,"Lower Bounds":2.0,"Behavioural Distances":2.0,"states":2.0,"Announce Type":1.0,"Abstract":1.0,"Behavioural distances":1.0,"a robust alternative":1.0,"notions":1.0,"equivalence":1.0}},"age_hours":2.7655186605555557,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9524,"joy":0.007,"surprise":0.0159,"sadness":0.0032,"fear":0.0041,"anger":0.0084,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper focuses on theoretical computer science, specifically on developing a system for proving lower bounds on behavioural distances in probabilistic transition systems. It does not directly address climate change or sustainability, but the underlying mathematical principles could potentially be applied to model and optimize complex systems relevant to sustainability. The research is at a very early stage, with no immediate deployment or measurable impact.","key_impact_metrics":[],"technology_tags":["formal verification","behavioural distance","modal logic"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:25:42.057394Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ac8d735c6d25","title":"VideoAds for Fast","content":"arXiv:2504.09282v2 Announce Type: replace Abstract: Advertisement videos serve as a rich and valuable source of purpose-driven information, encompassing high-quality visual, textual, and contextual cues designed to engage viewers. They are often more complex than general videos of similar duration due to their structured narratives and rapid scene transitions, posing significant challenges to multi-modal large language models (MLLMs). In this work, we introduce VideoAds, the first dataset tailored for benchmarking the performance of MLLMs on advertisement videos. VideoAds comprises well-curated advertisement videos with complex temporal structures, accompanied by \\textbf{manually} annotated diverse questions across three core tasks: visual finding, video summary, and visual reasoning. We propose a quantitative measure to compare VideoAds against existing benchmarks in terms of video complexity. Through extensive experiments, we find that Qwen2.5-VL-72B, an opensource MLLM, achieves 73.35\\% accuracy on VideoAds, outperforming GPT-4o (66.82\\%) and Gemini-1.5 Pro (69.66\\%); the two proprietary models especially fall behind the opensource model in video summarization and reasoning, but perform the best in visual finding. Notably, human experts easily achieve a remarkable accuracy of 94.27\\%. These results underscore the necessity of advancing MLLMs' temporal modeling capabilities and highlight VideoAds as a potentially pivotal benchmark for future research in understanding video that requires high FPS sampling. The dataset and evaluation code will be publicly available at https://videoadsbenchmark.netlify.app.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.09282","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.150572","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Zheyuan Zhang, Monica Dou, Linkai Peng, Hongyi Pan, Ulas Bagci, Boqing Gong","raw_content_length":1634,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["VideoAds"],"persons":[],"locations":[],"monetary":[]},"char_count":1633,"language_detected":"en","key_concepts":{"key_phrases":["VideoAds","Announce Type","Abstract","Advertisement videos","a rich and valuable source","purpose-driven information","high-quality visual textual and contextual cues","viewers","general videos","similar duration"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"VideoAds":3.0,"Announce Type":1.0,"Abstract":1.0,"Advertisement videos":1.0,"a rich and valuable source":1.0,"purpose-driven information":1.0,"high-quality visual textual and contextual cues":1.0,"viewers":1.0,"general videos":1.0,"similar duration":1.0}},"age_hours":2.765534511388889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.403500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8807,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9297,"joy":0.0177,"surprise":0.032,"sadness":0.0025,"fear":0.0066,"anger":0.0083,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new benchmark dataset (VideoAds) for evaluating MLLMs on advertisement videos. While the research itself doesn't directly impact sustainability, improved MLLMs could potentially be used to analyze and identify misleading or harmful advertisements, including those related to unsustainable products or practices. The dataset includes manually annotated questions and a quantitative measure for video complexity, and the paper reports accuracy scores for different MLLMs on the dataset.","key_impact_metrics":["Accuracy on VideoAds: 73.35%"],"technology_tags":["MLLM","Video analysis","Benchmarking"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:25:45.215604Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e2e7ef4822ff","title":"BabyVLM: Data","content":"arXiv:2504.09426v2 Announce Type: replace Abstract: Human infants rapidly develop visual reasoning skills from minimal input, suggesting that developmentally inspired pretraining could significantly enhance the efficiency of vision-language models (VLMs). Although recent efforts have leveraged infant-inspired datasets like SAYCam, existing evaluation benchmarks remain misaligned--they are either too simplistic, narrowly scoped, or tailored for large-scale pretrained models. Additionally, training exclusively on infant data overlooks the broader, diverse input from which infants naturally learn. To address these limitations, we propose BabyVLM, a novel framework comprising comprehensive in-domain evaluation benchmarks and a synthetic training dataset created via child-directed transformations of existing datasets. We demonstrate that VLMs trained with our synthetic dataset achieve superior performance on BabyVLM tasks compared to models trained solely on SAYCam or general-purpose data of the SAYCam size. BabyVLM thus provides a robust, developmentally aligned evaluation tool and illustrates how compact models trained on carefully curated data can generalize effectively, opening pathways toward data-efficient vision-language learning paradigms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.09426","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.151066","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Shengao Wang, Arjun Chandra, Aoming Liu, Venkatesh Saligrama, Boqing Gong","raw_content_length":1263,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["Data arXiv:2504.09426v2"],"persons":[],"locations":[],"monetary":[]},"char_count":1262,"language_detected":"en","key_concepts":{"key_phrases":["BabyVLM","Data","Announce Type","Abstract","Human infants","visual reasoning skills","minimal input","developmentally inspired pretraining","the efficiency","vision-language models"],"filter_categories":{"ai_ml":["Data"],"engineering":["developmentally inspired pretraining"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BabyVLM":2.0,"Data":2.0,"Announce Type":1.0,"Abstract":1.0,"Human infants":1.0,"visual reasoning skills":1.0,"minimal input":1.0,"developmentally inspired pretraining":1.0,"the efficiency":1.0,"vision-language models":1.0}},"age_hours":2.7655488108333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.726,"joy":0.0063,"surprise":0.0713,"sadness":0.0753,"fear":0.0125,"anger":0.0434,"disgust":0.0652},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (BabyVLM) for vision-language models, focusing on data efficiency. While it shows superior performance on BabyVLM tasks, it's still in the research phase with no clear path to deployment or quantified climate impact. The synthetic dataset creation is a concrete action, but the overall impact on sustainability is currently theoretical.","key_impact_metrics":["Superior performance on BabyVLM tasks compared to models trained solely on SAYCam or general-purpose data of the SAYCam size"],"technology_tags":["vision-language models","machine learning","data efficiency"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:25:48.535225Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_75ebfeee046c","title":"Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation","content":"arXiv:2504.09479v2 Announce Type: replace Abstract: Scientific diagrams are vital tools for communicating structured knowledge across disciplines. However, they are often published as static raster images, losing symbolic semantics and limiting reuse. While Multimodal Large Language Models (MLLMs) offer a pathway to bridging vision and structure, existing methods lack semantic control and structural interpretability, especially on complex diagrams. We propose Draw with Thought (DwT), a training-free framework that guides MLLMs to reconstruct diagrams into editable mxGraph XML code through cognitively-grounded Chain-of-Thought reasoning. DwT enables interpretable and controllable outputs without model fine-tuning by dividing the task into two stages: Coarse-to-Fine Planning, which handles perceptual structuring and semantic specification, and Structure-Aware Code Generation, enhanced by format-guided refinement. To support evaluation, we release Plot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard XML annotations. Extensive experiments across eight MLLMs show that our approach yields high-fidelity, semantically aligned, and structurally valid reconstructions, with human evaluations confirming strong alignment in both accuracy and visual aesthetics, offering a scalable solution for converting static visuals into executable representations and advancing machine understanding of scientific graphics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.09479","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.151464","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Zhiqing Cui, Jiahao Yuan, Hanqing Wang, Yanshu Li, Chenxu Du, Zhenglong Ding","raw_content_length":1445,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Structure-Aware Code Generation"],"persons":["DwT","XML"],"locations":[],"monetary":[]},"char_count":1444,"language_detected":"en","key_concepts":{"key_phrases":["Thought","Multimodal Reasoning","Scientific Diagram Generation","Announce Type","Abstract","Scientific diagrams","vital tools","structured knowledge","disciplines","static raster images"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Thought":3.0,"Multimodal Reasoning":2.0,"Scientific Diagram Generation":2.0,"Announce Type":1.0,"Abstract":1.0,"Scientific diagrams":1.0,"vital tools":1.0,"structured knowledge":1.0,"disciplines":1.0,"static raster images":1.0}},"age_hours":2.7655637625,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8419,"joy":0.0059,"surprise":0.0282,"sadness":0.0555,"fear":0.0106,"anger":0.0321,"disgust":0.0258},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the interpretability and reusability of scientific diagrams, which could indirectly support sustainability efforts by improving communication and collaboration in scientific fields. The concrete action is the development of a new framework (DwT) and a benchmark dataset (Plot2XML). The evidence is the experimental results across eight MLLMs, but it is still in the applied research stage with no deployed units.","key_impact_metrics":["247 real-world scientific diagrams","High-fidelity reconstructions"],"technology_tags":["Multimodal Large Language Models","mxGraph XML code"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:25:52.256448Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4c1486d09e54","title":"DUMP: Automated Distribution-Level Curriculum Learning for RL","content":"arXiv:2504.09710v3 Announce Type: replace Abstract: Recent advances in reinforcement learning (RL)-based post-training have led to notable improvements in large language models (LLMs), particularly in enhancing their reasoning capabilities to handle complex tasks. However, most existing methods treat the training data as a unified whole, overlooking the fact that modern LLM training often involves a mixture of data from diverse distributions-varying in both source and difficulty. This heterogeneity introduces a key challenge: how to adaptively schedule training across distributions to optimize learning efficiency. In this paper, we present a principled curriculum learning framework grounded in the notion of distribution-level learnability. Our core insight is that the magnitude of policy advantages reflects how much a model can still benefit from further training on a given distribution. Based on this, we propose a distribution-level curriculum learning framework for RL-based LLM post-training, which leverages the Upper Confidence Bound (UCB) principle to dynamically adjust sampling probabilities for different distrubutions. This approach prioritizes distributions with either high average advantage (exploitation) or low sample count (exploration), yielding an adaptive and theoretically grounded training schedule. We instantiate our curriculum learning framework with GRPO as the underlying RL algorithm and demonstrate its effectiveness on logic reasoning datasets with multiple difficulties and sources. Our experiments show that our framework significantly improves convergence speed and final performance, highlighting the value of distribution-aware curriculum strategies in LLM post-training. Code: https://github.com/ZhentingWang/DUMP.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.09710","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.152270","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":228,"author":"Zhenting Wang, Guofeng Cui, Yu-Jhe Li, Kun Wan, Wentian Zhao","raw_content_length":1764,"priority":7,"update_frequency":1,"reading_time_minutes":1.14,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1763,"language_detected":"en","key_concepts":{"key_phrases":["DUMP","Automated Distribution-Level Curriculum Learning","Announce Type","Abstract","Recent advances","reinforcement learning","RL-based post-training","notable improvements","large language models","LLMs"],"filter_categories":{"ai_ml":["reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DUMP":2.0,"Automated Distribution-Level Curriculum Learning":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"reinforcement learning":1.0,"RL-based post-training":1.0,"notable improvements":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7655943188888887,"is_recent":true,"quality_score":1.0,"sentiment_score":7.735000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.547,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8876,"joy":0.0087,"surprise":0.0699,"sadness":0.0062,"fear":0.004,"anger":0.0153,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a curriculum learning framework to improve the reasoning capabilities of LLMs, which could indirectly contribute to sustainability if LLMs are used to optimize energy consumption, resource allocation, or climate modeling. The paper demonstrates improved convergence speed and final performance on logic reasoning datasets, providing some evidence of effectiveness. However, it's still in the research phase with no clear path to deployment or quantifiable environmental impact.","key_impact_metrics":["Improved convergence speed","Improved final performance"],"technology_tags":["Reinforcement Learning","Large Language Models","Curriculum Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:25:55.597974Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ba42af406893","title":"Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data","content":"arXiv:2504.09895v3 Announce Type: replace Abstract: Large language models~(LLMs) are expected to be helpful, harmless, and honest. In different alignment scenarios, such as safety, confidence, and general preference alignment, binary preference data collection and reward modeling are resource-intensive but play a central role in transferring human preferences. In this work, we explore using the similarity between sampled generations and reference answers as a supplementary reward function for alignment. When unary reference answers are available, such similarity-based rewards can circumvent the need for binary preference data and explicit reward modeling. We introduce \\textit{RefAlign}, a versatile REINFORCE-style alignment algorithm that does not rely on reward or reference models. RefAlign utilizes language generation evaluation metrics, such as BERTScore, between sampled generations and reference answers as surrogate rewards. Beyond general preference optimization, RefAlign can be naturally extended to diverse scenarios, including safety and confidence alignment, by combining similarity-based rewards with task-specific objectives. Across multiple scenarios, RefAlign achieves performance comparable to prior alignment methods while operating without binary preference data or reward models. The code is available at https://github.com/mzhaoshuai/RefAlign.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.09895","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.152681","language":"en","tags":["computer-science","cslg","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Shuai Zhao, Yunqiu Xu, Linchao Zhu, Yi Yang","raw_content_length":1377,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["language models~(LLMs"],"locations":["BERTScore"],"monetary":[]},"char_count":1376,"language_detected":"en","key_concepts":{"key_phrases":["Reference Answers","Binary Human Preference Data","arXiv250409895v3 Announce Type","Abstract","Large language modelsLLMs","different alignment scenarios","safety","confidence","general preference alignment","binary preference data collection"],"filter_categories":{"ai_ml":["Large language modelsLLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reference Answers":2.0,"Binary Human Preference Data":2.0,"arXiv250409895v3 Announce Type":1.0,"Abstract":1.0,"Large language modelsLLMs":1.0,"different alignment scenarios":1.0,"safety":1.0,"confidence":1.0,"general preference alignment":1.0,"binary preference data collection":1.0}},"age_hours":2.765609706666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5055,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9011,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7742,"joy":0.1863,"surprise":0.0142,"sadness":0.0047,"fear":0.0029,"anger":0.0107,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (RefAlign) for aligning large language models with human preferences using similarity-based rewards, potentially reducing the need for resource-intensive binary preference data collection. While the approach is promising and shows comparable performance to existing methods, it is currently in the basic research stage with no deployed units or real-world data on energy consumption or environmental impact. The use of BERTScore as a surrogate reward provides a quantifiable metric, but its direct link to sustainability outcomes is weak.","key_impact_metrics":["BERTScore between sampled generations and reference answers"],"technology_tags":["Large Language Models","AI Alignment","Reinforcement Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:25:59.135508Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_449213580a8c","title":"Forecasting Clinical Risk from Textual Time Series: Structuring Narratives for Temporal AI in Healthcare","content":"arXiv:2504.10340v3 Announce Type: replace Abstract: Clinical case reports encode temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings -- extracted via an LLM-assisted annotation pipeline -- serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.10340","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.153068","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss","raw_content_length":1408,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Healthcare","LLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1407,"language_detected":"en","key_concepts":{"key_phrases":["Clinical Risk","Textual Time Series","Narratives","Temporal AI","Healthcare","arXiv250410340v3 Announce Type","Abstract","Clinical case","encode temporal patient trajectories","traditional machine learning methods"],"filter_categories":{"ai_ml":["Temporal AI","traditional machine learning methods"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Clinical Risk":2.0,"Textual Time Series":2.0,"Narratives":2.0,"Temporal AI":2.0,"Healthcare":2.0,"arXiv250410340v3 Announce Type":1.0,"Abstract":1.0,"Clinical case":1.0,"encode temporal patient trajectories":1.0,"traditional machine learning methods":1.0}},"age_hours":2.7656251094444446,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8389,"joy":0.006,"surprise":0.0241,"sadness":0.01,"fear":0.0919,"anger":0.0203,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores using LLMs to forecast clinical risk from textual time series data. While it has potential to improve healthcare efficiency and resource allocation, it does not directly address climate change or environmental sustainability. The research is in the applied research phase, demonstrating proof of concept with model evaluations and F1 scores.","key_impact_metrics":["F1 scores","Temporal concordance"],"technology_tags":["Large Language Models","Time Series Analysis","Healthcare AI"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:26:01.872916Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8cb2f0cfe038","title":"VLMGuard","content":"arXiv:2504.12661v2 Announce Type: replace Abstract: Aligning Vision-Language Models (VLMs) with safety standards is essential to mitigate risks arising from their multimodal complexity, where integrating vision and language unveils subtle threats beyond the reach of conventional safeguards. Inspired by the insight that reasoning across modalities is key to preempting intricate vulnerabilities, we propose a novel direction for VLM safety: multimodal reasoning-driven prompt rewriting. To this end, we introduce VLMGuard-R1, a proactive framework that refines user inputs through a reasoning-guided rewriter, dynamically interpreting text-image interactions to deliver refined prompts that bolster safety across diverse VLM architectures without altering their core parameters. To achieve this, we devise a three-stage reasoning pipeline to synthesize a dataset that trains the rewriter to infer subtle threats, enabling tailored, actionable responses over generic refusals. Extensive experiments across three benchmarks with five VLMs reveal that VLMGuard-R1 outperforms four baselines. In particular, VLMGuard-R1 achieves a remarkable 43.59\\% increase in average safety across five models on the SIUO benchmark.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12661","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.153918","language":"en","tags":["computer-science","cslg","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Menglan Chen, Xianghe Pang, Jingjing Dong, WenHao Wang, Yaxin Du, Siheng Chen","raw_content_length":1216,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["VLMGuard-R1","VLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1215,"language_detected":"en","key_concepts":{"key_phrases":["VLMGuard","arXiv250412661v2","Announce Type","Abstract","Vision-Language Models","VLMs","safety standards","risks","their multimodal complexity","vision"],"filter_categories":{"ai_ml":["vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"VLMGuard":2.0,"arXiv250412661v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Vision-Language Models":1.0,"VLMs":1.0,"safety standards":1.0,"risks":1.0,"their multimodal complexity":1.0,"vision":1.0}},"age_hours":2.7656538869444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.329,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8658,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5848,"joy":0.015,"surprise":0.016,"sadness":0.0071,"fear":0.353,"anger":0.0193,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel method for improving the safety of Vision-Language Models (VLMs) by rewriting prompts to mitigate potential risks. The concrete action is the development of VLMGuard-R1, a framework that refines user inputs. The evidence supporting claims is the reported 43.59% increase in average safety across five models on the SIUO benchmark. The innovation stage is applied research, as it's a framework tested on benchmarks but not yet deployed in real-world applications.","key_impact_metrics":["43.59% increase in average safety on SIUO benchmark"],"technology_tags":["Vision-Language Models","AI Safety","Prompt Engineering"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:26:05.561887Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a05daa41a21c","title":"Why Ask One When You Can Ask $k$? Learning-to","content":"arXiv:2504.12988v4 Announce Type: replace Abstract: Existing Learning-to-Defer (L2D) frameworks are limited to single-expert deferral, forcing each query to rely on only one expert and preventing the use of collective expertise. We introduce the first framework for Top-$k$ Learning-to-Defer, which allocates queries to the $k$ most cost-effective entities. Our formulation unifies and strictly generalizes prior approaches, including the one-stage and two-stage regimes, selective prediction, and classical cascades. In particular, it recovers the usual Top-1 deferral rule as a special case while enabling principled collaboration with multiple experts when $k>1$. We further propose Top-$k(x)$ Learning-to-Defer, an adaptive variant that learns the optimal number of experts per query based on input difficulty, expert quality, and consultation cost. To enable practical learning, we develop a novel surrogate loss that is Bayes-consistent, $\\mathcal{H}_h$-consistent in the one-stage setting, and $(\\mathcal{H}_r,\\mathcal{H}_g)$-consistent in the two-stage setting. Crucially, this surrogate is independent of $k$, allowing a single policy to be learned once and deployed flexibly across $k$. Experiments across both regimes show that Top-$k$ and Top-$k(x)$ deliver superior accuracy-cost trade-offs, opening a new direction for multi-expert deferral in L2D.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.12988","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.154361","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Yannis Montreuil, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi","raw_content_length":1363,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Existing Learning","Top-$k$ Learning","k>1$."],"locations":[],"monetary":[]},"char_count":1362,"language_detected":"en","key_concepts":{"key_phrases":["You","Learning","arXiv250412988v4 Announce Type","Abstract","Defer","L2D","single-expert deferral","each query","only one expert","the use"],"filter_categories":{"ai_ml":["Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"You":2.0,"Learning":2.0,"arXiv250412988v4 Announce Type":1.0,"Abstract":1.0,"Defer":1.0,"L2D":1.0,"single-expert deferral":1.0,"each query":1.0,"only one expert":1.0,"the use":1.0}},"age_hours":2.765670691388889,"is_recent":true,"quality_score":1.0,"sentiment_score":3.75,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.25,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9247,"joy":0.0079,"surprise":0.0369,"sadness":0.0039,"fear":0.0067,"anger":0.0156,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework for Learning-to-Defer (L2D) that allows for collaboration with multiple experts, improving accuracy-cost trade-offs. The surrogate loss is independent of k, allowing flexible deployment. However, it is currently in the research phase with no deployed units or real-world data, making it vaporware.","key_impact_metrics":["Accuracy-cost trade-offs","Optimal number of experts per query"],"technology_tags":["Learning-to-Defer","Machine Learning","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:26:08.780358Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1772423a523c","title":"An Empirical Study of Python Library Migration Using Large Language Models","content":"arXiv:2504.13272v2 Announce Type: replace Abstract: Library migration is the process of replacing one library with another library that provides similar functionality. Manual library migration is time consuming and error prone, as it requires developers to understand the APIs of both libraries, map them, and perform the necessary code transformations. Large Language Models (LLMs) are shown to be effective at generating and transforming code as well as finding similar code, which are necessary upstream tasks for library migration. Such capabilities suggest that LLMs may be suitable for library migration. Accordingly, this paper investigates the effectiveness of LLMs for migration between Python libraries. We evaluate three LLMs, Llama 3.1, GPT-4o mini, and GPT-4o on PyMigBench, where we migrate 321 real-world library migrations that include 2,989 migration-related code changes. To measure correctness, we (1) compare the LLM's migrated code with the developers' migrated code in the benchmark and (2) run the unit tests available in the client repositories. We find that LLama 3.1, GPT-4o mini, and GPT-4o correctly migrate 89%, 89%, and 94% of the migration-related code changes, respectively. We also find that 36%, 52% and 64% of the LLama 3.1, GPT-4o mini, and GPT-4o migrations pass the same tests that passed in the developer's migration. To ensure the LLMs are not reciting the migrations, we also evaluate them on 10 new repositories where the migration never happened. Overall, our results suggest that LLMs can be effective in migrating code between libraries, but we also identify some open challenges.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.13272","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.154916","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":246,"author":"Md Mohayeminul Islam, Ajay Kumar Jha, May Mahmoud, Ildar Akhmetov, Sarah Nadi","raw_content_length":1626,"priority":7,"update_frequency":1,"reading_time_minutes":1.23,"robust_parsing_used":true,"entities":{"organizations":["Python"],"persons":[],"locations":[],"monetary":[]},"char_count":1625,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","An Empirical Study","Python Library Migration","Announce Type","Abstract","Library migration","the process","one library","another library","similar functionality"],"filter_categories":{"ai_ml":["Large Language Models"],"research_academic":["An Empirical Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"An Empirical Study":2.0,"Python Library Migration":2.0,"Announce Type":1.0,"Abstract":1.0,"Library migration":1.0,"the process":1.0,"one library":1.0,"another library":1.0,"similar functionality":1.0}},"age_hours":2.7656867780555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7966,"joy":0.0354,"surprise":0.0522,"sadness":0.0147,"fear":0.0775,"anger":0.0129,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on using LLMs to automate library migration in Python, potentially reducing developer time and errors. The study evaluates LLMs on a benchmark of real-world library migrations and measures correctness by comparing the LLM's output with developer-migrated code and running unit tests. While promising, it's still in the applied research stage, with no actual deployment in production environments.","key_impact_metrics":["Correctly migrate 89-94% of code changes","Passes 36-64% of tests"],"technology_tags":["Large Language Models","Python","Library Migration"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:26:12.538893Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_46d40578ba1a","title":"Can LLMs Handle WebShell Detection? Overcoming Detection Challenges with Behavioral Function","content":"arXiv:2504.13811v4 Announce Type: replace Abstract: WebShell attacks, where malicious scripts are injected into web servers, pose a significant cybersecurity threat. Traditional ML and DL methods are often hampered by challenges such as the need for extensive training data, catastrophic forgetting, and poor generalization. Recently, Large Language Models have emerged as powerful alternatives for code-related tasks, but their potential in WebShell detection remains underexplored. In this paper, we make two contributions: (1) a comprehensive evaluation of seven LLMs, including GPT-4, LLaMA 3.1 70B, and Qwen 2.5 variants, benchmarked against traditional sequence- and graph-based methods using a dataset of 26.59K PHP scripts, and (2) the Behavioral Function-Aware Detection (BFAD) framework, designed to address the specific challenges of applying LLMs to this domain. Our framework integrates three components: a Critical Function Filter that isolates malicious PHP function calls, a Context-Aware Code Extraction strategy that captures the most behaviorally indicative code segments, and Weighted Behavioral Function Profiling that enhances in-context learning by prioritizing the most relevant demonstrations based on discriminative function-level profiles. Our results show that, stemming from their distinct analytical strategies, larger LLMs achieve near-perfect precision but lower recall, while smaller models exhibit the opposite trade-off. However, all baseline models lag behind previous SOTA methods. With the application of BFAD, the performance of all LLMs improves significantly, yielding an average F1 score increase of 13.82%. Notably, larger models now outperform SOTA benchmarks, while smaller models such as Qwen-2.5-Coder-3B achieve performance competitive with traditional methods. This work is the first to explore the feasibility and limitations of LLMs for WebShell detection and provides solutions to address the challenges in this task.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.13811","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.155353","language":"en","tags":["computer-science","cslg","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":267,"author":"Feijiang Han, Jiaming Zhang, Chuyi Deng, Jianheng Tang, Yunhuai Liu","raw_content_length":1970,"priority":7,"update_frequency":1,"reading_time_minutes":1.335,"robust_parsing_used":true,"entities":{"organizations":["Traditional ML","BFAD","WebShell","K PHP"],"persons":["GPT-4","Qwen 2.5"],"locations":[],"monetary":[]},"char_count":1969,"language_detected":"en","key_concepts":{"key_phrases":["Can LLMs Handle WebShell Detection","Detection Challenges","Behavioral Function","arXiv250413811v4","Announce Type","Abstract","WebShell attacks","malicious scripts","web servers","a significant cybersecurity threat"],"filter_categories":{"ai_ml":["Can LLMs Handle WebShell Detection"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Can LLMs Handle WebShell Detection":2.0,"Detection Challenges":2.0,"Behavioral Function":2.0,"arXiv250413811v4":1.0,"Announce Type":1.0,"Abstract":1.0,"WebShell attacks":1.0,"malicious scripts":1.0,"web servers":1.0,"a significant cybersecurity threat":1.0}},"age_hours":2.765702425,"is_recent":true,"quality_score":1.0,"sentiment_score":0.937,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8126,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3969,"joy":0.0038,"surprise":0.0221,"sadness":0.0192,"fear":0.513,"anger":0.0291,"disgust":0.0159},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework (BFAD) to improve LLM performance in WebShell detection, demonstrating a 13.82% average F1 score increase. While the research shows improved performance with the BFAD framework, it is still in the applied research phase and lacks real-world deployment data. The impact on climate is indirect, as improved cybersecurity can protect critical infrastructure, but this link is not explicitly quantified.","key_impact_metrics":["F1 score increase: 13.82%","Dataset size: 26.59K PHP scripts"],"technology_tags":["Large Language Models","WebShell detection","Cybersecurity"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:26:16.251365Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_852b77809821","title":"Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?","content":"arXiv:2504.13837v3 Announce Type: replace Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly on mathematics and programming tasks. Similar to how traditional RL helps agents explore and learn new strategies, RLVR is believed to enable LLMs to continuously self-improve, thus acquiring novel reasoning abilities beyond those of the corresponding base models. In this study we critically examine the current state of RLVR by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across various model families, RL algorithms, and math, coding, and visual reasoning benchmarks, using pass@k at large k values as the evaluation metric. Surprisingly, we find that the current training setup does not elicit fundamentally new reasoning patterns. While RLVR-trained models outperform their base models at small k (e.g., k = 1), the base models achieve a higher pass@k score when k is large. Coverage and perplexity analyses show that the observed reasoning abilities originate from and are bounded by the base model. Treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in leveraging the potential of the base model. By contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model's reasoning capabilities. Overall, our findings suggest that current RLVR methods have not yet realized the potential of RL to elicit truly novel reasoning abilities in LLMs. This highlights the need for improved RL paradigms, such as continual scaling and multi-turn agent-environment interaction, to unlock this potential.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.13837","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.155813","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":266,"author":"Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang","raw_content_length":1825,"priority":7,"update_frequency":1,"reading_time_minutes":1.33,"robust_parsing_used":true,"entities":{"organizations":["Reinforcement Learning"],"persons":[],"locations":[],"monetary":[]},"char_count":1824,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Reinforcement Learning Really Incentivize Reasoning Capacity","the Base Model","RLVR","arXiv250413837v3","Announce Type","Abstract","Reinforcement Learning","Verifiable Rewards","notable success"],"filter_categories":{"ai_ml":["LLMs","Reinforcement Learning Really Incentivize Reasoning Capacity","Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Reinforcement Learning Really Incentivize Reasoning Capacity":2.0,"the Base Model":2.0,"RLVR":2.0,"arXiv250413837v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Reinforcement Learning":1.0,"Verifiable Rewards":1.0,"notable success":1.0}},"age_hours":2.7657173594444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8555,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8605,"joy":0.0247,"surprise":0.0751,"sadness":0.0038,"fear":0.0069,"anger":0.0207,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes the effectiveness of Reinforcement Learning with Verifiable Rewards (RLVR) in improving the reasoning capabilities of LLMs. The concrete action is the systematic probing of RLVR-trained LLMs using pass@k as the evaluation metric. The evidence supporting the claims comes from quantitative analysis of model performance on math, coding, and visual reasoning benchmarks, coverage and perplexity analyses, and comparison with distillation methods. The stage of deployment is basic research, as it focuses on analyzing existing methods and suggesting improvements.","key_impact_metrics":["pass@k score at large k values","coverage and perplexity of reasoning abilities"],"technology_tags":["Reinforcement Learning","Large Language Models","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:26:19.900702Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_42dea9ab67cf","title":"CodeCrash: Exposing LLM Fragility to Misleading Natural Language in Code Reasoning","content":"arXiv:2504.14119v3 Announce Type: replace Abstract: Large Language Models (LLMs) have recently demonstrated strong capabilities in code-related tasks, but their robustness in code reasoning under perturbations remains underexplored. We introduce CodeCrash, a stress-testing framework with 1,279 questions from CruxEval and LiveCodeBench, designed to evaluate reasoning reliability under structural perturbations and misleading natural language (NL) contexts. Through a systematic evaluation of 17 LLMs, we find that models often shortcut reasoning by over-relying on NL cues, leading to an average performance degradation of 23.2% in output prediction tasks. Even with Chain-of-Thought reasoning, models on average still have a 13.8% drop due to distractibility and rationalization, revealing a lack of critical reasoning capability to distinguish the actual code behaviors. While Large Reasoning Models with internal reasoning mechanisms improve robustness by fostering critical thinking, plausible yet incorrect hints can trigger pathological self-reflection, causing 2-3 times token consumption and even catastrophic cognitive dissonance in extreme cases for QwQ-32B. We refer to this phenomenon as Reasoning Collapse. CodeCrash provides a rigorous benchmark for evaluating robustness in code reasoning, guiding future research and development toward more reliable and resilient models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14119","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.156204","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Man Ho Lam, Chaozheng Wang, Jen-tse Huang, Michael R. Lyu","raw_content_length":1390,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Misleading Natural Language","CodeCrash"],"persons":[],"locations":[],"monetary":[]},"char_count":1389,"language_detected":"en","key_concepts":{"key_phrases":["CodeCrash","LLM Fragility","Natural Language","Code Reasoning","arXiv250414119v3 Announce Type","Large Language Models","LLMs","strong capabilities","code-related tasks","their robustness"],"filter_categories":{"ai_ml":["LLM Fragility","Natural Language","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CodeCrash":3.0,"LLM Fragility":2.0,"Natural Language":2.0,"Code Reasoning":2.0,"arXiv250414119v3 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"strong capabilities":1.0,"code-related tasks":1.0,"their robustness":1.0}},"age_hours":2.7657321586111108,"is_recent":true,"quality_score":1.0,"sentiment_score":2.661,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4678,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.877,"joy":0.0043,"surprise":0.0349,"sadness":0.0177,"fear":0.0221,"anger":0.0264,"disgust":0.0175},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework, CodeCrash, for stress-testing LLMs in code reasoning. It identifies a vulnerability where models over-rely on natural language cues, leading to performance degradation of 23.2% in output prediction tasks. This is currently in the applied research stage, using existing LLMs and a newly developed benchmark.","key_impact_metrics":["Performance degradation of 23.2%","Performance drop of 13.8% with Chain-of-Thought"],"technology_tags":["Large Language Models","Code Reasoning","AI Safety"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:26:23.667228Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6a4de33427be","title":"LSP-ST: Ladder Shape","content":"arXiv:2504.14481v2 Announce Type: replace Abstract: Fine-tuning the Segment Anything Model (SAM) for infrared small target detection poses significant challenges due to severe domain shifts. Existing adaptation methods often incorporate handcrafted priors to bridge this gap, yet such designs limit generalization and scalability. We identify a fundamental texture bias in foundation models, which overly depend on local texture cues for target localization. To address this, we propose Ladder Shape-Biased Side-Tuning (LSP-ST), a novel approach that introduces a shape-aware inductive bias to facilitate effective adaptation beyond texture cues. In contrast to prior work that injects explicit edge or contour features, LSP-ST models shape as a global structural prior, integrating both boundaries and internal layouts. We design a Shape-Enhanced Large-Kernel Attention Module to hierarchically and implicitly capture structural information in a fully differentiable manner, without task-specific handcrafted guidance. A theoretical analysis grounded in matched filtering and backpropagation reveals the mechanism by which the proposed attention improves structure-aware learning. With only 4.72M learnable parameters, LSP-ST achieves state-of-the-art performance on multiple infrared small target detection benchmarks. Furthermore, its strong generalization is validated across tasks such as mirror detection, shadow detection, and camouflaged object detection, while maintaining stable performance on texture-driven tasks like salient object detection, demonstrating that the introduced shape bias complements rather than competes with texture-based reasoning.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14481","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.156625","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Guoyi Zhang, Siyang Chen, Guangsheng Xu, Han Wang, Donghe Wang, Xiaohu Zhang","raw_content_length":1664,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["LSP-ST","the Segment Anything Model (SAM","LSP"],"persons":["Ladder Shape-Biased Side-Tuning"],"locations":[],"monetary":[]},"char_count":1663,"language_detected":"en","key_concepts":{"key_phrases":["LSP-ST Ladder Shape","Announce Type","Abstract","the Segment Anything Model","SAM","infrared small target detection","significant challenges","severe domain shifts","Existing adaptation methods","handcrafted priors"],"filter_categories":{"ai_ml":["severe domain shifts"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LSP-ST Ladder Shape":2.0,"Announce Type":1.0,"Abstract":1.0,"the Segment Anything Model":1.0,"SAM":1.0,"infrared small target detection":1.0,"significant challenges":1.0,"severe domain shifts":1.0,"Existing adaptation methods":1.0,"handcrafted priors":1.0}},"age_hours":2.7657472955555558,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8675,"joy":0.0048,"surprise":0.0245,"sadness":0.0203,"fear":0.0434,"anger":0.024,"disgust":0.0155},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach (LSP-ST) for improving infrared small target detection using a shape-aware inductive bias. The concrete action is the development of a new attention module. The evidence supporting claims is theoretical analysis and benchmark performance. It is currently in the applied research stage, with no deployed units mentioned.","key_impact_metrics":["4.72M learnable parameters","state-of-the-art performance on multiple infrared small target detection benchmarks"],"technology_tags":["infrared small target detection","shape-biased side-tuning","attention module"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:26:27.013125Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8484b2d09725","title":"Retrieval is Not Enough: Enhancing RAG Reasoning through Test","content":"arXiv:2504.14858v4 Announce Type: replace Abstract: Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning and identify a central but underexplored problem: Reasoning Misalignment -- the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval. To address this issue, we propose AlignRAG, a novel iterative framework grounded in Critique-Driven Alignment (CDA). We further introduce AlignRAG-auto, an autonomous variant that dynamically terminates refinement, removing the need to pre-specify the number of critique iterations. At the heart of AlignRAG lies a contrastive critique synthesis mechanism that generates retrieval-sensitive critiques while mitigating self-bias. This mechanism trains a dedicated retrieval-augmented Critic Language Model (CLM) using labeled critiques that distinguish between evidence-aligned and misaligned reasoning. Empirical evaluations show that our approach significantly improves reasoning fidelity. Our 8B-parameter CLM improves performance over the Self-Refine baseline by 12.1% on out-of-domain tasks and outperforms a standard 72B-parameter CLM by 2.2%. Furthermore, AlignRAG-auto achieves this state-of-the-art performance while dynamically determining the optimal number of refinement steps, enhancing efficiency and usability. AlignRAG remains compatible with existing RAG architectures as a plug-and-play module and demonstrates strong robustness under both informative and noisy retrieval scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14858","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.157039","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun","raw_content_length":1831,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["Critique-Driven Alignment","CDA","LLM"],"persons":["Reasoning Misalignment","RAG"],"locations":["AlignRAG"],"monetary":[]},"char_count":1830,"language_detected":"en","key_concepts":{"key_phrases":["Retrieval","RAG Reasoning","Test","RAG","arXiv250414858v4","Announce Type","Abstract","Retrieval-augmented generation","a widely adopted paradigm","knowledge-grounded large language models"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["knowledge-grounded large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Retrieval":2.0,"RAG Reasoning":2.0,"Test":2.0,"RAG":2.0,"arXiv250414858v4":1.0,"Announce Type":1.0,"Abstract":1.0,"Retrieval-augmented generation":1.0,"a widely adopted paradigm":1.0,"knowledge-grounded large language models":1.0}},"age_hours":2.765762741944444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.213,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5574,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9086,"joy":0.0027,"surprise":0.0194,"sadness":0.0275,"fear":0.0126,"anger":0.019,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel RAG framework (AlignRAG) to improve the reasoning fidelity of LLMs, which could indirectly support sustainability efforts by improving the accuracy of information retrieval and analysis related to climate change and other environmental issues. The concrete action is the development and testing of a new algorithm, and the evidence is the reported performance improvement over baseline models. It is currently in the applied research stage, with no known deployments.","key_impact_metrics":["12.1% improvement on out-of-domain tasks","2.2% improvement over 72B-parameter CLM"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","Critique-Driven Alignment"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:26:30.791420Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5af7d0592dfd","title":"Exploring Compositional Generalization (in COGS/ReCOGS_pos) by Transformers using Restricted Access Sequence Processing (RASP)","content":"arXiv:2504.15349v2 Announce Type: replace Abstract: Humans understand new combinations of words encountered if they are combinations of words recognized from different contexts, an ability called Compositional Generalization. The COGS benchmark (Kim and Linzen, 2020) arXiv:2010.05465 reports 0% accuracy for Transformer models on some structural generalizations. We use (Weiss et al., 2021) arXiv:2106.06981's Restricted Access Sequence Processing (RASP), a Transformer-equivalent programming language, to demonstrate that a Transformer Encoder-Decoder can perform COGS and the semantically equivalent ReCOGS_pos (Wu et al., 2024) arXiv:2303.13716 systematically and compositionally: Our RASP models attain near perfect scores on structural generalization splits on COGS (exact match) and ReCOGS_pos (semantic exact match). Our RASP models show the (Re)COGS tasks do not require a hierarchical or tree-structured solution (contrary to (Kim and Linzen, 2020) arXiv:2010.05465, (Yao and Koller, 2022) arXiv:2210.13050, (Murty et al., 2022) arXiv:2305.18741, (Liu et al., 2021) arXiv:2107.06516): we use word-level tokens with an \"embedding\" layer that tags with possible part of speech, applying just once per encoder pass 19 attention-head compatible flat pattern-matching rules (easily identified with specific training examples), shown using grammar coverage (Zeller et al., 2023) to cover the non-recursive aspects of the input grammar, plus masking out prepositional phrases (\"pp noun\") and/or sentential complements (cp) when recognizing grammar patterns and extracting nouns related to the main verb in the sentence, and output the next logical form (LF) token (repeating until the LF is complete). The models do not apply recursive, tree-structured rules like \"np_det pp np -> np_pp -> np\", but score near perfect semantic and string exact match on both COGS and ReCOGS pp recursion, cp recursion using the decoder loop.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.15349","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.158034","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":268,"author":"William Bruns","raw_content_length":1928,"priority":7,"update_frequency":1,"reading_time_minutes":1.34,"robust_parsing_used":true,"entities":{"organizations":["Compositional Generalization","Weiss","Transformer","Restricted Access Sequence Processing","Restricted Access Sequence Processing ("],"persons":["arXiv:2106.06981","Wu et al.","Kim","COGS","al.","Announce Type"],"locations":["Linzen"],"monetary":[]},"char_count":1927,"language_detected":"en","key_concepts":{"key_phrases":["Compositional Generalization","RASP","COGSReCOGS_pos","Transformers","Restricted Access Sequence Processing","words","arXiv250415349v2 Announce Type","Abstract","Humans","new combinations"],"filter_categories":{"ai_ml":["Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Compositional Generalization":3.0,"RASP":3.0,"COGSReCOGS_pos":2.0,"Transformers":2.0,"Restricted Access Sequence Processing":2.0,"words":2.0,"arXiv250415349v2 Announce Type":1.0,"Abstract":1.0,"Humans":1.0,"new combinations":1.0}},"age_hours":2.7657934236111115,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8873,"joy":0.0112,"surprise":0.0832,"sadness":0.0041,"fear":0.0027,"anger":0.0078,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores compositional generalization in language models. While it demonstrates improved performance on specific benchmarks (near perfect scores on COGS and ReCOGS_pos), it's a basic research study with no direct deployment or measurable impact on climate change or sustainability. The research is validated by peer-reviewed publications.","key_impact_metrics":["Near perfect scores on COGS","Near perfect scores on ReCOGS_pos"],"technology_tags":["Transformer models","Natural Language Processing","Restricted Access Sequence Processing (RASP)"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:26:34.011314Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_29dfb0c2f00a","title":"Grasping Deformable Objects via Reinforcement Learning with Cross","content":"arXiv:2504.15595v2 Announce Type: replace Abstract: We consider the problem of grasping deformable objects with soft shells using a robotic gripper. Such objects have a center-of-mass that changes dynamically and are fragile so prone to burst. Thus, it is difficult for robots to generate appropriate control inputs not to drop or break the object while performing manipulation tasks. Multi-modal sensing data could help understand the grasping state through global information (e.g., shapes, pose) from visual data and local information around the contact (e.g., pressure) from tactile data. Although they have complementary information that can be beneficial to use together, fusing them is difficult owing to their different properties. We propose a method based on deep reinforcement learning (DRL) that generates control inputs of a simple gripper from visuo-tactile sensing information. Our method employs a cross-modal attention module in the encoder network and trains it in a self-supervised manner using the loss function of the RL agent. With the multi-modal fusion, the proposed method can learn the representation for the DRL agent from the visuo-tactile sensory data. The experimental result shows that cross-modal attention is effective to outperform other early and late data fusion methods across different environments including unseen robot motions and objects.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.15595","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.158432","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Yonghyun Lee, Sungeun Hong, Min-gu Kim, Gyeonghwan Kim, Changjoo Nam","raw_content_length":1383,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["DRL","Reinforcement Learning with"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1380,"language_detected":"en","key_concepts":{"key_phrases":["Deformable Objects","Reinforcement Learning","Cross","arXiv250415595v2 Announce Type","Abstract","the problem","deformable objects","soft shells","a robotic gripper","Such objects"],"filter_categories":{"ai_ml":["Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Deformable Objects":2.0,"Reinforcement Learning":2.0,"Cross":2.0,"arXiv250415595v2 Announce Type":1.0,"Abstract":1.0,"the problem":1.0,"deformable objects":1.0,"soft shells":1.0,"a robotic gripper":1.0,"Such objects":1.0}},"age_hours":2.765809065833333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.5040000000000004,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0992,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6389,"joy":0.0073,"surprise":0.0286,"sadness":0.0097,"fear":0.1759,"anger":0.0911,"disgust":0.0486},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a reinforcement learning method for grasping deformable objects, which is currently in the applied research stage. While it could potentially improve efficiency in manufacturing or logistics, leading to reduced waste and energy consumption, the impact is theoretical and not yet quantified. The lack of deployment and concrete metrics limits its current sustainability impact.","key_impact_metrics":[],"technology_tags":["robotics","reinforcement learning","computer vision"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:26:38.425963Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c7c21ed786e7","title":"Motion","content":"arXiv:2504.15665v2 Announce Type: replace Abstract: Infrared dim and small target detection presents a significant challenge due to dynamic multi-frame scenarios and weak target signatures in the infrared modality. Traditional low-rank plus sparse models often fail to capture dynamic backgrounds and global spatial-temporal correlations, which results in background leakage or target loss. In this paper, we propose a novel motion-enhanced nonlocal similarity implicit neural representation (INR) framework to address these challenges. We first integrate motion estimation via optical flow to capture subtle target movements, and propose multi-frame fusion to enhance motion saliency. Second, we leverage nonlocal similarity to construct patch tensors with strong low-rank properties, and propose an innovative tensor decomposition-based INR model to represent the nonlocal patch tensor, effectively encoding both the nonlocal low-rankness and spatial-temporal correlations of background through continuous neural representations. An alternating direction method of multipliers is developed for the nonlocal INR model, which enjoys theoretical fixed-point convergence. Experimental results show that our approach robustly separates dim targets from complex infrared backgrounds, outperforming state-of-the-art methods in detection accuracy and robustness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.15665","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.159070","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Pei Liu, Yisi Luo, Wenzhen Wang, Xiangyong Cao","raw_content_length":1357,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["Motion arXiv:2504.15665v2 Announce Type: replace Abstract","INR"],"persons":[],"locations":[],"monetary":[]},"char_count":1356,"language_detected":"en","key_concepts":{"key_phrases":["Motion","arXiv250415665v2 Announce Type","Abstract","Infrared dim","small target detection","a significant challenge","dynamic multi-frame scenarios","weak target signatures","the infrared modality","Traditional low-rank plus sparse models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Motion":2.0,"arXiv250415665v2 Announce Type":1.0,"Abstract":1.0,"Infrared dim":1.0,"small target detection":1.0,"a significant challenge":1.0,"dynamic multi-frame scenarios":1.0,"weak target signatures":1.0,"the infrared modality":1.0,"Traditional low-rank plus sparse models":1.0}},"age_hours":2.7658240375,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8047,"joy":0.0093,"surprise":0.0573,"sadness":0.0352,"fear":0.0348,"anger":0.0302,"disgust":0.0286},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a novel method for infrared dim target detection using motion-enhanced nonlocal similarity implicit neural representation. While it shows improved detection accuracy in experiments, it's still in the research phase with no deployed units or real-world operational data. The climate impact is indirect, potentially aiding in monitoring or security applications that could have some connection to environmental protection, but it's not a primary focus.","key_impact_metrics":["detection accuracy","robustness"],"technology_tags":["infrared detection","neural networks","motion estimation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:26:41.659902Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7c7775a72c11","title":"An Effective Gram Matrix Characterizes Generalization in Deep Networks","content":"arXiv:2504.16450v3 Announce Type: replace Abstract: We derive a differential equation that governs the evolution of the generalization gap when a deep network is trained by gradient descent. This differential equation is controlled by two quantities, a contraction factor that brings together trajectories corresponding to slightly different datasets, and a perturbation factor that accounts for them training on different datasets. We analyze this differential equation to compute an ``effective Gram matrix'' that characterizes the generalization gap in terms of the alignment between this Gram matrix and a certain initial ``residual''. Empirical evaluations on image classification datasets indicate that this analysis can predict the test loss accurately. Further, during training, the residual predominantly lies in the subspace of the effective Gram matrix with the smallest eigenvalues. This indicates that the generalization gap accumulates slowly along the direction of training, charactering a benign training process. We provide novel perspectives for explaining the generalization ability of neural network training with different datasets and architectures through the alignment pattern of the ``residual\" and the ``effective Gram matrix\".","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.16450","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.159496","language":"en","tags":["statml","cslg","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Rubing Yang, Pratik Chaudhari","raw_content_length":1254,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Gram"],"persons":[],"locations":[],"monetary":[]},"char_count":1253,"language_detected":"en","key_concepts":{"key_phrases":["An Effective Gram Matrix","Generalization","Deep Networks","arXiv250416450v3 Announce Type","Abstract","a differential equation","the evolution","the generalization gap","a deep network","gradient descent"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Effective Gram Matrix":2.0,"Generalization":2.0,"Deep Networks":2.0,"arXiv250416450v3 Announce Type":1.0,"Abstract":1.0,"a differential equation":1.0,"the evolution":1.0,"the generalization gap":1.0,"a deep network":1.0,"gradient descent":1.0}},"age_hours":2.765838632222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8878,"joy":0.0129,"surprise":0.0668,"sadness":0.0053,"fear":0.0073,"anger":0.013,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores a novel method for understanding generalization in deep networks, potentially leading to more efficient training and better performing models. While the research shows promise in predicting test loss accurately, it is still in the early stages of development and lacks concrete deployment or quantifiable impact on climate change. The research is primarily theoretical and needs further development to translate into tangible sustainability benefits.","key_impact_metrics":["test loss prediction accuracy"],"technology_tags":["deep learning","neural networks","generalization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:26:44.832596Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_955cf1eb04c7","title":"A Taylor Series Approach to Correction of Input Errors in Gaussian Process Regression","content":"arXiv:2504.18463v2 Announce Type: replace Abstract: Gaussian Processes (GPs) are widely recognized as powerful non-parametric models for regression and classification. Traditional GP frameworks predominantly operate under the assumption that the inputs are either accurately known or subject to zero-mean noise. However, several real-world applications such as mobile sensors have imperfect localization, leading to inputs with biased errors. These biases can typically be estimated through measurements collected over time using, for example, Kalman filters. To avoid recomputation of the entire GP model when better estimates of the inputs used in the training data become available, we introduce a technique for updating a trained GP model to incorporate updated estimates of the inputs. By leveraging the differentiability of the mean and covariance functions derived from the squared exponential kernel, a second-order correction algorithm is developed to update the trained GP models. Precomputed Jacobians and Hessians of kernels enable real-time refinement of the mean and covariance predictions. The efficacy of the developed approach is demonstrated using two simulation studies, with error analyses revealing improvements in both predictive accuracy and uncertainty quantification.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.18463","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.159900","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":177,"author":"Muzaffar Qureshi, Tochukwu Elijah Ogri, Zachary I. Bell, Wanjiku A. Makumi, Rushikesh Kamalapurkar","raw_content_length":1293,"priority":7,"update_frequency":1,"reading_time_minutes":0.885,"robust_parsing_used":true,"entities":{"organizations":["Correction of Input Errors","sec","Gaussian Processes"],"persons":["Kalman"],"locations":[],"monetary":[]},"char_count":1292,"language_detected":"en","key_concepts":{"key_phrases":["A Taylor Series Approach","Correction","Input Errors","Gaussian Process Regression","Announce Type","Gaussian Processes","GPs","powerful non-parametric models","regression","classification"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Taylor Series Approach":2.0,"Correction":2.0,"Input Errors":2.0,"Gaussian Process Regression":2.0,"Announce Type":1.0,"Gaussian Processes":1.0,"GPs":1.0,"powerful non-parametric models":1.0,"regression":1.0,"classification":1.0}},"age_hours":2.765853667777778,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8467,"joy":0.0127,"surprise":0.0532,"sadness":0.013,"fear":0.0268,"anger":0.0273,"disgust":0.0204},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a technique for updating Gaussian Process models with improved input estimates, potentially relevant for mobile sensors used in environmental monitoring or precision agriculture. The impact on climate change is indirect, as it improves the accuracy of models that could be used for climate-related applications. The approach is demonstrated in simulation studies, showing improvements in predictive accuracy.","key_impact_metrics":["Improvements in predictive accuracy","Improvements in uncertainty quantification"],"technology_tags":["Gaussian Process Regression","Error Correction","Machine Learning"],"sdg_alignment":[2,9,13],"analyzed_at":"2025-10-29T12:26:48.691559Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7e41ab13eb49","title":"Sentiment and Social Signals in the Climate Crisis: A Survey on Analyzing Social Media Responses to Extreme Weather Events","content":"arXiv:2504.18837v4 Announce Type: replace Abstract: Extreme weather events driven by climate change, such as wildfires, floods, and heatwaves, prompt significant public reactions on social media platforms. Analyzing the sentiment expressed in these online discussions can offer valuable insights into public perception, inform policy decisions, and enhance emergency responses. Although sentiment analysis has been widely studied in various fields, its specific application to climate-induced events, particularly in real-time, high-impact situations like the 2025 Los Angeles forest fires, remains underexplored. In this survey, we thoroughly examine the methods, datasets, challenges, and ethical considerations related to sentiment analysis of social media content concerning weather and climate change events. We present a detailed taxonomy of approaches, ranging from lexicon-based and machine learning models to the latest strategies driven by large language models (LLMs). Additionally, we discuss data collection and annotation techniques, including weak supervision and real-time event tracking. Finally, we highlight several open problems, such as misinformation detection, multimodal sentiment extraction, and model alignment with human values. Our goal is to guide researchers and practitioners in effectively understanding sentiment during the climate crisis era.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.18837","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.160658","language":"en","tags":["preprints","research","computer-science","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Pouya Shaeri, Yasaman Mohammadpour, Alimohammad Beigi, Ariane Middel","raw_content_length":1377,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["Sentiment and Social Signals","Analyzing Social Media Responses"],"persons":[],"locations":["Los Angeles"],"monetary":[]},"char_count":1376,"language_detected":"en","key_concepts":{"key_phrases":["Sentiment","Social Signals","the Climate Crisis","A Survey","Social Media Responses","Extreme Weather Events","arXiv250418837v4 Announce Type","Abstract","Extreme weather events","climate change"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sentiment":2.0,"Social Signals":2.0,"the Climate Crisis":2.0,"A Survey":2.0,"Social Media Responses":2.0,"Extreme Weather Events":2.0,"arXiv250418837v4 Announce Type":1.0,"Abstract":1.0,"Extreme weather events":1.0,"climate change":1.0}},"age_hours":2.7658810947222223,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5343,"joy":0.0311,"surprise":0.0191,"sadness":0.02,"fear":0.3059,"anger":0.0792,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article is a survey of methods for analyzing social media sentiment related to extreme weather events. While it aims to inform policy and emergency responses, it doesn't directly reduce GHG emissions or deploy any climate technology. The research is still in the early stages, focusing on methodology and data collection.","key_impact_metrics":[],"technology_tags":["sentiment analysis","social media analysis","natural language processing"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T12:26:51.628081Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f5275c221b4","title":"Accurate and Diverse LLM Mathematical Reasoning via Automated PRM","content":"arXiv:2504.19981v3 Announce Type: replace Abstract: Achieving both accuracy and diverse reasoning remains challenging for Large Language Models (LLMs) in complex domains like mathematics. A key bottleneck is evaluating intermediate reasoning steps to guide generation without costly human annotations. To address this, we first introduce a novel Process Reward Model (PRM) trained automatically using Monte Carlo Tree Search coupled with a similarity-based data augmentation technique, effectively capturing step-level reasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks (GFlowNets) to operate at the reasoning step level. Unlike traditional reinforcement learning focused on maximizing a single reward, GFlowNets naturally sample diverse, high-quality solutions proportional to their rewards, as measured by our PRM. Empirical evaluation shows strong improvements in both accuracy and solution diversity on challenging mathematical benchmarks (e.g., +2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective generalization to unseen datasets (+9.4\\% absolute on SAT MATH). Furthermore, we benchmark our PRM against existing open-source reward models, demonstrating superior alignment with reasoning quality and more consistent guidance for downstream generation. Our work demonstrates the potential of PRM-guided, step-level GFlowNets for developing more robust and versatile mathematical reasoning in LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.19981","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.161436","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Adam Younsi, Ahmed Attia, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou","raw_content_length":1452,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["PRM","Large Language Models","Accurate","Process Reward Model","Monte Carlo Tree Search","Automated PRM arXiv:2504.19981v3"],"persons":["Generative Flow Networks"],"locations":[],"monetary":[]},"char_count":1451,"language_detected":"en","key_concepts":{"key_phrases":["Accurate and Diverse LLM Mathematical Reasoning","Automated PRM","arXiv250419981v3 Announce Type","Abstract","both accuracy","diverse reasoning","Large Language Models","LLMs","complex domains","mathematics"],"filter_categories":{"ai_ml":["Accurate and Diverse LLM Mathematical Reasoning","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Accurate and Diverse LLM Mathematical Reasoning":2.0,"Automated PRM":2.0,"arXiv250419981v3 Announce Type":1.0,"Abstract":1.0,"both accuracy":1.0,"diverse reasoning":1.0,"Large Language Models":1.0,"LLMs":1.0,"complex domains":1.0,"mathematics":1.0}},"age_hours":2.7659111008333337,"is_recent":true,"quality_score":1.0,"sentiment_score":9.277,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8554,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.907,"joy":0.012,"surprise":0.0356,"sadness":0.0049,"fear":0.0211,"anger":0.0154,"disgust":0.004},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the accuracy and diversity of LLMs in mathematical reasoning using a Process Reward Model (PRM) and Generative Flow Networks (GFlowNets). The concrete action is the development and testing of this novel approach on mathematical benchmarks, showing improvements in accuracy. However, it is still in the applied research stage with no real-world deployment, limiting its immediate sustainability impact.","key_impact_metrics":["+2.59% absolute accuracy on MATH Level 5","+9.4% absolute on SAT MATH"],"technology_tags":["Large Language Models","Mathematical Reasoning","Process Reward Model","Generative Flow Networks"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:26:54.952043Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_68f1d3edb4c6","title":"DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi","content":"arXiv:2504.20371v3 Announce Type: replace Abstract: Currently, Large Language Models (LLMs) have achieved remarkable results in machine translation. However, their performance in multi-domain translation (MDT) is less satisfactory, the meanings of words can vary across different domains, highlighting the significant ambiguity inherent in MDT. Therefore, evaluating the disambiguation ability of LLMs in MDT, remains an open problem. To this end, we present an evaluation and analysis of LLMs on disambiguation in multi-domain translation (DMDTEval), our systematic evaluation framework consisting of three critical aspects: (1) we construct a translation test set with multi-domain ambiguous word annotation, (2) we curate a diverse set of disambiguation prompt strategies, and (3) we design precise disambiguation metrics, and study the efficacy of various prompt strategies on multiple state-of-the-art LLMs. We conduct comprehensive experiments across 4 language pairs and 13 domains, our extensive experiments reveal a number of crucial findings that we believe will pave the way and also facilitate further research in the critical area of improving the disambiguation of LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.20371","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.161838","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Zhibo Man, Yuanmeng Chen, Yujie Zhang, Jinan Xu","raw_content_length":1185,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["MDT"],"persons":[],"locations":[],"monetary":[]},"char_count":1184,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","MDT","DMDTEval An Evaluation","Analysis","Disambiguation","Multi","arXiv250420371v3 Announce Type","Abstract","Large Language Models","remarkable results"],"filter_categories":{"ai_ml":["LLMs","Large Language Models"],"business_innovation":["Analysis"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":5.0,"MDT":3.0,"DMDTEval An Evaluation":2.0,"Analysis":2.0,"Disambiguation":2.0,"Multi":2.0,"arXiv250420371v3 Announce Type":1.0,"Abstract":1.0,"Large Language Models":1.0,"remarkable results":1.0}},"age_hours":2.7659269980555554,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6785,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7357,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8609,"joy":0.0208,"surprise":0.0583,"sadness":0.0064,"fear":0.0277,"anger":0.0175,"disgust":0.0084},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a framework for evaluating LLMs, but it does not present any concrete actions related to sustainability. The framework itself is in the applied research stage, with no deployment or measurable outcomes related to climate change or other sustainability dimensions. The impact is theoretical at this point.","key_impact_metrics":["Number of language pairs: 4","Number of domains: 13"],"technology_tags":["Large Language Models","Machine Translation"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:26:58.510639Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_30a093ae32aa","title":"WebThinker: Empowering Large Reasoning Models with Deep Research Capability","content":"arXiv:2504.21776v2 Announce Type: replace Abstract: Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities. However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information. To address this, we propose WebThinker, a deep research agent that empowers LRMs to autonomously search the web, navigate among web pages, and draft reports during the reasoning process. WebThinker integrates a Deep Web Explorer module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps. It also employs an Autonomous Think-Search-and-Draft strategy, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time. To further enhance research tool utilization, we introduce an RL-based training strategy via iterative online Direct Preference Optimization (DPO). Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems. Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems. The code is available at https://github.com/RUC-NLPIR/WebThinker.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.21776","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.162675","language":"en","tags":["computer-science","csai","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yongkang Wu, Ji-Rong Wen, Yutao Zhu, Zhicheng Dou","raw_content_length":1536,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["WebThinker","DeepSeek-R1"],"persons":[],"locations":["LRMs"],"monetary":[]},"char_count":1535,"language_detected":"en","key_concepts":{"key_phrases":["WebThinker","Large Reasoning Models","Deep Research Capability","LRMs","arXiv250421776v2","Announce Type","Large reasoning models","OpenAI-o1","DeepSeek-R1","impressive long-horizon reasoning capabilities"],"filter_categories":{"research_academic":["Deep Research Capability"],"ai_ml":["OpenAI-o1"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"WebThinker":3.0,"Large Reasoning Models":2.0,"Deep Research Capability":2.0,"LRMs":2.0,"arXiv250421776v2":1.0,"Announce Type":1.0,"Large reasoning models":1.0,"OpenAI-o1":1.0,"DeepSeek-R1":1.0,"impressive long-horizon reasoning capabilities":1.0}},"age_hours":2.7659586750000003,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8528,"joy":0.0184,"surprise":0.0538,"sadness":0.0144,"fear":0.0296,"anger":0.0228,"disgust":0.0083},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a deep research agent, WebThinker, that enhances large reasoning models' ability to conduct web research and generate reports. The concrete action is the development and testing of this agent on complex reasoning benchmarks. While the research shows improved performance, there are no deployed units or real-world applications yet, placing it at the applied research stage.","key_impact_metrics":["Significantly outperforms existing methods on GPQA","Significantly outperforms existing methods on GAIA"],"technology_tags":["Large Language Models","Web Research Agent","Deep Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:27:01.840097Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b337c2c79115","title":"On the Schr\\\"odingerization method for linear non","content":"arXiv:2505.00370v2 Announce Type: replace Abstract: The Schr\\\"odingerization method converts linear partial and ordinary differential equations with non-unitary dynamics into systems of Schr\\\"odinger-type equations with unitary evolution. It does so via the so-called warped phase transformation that maps the original equation into a Schr\\\"odinger-type equation in one higher dimension \\cite{Schrshort,JLY22SchrLong}. The original proposal used a particular initial function in the auxiliary space that did not achieve optimal scaling in precision. Here we show that, by choosing smoother initial functions in auxiliary space, Schr\\\"odingerization \\textit{can} in fact achieve near optimal and even optimal scaling in matrix queries. We construct three necessary criteria that the initial auxiliary state must satisfy to achieve optimality. This paper presents detailed implementation of four smooth initializations for the Schr\\\"odingerization method: (a) the error function and related functions, (b) the cut-off function, (c) the higher-order polynomial interpolation, and (d) Fourier transform methods. Method (a) achieves optimality and methods (b), (c) and (d) can achieve near-optimality. A detailed analysis of key parameters affecting time complexity is conducted.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.00370","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.163064","language":"en","tags":["computer-science","quant-ph","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Shi Jin, Nana Liu, Chuwen Ma, Yue Yu","raw_content_length":1275,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1274,"language_detected":"en","key_concepts":{"key_phrases":["the Schrodingerization method","arXiv250500370v2 Announce Type","Abstract","The Schrodingerization method converts","partial and ordinary differential equations","non-unitary dynamics","systems","Schrodinger-type equations","unitary evolution","the so-called warped phase transformation"],"filter_categories":{"engineering":["systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Schrodingerization method":2.0,"arXiv250500370v2 Announce Type":1.0,"Abstract":1.0,"The Schrodingerization method converts":1.0,"partial and ordinary differential equations":1.0,"non-unitary dynamics":1.0,"systems":1.0,"Schrodinger-type equations":1.0,"unitary evolution":1.0,"the so-called warped phase transformation":1.0}},"age_hours":2.7659733761111114,"is_recent":true,"quality_score":0.7,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8015,"joy":0.0326,"surprise":0.1428,"sadness":0.0101,"fear":0.0035,"anger":0.0071,"disgust":0.0022},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the Schr\"odingerization method for solving linear differential equations, which has potential applications in various fields, including climate modeling and energy efficiency optimization. The paper presents detailed implementation and analysis of different initialization methods, achieving optimal scaling in matrix queries. However, it is still in the basic research stage with no immediate deployment or economic viability.","key_impact_metrics":["optimal scaling in matrix queries","time complexity analysis"],"technology_tags":["Schr\"odingerization method","linear differential equations"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T12:27:05.541468Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dfe397761447","title":"Large Language Models are overconfident and amplify human bias","content":"arXiv:2505.02151v2 Announce Type: replace Abstract: Large language models (LLMs) are revolutionizing every aspect of society. They are increasingly used in problem-solving tasks to substitute human assessment and reasoning. LLMs are trained on what humans write and are thus exposed to human bias. We evaluate whether LLMs inherit one of the most widespread human biases: overconfidence. We algorithmically construct reasoning problems with known ground truths. We prompt LLMs to answer these problems and assess the confidence in their answers, closely following similar protocols in human experiments. We find that all five LLMs we study are overconfident: they overestimate the probability that their answer is correct between 20% and 60%. Humans have accuracy similar to the more advanced LLMs, but far lower overconfidence. Although humans and LLMs are similarly biased in questions which they are certain they answered correctly, a key difference emerges between them: LLM bias increases sharply relative to humans if they become less sure that their answers are correct. We also show that LLM input has ambiguous effects on human decision making: LLM input leads to an increase in the accuracy, but it more than doubles the extent of overconfidence in the answers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.02151","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.163443","language":"en","tags":["computer-science","cscy","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Fengfei Sun, Ningke Li, Kailong Wang, Lorenz Goette","raw_content_length":1272,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1271,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","human bias","Large Language Models","arXiv250502151v2","Announce Type","Abstract","Large language models","every aspect","society","problem-solving tasks"],"filter_categories":{"ai_ml":["LLMs","Large Language Models","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"human bias":3.0,"Large Language Models":2.0,"arXiv250502151v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Large language models":1.0,"every aspect":1.0,"society":1.0,"problem-solving tasks":1.0}},"age_hours":2.7659884641666665,"is_recent":true,"quality_score":1.0,"sentiment_score":2.0705,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5859,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8997,"joy":0.0039,"surprise":0.0258,"sadness":0.0056,"fear":0.0185,"anger":0.0242,"disgust":0.0223},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research identifies overconfidence and bias amplification in LLMs, which could indirectly impact sustainability efforts if these models are used in decision-making processes related to climate or environmental issues. The study uses algorithmic problems with known ground truths to measure LLM confidence, finding overestimation of correctness between 20% and 60%. This is basic research with no immediate deployment or direct climate impact.","key_impact_metrics":["Overconfidence between 20% and 60%"],"technology_tags":["Large Language Models","AI Bias"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:27:08.890960Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_101685509792","title":"ViDRiP","content":"arXiv:2505.04192v2 Announce Type: replace Abstract: We present ViDRiP-LLaVA, the first large multimodal model (LMM) in computational pathology that integrates three distinct image scenarios, including single patch images, automatically segmented pathology video clips, and manually segmented pathology videos. This integration closely mirrors the natural diagnostic process of pathologists. By generating detailed histological descriptions and culminating in a definitive sign-out diagnosis, ViDRiP-LLaVA bridges visual narratives with diagnostic reasoning. Central to our approach is the ViDRiP-Instruct dataset, comprising 4278 video and diagnosis-specific chain-of-thought instructional pairs sourced from educational histopathology videos on YouTube. Although high-quality data is critical for enhancing diagnostic reasoning, its creation is time-intensive and limited in volume. To overcome this challenge, we transfer knowledge from existing single-image instruction datasets to train on weakly annotated, keyframe-extracted clips, followed by fine-tuning on manually segmented videos. ViDRiP-LLaVA establishes a new benchmark in pathology video analysis and offers a promising foundation for future AI systems that support clinical decision-making through integrated visual and diagnostic reasoning. Our code, data, and model are publicly available at: https://github.com/QuIIL/ViDRiP-LLaVA.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.04192","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.163856","language":"en","tags":["computer-science","csai","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":170,"author":"Trinh T. L. Vuong, Jin Tae Kwak","raw_content_length":1399,"priority":7,"update_frequency":1,"reading_time_minutes":0.85,"robust_parsing_used":true,"entities":{"organizations":["YouTube","LMM"],"persons":[],"locations":[],"monetary":[]},"char_count":1398,"language_detected":"en","key_concepts":{"key_phrases":["ViDRiP","Announce Type","Abstract","ViDRiP-LLaVA","the first large multimodal model","LMM","computational pathology","three distinct image scenarios","single patch images","pathology video clips"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ViDRiP":2.0,"Announce Type":1.0,"Abstract":1.0,"ViDRiP-LLaVA":1.0,"the first large multimodal model":1.0,"LMM":1.0,"computational pathology":1.0,"three distinct image scenarios":1.0,"single patch images":1.0,"pathology video clips":1.0}},"age_hours":2.7660032813888886,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8538,"joy":0.0416,"surprise":0.0875,"sadness":0.0041,"fear":0.004,"anger":0.0067,"disgust":0.0023},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel AI model for pathology video analysis. While it shows promise in improving diagnostic accuracy, its direct impact on climate change is minimal. The model is currently in the applied research stage, with no deployed units or customer contracts, thus limiting its economic viability and deployment readiness.","key_impact_metrics":["4278 video and diagnosis-specific chain-of-thought instructional pairs"],"technology_tags":["AI","Machine Learning","Computational Pathology"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T12:27:11.921008Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ccb4f9b2c6c3","title":"Data Standards in Audiology: A Mixed","content":"arXiv:2505.04728v3 Announce Type: replace Abstract: Objective: This study addresses conceptual issues around data standardisation in audiology, and outlines steps toward achieving it. It reports a survey of the computational audiology community on their current understanding, needs, and preferences concerning data standards. Based on survey findings and a panel discussion, recommendations are made concerning moving forward with standardisation in audiology. Design: Mixed-methods: 1) review of existing standardisation efforts; 2) a survey of the computational audiology community; 3) expert panel discussion in a dedicated session at the 2024 Virtual Conference of Computational Audiology. Sample: Survey: 82 members of the global community; Panel discussion: five experts. Results: A prerequisite for any global audiology database are agreed data standards. Although many are familiar with the general idea, few know of existing initiatives, or have actively participated in them. Ninety percent of respondents expressed willingness to follow or contribute to standardisation efforts. The panel discussed relevant initiatives (e.g. OMOP, openEHR, NOAH) and explored both challenges (around harmonisation) and opportunities (alignment with other medical fields and conversion among approaches). Conclusions: Combining conceptual discussion with stakeholder views, the study offers guidance for implementing interoperable data standards in audiology. It highlights community support, key issues to address, and suggests paths for future work.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.04728","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.164616","language":"en","tags":["eessas","preprints","research","cssd","physicsmed-ph","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Charlotte Vercammen, Antje Heinrich, Christophe Lesimple, Alessia Paglialonga, Jan-Willem A. Wasmann, Mareike Buhl","raw_content_length":1553,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Data Standards in Audiology"],"persons":[],"locations":["Panel"],"monetary":[]},"char_count":1546,"language_detected":"en","key_concepts":{"key_phrases":["Data Standards","Audiology","audiology","Announce Type","Abstract","Objective","This study","conceptual issues","data standardisation","steps"],"filter_categories":{"research_academic":["This study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Data Standards":2.0,"Audiology":2.0,"audiology":2.0,"Announce Type":1.0,"Abstract":1.0,"Objective":1.0,"This study":1.0,"conceptual issues":1.0,"data standardisation":1.0,"steps":1.0}},"age_hours":2.7660328980555557,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8814,"joy":0.0343,"surprise":0.0404,"sadness":0.0129,"fear":0.0102,"anger":0.0111,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article focuses on data standardization in audiology, which has indirect sustainability implications. While data standardization itself doesn't directly reduce emissions, it could facilitate research and development of technologies that improve healthcare access and efficiency, potentially reducing the carbon footprint of healthcare delivery. The study includes a survey and expert panel, providing some evidence for the community's needs and preferences.","key_impact_metrics":[],"technology_tags":["data standardization","audiology","healthcare"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:27:14.880951Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90b6019a96e2","title":"xTrace: A Facial Expressive Behaviour Analysis Tool for Continuous Affect Recognition","content":"arXiv:2505.05043v2 Announce Type: replace Abstract: Recognising expressive behaviours in face videos is a long-standing challenge in Affective Computing. Despite significant advancements in recent years, it still remains a challenge to build a robust and reliable system for naturalistic and in-the-wild facial expressive behaviour analysis in real time. This paper addresses two key challenges in building such a system: (1). The paucity of large-scale labelled facial affect video datasets with extensive coverage of the 2D emotion space, and (2). The difficulty of extracting facial video features that are discriminative, interpretable, robust, and computationally efficient. Toward addressing these challenges, this work introduces xTrace, a robust tool for facial expressive behaviour analysis and predicting continuous values of dimensional emotions, namely valence and arousal, from in-the-wild face videos. To address challenge (1), the proposed affect recognition model is trained on the largest facial affect video data set, containing $\\sim$450k videos that cover most emotion zones in the dimensional emotion space, making xTrace highly versatile in analysing a wide spectrum of naturalistic expressive behaviours. To address challenge (2), xTrace uses facial affect descriptors that are not only explainable, but can also achieve a high degree of accuracy and robustness with low computational complexity. The key components of xTrace are benchmarked against three existing tools: MediaPipe, OpenFace, and Augsburg Affect Toolbox. On an in-the-wild benchmarking set composed of $\\sim$50k videos, xTrace achieves 0.86 mean Concordance Correlation Coefficient (CCC) and on the SEWA test set it achieves 0.75 mean CCC, outperforming existing SOTA by $\\sim$7.1\\%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.05043","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.165021","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":248,"author":"Mani Kumar Tellamekala, Shashank Jaiswal, Thomas Smith, Timur Alamev, Gary McKeown, Anthony Brown, Michel Valstar","raw_content_length":1774,"priority":7,"update_frequency":1,"reading_time_minutes":1.24,"robust_parsing_used":true,"entities":{"organizations":["xTrace"],"persons":[],"locations":[],"monetary":[]},"char_count":1773,"language_detected":"en","key_concepts":{"key_phrases":["xTrace","A Facial Expressive Behaviour Analysis Tool","Continuous Affect Recognition","Announce Type","Abstract","expressive behaviours","face","videos","a long-standing challenge","Affective Computing"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"xTrace":2.0,"A Facial Expressive Behaviour Analysis Tool":2.0,"Continuous Affect Recognition":2.0,"Announce Type":1.0,"Abstract":1.0,"expressive behaviours":1.0,"face":1.0,"videos":1.0,"a long-standing challenge":1.0,"Affective Computing":1.0}},"age_hours":2.7660489116666667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.0175,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4035,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9104,"joy":0.0187,"surprise":0.03,"sadness":0.0051,"fear":0.0198,"anger":0.0119,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a tool for facial expression analysis. While it demonstrates improved accuracy (0.86 CCC on in-the-wild set), it's in the early stages of development and lacks clear connection to sustainability outcomes. The tool is benchmarked against existing tools, but no deployment or real-world application is mentioned.","key_impact_metrics":["0.86 mean CCC","0.75 mean CCC"],"technology_tags":["facial expression analysis","affective computing"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:27:18.080180Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_807db28c3a5d","title":"LiTransProQA: an LLM","content":"arXiv:2505.05423v4 Announce Type: replace Abstract: The impact of Large Language Models (LLMs) has extended into literary domains. However, existing evaluation metrics for literature prioritize mechanical accuracy over artistic expression and tend to overrate machine translation as being superior to human translation from experienced professionals. In the long run, this bias could result in an irreversible decline in translation quality and cultural authenticity. In response to the urgent need for a specialized literary evaluation metric, we introduce LITRANSPROQA, a novel, reference-free, LLM-based question-answering framework designed for literary translation evaluation. LITRANSPROQA integrates humans in the loop to incorporate insights from professional literary translators and researchers, focusing on critical elements in literary quality assessment such as literary devices, cultural understanding, and authorial voice. Our extensive evaluation shows that while literary-finetuned XCOMET-XL yields marginal gains, LITRANSPROQA substantially outperforms current metrics, achieving up to 0.07 gain in correlation and surpassing the best state-of-the-art metrics by over 15 points in adequacy assessments. Incorporating professional translator insights as weights further improves performance, highlighting the value of translator inputs. Notably, LITRANSPROQA reaches an adequacy performance comparable to trained linguistic student evaluators, though it still falls behind experienced professional translators. LITRANSPROQA shows broad applicability to open-source models like LLaMA3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and training-free tool for evaluating literary translations that require local processing due to copyright or ethical considerations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.05423","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.165415","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":225,"author":"Ran Zhang, Wei Zhao, Lieve Macken, Steffen Eger","raw_content_length":1799,"priority":7,"update_frequency":1,"reading_time_minutes":1.125,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","LITRANSPROQA","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1798,"language_detected":"en","key_concepts":{"key_phrases":["LiTransProQA","arXiv250505423v4 Announce Type","Abstract","The impact","Large Language Models","LLMs","literary domains","existing evaluation metrics","literature","mechanical accuracy"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LiTransProQA":2.0,"arXiv250505423v4 Announce Type":1.0,"Abstract":1.0,"The impact":1.0,"Large Language Models":1.0,"LLMs":1.0,"literary domains":1.0,"existing evaluation metrics":1.0,"literature":1.0,"mechanical accuracy":1.0}},"age_hours":2.7660636766666666,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8371,"joy":0.0073,"surprise":0.0557,"sadness":0.0189,"fear":0.0412,"anger":0.0232,"disgust":0.0166},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel LLM framework for literary translation evaluation. While it shows improved performance compared to existing metrics, achieving up to 0.07 gain in correlation and surpassing state-of-the-art metrics by 15 points in adequacy assessments, it's still in the research phase with no clear path to deployment or direct climate impact. The vaporware flag is raised due to the lack of deployed units or operational data.","key_impact_metrics":["correlation gain 0.07","adequacy assessments gain 15 points"],"technology_tags":["Large Language Models","Literary Translation Evaluation"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:27:22.320567Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_59827279d5c0","title":"Adaptive Stress Testing Black","content":"arXiv:2505.05665v2 Announce Type: replace Abstract: Large language models (LLMs) have recently demonstrated success in generalizing across decision-making tasks including planning, control, and prediction, but their tendency to hallucinate unsafe and undesired outputs poses risks. We argue that detecting such failures is necessary, especially in safety-critical scenarios. Existing methods for black-box models often detect hallucinations by identifying inconsistencies across multiple samples. Many of these approaches typically introduce prompt perturbations like randomizing detail order or generating adversarial inputs, with the intuition that a confident model should produce stable outputs. We first perform a manual case study showing that other forms of perturbations (e.g., adding noise, removing sensor details) cause LLMs to hallucinate in a multi-agent driving environment. We then propose a novel method for efficiently searching the space of prompt perturbations using adaptive stress testing (AST) with Monte-Carlo tree search (MCTS). Our AST formulation enables discovery of scenarios and prompts that cause language models to act with high uncertainty or even crash. By generating MCTS prompt perturbation trees across diverse scenarios, we show through extensive experiments that offline analyses can be used at runtime to automatically generate prompts that influence model uncertainty, and to inform real-time trust assessments of an LLM. We further characterize LLMs deployed as planners in a single-agent lunar lander environment and in a multi-agent robot crowd navigation simulation. Overall, ours is one of the first hallucination intervention algorithms to pave a path towards rigorous characterization of black-box LLM planners.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.05665","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.165836","language":"en","tags":["computer-science","csai","preprints","cscl","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell","raw_content_length":1759,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["Adaptive Stress Testing Black arXiv:2505.05665v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1758,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive Stress Testing Black","arXiv250505665v2 Announce Type","Large language models","LLMs","success","decision-making tasks","planning","control","prediction","their tendency"],"filter_categories":{"ai_ml":["Large language models"],"engineering":["control"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive Stress Testing Black":2.0,"arXiv250505665v2 Announce Type":1.0,"Large language models":1.0,"LLMs":1.0,"success":1.0,"decision-making tasks":1.0,"planning":1.0,"control":1.0,"prediction":1.0,"their tendency":1.0}},"age_hours":2.7660783136111107,"is_recent":true,"quality_score":1.0,"sentiment_score":0.7405,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8519,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4606,"joy":0.0047,"surprise":0.0117,"sadness":0.0154,"fear":0.4707,"anger":0.021,"disgust":0.0159},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the safety and reliability of LLMs in decision-making tasks, specifically by detecting and mitigating hallucinations. While it doesn't directly reduce GHG emissions, it could indirectly contribute to sustainability by improving the safety and efficiency of AI-driven systems in various sectors. The research uses MCTS and prompt perturbations to analyze model uncertainty, providing some quantified metrics.","key_impact_metrics":["Model uncertainty reduction","Hallucination detection rate"],"technology_tags":["Large Language Models","Adaptive Stress Testing","Monte-Carlo Tree Search"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:27:25.688397Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ba74b80ef3d6","title":"Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model","content":"arXiv:2505.06538v4 Announce Type: replace Abstract: The rapid development of Multimodal Large Reasoning Models (MLRMs) has demonstrated broad application potential, yet their safety and reliability remain critical concerns that require systematic exploration. To address this gap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs across 5 benchmarks and unveil prevalent safety degradation phenomena in most advanced models. Moreover, our analysis reveals distinct safety patterns across different benchmarks: significant safety degradation is observed across jailbreak robustness benchmarks, whereas safety-awareness benchmarks demonstrate less pronounced degradation. In particular, the long thought process in some scenarios even enhances safety performance. Therefore, it is a potential approach to address safety issues in MLRMs by leveraging the intrinsic reasoning capabilities of the model to detect unsafe intent. To operationalize this insight, we construct a multimodal tuning dataset that incorporates a safety-oriented thought process. Experimental results from fine-tuning existing MLRMs with this dataset effectively enhances the safety on both jailbreak robustness and safety-awareness benchmarks. This study provides a new perspective for developing safe MLRMs. Our dataset is available at https://github.com/xinyuelou/Think-in-Safety.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.06538","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.166211","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Large Reasoning Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Safety","Multimodal Large Reasoning Model","arXiv250506538v4 Announce Type","Abstract","The rapid development","Multimodal Large Reasoning Models","MLRMs","broad application potential","their safety","reliability"],"filter_categories":{"engineering":["The rapid development"],"ai_ml":["MLRMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Safety":2.0,"Multimodal Large Reasoning Model":2.0,"arXiv250506538v4 Announce Type":1.0,"Abstract":1.0,"The rapid development":1.0,"Multimodal Large Reasoning Models":1.0,"MLRMs":1.0,"broad application potential":1.0,"their safety":1.0,"reliability":1.0}},"age_hours":2.7660928000000005,"is_recent":true,"quality_score":1.0,"sentiment_score":9.43,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.886,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8241,"joy":0.0072,"surprise":0.0339,"sadness":0.015,"fear":0.0983,"anger":0.0168,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the safety of AI models, specifically MLRMs, by addressing safety degradation. The concrete action involves constructing a multimodal tuning dataset and fine-tuning existing models. While the study shows enhanced safety on benchmarks, it remains in the applied research stage with no clear path to economic viability or large-scale deployment yet.","key_impact_metrics":["safety degradation across jailbreak robustness benchmarks","safety-awareness benchmarks demonstrate less pronounced degradation"],"technology_tags":["Multimodal Large Reasoning Models","AI Safety"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:27:29.179892Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_99fd54facc79","title":"DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy","content":"arXiv:2505.11032v3 Announce Type: replace Abstract: Garment manipulation is a critical challenge due to the diversity in garment categories, geometries, and deformations. Despite this, humans can effortlessly handle garments, thanks to the dexterity of our hands. However, existing research in the field has struggled to replicate this level of dexterity, primarily hindered by the lack of realistic simulations of dexterous garment manipulation. Therefore, we propose DexGarmentLab, the first environment specifically designed for dexterous (especially bimanual) garment manipulation, which features large-scale high-quality 3D assets for 15 task scenarios, and refines simulation techniques tailored for garment modeling to reduce the sim-to-real gap. Previous data collection typically relies on teleoperation or training expert reinforcement learning (RL) policies, which are labor-intensive and inefficient. In this paper, we leverage garment structural correspondence to automatically generate a dataset with diverse trajectories using only a single expert demonstration, significantly reducing manual intervention. However, even extensive demonstrations cannot cover the infinite states of garments, which necessitates the exploration of new algorithms. To improve generalization across diverse garment shapes and deformations, we propose a Hierarchical gArment-manipuLation pOlicy (HALO). It first identifies transferable affordance points to accurately locate the manipulation area, then generates generalizable trajectories to complete the task. Through extensive experiments and detailed analysis of our method and baseline, we demonstrate that HALO consistently outperforms existing methods, successfully generalizing to previously unseen instances even with significant variations in shape and deformation where others fail. Our project page is available at: https://wayrise.github.io/DexGarmentLab/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11032","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.168574","language":"en","tags":["computer-science","csai","preprints","cscv","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Yuran Wang, Ruihai Wu, Yue Chen, Jiarui Wang, Jiaqi Liang, Ziyu Zhu, Haoran Geng, Jitendra Malik, Pieter Abbeel, Hao Dong","raw_content_length":1914,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1913,"language_detected":"en","key_concepts":{"key_phrases":["DexGarmentLab","Dexterous Garment Manipulation Environment","Generalizable Policy","arXiv250511032v3 Announce Type","Abstract","Garment manipulation","a critical challenge","the diversity","garment categories","geometries"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DexGarmentLab":3.0,"Dexterous Garment Manipulation Environment":2.0,"Generalizable Policy":2.0,"arXiv250511032v3 Announce Type":1.0,"Abstract":1.0,"Garment manipulation":1.0,"a critical challenge":1.0,"the diversity":1.0,"garment categories":1.0,"geometries":1.0}},"age_hours":2.7661834733333333,"is_recent":true,"quality_score":0.7,"sentiment_score":1.3245,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7351,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9288,"joy":0.0108,"surprise":0.0254,"sadness":0.0062,"fear":0.0115,"anger":0.0078,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel environment and policy for garment manipulation. While it has the potential to reduce waste in the garment industry by improving automation and efficiency, it is currently in the basic research phase with no deployed units or quantified environmental impact. The technical credibility is relatively high due to the detailed analysis and comparison with baselines, but the economic viability and deployment readiness are low.","key_impact_metrics":["Generalization to unseen instances","Reduction in manual intervention"],"technology_tags":["Robotics","Reinforcement Learning","Garment Manipulation","Simulation"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:27:32.552047Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8968b6122c6a","title":"Efficient Attention via Pre","content":"arXiv:2505.11040v2 Announce Type: replace Abstract: Recent advances in transformer architectures deeply enhanced long-context language modeling. Among them, HyperAttention achieves competitive efficiency by combining a single-level LSH-based clustering with uniform residual sampling. However, HyperAttention fails to find all significant keys, which in turn raises the overall perplexity. We propose a pre-scoring mechanism that prioritizes significant keys before applying HyperAttention. We introduce three scoring methods: $k$-means and kernel $k$-means clustering, $k$-median clustering, and leverage score-based ranking (inspired by LevAttention) to filter keys effectively. We further replace HyperAttention's original uniform residual sampling, relying exclusively on our pre-scoring mechanism. Experiments on ChatGLM2 (131k token context) reduce perplexity from 12 to 8.3, which outperforms standard HyperAttention. Moreover, when running on the Vision-Transformer (ViT), our method shows that it can guarantee similar accuracy compared with LevAttention, and will surpass LevAttention given specific parameters. Although this method introduces some computational overhead, its combination with HyperAttention achieves up to 20 times faster than FlashAttention, providing a balanced trade-off between speed and modeling accuracy. Our results highlight the effectiveness of integrating pre-scoring into hierarchical attention mechanisms, significantly improving transformer efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11040","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.169074","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Zhexiang Li, Haoyu Wang, Yutong Bao, David Woodruff","raw_content_length":1494,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Pre arXiv:2505.11040v2 Announce Type","Efficient Attention","the Vision-Transforme","LevAttention","HyperAttention","ChatGLM2"],"persons":[],"locations":[],"monetary":["k$-median","k$-means"]},"char_count":1493,"language_detected":"en","key_concepts":{"key_phrases":["HyperAttention","Efficient Attention","Pre","arXiv250511040v2 Announce Type","Abstract","Recent advances","transformer","deeply enhanced long-context language modeling","them","competitive efficiency"],"filter_categories":{"ai_ml":["transformer"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HyperAttention":3.0,"Efficient Attention":2.0,"Pre":2.0,"arXiv250511040v2 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"transformer":1.0,"deeply enhanced long-context language modeling":1.0,"them":1.0,"competitive efficiency":1.0}},"age_hours":2.7661983705555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.626,"joy":0.0067,"surprise":0.269,"sadness":0.0237,"fear":0.0194,"anger":0.0267,"disgust":0.0283},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel pre-scoring mechanism to improve the efficiency of transformer architectures, specifically reducing perplexity in language models. While the method shows promising results in reducing perplexity from 12 to 8.3 on ChatGLM2, it is still in the applied research stage with no evidence of deployment or commercialization. The 20x speedup compared to FlashAttention is a concrete metric, but economic viability remains uncertain without cost analysis.","key_impact_metrics":["perplexity reduction from 12 to 8.3","20 times faster than FlashAttention"],"technology_tags":["transformer architecture","attention mechanism","language modeling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:27:38.268805Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a87dd0489390","title":"SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short","content":"arXiv:2505.11166v2 Announce Type: replace Abstract: Despite advances in pretraining with extended context lengths, large language models (LLMs) still face challenges in effectively utilizing real-world long-context information, primarily due to insufficient long-context alignment caused by data quality issues, training inefficiencies, and the lack of well-designed optimization objectives. To address these limitations, we propose a framework named $\\textbf{S}$h$\\textbf{o}$rt-to-$\\textbf{Lo}$ng $\\textbf{P}$reference $\\textbf{O}$ptimization ($\\textbf{SoLoPO}$), decoupling long-context preference optimization (PO) into two components: short-context PO and short-to-long reward alignment (SoLo-RA), supported by both theoretical and empirical evidence. Specifically, short-context PO leverages preference pairs sampled from short contexts to enhance the model's contextual knowledge utilization ability. Meanwhile, SoLo-RA explicitly encourages reward score consistency utilization for the responses when conditioned on both short and long contexts that contain identical task-relevant information. This facilitates transferring the model's ability to handle short contexts into long-context scenarios. SoLoPO is compatible with mainstream preference optimization algorithms, while substantially improving the efficiency of data construction and training processes. Experimental results show that SoLoPO enhances all these algorithms with respect to stronger length and domain generalization abilities across various long-context benchmarks, while achieving notable improvements in both computational and memory efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11166","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.169492","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Huashan Sun, Shengyi Liao, Yansen Han, Yu Bai, Yang Gao, Cheng Fu, Weizhou Shen, Fanqi Wan, Ming Yan, Ji Zhang, Fei Huang","raw_content_length":1627,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Short arXiv:2505.11166v2 Announce Type: replace Abstract","SoLo-RA"],"persons":[],"locations":[],"monetary":["\\textbf{SoLoPO}$","$\\textbf{P}$reference $\\textbf{O}$ptimization","\\textbf{S}$h$\\textbf{o}$rt"]},"char_count":1626,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","SoLoPO","Unlocking Long-Context Capabilities","arXiv250511166v2 Announce Type","Abstract","advances","extended context lengths","large language models","challenges","real-world long-context information"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"SoLoPO":2.0,"Unlocking Long-Context Capabilities":2.0,"arXiv250511166v2 Announce Type":1.0,"Abstract":1.0,"advances":1.0,"extended context lengths":1.0,"large language models":1.0,"challenges":1.0,"real-world long-context information":1.0}},"age_hours":2.766213483055555,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9199,"joy":0.0068,"surprise":0.029,"sadness":0.0143,"fear":0.0175,"anger":0.0093,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (SoLoPO) for improving the long-context capabilities of LLMs, which could indirectly contribute to sustainability efforts by enhancing the efficiency and effectiveness of AI applications in climate modeling, resource management, and other related fields. The framework demonstrates improvements in computational and memory efficiency, suggesting potential resource savings. However, it's still in the research phase with no deployed units or real-world impact data.","key_impact_metrics":["computational efficiency improvement","memory efficiency improvement"],"technology_tags":["Large Language Models","Preference Optimization","Artificial Intelligence"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:27:44.975950Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f90777846173","title":"A Set","content":"arXiv:2505.11243v2 Announce Type: replace Abstract: Many prediction problems across science and engineering, especially in finance and economics, involve large cross-sections of individual time series, where each unit (e.g., a loan, stock, or customer) is driven by unit-level features and latent cross-sectional dynamics. While sequence models have advanced per-unit temporal prediction, capturing cross-sectional effects often still relies on hand-crafted summary features. We propose Set-Sequence, a model that learns cross-sectional structure directly, enhancing expressivity and eliminating manual feature engineering. At each time step, a permutation-invariant Set module summarizes the unit set; a Sequence module then models each unit's dynamics conditioned on both its features and the learned summary. The architecture accommodates unaligned series, supports varying numbers of units at inference, integrates with standard sequence backbones (e.g., Transformers), and scales linearly in cross-sectional size. Across a synthetic contagion task and two large-scale real-world applications, equity portfolio optimization and loan risk prediction, Set-Sequence significantly outperforms strong baselines, delivering higher Sharpe ratios, improved AUCs, and interpretable cross-sectional summaries.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11243","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.169888","language":"en","tags":["computer-science","cslg","q-fincp","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Elliot L. Epstein, Apaar Sadhwani, Kay Giesecke","raw_content_length":1304,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Sequence"],"persons":["Set-Sequence"],"locations":[],"monetary":[]},"char_count":1303,"language_detected":"en","key_concepts":{"key_phrases":["A Set","arXiv250511243v2","Announce Type","Many prediction problems","science","engineering","finance","economics","sections","individual time series"],"filter_categories":{"ai_ml":["science"],"research_academic":["science"],"engineering":["engineering"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Set":2.0,"arXiv250511243v2":1.0,"Announce Type":1.0,"Many prediction problems":1.0,"science":1.0,"engineering":1.0,"finance":1.0,"economics":1.0,"sections":1.0,"individual time series":1.0}},"age_hours":2.7662289494444443,"is_recent":true,"quality_score":0.7,"sentiment_score":5.5135000000000005,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8517,"joy":0.017,"surprise":0.1011,"sadness":0.0064,"fear":0.0099,"anger":0.0096,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel machine learning model (Set-Sequence) that improves prediction in finance and economics. While it shows improved performance (higher Sharpe ratios, improved AUCs) in equity portfolio optimization and loan risk prediction, the direct climate impact is currently theoretical. It's at the applied research stage, with no mention of real-world deployment yet.","key_impact_metrics":["Higher Sharpe ratios","Improved AUCs"],"technology_tags":["Machine Learning","Time Series Analysis","Portfolio Optimization","Risk Prediction"],"sdg_alignment":[8,9],"analyzed_at":"2025-10-29T12:27:48.400800Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fbbee1fb05a7","title":"Quantization Meets Reasoning: Exploring and Mitigating Degradation of Low","content":"arXiv:2505.11574v3 Announce Type: replace Abstract: Low-bit post-training quantization (PTQ) is a practical route to deploy reasoning-capable LLMs under tight memory and latency budgets, yet it can markedly impair mathematical reasoning (drops up to 69.81% in our harder settings). We address two deployment-critical questions with process-level precision: Where along a step-structured solution does degradation first arise? How to mitigate it while staying in the low-bit regime? Across widely used PTQ methods (AWQ, GPTQ, SmoothQuant), open-source model families (Qwen, LLaMA; 0.5--7B), and math reasoning benchmarks (GSM8K, MATH, AIME), we perform format-aligned chain-of-thought with step-aligned attribution and uncover two robust regularities: (i) PTQ disproportionately elevates method and execution errors relative to high-level conceptual mistakes; and (ii) failures emerge early, with the first vulnerable step flipping and cascading to the final answer. These regularities suggest a general intervention principle: restore local token-level margins exactly at the earliest failure frontier. We instantiate this principle as a lightweight measure$\\rightarrow$locate$\\rightarrow$restore loop that operates directly on the quantized model: detect the first faulty step, construct our \"Silver Bullet\" datasets, and apply small-scale supervised/preference tuning. In our settings, as few as 332 curated examples and 3--5 minutes of compute on a single GPU recover 4-bit weight math reasoning toward the full-precision baseline while preserving PTQ efficiency. Our framework is quantizer- and architecture-agnostic within the evaluated regimes, and turns low-bit degradation from a global accuracy problem into a local, reproducible process intervention.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11574","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.170697","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Zhen Li, Yupeng Su, Songmiao Wang, Runming Yang, Congkai Xie, Aofan Liu, Ming Li, Jiannong Cao, Ngai Wong, Hongxia Yang","raw_content_length":1761,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["GPTQ","Qwen","PTQ","SmoothQuant","AWQ"],"persons":[],"locations":[],"monetary":[]},"char_count":1760,"language_detected":"en","key_concepts":{"key_phrases":["Quantization","Reasoning","Mitigating","Degradation","Low","arXiv250511574v3 Announce Type","Abstract","Low-bit post-training quantization","PTQ","a practical route"],"filter_categories":{"ai_ml":["Low-bit post-training quantization"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Quantization":2.0,"Reasoning":2.0,"Mitigating":2.0,"Degradation":2.0,"Low":2.0,"arXiv250511574v3 Announce Type":1.0,"Abstract":1.0,"Low-bit post-training quantization":1.0,"PTQ":1.0,"a practical route":1.0}},"age_hours":2.7662592588888892,"is_recent":true,"quality_score":1.0,"sentiment_score":1.1749999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.765,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8685,"joy":0.002,"surprise":0.0284,"sadness":0.0198,"fear":0.0306,"anger":0.019,"disgust":0.0316},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of large language models, which indirectly contributes to sustainability by reducing the energy consumption associated with their use. The paper presents a method to recover math reasoning accuracy in low-bit quantized models, using as few as 332 curated examples and 3-5 minutes of compute on a single GPU. While not directly climate-focused, the energy savings from more efficient models can contribute to broader decarbonization efforts.","key_impact_metrics":["69.81% drop in math reasoning","3-5 minutes of compute"],"technology_tags":["quantization","large language models","artificial intelligence"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T12:27:52.105814Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e1015b07480a","title":"Simple and Effective Specialized Representations for Fair Classifiers","content":"arXiv:2505.11740v2 Announce Type: replace Abstract: Fair classification is a critical challenge that has gained increasing importance due to international regulations and its growing use in high-stakes decision-making settings. Existing methods often rely on adversarial learning or distribution matching across sensitive groups; however, adversarial learning can be unstable, and distribution matching can be computationally intensive. To address these limitations, we propose a novel approach based on the characteristic function distance. Our method ensures that the learned representation contains minimal sensitive information while maintaining high effectiveness for downstream tasks. By utilizing characteristic functions, we achieve a more stable and efficient solution compared to traditional methods. Additionally, we introduce a simple relaxation of the objective function that guarantees fairness in common classification models with no performance degradation. Experimental results on benchmark datasets demonstrate that our approach consistently matches or achieves better fairness and predictive accuracy than existing methods. Moreover, our method maintains robustness and computational efficiency, making it a practical solution for real-world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11740","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.171088","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Alberto Sinigaglia, Davide Sartor, Marina Ceccon, Gian Antonio Susto","raw_content_length":1275,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["Fair Classifiers arXiv:2505.11740v2 Announce Type: replace Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1274,"language_detected":"en","key_concepts":{"key_phrases":["Simple and Effective Specialized Representations","Fair Classifiers","adversarial learning","arXiv250511740v2 Announce Type","Abstract","Fair classification","a critical challenge","increasing importance","international regulations","its growing use"],"filter_categories":{"ai_ml":["Fair Classifiers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Simple and Effective Specialized Representations":2.0,"Fair Classifiers":2.0,"adversarial learning":2.0,"arXiv250511740v2 Announce Type":1.0,"Abstract":1.0,"Fair classification":1.0,"a critical challenge":1.0,"increasing importance":1.0,"international regulations":1.0,"its growing use":1.0}},"age_hours":2.7662726630555556,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9363,"joy":0.0118,"surprise":0.0202,"sadness":0.0059,"fear":0.0127,"anger":0.0085,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for fair classification, claiming improvements in stability, efficiency, and fairness compared to existing methods. Experimental results on benchmark datasets are mentioned, suggesting some level of validation, but there's no evidence of real-world deployment or quantified environmental impact. The method is still in the applied research stage.","key_impact_metrics":["Fairness improvement on benchmark datasets","Predictive accuracy on benchmark datasets"],"technology_tags":["Fair classification","Machine learning","Characteristic function distance"],"sdg_alignment":[10,16],"analyzed_at":"2025-10-29T12:28:00.718540Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b8a22e44de30","title":"Incentivize Contribution and Learn Parameters Too: Federated Learning with Strategic Data Owners","content":"arXiv:2505.12010v3 Announce Type: replace Abstract: Classical federated learning (FL) assumes that the clients have a limited amount of noisy data with which they voluntarily participate and contribute towards learning a global, more accurate model in a principled manner. The learning happens in a distributed fashion without sharing the data with the center. However, these methods do not consider the incentive of an agent for participating and contributing to the process, given that data collection and running a distributed algorithm is costly for the clients. The question of rationality of contribution has been asked recently in the literature and some results exist that consider this problem. This paper addresses the question of simultaneous parameter learning and incentivizing contribution in a truthful manner, which distinguishes it from the extant literature. Our first mechanism incentivizes each client to contribute to the FL process at a Nash equilibrium and simultaneously learn the model parameters. We also ensure that agents are incentivized to truthfully reveal information in the intermediate stages of the algorithm. However, this equilibrium outcome can be away from the optimal, where clients contribute with their full data and the algorithm learns the optimal parameters. We propose a second mechanism that enables the full data contribution along with optimal parameter learning. Large scale experiments with real (federated) datasets (CIFAR-10, FEMNIST, and Twitter) show that these algorithms converge quite fast in practice, yield good welfare guarantees and better model performance for all agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12010","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.171912","language":"en","tags":["computer-science","cslg","csma","preprints","csgt","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Drashthi Doshi, Aditya Vema Reddy Kesari, Avishek Ghosh, Swaprava Nath, Suhas S Kowshik","raw_content_length":1636,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["Incentivize Contribution and Learn Parameters Too"],"persons":[],"locations":[],"monetary":[]},"char_count":1635,"language_detected":"en","key_concepts":{"key_phrases":["Incentivize Contribution","Parameters","Federated Learning","Strategic Data Owners","arXiv250512010v3 Announce Type","Abstract","Classical federated learning","the clients","a limited amount","noisy data"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Incentivize Contribution":2.0,"Parameters":2.0,"Federated Learning":2.0,"Strategic Data Owners":2.0,"arXiv250512010v3 Announce Type":1.0,"Abstract":1.0,"Classical federated learning":1.0,"the clients":1.0,"a limited amount":1.0,"noisy data":1.0}},"age_hours":2.7663027658333337,"is_recent":true,"quality_score":1.0,"sentiment_score":1.3900000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.722,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9055,"joy":0.0118,"surprise":0.0048,"sadness":0.0046,"fear":0.013,"anger":0.0326,"disgust":0.0277},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel mechanism for incentivizing data contribution in federated learning, which could indirectly support sustainability efforts by improving model accuracy and efficiency in resource-intensive sectors. The experiments use real datasets (CIFAR-10, FEMNIST, and Twitter), showing convergence and improved model performance, but deployment is still at the pilot stage. The impact is theoretical as it doesn't directly address GHG emissions but could improve the efficiency of models used in climate-related applications.","key_impact_metrics":["Convergence speed","Model performance improvement"],"technology_tags":["Federated Learning","Incentive Mechanism"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:28:04.199580Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d7734fea2369","title":"mCLM: A Modular Chemical Language Model that Generates Functional and Makeable Molecules","content":"arXiv:2505.12565v2 Announce Type: replace Abstract: Despite their ability to understand chemical knowledge, large language models (LLMs) remain limited in their capacity to propose novel molecules with desired functions (e.g., drug-like properties). In addition, the molecules that LLMs propose can often be challenging to make, and are almost never compatible with automated synthesis approaches. To better enable the discovery of functional small molecules, LLMs need to learn a new molecular language that is more effective in predicting properties and inherently synced with automated synthesis technology. Current molecule LLMs are limited by representing molecules based on atoms. In this paper, we argue that just like tokenizing texts into meaning-bearing (sub-)word tokens instead of characters, molecules should be tokenized at the level of functional building blocks, i.e., parts of molecules that bring unique functions and serve as effective building blocks for real-world automated laboratory synthesis. This motivates us to propose mCLM, a modular Chemical-Language Model that comprises a bilingual language model that understands both natural language descriptions of functions and molecular blocks. mCLM front-loads synthesizability considerations while improving the predicted functions of molecules in a principled manner. mCLM, with only 3B parameters, achieves improvements in synthetic accessibility relative to 7 other leading generative AI methods including GPT-5. When tested on 122 out-of-distribution medicines using only building blocks/tokens that are compatible with automated modular synthesis, mCLM outperforms all baselines in property scores and synthetic accessibility. mCLM can also reason on multiple functions and iteratively self-improve to rescue drug candidates that failed late in clinical trials (\"fallen angels\").","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12565","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.172342","language":"en","tags":["cslg","csai","preprints","research","q-bioqm","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Carl Edwards, Chi Han, Gawon Lee, Thao Nguyen, Sara Szymku\\'c, Chetan Kumar Prasad, Bowen Jin, Jiawei Han, Ying Diao, Ge Liu, Hao Peng, Bartosz A. Grzybowski, Martin D. Burke, Heng Ji","raw_content_length":1858,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":["Generates Functional","Makeable Molecules arXiv:2505.12565v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1857,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","mCLM","A Modular Chemical Language Model","Functional and Makeable Molecules","arXiv250512565v2 Announce Type","Abstract","their ability","chemical knowledge","large language models","their capacity"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"mCLM":2.0,"A Modular Chemical Language Model":2.0,"Functional and Makeable Molecules":2.0,"arXiv250512565v2 Announce Type":1.0,"Abstract":1.0,"their ability":1.0,"chemical knowledge":1.0,"large language models":1.0,"their capacity":1.0}},"age_hours":2.7663181397222223,"is_recent":true,"quality_score":1.0,"sentiment_score":8.086,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6172,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8878,"joy":0.0132,"surprise":0.0582,"sadness":0.0081,"fear":0.0115,"anger":0.0136,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel AI model (mCLM) for generating functional and synthesizable molecules, which could accelerate drug discovery and materials science. It demonstrates improvements in synthetic accessibility relative to other AI methods and outperforms baselines in property scores and synthetic accessibility on 122 out-of-distribution medicines. However, it's still in the early stages of development, with no deployed units or customer contracts mentioned, hence the 'vaporware' flag.","key_impact_metrics":["Improvements in synthetic accessibility","Outperforms baselines in property scores"],"technology_tags":["AI","Machine Learning","Drug Discovery","Materials Science","Chemical Synthesis"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T12:28:07.631323Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e546c818a2d9","title":"CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models","content":"arXiv:2505.12677v2 Announce Type: replace Abstract: As Text-to-Image models continue to evolve, so does the risk of generating unsafe, copyrighted, or privacy-violating content. Existing safety interventions - ranging from training data curation and model fine-tuning to inference-time filtering and guidance - often suffer from incomplete concept removal, susceptibility to jail-breaking, computational inefficiency, or collateral damage to unrelated capabilities. In this paper, we introduce CURE, a training-free concept unlearning framework that operates directly in the weight space of pre-trained diffusion models, enabling fast, interpretable, and highly specific suppression of undesired concepts. At the core of our method is the Spectral Eraser, a closed-form, orthogonal projection module that identifies discriminative subspaces using Singular Value Decomposition over token embeddings associated with the concepts to forget and retain. Intuitively, the Spectral Eraser identifies and isolates features unique to the undesired concept while preserving safe attributes. This operator is then applied in a single step update to yield an edited model in which the target concept is effectively unlearned - without retraining, supervision, or iterative optimization. To balance the trade-off between filtering toxicity and preserving unrelated concepts, we further introduce an Expansion Mechanism for spectral regularization which selectively modulates singular vectors based on their relative significance to control the strength of forgetting. All the processes above are in closed-form, guaranteeing extremely efficient erasure in only $2$ seconds. Benchmarking against prior approaches, CURE achieves a more efficient and thorough removal for targeted artistic styles, objects, identities, or explicit content, with minor damage to original generation ability and demonstrates enhanced robustness against red-teaming.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12677","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.172783","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Shristi Das Biswas, Arani Roy, Kaushik Roy","raw_content_length":1931,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["Singular Value Decomposition","the Spectral Eraser","Diffusion Models arXiv:2505.12677v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1930,"language_detected":"en","key_concepts":{"key_phrases":["CURE","Concept","Orthogonal Representation Editing","Diffusion Models","arXiv250512677v2 Announce Type","Abstract","Image","the risk","unsafe copyrighted or privacy-violating content","Existing safety interventions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CURE":3.0,"Concept":2.0,"Orthogonal Representation Editing":2.0,"Diffusion Models":2.0,"arXiv250512677v2 Announce Type":1.0,"Abstract":1.0,"Image":1.0,"the risk":1.0,"unsafe copyrighted or privacy-violating content":1.0,"Existing safety interventions":1.0}},"age_hours":2.766333247222222,"is_recent":true,"quality_score":1.0,"sentiment_score":2.6485000000000003,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4703,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.415,"joy":0.003,"surprise":0.0103,"sadness":0.0403,"fear":0.3789,"anger":0.0863,"disgust":0.0663},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel algorithm for removing undesirable concepts from text-to-image diffusion models, which could indirectly support sustainability by preventing the generation of harmful or misleading content related to environmental issues. The algorithm's effectiveness is demonstrated through benchmarking, achieving concept removal in 2 seconds, but it is still in the research phase with no clear path to deployment or direct climate impact.","key_impact_metrics":["Erasure time: 2 seconds"],"technology_tags":["AI","Diffusion Models","Concept Unlearning"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:28:10.780328Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ab7decb4ef8c","title":"A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low","content":"arXiv:2505.12781v2 Announce Type: replace Abstract: Training high-performing Small Language Models (SLMs) remains costly, even with knowledge distillation and pruning from larger teacher models. Existing work often faces three key challenges: (1) information loss from hard pruning, (2) inefficient alignment of representations, and (3) underutilization of informative activations, particularly from Feed-Forward Networks (FFNs). To address these challenges, we introduce Low-Rank Clone (LRC), an efficient pre-training method that constructs SLMs aspiring to behavioral equivalence with strong teacher models. LRC trains a set of low-rank projection matrices that jointly enable soft pruning by compressing teacher weights, and activation clone by aligning student activations, including FFN signals, with those of the teacher. This unified design maximizes knowledge transfer while removing the need for explicit alignment modules. Extensive experiments with open-source teachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC matches or surpasses state-of-the-art models trained on trillions of tokens--while using only 20B tokens, achieving over 1,000x training efficiency. Our codes and model checkpoints are available at https://github.com/CURRENTF/LowRankClone and https://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12781","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.173175","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu","raw_content_length":1382,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Tokens","FFN","LRC","Small Language Models","Feed-Forward Networks","Token"],"persons":[],"locations":[],"monetary":[]},"char_count":1381,"language_detected":"en","key_concepts":{"key_phrases":["A Token","over 1000 Tokens","Efficient Knowledge Distillation","Low","arXiv250512781v2","Announce Type","Abstract","high-performing Small Language Models","SLMs","knowledge distillation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Token":2.0,"over 1000 Tokens":2.0,"Efficient Knowledge Distillation":2.0,"Low":2.0,"arXiv250512781v2":1.0,"Announce Type":1.0,"Abstract":1.0,"high-performing Small Language Models":1.0,"SLMs":1.0,"knowledge distillation":1.0}},"age_hours":2.7663487966666667,"is_recent":true,"quality_score":1.0,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.6032,"joy":0.0036,"surprise":0.0148,"sadness":0.0665,"fear":0.0971,"anger":0.113,"disgust":0.1018},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a method (LRC) to train smaller language models more efficiently, potentially reducing the energy consumption associated with training large AI models. The claim of 1000x training efficiency is supported by experiments using open-source teacher models and a reduction to 20B tokens. However, it is still in the applied research stage with no deployment data.","key_impact_metrics":["1000x training efficiency","20B tokens used"],"technology_tags":["knowledge distillation","low-rank projection","small language models"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-29T12:28:18.981431Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
