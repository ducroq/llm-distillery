{"id":"science_arxiv_cs_034706a07d39","title":"MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM","content":"arXiv:2510.12245v1 Announce Type: new Abstract: Effectively integrating molecular graph structures with Large Language Models (LLMs) is a key challenge in drug discovery. Most existing multi-modal alignment methods typically process these structures by fine-tuning the LLM or adding a static adapter simultaneously. However, these approaches have two main limitations: (1) it optimizes a shared parameter space across all molecular inputs, limiting the model's ability to capture instance-specific structural features; and (2) fine-tuning the LLM for molecular tasks can lead to catastrophic forgetting, undermining its general reasoning capabilities. In this paper, instead of static task-oriented adaptation, we propose an instance-specific parameter space alignment approach for each molecule on-the-fly. To this end, we introduce Molecule-aware Low-Rank Adaptation (MoRA) that produces a unique set of low-rank adaptation weights for each input molecular graph. These weights are then dynamically injected into a frozen LLM, allowing the model to adapt its reasoning to the structure of each molecular input, while preserving the LLM's core knowledge. Extensive experiments demonstrate that on key molecular tasks, such as chemical reaction prediction and molecular captioning, MoRA's instance-specific dynamic adaptation outperforms statically adapted baselines, including a 14.1% relative improvement in reaction prediction exact match and a 22% reduction in error for quantum property prediction. The code is available at https://github.com/jk-sounds/MoRA.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12245","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.328799","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Tao Yin, Xiaohong Zhang, Jiacheng Zhang, Li Huang, Zhibin Zhang, Yuansong Zeng, Jin Xie, Meng Yan","raw_content_length":1564,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Molecule","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1563,"language_detected":"en","key_concepts":{"key_phrases":["the-fly","LLM","arXiv251012245v1 Announce Type","new Abstract","molecular graph structures","Large Language Models","LLMs","a key challenge","drug discovery","Most existing multi-modal alignment methods"],"filter_categories":{"ai_ml":["LLM","Large Language Models"],"research_academic":["drug discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the-fly":2.0,"LLM":2.0,"arXiv251012245v1 Announce Type":1.0,"new Abstract":1.0,"molecular graph structures":1.0,"Large Language Models":1.0,"LLMs":1.0,"a key challenge":1.0,"drug discovery":1.0,"Most existing multi-modal alignment methods":1.0}},"age_hours":2.740258123611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.43,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.886,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9433,"joy":0.01,"surprise":0.0228,"sadness":0.0038,"fear":0.0046,"anger":0.0103,"disgust":0.0052},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning framework (MoRA) for improving the integration of molecular graph structures with LLMs, which could accelerate drug discovery. The framework demonstrates a 14.1% relative improvement in reaction prediction exact match and a 22% reduction in error for quantum property prediction compared to statically adapted baselines. However, it is still in the research phase with no deployed applications or economic viability demonstrated.","key_impact_metrics":["14.1% relative improvement in reaction prediction exact match","22% reduction in error for quantum property prediction"],"technology_tags":["Machine Learning","Large Language Models","Drug Discovery","Molecular Graph"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T15:46:50.780500Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c54dc71efbf2","title":"PromptFlow: Training Prompts Like Neural Networks","content":"arXiv:2510.12246v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated profound impact on Natural Language Processing (NLP) tasks. However, their effective deployment across diverse domains often require domain-specific adaptation strategies, as generic models may underperform when faced with specialized data distributions. Recent advances in prompt engineering (PE) offer a promising alternative to extensive retraining by refining input instructions to align LLM outputs with task objectives. This paradigm has emerged as a rapid and versatile approach for model fine-tuning. Despite its potential, manual prompt design remains labor-intensive and heavily depends on specialized expertise, often requiring iterative human effort to achieve optimal formulations. To address this limitation, automated prompt engineering methodologies have been developed to systematically generate task-specific prompts. However, current implementations predominantly employ static update rules and lack mechanisms for dynamic strategy selection, resulting in suboptimal adaptation to varying NLP task requirements. Furthermore, most methods treat and update the whole prompts at each step, without considering editing prompt sections at a finer granularity. At last, in particular, the problem of how to recycle experience in LLM is still underexplored. To this end, we propose the PromptFlow, a modular training framework inspired by TensorFlow, which integrates meta-prompts, operators, optimization, and evaluator. Our framework can be equipped with the latest optimization methods and autonomously explores optimal prompt refinement trajectories through gradient-based meta-learning, requiring minimal task-specific training data. Specifically, we devise a reinforcement learning method to recycle experience for LLM in the PE process. Finally, we conduct extensive experiments on various datasets, and demonstrate the effectiveness of PromptFlow.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12246","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.329262","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":255,"author":"Jingyi Wang, Hongyuan Zhu, Ye Niu, Yunhui Deng","raw_content_length":1963,"priority":7,"update_frequency":1,"reading_time_minutes":1.275,"robust_parsing_used":true,"entities":{"organizations":["NLP","Natural Language Processing"],"persons":[],"locations":[],"monetary":[]},"char_count":1962,"language_detected":"en","key_concepts":{"key_phrases":["Neural Networks","arXiv251012246v1 Announce Type","new Abstract","Large Language Models","LLMs","profound impact","NLP","their effective deployment","diverse domains","domain-specific adaptation strategies"],"filter_categories":{"ai_ml":["Neural Networks","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neural Networks":2.0,"arXiv251012246v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"profound impact":1.0,"NLP":1.0,"their effective deployment":1.0,"diverse domains":1.0,"domain-specific adaptation strategies":1.0}},"age_hours":2.7402727327777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3445,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8689,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9044,"joy":0.0144,"surprise":0.0436,"sadness":0.0046,"fear":0.0147,"anger":0.0112,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new framework for automated prompt engineering (PromptFlow) to improve the efficiency of Large Language Models (LLMs). While it aims to reduce the labor-intensive aspect of prompt design, its direct climate impact is theoretical at this stage. The framework is still in the research phase, with no deployed units or real-world data available yet.","key_impact_metrics":["Effectiveness of PromptFlow on various datasets"],"technology_tags":["Large Language Models","Prompt Engineering","Meta-learning","Reinforcement Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:46:59.232136Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_afa1a397d519","title":"Optimal Regularization for Performative Learning","content":"arXiv:2510.12249v1 Announce Type: new Abstract: In performative learning, the data distribution reacts to the deployed model - for example, because strategic users adapt their features to game it - which creates a more complex dynamic than in classical supervised learning. One should thus not only optimize the model for the current data but also take into account that the model might steer the distribution in a new direction, without knowing the exact nature of the potential shift. We explore how regularization can help cope with performative effects by studying its impact in high-dimensional ridge regression. We show that, while performative effects worsen the test risk in the population setting, they can be beneficial in the over-parameterized regime where the number of features exceeds the number of samples. We show that the optimal regularization scales with the overall strength of the performative effect, making it possible to set the regularization in anticipation of this effect. We illustrate this finding through empirical evaluations of the optimal regularization parameter on both synthetic and real-world datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12249","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.329683","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Edwige Cyffers, Alireza Mirrokni, Marco Mondelli","raw_content_length":1141,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Optimal Regularization for Performative Learning arXiv:2510.12249v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1140,"language_detected":"en","key_concepts":{"key_phrases":["Optimal Regularization","Performative Learning","the model","arXiv251012249v1 Announce Type","new Abstract","performative learning","the deployed model","example","strategic users","their features"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Optimal Regularization":2.0,"Performative Learning":2.0,"the model":2.0,"arXiv251012249v1 Announce Type":1.0,"new Abstract":1.0,"performative learning":1.0,"the deployed model":1.0,"example":1.0,"strategic users":1.0,"their features":1.0}},"age_hours":2.7402875886111113,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7265,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3453,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9095,"joy":0.0096,"surprise":0.038,"sadness":0.0051,"fear":0.006,"anger":0.0205,"disgust":0.0112},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores how regularization can help cope with performative effects in machine learning, potentially leading to more robust models in scenarios where data distributions shift due to model deployment. The research provides empirical evaluations on synthetic and real-world datasets, showing that optimal regularization scales with the strength of the performative effect. However, it is still in the basic research phase with no immediate deployment or quantified environmental impact.","key_impact_metrics":["optimal regularization parameter with performative effect strength"],"technology_tags":["machine learning","ridge regression","regularization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:47:04.091025Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a5d2a67df014","title":"DSAS: A Universal Plug-and","content":"arXiv:2510.12251v1 Announce Type: new Abstract: While large language models (LLMs) show considerable promise across various fields, they have notable limitations in handling multi-document question answering (Multi-doc QA) tasks. The first challenge is long-range dependency modeling, where LLMs struggle to focus on key information in long texts, which weakens important semantic connections. Second, most LLMs suffer from the ''lost-in-the-middle'' issue, where they have difficulty processing information in the middle of long inputs. Current solutions either truncate global dependencies or demand costly finetuning, ultimately lacking a universal and simple solution for these challenges. To resolve these limitations, we propose Dual-Stage Adaptive Sharpening (DSAS) containing two modules. (i) The Contextual Gate Weighting (CGW) module alleviates ''lost-in-the-middle'' by assessing paragraph relevance through layer-wise attention tracking and position-aware weighting. (ii) The Reciprocal Attention Suppression (RAS) module enhances focus on critical paragraphs by suppressing information exchange between key and irrelevant texts, thus mitigating the limitations in long-range dependency modeling. Notably, DSAS functions as a plug-and-play solution requiring no architectural modifications or extra training parameters. Extensive experiments on four benchmarks demonstrate DSAS's efficacy across mainstream LLMs (Llama, Qwen, Mistral, and Deepseek), with an average F1-score improvement of 4.2% in Multi-doc QA tasks on Llama-3.1-8B-Instruct and Qwen2.5-14B-Instruct. Ablation studies confirm the essential contributions of both the CGW and RAS modules. In addition, detailed discussions in the Appendix further validate the robustness and scalability of DSAS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12251","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.330115","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Jiakai Li, Rongzheng Wang, Yizhuo Ma, Shuang Liang, Guangchun Luo, Ke Qin","raw_content_length":1773,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["Dual-Stage Adaptive Sharpening","CGW"],"persons":[],"locations":[],"monetary":[]},"char_count":1772,"language_detected":"en","key_concepts":{"key_phrases":["DSAS","A Universal Plug","LLMs","new Abstract","large language models","considerable promise","various fields","notable limitations","multi-document question","Multi"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DSAS":2.0,"A Universal Plug":2.0,"LLMs":2.0,"new Abstract":1.0,"large language models":1.0,"considerable promise":1.0,"various fields":1.0,"notable limitations":1.0,"multi-document question":1.0,"Multi":1.0}},"age_hours":2.740303959722222,"is_recent":true,"quality_score":1.0,"sentiment_score":1.3715,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7257,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7429,"joy":0.0031,"surprise":0.0224,"sadness":0.1312,"fear":0.0338,"anger":0.0175,"disgust":0.0491},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (DSAS) to improve the performance of LLMs in multi-document question answering. The concrete action is the development of two modules (CGW and RAS) that address limitations in long-range dependency modeling and the 'lost-in-the-middle' issue. Evidence supporting the claims comes from experiments on four benchmarks, showing an average F1-score improvement of 4.2% on Llama-3.1-8B-Instruct and Qwen2.5-14B-Instruct. This is currently at the basic research stage, with no deployed units or economic viability demonstrated.","key_impact_metrics":["F1-score improvement of 4.2%"],"technology_tags":["Large Language Models","Multi-document Question Answering","Attention Mechanisms"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:47:07.310492Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b9a85ad7f572","title":"Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development","content":"arXiv:2510.12253v1 Announce Type: new Abstract: Diffusion Models (DMs), as a leading class of generative models, offer key advantages for reinforcement learning (RL), including multi-modal expressiveness, stable training, and trajectory-level planning. This survey delivers a comprehensive and up-to-date synthesis of diffusion-based RL. We first provide an overview of RL, highlighting its challenges, and then introduce the fundamental concepts of DMs, investigating how they are integrated into RL frameworks to address key challenges in this research field. We establish a dual-axis taxonomy that organizes the field along two orthogonal dimensions: a function-oriented taxonomy that clarifies the roles DMs play within the RL pipeline, and a technique-oriented taxonomy that situates implementations across online versus offline learning regimes. We also provide a comprehensive examination of this progression from single-agent to multi-agent domains, thereby forming several frameworks for DM-RL integration and highlighting their practical utility. Furthermore, we outline several categories of successful applications of diffusion-based RL across diverse domains, discuss open research issues of current methodologies, and highlight key directions for future research to advance the field. Finally, we summarize the survey to identify promising future development directions. We are actively maintaining a GitHub repository (https://github.com/ChangfuXu/D4RL-FTD) for papers and other related resources to apply DMs for RL.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12253","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.330932","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Changfu Xu, Jianxiong Guo, Yuzhu Liang, Haiyang Huang, Haodong Zou, Xi Zheng, Shui Yu, Xiaowen Chu, Jiannong Cao, Tian Wang","raw_content_length":1533,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["Development arXiv:2510.12253v1 Announce Type","Diffusion Models for Reinforcement Learning: Foundations"],"persons":[],"locations":[],"monetary":[]},"char_count":1532,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Models","Reinforcement Learning","Foundations","Taxonomy","Development","DMs","arXiv251012253v1 Announce Type","new Abstract","a leading class","generative models"],"filter_categories":{"ai_ml":["Reinforcement Learning"],"engineering":["Development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Models":3.0,"Reinforcement Learning":2.0,"Foundations":2.0,"Taxonomy":2.0,"Development":2.0,"DMs":2.0,"arXiv251012253v1 Announce Type":1.0,"new Abstract":1.0,"a leading class":1.0,"generative models":1.0}},"age_hours":2.7403341286111114,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9383,"joy":0.0229,"surprise":0.0188,"sadness":0.0025,"fear":0.0059,"anger":0.008,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper is a survey of diffusion models for reinforcement learning. It's primarily theoretical and focuses on the integration of diffusion models into RL frameworks. There are no concrete deployments or measured outcomes related to sustainability, but the technical credibility is relatively high due to its academic nature.","key_impact_metrics":[],"technology_tags":["diffusion models","reinforcement learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:47:18.068977Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f90ca2cb674c","title":"Shallow Robustness, Deep Vulnerabilities: Multi","content":"arXiv:2510.12255v1 Announce Type: new Abstract: Large language models (LLMs) are rapidly transitioning into medical clinical use, yet their reliability under realistic, multi-turn interactions remains poorly understood. Existing evaluation frameworks typically assess single-turn question answering under idealized conditions, overlooking the complexities of medical consultations where conflicting input, misleading context, and authority influence are common. We introduce MedQA-Followup, a framework for systematically evaluating multi-turn robustness in medical question answering. Our approach distinguishes between shallow robustness (resisting misleading initial context) and deep robustness (maintaining accuracy when answers are challenged across turns), while also introducing an indirect-direct axis that separates contextual framing (indirect) from explicit suggestion (direct). Using controlled interventions on the MedQA dataset, we evaluate five state-of-the-art LLMs and find that while models perform reasonably well under shallow perturbations, they exhibit severe vulnerabilities in multi-turn settings, with accuracy dropping from 91.2% to as low as 13.5% for Claude Sonnet 4. Counterintuitively, indirect, context-based interventions are often more harmful than direct suggestions, yielding larger accuracy drops across models and exposing a significant vulnerability for clinical deployment. Further compounding analyses reveal model differences, with some showing additional performance drops under repeated interventions while others partially recovering or even improving. These findings highlight multi-turn robustness as a critical but underexplored dimension for safe and reliable deployment of medical LLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12255","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.331739","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Blazej Manczak, Eric Lin, Francisco Eiras, James O' Neill, Vaikkunth Mugunthan","raw_content_length":1737,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1736,"language_detected":"en","key_concepts":{"key_phrases":["Shallow Robustness","Deep Vulnerabilities","Multi","new Abstract","Large language models","LLMs","medical clinical use","their reliability","multi-turn interactions","Existing evaluation frameworks"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Shallow Robustness":2.0,"Deep Vulnerabilities":2.0,"Multi":2.0,"new Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"medical clinical use":1.0,"their reliability":1.0,"multi-turn interactions":1.0,"Existing evaluation frameworks":1.0}},"age_hours":2.740362277777778,"is_recent":true,"quality_score":0.7,"sentiment_score":2.798,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4404,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5696,"joy":0.0072,"surprise":0.112,"sadness":0.0188,"fear":0.1035,"anger":0.0366,"disgust":0.1523},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on the robustness of LLMs in medical question answering. While the research is technically sound and uses specific metrics like accuracy dropping from 91.2% to 13.5% for Claude Sonnet 4, it's still in the early stages of development and doesn't have direct climate impact. The vaporware flag is raised because it's a prototype evaluation, not a deployed system.","key_impact_metrics":["accuracy dropping from 91.2% to 13.5%","accuracy drops across models"],"technology_tags":["Large Language Models","Medical Question Answering"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:47:22.579672Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3551ab85663f","title":"Vectorized Video Representation with Easy Editing via Hierarchical Spatio","content":"arXiv:2510.12256v1 Announce Type: new Abstract: Current video representations heavily rely on unstable and over-grained priors for motion and appearance modelling, \\emph{i.e.}, pixel-level matching and tracking. A tracking error of just a few pixels would lead to the collapse of the visual object representation, not to mention occlusions and large motion frequently occurring in videos. To overcome the above mentioned vulnerability, this work proposes spatio-temporally consistent proxy nodes to represent dynamically changing objects/scenes in the video. On the one hand, the hierarchical proxy nodes have the ability to stably express the multi-scale structure of visual objects, so they are not affected by accumulated tracking error, long-term motion, occlusion, and viewpoint variation. On the other hand, the dynamic representation update mechanism of the proxy nodes adequately leverages spatio-temporal priors of the video to mitigate the impact of inaccurate trackers, thereby effectively handling drastic changes in scenes and objects. Additionally, the decoupled encoding manner of the shape and texture representations across different visual objects in the video facilitates controllable and fine-grained appearance editing capability. Extensive experiments demonstrate that the proposed representation achieves high video reconstruction accuracy with fewer parameters and supports complex video processing tasks, including video in-painting and keyframe-based temporally consistent video editing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12256","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.332145","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Ye Chen, Liming Tan, Yupeng Zhu, Yuanbin Wang, Bingbing Ni","raw_content_length":1514,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Vectorized Video Representation","Hierarchical Spatio"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1513,"language_detected":"en","key_concepts":{"key_phrases":["Vectorized Video Representation","Easy Editing","Hierarchical Spatio","arXiv251012256v1 Announce Type","new Abstract","Current video representations","unstable and over-grained priors","motion","appearance modelling","emphie"],"filter_categories":{"ai_ml":["unstable and over-grained priors"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vectorized Video Representation":2.0,"Easy Editing":2.0,"Hierarchical Spatio":2.0,"arXiv251012256v1 Announce Type":1.0,"new Abstract":1.0,"Current video representations":1.0,"unstable and over-grained priors":1.0,"motion":1.0,"appearance modelling":1.0,"emphie":1.0}},"age_hours":2.7403772602777776,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2469999999999999,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7506,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8414,"joy":0.0036,"surprise":0.0301,"sadness":0.018,"fear":0.0765,"anger":0.0188,"disgust":0.0116},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a novel video representation method that achieves high video reconstruction accuracy with fewer parameters. While it supports complex video processing tasks, its direct climate impact is minimal at this stage. The technology is in the basic research phase, lacking deployment and economic viability data.","key_impact_metrics":["fewer parameters","high video reconstruction accuracy"],"technology_tags":["video representation","spatio-temporal modeling","hierarchical proxy nodes"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:47:25.569851Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_53bb19006cd6","title":"Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images","content":"arXiv:2510.12258v1 Announce Type: new Abstract: We propose two novel loss functions, Multiplicative Loss and Confidence-Adaptive Multiplicative Loss, for semantic segmentation in medical and cellular images. Although Cross Entropy and Dice Loss are widely used, their additive combination is sensitive to hyperparameters and often performs suboptimally, especially with limited data. Medical images suffer from data scarcity due to privacy, ethics, and costly annotations, requiring robust and efficient training objectives. Our Multiplicative Loss combines Cross Entropy and Dice losses multiplicatively, dynamically modulating gradients based on prediction confidence. This reduces penalties for confident correct predictions and amplifies gradients for incorrect overconfident ones, stabilizing optimization. Building on this, Confidence-Adaptive Multiplicative Loss applies a confidence-driven exponential scaling inspired by Focal Loss, integrating predicted probabilities and Dice coefficients to emphasize difficult samples. This enhances learning under extreme data scarcity by strengthening gradients when confidence is low. Experiments on cellular and medical segmentation benchmarks show our framework consistently outperforms tuned additive and existing loss functions, offering a simple, effective, and hyperparameter-free mechanism for robust segmentation under challenging data limitations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12258","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.332541","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Yuto Yokoi, Kazuhiro Hotta","raw_content_length":1406,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Cross Entropy","Multiplicative Loss","Cellular Images arXiv:2510.12258v1 Announce Type","Dice Loss","Dice","Confidence-Adaptive Multiplicative Loss"],"persons":[],"locations":[],"monetary":[]},"char_count":1405,"language_detected":"en","key_concepts":{"key_phrases":["Multiplicative Loss","Semantic Segmentation","Medical and Cellular Images","new Abstract","two novel loss functions","Confidence-Adaptive Multiplicative Loss","semantic segmentation","medical and cellular images","Cross Entropy","Dice Loss"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multiplicative Loss":3.0,"Semantic Segmentation":2.0,"Medical and Cellular Images":2.0,"new Abstract":1.0,"two novel loss functions":1.0,"Confidence-Adaptive Multiplicative Loss":1.0,"semantic segmentation":1.0,"medical and cellular images":1.0,"Cross Entropy":1.0,"Dice Loss":1.0}},"age_hours":2.740391556666667,"is_recent":true,"quality_score":1.0,"sentiment_score":0.41700000000000015,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9166,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8622,"joy":0.0084,"surprise":0.0275,"sadness":0.0518,"fear":0.015,"anger":0.0149,"disgust":0.0203},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel loss function for semantic segmentation in medical and cellular images, showing improved performance on benchmarks. While this could potentially improve efficiency in medical research and diagnostics, leading to indirect environmental benefits, there are no concrete actions or measurable outcomes related to direct climate impact. It is currently in the research phase with no deployment.","key_impact_metrics":["Improved segmentation accuracy on cellular and medical benchmarks","Hyperparameter-free mechanism for robust segmentation"],"technology_tags":["Semantic Segmentation","Medical Imaging","Machine Learning"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-29T15:47:35.378870Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ea9bd56e57a4","title":"Local Background Features Matter in Out","content":"arXiv:2510.12259v1 Announce Type: new Abstract: Out-of-distribution (OOD) detection is crucial when deploying deep neural networks in the real world to ensure the reliability and safety of their applications. One main challenge in OOD detection is that neural network models often produce overconfident predictions on OOD data. While some methods using auxiliary OOD datasets or generating fake OOD images have shown promising OOD detection performance, they are limited by the high costs of data collection and training. In this study, we propose a novel and effective OOD detection method that utilizes local background features as fake OOD features for model training. Inspired by the observation that OOD images generally share similar background regions with ID images, the background features are extracted from ID images as simulated OOD visual representations during training based on the local invariance of convolution. Through being optimized to reduce the $L_2$-norm of these background features, the neural networks are able to alleviate the overconfidence issue on OOD data. Extensive experiments on multiple standard OOD detection benchmarks confirm the effectiveness of our method and its wide combinatorial compatibility with existing post-hoc methods, with new state-of-the-art performance achieved from our method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12259","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.332985","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Jinlun Ye, Zhuohao Sun, Yiqiao Qiu, Qiu Li, Zhijun Tan, Ruixuan Wang","raw_content_length":1334,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1333,"language_detected":"en","key_concepts":{"key_phrases":["Local Background Features Matter","arXiv251012259v1 Announce Type","new Abstract","distribution","deep neural networks","the real world","the reliability","safety","their applications","One main challenge"],"filter_categories":{"ai_ml":["deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Local Background Features Matter":2.0,"arXiv251012259v1 Announce Type":1.0,"new Abstract":1.0,"distribution":1.0,"deep neural networks":1.0,"the real world":1.0,"the reliability":1.0,"safety":1.0,"their applications":1.0,"One main challenge":1.0}},"age_hours":2.7404061369444443,"is_recent":true,"quality_score":0.7,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8124,"joy":0.0033,"surprise":0.0102,"sadness":0.0128,"fear":0.0852,"anger":0.0402,"disgust":0.0358},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel method for improving the reliability of deep neural networks in real-world applications by addressing the overconfidence issue on out-of-distribution data. The method utilizes local background features as fake OOD features for model training, which could potentially improve the efficiency and safety of AI systems used in various sustainability applications. The effectiveness of the method is confirmed by experiments on standard OOD detection benchmarks, but it is still in the research phase with no deployed units.","key_impact_metrics":["state-of-the-art performance achieved from our method"],"technology_tags":["deep neural networks","out-of-distribution detection","machine learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:47:39.121050Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5bcf9a9bc8fe","title":"AngularFuse: A Closer Look at Angle-based Perception for Spatial","content":"arXiv:2510.12260v1 Announce Type: new Abstract: Visible-infrared image fusion is crucial in key applications such as autonomous driving and nighttime surveillance. Its main goal is to integrate multimodal information to produce enhanced images that are better suited for downstream tasks. Although deep learning based fusion methods have made significant progress, mainstream unsupervised approaches still face serious challenges in practical applications. Existing methods mostly rely on manually designed loss functions to guide the fusion process. However, these loss functions have obvious limitations. On one hand, the reference images constructed by existing methods often lack details and have uneven brightness. On the other hand, the widely used gradient losses focus only on gradient magnitude. To address these challenges, this paper proposes an angle-based perception framework for spatial-sensitive image fusion (AngularFuse). At first, we design a cross-modal complementary mask module to force the network to learn complementary information between modalities. Then, a fine-grained reference image synthesis strategy is introduced. By combining Laplacian edge enhancement with adaptive histogram equalization, reference images with richer details and more balanced brightness are generated. Last but not least, we introduce an angle-aware loss, which for the first time constrains both gradient magnitude and direction simultaneously in the gradient domain. AngularFuse ensures that the fused images preserve both texture intensity and correct edge orientation. Comprehensive experiments on the MSRS, RoadScene, and M3FD public datasets show that AngularFuse outperforms existing mainstream methods with clear margin. Visual comparisons further confirm that our method produces sharper and more detailed results in challenging scenes, demonstrating superior fusion capability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12260","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.333428","language":"en","tags":["preprints","computer-science","eessiv","cslg","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Xiaopeng Liu, Yupei Lin, Sen Zhang, Xiao Wang, Yukai Shi, Liang Lin","raw_content_length":1892,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["AngularFuse","Perception for Spatial arXiv:2510.12260v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1891,"language_detected":"en","key_concepts":{"key_phrases":["AngularFuse","A Closer Look","Angle-based Perception","Spatial","Announce Type","new Abstract","Visible-infrared image fusion","key applications","autonomous driving","nighttime surveillance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"AngularFuse":2.0,"A Closer Look":2.0,"Angle-based Perception":2.0,"Spatial":2.0,"Announce Type":1.0,"new Abstract":1.0,"Visible-infrared image fusion":1.0,"key applications":1.0,"autonomous driving":1.0,"nighttime surveillance":1.0}},"age_hours":2.7404201216666664,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7579,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3647,"joy":0.0104,"surprise":0.0144,"sadness":0.1199,"fear":0.4214,"anger":0.046,"disgust":0.0233},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel image fusion technique (AngularFuse) that improves the quality of visible-infrared images, which could potentially enhance the performance of autonomous driving and nighttime surveillance systems. The method is validated through experiments on public datasets (MSRS, RoadScene, and M3FD), demonstrating superior fusion capability compared to existing methods. However, the article does not provide any concrete evidence of real-world deployment or quantification of environmental benefits. It remains at the applied research stage.","key_impact_metrics":["Sharper and more detailed results in challenging scenes","Outperforms existing mainstream methods with clear margin"],"technology_tags":["image fusion","autonomous driving","nighttime surveillance","deep learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:47:42.446479Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c0a4e70719f3","title":"$\\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning","content":"arXiv:2510.12264v1 Announce Type: new Abstract: Active reasoning requires large language models (LLMs) to interact with external sources and strategically gather information to solve problems. Central to this process is belief tracking: maintaining a coherent understanding of the problem state and the missing information toward the solution. However, due to limited reasoning capabilities, LLM-based agents often suffer from belief deviation: they struggle to correctly model beliefs, lose track of problem states, and fall into uninformative or repetitive actions. Once this happens, errors compound and reinforcement learning (RL) training fails to properly credit the crucial exploratory steps. To address this issue, we propose to track the deviation of model beliefs and develop $\\mathbf{T^3}$, a simple yet effective method that detects excessive belief deviation and truncates trajectories during training to remove uninformative tails. By preserving credit for informative prefixes, $\\mathbf{T^3}$ systematically improves policy optimization. Across 5 challenging tasks, $\\mathbf{T^3}$ consistently enhances training stability, token efficiency, and final performance, achieving up to 30% gains while cutting rollout tokens by roughly 25%. These results highlight belief control as a key principle for developing robust and generalizable LLM-based active reasoners.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12264","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.335980","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Deyu Zou, Yongqiang Chen, Jianxiang Wang, Haochen Yang, Mufei Li, James Cheng, Pan Li, Yu Gong","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["\\mathbf{T^3}$"],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["mathbfT3","Belief Deviation","Reinforcement Learning","Active Reasoning","arXiv251012264v1 Announce Type","new Abstract","Active reasoning","large language models","LLMs","external sources"],"filter_categories":{"ai_ml":["Reinforcement Learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"mathbfT3":2.0,"Belief Deviation":2.0,"Reinforcement Learning":2.0,"Active Reasoning":2.0,"arXiv251012264v1 Announce Type":1.0,"new Abstract":1.0,"Active reasoning":1.0,"large language models":1.0,"LLMs":1.0,"external sources":1.0}},"age_hours":2.7404346230555556,"is_recent":true,"quality_score":1.0,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5645,"joy":0.0046,"surprise":0.0089,"sadness":0.0806,"fear":0.1681,"anger":0.0666,"disgust":0.1066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (T^3) to improve the training stability and efficiency of LLM-based agents for active reasoning. The concrete action is the truncation of trajectories during training based on belief deviation. The evidence supporting the claims comes from experiments across 5 challenging tasks, achieving up to 30% gains while cutting rollout tokens by roughly 25%. This is still in the applied research stage, without real-world deployment.","key_impact_metrics":["30% gains","25% cut in rollout tokens"],"technology_tags":["Reinforcement Learning","Large Language Models","Active Reasoning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T15:47:53.432861Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b0e620b05015","title":"Human-in-the","content":"arXiv:2510.12265v1 Announce Type: new Abstract: The quality of experience (QoE) delivered by video conferencing systems is significantly influenced by accurately estimating the time-varying available bandwidth between the sender and receiver. Bandwidth estimation for real-time communications remains an open challenge due to rapidly evolving network architectures, increasingly complex protocol stacks, and the difficulty of defining QoE metrics that reliably improve user experience. In this work, we propose a deployed, human-in-the-loop, data-driven framework for bandwidth estimation to address these challenges. Our approach begins with training objective QoE reward models derived from subjective user evaluations to measure audio and video quality in real-time video conferencing systems. Subsequently, we collect roughly $1$M network traces with objective QoE rewards from real-world Microsoft Teams calls to curate a bandwidth estimation training dataset. We then introduce a novel distributional offline reinforcement learning (RL) algorithm to train a neural-network-based bandwidth estimator aimed at improving QoE for users. Our real-world A/B test demonstrates that the proposed approach reduces the subjective poor call ratio by $11.41\\%$ compared to the baseline bandwidth estimator. Furthermore, the proposed offline RL algorithm is benchmarked on D4RL tasks to demonstrate its generalization beyond bandwidth estimation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12265","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.336413","language":"en","tags":["preprints","csai","eesssy","csmm","csni","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Sami Khairy, Gabriel Mittag, Vishak Gopal, Ross Cutler","raw_content_length":1440,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Microsoft Teams"],"persons":[],"locations":[],"monetary":["roughly $1$M"]},"char_count":1439,"language_detected":"en","key_concepts":{"key_phrases":["Human","arXiv251012265v1 Announce Type","new Abstract","The quality","experience","QoE","video conferencing systems","the time-varying available bandwidth","the sender","receiver"],"filter_categories":{"ai_ml":["the time-varying available bandwidth"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Human":2.0,"arXiv251012265v1 Announce Type":1.0,"new Abstract":1.0,"The quality":1.0,"experience":1.0,"QoE":1.0,"video conferencing systems":1.0,"the time-varying available bandwidth":1.0,"the sender":1.0,"receiver":1.0}},"age_hours":2.7404490988888885,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8858,"joy":0.0186,"surprise":0.0667,"sadness":0.0063,"fear":0.0117,"anger":0.0078,"disgust":0.003},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article describes a deployed, human-in-the-loop framework for bandwidth estimation in video conferencing. The A/B test demonstrates a reduction in subjective poor call ratio by 11.41% compared to the baseline. While the direct climate impact is low, improving video conferencing efficiency could lead to reduced travel and associated emissions.","key_impact_metrics":["poor call ratio reduction 11.41%"],"technology_tags":["bandwidth estimation","reinforcement learning","video conferencing"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T15:47:57.971281Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_50f71ef0eaad","title":"HiLoRA: Adaptive Hierarchical LoRA Routing for Training","content":"arXiv:2510.12266v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) has emerged as a widely used technique for adapting large language models (LLMs) to new domains, due to its modular design and broad availability on platforms such as HuggingFace. This availability has motivated efforts to reuse existing LoRAs for domain generalization. However, existing methods often rely on explicit task labels or additional training, which are impractical for deployment. Moreover, they typically activate a fixed number of entire LoRA modules, leading to parameter redundancy or insufficiency that degrade performance. In this paper, we propose \\texttt{HiLoRA}, a training-free framework that performs adaptive hierarchical routing over LoRA pools. Drawing on structural properties of LoRA, we define rank-one components (ROCs), in which each rank parameter is regarded as an independent unit. For a given input sequence, \\texttt{HiLoRA} first adaptively selects a subset of LoRAs and determines their ROC allocation based on Gaussian likelihoods at the sequence level. At the token level, it further refines routing by activating only the most informative ROCs. We further provide theoretical guarantees that \\texttt{HiLoRA} selects the most relevant LoRAs with high probability. Extensive experiments show that \\texttt{HiLoRA} achieves substantial improvements in domain generalization, with accuracy gains of up to {\\small $55\\%$} over state-of-the-art baselines, while maintaining comparable inference throughput.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12266","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.336867","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Ziyi Han, Huanyu Wang, Zeyu Zhang, Xiangxiang Dai, Xutong Liu, John C. S. Lui","raw_content_length":1524,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["LoRA","LoRAs","HuggingFace"],"persons":[],"locations":[],"monetary":[]},"char_count":1515,"language_detected":"en","key_concepts":{"key_phrases":["HiLoRA","Adaptive Hierarchical LoRA Routing","Training","arXiv251012266v1 Announce Type","new Abstract","Low-Rank Adaptation","LoRA","a widely used technique","large language models","LLMs"],"filter_categories":{"ai_ml":["Training","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HiLoRA":2.0,"Adaptive Hierarchical LoRA Routing":2.0,"Training":2.0,"arXiv251012266v1 Announce Type":1.0,"new Abstract":1.0,"Low-Rank Adaptation":1.0,"LoRA":1.0,"a widely used technique":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.740464359166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9292,"joy":0.0103,"surprise":0.0321,"sadness":0.0067,"fear":0.0056,"anger":0.0105,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (HiLoRA) for improving the efficiency of adapting large language models, leading to potential energy savings during training and inference. The method is evaluated through experiments showing accuracy gains, but there's no mention of actual energy consumption or deployment. The research is at the applied research stage, lacking real-world deployment data.","key_impact_metrics":["accuracy gains of up to 55%"],"technology_tags":["Low-Rank Adaptation","Domain Generalization","Machine Learning"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T15:48:01.155331Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce9234ee8faf","title":"SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis","content":"arXiv:2510.12267v1 Announce Type: new Abstract: With the increasing integration of Multimodal Large Language Models (MLLMs) into the medical field, comprehensive evaluation of their performance in various medical domains becomes critical. However, existing benchmarks primarily assess general medical tasks, inadequately capturing performance in nuanced areas like the spine, which relies heavily on visual input. To address this, we introduce SpineBench, a comprehensive Visual Question Answering (VQA) benchmark designed for fine-grained analysis and evaluation of MLLMs in the spinal domain. SpineBench comprises 64,878 QA pairs from 40,263 spine images, covering 11 spinal diseases through two critical clinical tasks: spinal disease diagnosis and spinal lesion localization, both in multiple-choice format. SpineBench is built by integrating and standardizing image-label pairs from open-source spinal disease datasets, and samples challenging hard negative options for each VQA pair based on visual similarity (similar but not the same disease), simulating real-world challenging scenarios. We evaluate 12 leading MLLMs on SpineBench. The results reveal that these models exhibit poor performance in spinal tasks, highlighting limitations of current MLLM in the spine domain and guiding future improvements in spinal medicine applications. SpineBench is publicly available at https://zhangchenghanyu.github.io/SpineBench.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12267","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.337275","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Chenghanyu Zhang, Zekun Li, Peipei Li, Xing Cui, Shuhan Xia, Weixiang Yan, Yiqiao Zhang, Qianyu Zhuang","raw_content_length":1439,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["VQA","SpineBench","Spinal Pathology Analysis arXiv:2510.12267v1 Announce Type","Multimodal Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1438,"language_detected":"en","key_concepts":{"key_phrases":["SpineBench","Multimodal LLMs","Spinal Pathology Analysis","arXiv251012267v1","Announce Type","new Abstract","the increasing integration","Multimodal Large Language Models","MLLMs","the medical field"],"filter_categories":{"ai_ml":["Multimodal LLMs","Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SpineBench":3.0,"Multimodal LLMs":2.0,"Spinal Pathology Analysis":2.0,"arXiv251012267v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"the increasing integration":1.0,"Multimodal Large Language Models":1.0,"MLLMs":1.0,"the medical field":1.0}},"age_hours":2.7404785455555554,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8472,"joy":0.0054,"surprise":0.0569,"sadness":0.0254,"fear":0.02,"anger":0.0261,"disgust":0.019},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a new benchmark (SpineBench) for evaluating MLLMs in spinal pathology analysis. While it doesn't directly reduce GHG emissions, it has the potential to improve medical diagnostics, which could indirectly lead to more efficient healthcare resource allocation. The technical credibility is supported by the creation of a dataset with 64,878 QA pairs and evaluation of 12 leading MLLMs, but it is still in the applied research stage.","key_impact_metrics":["64,878 QA pairs","40,263 spine images"],"technology_tags":["Multimodal Large Language Models","Visual Question Answering"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T15:48:06.115841Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_967427d920d1","title":"How Far I'll Go: Imagining Futures of Conversational AI with People with Visual Impairments Through Design Fiction","content":"arXiv:2510.12268v1 Announce Type: new Abstract: People with visual impairments (PVI) use a variety of assistive technologies to navigate their daily lives, and conversational AI (CAI) tools are a growing part of this toolset. Much existing HCI research has focused on the technical capabilities of current CAI tools, but in this paper, we instead examine how PVI themselves envision potential futures for living with CAI. We conducted a study with 14 participants with visual impairments using an audio-based Design Fiction probe featuring speculative dialogues between participants and a future CAI. Participants imagined using CAI to expand their boundaries by exploring new opportunities or places, but also voiced concerns about balancing reliance on CAI with maintaining autonomy, the need to consider diverse levels of vision-loss, and enhancing visibility of PVI for greater inclusion. We discuss implications for designing CAI that support genuine agency for PVI based on the future lives they envisioned.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12268","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.337685","language":"en","tags":["preprints","computer-science","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Jeanne Choi, Dasom Choi, Sejun Jeong, Hwajung Hong, Joseph Seering","raw_content_length":1014,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Design Fiction","PVI","CAI"],"persons":["HCI"],"locations":[],"monetary":[]},"char_count":1013,"language_detected":"en","key_concepts":{"key_phrases":["People","Futures","Conversational AI","Visual Impairments","Design Fiction","visual impairments","PVI","CAI","arXiv251012268v1 Announce Type","new Abstract"],"filter_categories":{"ai_ml":["Conversational AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"People":3.0,"Futures":2.0,"Conversational AI":2.0,"Visual Impairments":2.0,"Design Fiction":2.0,"visual impairments":2.0,"PVI":2.0,"CAI":2.0,"arXiv251012268v1 Announce Type":1.0,"new Abstract":1.0}},"age_hours":2.7404942163888886,"is_recent":true,"quality_score":1.0,"sentiment_score":6.423,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2846,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9038,"joy":0.0193,"surprise":0.0446,"sadness":0.0055,"fear":0.015,"anger":0.0075,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":6,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores potential futures of conversational AI for people with visual impairments through design fiction. While it identifies important considerations for equitable design, it doesn't present any concrete actions or measurable outcomes related to climate change or sustainability. The research is in the early stages, with no deployed technology or quantified impact data.","key_impact_metrics":[],"technology_tags":["conversational AI","assistive technology"],"sdg_alignment":[10],"analyzed_at":"2025-10-29T15:48:09.068899Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_02c5b1cd7714","title":"Tensor Logic: The Language of AI","content":"arXiv:2510.12269v1 Announce Type: new Abstract: Progress in AI is hindered by the lack of a programming language with all the requisite features. Libraries like PyTorch and TensorFlow provide automatic differentiation and efficient GPU implementation, but are additions to Python, which was never intended for AI. Their lack of support for automated reasoning and knowledge acquisition has led to a long and costly series of hacky attempts to tack them on. On the other hand, AI languages like LISP an Prolog lack scalability and support for learning. This paper proposes tensor logic, a language that solves these problems by unifying neural and symbolic AI at a fundamental level. The sole construct in tensor logic is the tensor equation, based on the observation that logical rules and Einstein summation are essentially the same operation, and all else can be reduced to them. I show how to elegantly implement key forms of neural, symbolic and statistical AI in tensor logic, including transformers, formal reasoning, kernel machines and graphical models. Most importantly, tensor logic makes new directions possible, such as sound reasoning in embedding space. This combines the scalability and learnability of neural networks with the reliability and transparency of symbolic reasoning, and is potentially a basis for the wider adoption of AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12269","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.338101","language":"en","tags":["preprints","csne","csai","statml","computer-science","cslg","research","cspl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Pedro Domingos","raw_content_length":1352,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["PyTorch","GPU","TensorFlow"],"persons":["Einstein"],"locations":[],"monetary":[]},"char_count":1351,"language_detected":"en","key_concepts":{"key_phrases":["Tensor Logic","The Language","arXiv251012269v1 Announce Type","new Abstract","Progress","the lack","a programming language","all the requisite features","Libraries","PyTorch"],"filter_categories":{"engineering":["a programming language"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Tensor Logic":2.0,"The Language":2.0,"arXiv251012269v1 Announce Type":1.0,"new Abstract":1.0,"Progress":1.0,"the lack":1.0,"a programming language":1.0,"all the requisite features":1.0,"Libraries":1.0,"PyTorch":1.0}},"age_hours":2.740509857777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6949,"joy":0.0037,"surprise":0.0554,"sadness":0.1398,"fear":0.019,"anger":0.029,"disgust":0.0581},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new AI language, tensor logic, aiming to unify neural and symbolic AI. While it presents a novel approach and shows potential for improved AI scalability and transparency, it is currently at the basic research stage with no deployed technology or measured outcomes. The potential climate impact is indirect, relying on future applications of this AI language to sustainability challenges.","key_impact_metrics":[],"technology_tags":["Tensor Logic","Artificial Intelligence","Neural Networks","Symbolic AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:48:14.595584Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1289baa6e731","title":"Heterogeneous RBCs via deep multi","content":"arXiv:2510.12272v1 Announce Type: new Abstract: Current macroeconomic models with agent heterogeneity can be broadly divided into two main groups. Heterogeneous-agent general equilibrium (GE) models, such as those based on Heterogeneous Agents New Keynesian (HANK) or Krusell-Smith (KS) approaches, rely on GE and 'rational expectations', somewhat unrealistic assumptions that make the models very computationally cumbersome, which in turn limits the amount of heterogeneity that can be modelled. In contrast, agent-based models (ABMs) can flexibly encompass a large number of arbitrarily heterogeneous agents, but typically require the specification of explicit behavioural rules, which can lead to a lengthy trial-and-error model-development process. To address these limitations, we introduce MARL-BC, a framework that integrates deep multi-agent reinforcement learning (MARL) with Real Business Cycle (RBC) models. We demonstrate that MARL-BC can: (1) recover textbook RBC results when using a single agent; (2) recover the results of the mean-field KS model using a large number of identical agents; and (3) effectively simulate rich heterogeneity among agents, a hard task for traditional GE approaches. Our framework can be thought of as an ABM if used with a variety of heterogeneous interacting agents, and can reproduce GE results in limit cases. As such, it is a step towards a synthesis of these often opposed modelling paradigms.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12272","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.338511","language":"en","tags":["preprints","econth","computer-science","cslg","research","csma","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Federico Gabriele, Aldo Glielmo, Marco Taboga","raw_content_length":1443,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Krusell-Smith","Heterogeneous Agents New Keynesian","Real Business Cycle","RBC","MARL-BC"],"persons":[],"locations":[],"monetary":[]},"char_count":1442,"language_detected":"en","key_concepts":{"key_phrases":["Heterogeneous RBCs","deep multi","arXiv251012272v1 Announce Type","new Abstract","Current macroeconomic models","agent heterogeneity","two main groups","Heterogeneous-agent general equilibrium GE models","those","Heterogeneous Agents New Keynesian"],"filter_categories":{"ai_ml":["two main groups"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Heterogeneous RBCs":2.0,"deep multi":2.0,"arXiv251012272v1 Announce Type":1.0,"new Abstract":1.0,"Current macroeconomic models":1.0,"agent heterogeneity":1.0,"two main groups":1.0,"Heterogeneous-agent general equilibrium GE models":1.0,"those":1.0,"Heterogeneous Agents New Keynesian":1.0}},"age_hours":2.740525856944444,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8986,"joy":0.0092,"surprise":0.029,"sadness":0.0088,"fear":0.0147,"anger":0.0206,"disgust":0.0192},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new modeling framework (MARL-BC) that integrates deep multi-agent reinforcement learning with Real Business Cycle models. While the framework could potentially be used to model the impact of climate policies or technological changes on the economy, the paper itself does not present any concrete actions or measurable outcomes related to sustainability. It is currently at the basic research stage with no deployment.","key_impact_metrics":[],"technology_tags":["macroeconomic modeling","multi-agent reinforcement learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:48:18.692231Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_43e45c5b9f75","title":"Metronome: Efficient Scheduling for Periodic Traffic Jobs with Network and Priority Awareness","content":"arXiv:2510.12274v1 Announce Type: new Abstract: With the rapid growth in computing power demand, cloud native networks have emerged as a promising solution to address the challenges of efficient resource coordination, particularly in coping with the dynamic fluctuations of network bandwidth in clusters. We propose Metronome, a network-aware and priority-aware scheduling mechanism for cloud native networks. This mechanism is designed to support jobs that exhibit periodic traffic patterns and dynamic bandwidth demands, particularly in the context of distributed training. Specifically, Metronome employs a time-division multiplexing approach that leverages job traffic characteristics to construct an elastic network resource allocation model, enabling efficient bandwidth sharing across multiple jobs. In addition, it incorporates a multi-objective optimization strategy, jointly considering latency and job priorities to achieve globally optimal as well as dynamic resource allocation. Finally, Metronome adapts to the dynamic environment by monitoring the cluster and performing reconfiguration operations. Extensive experiments with 13 common machine learning models demonstrate that Metronome can enhance cluster resource utilization while guaranteeing service performance. Compared with the existing Kubernetes scheduling mechanisms across multiple scenarios, Metronome reduces job completion time by up to 19.50% while improving average bandwidth utilization by up to 23.20%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12274","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.339371","language":"en","tags":["preprints","computer-science","csdc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Hao Jiang, Meng Qin, Ruijie Kuai, Dandan Liang","raw_content_length":1487,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Periodic Traffic Jobs","Metronome"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1486,"language_detected":"en","key_concepts":{"key_phrases":["Metronome","Efficient Scheduling","Periodic Traffic Jobs","Network and Priority Awareness","cloud native networks","arXiv251012274v1 Announce Type","new Abstract","the rapid growth","computing power demand","a promising solution"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Metronome":3.0,"Efficient Scheduling":2.0,"Periodic Traffic Jobs":2.0,"Network and Priority Awareness":2.0,"cloud native networks":2.0,"arXiv251012274v1 Announce Type":1.0,"new Abstract":1.0,"the rapid growth":1.0,"computing power demand":1.0,"a promising solution":1.0}},"age_hours":2.740554537222222,"is_recent":true,"quality_score":1.0,"sentiment_score":9.637,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9274,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8953,"joy":0.0399,"surprise":0.0428,"sadness":0.0032,"fear":0.0073,"anger":0.009,"disgust":0.0024},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"Metronome improves resource utilization in cloud native networks, potentially reducing energy consumption in data centers. The article provides specific metrics like a 19.50% reduction in job completion time and a 23.20% improvement in average bandwidth utilization compared to existing Kubernetes scheduling. It is currently at the applied research stage, with experiments conducted but no real-world deployment mentioned.","key_impact_metrics":["job completion time reduction 19.50%","bandwidth utilization improvement 23.20%"],"technology_tags":["cloud native networks","resource scheduling","time-division multiplexing"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T15:48:25.141552Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ce566de60156","title":"TFGA-Net: Temporal","content":"arXiv:2510.12275v1 Announce Type: new Abstract: The rapid development of auditory attention decoding (AAD) based on electroencephalography (EEG) signals offers the possibility EEG-driven target speaker extraction. However, how to effectively utilize the target-speaker common information between EEG and speech remains an unresolved problem. In this paper, we propose a model for brain-controlled speaker extraction, which utilizes the EEG recorded from the listener to extract the target speech. In order to effectively extract information from EEG signals, we derive multi-scale time--frequency features and further incorporate cortical topological structures that are selectively engaged during the task. Moreover, to effectively exploit the non-Euclidean structure of EEG signals and capture their global features, the graph convolutional networks and self-attention mechanism are used in the EEG encoder. In addition, to make full use of the fused EEG and speech feature and preserve global context and capture speech rhythm and prosody, we introduce MossFormer2 which combines MossFormer and RNN-Free Recurrent as separator. Experimental results on both the public Cocktail Party and KUL dataset in this paper show that our TFGA-Net model significantly outper-forms the state-of-the-art method in certain objective evaluation metrics. The source code is available at: https://github.com/LaoDa-X/TFGA-NET.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12275","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.339804","language":"en","tags":["preprints","csai","computer-science","research","cssd","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Youhao Si, Yuan Liao, Qiushi Han, Yuhang Yang, Rui Dai, Liya Huang","raw_content_length":1411,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["EEG","TFGA-Net: Temporal arXiv:2510.12275v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1410,"language_detected":"en","key_concepts":{"key_phrases":["TFGA-Net","arXiv251012275v1 Announce Type","new Abstract","The rapid development","auditory attention","electroencephalography","EEG signals","the possibility","EEG-driven target speaker extraction","the target-speaker common information"],"filter_categories":{"engineering":["The rapid development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"TFGA-Net":2.0,"arXiv251012275v1 Announce Type":1.0,"new Abstract":1.0,"The rapid development":1.0,"auditory attention":1.0,"electroencephalography":1.0,"EEG signals":1.0,"the possibility":1.0,"EEG-driven target speaker extraction":1.0,"the target-speaker common information":1.0}},"age_hours":2.7405695602777778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.913,"joy":0.0104,"surprise":0.0321,"sadness":0.0069,"fear":0.0128,"anger":0.0167,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel model (TFGA-Net) for brain-controlled speaker extraction using EEG signals. While the model shows improved performance on specific objective evaluation metrics compared to state-of-the-art methods, it is still in the research phase with no clear path to deployment or direct climate impact. The technology is at a very early stage of development.","key_impact_metrics":["Objective evaluation metrics improvement"],"technology_tags":["EEG","Auditory Attention Decoding","Graph Convolutional Networks","Self-Attention Mechanism"],"sdg_alignment":[],"analyzed_at":"2025-10-29T15:48:28.320913Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9cd544b3f6ff","title":"Spatial Forcing: Implicit Spatial Representation Alignment for Vision","content":"arXiv:2510.12276v1 Announce Type: new Abstract: Vision-language-action (VLA) models have recently shown strong potential in enabling robots to follow language instructions and execute precise actions. However, most VLAs are built upon vision-language models pretrained solely on 2D data, which lack accurate spatial awareness and hinder their ability to operate in the 3D physical world. Existing solutions attempt to incorporate explicit 3D sensor inputs such as depth maps or point clouds, but these approaches face challenges due to sensor noise, hardware heterogeneity, and incomplete depth coverage in existing datasets. Alternative methods that estimate 3D cues from 2D images also suffer from the limited performance of depth estimators.We propose Spatial Forcing (SF), a simple yet effective alignment strategy that implicitly forces VLA models to develop spatial comprehension capabilities without relying on explicit 3D inputs or depth estimators. SF aligns intermediate visual embeddings of VLAs with geometric representations produced by pretrained 3D foundation models. By enforcing alignment at intermediate layers, SF guides VLAs to encode richer spatial representations that enhance action precision.Extensive experiments in simulation and real-world environments demonstrate that SF achieves state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further accelerates training by up to 3.8x and improves data efficiency across diverse robotic tasks. Project page is at https://spatial-forcing.github.io/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12276","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.340216","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Fuhao Li, Wenxuan Song, Han Zhao, Jingbo Wang, Pengxiang Ding, Donglin Wang, Long Zeng, Haoang Li","raw_content_length":1533,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1532,"language_detected":"en","key_concepts":{"key_phrases":["Spatial Forcing","Implicit Spatial Representation Alignment","Vision","arXiv251012276v1 Announce Type","new Abstract Vision-language-action VLA models","strong potential","robots","language instructions","precise actions","most VLAs"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Spatial Forcing":2.0,"Implicit Spatial Representation Alignment":2.0,"Vision":2.0,"arXiv251012276v1 Announce Type":1.0,"new Abstract Vision-language-action VLA models":1.0,"strong potential":1.0,"robots":1.0,"language instructions":1.0,"precise actions":1.0,"most VLAs":1.0}},"age_hours":2.7405855455555557,"is_recent":true,"quality_score":0.7,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8846,"joy":0.0066,"surprise":0.0312,"sadness":0.0269,"fear":0.0111,"anger":0.022,"disgust":0.0175},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (Spatial Forcing) to improve spatial awareness in vision-language-action models for robotics, potentially leading to more efficient and precise robotic actions. The claim of accelerating training by up to 3.8x and improving data efficiency is a measurable outcome, but it's currently demonstrated in simulation and real-world environments, not yet deployed at scale. The lack of deployment and economic viability data limits the overall sustainability impact.","key_impact_metrics":["training acceleration 3.8x"],"technology_tags":["robotics","vision-language-action models","spatial awareness","3D foundation models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T15:48:35.793949Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d1c6698c535a","title":"A Direct Memory Access Controller (DMAC) for Irregular Data Transfers on RISC","content":"arXiv:2510.12277v1 Announce Type: new Abstract: With the ever-growing heterogeneity in computing systems, driven by modern machine learning applications, pressure is increasing on memory systems to handle arbitrary and more demanding transfers efficiently. Descriptor-based direct memory access controllers (DMACs) allow such transfers to be executed by decoupling memory transfers from processing units. Classical descriptor-based DMACs are inefficient when handling arbitrary transfers of small unit sizes. Excessive descriptor size and the serialized nature of processing descriptors employed by the DMAC lead to large static overheads when setting up transfers. To tackle this inefficiency, we propose a descriptor-based DMAC optimized to efficiently handle arbitrary transfers of small unit sizes. We implement a lightweight descriptor format in an AXI4-based DMAC. We further increase performance by implementing a low-overhead speculative descriptor prefetching scheme without additional latency penalties in the case of a misprediction. Our DMAC is integrated into a 64-bit Linux-capable RISC-V SoC and emulated on a Kintex FPGA to evaluate its performance. Compared to an off-the-shelf descriptor-based DMAC IP, we achieve 1.66x less latency launching transfers, increase bus utilization up to 2.5x in an ideal memory system with 64-byte-length transfers while requiring 11% fewer lookup tables, 23% fewer flip-flops, and no block RAMs. We can extend our lead in bus utilization to 3.6x with 64-byte-length transfers in deep memory systems. We synthesized our DMAC in GlobalFoundries' GF12LP+ node, achieving a clock frequency of over 1.44 GHz while occupying only 49.5 kGE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12277","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.340697","language":"en","tags":["preprints","computer-science","csar","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Thomas Benz, Axel Vanoni, Michael Rogenmoser, Luca Benini","raw_content_length":1684,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["DMACs","Irregular Data Transfers","DMAC"],"persons":[],"locations":[],"monetary":[]},"char_count":1683,"language_detected":"en","key_concepts":{"key_phrases":["A Direct Memory Access Controller","DMAC","Irregular Data Transfers","RISC","arXiv251012277v1 Announce Type","new Abstract","the ever-growing heterogeneity","computing systems","modern machine learning applications","pressure"],"filter_categories":{"ai_ml":["modern machine learning applications"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Direct Memory Access Controller":2.0,"DMAC":2.0,"Irregular Data Transfers":2.0,"RISC":2.0,"arXiv251012277v1 Announce Type":1.0,"new Abstract":1.0,"the ever-growing heterogeneity":1.0,"computing systems":1.0,"modern machine learning applications":1.0,"pressure":1.0}},"age_hours":2.7406008388888887,"is_recent":true,"quality_score":1.0,"sentiment_score":5.603,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1206,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8343,"joy":0.0197,"surprise":0.0978,"sadness":0.005,"fear":0.011,"anger":0.0242,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel DMAC design that improves memory transfer efficiency, potentially reducing energy consumption in computing systems. The claims are supported by performance metrics from emulation on an FPGA and synthesis results, but lack real-world deployment data. This is still in the applied research stage, with potential but unproven economic viability.","key_impact_metrics":["1.66x less latency launching transfers","2.5x increase in bus utilization"],"technology_tags":["DMAC","RISC-V","Memory Transfer Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:21:02.729918Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a2988a9db838","title":"Analysis and Evaluation of Using Microsecond-Latency Memory for In-Memory Indices and Caches in SSD","content":"arXiv:2510.12280v1 Announce Type: new Abstract: When key-value (KV) stores use SSDs for storing a large number of items, oftentimes they also require large in-memory data structures including indices and caches to be traversed to reduce IOs. This paper considers offloading most of such data structures from the costly host DRAM to secondary memory whose latency is in the microsecond range, an order of magnitude longer than those of currently available DIMM-mounted or CXL memory devices. While emerging microsecond-latency memory is likely to cost much less than DRAM, it can significantly slow down SSD-based KV stores if naively employed. This paper analyzes and evaluates the impact of microsecond-level memory latency on the KV operation throughput. Our analysis finds that a well-known latency-hiding technique of software prefetching for long-latency memory from user-level threads is effective. The novelty of our analysis lies in modeling how the interplay between prefetching and IO affects performance, from which we derive an equation that well explains the throughput degradation due to long memory latency. The model tells us that the presence of IO significantly enhances the tolerance to memory latency, leading to a finding that SSD-based KV stores can be made latency-tolerant without devising new techniques for microsecond-latency memory. To confirm this, we design a microbenchmark as well as modify existing SSD-based KV stores so that they issue prefetches from user-level threads, and run them while placing most of in-memory data structures on FPGA-based memory with adjustable microsecond latency. The results demonstrate that their KV operation throughputs can be well explained by our model, and the modified KV stores achieve near-DRAM throughputs for up to a memory latency of 5 microseconds. This suggests the possibility that SSD-based KV stores can use microsecond-latency memory as a cost-effective alternative to the host DRAM.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12280","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.341530","language":"en","tags":["preprints","computer-science","research","cspf","csdb","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":294,"author":"Yosuke Bando, Akinobu Mita, Kazuhiro Hiwada, Shintaro Sano, Tomoya Suzuki, Yu Nakanishi, Kazutaka Tomida, Hirotsugu Kajihara, Akiyuki Kaneko, Daisuke Taki, Yukimasa Miyamoto, Tomokazu Yoshida, Tatsuo Shiozawa","raw_content_length":1965,"priority":7,"update_frequency":1,"reading_time_minutes":1.47,"robust_parsing_used":true,"entities":{"organizations":["Microsecond-Latency Memory for In-Memory Indices and Caches","CXL","SSD","DRAM"],"persons":[],"locations":[],"monetary":[]},"char_count":1964,"language_detected":"en","key_concepts":{"key_phrases":["Analysis","Evaluation","Microsecond-Latency Memory","In-Memory Indices","Caches","SSD","arXiv251012280v1","Announce Type","new Abstract","key-value KV stores"],"filter_categories":{"business_innovation":["Analysis"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Analysis":2.0,"Evaluation":2.0,"Microsecond-Latency Memory":2.0,"In-Memory Indices":2.0,"Caches":2.0,"SSD":2.0,"arXiv251012280v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"key-value KV stores":1.0}},"age_hours":2.7406322050000003,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8704,"joy":0.0079,"surprise":0.0729,"sadness":0.0091,"fear":0.0063,"anger":0.0205,"disgust":0.013},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes the impact of using microsecond-latency memory in SSD-based key-value stores. The concrete action is the modification of existing SSD-based KV stores to issue prefetches from user-level threads, and running them on FPGA-based memory with adjustable microsecond latency. The evidence is the demonstration that the KV operation throughputs can be well explained by their model, achieving near-DRAM throughputs for up to a memory latency of 5 microseconds. This is currently at the applied research stage, with modifications to existing systems and testing on FPGA-based memory.","key_impact_metrics":["near-DRAM throughputs for up to 5 microseconds memory latency","throughput degradation due to long memory latency"],"technology_tags":["SSD","key-value stores","microsecond-latency memory","FPGA"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:21:06.207643Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_523c586c165b","title":"PAGS: Priority","content":"arXiv:2510.12282v1 Announce Type: new Abstract: Reconstructing dynamic 3D urban scenes is crucial for autonomous driving, yet current methods face a stark trade-off between fidelity and computational cost. This inefficiency stems from their semantically agnostic design, which allocates resources uniformly, treating static backgrounds and safety-critical objects with equal importance. To address this, we introduce Priority-Adaptive Gaussian Splatting (PAGS), a framework that injects task-aware semantic priorities directly into the 3D reconstruction and rendering pipeline. PAGS introduces two core contributions: (1) Semantically-Guided Pruning and Regularization strategy, which employs a hybrid importance metric to aggressively simplify non-critical scene elements while preserving fine-grained details on objects vital for navigation. (2) Priority-Driven Rendering pipeline, which employs a priority-based depth pre-pass to aggressively cull occluded primitives and accelerate the final shading computations. Extensive experiments on the Waymo and KITTI datasets demonstrate that PAGS achieves exceptional reconstruction quality, particularly on safety-critical objects, while significantly reducing training time and boosting rendering speeds to over 350 FPS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12282","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.341942","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Ying A, Wenzhang Sun, Chang Zeng, Chunfeng Wang, Hao Li, Jianxun Cui","raw_content_length":1270,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["fidelity"],"persons":["PAGS"],"locations":[],"monetary":[]},"char_count":1269,"language_detected":"en","key_concepts":{"key_phrases":["PAGS","Priority","Announce Type","new Abstract","dynamic 3D urban scenes","autonomous driving","current methods","a stark trade-off","fidelity","computational cost"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"PAGS":3.0,"Priority":2.0,"Announce Type":1.0,"new Abstract":1.0,"dynamic 3D urban scenes":1.0,"autonomous driving":1.0,"current methods":1.0,"a stark trade-off":1.0,"fidelity":1.0,"computational cost":1.0}},"age_hours":2.7406465752777773,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8386,"joy":0.0087,"surprise":0.0266,"sadness":0.0215,"fear":0.0045,"anger":0.0647,"disgust":0.0355},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (PAGS) for 3D urban scene reconstruction that improves efficiency and focuses on safety-critical objects. It claims a reduction in training time and a boost in rendering speeds to over 350 FPS, but lacks information on actual deployment or real-world energy savings. The technology is at the applied research stage, demonstrated on datasets but not yet deployed.","key_impact_metrics":["rendering speeds to over 350 FPS","reduced training time"],"technology_tags":["3D reconstruction","Gaussian Splatting","autonomous driving"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:21:10.026797Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e73286ae0293","title":"Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval","content":"arXiv:2510.12283v1 Announce Type: new Abstract: Almost all previous text-to-video retrieval works ideally assume that videos are pre-trimmed with short durations containing solely text-related content. However, in practice, videos are typically untrimmed in long durations with much more complicated background content. Therefore, in this paper, we focus on the more practical yet challenging task of Partially Relevant Video Retrieval (PRVR), which aims to retrieve partially relevant untrimmed videos with the given query. To tackle this task, we propose a novel framework that distills generalization knowledge from a powerful large-scale vision-language pre-trained model and transfers it to a lightweight, task-specific PRVR network. Specifically, we introduce a Dual Learning framework with Dynamic Knowledge Distillation (DL-DKD++), where a large teacher model provides supervision to a compact dual-branch student network. The student model comprises two branches: an inheritance branch that absorbs transferable knowledge from the teacher, and an exploration branch that learns task-specific information from the PRVR dataset to address domain gaps. To further enhance learning, we incorporate a dynamic soft-target construction mechanism. By replacing rigid hard-target supervision with adaptive soft targets that evolve during training, our method enables the model to better capture the fine-grained, partial relevance between videos and queries. Experiment results demonstrate that our proposed model achieves state-of-the-art performance on TVR, ActivityNet, and Charades-STA datasets for PRVR. The code is available at https://github.com/HuiGuanLab/DL-DKD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12283","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.342355","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Jianfeng Dong, Lei Huang, Daizong Liu, Xianke Chen, Xun Yang, Changting Lin, Xun Wang, Meng Wang","raw_content_length":1672,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["Partially Relevant Video Retrieval","Dynamic Knowledge Distillation"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1671,"language_detected":"en","key_concepts":{"key_phrases":["Partially Relevant Video Retrieval","Dual Learning","Dynamic Knowledge Distillation","Soft Alignment","videos","arXiv251012283v1 Announce Type","new Abstract","video","short durations","solely text-related content"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Partially Relevant Video Retrieval":3.0,"Dual Learning":2.0,"Dynamic Knowledge Distillation":2.0,"Soft Alignment":2.0,"videos":2.0,"arXiv251012283v1 Announce Type":1.0,"new Abstract":1.0,"video":1.0,"short durations":1.0,"solely text-related content":1.0}},"age_hours":2.7406618605555555,"is_recent":true,"quality_score":1.0,"sentiment_score":8.701,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7402,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9254,"joy":0.0144,"surprise":0.0272,"sadness":0.0059,"fear":0.0101,"anger":0.0102,"disgust":0.0068},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new framework for Partially Relevant Video Retrieval (PRVR) using dual learning and knowledge distillation. While it achieves state-of-the-art performance on benchmark datasets, it is still in the research phase with no deployed units or real-world impact demonstrated. The climate impact is indirect, as improved video retrieval could potentially support sustainability-related content, but there are no quantified emissions reductions or other concrete actions.","key_impact_metrics":["State-of-the-art performance on TVR dataset","State-of-the-art performance on ActivityNet dataset"],"technology_tags":["Video Retrieval","Knowledge Distillation","Machine Learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:21:14.387230Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ae349f02a166","title":"Chinese ModernBERT with Whole","content":"arXiv:2510.12285v1 Announce Type: new Abstract: Encoder-only Transformers have advanced along three axes -- architecture, data, and systems -- yielding Pareto gains in accuracy, speed, and memory efficiency. Yet these improvements have not fully transferred to Chinese, where tokenization and morphology differ markedly from English. We introduce Chinese ModernBERT, a from-scratch Chinese encoder that couples: (i) a hardware-aware 32k BPE vocabulary tailored to frequent Chinese affixes/compounds, lowering the embedding budget; (ii) whole-word masking (WWM) with a dynamic masking curriculum (30% -> 15%) to align task difficulty with training progress; (iii) a two-stage pre-training pipeline that extends the native context from 1,024 to 8,192 tokens using RoPE and alternating local/global attention; and (iv) a damped-cosine learning-rate schedule for stable long-horizon optimization. We pre-train on ~1.2T Chinese tokens from CCI3-HQ, CCI4 (Chinese), and Cosmopedia-Chinese. On CLUE, Chinese ModernBERT is competitive with strong Chinese encoders under a unified fine-tuning protocol. Under bf16 it achieves high long-sequence throughput while maintaining strong short-sequence speed, reflecting benefits from budget allocation and attention design. To probe retrieval-oriented quality, we add a small amount of open contrastive data: fine-tuning on SimCLUE (~3M pairs) improves further when adding T2Ranking (~2M), reaching 0.505 (Pearson) / 0.537 (Spearman) on the SimCLUE test set. Under this open-data setting, Chinese ModernBERT surpasses Qwen-0.6B-embedding on SimCLUE, suggesting a clear scaling path for STS with additional curated pairs. We will release tokenizer and weights to facilitate reproducible research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12285","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.342815","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":232,"author":"Zeyu Zhao, Ningtao Wang, Xing Fu, Yu Cheng","raw_content_length":1731,"priority":7,"update_frequency":1,"reading_time_minutes":1.16,"robust_parsing_used":true,"entities":{"organizations":["RoPE","BPE","WWM","CCI3-HQ"],"persons":["Pareto","Whole arXiv:2510.12285v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1730,"language_detected":"en","key_concepts":{"key_phrases":["Chinese ModernBERT","Whole","arXiv251012285v1 Announce Type","new Abstract","Encoder-only Transformers","three axes","architecture","data","systems","Pareto gains"],"filter_categories":{"ai_ml":["Encoder-only Transformers","data"],"engineering":["architecture","systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chinese ModernBERT":3.0,"Whole":2.0,"arXiv251012285v1 Announce Type":1.0,"new Abstract":1.0,"Encoder-only Transformers":1.0,"three axes":1.0,"architecture":1.0,"data":1.0,"systems":1.0,"Pareto gains":1.0}},"age_hours":2.740678308888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9149,"joy":0.0074,"surprise":0.0335,"sadness":0.0031,"fear":0.0142,"anger":0.0145,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new Chinese language model (Chinese ModernBERT) with architectural and training improvements. While improved language models can indirectly support sustainability efforts (e.g., better communication, data analysis), the direct climate impact is minimal at this stage. The model is currently in the applied research phase, with no deployed applications or economic viability demonstrated.","key_impact_metrics":["0.505 Pearson correlation on SimCLUE","0.537 Spearman correlation on SimCLUE"],"technology_tags":["Natural Language Processing","Transformer Model"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:21:17.950471Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d1ea605f44d9","title":"Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector","content":"arXiv:2510.12287v1 Announce Type: new Abstract: Vision Language Models (VLMs) have achieved impressive progress in multimodal reasoning; yet, they remain vulnerable to hallucinations, where outputs are not grounded in visual evidence. In this paper, we investigate a previously overlooked setting: logo hallucination, where models generate brand names or textual content despite logos containing no visible words. Using curated splits of pure symbols, hybrids, and text-bearing logos, as well as the challenging Hard-60 subset, we systematically measure hallucination across leading VLMs. We further probe robustness through nine structured perturbations and show that hallucinations persist even under strong distortions, with occlusion exposing the sharpest weaknesses. Embedding-level analysis with open-weight LLaVA demonstrates that hallucination is tied to a small subset of projector dimensions, and targeted ablation substantially reduces errors while preserving OCR accuracy. Together, these findings reveal that VLMs often rely on symbolic priors rather than genuine glyph perception, particularly for iconic circular logos, and that projector subspaces play a decisive role in this failure mode. Our work contributes both a novel diagnostic lens and actionable mitigation insights, highlighting projector disentanglement and OCR-guided decoding as promising directions for building more trustworthy multimodal systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12287","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.343211","language":"en","tags":["preprints","computer-science","research","cscl","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Sifan Li, Hongkai Chen, Yujun Cai, Qingwen Ye, Liyang Chen, Junsong Yuan, Yiwei Wang","raw_content_length":1430,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Vision Language Models","Semantic Entanglement"],"persons":[],"locations":[],"monetary":[]},"char_count":1429,"language_detected":"en","key_concepts":{"key_phrases":["Vision Language Models Map Logos","Semantic Entanglement","the Visual Projector","arXiv251012287v1","new Abstract","Vision Language Models","VLMs","impressive progress","multimodal reasoning","hallucinations"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vision Language Models Map Logos":2.0,"Semantic Entanglement":2.0,"the Visual Projector":2.0,"arXiv251012287v1":1.0,"new Abstract":1.0,"Vision Language Models":1.0,"VLMs":1.0,"impressive progress":1.0,"multimodal reasoning":1.0,"hallucinations":1.0}},"age_hours":2.7406939794444445,"is_recent":true,"quality_score":1.0,"sentiment_score":9.198500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8397,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4168,"joy":0.0044,"surprise":0.0168,"sadness":0.0118,"fear":0.478,"anger":0.0252,"disgust":0.0469},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies a flaw in Vision Language Models related to logo hallucination. While it doesn't directly address climate change, improving the accuracy and trustworthiness of AI systems could indirectly support sustainability efforts by ensuring data integrity and reducing misinformation in climate-related applications. The research is at a basic research stage, with no deployed technology or measured outcomes in a real-world setting.","key_impact_metrics":["Hallucination reduction with targeted ablation","OCR accuracy preservation"],"technology_tags":["Vision Language Models","Logo Recognition","AI Hallucination Mitigation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:21:21.905285Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_07b2f89d51e3","title":"General Fourier Feature Physics-Informed Extreme Learning Machine (GFF","content":"arXiv:2510.12293v1 Announce Type: new Abstract: Conventional physics-informed extreme learning machine (PIELM) often faces challenges in solving partial differential equations (PDEs) involving high-frequency and variable-frequency behaviors. To address these challenges, we propose a general Fourier feature physics-informed extreme learning machine (GFF-PIELM). We demonstrate that directly concatenating multiple Fourier feature mappings (FFMs) and an extreme learning machine (ELM) network makes it difficult to determine frequency-related hyperparameters. Fortunately, we find an alternative to establish the GFF-PIELM in three main steps. First, we integrate a variation of FFM into ELM as the Fourier-based activation function, so there is still one hidden layer in the GFF-PIELM framework. Second, we assign a set of frequency coefficients to the hidden neurons, which enables ELM network to capture diverse frequency components of target solutions. Finally, we develop an innovative, straightforward initialization method for these hyperparameters by monitoring the distribution of ELM output weights. GFF-PIELM not only retains the high accuracy, efficiency, and simplicity of the PIELM framework but also inherits the ability of FFMs to effectively handle high-frequency problems. We carry out five case studies with a total of ten numerical examples to highlight the feasibility and validity of the proposed GFF-PIELM, involving high frequency, variable frequency, multi-scale behaviour, irregular boundary and inverse problems. Compared to conventional PIELM, the GFF-PIELM approach significantly improves predictive accuracy without additional cost in training time and architecture complexity. Our results confirm that that PIELM can be extended to solve high-frequency and variable-frequency PDEs with high accuracy, and our initialization strategy may further inspire advances in other physics-informed machine learning (PIML) frameworks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12293","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.343653","language":"en","tags":["preprints","csne","computer-science","cslg","research","physicscomp-ph","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":259,"author":"Fei Ren, Sifan Wang, Pei-Zhi Zhuang, Hai-Sui Yu, He Yang","raw_content_length":1955,"priority":7,"update_frequency":1,"reading_time_minutes":1.295,"robust_parsing_used":true,"entities":{"organizations":["Fourier","GFF arXiv:2510.12293v1 Announce Type: new Abstract","ELM","FFM","GFF","GFF-PIELM"],"persons":["Fourier"],"locations":[],"monetary":[]},"char_count":1954,"language_detected":"en","key_concepts":{"key_phrases":["GFF","arXiv251012293v1 Announce Type","new Abstract","Conventional physics-informed extreme learning machine","PIELM","challenges","partial differential equations","PDEs","high-frequency and variable-frequency behaviors","these challenges"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GFF":2.0,"arXiv251012293v1 Announce Type":1.0,"new Abstract":1.0,"Conventional physics-informed extreme learning machine":1.0,"PIELM":1.0,"challenges":1.0,"partial differential equations":1.0,"PDEs":1.0,"high-frequency and variable-frequency behaviors":1.0,"these challenges":1.0}},"age_hours":2.740709211111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2940000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4588,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7464,"joy":0.0084,"surprise":0.0149,"sadness":0.0091,"fear":0.1448,"anger":0.0474,"disgust":0.029},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel machine learning approach (GFF-PIELM) for solving partial differential equations, which could potentially improve the accuracy and efficiency of modeling complex physical systems. While the method shows promise in numerical examples, it is still in the applied research stage with no real-world deployments or economic viability demonstrated. The impact on climate is indirect, depending on how this improved modeling is used in climate-relevant applications.","key_impact_metrics":["Predictive accuracy improvement","Training time savings"],"technology_tags":["Physics-informed machine learning","Extreme learning machine","Fourier features"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:21:24.563063Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_68cfa247ad2c","title":"Show Your Title! A Scoping Review on Verbalization in Software Engineering with LLM","content":"arXiv:2510.12294v1 Announce Type: new Abstract: Understanding how software developers think, make decisions, and behave remains a key challenge in software engineering (SE). Verbalization techniques (methods that capture spoken or written thought processes) offer a lightweight and accessible way to study these cognitive aspects. This paper presents a scoping review of research at the intersection of SE and psychology (PSY), focusing on the use of verbal data. To make large-scale interdisciplinary reviews feasible, we employed a large language model (LLM)-assisted screening pipeline using GPT to assess the relevance of over 9,000 papers based solely on titles. We addressed two questions: what themes emerge from verbalization-related work in SE, and how effective are LLMs in supporting interdisciplinary review processes? We validated GPT's outputs against human reviewers and found high consistency, with a 13\\% disagreement rate. Prominent themes mainly were tied to the craft of SE, while more human-centered topics were underrepresented. The data also suggests that SE frequently draws on PSY methods, whereas the reverse is rare.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12294","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.344038","language":"en","tags":["preprints","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Gerg\\H{o} Balogh, D\\'avid K\\'osz\\'o, Homayoun Safarpour Motealegh Mahalegi, L\\'aszl\\'o T\\'oth, Bence Szak\\'acs, \\'Aron B\\'ucs\\'u","raw_content_length":1144,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["GPT","PSY"],"persons":[],"locations":[],"monetary":[]},"char_count":1143,"language_detected":"en","key_concepts":{"key_phrases":["Your Title","A Scoping Review","Verbalization","Software Engineering","LLM","arXiv251012294v1","Announce Type","new Abstract","software developers","decisions"],"filter_categories":{"engineering":["Software Engineering"],"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Your Title":2.0,"A Scoping Review":2.0,"Verbalization":2.0,"Software Engineering":2.0,"LLM":2.0,"arXiv251012294v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"software developers":1.0,"decisions":1.0}},"age_hours":2.7407248363888885,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7555,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1511,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8253,"joy":0.0827,"surprise":0.0671,"sadness":0.003,"fear":0.0061,"anger":0.0115,"disgust":0.0042},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the use of LLMs to improve the efficiency of literature reviews, specifically in the context of software engineering and psychology. While the LLM is deployed to screen papers, the direct climate impact is minimal. The paper does provide a disagreement rate of 13% between the LLM and human reviewers, offering a measurable outcome of the LLM's performance.","key_impact_metrics":["Disagreement rate 13%"],"technology_tags":["Large Language Models","Software Engineering","Literature Review"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:21:27.449632Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6d6c65035a69","title":"Ground Stratification for a Logic of Definitions with Induction","content":"arXiv:2510.12297v1 Announce Type: new Abstract: The logic underlying the Abella proof assistant includes mechanisms for interpreting atomic predicates through fixed point definitions that can additionally be treated inductively or co-inductively. However, the original formulation of the logic includes a strict stratification condition on definitions that is too restrictive for some applications such as those that use a logical relations based approach to semantic equivalence. Tiu has shown how this restriction can be eased by utilizing a weaker notion referred to as ground stratification. Tiu's results were limited to a version of the logic that does not treat inductive definitions. We show here that they can be extended to cover such definitions. While our results are obtained by using techniques that have been previously deployed in related ways in this context, their use is sensitive to the particular way in which we generalize the logic. In particular, although ground stratification may be used with arbitrary fixed-point definitions, we show that weakening stratification to this form for inductive definitions leads to inconsistency. The particular generalization we describe accords well with the way logical relations are used in practice. Our results are also a intermediate step to building a more flexible form for definitions into the full logic underlying Abella, which additionally includes co-induction, generic quantification, and a mechanism referred to as nominal abstraction for analyzing occurrences of objects in terms that are governed by generic quantifiers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12297","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.344843","language":"en","tags":["preprints","computer-science","research","cspl","cslo","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":234,"author":"Nathan Guermond (University of Minnesota), Gopalan Nadathur (University of Minnesota)","raw_content_length":1597,"priority":7,"update_frequency":1,"reading_time_minutes":1.17,"robust_parsing_used":true,"entities":{"organizations":["Abella","Tiu"],"persons":["Ground Stratification"],"locations":[],"monetary":[]},"char_count":1596,"language_detected":"en","key_concepts":{"key_phrases":["Ground Stratification","a Logic","Definitions","Induction","arXiv251012297v1 Announce Type","new Abstract","The logic","the Abella proof assistant","mechanisms","atomic predicates"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Ground Stratification":2.0,"a Logic":2.0,"Definitions":2.0,"Induction":2.0,"arXiv251012297v1 Announce Type":1.0,"new Abstract":1.0,"The logic":1.0,"the Abella proof assistant":1.0,"mechanisms":1.0,"atomic predicates":1.0}},"age_hours":2.7407528625,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8883,"joy":0.0108,"surprise":0.026,"sadness":0.0058,"fear":0.0192,"anger":0.0274,"disgust":0.0224},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical research in logic and proof systems, specifically addressing limitations in the Abella proof assistant. While the research aims to improve the efficiency and applicability of formal verification, it's at a very early stage and doesn't have direct, measurable environmental impact. The technical credibility is high due to the scientific nature of the work, but deployment readiness is low.","key_impact_metrics":[],"technology_tags":["formal verification","proof assistant","logic"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:21:30.491498Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2dc74090f8ae","title":"Flavors of Quantifiers in Hyperlogics","content":"arXiv:2510.12298v1 Announce Type: new Abstract: Hypertrace logic is a sorted first-order logic with separate sorts for time and execution traces. Its formulas specify hyperproperties, which are properties relating multiple traces. In this work, we extend hypertrace logic by introducing trace quantifiers that range over the set of all possible traces. In this extended logic, formulas can quantify over two kinds of trace variables: constrained trace variables, which range over a fixed set of traces defined by the model, and unconstrained trace variables, which can be assigned to any trace. In comparison, hyperlogics such as HyperLTL have only constrained trace quantifiers. We use hypertrace logic to study how different quantifier patterns affect the decidability of the satisfiability problem. We prove that hypertrace logic without constrained trace quantifiers is equivalent to monadic second-order logic of one successor (S1S), and therefore satisfiable, and that the trace-prefixed fragment (all trace quantifiers precede all time quantifiers) is equivalent to HyperQPTL. Moreover, we show that all hypertrace formulas where the only alternation between constrained trace quantifiers is from an existential to a universal quantifier are equisatisfiable to formulas without constraints on their trace variables and, therefore, decidable as well. Our framework allows us to study also time-prefixed hyperlogics, for which we provide new decidability and undecidability results","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12298","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.345245","language":"en","tags":["preprints","computer-science","research","csfl","cslo","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Marek Chalupa, Thomas A. Henzinger, Ana Oliveira da Costa","raw_content_length":1487,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["HyperLTL"],"persons":[],"locations":["S1S","Hyperlogics"],"monetary":[]},"char_count":1486,"language_detected":"en","key_concepts":{"key_phrases":["Flavors","Quantifiers","Hyperlogics","which","arXiv251012298v1 Announce Type","new Abstract","Hypertrace logic","a sorted first-order logic","separate sorts","time and execution traces"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Flavors":2.0,"Quantifiers":2.0,"Hyperlogics":2.0,"which":2.0,"arXiv251012298v1 Announce Type":1.0,"new Abstract":1.0,"Hypertrace logic":1.0,"a sorted first-order logic":1.0,"separate sorts":1.0,"time and execution traces":1.0}},"age_hours":2.740768653611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9347,"joy":0.007,"surprise":0.0387,"sadness":0.0032,"fear":0.0031,"anger":0.0088,"disgust":0.0045},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents theoretical research extending hypertrace logic, a formal system for specifying properties of systems. While the research is technically credible and innovative, it is at a very early stage and has no direct, measurable impact on sustainability. The potential impact is indirect, as improved formal methods could lead to better verification of sustainable systems in the future.","key_impact_metrics":[],"technology_tags":["formal verification","hyperlogics","computer science"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:21:34.073833Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d2fd9a8668c2","title":"CoLF Logic Programming as Infinitary Proof Exploration","content":"arXiv:2510.12302v1 Announce Type: new Abstract: Logical Frameworks such as Automath [de Bruijn, 1968] or LF [Harper et al., 1993] were originally conceived as metalanguages for the specification of foundationally uncommitted deductive systems, yielding generic proof checkers. Their high level of abstraction was soon exploited to also express algorithms over deductive systems such as theorem provers, type-checkers, evaluators, compilers, proof transformers, etc. in the paradigm of computation-as-proof-construction. This has been realized in languages such as $\\lambda$-Prolog [Miller et al., 1991] or Elf [Pfenning, 1991] based on backward chaining, and LolliMon [Lopez et al., 2005] or Celf [Schack-Nielsen and Schuermann, 2008], which integrated forward chaining. None of these early frameworks supported the direct expression of infinitary objects or proofs, which are available in the recently developed CoLF$^\\omega$ [Chen, 2023]. In this work-in-progress report, we sketch an approach to computation-as-proof-construction over the first-order fragment of CoLF$^\\omega$ (called CoLF$^\\omega_1$ ) that already includes infinitary objects and proofs. A key idea is the interpretation of logic variables as communication channels and computation as concurrent message-passing. This is realized in a concrete compiler from CoLF$^\\omega_1$ to Sax, a proof-theoretically inspired parallel programming language based on the proof-reduction in the semi-axiomatic sequent calculus [DeYoung et al., 2020].","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12302","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.348135","language":"en","tags":["preprints","computer-science","cslo","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Zhibo Chen (Carnegie Mellon University), Frank Pfenning (Carnegie Mellon University)","raw_content_length":1506,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Schack-Nielsen","Schuermann","LolliMon","CoLF Logic Programming"],"persons":["Celf","Miller","Frameworks","al.","Chen"],"locations":[],"monetary":[]},"char_count":1505,"language_detected":"en","key_concepts":{"key_phrases":["CoLF Logic Programming","Infinitary Proof Exploration","arXiv251012302v1 Announce Type","new Abstract","Logical Frameworks","Automath de Bruijn","et al","metalanguages","the specification","foundationally uncommitted deductive systems"],"filter_categories":{"engineering":["CoLF Logic Programming"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CoLF Logic Programming":2.0,"Infinitary Proof Exploration":2.0,"arXiv251012302v1 Announce Type":1.0,"new Abstract":1.0,"Logical Frameworks":1.0,"Automath de Bruijn":1.0,"et al":1.0,"metalanguages":1.0,"the specification":1.0,"foundationally uncommitted deductive systems":1.0}},"age_hours":2.7408133866666664,"is_recent":true,"quality_score":1.0,"sentiment_score":3.634,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2732,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8548,"joy":0.0361,"surprise":0.0859,"sadness":0.0043,"fear":0.0046,"anger":0.0112,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper describes a theoretical framework for computation-as-proof-construction, specifically focusing on infinitary objects and proofs. It mentions a compiler to a parallel programming language, but there is no evidence of deployment, measured outcomes, or specific impact on climate change. It is at the basic research stage.","key_impact_metrics":[],"technology_tags":["Logic Programming","Parallel Programming","Compilers"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:21:37.016127Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e71b7268358c","title":"Type Theory with Single Substitutions","content":"arXiv:2510.12303v1 Announce Type: new Abstract: Type theory can be described as a generalised algebraic theory. This automatically gives a notion of model and the existence of the syntax as the initial model, which is a quotient inductive-inductive type. Algebraic definitions of type theory include Ehrhard's definition of model, categories with families (CwFs), contextual categories, Awodey's natural models, C-systems, B-systems. With the exception of B-systems, these notions are based on a parallel substitution calculus where substitutions form a category. In this paper we define a single substitution calculus (SSC) for type theory and show that the SSC syntax and the CwF syntax are isomorphic for a theory with dependent function space and a hierarchy of universes. SSC only includes single substitutions and single weakenings, and eight equations relating these: four equations describe how to substitute variables, and there are four equations on types which are needed to typecheck the other equations. SSC provides a simple, minimalistic alternative to parallel substitution calculi or B-systems for defining type theory. SSC relates to CwF as extensional combinatory calculus relates to lambda calculus: there are more models of the former, but the syntaxes are equivalent. If we have some additional type formers, we show that an SSC model gives rise to a CwF.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12303","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.348545","language":"en","tags":["preprints","computer-science","cslo","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Ambrus Kaposi (E\\\"otv\\\"os Lor\\'and University), Szumi Xie (E\\\"otv\\\"os Lor\\'and University)","raw_content_length":1378,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["CwF","Ehrhard","SSC","Awodey","CwFs"],"persons":[],"locations":[],"monetary":[]},"char_count":1377,"language_detected":"en","key_concepts":{"key_phrases":["Type Theory","Single Substitutions","model","B-systems","arXiv251012303v1 Announce Type","new Abstract","Type theory","a generalised algebraic theory","a notion","the existence"],"filter_categories":{"ai_ml":["model"],"business_innovation":["model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Type Theory":2.0,"Single Substitutions":2.0,"model":2.0,"B-systems":2.0,"arXiv251012303v1 Announce Type":1.0,"new Abstract":1.0,"Type theory":1.0,"a generalised algebraic theory":1.0,"a notion":1.0,"the existence":1.0}},"age_hours":2.740829581666667,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8764,"joy":0.0179,"surprise":0.0308,"sadness":0.0047,"fear":0.0355,"anger":0.024,"disgust":0.0108},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical advancement in type theory, specifically a single substitution calculus (SSC). While it aims to simplify the foundations of type theory, it's currently at the basic research stage with no direct, measurable impact on sustainability. The technical credibility is relatively high due to its mathematical nature and potential for peer review.","key_impact_metrics":[],"technology_tags":["Type Theory","Single Substitution Calculus"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:21:39.816748Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dab94b281ff2","title":"A large","content":"arXiv:2510.12306v1 Announce Type: new Abstract: As natural language corpora expand at an unprecedented rate, manual annotation remains a significant methodological bottleneck in corpus linguistic work. We address this challenge by presenting a scalable, unsupervised pipeline for automating grammatical annotation in voluminous corpora using large language models (LLMs). Unlike previous supervised and iterative approaches, our method employs a four-phase workflow: prompt engineering, pre-hoc evaluation, automated batch processing, and post-hoc validation. We demonstrate the pipeline's accessibility and effectiveness through a diachronic case study of variation in the English consider construction. Using GPT-5 through the OpenAI API, we annotate 143,933 sentences from the Corpus of Historical American English (COHA) in under 60 hours, achieving 98%+ accuracy on two sophisticated annotation procedures. Our results suggest that LLMs can perform a range of data preparation tasks at scale with minimal human intervention, opening new possibilities for corpus-based research, though implementation requires attention to costs, licensing, and other ethical considerations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12306","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.349713","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Cameron Morin, Matti Marttinen Larsson","raw_content_length":1179,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["the Corpus of Historical American English","COHA"],"persons":[],"locations":[],"monetary":[]},"char_count":1178,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251012306v1 Announce Type","new Abstract","natural language corpora","an unprecedented rate","manual annotation","a significant methodological bottleneck","corpus linguistic work","this challenge","a scalable unsupervised pipeline","grammatical annotation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251012306v1 Announce Type":1.0,"new Abstract":1.0,"natural language corpora":1.0,"an unprecedented rate":1.0,"manual annotation":1.0,"a significant methodological bottleneck":1.0,"corpus linguistic work":1.0,"this challenge":1.0,"a scalable unsupervised pipeline":1.0,"grammatical annotation":1.0}},"age_hours":2.740869201111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.581,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7162,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8544,"joy":0.0272,"surprise":0.0723,"sadness":0.0077,"fear":0.0201,"anger":0.0146,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method for automating grammatical annotation using LLMs, achieving 98%+ accuracy on annotation procedures. While it automates a process, it doesn't directly reduce GHG emissions or address climate change. The deployment readiness is low as it's a pipeline demonstration, not a deployed solution with established supply chains or regulatory approvals.","key_impact_metrics":["98%+ accuracy","143,933 sentences annotated"],"technology_tags":["Large Language Models","Natural Language Processing","Automated Annotation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:21:42.822638Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6c386346549c","title":"Hybrid Gaussian Splatting for Novel Urban View Synthesis","content":"arXiv:2510.12308v1 Announce Type: new Abstract: This paper describes the Qualcomm AI Research solution to the RealADSim-NVS challenge, hosted at the RealADSim Workshop at ICCV 2025. The challenge concerns novel view synthesis in street scenes, and participants are required to generate, starting from car-centric frames captured during some training traversals, renders of the same urban environment as viewed from a different traversal (e.g. different street lane or car direction). Our solution is inspired by hybrid methods in scene generation and generative simulators merging gaussian splatting and diffusion models, and it is composed of two stages: First, we fit a 3D reconstruction of the scene and render novel views as seen from the target cameras. Then, we enhance the resulting frames with a dedicated single-step diffusion model. We discuss specific choices made in the initialization of gaussian primitives as well as the finetuning of the enhancer model and its training data curation. We report the performance of our model design and we ablate its components in terms of novel view quality as measured by PSNR, SSIM and LPIPS. On the public leaderboard reporting test results, our proposal reaches an aggregated score of 0.432, achieving the second place overall.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12308","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.350621","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Mohamed Omran, Farhad Zanjani, Davide Abati, Jens Petersen, Amirhossein Habibian","raw_content_length":1281,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["the Qualcomm AI Research","RealADSim-NVS"],"persons":[],"locations":[],"monetary":[]},"char_count":1280,"language_detected":"en","key_concepts":{"key_phrases":["Hybrid Gaussian Splatting","Novel Urban View Synthesis","arXiv251012308v1 Announce Type","new Abstract","This paper","the Qualcomm AI Research solution","the RealADSim-NVS challenge","the RealADSim Workshop","ICCV","The challenge"],"filter_categories":{"ai_ml":["the Qualcomm AI Research solution"],"research_academic":["the Qualcomm AI Research solution"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hybrid Gaussian Splatting":2.0,"Novel Urban View Synthesis":2.0,"arXiv251012308v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"the Qualcomm AI Research solution":1.0,"the RealADSim-NVS challenge":1.0,"the RealADSim Workshop":1.0,"ICCV":1.0,"The challenge":1.0}},"age_hours":2.740898875,"is_recent":true,"quality_score":1.0,"sentiment_score":8.7895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7579,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8665,"joy":0.0662,"surprise":0.0378,"sadness":0.0038,"fear":0.0059,"anger":0.0146,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper describes a novel view synthesis method for urban environments using gaussian splatting and diffusion models. While the technology is innovative and demonstrates performance based on PSNR, SSIM and LPIPS metrics, it is still in the research phase with no concrete deployment or measurable environmental impact. The vaporware flag is raised due to the lack of deployment and operational data.","key_impact_metrics":["Aggregated score on public leaderboard: 0.432","PSNR, SSIM and LPIPS scores"],"technology_tags":["Gaussian Splatting","Diffusion Models","Novel View Synthesis"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:21:46.318339Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8f4be1162212","title":"DeepTrust: Multi","content":"arXiv:2510.12310v1 Announce Type: new Abstract: Over the last decade, machine learning has been extensively applied to identify malicious Android applications. However, such approaches remain vulnerable against adversarial examples, i.e., examples that are subtly manipulated to fool a machine learning model into making incorrect predictions. This research presents DeepTrust, a novel metaheuristic that arranges flexible classifiers, like deep neural networks, into an ordered sequence where the final decision is made by a single internal model based on conditions activated in cascade. In the Robust Android Malware Detection competition at the 2025 IEEE Conference SaTML, DeepTrust secured the first place and achieved state-of-the-art results, outperforming the next-best competitor by up to 266% under feature-space evasion attacks. This is accomplished while maintaining the highest detection rate on non-adversarial malware and a false positive rate below 1%. The method's efficacy stems from maximizing the divergence of the learned representations among the internal models. By using classifiers inducing fundamentally dissimilar embeddings of the data, the decision space becomes unpredictable for an attacker. This frustrates the iterative perturbation process inherent to evasion attacks, enhancing system robustness without compromising accuracy on clean examples.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12310","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.351030","language":"en","tags":["preprints","computer-science","cscr","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Daniel Pulido-Cort\\'azar, Daniel Gibert, Felip Many\\`a","raw_content_length":1380,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Android","DeepTrust"],"persons":[],"locations":[],"monetary":[]},"char_count":1379,"language_detected":"en","key_concepts":{"key_phrases":["DeepTrust","Multi","arXiv251012310v1","Announce Type","new Abstract","the last decade","machine learning","malicious Android applications","such approaches","adversarial examples"],"filter_categories":{"ai_ml":["machine learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepTrust":3.0,"Multi":2.0,"arXiv251012310v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"the last decade":1.0,"machine learning":1.0,"malicious Android applications":1.0,"such approaches":1.0,"adversarial examples":1.0}},"age_hours":2.740913446388889,"is_recent":true,"quality_score":1.0,"sentiment_score":2.5305,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4939,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4995,"joy":0.0065,"surprise":0.016,"sadness":0.0112,"fear":0.3648,"anger":0.0572,"disgust":0.0447},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel metaheuristic for detecting malicious Android applications. While it achieved state-of-the-art results in a competition, there is no direct climate impact or deployment of the technology in a real-world setting. The technology is still in the applied research stage, with potential for future development.","key_impact_metrics":["outperforming competitor by 266%","false positive rate below 1%"],"technology_tags":["machine learning","malware detection","deep neural networks"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T16:21:49.482459Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_af78e75dcbfe","title":"Beating Harmful Stereotypes Through Facts: RAG","content":"arXiv:2510.12316v1 Announce Type: new Abstract: Counter-speech generation is at the core of many expert activities, such as fact-checking and hate speech, to counter harmful content. Yet, existing work treats counter-speech generation as pure text generation task, mainly based on Large Language Models or NGO experts. These approaches show severe drawbacks due to the limited reliability and coherence in the generated countering text, and in scalability, respectively. To close this gap, we introduce a novel framework to model counter-speech generation as knowledge-wise text generation process. Our framework integrates advanced Retrieval-Augmented Generation (RAG) pipelines to ensure the generation of trustworthy counter-speech for 8 main target groups identified in the hate speech literature, including women, people of colour, persons with disabilities, migrants, Muslims, Jews, LGBT persons, and other. We built a knowledge base over the United Nations Digital Library, EUR-Lex and the EU Agency for Fundamental Rights, comprising a total of 32,792 texts. We use the MultiTarget-CONAN dataset to empirically assess the quality of the generated counter-speech, both through standard metrics (i.e., JudgeLM) and a human evaluation. Results show that our framework outperforms standard LLM baselines and competitive approach, on both assessments. The resulting framework and the knowledge base pave the way for studying trustworthy and sound counter-speech generation, in hate speech and beyond.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12316","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.352213","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":211,"author":"Greta Damo, Elena Cabrio, Serena Villata","raw_content_length":1504,"priority":7,"update_frequency":1,"reading_time_minutes":1.055,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Retrieval-Augmented Generation","LGBT"],"persons":["RAG arXiv:2510.12316v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1503,"language_detected":"en","key_concepts":{"key_phrases":["Harmful Stereotypes","Facts","RAG","arXiv251012316v1 Announce Type","new Abstract","Counter-speech generation","the core","many expert activities","fact-checking and hate speech","harmful content"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Harmful Stereotypes":2.0,"Facts":2.0,"RAG":2.0,"arXiv251012316v1 Announce Type":1.0,"new Abstract":1.0,"Counter-speech generation":1.0,"the core":1.0,"many expert activities":1.0,"fact-checking and hate speech":1.0,"harmful content":1.0}},"age_hours":2.7409590833333333,"is_recent":true,"quality_score":1.0,"sentiment_score":1.018,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7964,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4503,"joy":0.0085,"surprise":0.0105,"sadness":0.0804,"fear":0.0368,"anger":0.1311,"disgust":0.2824},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":7,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework for counter-speech generation using RAG pipelines and a knowledge base of 32,792 texts. It demonstrates improved performance over LLM baselines using the MultiTarget-CONAN dataset, assessed through JudgeLM and human evaluation. While promising, it's still in the applied research stage with no clear path to economic viability or large-scale deployment, hence the low scores in those areas.","key_impact_metrics":["32,792 texts in knowledge base","Outperforms LLM baselines on MultiTarget-CONAN dataset"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T16:21:52.963159Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dee85e7aa1c6","title":"Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints","content":"arXiv:2510.12318v1 Announce Type: new Abstract: Since the 1990s, widespread introduction of central (wholesale) electricity markets has been seen across multiple continents, driven by the search for efficient operation of the power grid through competition. The increase of renewables has made significant impacts both on central electricity markets and distribution-level grids as renewable power generation is often connected to the latter. These stochastic renewable technologies have both advantages and disadvantages. On one hand they offer very low marginal cost and carbon emissions, while on the other hand, their output is uncertain, requiring flexible backup power with high marginal cost. Flexibility from end-prosumers or smaller market participants is therefore seen as a key enabler of large-scale integration of renewables. However, current central electricity markets do not directly include uncertainty into the market clearing and do not account for physical constraints of distribution grids. In this paper we propose a local electricity market framework based on probabilistic locational marginal pricing, effectively accounting for uncertainties in production, consumption and grid variables. The model includes a representation of the grid using the lindistflow equations and accounts for the propagation of uncertainty using general Polynomial Chaos (gPC). A two-stage convex model is proposed; in the day-ahead stage, probability distributions of prices are calculated for every timestep, where the expected values represent the day-ahead (spot) prices. In the real-time stage, uncertainties are realized (measured) and a trivial calculation reveals the real-time price. Through four instructive case-studies we highlight the effectiveness of the method to incentivize end-prosumers' participation in the market, while ensuring that their behavior does not have an adverse impact on the operation of the grid.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12318","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.352873","language":"en","tags":["preprints","eesssy","computer-science","research","cssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":270,"author":"P{\\aa}l Forr Austnes, Matthieu Jacobs, Lu Wang, Mario Paolone","raw_content_length":1934,"priority":7,"update_frequency":1,"reading_time_minutes":1.35,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1933,"language_detected":"en","key_concepts":{"key_phrases":["Prosumers","Incentive Design","Local Electricity Markets","Generalized Uncertainty","Grid Constraints","arXiv251012318v1 Announce Type","new Abstract","widespread introduction","central wholesale electricity markets","multiple continents"],"filter_categories":{"ai_ml":["Generalized Uncertainty"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Prosumers":2.0,"Incentive Design":2.0,"Local Electricity Markets":2.0,"Generalized Uncertainty":2.0,"Grid Constraints":2.0,"arXiv251012318v1 Announce Type":1.0,"new Abstract":1.0,"widespread introduction":1.0,"central wholesale electricity markets":1.0,"multiple continents":1.0}},"age_hours":2.7409734986111114,"is_recent":true,"quality_score":0.7,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5437,"joy":0.0321,"surprise":0.0338,"sadness":0.0149,"fear":0.2904,"anger":0.0664,"disgust":0.0186},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":6,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper proposes a local electricity market framework that incentivizes prosumer participation and accounts for grid constraints. The model uses probabilistic locational marginal pricing and general Polynomial Chaos (gPC) to handle uncertainties. The effectiveness is highlighted through four case studies, but there is no mention of real-world deployment, making it vaporware.","key_impact_metrics":["low marginal cost of renewables","carbon emissions reduction"],"technology_tags":["local electricity markets","probabilistic locational marginal pricing","Polynomial Chaos"],"sdg_alignment":[7,13],"analyzed_at":"2025-10-29T16:21:55.959677Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_025a3badfea5","title":"RAG-Anything: All","content":"arXiv:2510.12323v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm for expanding Large Language Models beyond their static training limitations. However, a critical misalignment exists between current RAG capabilities and real-world information environments. Modern knowledge repositories are inherently multimodal, containing rich combinations of textual content, visual elements, structured tables, and mathematical expressions. Yet existing RAG frameworks are limited to textual content, creating fundamental gaps when processing multimodal documents. We present RAG-Anything, a unified framework that enables comprehensive knowledge retrieval across all modalities. Our approach reconceptualizes multimodal content as interconnected knowledge entities rather than isolated data types. The framework introduces dual-graph construction to capture both cross-modal relationships and textual semantics within a unified representation. We develop cross-modal hybrid retrieval that combines structural knowledge navigation with semantic matching. This enables effective reasoning over heterogeneous content where relevant evidence spans multiple modalities. RAG-Anything demonstrates superior performance on challenging multimodal benchmarks, achieving significant improvements over state-of-the-art methods. Performance gains become particularly pronounced on long documents where traditional approaches fail. Our framework establishes a new paradigm for multimodal knowledge access, eliminating the architectural fragmentation that constrains current systems. Our framework is open-sourced at: https://github.com/HKUDS/RAG-Anything.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12323","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.353304","language":"en","tags":["preprints","computer-science","csai","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Zirui Guo, Xubin Ren, Lingrui Xu, Jiahao Zhang, Chao Huang","raw_content_length":1689,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["RAG","Language Models","Retrieval-Augmented Generation (RAG"],"persons":["RAG","RAG-Anything"],"locations":[],"monetary":[]},"char_count":1688,"language_detected":"en","key_concepts":{"key_phrases":["RAG","Anything","arXiv251012323v1 Announce Type","new Abstract","Retrieval-Augmented Generation","a fundamental paradigm","Large Language Models","their static training limitations","a critical misalignment","current RAG capabilities"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RAG":3.0,"Anything":2.0,"arXiv251012323v1 Announce Type":1.0,"new Abstract":1.0,"Retrieval-Augmented Generation":1.0,"a fundamental paradigm":1.0,"Large Language Models":1.0,"their static training limitations":1.0,"a critical misalignment":1.0,"current RAG capabilities":1.0}},"age_hours":2.7409872988888893,"is_recent":true,"quality_score":1.0,"sentiment_score":6.591,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3182,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9006,"joy":0.0048,"surprise":0.0612,"sadness":0.0069,"fear":0.0062,"anger":0.0106,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (RAG-Anything) for multimodal knowledge retrieval, which could indirectly support sustainability efforts by improving access to relevant information. The framework is open-sourced, which enhances transparency and reproducibility. However, it is currently at the basic research stage with no deployed units or operational data, limiting its immediate impact.","key_impact_metrics":["Significant improvements over state-of-the-art methods on multimodal benchmarks"],"technology_tags":["Retrieval-Augmented Generation","Large Language Models","Multimodal Knowledge Retrieval"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:21:59.233878Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_226038dd8ee4","title":"Simple Projection Variants Improve ColBERT Performance","content":"arXiv:2510.12327v1 Announce Type: new Abstract: Multi-vector dense retrieval methods like ColBERT systematically use a single-layer linear projection to reduce the dimensionality of individual vectors. In this study, we explore the implications of the MaxSim operator on the gradient flows of the training of multi-vector models and show that such a simple linear projection has inherent, if non-critical, limitations in this setting. We then discuss the theoretical improvements that could result from replacing this single-layer projection with well-studied alternative feedforward linear networks (FFN), such as deeper, non-linear FFN blocks, GLU blocks, and skip-connections, could alleviate these limitations. Through the design and systematic evaluation of alternate projection blocks, we show that better-designed final projections positively impact the downstream performance of ColBERT models. We highlight that many projection variants outperform the original linear projections, with the best-performing variants increasing average performance on a range of retrieval benchmarks across domains by over 2 NDCG@10 points. We then conduct further exploration on the individual parameters of these projections block in order to understand what drives this empirical performance, highlighting the particular importance of upscaled intermediate projections and residual connections. As part of these ablation studies, we show that numerous suboptimal projection variants still outperform the traditional single-layer projection across multiple benchmarks, confirming our hypothesis. Finally, we observe that this effect is consistent across random seeds, further confirming that replacing the linear layer of ColBERT models is a robust, drop-in upgrade.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12327","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.354182","language":"en","tags":["preprints","csai","csir","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Benjamin Clavi\\'e, Sean Lee, Rikiya Takehi, Aamir Shakir, Makoto P. Kato","raw_content_length":1759,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["FFN","GLU","linear","ColBERT"],"persons":[],"locations":[],"monetary":[]},"char_count":1758,"language_detected":"en","key_concepts":{"key_phrases":["Simple Projection Variants","ColBERT Performance","arXiv251012327v1","Announce Type","new Abstract","Multi-vector dense retrieval methods","ColBERT","a single-layer linear projection","the dimensionality","individual vectors"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Simple Projection Variants":2.0,"ColBERT Performance":2.0,"arXiv251012327v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Multi-vector dense retrieval methods":1.0,"ColBERT":1.0,"a single-layer linear projection":1.0,"the dimensionality":1.0,"individual vectors":1.0}},"age_hours":2.7410178241666667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.2985,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6597,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.891,"joy":0.0448,"surprise":0.0309,"sadness":0.0055,"fear":0.0068,"anger":0.0145,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores improvements to the ColBERT model, a multi-vector dense retrieval method, by modifying the linear projection layer. The concrete action is the design and evaluation of alternative projection blocks, showing a performance increase of over 2 NDCG@10 points on retrieval benchmarks. This is currently basic research with no deployed units, impacting climate indirectly by potentially improving information retrieval for sustainability-related topics.","key_impact_metrics":["NDCG@10 increase: 2"],"technology_tags":["ColBERT","Multi-vector dense retrieval","Linear Projection","Feedforward Neural Networks"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T16:22:02.737857Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06950c9893c9","title":"Leveraging Teleconnections with Physics","content":"arXiv:2510.12328v1 Announce Type: new Abstract: Accurate rainfall forecasting, particularly for extreme events, remains a significant challenge in climatology and the Earth system. This paper presents novel physics-informed Graph Neural Networks (GNNs) combined with extreme-value analysis techniques to improve gauge-station rainfall predictions across Thailand. The model leverages a graph-structured representation of gauge stations to capture complex spatiotemporal patterns, and it offers explainability through teleconnections. We preprocess relevant climate indices that potentially influence regional rainfall. The proposed Graph Attention Network with Long Short-Term Memory (Attention-LSTM) applies the attention mechanism using initial edge features derived from simple orographic-precipitation physics formulation. The embeddings are subsequently processed by LSTM layers. To address extremes, we perform Peak-Over-Threshold (POT) mapping using the novel Spatial Season-aware Generalized Pareto Distribution (GPD) method, which overcomes limitations of traditional machine-learning models. Experiments demonstrate that our method outperforms well-established baselines across most regions, including areas prone to extremes, and remains strongly competitive with the state of the art. Compared with the operational forecasting system SEAS5, our real-world application improves extreme-event prediction and offers a practical enhancement to produce fine-resolution maps that support decision-making in long-term water management.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12328","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.354615","language":"en","tags":["preprints","cslg","computer-science","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Kiattikun Chobtham, Kanoksri Sarinnapakorn, Kritanai Torsri, Prattana Deeprasertkul, Jirawan Kamma","raw_content_length":1541,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["POT","Graph Neural Networks"],"persons":[],"locations":["Earth","Thailand"],"monetary":[]},"char_count":1540,"language_detected":"en","key_concepts":{"key_phrases":["Teleconnections","Physics","arXiv251012328v1 Announce Type","new Abstract","Accurate rainfall forecasting","extreme events","a significant challenge","climatology","the Earth system","This paper"],"filter_categories":{"ai_ml":["Accurate rainfall forecasting"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Teleconnections":2.0,"Physics":2.0,"arXiv251012328v1 Announce Type":1.0,"new Abstract":1.0,"Accurate rainfall forecasting":1.0,"extreme events":1.0,"a significant challenge":1.0,"climatology":1.0,"the Earth system":1.0,"This paper":1.0}},"age_hours":2.7410320744444445,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8867,"joy":0.0311,"surprise":0.0384,"sadness":0.0073,"fear":0.0174,"anger":0.013,"disgust":0.0061},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":4,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel physics-informed GNN model for improved rainfall prediction, demonstrating outperformance against established baselines and SEAS5. This could lead to better water management and adaptation to climate change, but it is still in the applied research stage with no operational deployment mentioned. The improvement in extreme-event prediction is a concrete action, but economic viability and deployment readiness are low due to the lack of cost data and operational units.","key_impact_metrics":["Improved extreme-event prediction","Fine-resolution maps for water management"],"technology_tags":["Graph Neural Networks","Extreme-value analysis","Climate modeling"],"sdg_alignment":[6,13],"analyzed_at":"2025-10-29T16:22:06.878228Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a8ba059c05f","title":"Shape","content":"arXiv:2510.12332v1 Announce Type: new Abstract: This paper presents a shape-aware whole-body control framework for tendon-driven continuum robots with direct application to endoluminal surgical navigation. Endoluminal procedures, such as bronchoscopy, demand precise and safe navigation through tortuous, patient-specific anatomy where conventional tip-only control often leads to wall contact, tissue trauma, or failure to reach distal targets. To address these challenges, our approach combines a physics-informed backbone model with residual learning through an Augmented Neural ODE, enabling accurate shape estimation and efficient Jacobian computation. A sampling-based Model Predictive Path Integral (MPPI) controller leverages this representation to jointly optimize tip tracking, backbone conformance, and obstacle avoidance under actuation constraints. A task manager further enhances adaptability by allowing real-time adjustment of objectives, such as wall clearance or direct advancement, during tele-operation. Extensive simulation studies demonstrate millimeter-level accuracy across diverse scenarios, including trajectory tracking, dynamic obstacle avoidance, and shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom validate the framework, showing improved lumen-following accuracy, reduced wall contacts, and enhanced adaptability compared to joystick-only navigation and existing baselines. These results highlight the potential of the proposed framework to increase safety, reliability, and operator efficiency in minimally invasive endoluminal surgery, with broader applicability to other confined and safety-critical environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12332","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.355025","language":"en","tags":["preprints","computer-science","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Mohammadreza Kasaei, Mostafa Ghobadi, Mohsen Khadem","raw_content_length":1677,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Model Predictive Path Integral"],"persons":[],"locations":[],"monetary":[]},"char_count":1676,"language_detected":"en","key_concepts":{"key_phrases":["Shape","arXiv251012332v1 Announce Type","new Abstract","This paper","a shape-aware whole-body control framework","tendon-driven continuum robots","direct application","endoluminal surgical navigation","Endoluminal procedures","bronchoscopy"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Shape":2.0,"arXiv251012332v1 Announce Type":1.0,"new Abstract":1.0,"This paper":1.0,"a shape-aware whole-body control framework":1.0,"tendon-driven continuum robots":1.0,"direct application":1.0,"endoluminal surgical navigation":1.0,"Endoluminal procedures":1.0,"bronchoscopy":1.0}},"age_hours":2.741046183611111,"is_recent":true,"quality_score":0.7,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7107,"joy":0.0046,"surprise":0.0203,"sadness":0.0335,"fear":0.1954,"anger":0.0141,"disgust":0.0212},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a shape-aware control framework for continuum robots used in endoluminal surgery. While it demonstrates improved lumen-following accuracy and reduced wall contacts in a bronchoscopy phantom, it is still in the pilot stage and lacks real-world deployment data. The sustainability impact is indirect, potentially reducing medical waste and improving patient outcomes, but not directly addressing climate change or environmental issues.","key_impact_metrics":["millimeter-level accuracy","reduced wall contacts"],"technology_tags":["robotics","surgical navigation","AI"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T16:22:09.821426Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d6f86f032a8f","title":"Finite","content":"arXiv:2510.12334v1 Announce Type: new Abstract: Many popular practical reinforcement learning (RL) algorithms employ evolving reward functions-through techniques such as reward shaping, entropy regularization, or curriculum learning-yet their theoretical foundations remain underdeveloped. This paper provides the first finite-time convergence analysis of a single-timescale actor-critic algorithm in the presence of an evolving reward function under Markovian sampling. We consider a setting where the reward parameters may change at each time step, affecting both policy optimization and value estimation. Under standard assumptions, we derive non-asymptotic bounds for both actor and critic errors. Our result shows that an $O(1/\\sqrt{T})$ convergence rate is achievable, matching the best-known rate for static rewards, provided the reward parameters evolve slowly enough. This rate is preserved when the reward is updated via a gradient-based rule with bounded gradient and on the same timescale as the actor and critic, offering a theoretical foundation for many popular RL techniques. As a secondary contribution, we introduce a novel analysis of distribution mismatch under Markovian sampling, improving the best-known rate by a factor of $\\log^2T$ in the static-reward case.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12334","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.355423","language":"en","tags":["preprints","csai","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Rui Hu, Yu Chen, Longbo Huang","raw_content_length":1284,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Markovian","O(1/\\sqrt{T})$"],"locations":[],"monetary":[]},"char_count":1283,"language_detected":"en","key_concepts":{"key_phrases":["Finite","arXiv251012334v1","Announce Type","new Abstract","Many popular practical reinforcement learning","algorithms","reward functions","techniques","regularization","their theoretical foundations"],"filter_categories":{"ai_ml":["Many popular practical reinforcement learning","algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Finite":2.0,"arXiv251012334v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Many popular practical reinforcement learning":1.0,"algorithms":1.0,"reward functions":1.0,"techniques":1.0,"regularization":1.0,"their theoretical foundations":1.0}},"age_hours":2.7410603152777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6565,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9313,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8414,"joy":0.02,"surprise":0.097,"sadness":0.0076,"fear":0.0089,"anger":0.0186,"disgust":0.0066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical analysis of reinforcement learning algorithms with evolving reward functions, achieving an O(1/T) convergence rate. While the research is technically sound and peer-reviewed, it's currently in the basic research stage with no deployed technology or concrete actions demonstrating climate impact. The economic viability and deployment readiness are low due to the lack of practical application at this stage.","key_impact_metrics":["O(1/T) convergence rate","log^2T improvement in distribution mismatch"],"technology_tags":["reinforcement learning","actor-critic algorithms","Markovian sampling"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:22:14.268522Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f34bac8d47f","title":"Physics","content":"arXiv:2507.08986v2 Announce Type: replace-cross Abstract: Modeling rarefied hypersonic flows remains a fundamental challenge due to the breakdown of classical continuum assumptions in the transition-continuum regime, where the Knudsen number ranges from approximately 0.1 to 10. Conventional Navier-Stokes-Fourier (NSF) models with empirical slip-wall boundary conditions fail to accurately predict nonequilibrium effects such as velocity slip, temperature jump, and shock structure deviations. We develop a physics-constrained machine learning framework that augments transport models and boundary conditions to extend the applicability of continuum solvers in nonequilibrium hypersonic regimes. We employ deep learning PDE models (DPMs) for the viscous stress and heat flux embedded in the governing PDEs and trained via adjoint-based optimization. We evaluate these for two-dimensional supersonic flat-plate flows across a range of Mach and Knudsen numbers. Additionally, we introduce a wall model based on a mixture of skewed Gaussian approximations of the particle velocity distribution function. This wall model replaces empirical slip conditions with physically informed, data-driven boundary conditions for the streamwise velocity and wall temperature. Our results show that a trace-free anisotropic viscosity model, paired with the skewed-Gaussian distribution function wall model, achieves significantly improved accuracy, particularly at high-Mach and high-Knudsen number regimes. Strategies such as parallel training across multiple Knudsen numbers and inclusion of high-Mach data during training are shown to enhance model generalization. Increasing model complexity yields diminishing returns for out-of-sample cases, underscoring the need to balance degrees of freedom and overfitting. This work establishes data-driven, physics-consistent strategies for improving hypersonic flow modeling for regimes in which conventional continuum approaches are invalid.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.08986","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.735231","language":"en","tags":["preprints","computer-science","cslg","research","physicsflu-dyn","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":254,"author":"Ashish S. Nair, Narendra Singh, Marco Panesi, Justin Sirignano, Jonathan F. MacArt","raw_content_length":1973,"priority":7,"update_frequency":1,"reading_time_minutes":1.27,"robust_parsing_used":true,"entities":{"organizations":["PDE","NSF"],"persons":["Navier-Stokes-Fourier","Knudsen","Mach"],"locations":[],"monetary":[]},"char_count":1972,"language_detected":"en","key_concepts":{"key_phrases":["Physics","arXiv250708986v2","replace-cross Abstract","a fundamental challenge","the breakdown","classical continuum assumptions","the transition-continuum regime","the Knudsen number","Conventional Navier-Stokes-Fourier NSF models","empirical slip-wall boundary conditions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Physics":2.0,"arXiv250708986v2":1.0,"replace-cross Abstract":1.0,"a fundamental challenge":1.0,"the breakdown":1.0,"classical continuum assumptions":1.0,"the transition-continuum regime":1.0,"the Knudsen number":1.0,"Conventional Navier-Stokes-Fourier NSF models":1.0,"empirical slip-wall boundary conditions":1.0}},"age_hours":2.7505616091666667,"is_recent":true,"quality_score":1.0,"sentiment_score":1.6475,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6705,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8031,"joy":0.0083,"surprise":0.0837,"sadness":0.037,"fear":0.0395,"anger":0.0189,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a physics-constrained machine learning framework to improve hypersonic flow modeling. The concrete action is the development and evaluation of deep learning PDE models for viscous stress and heat flux. The evidence supporting claims includes improved accuracy at high-Mach and high-Knudsen number regimes, but it is still in the applied research stage with no deployment.","key_impact_metrics":["Improved accuracy at high-Mach number regimes","Improved accuracy at high-Knudsen number regimes"],"technology_tags":["Machine Learning","Hypersonic Flow Modeling","Deep Learning PDE Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:22:20.502979Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38fb790e7020","title":"MoBiLE: Efficient Mixture","content":"arXiv:2510.12357v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) models have recently demonstrated exceptional performance across a diverse range of applications. The principle of sparse activation in MoE models facilitates an offloading strategy, wherein active experts are maintained in GPU HBM, while inactive experts are stored in CPU DRAM. The efficacy of this approach, however, is fundamentally constrained by the limited bandwidth of the CPU-GPU interconnect. To mitigate this bottleneck, existing approaches have employed prefetching to accelerate MoE inference. These methods attempt to predict and prefetch the required experts using specially trained modules. Nevertheless, such techniques are often encumbered by significant training overhead and have shown diminished effectiveness on recent MoE models with fine-grained expert segmentation. In this paper, we propose MoBiLE, a plug-and-play offloading-based MoE inference framework with \\textit{mixture of big-little experts}. It reduces the number of experts for unimportant tokens to half for acceleration while maintaining full experts for important tokens to guarantee model quality. Further, a dedicated fallback and prefetching mechanism is designed for switching between little and big experts to improve memory efficiency. We evaluate MoBiLE on four typical modern MoE architectures and challenging generative tasks. Our results show that MoBiLE achieves a speedup of 1.60x to 1.72x compared to the baseline on a consumer GPU system, with negligible degradation in accuracy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12357","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.359715","language":"en","tags":["preprints","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Yushu Zhao, Yubin Qin, Yang Wang, Xiaolong Yang, Huiming Han, Shaojun Wei, Yang Hu, Shouyi Yin","raw_content_length":1558,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Efficient Mixture arXiv:2510.12357v1 Announce Type","GPU","CPU","HBM"],"persons":[],"locations":["CPU DRAM","\\textit{mixtur"],"monetary":[]},"char_count":1555,"language_detected":"en","key_concepts":{"key_phrases":["MoBiLE","Efficient Mixture","arXiv251012357v1 Announce Type","new Abstract","Experts","MoE","exceptional performance","a diverse range","applications","The principle"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MoBiLE":2.0,"Efficient Mixture":2.0,"arXiv251012357v1 Announce Type":1.0,"new Abstract":1.0,"Experts":1.0,"MoE":1.0,"exceptional performance":1.0,"a diverse range":1.0,"applications":1.0,"The principle":1.0}},"age_hours":2.7412052222222223,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8972,"joy":0.0176,"surprise":0.0492,"sadness":0.0074,"fear":0.0046,"anger":0.0136,"disgust":0.0105},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach (MoBiLE) to improve the efficiency of Mixture-of-Experts models, resulting in a reported 1.60x to 1.72x speedup on a consumer GPU system. This increased efficiency translates to reduced energy consumption for AI workloads. However, it is still in the applied research stage, with no evidence of deployment in real-world systems.","key_impact_metrics":["speedup of 1.60x to 1.72x","negligible degradation in accuracy"],"technology_tags":["mixture-of-experts","model optimization","GPU efficiency"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T16:22:27.383077Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_aaa9ff2691f6","title":"CurriFlow: Curriculum","content":"arXiv:2510.12362v1 Announce Type: new Abstract: Semantic Scene Completion (SSC) aims to infer complete 3D geometry and semantics from monocular images, serving as a crucial capability for camera-based perception in autonomous driving. However, existing SSC methods relying on temporal stacking or depth projection often lack explicit motion reasoning and struggle with occlusions and noisy depth supervision. We propose CurriFlow, a novel semantic occupancy prediction framework that integrates optical flow-based temporal alignment with curriculum-guided depth fusion. CurriFlow employs a multi-level fusion strategy to align segmentation, visual, and depth features across frames using pre-trained optical flow, thereby improving temporal consistency and dynamic object understanding. To enhance geometric robustness, a curriculum learning mechanism progressively transitions from sparse yet accurate LiDAR depth to dense but noisy stereo depth during training, ensuring stable optimization and seamless adaptation to real-world deployment. Furthermore, semantic priors from the Segment Anything Model (SAM) provide category-agnostic supervision, strengthening voxel-level semantic learning and spatial consistency. Experiments on the SemanticKITTI benchmark demonstrate that CurriFlow achieves state-of-the-art performance with a mean IoU of 16.9, validating the effectiveness of our motion-guided and curriculum-aware design for camera-based 3D semantic scene completion.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12362","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.360490","language":"en","tags":["preprints","computer-science","research","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Jinzhou Lin, Jie Zhou, Wenhao Xu, Rongtao Xu, Changwei Wang, Shunpeng Chen, Kexue Fu, Yihua Shao, Li Guo, Shibiao Xu","raw_content_length":1476,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["CurriFlow","Semantic Scene Completion","noisy depth supervision","SSC"],"persons":[],"locations":[],"monetary":[]},"char_count":1475,"language_detected":"en","key_concepts":{"key_phrases":["CurriFlow","Curriculum","arXiv251012362v1 Announce Type","new Abstract","Semantic Scene Completion","SSC","complete 3D geometry","semantics","monocular images","a crucial capability"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CurriFlow":3.0,"Curriculum":2.0,"arXiv251012362v1 Announce Type":1.0,"new Abstract":1.0,"Semantic Scene Completion":1.0,"SSC":1.0,"complete 3D geometry":1.0,"semantics":1.0,"monocular images":1.0,"a crucial capability":1.0}},"age_hours":2.741233978611111,"is_recent":true,"quality_score":1.0,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.894,"joy":0.0083,"surprise":0.0301,"sadness":0.0151,"fear":0.0294,"anger":0.0161,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"CurriFlow improves semantic scene completion for autonomous driving, potentially leading to safer and more efficient transportation systems. The article presents a novel framework with a curriculum learning mechanism and demonstrates state-of-the-art performance on the SemanticKITTI benchmark, achieving a mean IoU of 16.9. However, it is still in the applied research stage with no deployed units or economic viability data.","key_impact_metrics":["mean IoU of 16.9","improved temporal consistency"],"technology_tags":["semantic scene completion","autonomous driving","optical flow","curriculum learning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T16:22:30.609177Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6016bcbbccb9","title":"Pretraining in Actor","content":"arXiv:2510.12363v1 Announce Type: new Abstract: The pretraining-finetuning paradigm has facilitated numerous transformative advancements in artificial intelligence research in recent years. However, in the domain of reinforcement learning (RL) for robot motion control, individual skills are often learned from scratch despite the high likelihood that some generalizable knowledge is shared across all task-specific policies belonging to a single robot embodiment. This work aims to define a paradigm for pretraining neural network models that encapsulate such knowledge and can subsequently serve as a basis for warm-starting the RL process in classic actor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin with a task-agnostic exploration-based data collection algorithm to gather diverse, dynamic transition data, which is then used to train a Proprioceptive Inverse Dynamics Model (PIDM) through supervised learning. The pretrained weights are loaded into both the actor and critic networks to warm-start the policy optimization of actual tasks. We systematically validated our proposed method on seven distinct robot motion control tasks, showing significant benefits to this initialization strategy. Our proposed approach on average improves sample efficiency by 40.1% and task performance by 7.5%, compared to random initialization. We further present key ablation studies and empirical analyses that shed light on the mechanisms behind the effectiveness of our method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12363","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.360915","language":"en","tags":["preprints","computer-science","cslg","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Jiale Fan, Andrei Cramariuc, Tifanny Portela, Marco Hutter","raw_content_length":1500,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":["PPO"],"persons":["arXiv:2510.12363v1 Announce"],"locations":[],"monetary":[]},"char_count":1499,"language_detected":"en","key_concepts":{"key_phrases":["Actor","arXiv251012363v1 Announce Type","new Abstract","The pretraining-finetuning paradigm","numerous transformative advancements","artificial intelligence research","recent years","the domain","reinforcement learning","robot motion control"],"filter_categories":{"ai_ml":["The pretraining-finetuning paradigm","artificial intelligence research","reinforcement learning"],"research_academic":["artificial intelligence research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Actor":2.0,"arXiv251012363v1 Announce Type":1.0,"new Abstract":1.0,"The pretraining-finetuning paradigm":1.0,"numerous transformative advancements":1.0,"artificial intelligence research":1.0,"recent years":1.0,"the domain":1.0,"reinforcement learning":1.0,"robot motion control":1.0}},"age_hours":2.741248306666667,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8014,"joy":0.0078,"surprise":0.0167,"sadness":0.0084,"fear":0.0701,"anger":0.0548,"disgust":0.0408},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a pretraining method for robot motion control that improves sample efficiency and task performance compared to random initialization. The concrete action is the development and validation of a Proprioceptive Inverse Dynamics Model (PIDM) through supervised learning. The evidence supporting the claims is the systematic validation on seven distinct robot motion control tasks, showing a 40.1% improvement in sample efficiency and a 7.5% improvement in task performance. The deployment stage is currently at the applied research level.","key_impact_metrics":["sample efficiency improvement 40.1%","task performance improvement 7.5%"],"technology_tags":["Reinforcement Learning","Robot Motion Control","Pretraining"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T16:22:33.962791Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_002bfe646069","title":"(R)evolution of Programming: Vibe Coding as a Post","content":"arXiv:2510.12364v1 Announce Type: new Abstract: Recent advancements in generative artificial intelligence (GenAI), particularly large language models, have introduced new possibilities for software development practices. In our paper we investigate the emerging Vibe Coding (VC) paradigm that emphasizes intuitive, affect-driven, and improvisational interactions between developers and AI systems. Building upon the discourse of End-User Development (EUD), we explore how VC diverges from conventional programming approaches such as those supported by tools like GitHub Copilot. Through five semi-structured interview sessions with ten experienced software practitioners, we identify five thematic dimensions: creativity, sustainability, the future of programming, collaboration, and criticism. Our analysis conceptualizes VC within the metaphor of co-drifting, contrasting it with the prevalent co-piloting perspective of AI-assisted development. We argue that VC reconfigures the developers role, blurring boundaries between professional and non-developers. While VC enables novel forms of expression and rapid prototyping, it also introduces challenges regarding reproducibility, scalability, and inclusivity. We propose that VC represents a meaningful shift in programming culture, warranting further investigation within human-computer interaction (HCI) and software engineering research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12364","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.361465","language":"en","tags":["preprints","cshc","csai","computer-science","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Kevin Krings, Nino S. Bohn, Thomas Ludwig","raw_content_length":1394,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["End-User Development","Post","GitHub Copilot"],"persons":[],"locations":[],"monetary":[]},"char_count":1393,"language_detected":"en","key_concepts":{"key_phrases":["Revolution","Programming","Vibe Coding","a Post","Announce Type","new Abstract","Recent advancements","generative artificial intelligence","GenAI","particularly large language models"],"filter_categories":{"engineering":["Programming"],"ai_ml":["generative artificial intelligence","particularly large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Revolution":2.0,"Programming":2.0,"Vibe Coding":2.0,"a Post":2.0,"Announce Type":1.0,"new Abstract":1.0,"Recent advancements":1.0,"generative artificial intelligence":1.0,"GenAI":1.0,"particularly large language models":1.0}},"age_hours":2.741262718611111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7316,"joy":0.0342,"surprise":0.0226,"sadness":0.0061,"fear":0.126,"anger":0.0428,"disgust":0.0367},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores a new programming paradigm called Vibe Coding, but it's currently in the conceptual stage based on interviews. There are no concrete actions or measurable outcomes related to sustainability, and the focus is on the developer experience rather than environmental impact. The research is early-stage and lacks deployment or quantifiable data.","key_impact_metrics":[],"technology_tags":["AI","Generative AI","Software Development"],"sdg_alignment":[],"analyzed_at":"2025-10-29T16:22:36.675491Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a8623bd8cb69","title":"LLM","content":"arXiv:2510.12367v1 Announce Type: new Abstract: The rapid advancement of large language models (LLMs) has inspired researchers to integrate them extensively into the academic workflow, potentially reshaping how research is practiced and reviewed. While previous studies highlight the potential of LLMs in supporting research and peer review, their dual roles in the academic workflow and the complex interplay between research and review bring new risks that remain largely underexplored. In this study, we focus on how the deep integration of LLMs into both peer-review and research processes may influence scholarly fairness, examining the potential risks of using LLMs as reviewers by simulation. This simulation incorporates a research agent, which generates papers and revises, alongside a review agent, which assesses the submissions. Based on the simulation results, we conduct human annotations and identify pronounced misalignment between LLM-based reviews and human judgments: (1) LLM reviewers systematically inflate scores for LLM-authored papers, assigning them markedly higher scores than human-authored ones; (2) LLM reviewers persistently underrate human-authored papers with critical statements (e.g., risk, fairness), even after multiple revisions. Our analysis reveals that these stem from two primary biases in LLM reviewers: a linguistic feature bias favoring LLM-generated writing styles, and an aversion toward critical statements. These results highlight the risks and equity concerns posed to human authors and academic research if LLMs are deployed in the peer review cycle without adequate caution. On the other hand, revisions guided by LLM reviews yield quality gains in both LLM-based and human evaluations, illustrating the potential of the LLMs-as-reviewers for early-stage researchers and enhancing low-quality papers.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12367","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.361929","language":"en","tags":["preprints","csai","computer-science","research","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":258,"author":"Rui Li, Jia-Chen Gu, Po-Nien Kung, Heming Xia, Junfeng liu, Xiangwen Kong, Zhifang Sui, Nanyun Peng","raw_content_length":1852,"priority":7,"update_frequency":1,"reading_time_minutes":1.29,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1851,"language_detected":"en","key_concepts":{"key_phrases":["research","LLM","LLMs","the academic workflow","arXiv251012367v1 Announce Type","new Abstract","The rapid advancement","large language models","researchers","them"],"filter_categories":{"healthcare_tech":["research"],"research_academic":["research","the academic workflow","researchers"],"ai_ml":["LLM","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"research":3.0,"LLM":2.0,"LLMs":2.0,"the academic workflow":2.0,"arXiv251012367v1 Announce Type":1.0,"new Abstract":1.0,"The rapid advancement":1.0,"large language models":1.0,"researchers":1.0,"them":1.0}},"age_hours":2.7412773125000003,"is_recent":true,"quality_score":0.7,"sentiment_score":8.753,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7506,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.4914,"joy":0.0152,"surprise":0.0156,"sadness":0.0063,"fear":0.4242,"anger":0.0358,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores the potential biases of LLMs in peer review, using simulations to identify misalignment between LLM and human judgments. While it highlights potential quality gains in revisions guided by LLM reviews, it is primarily focused on identifying risks and biases, not on deploying technology for direct climate impact. The study is at the basic research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["LLM reviewer score inflation for LLM-authored papers","LLM reviewer score deflation for human-authored papers with critical statements"],"technology_tags":["Large Language Models","Peer Review Automation"],"sdg_alignment":[4,9,16],"analyzed_at":"2025-10-29T16:22:39.895089Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_825b09264216","title":"Constrained Sensing and Reliable State Estimation with Shallow Recurrent Decoders on a TRIGA Mark II Reactor","content":"arXiv:2510.12368v1 Announce Type: new Abstract: Shallow Recurrent Decoder networks are a novel data-driven methodology able to provide accurate state estimation in engineering systems, such as nuclear reactors. This deep learning architecture is a robust technique designed to map the temporal trajectories of a few sparse measures to the full state space, including unobservable fields, which is agnostic to sensor positions and able to handle noisy data through an ensemble strategy, leveraging the short training times and without the need for hyperparameter tuning. Following its application to a novel reactor concept, this work investigates the performance of Shallow Recurrent Decoders when applied to a real system. The underlying model is represented by a fluid dynamics model of the TRIGA Mark II research reactor; the architecture will use both synthetic temperature data coming from the numerical model and leveraging experimental temperature data recorded during a previous campaign. The objective of this work is, therefore, two-fold: 1) assessing if the architecture can reconstruct the full state of the system (temperature, velocity, pressure, turbulence quantities) given sparse data located in specific, low-dynamics channels and 2) assessing the correction capabilities of the architecture (that is, given a discrepancy between model and data, assessing if sparse measurements can provide some correction to the architecture output). As will be shown, the accurate reconstruction of every characteristic field, using both synthetic and experimental data, in real-time makes this approach suitable for interpretable monitoring and control purposes in the framework of a reactor digital twin.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.12368","published_date":"2025-10-15T04:00:00","collected_date":"2025-10-15T06:39:20.362350","language":"en","tags":["csce","preprints","computer-science","cslg","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":246,"author":"Stefano Riva, Carolina Introini, Jos\\`e Nathan Kutz, Antonio Cammi","raw_content_length":1711,"priority":7,"update_frequency":1,"reading_time_minutes":1.23,"robust_parsing_used":true,"entities":{"organizations":["Reliable State Estimation with Shallow Recurrent Decoders","Shallow Recurrent Decoders"],"persons":["Constrained Sensing","arXiv:2510.12368v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1710,"language_detected":"en","key_concepts":{"key_phrases":["Constrained Sensing","Reliable State Estimation","Shallow Recurrent Decoders","a TRIGA Mark II Reactor","arXiv251012368v1 Announce Type","new Abstract Shallow Recurrent Decoder networks","a novel data-driven methodology","accurate state estimation","engineering systems","nuclear reactors"],"filter_categories":{"ai_ml":["Constrained Sensing"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Constrained Sensing":2.0,"Reliable State Estimation":2.0,"Shallow Recurrent Decoders":2.0,"a TRIGA Mark II Reactor":2.0,"arXiv251012368v1 Announce Type":1.0,"new Abstract Shallow Recurrent Decoder networks":1.0,"a novel data-driven methodology":1.0,"accurate state estimation":1.0,"engineering systems":1.0,"nuclear reactors":1.0}},"age_hours":2.7412919722222218,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9116,"joy":0.0098,"surprise":0.0407,"sadness":0.0041,"fear":0.0093,"anger":0.0107,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel deep learning architecture for state estimation in nuclear reactors, using both synthetic and experimental data from a TRIGA Mark II reactor. While it shows promising results in reconstructing the full state of the system, it is still in the applied research stage with no deployed units or customer contracts. The impact on climate change is indirect, potentially improving reactor safety and efficiency, but not directly reducing emissions.","key_impact_metrics":["Real-time reconstruction of characteristic fields","Correction capabilities of architecture"],"technology_tags":["Shallow Recurrent Decoders","Digital Twin","Nuclear Reactor Monitoring"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T16:22:43.413546Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
