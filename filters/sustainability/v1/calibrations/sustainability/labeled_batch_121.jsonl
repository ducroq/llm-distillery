{"id":"science_arxiv_cs_1ca225286d19","title":"Networks Multiscale Entropy Analysis","content":"arXiv:2510.11524v1 Announce Type: new Abstract: Understanding the structural complexity and predictability of complex networks is a central challenge in network science. Although recent studies have revealed a relationship between compression-based entropy and link prediction performance, existing methods focus on single-scale representations. This approach often overlooks the rich hierarchical patterns that can exist in real-world networks. In this study, we introduce a multiscale entropy framework that extends previous entropy-based approaches by applying spectral graph reduction. This allows us to quantify how structural entropy evolves as the network is gradually coarsened, capturing complexity across multiple scales. We apply our framework to real-world networks across biological, economic, social, technological, and transportation domains. The results uncover consistent entropy profiles across network families, revealing three structural regimes$\\unicode{x2013}$stable, increasing, and hybrid$\\unicode{x2013}$that align with domain-specific behaviors. Compared to single-scale models, multiscale entropy significantly improves our ability to determine network predictability. This shows that considering structural information across scales provides a more complete characterization of network complexity. Together, these results position multiscale entropy as a powerful and scalable tool for characterizing, classifying, and assessing the structure of complex networks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11524","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.989974","language":"en","tags":["computer-science","preprints","math-ph","mathmp","research","cssi","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Sebasti\\'an Brzovic, Crist\\'obal Rojas, Andr\\'es Abeliuk","raw_content_length":1492,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["Networks Multiscale Entropy Analysis arXiv:2510.11524v1 Announce Type: new Abstract"],"persons":[],"locations":[],"monetary":[]},"char_count":1491,"language_detected":"en","key_concepts":{"key_phrases":["Networks Multiscale Entropy Analysis","Announce Type","new Abstract","the structural complexity","predictability","complex networks","a central challenge","network science","recent studies","a relationship"],"filter_categories":{"research_academic":["network science"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Networks Multiscale Entropy Analysis":2.0,"Announce Type":1.0,"new Abstract":1.0,"the structural complexity":1.0,"predictability":1.0,"complex networks":1.0,"a central challenge":1.0,"network science":1.0,"recent studies":1.0,"a relationship":1.0}},"age_hours":2.7596241058333333,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7012,"joy":0.005,"surprise":0.0199,"sadness":0.0115,"fear":0.1135,"anger":0.0734,"disgust":0.0755},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel method for analyzing complex networks, showing improved predictability compared to single-scale models. While it applies to networks in domains like transportation and economics, there's no direct evidence of GHG emission reduction or climate adaptation. The research is at an early stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["Improved network predictability","Consistent entropy profiles across network families"],"technology_tags":["Network analysis","Multiscale entropy","Spectral graph reduction"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:03:03.727237Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_12d612ec7beb","title":"A fourth","content":"arXiv:2510.11527v1 Announce Type: new Abstract: The active flux (AF) method is a compact high-order finite volume method originally proposed for solving hyperbolic conservation laws, in which cell averages and point values at cell interfaces are evolved simultaneously. This paper develops a fourth-order AF method for one- and two-dimensional parabolic problems, employing the explicit strong-stability-preserving Runge-Kutta (SSP-RK) method for time integration. The proposed method is built on a degenerate first-order system with auxiliary variables representing the derivatives of the primal variable, similar to local discontinuous Galerkin (LDG) methods, which avoids introducing pseudo-time or performing iterations within a physical time step in the existing hyperbolic formulations. The evolution of cell averages follows the standard finite volume method, ensuring conservation, while the point values of both the primal and auxiliary variables are updated using fourth-order central finite difference operators. A discrete Fourier analysis confirms the fourth-order accuracy in 1D. With the third-order SSP-RK method, the maximum CFL number for stability is $0.27$ in 1D, as obtained by von Neumann analysis, larger than that of LDG methods. The proposed method is further applied to the porous medium equation, and positivity-preserving limitings are incorporated to guarantee the non-negativity of the numerical solutions. Several numerical experiments validate the theoretical results and efficacy of the method.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11527","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.990777","language":"en","tags":["computer-science","preprints","csna","mathna","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":209,"author":"Junming Duan","raw_content_length":1528,"priority":7,"update_frequency":1,"reading_time_minutes":1.045,"robust_parsing_used":true,"entities":{"organizations":["Runge-Kutta","LDG"],"persons":["Galerkin","Announce Type"],"locations":[],"monetary":["fourth-order cent"]},"char_count":1527,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011527v1 Announce Type","new Abstract","The active flux","AF method","a compact high-order finite volume method","hyperbolic conservation laws","which","point values","cell interfaces","This paper"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011527v1 Announce Type":1.0,"new Abstract":1.0,"The active flux":1.0,"AF method":1.0,"a compact high-order finite volume method":1.0,"hyperbolic conservation laws":1.0,"which":1.0,"point values":1.0,"cell interfaces":1.0,"This paper":1.0}},"age_hours":2.7596533019444447,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8012,"joy":0.084,"surprise":0.0934,"sadness":0.0047,"fear":0.0035,"anger":0.0097,"disgust":0.0034},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new numerical method for solving parabolic problems, including the porous medium equation, which could be relevant for modeling subsurface CO2 storage or groundwater flow. However, it is currently in the basic research phase with no deployment or economic viability demonstrated. The method's accuracy is validated through discrete Fourier analysis and numerical experiments, providing some evidence of its technical credibility.","key_impact_metrics":["CFL number for stability: 0.27","Fourth-order accuracy in 1D"],"technology_tags":["numerical methods","finite volume method","parabolic equations","porous medium equation"],"sdg_alignment":[6,9],"analyzed_at":"2025-10-29T12:03:07.394735Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_07d54789ee9f","title":"Hallucination Detection via Internal States and Structured Reasoning Consistency in Large Language Models","content":"arXiv:2510.11529v1 Announce Type: new Abstract: The detection of sophisticated hallucinations in Large Language Models (LLMs) is hampered by a ``Detection Dilemma'': methods probing internal states (Internal State Probing) excel at identifying factual inconsistencies but fail on logical fallacies, while those verifying externalized reasoning (Chain-of-Thought Verification) show the opposite behavior. This schism creates a task-dependent blind spot: Chain-of-Thought Verification fails on fact-intensive tasks like open-domain QA where reasoning is ungrounded, while Internal State Probing is ineffective on logic-intensive tasks like mathematical reasoning where models are confidently wrong. We resolve this with a unified framework that bridges this critical gap. However, unification is hindered by two fundamental challenges: the Signal Scarcity Barrier, as coarse symbolic reasoning chains lack signals directly comparable to fine-grained internal states, and the Representational Alignment Barrier, a deep-seated mismatch between their underlying semantic spaces. To overcome these, we introduce a multi-path reasoning mechanism to obtain more comparable, fine-grained signals, and a segment-aware temporalized cross-attention module to adaptively fuse these now-aligned representations, pinpointing subtle dissonances. Extensive experiments on three diverse benchmarks and two leading LLMs demonstrate that our framework consistently and significantly outperforms strong baselines. Our code is available: https://github.com/peach918/HalluDet.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11529","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.991172","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Yusheng Song, Lirong Qiu, Xi Zhang, Zhihao Tang","raw_content_length":1554,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Hallucination Detection","the Signal Scarcity Barrier","Internal State Probing"],"persons":[],"locations":["Large","Internal States"],"monetary":[]},"char_count":1553,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Hallucination Detection","Internal States","Structured Reasoning Consistency","Thought","new Abstract","The detection","sophisticated hallucinations","LLMs","a Detection Dilemma"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":3.0,"Hallucination Detection":2.0,"Internal States":2.0,"Structured Reasoning Consistency":2.0,"Thought":2.0,"new Abstract":1.0,"The detection":1.0,"sophisticated hallucinations":1.0,"LLMs":1.0,"a Detection Dilemma":1.0}},"age_hours":2.7596685794444444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6232,"joy":0.0034,"surprise":0.04,"sadness":0.0593,"fear":0.0779,"anger":0.0564,"disgust":0.1397},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on detecting hallucinations in LLMs, which is currently in the basic research stage. While improved AI could potentially contribute to sustainability efforts in the future by optimizing resource allocation or improving climate modeling, there are no concrete actions or measurable outcomes related to sustainability in this paper. The research is focused on improving the accuracy of AI models, not on directly addressing environmental or social issues.","key_impact_metrics":[],"technology_tags":["Large Language Models","Hallucination Detection","AI"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:03:10.398298Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c1918490634","title":"Exploring Artificial Intelligence and Culture: Methodology for a comparative study of AI's impact on norms, trust, and problem","content":"arXiv:2510.11530v1 Announce Type: new Abstract: This paper proposes a rigorous framework to examine the two-way relationship between artificial intelligence (AI), human cognition, problem-solving, and cultural adaptation across academic and business settings. It addresses a key gap by asking how AI reshapes cognitive processes and organizational norms, and how cultural values and institutional contexts shape AI adoption, trust, and use over time. We employ a three-wave longitudinal design that tracks AI knowledge, perceived competence, trust trajectories, and cultural responses. Participants span academic institutions and diverse firms, enabling contextual comparison. A dynamic sample continuous, intermittent, and wave-specific respondents mirrors real organizational variability and strengthens ecological validity. Methodologically, the study integrates quantitative longitudinal modeling with qualitative thematic analysis to capture temporal, structural, and cultural patterns in AI uptake. We trace AI acculturation through phases of initial resistance, exploratory adoption, and cultural embedding, revealing distinctive trust curves and problem-solving strategies by context: academic environments tend to collaborative, deliberative integration; business environments prioritize performance, speed, and measurable outcomes. Framing adoption as bidirectional challenges deterministic views: AI both reflects and reconfigures norms, decision-making, and cognitive engagement. As the first comparative longitudinal study of its kind, this work advances methodological rigor and offers actionable foundations for human-centred, culturally responsive AI strategies-supporting evidence-based policies, training, and governance that align cognitive performance, organizational goals, and ethical commitments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11530","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.991604","language":"en","tags":["computer-science","cscy","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Matthias Huemmer, Theophile Shyiramunda, Michelle J. Cummings-Koether","raw_content_length":1820,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1819,"language_detected":"en","key_concepts":{"key_phrases":["trust","Artificial Intelligence","Culture","Methodology","a comparative study","AIs impact","norms","problem","arXiv251011530v1","Announce Type"],"filter_categories":{"ai_ml":["Artificial Intelligence"],"research_academic":["a comparative study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"trust":3.0,"Artificial Intelligence":2.0,"Culture":2.0,"Methodology":2.0,"a comparative study":2.0,"AIs impact":2.0,"norms":2.0,"problem":2.0,"arXiv251011530v1":1.0,"Announce Type":1.0}},"age_hours":2.7596840541666667,"is_recent":true,"quality_score":0.7,"sentiment_score":9.063,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8126,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.863,"joy":0.0318,"surprise":0.0353,"sadness":0.006,"fear":0.0307,"anger":0.0209,"disgust":0.0123},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a framework for studying the impact of AI on cultural norms and problem-solving. It is still in the research phase, with no deployed technology or measured outcomes related to climate impact. The study integrates quantitative and qualitative analysis, providing some evidence strength, but lacks concrete actions related to sustainability.","key_impact_metrics":["AI knowledge","Perceived competence"],"technology_tags":["Artificial Intelligence","Longitudinal Study"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T12:03:13.604545Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f62b3696efc1","title":"IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy","content":"arXiv:2510.11534v1 Announce Type: new Abstract: Realistic traffic simulation is critical for ensuring the safety and reliability of autonomous vehicles (AVs), especially in complex and diverse urban traffic environments. However, existing data-driven simulators face two key challenges: a limited focus on modeling dense, heterogeneous interactions at urban intersections - which are prevalent, crucial, and practically significant in countries like China, featuring diverse agents including motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and the inherent difficulty in robustly learning high-dimensional joint distributions for such high-density scenes, often leading to mode collapse and long-term simulation instability. We introduce City Crossings Dataset (CiCross), a large-scale dataset collected from a real-world urban intersection, uniquely capturing dense, heterogeneous multi-agent interactions, particularly with a substantial proportion of MVs, NMVs and pedestrians. Based on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving Environment), a data-driven simulator tailored for complex urban intersection scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a training paradigm that learns compositional dynamics from agent subsets, enabling the marginal-to-joint simulation. Integrated into a scene-aware Transformer network with specialized training techniques, IDS significantly enhances simulation robustness and long-term stability for modeling heterogeneous interactions. Experiments on CiCross show that IntersectioNDE outperforms baseline methods in simulation fidelity, stability, and its ability to replicate complex, distribution-level urban traffic dynamics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11534","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.992014","language":"en","tags":["eesssy","cssy","preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Enli Lin, Ziyuan Yang, Qiujing Lu, Jianming Hu, Shuo Feng","raw_content_length":1759,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Learning Complex Urban Traffic Dynamics","CiCross","City Crossings Dataset","Interaction Decoupling Strategy arXiv:2510.11534v1"],"persons":["Announce Type"],"locations":["China"],"monetary":[]},"char_count":1758,"language_detected":"en","key_concepts":{"key_phrases":["IntersectioNDE Learning Complex Urban Traffic Dynamics","Interaction Decoupling Strategy","arXiv251011534v1 Announce Type","new Abstract","Realistic traffic simulation","the safety","reliability","autonomous vehicles","AVs","complex and diverse urban traffic environments"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IntersectioNDE Learning Complex Urban Traffic Dynamics":2.0,"Interaction Decoupling Strategy":2.0,"arXiv251011534v1 Announce Type":1.0,"new Abstract":1.0,"Realistic traffic simulation":1.0,"the safety":1.0,"reliability":1.0,"autonomous vehicles":1.0,"AVs":1.0,"complex and diverse urban traffic environments":1.0}},"age_hours":2.7596993188888885,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8329,"joy":0.0264,"surprise":0.0283,"sadness":0.0101,"fear":0.0752,"anger":0.0209,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel data-driven simulator for urban traffic, IntersectioNDE, which aims to improve the safety and reliability of autonomous vehicles. While the simulator shows promise in replicating complex traffic dynamics, it is still in the applied research phase with no deployed units or real-world impact data. The potential climate impact is theoretical, relying on the assumption that improved AVs will lead to more efficient traffic flow and reduced emissions.","key_impact_metrics":["Simulation fidelity","Simulation stability"],"technology_tags":["Traffic simulation","Autonomous vehicles","Data-driven modeling"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:03:16.875306Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_91e09bd81ceb","title":"A Flexible Multi","content":"arXiv:2510.11535v1 Announce Type: new Abstract: Timely delivery of delay-sensitive information over dynamic, heterogeneous networks is increasingly essential for a range of interactive applications, such as industrial automation, self-driving vehicles, and augmented reality. However, most existing network control solutions target only average delay performance, falling short of providing strict End-to-End (E2E) peak latency guarantees. This paper addresses the challenge of reliably delivering packets within application-imposed deadlines by leveraging recent advancements in Multi-Agent Deep Reinforcement Learning (MA-DRL). After introducing the Delay-Constrained Maximum-Throughput (DCMT) dynamic network control problem, and highlighting the limitations of current solutions, we present a novel MA-DRL network control framework that leverages a centralized routing and distributed scheduling architecture. The proposed framework leverages critical networking domain knowledge for the design of effective MA-DRL strategies based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) technique, where centralized routing and distributed scheduling agents dynamically assign paths and schedule packet transmissions according to packet lifetimes, thereby maximizing on-time packet delivery. The generality of the proposed framework allows integrating both data-driven \\blue{Deep Reinforcement Learning (DRL)} agents and traditional rule-based policies in order to strike the right balance between performance and learning complexity. Our results confirm the superiority of the proposed framework with respect to traditional stochastic optimization-based approaches and provide key insights into the role and interplay between data-driven DRL agents and new rule-based policies for both efficient and high-performance control of latency-critical services.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11535","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.992425","language":"en","tags":["computer-science","csai","preprints","csni","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":230,"author":"Vincenzo Norman Vitale, Antonia Maria Tulino, Andreas F. Molisch, Jaime Llorca","raw_content_length":1868,"priority":7,"update_frequency":1,"reading_time_minutes":1.15,"robust_parsing_used":true,"entities":{"organizations":["MA-DRL"],"persons":[],"locations":["Multi"],"monetary":[]},"char_count":1867,"language_detected":"en","key_concepts":{"key_phrases":["A Flexible Multi","arXiv251011535v1 Announce Type","new Abstract","Timely delivery","delay-sensitive information","dynamic heterogeneous networks","a range","interactive applications","industrial automation","self-driving vehicles"],"filter_categories":{"engineering":["industrial automation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Flexible Multi":2.0,"arXiv251011535v1 Announce Type":1.0,"new Abstract":1.0,"Timely delivery":1.0,"delay-sensitive information":1.0,"dynamic heterogeneous networks":1.0,"a range":1.0,"interactive applications":1.0,"industrial automation":1.0,"self-driving vehicles":1.0}},"age_hours":2.759713698888889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.909,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3818,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9402,"joy":0.0086,"surprise":0.0257,"sadness":0.0069,"fear":0.0066,"anger":0.0082,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel MA-DRL network control framework to improve the timely delivery of delay-sensitive information. The framework is currently in the applied research stage, with results confirming its superiority compared to traditional approaches. While the technology has the potential to improve the efficiency of various applications, its climate impact is theoretical and not yet quantified in terms of GHG emissions reduction.","key_impact_metrics":["Maximum-Throughput","End-to-End peak latency guarantees"],"technology_tags":["Multi-Agent Deep Reinforcement Learning","Network Control","Dynamic Networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:03:20.044410Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5210975b1359","title":"CodeWatcher: IDE Telemetry Data Extraction Tool for Understanding Coding Interactions with LLMs","content":"arXiv:2510.11536v1 Announce Type: new Abstract: Understanding how developers interact with code generation tools (CGTs) requires detailed, real-time data on programming behavior which is often difficult to collect without disrupting workflow. We present \\textit{CodeWatcher}, a lightweight, unobtrusive client-server system designed to capture fine-grained interaction events from within the Visual Studio Code (VS Code) editor. \\textit{CodeWatcher} logs semantically meaningful events such as insertions made by CGTs, deletions, copy-paste actions, and focus shifts, enabling continuous monitoring of developer activity without modifying user workflows. The system comprises a VS Code plugin, a Python-based RESTful API, and a MongoDB backend, all containerized for scalability and ease of deployment. By structuring and timestamping each event, \\textit{CodeWatcher} enables post-hoc reconstruction of coding sessions and facilitates rich behavioral analyses, including how and when CGTs are used during development. This infrastructure is crucial for supporting research on responsible AI, developer productivity, and the human-centered evaluation of CGTs. Please find the demo, diagrams, and tool here: https://osf.io/j2kru/overview.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11536","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.992824","language":"en","tags":["computer-science","csai","preprints","csse","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Manaal Basha, Aime\\^e M. Ribeiro, Jeena Javahar, Cleidson R. B. de Souza, Gema Rodr\\'iguez-P\\'erez","raw_content_length":1237,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["API","IDE Telemetry Data Extraction Tool for Understanding Coding Interactions","Python","CodeWatcher","the Visual Studio Code"],"persons":[],"locations":[],"monetary":[]},"char_count":1236,"language_detected":"en","key_concepts":{"key_phrases":["CodeWatcher","IDE Telemetry Data Extraction Tool","Understanding Coding Interactions","LLMs","arXiv251011536v1 Announce Type","new Abstract","developers","code generation tools","CGTs","detailed real-time data"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CodeWatcher":2.0,"IDE Telemetry Data Extraction Tool":2.0,"Understanding Coding Interactions":2.0,"LLMs":2.0,"arXiv251011536v1 Announce Type":1.0,"new Abstract":1.0,"developers":1.0,"code generation tools":1.0,"CGTs":1.0,"detailed real-time data":1.0}},"age_hours":2.7597288358333336,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8874,"joy":0.0153,"surprise":0.0195,"sadness":0.0037,"fear":0.0396,"anger":0.0228,"disgust":0.0117},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a tool for collecting data on developer interactions with code generation tools. While it aims to support research on responsible AI, it does not directly reduce GHG emissions or address climate change. The tool is in the early stages of development and lacks deployment data.","key_impact_metrics":[],"technology_tags":["AI","Code Generation","Developer Tools"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:03:24.791171Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2012e9cc7ca0","title":"An Encoder","content":"arXiv:2510.11537v1 Announce Type: new Abstract: We propose a novel neural architecture named TextGraphFuseGAT, which integrates a pretrained transformer encoder (PhoBERT) with Graph Attention Networks for token-level classification tasks. The proposed model constructs a fully connected graph over the token embeddings produced by PhoBERT, enabling the GAT layer to capture rich inter-token dependencies beyond those modeled by sequential context alone. To further enhance contextualization, a Transformer-style self-attention layer is applied on top of the graph-enhanced embeddings. The final token representations are passed through a classification head to perform sequence labeling. We evaluate our approach on three Vietnamese benchmark datasets: PhoNER-COVID19 for named entity recognition in the COVID-19 domain, PhoDisfluency for speech disfluency detection, and VietMed-NER for medical-domain NER. VietMed-NER is the first Vietnamese medical spoken NER dataset, featuring 18 entity types collected from real-world medical speech transcripts and annotated with the BIO tagging scheme. Its specialized vocabulary and domain-specific expressions make it a challenging benchmark for token-level classification models. Experimental results show that our method consistently outperforms strong baselines, including transformer-only and hybrid neural models such as BiLSTM + CNN + CRF, confirming the effectiveness of combining pretrained semantic features with graph-based relational modeling for improved token classification across multiple domains.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11537","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.993213","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Ba-Quang Nguyen","raw_content_length":1556,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["GAT","COVID-19","NER","Graph Attention Networks","PhoBERT","Transformer","PhoDisfluency","VietMed-NER"],"persons":[],"locations":[],"monetary":[]},"char_count":1555,"language_detected":"en","key_concepts":{"key_phrases":["An Encoder","PhoBERT","arXiv251011537v1 Announce Type","new Abstract","a novel neural architecture","TextGraphFuseGAT","which","a pretrained transformer encoder","Graph Attention Networks","token-level classification tasks"],"filter_categories":{"ai_ml":["a pretrained transformer encoder"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"An Encoder":2.0,"PhoBERT":2.0,"arXiv251011537v1 Announce Type":1.0,"new Abstract":1.0,"a novel neural architecture":1.0,"TextGraphFuseGAT":1.0,"which":1.0,"a pretrained transformer encoder":1.0,"Graph Attention Networks":1.0,"token-level classification tasks":1.0}},"age_hours":2.7597432477777777,"is_recent":true,"quality_score":1.0,"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.874,"joy":0.0281,"surprise":0.0698,"sadness":0.0037,"fear":0.0061,"anger":0.0115,"disgust":0.0069},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new neural network architecture. While it shows improved performance on Vietnamese NLP tasks, it's in the basic research stage with no clear path to direct climate impact or deployment. The technical credibility is relatively high due to the peer-reviewed nature of the arXiv submission.","key_impact_metrics":[],"technology_tags":["Natural Language Processing","Graph Attention Networks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:03:27.749613Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_40352388a135","title":"Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers","content":"arXiv:2510.11538v1 Announce Type: new Abstract: Diffusion Transformers (DiTs) have recently emerged as a powerful backbone for visual generation. Recent observations reveal \\emph{Massive Activations} (MAs) in their internal feature maps, yet their function remains poorly understood. In this work, we systematically investigate these activations to elucidate their role in visual generation. We found that these massive activations occur across all spatial tokens, and their distribution is modulated by the input timestep embeddings. Importantly, our investigations further demonstrate that these massive activations play a key role in local detail synthesis, while having minimal impact on the overall semantic content of output. Building on these insights, we propose \\textbf{D}etail \\textbf{G}uidance (\\textbf{DG}), a MAs-driven, training-free self-guidance strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG constructs a degraded ``detail-deficient'' model by disrupting MAs and leverages it to guide the original network toward higher-quality detail synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG), enabling further refinements of fine-grained details. Extensive experiments demonstrate that our DG consistently improves fine-grained detail quality across various pre-trained DiTs (\\eg, SD3, SD3.5, and Flux).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11538","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.993612","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Chaofan Gan, Zicheng Zhao, Yuanpeng Tu, Xi Chen, Ziran Qin, Tieyuan Chen, Mehrtash Harandi, Weiyao Lin","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Diffusion Transformers arXiv:2510.11538v1 Announce Type","Massive Activations"],"persons":[],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Transformers","Massive Activations","the Key","Local Detail Synthesis","visual generation","arXiv251011538v1 Announce Type","new Abstract","DiTs","a powerful backbone","Recent observations"],"filter_categories":{"ai_ml":["Diffusion Transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Transformers":3.0,"Massive Activations":2.0,"the Key":2.0,"Local Detail Synthesis":2.0,"visual generation":2.0,"arXiv251011538v1 Announce Type":1.0,"new Abstract":1.0,"DiTs":1.0,"a powerful backbone":1.0,"Recent observations":1.0}},"age_hours":2.7597577175,"is_recent":true,"quality_score":1.0,"sentiment_score":7.1075,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4215,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8139,"joy":0.0116,"surprise":0.1102,"sadness":0.0108,"fear":0.0116,"anger":0.0247,"disgust":0.0172},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel technique (Detail Guidance) to improve the detail fidelity of Diffusion Transformers. While the research is technically sound and peer-reviewed, it is at a very early stage (basic research) and does not have any concrete deployments or measurable outcomes related to climate impact. The potential for climate impact is theoretical at this stage, as it's unclear how this improved image generation technique could directly reduce GHG emissions or address climate change.","key_impact_metrics":[],"technology_tags":["Diffusion Transformers","Image Generation","Machine Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:03:30.874306Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f90b576fb9d8","title":"Query","content":"arXiv:2510.11541v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) has demonstrated its ability to enhance Large Language Models (LLMs) by integrating external knowledge sources. However, multi-hop questions, which require the identification of multiple knowledge targets to form a synthesized answer, raise new challenges for RAG systems. Under the multi-hop settings, existing methods often struggle to fully understand the questions with complex semantic structures and are susceptible to irrelevant noise during the retrieval of multiple information targets. To address these limitations, we propose a novel graph representation learning framework for multi-hop question retrieval. We first introduce a Multi-information Level Knowledge Graph (Multi-L KG) to model various information levels for a more comprehensive understanding of multi-hop questions. Based on this, we design a Query-Specific Graph Neural Network (QSGNN) for representation learning on the Multi-L KG. QSGNN employs intra/inter-level message passing mechanisms, and in each message passing the information aggregation is guided by the query, which not only facilitates multi-granular information aggregation but also significantly reduces the impact of noise. To enhance its ability to learn robust representations, we further propose two synthesized data generation strategies for pre-training the QSGNN. Extensive experimental results demonstrate the effectiveness of our framework in multi-hop scenarios, especially in high-hop questions the improvement can reach 33.8\\%. The code is available at: https://github.com/Jerry2398/QSGNN.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11541","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.994392","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":213,"author":"Yuchen Yan, Zhihua Liu, Hao Wang, Weiming Li, Xiaoshuai Hao","raw_content_length":1630,"priority":7,"update_frequency":1,"reading_time_minutes":1.065,"robust_parsing_used":true,"entities":{"organizations":["RAG","QSGNN","Query-Specific Graph Neural Network","Query arXiv:2510.11541v1 Announce Type: new Abstract: Retrieval"],"persons":["Level Knowledge Graph"],"locations":[],"monetary":[]},"char_count":1629,"language_detected":"en","key_concepts":{"key_phrases":["Query","arXiv251011541v1 Announce Type","new Abstract","Retrieval-augmented generation","RAG","its ability","Large Language Models","LLMs","external knowledge sources","multi-hop questions"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Query":2.0,"arXiv251011541v1 Announce Type":1.0,"new Abstract":1.0,"Retrieval-augmented generation":1.0,"RAG":1.0,"its ability":1.0,"Large Language Models":1.0,"LLMs":1.0,"external knowledge sources":1.0,"multi-hop questions":1.0}},"age_hours":2.759786853611111,"is_recent":true,"quality_score":0.7,"sentiment_score":5.385999999999999,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8945,"joy":0.0038,"surprise":0.0334,"sadness":0.0119,"fear":0.0298,"anger":0.0179,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel graph representation learning framework (QSGNN) for multi-hop question retrieval, improving performance by up to 33.8% in high-hop questions. While the research shows promise in enhancing information retrieval, it is currently in the basic research stage with no deployed units or real-world data demonstrating a direct climate impact. The vaporware flag is raised due to the lack of deployment and operational data.","key_impact_metrics":["Improvement in high-hop questions: 33.8%"],"technology_tags":["Retrieval-augmented generation","Graph Neural Networks","Knowledge Graph"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:03:35.048998Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e1a22013823","title":"NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning","content":"arXiv:2510.11542v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as a powerful method to learn robust control policies for bipedal locomotion. Yet, it can be difficult to tune desired robot behaviors due to unintuitive and complex reward design. In comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics, offer more tuneable, interpretable, and mathematically grounded motion plans for high-dimensional legged systems. However, these methods often remain brittle to real-world disturbances like external perturbations. In this work, we present NaviGait, a hierarchical framework that combines the structure of trajectory optimization with the adaptability of RL for robust and intuitive locomotion control. NaviGait leverages a library of offline-optimized gaits and smoothly interpolates between them to produce continuous reference motions in response to high-level commands. The policy provides both joint-level and velocity command residual corrections to modulate and stabilize the reference trajectories in the gait library. One notable advantage of NaviGait is that it dramatically simplifies reward design by encoding rich motion priors from trajectory optimization, reducing the need for finely tuned shaping terms and enabling more stable and interpretable learning. Our experimental results demonstrate that NaviGait enables faster training compared to conventional and imitation-based RL, and produces motions that remain closest to the original reference. Overall, by decoupling high-level motion generation from low-level correction, NaviGait offers a more scalable and generalizable approach for achieving dynamic and robust locomotion.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11542","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.994818","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Neil C. Janwani, Varun Madabushi, Maegan Tucker","raw_content_length":1701,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["Hybrid Zero Dynamics","Deep Reinforcement Learning arXiv:2510.11542v1 Announce Type"],"persons":[],"locations":["NaviGait"],"monetary":[]},"char_count":1698,"language_detected":"en","key_concepts":{"key_phrases":["NaviGait","Dynamically Feasible Gait Libraries","Deep Reinforcement Learning","Announce Type","new Abstract","Reinforcement learning","a powerful method","robust control policies","bipedal locomotion","desired robot behaviors"],"filter_categories":{"ai_ml":["NaviGait","Deep Reinforcement Learning","Reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"NaviGait":2.0,"Dynamically Feasible Gait Libraries":2.0,"Deep Reinforcement Learning":2.0,"Announce Type":1.0,"new Abstract":1.0,"Reinforcement learning":1.0,"a powerful method":1.0,"robust control policies":1.0,"bipedal locomotion":1.0,"desired robot behaviors":1.0}},"age_hours":2.759801566666667,"is_recent":true,"quality_score":1.0,"sentiment_score":9.701500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9403,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.895,"joy":0.0086,"surprise":0.042,"sadness":0.0072,"fear":0.017,"anger":0.0164,"disgust":0.0138},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to bipedal locomotion control using reinforcement learning and trajectory optimization. While the experimental results demonstrate faster training compared to conventional methods, it is still in the early stages of development with no deployed units or real-world applications. The impact on climate is indirect, potentially reducing energy consumption of robots, but not quantified.","key_impact_metrics":["Faster training compared to conventional RL","Motions remain closest to the original reference"],"technology_tags":["Reinforcement Learning","Trajectory Optimization","Bipedal Locomotion"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:03:40.100648Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e268af59e47a","title":"Sublinear Algorithms for Estimating Single","content":"arXiv:2510.11547v1 Announce Type: new Abstract: Single-linkage clustering is a fundamental method for data analysis. Algorithmically, one can compute a single-linkage $k$-clustering (a partition into $k$ clusters) by computing a minimum spanning tree and dropping the $k-1$ most costly edges. This clustering minimizes the sum of spanning tree weights of the clusters. This motivates us to define the cost of a single-linkage $k$-clustering as the weight of the corresponding spanning forest, denoted by $\\mathrm{cost}_k$. Besides, if we consider single-linkage clustering as computing a hierarchy of clusterings, the total cost of the hierarchy is defined as the sum of the individual clusterings, denoted by $\\mathrm{cost}(G) = \\sum_{k=1}^{n} \\mathrm{cost}_k$. In this paper, we assume that the distances between data points are given as a graph $G$ with average degree $d$ and edge weights from $\\{1,\\dots, W\\}$. Given query access to the adjacency list of $G$, we present a sampling-based algorithm that computes a succinct representation of estimates $\\widehat{\\mathrm{cost}}_k$ for all $k$. The running time is $\\tilde O(d\\sqrt{W}/\\varepsilon^3)$, and the estimates satisfy $\\sum_{k=1}^{n} |\\widehat{\\mathrm{cost}}_k - \\mathrm{cost}_k| \\le \\varepsilon\\cdot \\mathrm{cost}(G)$, for any $0<\\varepsilon <1$. Thus we can approximate the cost of every $k$-clustering upto $(1+\\varepsilon)$ factor \\emph{on average}. In particular, our result ensures that we can estimate $\\cost(G)$ upto a factor of $1\\pm \\varepsilon$ in the same running time. We also extend our results to the setting where edges represent similarities. In this case, the clusterings are defined by a maximum spanning tree, and our algorithms run in $\\tilde{O}(dW/\\varepsilon^3)$ time. We futher prove nearly matching lower bounds for estimating the total clustering cost and we extend our algorithms to metric space settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11547","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.995652","language":"en","tags":["preprints","research","computer-science","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":267,"author":"Pan Peng, Christian Sohler, Yi Xu","raw_content_length":1899,"priority":7,"update_frequency":1,"reading_time_minutes":1.335,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Sublinear Algorithms","\\mathrm{cost}_k$. Besides","\\sum_{k=1}^{n} \\mathrm{cost}_k$."],"locations":[],"monetary":["\\{1,\\dots","$k-1$"]},"char_count":1894,"language_detected":"en","key_concepts":{"key_phrases":["Sublinear Algorithms","Estimating Single","a single-linkage k-clustering","arXiv251011547v1 Announce Type","new Abstract","Single-linkage clustering","a fundamental method","data analysis","one","a partition"],"filter_categories":{"ai_ml":["Sublinear Algorithms"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sublinear Algorithms":2.0,"Estimating Single":2.0,"a single-linkage k-clustering":2.0,"arXiv251011547v1 Announce Type":1.0,"new Abstract":1.0,"Single-linkage clustering":1.0,"a fundamental method":1.0,"data analysis":1.0,"one":1.0,"a partition":1.0}},"age_hours":2.7598313783333333,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1194999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1761,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8994,"joy":0.0397,"surprise":0.0267,"sadness":0.0063,"fear":0.0043,"anger":0.0142,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for estimating the cost of single-linkage clustering, which could potentially be applied to optimize resource allocation in various sustainability-related domains. The algorithm's performance is quantified with a running time of $\\tilde O(d\\sqrt{W}/\\varepsilon^3)$ and an approximation error bound, and it is supported by nearly matching lower bounds. However, it remains at the basic research stage with no immediate deployment or concrete climate impact.","key_impact_metrics":["Running time: $\\tilde O(d\\sqrt{W}/\\varepsilon^3)$","Approximation error: $\\varepsilon\\cdot \\mathrm{cost}(G)$"],"technology_tags":["Clustering algorithms","Data analysis","Optimization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:03:43.923921Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ca74763069bf","title":"ODI","content":"arXiv:2510.11549v1 Announce Type: new Abstract: Omnidirectional images (ODIs) provide full 360x180 view which are widely adopted in VR, AR and embodied intelligence applications. While multi-modal large language models (MLLMs) have demonstrated remarkable performance on conventional 2D image and video understanding benchmarks, their ability to comprehend the immersive environments captured by ODIs remains largely unexplored. To address this gap, we first present ODI-Bench, a novel comprehensive benchmark specifically designed for omnidirectional image understanding. ODI-Bench contains 2,000 high-quality omnidirectional images and over 4,000 manually annotated question-answering (QA) pairs across 10 fine-grained tasks, covering both general-level and spatial-level ODI understanding. Extensive experiments are conducted to benchmark 20 representative MLLMs, including proprietary and open-source models, under both close-ended and open-ended settings. Experimental results reveal that current MLLMs still struggle to capture the immersive context provided by ODIs. To this end, we further introduce Omni-CoT, a training-free method which significantly enhances MLLMs' comprehension ability in the omnidirectional environment through chain-of-thought reasoning across both textual information and visual cues. Both the benchmark and the code will be released upon the publication.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11549","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.996041","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Liu Yang, Huiyu Duan, Ran Tao, Juntao Cheng, Sijing Wu, Yunhao Li, Jing Liu, Xiongkuo Min, Guangtao Zhai","raw_content_length":1389,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["ODI","ODI arXiv:2510.11549v1 Announce Type","ODI-Bench"],"persons":[],"locations":[],"monetary":[]},"char_count":1388,"language_detected":"en","key_concepts":{"key_phrases":["ODI","ODIs","arXiv251011549v1 Announce Type","new Abstract","Omnidirectional images","full 360x180 view","which","intelligence applications","multi-modal large language models","MLLMs"],"filter_categories":{"ai_ml":["multi-modal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ODI":2.0,"ODIs":2.0,"arXiv251011549v1 Announce Type":1.0,"new Abstract":1.0,"Omnidirectional images":1.0,"full 360x180 view":1.0,"which":1.0,"intelligence applications":1.0,"multi-modal large language models":1.0,"MLLMs":1.0}},"age_hours":2.7598458527777776,"is_recent":true,"quality_score":0.7,"sentiment_score":9.531,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9062,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8381,"joy":0.0191,"surprise":0.1211,"sadness":0.0039,"fear":0.0062,"anger":0.008,"disgust":0.0036},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a new benchmark and method for omnidirectional image understanding using MLLMs. While the technology could potentially improve applications in areas like embodied intelligence, its direct impact on climate change or sustainability is currently theoretical and unquantified. The research is in an early stage, with no deployed units or real-world data available yet.","key_impact_metrics":[],"technology_tags":["Omnidirectional images","Multi-modal large language models","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:03:47.486174Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a661c7a0f77a","title":"Personalized and Constructive Feedback for Computer Science Students Using the Large Language Model (LLM)","content":"arXiv:2510.11556v1 Announce Type: new Abstract: The evolving pedagogy paradigms are leading toward educational transformations. One fundamental aspect of effective learning is relevant, immediate, and constructive feedback to students. Providing constructive feedback to large cohorts in academia is an ongoing challenge. Therefore, academics are moving towards automated assessment to provide immediate feedback. However, current approaches are often limited in scope, offering simplistic responses that do not provide students with personalized feedback to guide them toward improvements. This paper addresses this limitation by investigating the performance of Large Language Models (LLMs) in processing students assessments with predefined rubrics and marking criteria to generate personalized feedback for in-depth learning. We aim to leverage the power of existing LLMs for Marking Assessments, Tracking, and Evaluation (LLM-MATE) with personalized feedback to enhance students learning. To evaluate the performance of LLM-MATE, we consider the Software Architecture (SA) module as a case study. The LLM-MATE approach can help module leaders overcome assessment challenges with large cohorts. Also, it helps students improve their learning by obtaining personalized feedback in a timely manner. Additionally, the proposed approach will facilitate the establishment of ground truth for automating the generation of students assessment feedback using the ChatGPT API, thereby reducing the overhead associated with large cohort assessments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11556","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.997756","language":"en","tags":["cscy","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Javed Ali Khan, Muhammad Yaqoob, Mamoona Tasadduq, Hafsa Shareef Dar, Aitezaz Ahsan","raw_content_length":1544,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","Marking Assess"],"persons":[],"locations":[],"monetary":[]},"char_count":1543,"language_detected":"en","key_concepts":{"key_phrases":["Personalized and Constructive Feedback","Computer Science Students","the Large Language Model","LLM","arXiv251011556v1 Announce Type","new Abstract","The evolving pedagogy paradigms","educational transformations","One fundamental aspect","effective learning"],"filter_categories":{"research_academic":["Computer Science Students"],"ai_ml":["the Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Personalized and Constructive Feedback":2.0,"Computer Science Students":2.0,"the Large Language Model":2.0,"LLM":2.0,"arXiv251011556v1 Announce Type":1.0,"new Abstract":1.0,"The evolving pedagogy paradigms":1.0,"educational transformations":1.0,"One fundamental aspect":1.0,"effective learning":1.0}},"age_hours":2.759904728888889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8886,"joy":0.0403,"surprise":0.0238,"sadness":0.0037,"fear":0.0078,"anger":0.0245,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the use of LLMs for personalized feedback in computer science education. While it aims to improve learning outcomes, it doesn't directly address climate change or environmental sustainability. The research is in the early stages, with no deployed units or operational data available, hence the vaporware flag.","key_impact_metrics":[],"technology_tags":["Large Language Models","Automated Assessment"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:03:50.872319Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_47444fd3fff3","title":"Invisible Languages of the LLM Universe","content":"arXiv:2510.11557v1 Announce Type: new Abstract: Large Language Models are trained on massive multilingual corpora, yet this abundance masks a profound crisis: of the world's 7,613 living languages, approximately 2,000 languages with millions of speakers remain effectively invisible in digital ecosystems. We propose a critical framework connecting empirical measurements of language vitality (real world demographic strength) and digitality (online presence) with postcolonial theory and epistemic injustice to explain why linguistic inequality in AI systems is not incidental but structural. Analyzing data across all documented human languages, we identify four categories: Strongholds (33%, high vitality and digitality), Digital Echoes (6%, high digitality despite declining vitality), Fading Voices (36%, low on both dimensions), and critically, Invisible Giants (27%, high vitality but near-zero digitality) - languages spoken by millions yet absent from the LLM universe. We demonstrate that these patterns reflect continuities from colonial-era linguistic hierarchies to contemporary AI development, constituting what we term digital epistemic injustice. Our analysis reveals that English dominance in AI is not a technical necessity but an artifact of power structures that systematically exclude marginalized linguistic knowledge. We conclude with implications for decolonizing language technology and democratizing access to AI benefits.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11557","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.998155","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":192,"author":"Saurabh Khanna, Xinxu Li","raw_content_length":1450,"priority":7,"update_frequency":1,"reading_time_minutes":0.96,"robust_parsing_used":true,"entities":{"organizations":["Invisible Giants","Digital Echoes"],"persons":["Strongholds"],"locations":[],"monetary":[]},"char_count":1449,"language_detected":"en","key_concepts":{"key_phrases":["Invisible Languages","the LLM Universe","arXiv251011557v1","Announce Type","new Abstract","Large Language Models","massive multilingual corpora","this abundance masks","a profound crisis","the worlds 7613 living languages"],"filter_categories":{"ai_ml":["the LLM Universe","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Invisible Languages":2.0,"the LLM Universe":2.0,"arXiv251011557v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"massive multilingual corpora":1.0,"this abundance masks":1.0,"a profound crisis":1.0,"the worlds 7613 living languages":1.0}},"age_hours":2.7599201430555556,"is_recent":true,"quality_score":1.0,"sentiment_score":6.25,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.25,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5914,"joy":0.0156,"surprise":0.167,"sadness":0.0296,"fear":0.1468,"anger":0.0329,"disgust":0.0167},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":5,"justice_equity":8,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research identifies a significant problem of linguistic inequality in AI systems, which has implications for equitable access to AI benefits and perpetuates existing power structures. The concrete action is the empirical measurement of language vitality and digitality across all documented human languages, leading to the identification of 'Invisible Giants'. The evidence is based on data analysis and postcolonial theory, but it is still in the basic research stage with no deployed technology or measured outcomes related to climate impact.","key_impact_metrics":["Languages with high vitality but near-zero digitality: 27%"],"technology_tags":["Large Language Models","AI","Natural Language Processing"],"sdg_alignment":[4,10,16],"analyzed_at":"2025-10-29T12:03:54.192797Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_77a99d39740b","title":"Zero Data Retention in LLM","content":"arXiv:2510.11558v1 Announce Type: new Abstract: Governance of data, compliance, and business privacy matters, particularly for healthcare and finance businesses. Since the recent emergence of AI enterprise AI assistants enhancing business productivity, safeguarding private data and compliance is now a priority. With the implementation of AI assistants across the enterprise, the zero data retention can be achieved by implementing zero data retention policies by Large Language Model businesses like Open AI and Anthropic and Meta. In this work, we explore zero data retention policies for the Enterprise apps of large language models (LLMs). Our key contribution is defining the architectural, compliance, and usability trade-offs of such systems in parallel. In this research work, we examine the development of commercial AI assistants with two industry leaders and market titans in this arena - Salesforce and Microsoft. Both of these companies used distinct technical architecture to support zero data retention policies. Salesforce AgentForce and Microsoft Copilot are among the leading AI assistants providing much-needed push to business productivity in customer care. The purpose of this paper is to analyze the technical architecture and deployment of zero data retention policy by consuming applications as well as big language models service providers like Open Ai, Anthropic, and Meta.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11558","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.998582","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Komal Gupta, Aditya Shrivastava","raw_content_length":1401,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Microsoft","Zero Data Retention"],"persons":["Anthropic","Meta","Large Language Model"],"locations":[],"monetary":[]},"char_count":1400,"language_detected":"en","key_concepts":{"key_phrases":["Zero Data Retention","LLM","compliance","arXiv251011558v1","Announce Type","new Abstract","Governance","data","business privacy matters","healthcare and finance businesses"],"filter_categories":{"ai_ml":["LLM","data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Zero Data Retention":2.0,"LLM":2.0,"compliance":2.0,"arXiv251011558v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Governance":1.0,"data":1.0,"business privacy matters":1.0,"healthcare and finance businesses":1.0}},"age_hours":2.7599350841666666,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9309,"joy":0.016,"surprise":0.0183,"sadness":0.0031,"fear":0.0092,"anger":0.0136,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":5,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores zero data retention policies for LLMs, focusing on architectural, compliance, and usability trade-offs. It mentions Salesforce AgentForce and Microsoft Copilot as examples, but lacks concrete deployment data or measured outcomes related to environmental impact. The analysis is primarily conceptual at this stage.","key_impact_metrics":[],"technology_tags":["Large Language Models","AI Assistants","Zero Data Retention"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:03:57.084358Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e261b4d6ab01","title":"Characterizing Web Search in The Age of Generative AI","content":"arXiv:2510.11560v1 Announce Type: new Abstract: The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response. This output modality stands in stark contrast to traditional web search, where results are returned as a ranked list of independent web pages. In this paper, we ask: Along what dimensions do generative search outputs differ from traditional web search? We compare Google, a traditional web search engine, with four generative search engines from two providers (Google and OpenAI) across queries from four domains. Our analysis reveals intriguing differences. Most generative search engines cover a wider range of sources compared to web search. Generative search engines vary in the degree to which they rely on internal knowledge contained within the model parameters v.s. external knowledge retrieved from the web. Generative search engines surface varying sets of concepts, creating new opportunities for enhancing search diversity and serendipity. Our results also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11560","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.998978","language":"en","tags":["computer-science","csai","preprints","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Elisabeth Kirsten, Jost Grosse Perdekamp, Mihir Upadhyay, Krishna P. Gummadi, Muhammad Bilal Zafar","raw_content_length":1198,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["OpenAI","Google"],"persons":[],"locations":[],"monetary":[]},"char_count":1197,"language_detected":"en","key_concepts":{"key_phrases":["Web Search","The Age","Generative AI","traditional web search","arXiv251011560v1 Announce Type","new Abstract","The advent","LLMs","rise","a new type"],"filter_categories":{"ai_ml":["Generative AI"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Web Search":2.0,"The Age":2.0,"Generative AI":2.0,"traditional web search":2.0,"arXiv251011560v1 Announce Type":1.0,"new Abstract":1.0,"The advent":1.0,"LLMs":1.0,"rise":1.0,"a new type":1.0}},"age_hours":2.759950728333333,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8001,"joy":0.007,"surprise":0.1029,"sadness":0.0048,"fear":0.0145,"anger":0.0462,"disgust":0.0246},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper analyzes the differences between traditional and generative web search engines. While it identifies varying degrees of reliance on internal vs. external knowledge, it doesn't present any concrete actions or measurable outcomes related to sustainability. The research is at an early stage, focusing on characterizing the technology rather than demonstrating environmental impact.","key_impact_metrics":[],"technology_tags":["Generative AI","Web Search","LLMs"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:04:00.095834Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_32c30adf4c40","title":"SNAP: Towards Segmenting Anything in Any Point Cloud","content":"arXiv:2510.11565v1 Announce Type: new Abstract: Interactive 3D point cloud segmentation enables efficient annotation of complex 3D scenes through user-guided prompts. However, current approaches are typically restricted in scope to a single domain (indoor or outdoor), and to a single form of user interaction (either spatial clicks or textual prompts). Moreover, training on multiple datasets often leads to negative transfer, resulting in domain-specific tools that lack generalizability. To address these limitations, we present \\textbf{SNAP} (\\textbf{S}egment a\\textbf{N}ything in \\textbf{A}ny \\textbf{P}oint cloud), a unified model for interactive 3D segmentation that supports both point-based and text-based prompts across diverse domains. Our approach achieves cross-domain generalizability by training on 7 datasets spanning indoor, outdoor, and aerial environments, while employing domain-adaptive normalization to prevent negative transfer. For text-prompted segmentation, we automatically generate mask proposals without human intervention and match them against CLIP embeddings of textual queries, enabling both panoptic and open-vocabulary segmentation. Extensive experiments demonstrate that SNAP consistently delivers high-quality segmentation results. We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for spatial-prompted segmentation and demonstrate competitive results on all 5 text-prompted benchmarks. These results show that a unified model can match or exceed specialized domain-specific approaches, providing a practical tool for scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11565","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.000143","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Aniket Gupta, Hanhui Wang, Charles Saunders, Aruni RoyChowdhury, Hanumant Singh, Huaizu Jiang","raw_content_length":1655,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1654,"language_detected":"en","key_concepts":{"key_phrases":["SNAP","Segmenting Anything","Any Point Cloud","arXiv251011565v1 Announce Type","new Abstract","Interactive 3D point cloud segmentation","efficient annotation","complex 3D scenes","user-guided prompts","current approaches"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"SNAP":2.0,"Segmenting Anything":2.0,"Any Point Cloud":2.0,"arXiv251011565v1 Announce Type":1.0,"new Abstract":1.0,"Interactive 3D point cloud segmentation":1.0,"efficient annotation":1.0,"complex 3D scenes":1.0,"user-guided prompts":1.0,"current approaches":1.0}},"age_hours":2.759992147222222,"is_recent":true,"quality_score":0.7,"sentiment_score":2.2885,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5423,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8933,"joy":0.0044,"surprise":0.0206,"sadness":0.0148,"fear":0.0147,"anger":0.0278,"disgust":0.0243},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI model for 3D point cloud segmentation. While the model achieves state-of-the-art performance on benchmarks, it is still in the research phase with no deployed units or operational data available. The potential climate impact is indirect, as improved segmentation could enable more efficient annotation and analysis of 3D environmental data.","key_impact_metrics":["State-of-the-art performance on 8 out of 9 zero-shot benchmarks","Competitive results on all 5 text-prompted benchmarks"],"technology_tags":["AI","3D segmentation","Point cloud processing"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T12:04:07.126581Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_67f23281c912","title":"SCOOP'D: Learning Mixed","content":"arXiv:2510.11566v1 Announce Type: new Abstract: Scooping items with tools such as spoons and ladles is common in daily life, ranging from assistive feeding to retrieving items from environmental disaster sites. However, developing a general and autonomous robotic scooping policy is challenging since it requires reasoning about complex tool-object interactions. Furthermore, scooping often involves manipulating deformable objects, such as granular media or liquids, which is challenging due to their infinite-dimensional configuration spaces and complex dynamics. We propose a method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA Omniverse) to collect scooping demonstrations using algorithmic procedures that rely on privileged state information. Then, we use generative policies via diffusion to imitate demonstrations from observational input. We directly apply the learned policy in diverse real-world scenarios, testing its performance on various item quantities, item characteristics, and container types. In zero-shot deployment, our method demonstrates promising results across 465 trials in diverse scenarios, including objects of different difficulty levels that we categorize as \"Level 1\" and \"Level 2.\" SCOOP'D outperforms all baselines and ablations, suggesting that this is a promising approach to acquiring robotic scooping skills. Project page is at https://scoopdiff.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11566","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.000559","language":"en","tags":["computer-science","preprints","cscv","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Kuanning Wang, Yongchong Gu, Yuqian Fu, Zeyu Shangguan, Sicheng He, Xiangyang Xue, Yanwei Fu, Daniel Seita","raw_content_length":1417,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["OmniGibson"],"persons":[],"locations":[],"monetary":[]},"char_count":1416,"language_detected":"en","key_concepts":{"key_phrases":["SCOOPD","items","arXiv251011566v1","Announce Type","new Abstract","tools","spoons","ladles","daily life","assistive feeding"],"filter_categories":{"ai_ml":["daily life"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SCOOPD":2.0,"items":2.0,"arXiv251011566v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"tools":1.0,"spoons":1.0,"ladles":1.0,"daily life":1.0,"assistive feeding":1.0}},"age_hours":2.7600065594444443,"is_recent":true,"quality_score":1.0,"sentiment_score":1.408,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7184,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8783,"joy":0.0041,"surprise":0.0341,"sadness":0.0074,"fear":0.0284,"anger":0.0182,"disgust":0.0296},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a robotic scooping method (SCOOP'D) tested in real-world scenarios with 465 trials. While the technology is deployed in a controlled environment, its direct climate impact is currently minimal, focusing more on automation and robotics. The technical credibility is relatively high due to the use of simulation and real-world testing, but economic viability and broader systemic impacts are still unclear.","key_impact_metrics":["465 trials","Level 1 and Level 2 difficulty levels"],"technology_tags":["robotics","automation","AI","simulation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:04:10.514512Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f05333660c42","title":"A Framework for Low","content":"arXiv:2510.11567v1 Announce Type: new Abstract: Synthetic datasets are widely used for training urban scene recognition models, but even highly realistic renderings show a noticeable gap to real imagery. This gap is particularly pronounced when adapting to a specific target domain, such as Cityscapes, where differences in architecture, vegetation, object appearance, and camera characteristics limit downstream performance. Closing this gap with more detailed 3D modelling would require expensive asset and scene design, defeating the purpose of low-cost labelled data. To address this, we present a new framework that adapts an off-the-shelf diffusion model to a target domain using only imperfect pseudo-labels. Once trained, it generates high-fidelity, target-aligned images from semantic maps of any synthetic dataset, including low-effort sources created in hours rather than months. The method filters suboptimal generations, rectifies image-label misalignments, and standardises semantics across datasets, transforming weak synthetic data into competitive real-domain training sets. Experiments on five synthetic datasets and two real target datasets show segmentation gains of up to +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly constructed synthetic datasets as effective as high-effort, time-intensive synthetic datasets requiring extensive manual design. This work highlights a valuable collaborative paradigm where fast semantic prototyping, combined with generative models, enables scalable, high-quality training data creation for urban scene understanding.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11567","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.000965","language":"en","tags":["computer-science","cslg","preprints","cscv","csgr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Denis Zavadski, Damjan Kal\\v{s}an, Tim K\\\"uchler, Haebom Lee, Stefan Roth, Carsten Rother","raw_content_length":1600,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Cityscapes"],"persons":[],"locations":[],"monetary":[]},"char_count":1599,"language_detected":"en","key_concepts":{"key_phrases":["A Framework","Low","arXiv251011567v1 Announce Type","new Abstract","Synthetic datasets","urban scene recognition models","even highly realistic renderings","a noticeable gap","real imagery","This gap"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Framework":2.0,"Low":2.0,"arXiv251011567v1 Announce Type":1.0,"new Abstract":1.0,"Synthetic datasets":1.0,"urban scene recognition models":1.0,"even highly realistic renderings":1.0,"a noticeable gap":1.0,"real imagery":1.0,"This gap":1.0}},"age_hours":2.760021400277778,"is_recent":true,"quality_score":1.0,"sentiment_score":4.297,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1406,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8445,"joy":0.0086,"surprise":0.0731,"sadness":0.017,"fear":0.0134,"anger":0.0193,"disgust":0.0242},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework to improve synthetic data for training urban scene recognition models. This could indirectly reduce emissions by improving the efficiency of urban planning and resource management, but the impact is not directly quantified and is currently in the applied research stage. The framework shows segmentation gains of up to +8.0%pt. mIoU over state-of-the-art translation methods.","key_impact_metrics":["segmentation gains of +8.0%pt mIoU"],"technology_tags":["diffusion models","synthetic data","urban scene recognition"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T12:04:13.473369Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6a297acef6e7","title":"Bag of Tricks for Subverting Reasoning","content":"arXiv:2510.11570v1 Announce Type: new Abstract: Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative alignment, have shown strong defense against jailbreak attacks. By leveraging LRMs' reasoning ability, these guardrails help the models to assess the safety of user inputs before generating final responses. The powerful reasoning ability can analyze the intention of the input query and will refuse to assist once it detects the harmful intent hidden by the jailbreak methods. Such guardrails have shown a significant boost in defense, such as the near-perfect refusal rates on the open-source gpt-oss series. Unfortunately, we find that these powerful reasoning-based guardrails can be extremely vulnerable to subtle manipulation of the input prompts, and once hijacked, can lead to even more harmful results. Specifically, we first uncover a surprisingly fragile aspect of these guardrails: simply adding a few template tokens to the input prompt can successfully bypass the seemingly powerful guardrails and lead to explicit and harmful responses. To explore further, we introduce a bag of jailbreak methods that subvert the reasoning-based guardrails. Our attacks span white-, gray-, and black-box settings and range from effortless template manipulations to fully automated optimization. Along with the potential for scalable implementation, these methods also achieve alarmingly high attack success rates (e.g., exceeding 90% across 5 different benchmarks on gpt-oss series on both local host models and online API services). Evaluations across various leading open-source LRMs confirm that these vulnerabilities are systemic, underscoring the urgent need for stronger alignment techniques for open-sourced LRMs to prevent malicious misuse. Code is open-sourced at https://chenxshuo.github.io/bag-of-tricks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11570","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.001381","language":"en","tags":["computer-science","preprints","cscr","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":258,"author":"Shuo Chen, Zhen Han, Haokun Chen, Bailan He, Shengyun Si, Jingpei Wu, Philip Torr, Volker Tresp, Jindong Gu","raw_content_length":1859,"priority":7,"update_frequency":1,"reading_time_minutes":1.29,"robust_parsing_used":true,"entities":{"organizations":["Bag of Tricks for Subverting Reasoning arXiv:2510.11570v1","Large Reasoning Models"],"persons":[],"locations":["LRMs"],"monetary":[]},"char_count":1858,"language_detected":"en","key_concepts":{"key_phrases":["Bag","Tricks","Subverting Reasoning","arXiv251011570v1","Announce Type","new Abstract","Large Reasoning Models","LRMs","deliberative alignment","strong defense"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bag":2.0,"Tricks":2.0,"Subverting Reasoning":2.0,"arXiv251011570v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Large Reasoning Models":1.0,"LRMs":1.0,"deliberative alignment":1.0,"strong defense":1.0}},"age_hours":2.7600363530555554,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9169,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7626,"joy":0.0104,"surprise":0.0057,"sadness":0.0081,"fear":0.0374,"anger":0.1087,"disgust":0.0672},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research identifies vulnerabilities in AI safety guardrails, specifically showing that they can be bypassed with simple prompt manipulations. While the research itself doesn't directly impact sustainability, it highlights a potential risk in relying on AI for climate-related tasks if those AI systems are easily compromised. The paper reports attack success rates exceeding 90% across benchmarks, indicating a significant vulnerability.","key_impact_metrics":["Attack success rate > 90%"],"technology_tags":["Large Reasoning Models","AI Safety","Jailbreak Attacks"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T12:04:19.336089Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_07c67402c0f8","title":"(Dis)Proving Spectre Security with Speculation","content":"arXiv:2510.11573v1 Announce Type: new Abstract: Constant-time (CT) verification tools are commonly used for detecting potential side-channel vulnerabilities in cryptographic libraries. Recently, a new class of tools, called speculative constant-time (SCT) tools, has also been used for detecting potential Spectre vulnerabilities. In many cases, these SCT tools have emerged as liftings of CT tools. However, these liftings are seldom defined precisely and are almost never analyzed formally. The goal of this paper is to address this gap, by developing formal foundations for these liftings, and to demonstrate that these foundations can yield practical benefits. Concretely, we introduce a program transformation, coined Speculation-Passing Style (SPS), for reducing SCT verification to CT verification. Essentially, the transformation instruments the program with a new input that corresponds to attacker-controlled predictions and modifies the program to follow them. This approach is sound and complete, in the sense that a program is SCT if and only if its SPS transform is CT. Thus, we can leverage existing CT verification tools to prove SCT; we illustrate this by combining SPS with three standard methodologies for CT verification, namely reducing it to non-interference, assertion safety and dynamic taint analysis. We realize these combinations with three existing tools, EasyCrypt, BINSEC, and ctgrind, and we evaluate them on Kocher's benchmarks for Spectre-v1. Our results focus on Spectre-v1 in the standard CT leakage model; however, we also discuss applications of our method to other variants of Spectre and other leakage models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11573","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.001805","language":"en","tags":["research","cspl","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Santiago Arranz-Olmos, Gilles Barthe, Lionel Blatter, Xingyu Xie, Zhiyuan Zhang","raw_content_length":1651,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":["SCT","Speculation-Passing Style","SPS"],"persons":["Spectre"],"locations":[],"monetary":[]},"char_count":1648,"language_detected":"en","key_concepts":{"key_phrases":["Spectre Security","Speculation","new Abstract","Constant-time CT verification tools","potential side-channel vulnerabilities","cryptographic libraries","a new class","tools","speculative constant-time SCT tools","potential Spectre vulnerabilities"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Spectre Security":2.0,"Speculation":2.0,"new Abstract":1.0,"Constant-time CT verification tools":1.0,"potential side-channel vulnerabilities":1.0,"cryptographic libraries":1.0,"a new class":1.0,"tools":1.0,"speculative constant-time SCT tools":1.0,"potential Spectre vulnerabilities":1.0}},"age_hours":2.760051585277778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.7655,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1531,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7279,"joy":0.0141,"surprise":0.0507,"sadness":0.0096,"fear":0.1753,"anger":0.017,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a program transformation to improve the detection of Spectre vulnerabilities. While it has the potential to improve the security of software, including that used in climate-relevant technologies, it is currently in the research phase and lacks concrete deployment or quantified climate impact. The research is peer-reviewed and uses existing tools, lending credibility to the findings.","key_impact_metrics":["Kocher's benchmarks for Spectre-v1","Reduction of SCT verification to CT verification"],"technology_tags":["Spectre vulnerability detection","Program transformation","Constant-time verification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:04:26.476074Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_83f62b082427","title":"Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery","content":"arXiv:2510.11574v1 Announce Type: new Abstract: Accurate real-time estimation of end effector interaction forces in hydraulic excavators is a key enabler for advanced automation in heavy machinery. Accurate knowledge of these forces allows improved, precise grading and digging maneuvers. To address these challenges, we introduce a high-accuracy, retrofittable 2D force- and payload estimation algorithm that does not impose additional requirements on the operator regarding trajectory, acceleration or the use of the slew joint. The approach is designed for retrofittability, requires minimal calibration and no prior knowledge of machine-specific dynamic characteristics. Specifically, we propose a method for identifying a dynamic model, necessary to estimate both end effector interaction forces and bucket payload during normal operation. Our optimization-based payload estimation achieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the online force measurement from pressure and inertial measurements achieves a direction accuracy of 13 degree and a magnitude accuracy of 383 N. The method's accuracy and generalization capability are validated on two excavator platforms of different type and weight classes. We benchmark our payload estimation against a classical quasistatic method and a commercially available system. Our system outperforms both in accuracy and precision.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11574","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.002191","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Lennart Werner, Pol Eyschen, Sean Costello, Pierluigi Micarelli, Marco Hutter","raw_content_length":1408,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["payload estimation achieves","payload estimation algorithm"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1407,"language_detected":"en","key_concepts":{"key_phrases":["Calibrated Dynamic Modeling","Force","Payload Estimation","Hydraulic Machinery","arXiv251011574v1 Announce Type","new Abstract","Accurate real-time estimation","end effector interaction forces","hydraulic excavators","a key enabler"],"filter_categories":{"ai_ml":["Force"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Calibrated Dynamic Modeling":2.0,"Force":2.0,"Payload Estimation":2.0,"Hydraulic Machinery":2.0,"arXiv251011574v1 Announce Type":1.0,"new Abstract":1.0,"Accurate real-time estimation":1.0,"end effector interaction forces":1.0,"hydraulic excavators":1.0,"a key enabler":1.0}},"age_hours":2.7600662588888887,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1775,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8355,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9189,"joy":0.0129,"surprise":0.036,"sadness":0.0036,"fear":0.0089,"anger":0.0145,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a retrofittable algorithm for force and payload estimation in hydraulic excavators, leading to improved grading and digging. The system achieves 1% full-scale payload accuracy and is validated on two excavator platforms. This could reduce fuel consumption and improve efficiency in construction and mining, but it's currently in the applied research phase with no deployed units.","key_impact_metrics":["1% full-scale payload accuracy","13 degree direction accuracy","383 N magnitude accuracy"],"technology_tags":["force estimation","payload estimation","hydraulic machinery","automation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:04:31.202512Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9a0a4449c128","title":"LLMAtKGE: Large Language Models as Explainable Attackers against Knowledge Graph Embeddings","content":"arXiv:2510.11584v1 Announce Type: new Abstract: Adversarial attacks on knowledge graph embeddings (KGE) aim to disrupt the model's ability of link prediction by removing or inserting triples. A recent black-box method has attempted to incorporate textual and structural information to enhance attack performance. However, it is unable to generate human-readable explanations, and exhibits poor generalizability. In the past few years, large language models (LLMs) have demonstrated powerful capabilities in text comprehension, generation, and reasoning. In this paper, we propose LLMAtKGE, a novel LLM-based framework that selects attack targets and generates human-readable explanations. To provide the LLM with sufficient factual context under limited input constraints, we design a structured prompting scheme that explicitly formulates the attack as multiple-choice questions while incorporating KG factual evidence. To address the context-window limitation and hesitation issues, we introduce semantics-based and centrality-based filters, which compress the candidate set while preserving high recall of attack-relevant information. Furthermore, to efficiently integrate both semantic and structural information into the filter, we precompute high-order adjacency and fine-tune the LLM with a triple classification task to enhance filtering performance. Experiments on two widely used knowledge graph datasets demonstrate that our attack outperforms the strongest black-box baselines and provides explanations via reasoning, and showing competitive performance compared with white-box methods. Comprehensive ablation and case studies further validate its capability to generate explanations.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11584","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.003797","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Ting Li, Yang Yang, Yipeng Yu, Liang Yao, Guoqing Chao, Ruifeng Xu","raw_content_length":1697,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["KGE","LLM"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1696,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Models","Explainable Attackers","Knowledge Graph Embeddings","arXiv251011584v1 Announce Type","new Abstract","Adversarial attacks","knowledge graph embeddings","KGE","the models ability","link prediction"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Models":2.0,"Explainable Attackers":2.0,"Knowledge Graph Embeddings":2.0,"arXiv251011584v1 Announce Type":1.0,"new Abstract":1.0,"Adversarial attacks":1.0,"knowledge graph embeddings":1.0,"KGE":1.0,"the models ability":1.0,"link prediction":1.0}},"age_hours":2.7601256738888886,"is_recent":true,"quality_score":1.0,"sentiment_score":0.40700000000000014,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9186,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2366,"joy":0.0026,"surprise":0.0096,"sadness":0.0365,"fear":0.2322,"anger":0.3669,"disgust":0.1156},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel LLM-based framework (LLMAtKGE) to improve the robustness of knowledge graph embeddings against adversarial attacks. While the research is technically sound and demonstrates improved performance compared to baselines, it is currently in the applied research stage with no mention of deployment or real-world impact on sustainability efforts. The climate impact potential is low as it primarily focuses on improving AI model security rather than directly addressing environmental issues.","key_impact_metrics":["Attack performance improvement","Explanation generation"],"technology_tags":["Large Language Models","Knowledge Graph Embeddings","Adversarial Attacks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:04:34.918947Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_84bb8b4f7c29","title":"Survey Response Generation: Generating Closed","content":"arXiv:2510.11586v1 Announce Type: new Abstract: Many in-silico simulations of human survey responses with large language models (LLMs) focus on generating closed-ended survey responses, whereas LLMs are typically trained to generate open-ended text instead. Previous research has used a diverse range of methods for generating closed-ended survey responses with LLMs, and a standard practice remains to be identified. In this paper, we systematically investigate the impact that various Survey Response Generation Methods have on predicted survey responses. We present the results of 32 mio. simulated survey responses across 8 Survey Response Generation Methods, 4 political attitude surveys, and 10 open-weight language models. We find significant differences between the Survey Response Generation Methods in both individual-level and subpopulation-level alignment. Our results show that Restricted Generation Methods perform best overall, and that reasoning output does not consistently improve alignment. Our work underlines the significant impact that Survey Response Generation Methods have on simulated survey responses, and we develop practical recommendations on the application of Survey Response Generation Methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11586","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.004179","language":"en","tags":["computer-science","cscy","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Georg Ahnert, Anna-Carolina Haensch, Barbara Plank, Markus Strohmaier","raw_content_length":1228,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["the Survey Response Generation Methods"],"persons":[],"locations":[],"monetary":[]},"char_count":1227,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","closed-ended survey responses","arXiv251011586v1 Announce Type","new Abstract","silico","human survey responses","large language models","open-ended text","Previous research","a diverse range"],"filter_categories":{"ai_ml":["LLMs","large language models"],"research_academic":["Previous research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"closed-ended survey responses":2.0,"arXiv251011586v1 Announce Type":1.0,"new Abstract":1.0,"silico":1.0,"human survey responses":1.0,"large language models":1.0,"open-ended text":1.0,"Previous research":1.0,"a diverse range":1.0}},"age_hours":2.7601405902777776,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8914,"joy":0.0157,"surprise":0.0331,"sadness":0.0047,"fear":0.0143,"anger":0.0237,"disgust":0.017},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper investigates methods for generating simulated survey responses using LLMs. While the research itself does not directly impact climate change, understanding biases in simulated data could indirectly influence policy decisions related to sustainability. The study analyzes 32 million simulated survey responses, providing some measurable data.","key_impact_metrics":["32 mio. simulated survey responses","8 Survey Response Generation Methods"],"technology_tags":["Large Language Models","Survey Simulation"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:04:38.254626Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d155763c2856","title":"Analyzing and Internalizing Complex Policy Documents for LLM Agents","content":"arXiv:2510.11588v1 Announce Type: new Abstract: Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11588","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.004599","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Jiateng Liu, Zhenhailong Wang, Xiaojiang Huang, Yingjie Li, Xing Fan, Xiang Li, Chenlei Guo, Ruhi Sarikaya, Heng Ji","raw_content_length":1797,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["Controllable Complexity","Analyzing and Internalizing Complex Policy Documents for LLM Agents arXiv:2510.11588v1 Announce Type: new Abstract","CC-Gen"],"persons":[],"locations":[],"monetary":[]},"char_count":1796,"language_detected":"en","key_concepts":{"key_phrases":["Complex Policy Documents","LLM Agents","arXiv251011588v1 Announce Type","new Abstract","Large Language Model","LLM-based agentic systems","context","diverse business rules","requirements","these documents"],"filter_categories":{"ai_ml":["LLM Agents","Large Language Model"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Complex Policy Documents":2.0,"LLM Agents":2.0,"arXiv251011588v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Model":1.0,"LLM-based agentic systems":1.0,"context":1.0,"diverse business rules":1.0,"requirements":1.0,"these documents":1.0}},"age_hours":2.7601544927777777,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8275,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1655,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9297,"joy":0.0079,"surprise":0.0337,"sadness":0.0089,"fear":0.0038,"anger":0.0099,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method (CAP-CPT) to improve the ability of LLMs to internalize complex policy documents, reducing prompt length by 97.3% on CC-Gen and improving performance on Qwen-3-32B by up to 41% and 22%. While the research is promising, it is still in the applied research stage, with no indication of real-world deployment or economic viability. The climate impact is indirect, as it aims to improve the efficiency of AI systems that *could* be used for climate-related tasks.","key_impact_metrics":["97.3% prompt length reduction","41% gain on Qwen-3-32B"],"technology_tags":["Large Language Models","Policy Internalization","Agentic Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:04:42.525929Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9b5010e81fda","title":"QDER: Query-Specific Document and Entity Representations for Multi","content":"arXiv:2510.11589v1 Announce Type: new Abstract: Neural IR has advanced through two distinct paths: entity-oriented approaches leveraging knowledge graphs and multi-vector models capturing fine-grained semantics. We introduce QDER, a neural re-ranking model that unifies these approaches by integrating knowledge graph semantics into a multi-vector model. QDER's key innovation lies in its modeling of query-document relationships: rather than computing similarity scores on aggregated embeddings, we maintain individual token and entity representations throughout the ranking process, performing aggregation only at the final scoring stage - an approach we call \"late aggregation.\" We first transform these fine-grained representations through learned attention patterns, then apply carefully chosen mathematical operations for precise matches. Experiments across five standard benchmarks show that QDER achieves significant performance gains, with improvements of 36% in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar improvements on other datasets. QDER particularly excels on difficult queries, achieving an nDCG@20 of 0.70 where traditional approaches fail completely (nDCG@20 = 0.0), setting a foundation for future work in entity-aware retrieval.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11589","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.004983","language":"en","tags":["computer-science","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Shubham Chatterjee, Jeff Dalton","raw_content_length":1274,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["QDER","Query-Specific Document"],"persons":[],"locations":[],"monetary":[]},"char_count":1273,"language_detected":"en","key_concepts":{"key_phrases":["QDER","Query-Specific Document and Entity Representations","Multi","arXiv251011589v1 Announce Type","new Abstract","Neural IR","two distinct paths","entity-oriented approaches","knowledge graphs","multi-vector models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"QDER":3.0,"Query-Specific Document and Entity Representations":2.0,"Multi":2.0,"arXiv251011589v1 Announce Type":1.0,"new Abstract":1.0,"Neural IR":1.0,"two distinct paths":1.0,"entity-oriented approaches":1.0,"knowledge graphs":1.0,"multi-vector models":1.0}},"age_hours":2.7601690805555554,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9041,"joy":0.0166,"surprise":0.0516,"sadness":0.0037,"fear":0.0056,"anger":0.0133,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel neural re-ranking model (QDER) for information retrieval. While it shows significant performance gains (36% in nDCG@20 on TREC Robust 2004), it is still in the research phase with no deployed technology or measurable environmental impact. The improved information retrieval could potentially indirectly support sustainability efforts by improving access to relevant information, but this is highly speculative.","key_impact_metrics":["nDCG@20 improvement of 36%","nDCG@20 of 0.70 on difficult queries"],"technology_tags":["neural re-ranking","information retrieval","knowledge graph"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:04:45.800756Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6b850678d01d","title":"REGENT: Relevance-Guided Attention for Entity-Aware Multi","content":"arXiv:2510.11592v1 Announce Type: new Abstract: Current neural re-rankers often struggle with complex information needs and long, content-rich documents. The fundamental issue is not computational--it is intelligent content selection: identifying what matters in lengthy, multi-faceted texts. While humans naturally anchor their understanding around key entities and concepts, neural models process text within rigid token windows, treating all interactions as equally important and missing critical semantic signals. We introduce REGENT, a neural re-ranking model that mimics human-like understanding by using entities as a \"semantic skeleton\" to guide attention. REGENT integrates relevance guidance directly into the attention mechanism, combining fine-grained lexical matching with high-level semantic reasoning. This relevance-guided attention enables the model to focus on conceptually important content while maintaining sensitivity to precise term matches. REGENT achieves new state-of-the-art performance in three challenging datasets, providing up to 108% improvement over BM25 and consistently outperforming strong baselines including ColBERT and RankVicuna. To our knowledge, this is the first work to successfully integrate entity semantics directly into neural attention, establishing a new paradigm for entity-aware information retrieval.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11592","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.005788","language":"en","tags":["computer-science","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Shubham Chatterjee","raw_content_length":1354,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Relevance-Guided Attention for Entity-Aware Multi arXiv:2510.11592v1 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1353,"language_detected":"en","key_concepts":{"key_phrases":["REGENT","Relevance-Guided Attention","Entity-Aware Multi","Announce Type","new Abstract","Current neural re","rankers","complex information needs","long content-rich documents","The fundamental issue"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"REGENT":2.0,"Relevance-Guided Attention":2.0,"Entity-Aware Multi":2.0,"Announce Type":1.0,"new Abstract":1.0,"Current neural re":1.0,"rankers":1.0,"complex information needs":1.0,"long content-rich documents":1.0,"The fundamental issue":1.0}},"age_hours":2.7601986797222224,"is_recent":true,"quality_score":1.0,"sentiment_score":1.8269999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6346,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9154,"joy":0.0024,"surprise":0.0297,"sadness":0.0087,"fear":0.0108,"anger":0.0212,"disgust":0.0118},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel AI model for information retrieval. While it achieves significant performance improvements (up to 108% over BM25), it's currently in the research phase with no deployed applications or quantified environmental benefits. The model could potentially improve access to information about sustainability, but this is indirect and unproven.","key_impact_metrics":["108% improvement over BM25"],"technology_tags":["Artificial Intelligence","Information Retrieval","Neural Networks"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:04:48.920696Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_441dd4f80d86","title":"Reproducibility: The New Frontier in AI Governance","content":"arXiv:2510.11595v1 Announce Type: new Abstract: AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11595","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.006178","language":"en","tags":["computer-science","csai","preprints","csgl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Israel Mason-Williams, Gabryel Mason-Williams","raw_content_length":1542,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Signal","The New Frontier"],"persons":[],"locations":[],"monetary":[]},"char_count":1541,"language_detected":"en","key_concepts":{"key_phrases":["Reproducibility","The New Frontier","AI Governance","arXiv251011595v1 Announce Type","new Abstract","AI policymakers","effective governance mechanisms","safe aligned and trustworthy AI development","the information environment","policymakers"],"filter_categories":{"ai_ml":["AI Governance"],"engineering":["safe aligned and trustworthy AI development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reproducibility":2.0,"The New Frontier":2.0,"AI Governance":2.0,"arXiv251011595v1 Announce Type":1.0,"new Abstract":1.0,"AI policymakers":1.0,"effective governance mechanisms":1.0,"safe aligned and trustworthy AI development":1.0,"the information environment":1.0,"policymakers":1.0}},"age_hours":2.760213497777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3445,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8689,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.662,"joy":0.0169,"surprise":0.019,"sadness":0.0237,"fear":0.1922,"anger":0.0476,"disgust":0.0386},"emotion_method":"local"},"sustainability_analysis":{"content_type":"policy_action","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper proposes stricter reproducibility guidelines for AI research to assist governance and improve consensus on AI risks. It suggests adopting preregistration, increased statistical power, and negative result publication reproducibility protocols. The concrete action is advocating for policy changes in AI research standards, but there are no deployed technologies or measured outcomes yet.","key_impact_metrics":[],"technology_tags":["AI governance","reproducibility","policy"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:04:51.760026Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_432b4db4568d","title":"GlobalizeEd: A Multimodal Translation System that Preserves Speaker Identity in Academic Lectures","content":"arXiv:2510.11596v1 Announce Type: new Abstract: A large amount of valuable academic content is only available in its original language, creating a significant access barrier for the global student community. This is a challenge for translating in several subjects, such as history, culture, and the arts, where current automated subtitle tools fail to convey the appropriate pedagogical tone and specialized meaning. In addition, reading traditional automated subtitles increases cognitive load and leads to a disconnected learning experience. Through a mixed-methods study involving 36 participants, we found that GlobalizeEds dubbed formats significantly reduce cognitive load and offer a more immersive learning experience compared to traditional subtitles. Although learning effectiveness was comparable between high-quality subtitles and dubbed formats, both groups valued GlobalizeEds ability to preserve the speakers voice, which enhanced perceived authenticity. Instructors rated translation accuracy and vocal naturalness, whereas students reported that synchronized, identity-preserving outputs fostered engagement and trust. This work contributes a novel human-centered AI framework for cross-lingual education, demonstrating how multimodal translation systems can balance linguistic fidelity, cultural adaptability, and user control to create more inclusive global learning experiences.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11596","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.006579","language":"en","tags":["preprints","research","computer-science","cshc","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Hoang-Son Vo, Karina Kolmogortseva, Ngumimi Karen Iyortsuun, Hong-Duyen Vo, Soo-Hyung Kim","raw_content_length":1399,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":["GlobalizeEds","Preserves Speaker Identity","GlobalizeEd: A Multimodal Translation System"],"persons":[],"locations":[],"monetary":[]},"char_count":1398,"language_detected":"en","key_concepts":{"key_phrases":["GlobalizeEd A Multimodal Translation System","Speaker Identity","Academic Lectures","arXiv251011596v1 Announce Type","new Abstract","A large amount","valuable academic content","its original language","a significant access barrier","the global student community"],"filter_categories":{"research_academic":["Academic Lectures","valuable academic content"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"GlobalizeEd A Multimodal Translation System":2.0,"Speaker Identity":2.0,"Academic Lectures":2.0,"arXiv251011596v1 Announce Type":1.0,"new Abstract":1.0,"A large amount":1.0,"valuable academic content":1.0,"its original language":1.0,"a significant access barrier":1.0,"the global student community":1.0}},"age_hours":2.760228682222222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.859499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5719,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6892,"joy":0.0115,"surprise":0.1306,"sadness":0.0551,"fear":0.0609,"anger":0.0355,"disgust":0.0171},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":5,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel AI framework for cross-lingual education. While it demonstrates reduced cognitive load and enhanced engagement in a small study (36 participants), it's still in the early stages of development with no deployed units or real-world data beyond the initial study. The impact on climate change is minimal, but it does consider equity by improving access to education.","key_impact_metrics":["cognitive load reduction","learning effectiveness comparable to high-quality subtitles"],"technology_tags":["multimodal translation","human-centered AI","cross-lingual education"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T12:04:55.645337Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c8df3740c0cf","title":"MeTA-LoRA: Data-Efficient Multi","content":"arXiv:2510.11598v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) has emerged as one of the most widely used parameter-efficient fine-tuning (PEFT) methods for adapting large language models (LLMs) to downstream tasks. While highly effective in single-task settings, it struggles to efficiently leverage inter-task knowledge in complex multi-task learning scenarios, often requiring substantial task-specific data to achieve optimal performance. To address this limitation, we introduce MeTA-LoRA, a two-stage optimization framework that significantly improves data efficiency in multi-task adaptation. In the first stage, task-specific LoRA adapters are learned using only a few samples from each involved dataset, enabling rapid adaptation without large-scale supervision. In the second stage, the shared LoRA adapter is updated by aggregating gradients from multiple tasks to promote knowledge transfer across tasks, further reducing data usage by leveraging common patterns. In both multi-task learning and multilingual learning scenarios, our method matches or surpasses the performance of traditional full-data LoRA fine-tuning approaches, while using significantly less task-specific data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11598","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.006951","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Bo Cheng, Xu Wang, Jinda Liu, Yi Chang, Yuan Wu","raw_content_length":1206,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["LoRA","MeTA-LoRA"],"persons":["arXiv:2510.11598v1 Announce"],"locations":[],"monetary":[]},"char_count":1205,"language_detected":"en","key_concepts":{"key_phrases":["MeTA-LoRA","Data-Efficient Multi","arXiv251011598v1 Announce Type","new Abstract","Low-Rank Adaptation","LoRA","large language models","LLMs","tasks","single-task settings"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MeTA-LoRA":2.0,"Data-Efficient Multi":2.0,"arXiv251011598v1 Announce Type":1.0,"new Abstract":1.0,"Low-Rank Adaptation":1.0,"LoRA":1.0,"large language models":1.0,"LLMs":1.0,"tasks":1.0,"single-task settings":1.0}},"age_hours":2.7602443083333337,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9205,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7841,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8197,"joy":0.0045,"surprise":0.0411,"sadness":0.0523,"fear":0.0239,"anger":0.032,"disgust":0.0265},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel machine learning technique (MeTA-LoRA) that improves data efficiency in multi-task adaptation for large language models. This could indirectly reduce energy consumption associated with training and using these models, but the impact is not quantified. The technology is in the applied research stage, with performance matching or surpassing traditional methods while using less data.","key_impact_metrics":["Significantly less task-specific data"],"technology_tags":["Machine Learning","Large Language Models","Low-Rank Adaptation"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-29T12:04:58.717509Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9889bad1f129","title":"SemCSE","content":"arXiv:2510.11599v1 Announce Type: new Abstract: We propose SemCSE-Multi, a novel unsupervised framework for generating multifaceted embeddings of scientific abstracts, evaluated in the domains of invasion biology and medicine. These embeddings capture distinct, individually specifiable aspects in isolation, thus enabling fine-grained and controllable similarity assessments as well as adaptive, user-driven visualizations of scientific domains. Our approach relies on an unsupervised procedure that produces aspect-specific summarizing sentences and trains embedding models to map semantically related summaries to nearby positions in the embedding space. We then distill these aspect-specific embedding capabilities into a unified embedding model that directly predicts multiple aspect embeddings from a scientific abstract in a single, efficient forward pass. In addition, we introduce an embedding decoding pipeline that decodes embeddings back into natural language descriptions of their associated aspects. Notably, we show that this decoding remains effective even for unoccupied regions in low-dimensional visualizations, thus offering vastly improved interpretability in user-centric settings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11599","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.007332","language":"en","tags":["cslg","csai","preprints","research","cscl","csir","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":152,"author":"Marc Brinner, Sina Zarrie{\\ss}","raw_content_length":1204,"priority":7,"update_frequency":1,"reading_time_minutes":0.76,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1203,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251011599v1 Announce Type","new Abstract","SemCSE-Multi","a novel unsupervised framework","multifaceted embeddings","scientific abstracts","the domains","invasion biology","medicine","These embeddings"],"filter_categories":{"ai_ml":["the domains"],"healthcare_tech":["medicine"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251011599v1 Announce Type":1.0,"new Abstract":1.0,"SemCSE-Multi":1.0,"a novel unsupervised framework":1.0,"multifaceted embeddings":1.0,"scientific abstracts":1.0,"the domains":1.0,"invasion biology":1.0,"medicine":1.0,"These embeddings":1.0}},"age_hours":2.7602581263888886,"is_recent":true,"quality_score":0.7,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8304,"joy":0.0597,"surprise":0.0718,"sadness":0.005,"fear":0.01,"anger":0.0174,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel unsupervised framework for generating multifaceted embeddings of scientific abstracts. While the technology could potentially aid in identifying and categorizing research related to sustainability, it is currently in the basic research phase with no concrete deployments or measurable outcomes related to climate change mitigation or adaptation. The impact is theoretical at this stage.","key_impact_metrics":[],"technology_tags":["natural_language_processing","machine_learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:01.769641Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1282457f4720","title":"Deconstructing Attention: Investigating Design Principles for Effective Language Modeling","content":"arXiv:2510.11602v1 Announce Type: new Abstract: The success of Transformer language models is widely credited to their dot-product attention mechanism, which interweaves a set of key design principles: mixing information across positions (enabling multi-token interactions), sequence-dependent activations (where attention weights adapt to each input), a specific mathematical form (dot-product similarities plus softmax weighting), and coupling of queries and keys to evolving hidden states (grounding attention in the current layer). However, the necessity of each of these principles remains largely untested. In this work, we systematically deconstruct attention by designing controlled variants that selectively relax these principles, applied both uniformly across all layers and in hybrid architectures where only some layers retain standard attention. Our empirical analysis reveals that mechanisms for mixing tokens are indispensable, as their absence collapses models to near-random behavior, while the exact mathematical form and sequence dependency can be substantially relaxed, especially when preserved in just a subset of layers. Surprisingly, even variants that fail in isolation can achieve robust performance when interleaved with standard attention, highlighting a cooperative effect. These findings deepen our understanding of what truly underpins attention's effectiveness and open new avenues for simplifying language models without sacrificing performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11602","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.007740","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Huiyin Xue, Nafise Sadat Moosavi, Nikolaos Aletras","raw_content_length":1480,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1479,"language_detected":"en","key_concepts":{"key_phrases":["Attention","Design Principles","Effective Language Modeling","arXiv251011602v1 Announce Type","new Abstract","The success","Transformer language models","their dot-product attention mechanism","which","a set"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Attention":2.0,"Design Principles":2.0,"Effective Language Modeling":2.0,"arXiv251011602v1 Announce Type":1.0,"new Abstract":1.0,"The success":1.0,"Transformer language models":1.0,"their dot-product attention mechanism":1.0,"which":1.0,"a set":1.0}},"age_hours":2.760273284722222,"is_recent":true,"quality_score":0.7,"sentiment_score":9.259500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8519,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7928,"joy":0.0468,"surprise":0.0301,"sadness":0.0053,"fear":0.0652,"anger":0.0448,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper explores the design principles of attention mechanisms in language models, aiming to simplify them without sacrificing performance. While it doesn't directly address climate change, improved efficiency in language models could indirectly reduce energy consumption in data centers. The research is at an early stage (basic research) with no deployed technology or measured outcomes related to energy savings.","key_impact_metrics":[],"technology_tags":["language modeling","transformer networks","attention mechanisms"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:04.817215Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_513275c958ca","title":"ACE","content":"arXiv:2510.11605v1 Announce Type: new Abstract: Scene coordinate regression (SCR) has established itself as a promising learning-based approach to visual relocalization. After mere minutes of scene-specific training, SCR models estimate camera poses of query images with high accuracy. Still, SCR methods fall short of the generalization capabilities of more classical feature-matching approaches. When imaging conditions of query images, such as lighting or viewpoint, are too different from the training views, SCR models fail. Failing to generalize is an inherent limitation of previous SCR frameworks, since their training objective is to encode the training views in the weights of the coordinate regressor itself. The regressor essentially overfits to the training views, by design. We propose to separate the coordinate regressor and the map representation into a generic transformer and a scene-specific map code. This separation allows us to pre-train the transformer on tens of thousands of scenes. More importantly, it allows us to train the transformer to generalize from mapping images to unseen query images during pre-training. We demonstrate on multiple challenging relocalization datasets that our method, ACE-G, leads to significantly increased robustness while keeping the computational footprint attractive.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11605","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.008515","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Leonard Bruns, Axel Barroso-Laguna, Tommaso Cavallari, \\'Aron Monszpart, Sowmya Munukutla, Victor Adrian Prisacariu, Eric Brachmann","raw_content_length":1328,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["ACE arXiv:2510.11605v1 Announce Type","SCR"],"persons":[],"locations":[],"monetary":[]},"char_count":1327,"language_detected":"en","key_concepts":{"key_phrases":["ACE","query images","arXiv251011605v1 Announce Type","new Abstract","Scene coordinate regression","SCR","itself","a promising learning-based approach","visual relocalization","mere minutes"],"filter_categories":{"healthcare_tech":["ACE"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ACE":2.0,"query images":2.0,"arXiv251011605v1 Announce Type":1.0,"new Abstract":1.0,"Scene coordinate regression":1.0,"SCR":1.0,"itself":1.0,"a promising learning-based approach":1.0,"visual relocalization":1.0,"mere minutes":1.0}},"age_hours":2.7603026155555557,"is_recent":true,"quality_score":0.7,"sentiment_score":7.009499999999999,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4019,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8985,"joy":0.0103,"surprise":0.0587,"sadness":0.0116,"fear":0.0059,"anger":0.0079,"disgust":0.0071},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new method for visual relocalization (ACE-G) that improves robustness compared to previous methods. It mentions demonstrating increased robustness on multiple datasets, indicating some level of validation. However, it is still in the research phase and lacks information on deployment or economic viability.","key_impact_metrics":["significantly increased robustness"],"technology_tags":["visual relocalization","scene coordinate regression","transformer networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:07.593716Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_181e96d3c04c","title":"ExpVid: A Benchmark for Experiment Video Understanding & Reasoning","content":"arXiv:2510.11606v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) hold promise for accelerating scientific discovery by interpreting complex experimental procedures. However, their true capabilities are poorly understood, as existing benchmarks neglect the fine-grained and long-horizon nature of authentic laboratory work, especially in wet-lab settings. To bridge this gap, we introduce ExpVid, the first benchmark designed to systematically evaluate MLLMs on scientific experiment videos. Curated from peer-reviewed video publications, ExpVid features a new three-level task hierarchy that mirrors the scientific process: (1) Fine-grained Perception of tools, materials, and actions; (2) Procedural Understanding of step order and completeness; and (3) Scientific Reasoning that connects the full experiment to its published conclusions. Our vision-centric annotation pipeline, combining automated generation with multi-disciplinary expert validation, ensures that tasks require visual grounding. We evaluate 19 leading MLLMs on ExpVid and find that while they excel at coarse-grained recognition, they struggle with disambiguating fine details, tracking state changes over time, and linking experimental procedures to scientific outcomes. Our results reveal a notable performance gap between proprietary and open-source models, particularly in high-order reasoning. ExpVid not only provides a diagnostic tool but also charts a roadmap for developing MLLMs capable of becoming trustworthy partners in scientific experimentation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11606","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.008913","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Yicheng Xu, Yue Wu, Jiashuo Yu, Ziang Yan, Tianxiang Jiang, Yinan He, Qingsong Zhao, Kai Chen, Yu Qiao, Limin Wang, Manabu Okumura, Yi Wang","raw_content_length":1555,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["ExpVid"],"persons":[],"locations":[],"monetary":[]},"char_count":1554,"language_detected":"en","key_concepts":{"key_phrases":["ExpVid","A Benchmark","Experiment Video Understanding","Reasoning","MLLMs","Announce Type","new Abstract","Multimodal Large Language Models","promise","scientific discovery"],"filter_categories":{"ai_ml":["MLLMs","Multimodal Large Language Models"],"research_academic":["scientific discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ExpVid":3.0,"A Benchmark":2.0,"Experiment Video Understanding":2.0,"Reasoning":2.0,"MLLMs":2.0,"Announce Type":1.0,"new Abstract":1.0,"Multimodal Large Language Models":1.0,"promise":1.0,"scientific discovery":1.0}},"age_hours":2.760317469722222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3660000000000005,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2732,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8655,"joy":0.0063,"surprise":0.0356,"sadness":0.0102,"fear":0.0605,"anger":0.0144,"disgust":0.0076},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark (ExpVid) to evaluate MLLMs on scientific experiment videos. While it doesn't directly reduce GHG emissions, it aims to improve AI's ability to understand and reason about scientific experiments, which *could* accelerate the discovery of sustainable technologies. The benchmark is based on peer-reviewed video publications, lending some credibility, but it is still in the early stages of research and development.","key_impact_metrics":["Performance gap between proprietary and open-source models"],"technology_tags":["Multimodal Large Language Models","Scientific Experiment Video Analysis"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:05:10.650960Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8d666de9e6a7","title":"ParaCook: On Time","content":"arXiv:2510.11608v1 Announce Type: new Abstract: Large Language Models (LLMs) exhibit strong reasoning abilities for planning long-horizon, real-world tasks, yet existing agent benchmarks focus on task completion while neglecting time efficiency in parallel and asynchronous operations. To address this, we present ParaCook, a benchmark for time-efficient collaborative planning. Inspired by the Overcooked game, ParaCook provides an environment for various challenging interaction planning of multi-agent systems that are instantiated as cooking tasks, with a simplified action space to isolate the core challenge of strategic parallel planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find that current approaches achieve suboptimal plans, which struggle with parallel actions or coordination. Our analysis also reveals LLMs' potential on abstract tasks where they can focus on high-level parallel optimization. ParaCook provides a scalable evaluation framework with adjustable complexity, establishing a foundation for developing and assessing time efficiency-aware multi-agent planning. The code and data are available at https://github.com/zsq259/ParaCook.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11608","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.009294","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Shiqi Zhang, Xinbei Ma, Yunqing Xu, Zouying Cao, Pengrui Lu, Haobo Yuan, Tiancheng Shen, Zhuosheng Zhang, Hai Zhao, Ming-Hsuan Yang","raw_content_length":1185,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1184,"language_detected":"en","key_concepts":{"key_phrases":["ParaCook","Time","arXiv251011608v1 Announce Type","new Abstract","Large Language Models","LLMs","strong reasoning abilities","long-horizon","real-world tasks","existing agent"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ParaCook":4.0,"Time":2.0,"arXiv251011608v1 Announce Type":1.0,"new Abstract":1.0,"Large Language Models":1.0,"LLMs":1.0,"strong reasoning abilities":1.0,"long-horizon":1.0,"real-world tasks":1.0,"existing agent":1.0}},"age_hours":2.760332161388889,"is_recent":true,"quality_score":0.7,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8351,"joy":0.0105,"surprise":0.0147,"sadness":0.0058,"fear":0.0833,"anger":0.0374,"disgust":0.0132},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the time efficiency of multi-agent systems using LLMs, specifically in planning tasks. While the research aims to improve efficiency, it doesn't directly translate to concrete actions that reduce GHG emissions or address climate change. The project is in the early stages of research and development, with code and data available but no deployed units or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["Large Language Models","Multi-Agent Systems"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T12:05:14.317115Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_13daaef87ed4","title":"Attention Factors for Statistical Arbitrage","content":"arXiv:2510.11616v1 Announce Type: new Abstract: Statistical arbitrage exploits temporal price differences between similar assets. We develop a framework to jointly identify similar assets through factors, identify mispricing and form a trading policy that maximizes risk-adjusted performance after trading costs. Our Attention Factors are conditional latent factors that are the most useful for arbitrage trading. They are learned from firm characteristic embeddings that allow for complex interactions. We identify time-series signals from the residual portfolios of our factors with a general sequence model. Estimating factors and the arbitrage trading strategy jointly is crucial to maximize profitability after trading costs. In a comprehensive empirical study we show that our Attention Factor model achieves an out-of-sample Sharpe ratio above 4 on the largest U.S. equities over a 24-year period. Our one-step solution yields an unprecedented Sharpe ratio of 2.3 net of transaction costs. We show that weak factors are important for arbitrage trading.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11616","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.010502","language":"en","tags":["computer-science","cslg","q-fincp","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":150,"author":"Elliot L. Epstein, Rose Wang, Jaewon Choi, Markus Pelger","raw_content_length":1060,"priority":7,"update_frequency":1,"reading_time_minutes":0.75,"robust_parsing_used":true,"entities":{"organizations":["Attention","Sharp"],"persons":[],"locations":["U.S."],"monetary":[]},"char_count":1059,"language_detected":"en","key_concepts":{"key_phrases":["Attention Factors","Statistical Arbitrage","similar assets","arXiv251011616v1 Announce Type","new Abstract","Statistical arbitrage","temporal price differences","a framework","factors","mispricing"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Attention Factors":2.0,"Statistical Arbitrage":2.0,"similar assets":2.0,"arXiv251011616v1 Announce Type":1.0,"new Abstract":1.0,"Statistical arbitrage":1.0,"temporal price differences":1.0,"a framework":1.0,"factors":1.0,"mispricing":1.0}},"age_hours":2.760375209166667,"is_recent":true,"quality_score":1.0,"sentiment_score":7.463500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4927,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9073,"joy":0.0128,"surprise":0.0108,"sadness":0.0039,"fear":0.024,"anger":0.027,"disgust":0.0141},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel statistical arbitrage model that achieves a high Sharpe ratio in backtesting. While the model itself doesn't directly impact climate or sustainability, it could potentially be used to optimize investment strategies in sustainable assets. However, the paper is theoretical and lacks real-world deployment data, making it difficult to assess its actual impact.","key_impact_metrics":["Sharpe ratio above 4","Sharpe ratio of 2.3 net of transaction costs"],"technology_tags":["statistical arbitrage","machine learning","financial modeling"],"sdg_alignment":[8],"analyzed_at":"2025-10-29T12:05:17.963409Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e83d19bdfd2a","title":"StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom","content":"arXiv:2510.11618v1 Announce Type: new Abstract: Human writers often begin their stories with an overarching mental scene, where they envision the interactions between characters and their environment. Inspired by this creative process, we propose a novel approach to long-form story generation, termed hybrid bottom-up long-form story generation, using multi-agent simulations. In our method, agents interact within a dynamic sandbox environment, where their behaviors and interactions with one another and the environment generate emergent events. These events form the foundation for the story, enabling organic character development and plot progression. Unlike traditional top-down approaches that impose rigid structures, our hybrid bottom-up approach allows for the natural unfolding of events, fostering more spontaneous and engaging storytelling. The system is capable of generating stories exceeding 10,000 words while maintaining coherence and consistency, addressing some of the key challenges faced by current story generation models. We achieve state-of-the-art performance across several metrics. This approach offers a scalable and innovative solution for creating dynamic, immersive long-form stories that evolve organically from agent-driven interactions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11618","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.011252","language":"en","tags":["computer-science","csma","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Zehao Chen, Rong Pan, Haoran Li","raw_content_length":1273,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1272,"language_detected":"en","key_concepts":{"key_phrases":["StoryBox","Collaborative Multi-Agent Simulation","Hybrid Bottom","arXiv251011618v1 Announce Type","new Abstract","Human writers","their stories","an overarching mental scene","the interactions","characters"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"StoryBox":2.0,"Collaborative Multi-Agent Simulation":2.0,"Hybrid Bottom":2.0,"arXiv251011618v1 Announce Type":1.0,"new Abstract":1.0,"Human writers":1.0,"their stories":1.0,"an overarching mental scene":1.0,"the interactions":1.0,"characters":1.0}},"age_hours":2.760402676388889,"is_recent":true,"quality_score":0.7,"sentiment_score":9.375,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.875,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8985,"joy":0.0391,"surprise":0.0368,"sadness":0.0027,"fear":0.0065,"anger":0.0119,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel approach to story generation using multi-agent simulations. While innovative, it's in the basic research stage with no concrete actions or measurable outcomes related to sustainability. The system generates stories exceeding 10,000 words, but this metric is unrelated to environmental impact.","key_impact_metrics":["Story length: 10,000 words"],"technology_tags":["Multi-agent simulation","Story generation","Artificial intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T12:05:21.229600Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_06e7eef22b4a","title":"Enhancing Long Chain-of","content":"arXiv:2510.11620v1 Announce Type: new Abstract: Inference-time scaling enhances the reasoning ability of a language model (LM) by extending its chain-of-thought (CoT). However, existing approaches typically generate the entire reasoning chain in a single forward pass, which often leads to CoT derailment, i.e., the reasoning trajectory drifting off course due to compounding errors. This problem is particularly severe for smaller LMs with long CoTs due to their limited capacity. To address this, we analyze raw long CoTs and uncover a reasoning hierarchy consisting of planning and execution steps. Our analysis reveals that most reasoning errors stem from incorrect planning. Motivated by this observation, we propose Multi-Path Plan Aggregation (MPPA), a framework that augments single-pass reasoning with plan exploration and aggregation. Following a variable interval schedule based on the token position, MPPA generates multiple candidate plans and aggregates them into a refined planning step. To maintain efficiency, we adopt a minimal design in which the base LM serves as the primary policy, while a lightweight LoRA module implements the plan aggregation policy. We further observe that outcome-reward RL is inefficient for long trajectories (e.g., exceeding 4K tokens). To overcome this, we introduce online Step-DPO, a process-level preference optimization scheme that leverages Twisted Sequential Monte Carlo (TSMC) to provide scalable stepwise supervision using small LMs. This yields more efficient training, improved stability, and higher accuracy. Extensive experiments on challenging math, science, and logical reasoning benchmarks demonstrate that, with only 10% SFT data and 5% of preference pairs, our method outperforms both the DeepSeek-R1 distillation baseline and the outcome-reward RL baseline across multiple base models and tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11620","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.011692","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":263,"author":"Siheng Xiong, Ali Payani, Faramarz Fekri","raw_content_length":1862,"priority":7,"update_frequency":1,"reading_time_minutes":1.315,"robust_parsing_used":true,"entities":{"organizations":["CoT","Multi-Path Plan Aggregation"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1861,"language_detected":"en","key_concepts":{"key_phrases":["Long Chain","Announce Type","new Abstract","Inference-time scaling","the reasoning ability","a language model","thought","existing approaches","the entire reasoning chain","a single forward pass"],"filter_categories":{"ai_ml":["Long Chain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Long Chain":2.0,"Announce Type":1.0,"new Abstract":1.0,"Inference-time scaling":1.0,"the reasoning ability":1.0,"a language model":1.0,"thought":1.0,"existing approaches":1.0,"the entire reasoning chain":1.0,"a single forward pass":1.0}},"age_hours":2.760418038888889,"is_recent":true,"quality_score":1.0,"sentiment_score":1.0420000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7916,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3129,"joy":0.0028,"surprise":0.0207,"sadness":0.291,"fear":0.0605,"anger":0.2029,"disgust":0.1092},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (MPPA) for improving the reasoning ability of language models, which could potentially be applied to optimize various sustainability-related processes. However, it is currently in the basic research stage with no deployed technology or measured outcomes related to climate impact. The claim of outperforming baselines is supported by experiments on math, science, and logical reasoning benchmarks.","key_impact_metrics":["10% SFT data","5% of preference pairs"],"technology_tags":["Language Model","Chain-of-Thought","Multi-Path Plan Aggregation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T12:05:25.503372Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_439fb5d71477","title":"Multiwinner Voting with Interval Preferences under Incomplete Information","content":"arXiv:2510.11625v1 Announce Type: new Abstract: In multiwinner approval elections with many candidates, voters may struggle to determine their preferences over the entire slate of candidates. It is therefore of interest to explore which (if any) fairness guarantees can be provided under reduced communication. In this paper, we consider voters with one-dimensional preferences: voters and candidates are associated with points in $\\mathbb R$, and each voter's approval set forms an interval of $\\mathbb R$. We put forward a probabilistic preference model, where the voter set consists of $\\sigma$ different groups; each group is associated with a distribution over an interval of $\\mathbb R$, so that each voter draws the endpoints of her approval interval from the distribution associated with her group. We present an algorithm for computing committees that provide Proportional Justified Representation + (PJR+), which proceeds by querying voters' preferences, and show that, in expectation, it makes $\\mathcal{O}(\\log( \\sigma\\cdot k))$ queries per voter, where $k$ is the desired committee size.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11625","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.012076","language":"en","tags":["research","csgt","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":160,"author":"Drew Springham, Edith Elkind, Bart de Keijzer, Maria Polukarov","raw_content_length":1101,"priority":7,"update_frequency":1,"reading_time_minutes":0.8,"robust_parsing_used":true,"entities":{"organizations":["Interval Preferences","Proportional Justified Representation +"],"persons":["Multiwinner Voting with","\\mathbb"],"locations":[],"monetary":["\\mathbb"]},"char_count":1100,"language_detected":"en","key_concepts":{"key_phrases":["voters","Interval Preferences","Incomplete Information","candidates","arXiv251011625v1 Announce Type","new Abstract","multiwinner approval elections","many candidates","their preferences","the entire slate"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"voters":3.0,"Interval Preferences":2.0,"Incomplete Information":2.0,"candidates":2.0,"arXiv251011625v1 Announce Type":1.0,"new Abstract":1.0,"multiwinner approval elections":1.0,"many candidates":1.0,"their preferences":1.0,"the entire slate":1.0}},"age_hours":2.760433255,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9168,"joy":0.0047,"surprise":0.0239,"sadness":0.0164,"fear":0.0078,"anger":0.0137,"disgust":0.0167},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents an algorithm for multiwinner approval elections with interval preferences under incomplete information. While it aims to improve fairness and reduce communication, it is theoretical research with no immediate or direct impact on sustainability. The algorithm's efficiency is measured by the number of queries per voter, which is O(log(k)).","key_impact_metrics":["queries per voter: O(log(k))"],"technology_tags":["voting algorithms","preference elicitation"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T12:05:33.650544Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1a818443d2b0","title":"Sublinear Metric Steiner Forest via Maximal Independent Set","content":"arXiv:2510.11627v1 Announce Type: new Abstract: In this work we consider the Metric Steiner Forest problem in the sublinear time model. Given a set $V$ of $n$ points in a metric space where distances are provided by means of query access to an $n\\times n$ distance matrix, along with a set of $k$ terminal pairs $(s_1,t_1), \\dots, (s_k,t_k)\\in V\\times V$, the goal is to find a minimum-weight subset of edges that connects each terminal pair. Although sublinear time algorithms have been studied for estimating the weight of a minimum spanning tree in both general and metric settings, as well as for the metric Steiner Tree problem, no sublinear time algorithm was known for the metric Steiner Forest problem. Here, we give an $O(\\log k)$-approximation algorithm for the problem that runs in time $\\widetilde{O}(n^{3/2})$. Along the way, we provide the first sublinear-time algorithm for estimating the size of a Maximal Independent Set (MIS). Our algorithm runs in time $\\widetilde{O}(n^{3/2}/\\varepsilon^2)$ under the adjacency matrix oracle model and obtains a purely multiplicative $(1+\\varepsilon)$-approximation. Previously, sublinear-time algorithms for MIS were only known for bounded-degree graphs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11627","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.012456","language":"en","tags":["preprints","research","computer-science","csds","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Sepideh Mahabadi, Mohammad Roghani, Jakub Tarnawski, Ali Vakilian","raw_content_length":1211,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["Sublinear Metric Steiner Forest","Steiner Tree","Steiner Forest","the Metric Steiner Forest","Maximal Independent Set arXiv:2510.11627v1 Announce Type","\\dots","a Maximal Independent Set (M"],"persons":["\\widetilde{O}(n^{3/2})$. Along"],"locations":[],"monetary":["n\\times","$O(\\log k)$-approximation"]},"char_count":1208,"language_detected":"en","key_concepts":{"key_phrases":["Metric Steiner Forest","Maximal Independent Set","arXiv251011627v1 Announce Type","new Abstract","this work","the Metric Steiner Forest problem","the sublinear time model","n points","a metric space","distances"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Metric Steiner Forest":2.0,"Maximal Independent Set":2.0,"arXiv251011627v1 Announce Type":1.0,"new Abstract":1.0,"this work":1.0,"the Metric Steiner Forest problem":1.0,"the sublinear time model":1.0,"n points":1.0,"a metric space":1.0,"distances":1.0}},"age_hours":2.7604503077777776,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8458,"joy":0.0372,"surprise":0.0949,"sadness":0.008,"fear":0.0033,"anger":0.0083,"disgust":0.0026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm for the Metric Steiner Forest problem, achieving an O(log k)-approximation in sublinear time. While the algorithm itself doesn't directly reduce emissions, it improves the efficiency of solving a network optimization problem, which could indirectly contribute to sustainability by optimizing resource allocation in various applications. The technical credibility is high due to the mathematical nature of the work and the potential for peer review.","key_impact_metrics":["O(log k)-approximation","O(n^{3/2}) time complexity"],"technology_tags":["algorithms","optimization","network design"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:37.270269Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6274d15ebbc3","title":"EvoCAD: Evolutionary CAD Code Generation with Vision Language Models","content":"arXiv:2510.11631v1 Announce Type: new Abstract: Combining large language models with evolutionary computation algorithms represents a promising research direction leveraging the remarkable generative and in-context learning capabilities of LLMs with the strengths of evolutionary algorithms. In this work, we present EvoCAD, a method for generating computer-aided design (CAD) objects through their symbolic representations using vision language models and evolutionary optimization. Our method samples multiple CAD objects, which are then optimized using an evolutionary approach with vision language and reasoning language models. We assess our method using GPT-4V and GPT-4o, evaluating it on the CADPrompt benchmark dataset and comparing it to prior methods. Additionally, we introduce two new metrics based on topological properties defined by the Euler characteristic, which capture a form of semantic similarity between 3D objects. Our results demonstrate that EvoCAD outperforms previous approaches on multiple metrics, particularly in generating topologically correct objects, which can be efficiently evaluated using our two novel metrics that complement existing spatial metrics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11631","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.012859","language":"en","tags":["csai","preprints","cscv","research","csne","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Tobias Preintner, Weixuan Yuan, Adrian K\\\"onig, Thomas B\\\"ack, Elena Raponi, Niki van Stein","raw_content_length":1191,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["CAD","CADPrompt"],"persons":["Euler"],"locations":[],"monetary":[]},"char_count":1190,"language_detected":"en","key_concepts":{"key_phrases":["EvoCAD","Evolutionary CAD Code Generation","Vision Language Models","arXiv251011631v1 Announce Type","new Abstract","large language models","evolutionary computation algorithms","a promising research direction","context","LLMs"],"filter_categories":{"ai_ml":["large language models","evolutionary computation algorithms"],"research_academic":["a promising research direction"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"EvoCAD":3.0,"Evolutionary CAD Code Generation":2.0,"Vision Language Models":2.0,"arXiv251011631v1 Announce Type":1.0,"new Abstract":1.0,"large language models":1.0,"evolutionary computation algorithms":1.0,"a promising research direction":1.0,"context":1.0,"LLMs":1.0}},"age_hours":2.7604644141666665,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9001,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6622,"joy":0.1415,"surprise":0.1264,"sadness":0.0082,"fear":0.021,"anger":0.0261,"disgust":0.0145},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a method (EvoCAD) for generating CAD objects using vision language models and evolutionary optimization. While the method outperforms previous approaches on certain metrics, it is still in the early stages of development and lacks concrete deployment or measurable outcomes related to sustainability. The impact on climate change is theoretical at this point.","key_impact_metrics":["Topological correctness using Euler characteristic","Performance compared to CADPrompt benchmark"],"technology_tags":["Vision Language Models","Evolutionary Computation","Computer-Aided Design"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:40.569297Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_34ac2706c010","title":"NV3D: Leveraging Spatial Shape Through Normal Vector","content":"arXiv:2510.11632v1 Announce Type: new Abstract: Recent studies in 3D object detection for autonomous vehicles aim to enrich features through the utilization of multi-modal setups or the extraction of local patterns within LiDAR point clouds. However, multi-modal methods face significant challenges in feature alignment, and gaining features locally can be oversimplified for complex 3D object detection tasks. In this paper, we propose a novel model, NV3D, which utilizes local features acquired from voxel neighbors, as normal vectors computed per voxel basis using K-nearest neighbors (KNN) and principal component analysis (PCA). This informative feature enables NV3D to determine the relationship between the surface and pertinent target entities, including cars, pedestrians, or cyclists. During the normal vector extraction process, NV3D offers two distinct sampling strategies: normal vector density-based sampling and FOV-aware bin-based sampling, allowing elimination of up to 55% of data while maintaining performance. In addition, we applied element-wise attention fusion, which accepts voxel features as the query and value and normal vector features as the key, similar to the attention mechanism. Our method is trained on the KITTI dataset and has demonstrated superior performance in car and cyclist detection owing to their spatial shapes. In the validation set, NV3D without sampling achieves 86.60% and 80.18% mean Average Precision (mAP), greater than the baseline Voxel R-CNN by 2.61% and 4.23% mAP, respectively. With both samplings, NV3D achieves 85.54% mAP in car detection, exceeding the baseline by 1.56% mAP, despite roughly 55% of voxels being filtered out.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11632","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.013278","language":"en","tags":["computer-science","cslg","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":243,"author":"Krittin Chaowakarn, Paramin Sangwongngam, Nang Htet Htet Aung, Chalie Charoenlarpnopparut","raw_content_length":1686,"priority":7,"update_frequency":1,"reading_time_minutes":1.215,"robust_parsing_used":true,"entities":{"organizations":["NV3D","PCA","KNN","Normal Vector arXiv:2510.11632v1 Announce Type: new Abstract","FOV"],"persons":[],"locations":[],"monetary":[]},"char_count":1685,"language_detected":"en","key_concepts":{"key_phrases":["Spatial Shape","Normal Vector","features","arXiv251011632v1 Announce Type","new Abstract","Recent studies","3D object detection","autonomous vehicles","the utilization","multi-modal setups"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Spatial Shape":2.0,"Normal Vector":2.0,"features":2.0,"arXiv251011632v1 Announce Type":1.0,"new Abstract":1.0,"Recent studies":1.0,"3D object detection":1.0,"autonomous vehicles":1.0,"the utilization":1.0,"multi-modal setups":1.0}},"age_hours":2.7604797097222225,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7803,"joy":0.0115,"surprise":0.0129,"sadness":0.0081,"fear":0.1074,"anger":0.0464,"disgust":0.0334},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel model (NV3D) for 3D object detection in autonomous vehicles, demonstrating improved mAP in car and cyclist detection on the KITTI dataset. While the technology shows promise in reducing data processing requirements (55% data reduction), its direct climate impact is indirect (potentially more efficient autonomous driving). The research is in the applied research stage, with no evidence of real-world deployment or economic viability.","key_impact_metrics":["55% data reduction","86.60% mAP in car detection"],"technology_tags":["3D object detection","autonomous vehicles","LiDAR"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:43.966415Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1c5d21d6f797","title":"LRQ-Solver: A Transformer","content":"arXiv:2510.11636v1 Announce Type: new Abstract: Solving large-scale Partial Differential Equations (PDEs) on complex three-dimensional geometries represents a central challenge in scientific and engineering computing, often impeded by expensive pre-processing stages and substantial computational overhead. We introduce Low-Rank Query-based PDE Solver (LRQ-Solver), a physics-integrated framework engineered for rapid, accurate, and highly scalable simulations of industrial-grade models. This framework is built upon two primary technical innovations. First, our Parameter Conditioned Lagrangian Modeling (PCLM) approach explicitly couples local physical states with global design parameters, enabling robust predictions across varied simulation configurations. By embedding physical consistency directly into the learning architecture, PCLM ensures that predictions remain physically meaningful even under unseen design conditions, significantly enhancing generalization and reliability. Second, the Low-Rank Query Attention (LR-QA) module leverages the second-order statistics of physical fields to construct a global coherence kernel, reducing the computational complexity of attention from O(N2) to O(NC2 + C3). By replacing point-wise clustering with covariance decomposition, LRQ-Solver achieves exceptional scalability efficiently processing up to 2 million points on a single GPU. Validated on standard benchmarks, LRQ-Solver achieves a 38.9% error reduction on the DrivAer++ dataset and 28.76% on the 3D Beam dataset, alongside a training speedup of up to 50 times. Our results establish that LRQ-Solver offers a powerful paradigm for multi-configuration physics simulations, delivering a SOTA combination of accuracy, scalability, and efficiency. Code to reproduce the experiments is available at https://github.com/LilaKen/LRQ-Solver.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11636","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.013826","language":"en","tags":["preprints","research","computer-science","csce","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Peijian Zeng, Guan Wang, Haohao Gu, Xiaoguang Hu,  TiezhuGao, Zhuowei Wang, Aimin Yang, Xiaoyu Song","raw_content_length":1847,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":["PDE Solver","PCLM","LRQ-Solver: A Transformer arXiv:2510.11636v1 Announce Type: new Abstract","Parameter Conditioned Lagrangian Modeling"],"persons":[],"locations":[],"monetary":[]},"char_count":1846,"language_detected":"en","key_concepts":{"key_phrases":["LRQ-Solver","A Transformer","arXiv251011636v1 Announce Type","new Abstract","large-scale Partial Differential Equations","PDEs","complex three-dimensional geometries","a central challenge","scientific and engineering computing","expensive pre-processing stages"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LRQ-Solver":3.0,"A Transformer":2.0,"arXiv251011636v1 Announce Type":1.0,"new Abstract":1.0,"large-scale Partial Differential Equations":1.0,"PDEs":1.0,"complex three-dimensional geometries":1.0,"a central challenge":1.0,"scientific and engineering computing":1.0,"expensive pre-processing stages":1.0}},"age_hours":2.7604945941666665,"is_recent":true,"quality_score":1.0,"sentiment_score":7.7115,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5423,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8822,"joy":0.0166,"surprise":0.0685,"sadness":0.0052,"fear":0.0112,"anger":0.0125,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The LRQ-Solver framework shows promise in accelerating PDE simulations, which can lead to faster design and optimization of energy-efficient systems. The framework achieves a 38.9% error reduction on the DrivAer++ dataset and 28.76% on the 3D Beam dataset, alongside a training speedup of up to 50 times. However, it is still in the applied research stage with no deployed units.","key_impact_metrics":["38.9% error reduction on DrivAer++","28.76% error reduction on 3D Beam"],"technology_tags":["PDE Solver","Transformer","Computational Fluid Dynamics"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T12:05:47.673569Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_676e5ccd479c","title":"Continual Release of Densest Subgraphs: Privacy Amplification & Sublinear Space via Subsampling","content":"arXiv:2510.11640v1 Announce Type: new Abstract: We study the sublinear space continual release model for edge-differentially private (DP) graph algorithms, with a focus on the densest subgraph problem (DSG) in the insertion-only setting. Our main result is the first continual release DSG algorithm that matches the additive error of the best static DP algorithms and the space complexity of the best non-private streaming algorithms, up to constants. The key idea is a refined use of subsampling that simultaneously achieves privacy amplification and sparsification, a connection not previously formalized in graph DP. Via a simple black-box reduction to the static setting, we obtain both pure and approximate-DP algorithms with $O(\\log n)$ additive error and $O(n\\log n)$ space, improving both accuracy and space complexity over the previous state of the art. Along the way, we introduce graph densification in the graph DP setting, adding edges to trigger earlier subsampling, which removes the extra logarithmic factors in error and space incurred by prior work [ELMZ25]. We believe this simple idea may be of independent interest.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11640","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.014616","language":"en","tags":["computer-science","cslg","csds","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Felix Zhou","raw_content_length":1137,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["DSG"],"persons":["O(\\log","Announce Type"],"locations":[],"monetary":[]},"char_count":1136,"language_detected":"en","key_concepts":{"key_phrases":["Continual Release","Densest Subgraphs","Privacy Amplification","Sublinear Space","Subsampling","new Abstract","the sublinear space continual release model","a focus","the densest subgraph problem","DSG"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Continual Release":2.0,"Densest Subgraphs":2.0,"Privacy Amplification":2.0,"Sublinear Space":2.0,"Subsampling":2.0,"new Abstract":1.0,"the sublinear space continual release model":1.0,"a focus":1.0,"the densest subgraph problem":1.0,"DSG":1.0}},"age_hours":2.760525383888889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8976,"joy":0.0212,"surprise":0.051,"sadness":0.0054,"fear":0.0057,"anger":0.0112,"disgust":0.008},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for privacy-preserving graph analysis, specifically for identifying dense subgraphs. While the algorithm itself doesn't directly reduce GHG emissions, it could potentially contribute to sustainability efforts by enabling privacy-preserving analysis of energy consumption patterns or other environmentally relevant data. The research is at an early stage, with no deployed units or real-world data presented.","key_impact_metrics":[],"technology_tags":["differential privacy","graph algorithms","data analysis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:50.942141Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2f4b160dee69","title":"BridgeCode: A Dual Speech Representation Paradigm for Autoregressive Zero-Shot Text","content":"arXiv:2510.11646v1 Announce Type: new Abstract: Autoregressive (AR) frameworks have recently achieved remarkable progress in zero-shot text-to-speech (TTS) by leveraging discrete speech tokens and large language model techniques. Despite their success, existing AR-based zero-shot TTS systems face two critical limitations: (i) an inherent speed-quality trade-off, as sequential token generation either reduces frame rates at the cost of expressiveness or enriches tokens at the cost of efficiency, and (ii) a text-oriented supervision mismatch, as cross-entropy loss penalizes token errors uniformly without considering the fine-grained acoustic similarity among adjacent tokens. To address these challenges, we propose BridgeTTS, a novel AR-TTS framework built upon the dual speech representation paradigm BridgeCode. BridgeTTS reduces AR iterations by predicting sparse tokens while reconstructing rich continuous features for high-quality synthesis. Joint optimization of token-level and feature-level objectives further enhances naturalness and intelligibility. Experiments demonstrate that BridgeTTS achieves competitive quality and speaker similarity while significantly accelerating synthesis. Speech demos are available at https://test1562.github.io/demo/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.11646","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:39.015003","language":"en","tags":["computer-science","research","cssd","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Jingyuan Xing, Mingru Yang, Zhipeng Li, Xiaofen Xing, Xiangmin Xu","raw_content_length":1266,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["Autoregressive Zero-Shot Text arXiv:2510.11646v1 Announce Type","BridgeCode","A Dual Speech Representation Paradigm for","BridgeTTS","TTS"],"persons":[],"locations":[],"monetary":[]},"char_count":1265,"language_detected":"en","key_concepts":{"key_phrases":["BridgeCode","A Dual Speech Representation Paradigm","Autoregressive Zero-Shot Text","the cost","arXiv251011646v1 Announce Type","new Abstract Autoregressive AR frameworks","remarkable progress","zero-shot text","speech","TTS"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"BridgeCode":2.0,"A Dual Speech Representation Paradigm":2.0,"Autoregressive Zero-Shot Text":2.0,"the cost":2.0,"arXiv251011646v1 Announce Type":1.0,"new Abstract Autoregressive AR frameworks":1.0,"remarkable progress":1.0,"zero-shot text":1.0,"speech":1.0,"TTS":1.0}},"age_hours":2.7605416525,"is_recent":true,"quality_score":1.0,"sentiment_score":6.3685,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2737,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7859,"joy":0.0158,"surprise":0.1314,"sadness":0.008,"fear":0.0282,"anger":0.0215,"disgust":0.0093},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel autoregressive text-to-speech framework (BridgeTTS) that aims to improve synthesis speed and quality. While the research shows promise by accelerating synthesis, it is still in the early stages of development with no deployed units or real-world data. The impact on sustainability is indirect, potentially reducing energy consumption in data centers if widely adopted and more efficient than existing methods, but this is not quantified.","key_impact_metrics":["synthesis acceleration","quality improvement"],"technology_tags":["text-to-speech","autoregressive models","speech synthesis"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T12:05:54.332682Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
