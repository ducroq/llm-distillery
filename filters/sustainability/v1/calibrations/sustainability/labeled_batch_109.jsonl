{"id":"science_arxiv_cs_971af76a9969","title":"A Mathematics","content":"arXiv:2510.10081v1 Announce Type: new Abstract: Floating-point program errors can lead to severe consequences, particularly in critical domains such as military applications. Only a small subset of inputs may induce substantial floating-point errors, prompting researchers to develop methods for identifying these error-inducing inputs. Although existing approaches have achieved some success, they still suffer from two major limitations: (1) High computational cost: The evaluation of error magnitude for candidate inputs relies on high-precision programs, which are prohibitively time-consuming. (2) Limited long-range convergence capability: Current methods exhibit inefficiency in search, making the process akin to finding a needle in a haystack. To address these two limitations, we propose a novel method, named MGDE, to detect error-inducing inputs based on mathematical guidance. By employing the Newton-Raphson method, which exhibits quadratic convergence properties, we achieve highly effective and efficient results. Since the goal of identifying error-inducing inputs is to uncover the underlying bugs, we use the number of bugs detected in floating-point programs as the primary evaluation metric in our experiments. As FPCC represents the most effective state-of-the-art approach to date, we use it as the baseline for comparison. The dataset of FPCC consists of 88 single-input floating-point programs. FPCC is able to detect 48 bugs across 29 programs, whereas our method successfully identifies 89 bugs across 44 programs. Moreover, FPCC takes 6.4096 times as long as our proposed method. We also deploy our method to multi-input programs, identifying a total of nine bugs with an average detection time of 0.6443 seconds per program. In contrast, FPCC fails to detect any bugs while requiring an average computation time of 100 seconds per program.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10081","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.630650","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":268,"author":"Youshuai Tan, Zhanwei Zhang, Zishuo Ding, Lianyu Zheng, Jinfu Chen, Weiyi Shang","raw_content_length":1871,"priority":7,"update_frequency":1,"reading_time_minutes":1.34,"robust_parsing_used":true,"entities":{"organizations":["MGDE"],"persons":[],"locations":["Newton"],"monetary":[]},"char_count":1868,"language_detected":"en","key_concepts":{"key_phrases":["A Mathematics","arXiv251010081v1 Announce Type","new Abstract","Floating-point program errors","severe consequences","critical domains","military applications","Only a small subset","inputs","substantial floating-point errors"],"filter_categories":{"ai_ml":["critical domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Mathematics":2.0,"arXiv251010081v1 Announce Type":1.0,"new Abstract":1.0,"Floating-point program errors":1.0,"severe consequences":1.0,"critical domains":1.0,"military applications":1.0,"Only a small subset":1.0,"inputs":1.0,"substantial floating-point errors":1.0}},"age_hours":2.7480942419444445,"is_recent":true,"quality_score":1.0,"sentiment_score":0.6745000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8651,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6851,"joy":0.009,"surprise":0.0302,"sadness":0.0657,"fear":0.1534,"anger":0.0244,"disgust":0.0323},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research presents a novel method (MGDE) for detecting errors in floating-point programs, which can have significant consequences in critical domains. The method demonstrates improved bug detection compared to the baseline (FPCC), identifying 89 bugs across 44 programs versus 48 bugs across 29 programs. While not directly related to climate, reducing errors in programs used in climate modeling or energy systems could indirectly improve sustainability outcomes.","key_impact_metrics":["89 bugs detected","6.4096 times faster"],"technology_tags":["error detection","floating-point programs","mathematical guidance"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:08:15.878665Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4707e1bdf286","title":"Diversity Augmentation of Dynamic User Preference Data for Boosting Personalized Text Summarizers","content":"arXiv:2510.10082v1 Announce Type: new Abstract: Document summarization enables efficient extraction of user-relevant content but is inherently shaped by individual subjectivity, making it challenging to identify subjective salient information in multifaceted documents. This complexity underscores the necessity for personalized summarization. However, training models for personalized summarization has so far been challenging, particularly because diverse training data containing both user preference history (i.e., click-skip trajectory) and expected (gold-reference) summaries are scarce. The MS/CAS PENS dataset is a valuable resource but includes only preference history without target summaries, preventing end-to-end supervised learning, and its limited topic-transition diversity further restricts generalization. To address this, we propose $\\mathrm{PerAugy}$, a novel cross-trajectory shuffling and summary-content perturbation based data augmentation technique that significantly boosts the accuracy of four state-of-the-art baseline (SOTA) user-encoders commonly used in personalized summarization frameworks (best result: $\\text{0.132}$$\\uparrow$ w.r.t AUC). We select two such SOTA summarizer frameworks as baselines and observe that when augmented with their corresponding improved user-encoders, they consistently show an increase in personalization (avg. boost: $\\text{61.2\\%}\\uparrow$ w.r.t. PSE-SU4 metric). As a post-hoc analysis of the role of induced diversity in the augmented dataset by \\peraugy, we introduce three dataset diversity metrics -- $\\mathrm{TP}$, $\\mathrm{RTC}$, and \\degreed\\ to quantify the induced diversity. We find that $\\mathrm{TP}$ and $\\mathrm{DegreeD}$ strongly correlate with user-encoder performance on the PerAugy-generated dataset across all accuracy metrics, indicating that increased dataset diversity is a key factor driving performance gains.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10082","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.631077","language":"en","tags":["computer-science","cslg","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Parthiv Chatterjee, Shivam Sonawane, Amey Hengle, Aditya Tanna, Sourish Dasgupta, Tanmoy Chakraborty","raw_content_length":1899,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":["The MS/CAS PENS"],"persons":[],"locations":[],"monetary":[]},"char_count":1898,"language_detected":"en","key_concepts":{"key_phrases":["Diversity Augmentation","Dynamic User Preference Data","Personalized Text Summarizers","personalized summarization","arXiv251010082v1 Announce Type","new Abstract","Document summarization","efficient extraction","user-relevant content","individual subjectivity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diversity Augmentation":2.0,"Dynamic User Preference Data":2.0,"Personalized Text Summarizers":2.0,"personalized summarization":2.0,"arXiv251010082v1 Announce Type":1.0,"new Abstract":1.0,"Document summarization":1.0,"efficient extraction":1.0,"user-relevant content":1.0,"individual subjectivity":1.0}},"age_hours":2.748108646388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.937999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7876,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9335,"joy":0.0068,"surprise":0.0262,"sadness":0.0046,"fear":0.0105,"anger":0.01,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel data augmentation technique (PerAugy) to improve the accuracy of personalized text summarizers. The concrete action is the development and testing of this technique, with measured outcomes reported as AUC and PSE-SU4 metric improvements. The stage of deployment is basic research, as it focuses on algorithm development and evaluation on datasets.","key_impact_metrics":["AUC improvement: 0.132","PSE-SU4 boost: 61.2%"],"technology_tags":["Data Augmentation","Personalized Summarization","Machine Learning"],"sdg_alignment":[4],"analyzed_at":"2025-10-29T11:08:19.322496Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c3aeeea31085","title":"Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework","content":"arXiv:2510.10084v1 Announce Type: new Abstract: Tracking the spatiotemporal evolution of large-scale landslide scars is critical for understanding the evolution mechanisms and failure precursors, enabling effective early-warning. However, most existing studies have focused on single-phase or pre- and post-failure dual-phase landslide identification. Although these approaches delineate post-failure landslide boundaries, it is challenging to track the spatiotemporal evolution of landslide scars. To address this problem, this study proposes a novel and universal framework for tracking the spatiotemporal evolution of large-scale landslide scars using a vision foundation model. The key idea behind the proposed framework is to reconstruct discrete optical remote sensing images into a continuous video sequence. This transformation enables a vision foundation model, which is developed for video segmentation, to be used for tracking the evolution of landslide scars. The proposed framework operates within a knowledge-guided, auto-propagation, and interactive refinement paradigm to ensure the continuous and accurate identification of landslide scars. The proposed framework was validated through application to two representative cases: the post-failure Baige landslide and the active Sela landslide (2017-2025). Results indicate that the proposed framework enables continuous tracking of landslide scars, capturing both failure precursors critical for early warning and post-failure evolution essential for assessing secondary hazards and long-term stability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10084","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.631502","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Meijun Zhou, Gang Mei, Zhengjing Ma, Nengxiong Xu, Jianbing Peng","raw_content_length":1568,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["the Spatiotemporal Evolution of Landslide Scars"],"persons":["Universal Framework arXiv:2510.10084v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1567,"language_detected":"en","key_concepts":{"key_phrases":["the Spatiotemporal Evolution","Landslide Scars","a Vision Foundation Model","A Novel and Universal Framework","the spatiotemporal evolution","arXiv251010084v1 Announce Type","new Abstract","large-scale landslide scars","the evolution mechanisms","failure precursors"],"filter_categories":{"engineering":["the Spatiotemporal Evolution","the spatiotemporal evolution"],"ai_ml":["failure precursors"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Spatiotemporal Evolution":2.0,"Landslide Scars":2.0,"a Vision Foundation Model":2.0,"A Novel and Universal Framework":2.0,"the spatiotemporal evolution":2.0,"arXiv251010084v1 Announce Type":1.0,"new Abstract":1.0,"large-scale landslide scars":1.0,"the evolution mechanisms":1.0,"failure precursors":1.0}},"age_hours":2.7481237755555554,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6062,"joy":0.0089,"surprise":0.0247,"sadness":0.0155,"fear":0.3216,"anger":0.0164,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework for tracking landslide scars using a vision foundation model, validated on two case studies (Baige and Sela landslides). While the framework shows promise for early warning and hazard assessment, it's currently in the applied research stage with limited information on economic viability and deployment readiness beyond these case studies. The framework's ability to capture failure precursors and post-failure evolution is a concrete action with potential for significant impact.","key_impact_metrics":["Continuous tracking of landslide scars","Capturing failure precursors"],"technology_tags":["Vision Foundation Model","Remote Sensing","Landslide Monitoring"],"sdg_alignment":[9,11,13,15],"analyzed_at":"2025-10-29T11:08:22.760045Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f849532d46c5","title":"Pharmacist: Safety Alignment Data Curation for Large Language Models against Harmful Fine","content":"arXiv:2510.10085v1 Announce Type: new Abstract: Harmful fine-tuning issues present significant safety challenges for fine-tuning-as-a-service in large language models. Existing alignment-stage defenses, e.g., Vaccine, Repnoise, Booster, and T-Vaccine, mitigate harmful fine-tuning issues by enhancing the model's robustness during the alignment phase. While these methods have been proposed to mitigate the issue, they often overlook a critical upstream factor: the role of the original safety-alignment data. We observe that their defense performance and computational efficiency remain constrained by the quality and composition of the alignment dataset. To address this limitation, we propose Pharmacist, a safety alignment data curation solution that enhances defense against harmful fine-tuning by selecting a high-quality and safety-critical core subset from the original alignment data. The core idea of Pharmacist is to train an alignment data selector to rank alignment data. Specifically, up-ranking high-quality and safety-critical alignment data, down-ranking low-quality and non-safety-critical data. Empirical results indicate that models trained on datasets selected by Pharmacist outperform those trained on datasets selected by existing selection methods in both defense and inference performance. In addition, Pharmacist can be effectively integrated with mainstream alignment-stage defense methods. For example, when applied to RepNoise and T-Vaccine, using the dataset selected by Pharmacist instead of the full dataset leads to improvements in defense performance by 2.60\\% and 3.30\\%, respectively, and enhances inference performance by 3.50\\% and 1.10\\%. Notably, it reduces training time by 56.83\\% and 57.63\\%, respectively. Our code is available at https://github.com/Lslland/Pharmacist.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10085","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.631934","language":"en","tags":["computer-science","cslg","csai","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Guozhi Liu, Qi Mu, Tiansheng Huang, Xinhua Wang, Li Shen, Weiwei Lin, Zhang Li","raw_content_length":1814,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["Safety Alignment Data Curation for Large Language Models"],"persons":["Booster","Vaccine","Repnoise","Harmful Fine arXiv:2510.10085v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1813,"language_detected":"en","key_concepts":{"key_phrases":["Pharmacist","Safety Alignment Data Curation","Large Language Models","Harmful Fine","arXiv251010085v1 Announce Type","new Abstract","Harmful fine-tuning issues","significant safety challenges","fine-tuning","a-service"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Pharmacist":2.0,"Safety Alignment Data Curation":2.0,"Large Language Models":2.0,"Harmful Fine":2.0,"arXiv251010085v1 Announce Type":1.0,"new Abstract":1.0,"Harmful fine-tuning issues":1.0,"significant safety challenges":1.0,"fine-tuning":1.0,"a-service":1.0}},"age_hours":2.748140083611111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2405,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8481,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5158,"joy":0.0108,"surprise":0.0088,"sadness":0.0272,"fear":0.2211,"anger":0.0722,"disgust":0.1442},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a method (Pharmacist) to improve the safety of large language models by curating safety-alignment data. It shows measurable improvements in defense performance (2.60% and 3.30%) and inference performance (3.50% and 1.10%) when integrated with existing methods, and reduces training time (56.83% and 57.63%). This is still in the applied research stage, with no evidence of real-world deployment.","key_impact_metrics":["defense performance improvement 2.60%","training time reduction 56.83%"],"technology_tags":["large language models","AI safety","data curation"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T11:08:26.158213Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4f9b5f4865db","title":"Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety","content":"arXiv:2510.10086v1 Announce Type: new Abstract: Current evaluation methods for autonomous driving prediction models rely heavily on simplistic metrics such as Average Displacement Error (ADE) and Final Displacement Error (FDE). While these metrics offer basic performance assessments, they fail to capture the nuanced behavior of prediction modules under complex, interactive, and safety-critical driving scenarios. For instance, existing benchmarks do not distinguish the influence of nearby versus distant agents, nor systematically test model robustness across varying multi-agent interactions. This paper addresses this critical gap by proposing a novel testing framework that evaluates prediction performance under diverse scene structures, saying, map context, agent density and spatial distribution. Through extensive empirical analysis, we quantify the differential impact of agent proximity on target trajectory prediction and identify scenario-specific failure cases that are not exposed by traditional metrics. Our findings highlight key vulnerabilities in current state-of-the-art prediction models and demonstrate the importance of scenario-aware evaluation. The proposed framework lays the groundwork for rigorous, safety-driven prediction validation, contributing significantly to the identification of failure-prone corner cases and the development of robust, certifiable prediction systems for autonomous vehicles.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10086","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.632336","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Feifei Liu, Haozhe Wang, Zejun Wei, Qirong Lu, Yiyang Wen, Xiaoyu Tang, Jingyan Jiang, Zhijian He","raw_content_length":1432,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["ADE","Final Displacement Error","Average Displacement Error"],"persons":[],"locations":[],"monetary":[]},"char_count":1431,"language_detected":"en","key_concepts":{"key_phrases":["ADE","FDE","Safety","Announce Type","new Abstract","Current evaluation methods","autonomous driving prediction models","simplistic metrics","Average Displacement Error","Final Displacement Error"],"filter_categories":{"research_academic":["ADE"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ADE":3.0,"FDE":3.0,"Safety":2.0,"Announce Type":1.0,"new Abstract":1.0,"Current evaluation methods":1.0,"autonomous driving prediction models":1.0,"simplistic metrics":1.0,"Average Displacement Error":1.0,"Final Displacement Error":1.0}},"age_hours":2.7481544444444443,"is_recent":true,"quality_score":1.0,"sentiment_score":1.8755,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6249,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8172,"joy":0.0043,"surprise":0.0411,"sadness":0.0428,"fear":0.0241,"anger":0.0331,"disgust":0.0373},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel testing framework for autonomous driving prediction models, addressing limitations of existing metrics. The framework quantifies the impact of agent proximity on trajectory prediction and identifies scenario-specific failures, contributing to the development of robust prediction systems. However, it is still in the research phase with no deployed units or customer contracts, limiting its current impact.","key_impact_metrics":["differential impact of agent proximity on target trajectory prediction","scenario-specific failure cases identified"],"technology_tags":["autonomous driving","prediction models","safety validation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:08:29.383442Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_174a23d55bc9","title":"Matchmaker: An Open","content":"arXiv:2510.10087v1 Announce Type: new Abstract: Real-time music alignment, also known as score following, is a fundamental MIR task with a long history and is essential for many interactive applications. Despite its importance, there has not been a unified open framework for comparing models, largely due to the inherent complexity of real-time processing and the language- or system-dependent implementations. In addition, low compatibility with the existing MIR environment has made it difficult to develop benchmarks using large datasets available in recent years. While new studies based on established methods (e.g., dynamic programming, probabilistic models) have emerged, most evaluations compare models only within the same family or on small sets of test data. This paper introduces Matchmaker, an open-source Python library for real-time music alignment that is easy to use and compatible with modern MIR libraries. Using this, we systematically compare methods along two dimensions: music representations and alignment methods. We evaluated our approach on a large test set of solo piano music from the (n)ASAP, Batik, and Vienna4x22 datasets with a comprehensive set of metrics to ensure robust assessment. Our work aims to establish a benchmark framework for score-following research while providing a practical tool that developers can easily integrate into their applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10087","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.632766","language":"en","tags":["computer-science","research","cssd","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":202,"author":"Jiyun Park, Carlos Cancino-Chac\\'on, Suhit Chiruthapudi, Juhan Nam","raw_content_length":1393,"priority":7,"update_frequency":1,"reading_time_minutes":1.01,"robust_parsing_used":true,"entities":{"organizations":["MIR"],"persons":["Matchmaker"],"locations":[],"monetary":[]},"char_count":1392,"language_detected":"en","key_concepts":{"key_phrases":["Matchmaker","An Open","arXiv251010087v1 Announce Type","new Abstract","Real-time music alignment","a fundamental MIR task","a long history","many interactive applications","its importance","a unified open framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Matchmaker":2.0,"An Open":2.0,"arXiv251010087v1 Announce Type":1.0,"new Abstract":1.0,"Real-time music alignment":1.0,"a fundamental MIR task":1.0,"a long history":1.0,"many interactive applications":1.0,"its importance":1.0,"a unified open framework":1.0}},"age_hours":2.748169415555555,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7045,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6591,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8266,"joy":0.0346,"surprise":0.1107,"sadness":0.0109,"fear":0.0069,"anger":0.0077,"disgust":0.0026},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces an open-source Python library for real-time music alignment. While it's a valuable tool for music information retrieval, its direct impact on sustainability is minimal. The library is evaluated on datasets, but there's no deployment or direct link to environmental benefits.","key_impact_metrics":[],"technology_tags":["music information retrieval","score following","python library"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:08:32.307355Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4ee213b4adb9","title":"What Makes Looped Transformers Perform Better Than Non","content":"arXiv:2510.10089v1 Announce Type: new Abstract: While looped transformers (termed as Looped-Attn) often outperform standard transformers (termed as Single-Attn) on complex reasoning tasks, the theoretical basis for this advantage remains underexplored. In this paper, we explain this phenomenon through the lens of loss landscape geometry, inspired by empirical observations of their distinct dynamics at both sample and Hessian levels. To formalize this, we extend the River-Valley landscape model by distinguishing between U-shaped valleys (flat) and V-shaped valleys (steep). Based on empirical observations, we conjecture that the recursive architecture of Looped-Attn induces a landscape-level inductive bias towards River-V-Valley. Theoretical derivations based on this inductive bias guarantee a better loss convergence along the river due to valley hopping, and further encourage learning about complex patterns compared to the River-U-Valley induced by Single-Attn. Building on this insight, we propose SHIFT (Staged HIerarchical Framework for Progressive Training), a staged training framework that accelerates the training process of Looped-Attn while achieving comparable performances.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10089","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.633163","language":"en","tags":["statml","cslg","csai","preprints","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":157,"author":"Zixuan Gong, Jiaye Teng, Yong Liu","raw_content_length":1198,"priority":7,"update_frequency":1,"reading_time_minutes":0.785,"robust_parsing_used":true,"entities":{"organizations":["Single-Attn","Looped-Attn"],"persons":[],"locations":["River-Valley"],"monetary":[]},"char_count":1197,"language_detected":"en","key_concepts":{"key_phrases":["What","Looped Transformers","Non","arXiv251010089v1 Announce Type","new Abstract","looped transformers","Looped-Attn","standard transformers","Single-Attn","complex reasoning tasks"],"filter_categories":{"ai_ml":["Looped Transformers","looped transformers","standard transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Looped Transformers":2.0,"Non":2.0,"arXiv251010089v1 Announce Type":1.0,"new Abstract":1.0,"looped transformers":1.0,"Looped-Attn":1.0,"standard transformers":1.0,"Single-Attn":1.0,"complex reasoning tasks":1.0}},"age_hours":2.7481851511111115,"is_recent":true,"quality_score":1.0,"sentiment_score":8.995999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7992,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8294,"joy":0.0219,"surprise":0.0322,"sadness":0.0044,"fear":0.0508,"anger":0.0372,"disgust":0.0241},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on the theoretical advantages of looped transformers in AI, specifically concerning loss landscape geometry and training efficiency. While the research proposes a new training framework (SHIFT), it remains at the basic research stage with no deployed technology or measured outcomes in a real-world setting. The potential climate impact is indirect, relying on the assumption that more efficient AI could lead to more efficient solutions in climate-related fields.","key_impact_metrics":[],"technology_tags":["Looped Transformers","Artificial Intelligence","Machine Learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:08:35.209659Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_683f48b8bb20","title":"CardRewriter: Leveraging Knowledge Cards for Long","content":"arXiv:2510.10095v1 Announce Type: new Abstract: Short-video platforms have rapidly become a new generation of information retrieval systems, where users formulate queries to access desired videos. However, user queries, especially long-tail ones, often suffer from spelling errors, incomplete phrasing, and ambiguous intent, resulting in mismatches between user expectations and retrieved results. While large language models (LLMs) have shown success in long-tail query rewriting within e-commerce, they struggle on short-video platforms, where proprietary content such as short videos, live streams, micro dramas, and user social networks falls outside their training distribution. To address this challenge, we introduce \\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specific knowledge to enhance long-tail query rewriting. For each query, our method aggregates multi-source knowledge relevant to the query and summarizes it into an informative and query-relevant knowledge card. This card then guides the LLM to better capture user intent and produce more effective query rewrites. We optimize CardRewriter using a two-stage training pipeline: supervised fine-tuning followed by group relative policy optimization, with a tailored reward system balancing query relevance and retrieval effectiveness. Offline experiments show that CardRewriter substantially improves rewriting quality for queries targeting proprietary content. Online A/B testing further confirms significant gains in long-view rate (LVR) and click-through rate (CTR), along with a notable reduction in initiative query reformulation rate (IQRR). Since September 2025, CardRewriter has been deployed on Kuaishou, one of China's largest short-video platforms, serving hundreds of millions of users daily.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10095","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.633614","language":"en","tags":["computer-science","preprints","cscl","csir","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Peiyuan Gong, Feiran Zhu, Yaqi Yin, Chenglei Dai, Chao Zhang, Kai Zheng, Wentian Bao, Jiaxin Mao, Yi Zhang","raw_content_length":1799,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["LLM","CardRewriter"],"persons":[],"locations":[],"monetary":[]},"char_count":1798,"language_detected":"en","key_concepts":{"key_phrases":["CardRewriter","Knowledge Cards","Long","arXiv251010095v1 Announce Type","new Abstract Short-video platforms","a new generation","information retrieval systems","users","queries","access"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CardRewriter":2.0,"Knowledge Cards":2.0,"Long":2.0,"arXiv251010095v1 Announce Type":1.0,"new Abstract Short-video platforms":1.0,"a new generation":1.0,"information retrieval systems":1.0,"users":1.0,"queries":1.0,"access":1.0}},"age_hours":2.7482003597222224,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8807,"joy":0.0044,"surprise":0.0229,"sadness":0.0439,"fear":0.0154,"anger":0.0115,"disgust":0.0213},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":6,"economic_viability":5,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"CardRewriter is deployed on Kuaishou, a major short-video platform, serving hundreds of millions of users daily. The technology has demonstrated improvements in long-view rate (LVR) and click-through rate (CTR), and a reduction in initiative query reformulation rate (IQRR) through A/B testing. While deployed, the direct climate impact is unclear, but improved information retrieval could reduce energy consumption from unnecessary searches.","key_impact_metrics":["Long-view rate (LVR)","Click-through rate (CTR)","Initiative query reformulation rate (IQRR)"],"technology_tags":["LLM","Knowledge Cards","Query Rewriting"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:08:38.626432Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3e184ccfbccf","title":"Gesplat: Robust Pose","content":"arXiv:2510.10097v1 Announce Type: new Abstract: Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have advanced 3D reconstruction and novel view synthesis, but remain heavily dependent on accurate camera poses and dense viewpoint coverage. These requirements limit their applicability in sparse-view settings, where pose estimation becomes unreliable and supervision is insufficient. To overcome these challenges, we introduce Gesplat, a 3DGS-based framework that enables robust novel view synthesis and geometrically consistent reconstruction from unposed sparse images. Unlike prior works that rely on COLMAP for sparse point cloud initialization, we leverage the VGGT foundation model to obtain more reliable initial poses and dense point clouds. Our approach integrates several key innovations: 1) a hybrid Gaussian representation with dual position-shape optimization enhanced by inter-view matching consistency; 2) a graph-guided attribute refinement module to enhance scene details; and 3) flow-based depth regularization that improves depth estimation accuracy for more effective supervision. Comprehensive quantitative and qualitative experiments demonstrate that our approach achieves more robust performance on both forward-facing and large-scale complex datasets compared to other pose-free methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10097","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.634017","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Jiahui Lu, Haihong Xiao, Xueyan Zhao, Wenxiong Kang","raw_content_length":1325,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["VGGT","NeRF","COLMAP"],"persons":["Gesplat","Radiance Fields"],"locations":[],"monetary":[]},"char_count":1324,"language_detected":"en","key_concepts":{"key_phrases":["Gesplat Robust Pose","arXiv251010097v1 Announce Type","new Abstract","NeRF","3DGS","3D reconstruction","novel view synthesis","accurate camera poses","dense viewpoint coverage","These requirements"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Gesplat Robust Pose":2.0,"arXiv251010097v1 Announce Type":1.0,"new Abstract":1.0,"NeRF":1.0,"3DGS":1.0,"3D reconstruction":1.0,"novel view synthesis":1.0,"accurate camera poses":1.0,"dense viewpoint coverage":1.0,"These requirements":1.0}},"age_hours":2.7482151522222225,"is_recent":true,"quality_score":1.0,"sentiment_score":8.062000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6124,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9148,"joy":0.0101,"surprise":0.023,"sadness":0.011,"fear":0.0173,"anger":0.0148,"disgust":0.009},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (Gesplat) for improving 3D reconstruction and novel view synthesis from sparse images. While the technology itself doesn't directly reduce GHG emissions, improved 3D reconstruction could potentially contribute to more efficient design and planning in various sectors, including infrastructure and urban planning, leading to indirect sustainability benefits. The research is in its early stages (basic research) and lacks concrete deployment or economic viability data, but it does present quantitative results demonstrating performance improvements.","key_impact_metrics":["Improved pose estimation accuracy","More robust performance on forward-facing and large-scale complex datasets"],"technology_tags":["Neural Radiance Fields","3D Gaussian Splatting","Computer Vision","Machine Learning"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T11:08:42.094927Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f5578ff11831","title":"Cooperative Pseudo Labeling for Unsupervised Federated Classification","content":"arXiv:2510.10100v1 Announce Type: new Abstract: Unsupervised Federated Learning (UFL) aims to collaboratively train a global model across distributed clients without sharing data or accessing label information. Previous UFL works have predominantly focused on representation learning and clustering tasks. Recently, vision language models (e.g., CLIP) have gained significant attention for their powerful zero-shot prediction capabilities. Leveraging this advancement, classification problems that were previously infeasible under the UFL paradigm now present promising new opportunities, yet remain largely unexplored. In this paper, we extend UFL to the classification problem with CLIP for the first time and propose a novel method, \\underline{\\textbf{Fed}}erated \\underline{\\textbf{Co}}operative \\underline{\\textbf{P}}seudo \\underline{\\textbf{L}}abeling (\\textbf{FedCoPL}). Specifically, clients estimate and upload their pseudo label distribution, and the server adjusts and redistributes them to avoid global imbalance among classes. Moreover, we introduce a partial prompt aggregation protocol for effective collaboration and personalization. In particular, visual prompts containing general image features are aggregated at the server, while text prompts encoding personalized knowledge are retained locally. Extensive experiments demonstrate the superior performance of our FedCoPL compared to baseline methods. Our code is available at \\href{https://github.com/krumpguo/FedCoPL}{https://github.com/krumpguo/FedCoPL}.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10100","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.634421","language":"en","tags":["computer-science","cslg","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Kuangpu Guo, Lijun Sheng, Yongcan Yu, Jian Liang, Zilei Wang, Ran He","raw_content_length":1527,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Unsupervised Federated Learning","UFL","CLIP"],"persons":[],"locations":[],"monetary":[]},"char_count":1526,"language_detected":"en","key_concepts":{"key_phrases":["Cooperative Pseudo Labeling","Unsupervised Federated Classification","Announce Type","new Abstract","Unsupervised Federated Learning","UFL","a global model","distributed clients","data","accessing label information"],"filter_categories":{"ai_ml":["data"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cooperative Pseudo Labeling":2.0,"Unsupervised Federated Classification":2.0,"Announce Type":1.0,"new Abstract":1.0,"Unsupervised Federated Learning":1.0,"UFL":1.0,"a global model":1.0,"distributed clients":1.0,"data":1.0,"accessing label information":1.0}},"age_hours":2.7482285558333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.520999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9042,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8973,"joy":0.0346,"surprise":0.0361,"sadness":0.0048,"fear":0.0088,"anger":0.013,"disgust":0.0054},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel federated learning method (FedCoPL) for unsupervised classification using CLIP models. While the approach is innovative and shows promise in improving classification accuracy without data sharing, it is currently in the basic research stage with no deployed units or quantified environmental impact. The potential climate impact is indirect and depends on the application of the classification model.","key_impact_metrics":[],"technology_tags":["Federated Learning","Unsupervised Learning","CLIP Model","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:08:45.153002Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_caaace7a1e43","title":"Rademacher Meets Colors: More Expressivity, but at What Cost ?","content":"arXiv:2510.10101v1 Announce Type: new Abstract: The expressive power of graph neural networks (GNNs) is typically understood through their correspondence with graph isomorphism tests such as the Weisfeiler-Leman (WL) hierarchy. While more expressive GNNs can distinguish a richer set of graphs, they are also observed to suffer from higher generalization error. This work provides a theoretical explanation for this trade-off by linking expressivity and generalization through the lens of coloring algorithms. Specifically, we show that the number of equivalence classes induced by WL colorings directly bounds the GNNs Rademacher complexity -- a key data-dependent measure of generalization. Our analysis reveals that greater expressivity leads to higher complexity and thus weaker generalization guarantees. Furthermore, we prove that the Rademacher complexity is stable under perturbations in the color counts across different samples, ensuring robustness to sampling variability across datasets. Importantly, our framework is not restricted to message-passing GNNs or 1-WL, but extends to arbitrary GNN architectures and expressivity measures that partition graphs into equivalence classes. These results unify the study of expressivity and generalization in GNNs, providing a principled understanding of why increasing expressive power often comes at the cost of generalization.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10101","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.634843","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Martin Carrasco, Caio Deberaldini Netto, Vahan A. Martirosyan, Aneeqa Mehrab, Ehimare Okoyomon, Caterina Graziani","raw_content_length":1384,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Weisfeiler-Leman"],"persons":["Rademacher","Announce Type","Rademacher Meets Colors"],"locations":[],"monetary":[]},"char_count":1383,"language_detected":"en","key_concepts":{"key_phrases":["Rademacher","More Expressivity","What Cost","arXiv251010101v1","Announce Type","new Abstract","The expressive power","graph neural networks","GNNs","their correspondence"],"filter_categories":{"ai_ml":["graph neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Rademacher":2.0,"More Expressivity":2.0,"What Cost":2.0,"arXiv251010101v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"The expressive power":1.0,"graph neural networks":1.0,"GNNs":1.0,"their correspondence":1.0}},"age_hours":2.7482432230555554,"is_recent":true,"quality_score":1.0,"sentiment_score":2.1405000000000003,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5719,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8081,"joy":0.0068,"surprise":0.0435,"sadness":0.0684,"fear":0.0118,"anger":0.015,"disgust":0.0463},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This theoretical research explores the trade-off between expressivity and generalization in graph neural networks, linking coloring algorithms to Rademacher complexity. While it provides a principled understanding of GNN limitations, it lacks concrete actions or measurable outcomes related to climate change mitigation or adaptation. It is at the basic research stage with no deployment or economic viability demonstrated.","key_impact_metrics":[],"technology_tags":["graph neural networks","machine learning","coloring algorithms"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:08:48.000163Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d085eaa7e414","title":"PANTHER: Generative Pretraining Beyond Language for Sequential User Behavior Modeling","content":"arXiv:2510.10102v1 Announce Type: new Abstract: Large language models (LLMs) have shown that generative pretraining can distill vast world knowledge into compact token representations. While LLMs encapsulate extensive world knowledge, they remain limited in modeling the behavioral knowledge contained within user interaction histories. User behavior forms a distinct modality, where each action, defined by multi-dimensional attributes such as time, context, and transaction type, constitutes a behavioral token. Modeling these high-cardinality sequences is challenging, and discriminative models often falter under limited supervision. To bridge this gap, we extend generative pretraining to user behavior, learning transferable representations from unlabeled behavioral data analogous to how LLMs learn from text. We present PANTHER, a hybrid generative-discriminative framework that unifies user behavior pretraining and downstream adaptation, enabling large-scale sequential user representation learning and real-time inference. PANTHER introduces: (1) Structured Tokenization to compress multi-dimensional transaction attributes into an interpretable vocabulary; (2) Sequence Pattern Recognition Module (SPRM) for modeling periodic transaction motifs; (3) a Unified User-Profile Embedding that fuses static demographics with dynamic transaction histories; and (4) Real-time scalability enabled by offline caching of pretrained embeddings for millisecond-level inference. Fully deployed and operational online at WeChat Pay, PANTHER delivers a 25.6 percent boost in next-transaction prediction HitRate@1 and a 38.6 percent relative improvement in fraud detection recall over baselines. Cross-domain evaluations on public benchmarks show strong generalization, achieving up to 21 percent HitRate@1 gains over transformer baselines, establishing PANTHER as a scalable, high-performance framework for industrial sequential user behavior modeling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10102","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.635264","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":242,"author":"Guilin Li, Yun Zhang, Xiuyuan Chen, Chengqi Li, Bo Wang, Linghe Kong, Wenjia Wang, Weiran Huang, Matthias Hwai Yong Tan","raw_content_length":1949,"priority":7,"update_frequency":1,"reading_time_minutes":1.21,"robust_parsing_used":true,"entities":{"organizations":["PANTHER"],"persons":[],"locations":[],"monetary":[]},"char_count":1948,"language_detected":"en","key_concepts":{"key_phrases":["PANTHER","Language","Sequential User Behavior Modeling","LLMs","arXiv251010102v1 Announce Type","new Abstract","Large language models","that generative pretraining","vast world knowledge","compact token representations"],"filter_categories":{"ai_ml":["Language","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PANTHER":2.0,"Language":2.0,"Sequential User Behavior Modeling":2.0,"LLMs":2.0,"arXiv251010102v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"that generative pretraining":1.0,"vast world knowledge":1.0,"compact token representations":1.0}},"age_hours":2.7482575052777776,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9325,"joy":0.0098,"surprise":0.0271,"sadness":0.0035,"fear":0.0053,"anger":0.013,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":6,"deployment_readiness":7,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":false,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"PANTHER is deployed and operational at WeChat Pay, indicating commercial deployment. It delivers a 25.6% boost in next-transaction prediction HitRate@1 and a 38.6% relative improvement in fraud detection recall over baselines, providing measurable outcomes. The technical credibility is supported by the reported performance gains, although peer review is not explicitly mentioned.","key_impact_metrics":["25.6 percent boost in next-transaction prediction HitRate@1","38.6 percent relative improvement in fraud detection recall"],"technology_tags":["Generative Pretraining","User Behavior Modeling","Fraud Detection"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:08:50.813534Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f699a2526b18","title":"Stop When Enough: Adaptive Early-Stopping for Chain","content":"arXiv:2510.10103v1 Announce Type: new Abstract: Chain-of-Thought (CoT) reasoning has driven recent gains of large language models (LLMs) on reasoning-intensive tasks by externalizing intermediate steps. However, excessive or redundant reasoning -- so-called overthinking -- can increase inference costs and lead LLMs toward incorrect conclusions. In this paper, we present REFRAIN ($\\underline{REF}$lective-$\\underline{R}$edundancy for $\\underline{A}$daptive $\\underline{IN}$ference), a training-free framework that adaptively determines when to stop reasoning to mitigate overthinking. REFRAIN integrates a two-stage stop discriminator to identify reflective yet redundant reasoning and a sliding-window Upper Confidence Bound (SW-UCB) multi-armed bandit controller to dynamically adjust stopping thresholds according to problem difficulty without supervision or fine-tuning. Across four representative benchmarks and two model families, REFRAIN reduces token usage by 20-55% while maintaining or improving accuracy compared to standard CoT prompting. Extensive ablation and robustness analyses demonstrate its stability across models, scorers, and prompt variations. In summary, our findings highlight when-to-stop as a new and practical axis of test-time scaling -- enabling models to reason not just more, but just enough.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10103","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.635677","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Renliang Sun, Wei Cheng, Dawei Li, Haifeng Chen, Wei Wang","raw_content_length":1327,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["Upper Confidence Bound","CoT","REFRAIN r","Chain arXiv:2510.10103v1 Announce Type"],"persons":["REFRAIN"],"locations":[],"monetary":["$\\underline{A}$daptive $"]},"char_count":1326,"language_detected":"en","key_concepts":{"key_phrases":["Chain","LLMs","arXiv251010103v1 Announce Type","new Abstract","Thought","CoT","recent gains","large language models","reasoning-intensive tasks","intermediate steps"],"filter_categories":{"ai_ml":["Chain","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chain":2.0,"LLMs":2.0,"arXiv251010103v1 Announce Type":1.0,"new Abstract":1.0,"Thought":1.0,"CoT":1.0,"recent gains":1.0,"large language models":1.0,"reasoning-intensive tasks":1.0,"intermediate steps":1.0}},"age_hours":2.7482726824999997,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7352,"joy":0.0038,"surprise":0.009,"sadness":0.012,"fear":0.0902,"anger":0.116,"disgust":0.0337},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a training-free framework (REFRAIN) that adaptively determines when to stop reasoning in large language models (LLMs) to mitigate overthinking, which can reduce inference costs. The concrete action is the development and testing of this framework. The evidence supporting the claims is the reduction in token usage by 20-55% while maintaining or improving accuracy compared to standard CoT prompting across four benchmarks and two model families. This is currently in the applied research stage, with no indication of real-world deployment.","key_impact_metrics":["token usage reduction 20-55%","accuracy maintained or improved"],"technology_tags":["large language models","chain-of-thought reasoning","adaptive inference"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:08:53.928116Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_32aa9b21df4c","title":"Answer-Consistent Chain-of","content":"arXiv:2510.10104v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have demonstrated that reinforcement learning with verifiable rewards (RLVR) can significantly enhance reasoning abilities by directly optimizing correctness, rather than relying solely on supervised imitation. This paradigm has been extended to multimodal LLMs for complex video and image understanding tasks. However, while outcome-driven RL improves answer accuracy, it can inadvertently decouple the reasoning chain from the final answer, leading to situations where models produce inconsistency between the reasoning trace and final answer. In our experiments on multiple-choice visual question-answering tasks, the standard GRPO method yields only 79.7\\% consistency on MMVU between the reasoning steps and the chosen answers, indicating frequent mismatches between answers and reasoning. To this end, we propose Answer-Consistent Reinforcement Learning (ACRE) that modifies the GRPO algorithm with an auxiliary consistency check. After the model generates a chain of thought and an initial answer for a given question, we shuffle the answer options and prompt the model again with the same reasoning trace to predict a second answer. We design a consistency-verification reward that grants a high reward only if both the original and the post-shuffle answers agree and are correct; otherwise, a lower reward is assigned accordingly. This mechanism penalizes reasoning-answer misalignment and discourages the model from relying on spurious patterns, such as option ordering biases. We evaluate ACRE on challenging Video Reasoning benchmarks and multimodal math reasoning benchmarks, achieving an average 2.2\\% and 1.5\\% improvement for Video Reasoning and Math Reasoning tasks over the GRPO baseline.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10104","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.636102","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Minbin Huang, Runhui Huang, Chuanyang Zheng, Jingyao Li, Guoxuan Chen, Han Shi, Hong Cheng","raw_content_length":1803,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["MMVU","Answer-Consistent Chain-of","Answer-Consistent Reinforcement Learning","GRPO"],"persons":["modif"],"locations":[],"monetary":[]},"char_count":1802,"language_detected":"en","key_concepts":{"key_phrases":["Answer-Consistent Chain","LLMs","arXiv251010104v1 Announce Type","new Abstract","Recent advances","large language models","that reinforcement learning","verifiable rewards","RLVR","reasoning abilities"],"filter_categories":{"ai_ml":["Answer-Consistent Chain","large language models","that reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Answer-Consistent Chain":2.0,"LLMs":2.0,"arXiv251010104v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"large language models":1.0,"that reinforcement learning":1.0,"verifiable rewards":1.0,"RLVR":1.0,"reasoning abilities":1.0}},"age_hours":2.748287028888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.36,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.872,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9142,"joy":0.0138,"surprise":0.0327,"sadness":0.0087,"fear":0.0063,"anger":0.0156,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (ACRE) to improve the consistency of reasoning in LLMs, specifically in visual question-answering tasks. While the algorithm shows a 2.2% and 1.5% improvement on Video Reasoning and Math Reasoning tasks, respectively, it is still in the research phase and has no direct, measurable impact on sustainability at this stage, although improved AI could indirectly contribute to sustainability efforts in the future.","key_impact_metrics":["2.2% improvement for Video Reasoning","1.5% improvement for Math Reasoning"],"technology_tags":["Reinforcement Learning","Large Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:08:57.136899Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8b2df2c6b57d","title":"Lighter-X: An Efficient and Plug-and","content":"arXiv:2510.10105v1 Announce Type: new Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in recommendation systems. However, conventional graph-based recommenders, such as LightGCN, require maintaining embeddings of size $d$ for each node, resulting in a parameter complexity of $\\mathcal{O}(n \\times d)$, where $n$ represents the total number of users and items. This scaling pattern poses significant challenges for deployment on large-scale graphs encountered in real-world applications. To address this scalability limitation, we propose \\textbf{Lighter-X}, an efficient and modular framework that can be seamlessly integrated with existing GNN-based recommender architectures. Our approach substantially reduces both parameter size and computational complexity while preserving the theoretical guarantees and empirical performance of the base models, thereby enabling practical deployment at scale. Specifically, we analyze the original structure and inherent redundancy in their parameters, identifying opportunities for optimization. Based on this insight, we propose an efficient compression scheme for the sparse adjacency structure and high-dimensional embedding matrices, achieving a parameter complexity of $\\mathcal{O}(h \\times d)$, where $h \\ll n$. Furthermore, the model is optimized through a decoupled framework, reducing computational complexity during the training process and enhancing scalability. Extensive experiments demonstrate that Lighter-X achieves comparable performance to baseline models with significantly fewer parameters. In particular, on large-scale interaction graphs with millions of edges, we are able to attain even better results with only 1\\% of the parameter over LightGCN.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10105","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.636532","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Yanping Zheng, Zhewei Wei, Frank de Hoog, Xu Chen, Hongteng Xu, Yuhang Ye, Jiadeng Huang","raw_content_length":1748,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["GNN","LightGCN","Graph Neural Networks"],"persons":[],"locations":[],"monetary":[]},"char_count":1747,"language_detected":"en","key_concepts":{"key_phrases":["Lighter-X"," An Efficient","Plug","arXiv251010105v1 Announce Type","new Abstract","Graph Neural Networks","GNNs","remarkable effectiveness","recommendation systems","conventional graph-based recommenders"],"filter_categories":{"ai_ml":["Graph Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Lighter-X":2.0," An Efficient":2.0,"Plug":2.0,"arXiv251010105v1 Announce Type":1.0,"new Abstract":1.0,"Graph Neural Networks":1.0,"GNNs":1.0,"remarkable effectiveness":1.0,"recommendation systems":1.0,"conventional graph-based recommenders":1.0}},"age_hours":2.7483020313888886,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2195,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8439,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8537,"joy":0.0157,"surprise":0.0729,"sadness":0.0091,"fear":0.0208,"anger":0.0179,"disgust":0.0098},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to reduce the parameter size and computational complexity of Graph Neural Networks (GNNs) used in recommendation systems. The concrete action is the proposal of the Lighter-X framework and its demonstrated performance on large-scale interaction graphs. The evidence supporting the claims comes from extensive experiments, showing comparable or better performance with significantly fewer parameters (1% of the parameters of LightGCN). The innovation is at the applied research stage, with no mention of real-world deployment.","key_impact_metrics":["1% of the parameter over LightGCN","Parameter complexity of O(h x d) where h << n"],"technology_tags":["Graph Neural Networks","Recommendation Systems","Model Compression"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:09:00.794975Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e97bb098e2cc","title":"Integrating Structure","content":"arXiv:2510.10109v1 Announce Type: new Abstract: This paper designs and implements an explainable recommendation model that integrates knowledge graphs with structure-aware attention mechanisms. The model is built on graph neural networks and incorporates a multi-hop neighbor aggregation strategy. By integrating the structural information of knowledge graphs and dynamically assigning importance to different neighbors through an attention mechanism, the model enhances its ability to capture implicit preference relationships. In the proposed method, users and items are embedded into a unified graph structure. Multi-level semantic paths are constructed based on entities and relations in the knowledge graph to extract richer contextual information. During the rating prediction phase, recommendations are generated through the interaction between user and target item representations. The model is optimized using a binary cross-entropy loss function. Experiments conducted on the Amazon Books dataset validate the superior performance of the proposed model across various evaluation metrics. The model also shows good convergence and stability. These results further demonstrate the effectiveness and practicality of structure-aware attention mechanisms in knowledge graph-enhanced recommendation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10109","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.637335","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Shuangquan Lyu, Ming Wang, Huajun Zhang, Jiasen Zheng, Junjiang Lin, Xiaoxuan Sun","raw_content_length":1304,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Structure arXiv:2510.10109v1 Announce Type"],"locations":[],"monetary":[]},"char_count":1303,"language_detected":"en","key_concepts":{"key_phrases":["Structure","knowledge graphs","arXiv251010109v1 Announce Type","new Abstract","This paper designs","an explainable recommendation model","structure-aware attention mechanisms","The model","graph neural networks","a multi-hop neighbor aggregation strategy"],"filter_categories":{"ai_ml":["an explainable recommendation model","graph neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Structure":2.0,"knowledge graphs":2.0,"arXiv251010109v1 Announce Type":1.0,"new Abstract":1.0,"This paper designs":1.0,"an explainable recommendation model":1.0,"structure-aware attention mechanisms":1.0,"The model":1.0,"graph neural networks":1.0,"a multi-hop neighbor aggregation strategy":1.0}},"age_hours":2.748329766944444,"is_recent":true,"quality_score":1.0,"sentiment_score":8.715,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.743,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8576,"joy":0.0412,"surprise":0.0603,"sadness":0.0051,"fear":0.0069,"anger":0.0213,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a recommendation model that integrates knowledge graphs. While the model shows superior performance on the Amazon Books dataset, it's still in the applied research stage with no real-world deployment or quantified environmental impact. The model's potential to influence consumer choices towards more sustainable options is theoretical at this point.","key_impact_metrics":["Superior performance across various evaluation metrics","Good convergence and stability"],"technology_tags":["Explainable Recommendation Model","Knowledge Graph","Graph Neural Networks"],"sdg_alignment":[12],"analyzed_at":"2025-10-29T11:09:03.815533Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0d0db8f2579e","title":"ImmerIris: A Large","content":"arXiv:2510.10113v1 Announce Type: new Abstract: In egocentric applications such as augmented and virtual reality, immersive iris recognition is emerging as an accurate and seamless way to identify persons. While classic systems acquire iris images on-axis, i.e., via dedicated frontal sensors in controlled settings, the immersive setup primarily captures off-axis irises through tilt-placed headset cameras, with only mild control in open scenes. This yields unique challenges, including perspective distortion, intensified quality degradations, and intra-class variations in iris texture. Datasets capturing these challenges remain scarce. To fill this gap, this paper introduces ImmerIris, a large-scale dataset collected via VR headsets, containing 499,791 ocular images from 564 subjects. It is, to the best of current knowledge, the largest public dataset and among the first dedicated to off-axis acquisition. Based on ImmerIris, evaluation protocols are constructed to benchmark recognition methods under different challenging factors. Current methods, primarily designed for classic on-axis imagery, perform unsatisfactorily on the immersive setup, mainly due to reliance on fallible normalization. To this end, this paper further proposes a normalization-free paradigm that directly learns from ocular images with minimal adjustment. Despite its simplicity, this approach consistently outperforms normalization-based counterparts, pointing to a promising direction for robust immersive recognition.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10113","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.638184","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":198,"author":"Yuxi Mi, Qiuyang Yuan, Zhizhou Zhong, Xuan Zhao, Jiaogen Zhou, Fubao Zhu, Jihong Guan, Shuigeng Zhou","raw_content_length":1509,"priority":7,"update_frequency":1,"reading_time_minutes":0.99,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["iris images"],"locations":["ImmerIris"],"monetary":[]},"char_count":1508,"language_detected":"en","key_concepts":{"key_phrases":["ImmerIris","new Abstract","egocentric applications","augmented and virtual reality","immersive iris recognition","an accurate and seamless way","persons","classic systems","iris images","axis"],"filter_categories":{"ai_ml":["an accurate and seamless way"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ImmerIris":2.0,"new Abstract":1.0,"egocentric applications":1.0,"augmented and virtual reality":1.0,"immersive iris recognition":1.0,"an accurate and seamless way":1.0,"persons":1.0,"classic systems":1.0,"iris images":1.0,"axis":1.0}},"age_hours":2.748360116111111,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8515,"joy":0.0372,"surprise":0.0931,"sadness":0.0051,"fear":0.0045,"anger":0.0048,"disgust":0.0039},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a large-scale dataset (ImmerIris) for immersive iris recognition. While the dataset itself doesn't directly address climate change, the improved recognition methods could potentially contribute to security systems that indirectly support sustainability efforts. The dataset is a research contribution with potential for future applications, but currently at an early stage of deployment.","key_impact_metrics":["ocular images: 499,791","subjects: 564"],"technology_tags":["iris recognition","virtual reality","augmented reality"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T11:09:07.304632Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a187d46276f3","title":"LinearRAG: Linear Graph Retrieval Augmented Generation on Large","content":"arXiv:2510.10114v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) is widely used to mitigate hallucinations of Large Language Models (LLMs) by leveraging external knowledge. While effective for simple queries, traditional RAG systems struggle with large-scale, unstructured corpora where information is fragmented. Recent advances incorporate knowledge graphs to capture relational structures, enabling more comprehensive retrieval for complex, multi-hop reasoning tasks. However, existing graph-based RAG (GraphRAG) methods rely on unstable and costly relation extraction for graph construction, often producing noisy graphs with incorrect or inconsistent relations that degrade retrieval quality. In this paper, we revisit the pipeline of existing GraphRAG systems and propose LinearRAG (Linear Graph-based Retrieval-Augmented Generation), an efficient framework that enables reliable graph construction and precise passage retrieval. Specifically, LinearRAG constructs a relation-free hierarchical graph, termed Tri-Graph, using only lightweight entity extraction and semantic linking, avoiding unstable relation modeling. This new paradigm of graph construction scales linearly with corpus size and incurs no extra token consumption, providing an economical and reliable indexing of the original passages. For retrieval, LinearRAG adopts a two-stage strategy: (i) relevant entity activation via local semantic bridging, followed by (ii) passage retrieval through global importance aggregation. Extensive experiments on four datasets demonstrate that LinearRAG significantly outperforms baseline models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10114","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.638614","language":"en","tags":["preprints","research","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Luyao Zhuang, Shengyuan Chen, Yilin Xiao, Huachi Zhou, Yujing Zhang, Hao Chen, Qinggang Zhang, Xiao Huang","raw_content_length":1626,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","RAG","RAG (GraphRAG","Retrieval-Augmented Generation (RAG","Linear Graph Retrieval Augmented","Retrieval-Augmented Generation"],"persons":["LinearRAG"],"locations":["GraphRAG"],"monetary":[]},"char_count":1625,"language_detected":"en","key_concepts":{"key_phrases":["LinearRAG","Linear Graph Retrieval Augmented Generation","arXiv251010114v1","new Abstract","Retrieval-Augmented Generation","RAG","hallucinations","Large Language Models","LLMs","external knowledge"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LinearRAG":2.0,"Linear Graph Retrieval Augmented Generation":2.0,"arXiv251010114v1":1.0,"new Abstract":1.0,"Retrieval-Augmented Generation":1.0,"RAG":1.0,"hallucinations":1.0,"Large Language Models":1.0,"LLMs":1.0,"external knowledge":1.0}},"age_hours":2.7483749341666663,"is_recent":true,"quality_score":1.0,"sentiment_score":7.377000000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4754,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7637,"joy":0.0098,"surprise":0.0306,"sadness":0.0103,"fear":0.1466,"anger":0.0229,"disgust":0.016},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (LinearRAG) for improving the efficiency of retrieval-augmented generation in large language models. While the research shows improved performance on datasets, it is still in the basic research stage with no deployed units or real-world data on its impact on energy consumption or other sustainability metrics. The claim of economical indexing is a potential benefit, but needs further validation.","key_impact_metrics":["Scales linearly with corpus size","No extra token consumption"],"technology_tags":["Large Language Models","Retrieval-Augmented Generation","Knowledge Graphs"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:09:10.632422Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3fa38fbb9323","title":"Targeted Sequential Pattern Mining with High Average Utility","content":"arXiv:2510.10115v1 Announce Type: new Abstract: Incorporating utility into targeted pattern mining can address the practical limitations of traditional frequency-based approaches. However, utility-based methods often suffer from generating a large number of long and complicated sequences. To improve pattern relevance and interpretability, average utility provides a more balanced metric by considering both utility and sequence length. Moreover, incorporating user-defined query targets into the mining process enhances usability and interactivity by retaining only patterns containing user-specified goals. To address challenges related to mining efficiency in large-scale, long-sequence datasets, this study introduces average utility into targeted sequential pattern mining. A novel algorithm, TAUSQ-PG, is designed to find targeted high average utility sequential patterns. It incorporates efficient filtering and pruning strategies, tighter upper bound models, as well as novel specialized evaluation metrics and query flags tailored to this task. Extensive comparative experiments on different datasets demonstrate that TAUSQ-PG effectively controls the candidate set size, thereby reducing redundant sequence generation and significantly improving runtime and memory efficiency.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10115","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.639002","language":"en","tags":["computer-science","research","csdb","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Kai Cao, Yucong Duan, Wensheng Gan","raw_content_length":1288,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["Targeted Sequential Pattern Mining"],"persons":[],"locations":[],"monetary":[]},"char_count":1287,"language_detected":"en","key_concepts":{"key_phrases":["Sequential Pattern Mining","High Average Utility","arXiv251010115v1 Announce Type","new Abstract","utility","targeted pattern mining","the practical limitations","traditional frequency-based approaches","utility-based methods","a large number"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sequential Pattern Mining":2.0,"High Average Utility":2.0,"arXiv251010115v1 Announce Type":1.0,"new Abstract":1.0,"utility":1.0,"targeted pattern mining":1.0,"the practical limitations":1.0,"traditional frequency-based approaches":1.0,"utility-based methods":1.0,"a large number":1.0}},"age_hours":2.7483893219444444,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.925,"joy":0.013,"surprise":0.0161,"sadness":0.0221,"fear":0.0034,"anger":0.0085,"disgust":0.012},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (TAUSQ-PG) for targeted high average utility sequential pattern mining. It focuses on improving mining efficiency and reducing redundant sequence generation, which could indirectly contribute to sustainability by optimizing resource usage in data analysis. The algorithm's effectiveness is demonstrated through comparative experiments, but there's no mention of real-world deployment or specific impact metrics related to sustainability.","key_impact_metrics":["Runtime improvement","Memory efficiency"],"technology_tags":["Data Mining","Algorithm Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:09:14.186403Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8553c2e38626","title":"DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision","content":"arXiv:2510.10117v1 Announce Type: new Abstract: Multimodal abductive reasoning--the generation and selection of explanatory hypotheses from partial observations--is a cornerstone of intelligence. Current evaluations of this ability in vision-language models (VLMs) are largely confined to static, single-agent tasks. Inspired by Dixit, we introduce DixitWorld, a comprehensive evaluation suite designed to deconstruct this challenge. DIXITWORLD features two core components: DixitArena, a dynamic, multi-agent environment that evaluates both hypothesis generation (a \"storyteller\" crafting cryptic clues) and hypothesis selection (\"listeners\" choosing the target image from decoys) under imperfect information; and DixitBench, a static QA benchmark that isolates the listener's task for efficient, controlled evaluation. Results from DixitArena reveal distinct, role-dependent behaviors: smaller open-source models often excel as creative storytellers, producing imaginative yet less discriminative clues, whereas larger proprietary models demonstrate superior overall performance, particularly as listeners. Performance on DixitBench strongly correlates with listener results in DixitArena, validating it as a reliable proxy for hypothesis selection. Our findings reveal a key trade-off between generative creativity and discriminative understanding in multimodal abductive reasoning, a central challenge for developing more balanced and capable vision-language agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10117","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.639819","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Yunxiang Mo, Tianshi Zheng, Qing Zong, Jiayu Liu, Baixuan Xu, Yauwai Yim, Chunkit Chan, Jiaxin Bai, Yangqiu Song","raw_content_length":1471,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["DixitBench","Vision arXiv:2510.10117v1","DIXITWORLD","DixitWorld","DixitArena"],"persons":["Dixit"],"locations":["creati"],"monetary":[]},"char_count":1470,"language_detected":"en","key_concepts":{"key_phrases":["DixitWorld","Multimodal Abductive Reasoning","Vision","arXiv251010117v1 Announce Type","new Abstract","Multimodal abductive reasoning","the generation","selection","explanatory hypotheses","partial observations"],"filter_categories":{"ai_ml":["Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DixitWorld":3.0,"Multimodal Abductive Reasoning":2.0,"Vision":2.0,"arXiv251010117v1 Announce Type":1.0,"new Abstract":1.0,"Multimodal abductive reasoning":1.0,"the generation":1.0,"selection":1.0,"explanatory hypotheses":1.0,"partial observations":1.0}},"age_hours":2.7484208727777775,"is_recent":true,"quality_score":1.0,"sentiment_score":9.531,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9062,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8821,"joy":0.0193,"surprise":0.0511,"sadness":0.0045,"fear":0.0216,"anger":0.0157,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new evaluation suite for multimodal abductive reasoning in vision-language models. While the research is innovative, it is at a very early stage and does not directly translate to concrete climate action or measurable environmental outcomes. The paper focuses on improving AI capabilities, not on deploying technology for sustainability.","key_impact_metrics":[],"technology_tags":["Vision-Language Models","Multimodal Abductive Reasoning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:09:17.251373Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1cd51d1fa59b","title":"IntrinTrans: LLM","content":"arXiv:2510.10119v1 Announce Type: new Abstract: The use of intrinsic functions to exploit hardware-specific capabilities is an important approach for optimizing library performance. Many mainstream libraries implement a large number of vectorized algorithms on Arm or x86 SIMD intrinsic functions. With the rapid expansion of the RISC-V hardware-software ecosystem, there is a growing demand for support of the RISC-V Vector (RVV) extension. Translating existing vectorized intrinsic code onto RVV intrinsics is a practical and effective approach. However, current cross-architecture translation largely relies on manual rewriting, which is time-consuming and error-prone. Furthermore, while some rule-based methods can reduce the need for manual intervention, their translation success rate is limited by incomplete rule coverage and syntactic constraints, and the performance suffers from inadequate utilization of RVV-specific features. We present IntrinTrans, a LLM-based multi-agent approach that utilizes compile-and-test feedback to translate intrinsic code across architectures automatically, and further optimizes the generated RVV intrinsics using register-usage information derived from liveness analysis. To evaluate the effectiveness of our approach, we collected 34 vectorized algorithm cases from open-source libraries. Each case includes an Arm Neon intrinsics implementation and a RVV intrinsics implementation contributed by the open-source community, together with correctness and performance tests. Our experiments show that advanced LLMs produce semantically correct RISC-V Vector intrinsics in most cases within a limited number of iterations, and in some cases achieve up to 5.93x the performance of the native implementation from the open-source community.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10119","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.640244","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":235,"author":"Liutong Han, Zhiyuan Tan, Hongbin Zhang, Pengcheng Wang, Chu Kang, Mingjie Xing, Yanjun Wu","raw_content_length":1781,"priority":7,"update_frequency":1,"reading_time_minutes":1.175,"robust_parsing_used":true,"entities":{"organizations":["RVV","LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1780,"language_detected":"en","key_concepts":{"key_phrases":["IntrinTrans","LLM","arXiv251010119v1 Announce Type","new Abstract","The use","intrinsic functions","hardware-specific capabilities","an important approach","library performance","Many mainstream libraries"],"filter_categories":{"ai_ml":["LLM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"IntrinTrans":2.0,"LLM":2.0,"arXiv251010119v1 Announce Type":1.0,"new Abstract":1.0,"The use":1.0,"intrinsic functions":1.0,"hardware-specific capabilities":1.0,"an important approach":1.0,"library performance":1.0,"Many mainstream libraries":1.0}},"age_hours":2.7484361911111113,"is_recent":true,"quality_score":1.0,"sentiment_score":8.825000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.765,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.864,"joy":0.0168,"surprise":0.0252,"sadness":0.0048,"fear":0.0424,"anger":0.0318,"disgust":0.015},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":4,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents an LLM-based approach to translate and optimize code for RISC-V Vector (RVV) extensions, potentially improving energy efficiency in computing. The claim of up to 5.93x performance improvement over native implementations is a concrete metric, but it's based on a limited set of cases and lacks peer review or deployment data, keeping it at the applied research stage.","key_impact_metrics":["5.93x performance improvement","34 vectorized algorithm cases"],"technology_tags":["LLM","RISC-V Vector","code translation","energy efficiency"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:09:20.474460Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_15b700c8d6dc","title":"Multi Class Parkinsons Disease Detection Based on Finger Tapping Using Attention","content":"arXiv:2510.10121v1 Announce Type: new Abstract: Effective clinical management and intervention development depend on accurate evaluation of Parkinsons disease (PD) severity. Many researchers have worked on developing gesture-based PD recognition systems; however, their performance accuracy is not satisfactory. In this study, we propose a multi-class Parkinson Disease detection system based on finger tapping using an attention-enhanced CNN BiLSTM. We collected finger tapping videos and derived temporal, frequency, and amplitude based features from wrist and hand movements. Then, we proposed a hybrid deep learning framework integrating CNN, BiLSTM, and attention mechanisms for multi-class PD severity classification from video-derived motion features. First, the input sequence is reshaped and passed through a Conv1D MaxPooling block to capture local spatial dependencies. The resulting feature maps are fed into a BiLSTM layer to model temporal dynamics. An attention mechanism focuses on the most informative temporal features, producing a context vector that is further processed by a second BiLSTM layer. CNN-derived features and attention-enhanced BiLSTM outputs are concatenated, followed by dense and dropout layers, before the final softmax classifier outputs the predicted PD severity level. The model demonstrated strong performance in distinguishing between the five severity classes, suggesting that integrating spatial temporal representations with attention mechanisms can improve automated PD severity detection, making it a promising non-invasive tool to support clinicians in PD monitoring and progression tracking.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10121","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.640675","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":220,"author":"Abu Saleh Musa Miah, Najmul Hassan, Md Maruf Al Hossain, Yuichi Okuyama, Jungpil Shin","raw_content_length":1641,"priority":7,"update_frequency":1,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["Finger Tapping Using Attention arXiv:2510.10121v1 Announce","MaxPooling","CNN"],"persons":["BiLSTM"],"locations":[],"monetary":[]},"char_count":1640,"language_detected":"en","key_concepts":{"key_phrases":["Multi Class Parkinsons Disease Detection","Finger Tapping Using Attention","arXiv251010121v1 Announce Type","new Abstract","Effective clinical management","intervention development","accurate evaluation","Parkinsons disease PD severity","Many researchers","gesture-based PD recognition systems"],"filter_categories":{"engineering":["intervention development"],"research_academic":["Many researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multi Class Parkinsons Disease Detection":2.0,"Finger Tapping Using Attention":2.0,"arXiv251010121v1 Announce Type":1.0,"new Abstract":1.0,"Effective clinical management":1.0,"intervention development":1.0,"accurate evaluation":1.0,"Parkinsons disease PD severity":1.0,"Many researchers":1.0,"gesture-based PD recognition systems":1.0}},"age_hours":2.748451322222222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.2385,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2477,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7246,"joy":0.0159,"surprise":0.0295,"sadness":0.1394,"fear":0.0441,"anger":0.0248,"disgust":0.0217},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a novel method for detecting Parkinson's disease severity using finger tapping and deep learning. While the technology shows promise, it is still in the early stages of development with no deployed units or customer contracts. The impact on climate change is negligible, but it could improve healthcare access and outcomes.","key_impact_metrics":["Accuracy in distinguishing between five severity classes"],"technology_tags":["Deep Learning","CNN","BiLSTM","Attention Mechanisms","Parkinson's Disease Detection"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T11:09:23.859278Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d4d2d993e883","title":"DeepFusionNet: Autoencoder-Based Low","content":"arXiv:2510.10122v1 Announce Type: new Abstract: Computer vision and image processing applications suffer from dark and low-light images, particularly during real-time image transmission. Currently, low light and dark images are converted to bright and colored forms using autoencoders; however, these methods often achieve low SSIM and PSNR scores and require high computational power due to their large number of parameters. To address these challenges, the DeepFusionNet architecture has been developed. According to the results obtained with the LOL-v1 dataset, DeepFusionNet achieved an SSIM of 92.8% and a PSNR score of 26.30, while containing only approximately 2.5 million parameters. On the other hand, conversion of blurry and low-resolution images into high-resolution and blur-free images has gained importance in image processing applications. Unlike GAN-based super-resolution methods, an autoencoder-based super resolution model has been developed that contains approximately 100 thousand parameters and uses the DeepFusionNet architecture. According to the results of the tests, the DeepFusionNet based super-resolution method achieved a PSNR of 25.30 and a SSIM score of 80.7 percent according to the validation set.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10122","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.641084","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Halil H\\\"useyin \\c{C}al{\\i}\\c{s}kan, Talha Koruk","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["PSNR","GAN","Autoencoder-Based Low arXiv:2510.10122v1 Announce Type: new Abstract","LOL"],"persons":[],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["DeepFusionNet Autoencoder-Based Low","Announce Type","new Abstract","Computer vision","image processing applications","dark and low-light images","real-time image transmission","low light and dark images","bright and colored forms","autoencoders"],"filter_categories":{"ai_ml":["Computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DeepFusionNet Autoencoder-Based Low":2.0,"Announce Type":1.0,"new Abstract":1.0,"Computer vision":1.0,"image processing applications":1.0,"dark and low-light images":1.0,"real-time image transmission":1.0,"low light and dark images":1.0,"bright and colored forms":1.0,"autoencoders":1.0}},"age_hours":2.748466461944444,"is_recent":true,"quality_score":1.0,"sentiment_score":2.4469999999999996,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5106,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6575,"joy":0.0069,"surprise":0.0352,"sadness":0.189,"fear":0.0655,"anger":0.0138,"disgust":0.0321},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new autoencoder architecture (DeepFusionNet) for improving image quality in low-light conditions and for super-resolution. While it reports performance metrics (SSIM and PSNR) on the LOL-v1 dataset, it lacks information on real-world deployment or energy consumption, limiting its demonstrated impact. It is currently in the applied research phase, with potential for energy savings in image processing but without concrete evidence of deployment or scalability.","key_impact_metrics":["SSIM of 92.8%","PSNR score of 26.30"],"technology_tags":["autoencoders","image processing","super-resolution"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:09:27.854650Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fc5e94a25a93","title":"The Hybrid Multimodal Graph Index (HMGI): A Comprehensive Framework for Integrated Relational and Vector Search","content":"arXiv:2510.10123v1 Announce Type: new Abstract: The proliferation of complex, multimodal datasets has exposed a critical gap between the capabilities of specialized vector databases and traditional graph databases. While vector databases excel at semantic similarity search, they lack the capacity for deep relational querying. Conversely, graph databases master complex traversals but are not natively optimized for high-dimensional vector search. This paper introduces the Hybrid Multimodal Graph Index (HMGI), a novel framework designed to bridge this gap by creating a unified system for efficient, hybrid queries on multimodal data. HMGI leverages the native graph database architecture and integrated vector search capabilities, exemplified by platforms like Neo4j, to combine Approximate Nearest Neighbor Search (ANNS) with expressive graph traversal queries. Key innovations of the HMGI framework include modality-aware partitioning of embeddings to optimize index structure and query performance, and a system for adaptive, low-overhead index updates to support dynamic data ingestion, drawing inspiration from the architectural principles of systems like TigerVector. By integrating semantic similarity search directly with relational context, HMGI aims to outperform pure vector databases like Milvus in complex, relationship-heavy query scenarios and achieve sub-linear query times for hybrid tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10123","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.641504","language":"en","tags":["cslg","preprints","research","csdb","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Joydeep Chandra, Satyam Kumar Navneet, Yong Zhang","raw_content_length":1412,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["HMGI","Approximate Nearest Neighbor Search","the Hybrid Multimodal Graph Index"],"persons":["Neo4j","ANNS"],"locations":[],"monetary":[]},"char_count":1411,"language_detected":"en","key_concepts":{"key_phrases":["The Hybrid Multimodal Graph Index","HMGI","A Comprehensive Framework","Integrated Relational","Vector Search","arXiv251010123v1 Announce Type","new Abstract","The proliferation","complex multimodal datasets","a critical gap"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Hybrid Multimodal Graph Index":2.0,"HMGI":2.0,"A Comprehensive Framework":2.0,"Integrated Relational":2.0,"Vector Search":2.0,"arXiv251010123v1 Announce Type":1.0,"new Abstract":1.0,"The proliferation":1.0,"complex multimodal datasets":1.0,"a critical gap":1.0}},"age_hours":2.748481687777778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0645,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0129,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8164,"joy":0.0179,"surprise":0.1122,"sadness":0.0117,"fear":0.0135,"anger":0.0201,"disgust":0.0082},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (HMGI) for hybrid queries on multimodal data, integrating vector and graph databases. While promising, it's currently at the applied research stage, with no deployed units or customer contracts mentioned. The potential climate impact is indirect, as it could improve the efficiency of data analysis for sustainability-related applications, but this is theoretical at this point.","key_impact_metrics":[],"technology_tags":["graph databases","vector databases","data indexing","approximate nearest neighbor search"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:09:30.909800Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_43351b862bc0","title":"Ctrl","content":"arXiv:2510.10125v1 Announce Type: new Abstract: Generalist robot policies can now perform a wide range of manipulation skills, but evaluating and improving their ability with unfamiliar objects and instructions remains a significant challenge. Rigorous evaluation requires a large number of real-world rollouts, while systematic improvement demands additional corrective data with expert labels. Both of these processes are slow, costly, and difficult to scale. World models offer a promising, scalable alternative by enabling policies to rollout within imagination space. However, a key challenge is building a controllable world model that can handle multi-step interactions with generalist robot policies. This requires a world model compatible with modern generalist policies by supporting multi-view prediction, fine-grained action control, and consistent long-horizon interactions, which is not achieved by previous works. In this paper, we make a step forward by introducing a controllable multi-view world model that can be used to evaluate and improve the instruction-following ability of generalist robot policies. Our model maintains long-horizon consistency with a pose-conditioned memory retrieval mechanism and achieves precise action control through frame-level action conditioning. Trained on the DROID dataset (95k trajectories, 564 scenes), our model generates spatially and temporally consistent trajectories under novel scenarios and new camera placements for over 20 seconds. We show that our method can accurately rank policy performance without real-world robot rollouts. Moreover, by synthesizing successful trajectories in imagination and using them for supervised fine-tuning, our approach can improve policy success by 44.7\\%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10125","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.642093","language":"en","tags":["computer-science","csai","preprints","research","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Yanjiang Guo, Lucy Xiaoyang Shi, Jianyu Chen, Chelsea Finn","raw_content_length":1754,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Generalist"],"locations":[],"monetary":[]},"char_count":1753,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251010125v1 Announce Type","new Abstract","Generalist robot policies","a wide range","manipulation skills","their ability","unfamiliar objects","instructions","a significant challenge","Rigorous evaluation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251010125v1 Announce Type":1.0,"new Abstract":1.0,"Generalist robot policies":1.0,"a wide range":1.0,"manipulation skills":1.0,"their ability":1.0,"unfamiliar objects":1.0,"instructions":1.0,"a significant challenge":1.0,"Rigorous evaluation":1.0}},"age_hours":2.7484959427777778,"is_recent":true,"quality_score":0.7,"sentiment_score":9.403500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8807,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9185,"joy":0.004,"surprise":0.0154,"sadness":0.0212,"fear":0.0157,"anger":0.0125,"disgust":0.0128},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a controllable multi-view world model to evaluate and improve generalist robot policies. The model was trained on the DROID dataset (95k trajectories, 564 scenes) and showed a 44.7% improvement in policy success through supervised fine-tuning. While promising, this is still in the applied research stage with no real-world deployment yet.","key_impact_metrics":["44.7% improvement in policy success"],"technology_tags":["robotics","world model","machine learning","generalist robot policies"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:09:33.964301Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_79ed50181b4b","title":"Breaking the Likelihood Trap: Consistent Generative Recommendation with Graph","content":"arXiv:2510.10127v1 Announce Type: new Abstract: Reranking, as the final stage of recommender systems, demands real-time inference, accuracy, and diversity. It plays a crucial role in determining the final exposure, directly influencing user experience. Recently, generative reranking has gained increasing attention for its strong ability to model complex dependencies among items. However, most existing methods suffer from the \"likelihood trap\", where high-likelihood sequences are often perceived as low-quality by humans. These models tend to repeatedly recommend a set of high-frequency items, resulting in list homogeneity, thereby limiting user engagement. In this work, we propose Consistent Graph-structured Generative Recommendation (Congrats), a novel generative reranking framework. To break the likelihood trap, we introduce a novel graph-structured decoder that can capture diverse sequences along multiple paths. This design not only expands the decoding space to promote diversity, but also improves prediction accuracy by implicit item dependencies derived from vertex transitions. Furthermore, we design a differentiable cascade system that incorporates an evaluator, enabling the model to learn directly from user preferences as the training objective. Extensive offline experiments validate the superior performance of Congrats over state-of-the-art reranking methods. Moreover, Congrats has been evaluated on a large-scale video-sharing app, Kuaishou, with over 300 million daily active users, demonstrating that our approach significantly improves both recommendation quality and diversity, validating our effectiveness in practical industrial environments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10127","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.642935","language":"en","tags":["csir","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"Qiya Yang, Xiaoxi Liang, Zeping Xiao, Yingjie Deng, Yalong Wang, Yongqi Liu, Han Li","raw_content_length":1680,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["the Likelihood Trap: Consistent Generative Recommendation"],"persons":["Generative Recommendation","Consistent Graph-structured"],"locations":[],"monetary":[]},"char_count":1679,"language_detected":"en","key_concepts":{"key_phrases":["the Likelihood Trap","Consistent Generative Recommendation","Graph","arXiv251010127v1 Announce Type","new Abstract","Reranking","the final stage","recommender systems","real-time inference","accuracy"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Likelihood Trap":2.0,"Consistent Generative Recommendation":2.0,"Graph":2.0,"arXiv251010127v1 Announce Type":1.0,"new Abstract":1.0,"Reranking":1.0,"the final stage":1.0,"recommender systems":1.0,"real-time inference":1.0,"accuracy":1.0}},"age_hours":2.7485267308333334,"is_recent":true,"quality_score":1.0,"sentiment_score":7.415000000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.483,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8886,"joy":0.0046,"surprise":0.0278,"sadness":0.0197,"fear":0.0223,"anger":0.0141,"disgust":0.0229},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed recommendation system (Congrats) within Kuaishou, a large-scale video-sharing app with over 300 million daily active users. The system aims to improve recommendation quality and diversity, validated through offline experiments and practical industrial environments. While it doesn't directly address climate change, improved recommendation systems can potentially reduce energy consumption by optimizing content delivery and user engagement.","key_impact_metrics":["300 million daily active users","Improved recommendation quality and diversity"],"technology_tags":["Recommendation Systems","Graph Neural Networks"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:09:36.968778Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5a3b2da8aa74","title":"CacheClip: Accelerating RAG with Effective KV Cache Reuse","content":"arXiv:2510.10129v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) systems suffer from severe time-to-first-token (TTFT) bottlenecks due to long input sequences. Existing KV cache reuse methods face a fundamental trade-off: prefix caching requires identical prefixes that rarely occur in RAG scenarios, while direct precomputation sacrifices quality due to missing inter-chunk attention and repeated attention sinks. Recent methods like APE and CacheBlend partially address these issues but remain inadequate for robust RAG applications. This paper presents CacheClip, a novel framework that achieves both fast TTFT and high generation quality. Our key insight is that small auxiliary LLMs exhibit similar last-layer attention distributions to primary LLMs (the target model for generation), enabling efficient identification of tokens critical for restoring inter-chunk attention, thereby significantly improving response quality on cross-chunk reasoning tasks. CacheClip integrates three techniques: (1) auxiliary-model-guided token selection for selective KV cache recomputation, where the auxiliary model is finetuned to improve selection accuracy, (2) shared prefixes to eliminate redundant attention sinks, and (3) grouping strategy to maintain local coherence during partial KV cache updates. Experiments show CacheClip retains up to 94.8% and 85.0% of full-attention performance on NIAH and LongBench, outperforming APE and CacheBlend by 25.2% and 35.1% on NIAH (with reomp% = 20%). Meanwhile, CacheClip accelerates LLM inference by up to 1.92x in prefill time, providing a practical solution to the efficiency-quality trade-off in RAG systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10129","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.643358","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Bin Yang, Qiuyu Leng, Jun Zeng, Zhenhua Wu","raw_content_length":1671,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["RAG","APE","CacheClip","CacheBlend","Retrieval-Augmented Generation"],"persons":["RAG"],"locations":[],"monetary":[]},"char_count":1670,"language_detected":"en","key_concepts":{"key_phrases":["CacheClip","RAG","Effective KV Cache Reuse","Announce Type","new Abstract Retrieval-Augmented Generation RAG systems","severe time-to-first-token TTFT","bottlenecks","long input sequences","Existing KV cache reuse methods","a fundamental trade-off"],"filter_categories":{"hydrogen_energy":["RAG"],"renewable_energy":["RAG"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CacheClip":2.0,"RAG":2.0,"Effective KV Cache Reuse":2.0,"Announce Type":1.0,"new Abstract Retrieval-Augmented Generation RAG systems":1.0,"severe time-to-first-token TTFT":1.0,"bottlenecks":1.0,"long input sequences":1.0,"Existing KV cache reuse methods":1.0,"a fundamental trade-off":1.0}},"age_hours":2.7485425005555553,"is_recent":true,"quality_score":1.0,"sentiment_score":1.8155,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6369,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6227,"joy":0.0048,"surprise":0.0366,"sadness":0.1759,"fear":0.0899,"anger":0.0315,"disgust":0.0386},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"CacheClip improves RAG system efficiency by accelerating LLM inference, potentially reducing energy consumption in large language models. The paper presents performance metrics on NIAH and LongBench, demonstrating improvements over existing methods. However, it is still in the research phase with no deployed units or real-world operational data, thus vaporware risk is flagged.","key_impact_metrics":["1.92x acceleration in prefill time","25.2% improvement on NIAH over APE"],"technology_tags":["Retrieval-Augmented Generation","KV Cache Reuse","Large Language Models"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:09:39.969426Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_253fb935eb10","title":"Proof Strategy Extraction from LLMs for Enhancing Symbolic Provers","content":"arXiv:2510.10131v1 Announce Type: new Abstract: One important approach to software verification is interactive theorem proving. However, writing formal proofs often requires substantial human effort, making proof automation highly important. Traditionally, proof automation has relied on symbolic provers. Recently, large language models (LLMs) have demonstrated strong capabilities in theorem proving, complementing symbolic provers. Nonetheless, prompting LLMs can be expensive and may pose security risks for confidential codebases. As a result, purely symbolic approaches remain important even in the LLM era, as they are cost-effective, secure, and complement the strengths of LLMs. Motivated by these considerations, we ask a new research question: can we extract the internal strategies of LLMs to enhance the capabilities of symbolic provers? As an initial attempt to answer this question, we propose Strat2Rocq, which extracts proof strategies from LLMs and formalizes them as lemmas in Rocq. These lemmas are accessible to symbolic provers such as CoqHammer. With the addition of these LLM-extracted lemmas, CoqHammer is able to prove more theorems. The knowledge extraction process involves analyzing the proof trajectories of LLMs on a training set of proved theorems. For each theorem, we prompt the LLM to generate a natural language proof, then ask it to summarize this proof into formalized lemmas with proofs. We also employ a standard agentic approach to mitigate errors during formalization. Our evaluation demonstrates that, on open-source Rocq projects for software verification, Strat2Rocq enhances the success rate of CoqHammer by 13.41%.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10131","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.643810","language":"en","tags":["preprints","research","computer-science","cslo","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":238,"author":"Jian Fang, Yican Sun, Yingfei Xiong","raw_content_length":1664,"priority":7,"update_frequency":1,"reading_time_minutes":1.19,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1661,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Proof Strategy Extraction","Enhancing Symbolic Provers","proof automation","symbolic provers","arXiv251010131v1 Announce Type","new Abstract","One important approach","software verification","interactive theorem proving"],"filter_categories":{"ai_ml":["LLMs"],"engineering":["proof automation"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":4.0,"Proof Strategy Extraction":2.0,"Enhancing Symbolic Provers":2.0,"proof automation":2.0,"symbolic provers":2.0,"arXiv251010131v1 Announce Type":1.0,"new Abstract":1.0,"One important approach":1.0,"software verification":1.0,"interactive theorem proving":1.0}},"age_hours":2.74855711,"is_recent":true,"quality_score":1.0,"sentiment_score":8.951,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7902,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8947,"joy":0.0368,"surprise":0.0411,"sadness":0.0041,"fear":0.0064,"anger":0.0113,"disgust":0.0056},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores using LLMs to enhance symbolic provers, leading to more efficient software verification. The concrete action is the extraction of proof strategies from LLMs and their formalization as lemmas. The evidence is a 13.41% enhancement in the success rate of CoqHammer on open-source Rocq projects, but this is still in a research phase with no deployed units.","key_impact_metrics":["CoqHammer success rate enhancement 13.41%"],"technology_tags":["Large Language Models","Symbolic Provers","Software Verification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:09:43.020254Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d95a149f49c2","title":"PermLLM: Learnable Channel Permutation for N:M Sparse Large Language Models","content":"arXiv:2510.10136v1 Announce Type: new Abstract: Channel permutation is a powerful technique for enhancing the accuracy of N:M sparse models by reordering the channels of weight matrices to prioritize the retention of important weights. However, traditional channel permutation methods rely on handcrafted quality metrics, which often fail to accurately capture the true impact of pruning on model performance. To address this limitation, we propose PermLLM, a novel post-training pruning framework that introduces learnable channel permutation (LCP) for N:M sparsity. LCP leverages Sinkhorn normalization to transform discrete permutation matrices into differentiable soft permutation matrices, enabling end-to-end optimization. Additionally, PermLLM incorporates an efficient block-wise channel permutation strategy, which significantly reduces the number of learnable parameters and computational complexity. PermLLM seamlessly integrates with existing one-shot pruning methods to adaptively optimize channel permutations, effectively mitigating pruning-induced errors. Extensive experiments on the LLaMA series, Qwen, and OPT models demonstrate that PermLLM achieves superior performance in optimizing N:M sparse models. The code is available at https://github.com/lanchengzou/PermLLM.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10136","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.644600","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Lancheng Zou, Shuo Yin, Zehua Pei, Tsung-Yi Ho, Farzan Farnia, Bei Yu","raw_content_length":1289,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["LCP"],"persons":[],"locations":["Sinkhorn"],"monetary":[]},"char_count":1288,"language_detected":"en","key_concepts":{"key_phrases":["PermLLM Learnable Channel Permutation","M Sparse","Large Language Models","arXiv251010136v1 Announce Type","new Abstract","Channel permutation","a powerful technique","the accuracy","the channels","weight matrices"],"filter_categories":{"ai_ml":["PermLLM Learnable Channel Permutation","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"PermLLM Learnable Channel Permutation":2.0,"M Sparse":2.0,"Large Language Models":2.0,"arXiv251010136v1 Announce Type":1.0,"new Abstract":1.0,"Channel permutation":1.0,"a powerful technique":1.0,"the accuracy":1.0,"the channels":1.0,"weight matrices":1.0}},"age_hours":2.7485862997222226,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9122,"joy":0.0045,"surprise":0.0286,"sadness":0.0168,"fear":0.0101,"anger":0.018,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (PermLLM) for improving the efficiency of large language models through learnable channel permutation, which could lead to reduced energy consumption during training and inference. The framework is tested on LLaMA, Qwen, and OPT models, demonstrating performance improvements. However, it is still in the research phase, with no deployed units or real-world operational data available yet.","key_impact_metrics":["Superior performance in optimizing N:M sparse models"],"technology_tags":["Large Language Models","Model Compression","Sparse Models","Channel Permutation"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-29T11:09:46.239610Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e0073264f126","title":"Hybrid OCR-LLM Framework for Enterprise","content":"arXiv:2510.10138v1 Announce Type: new Abstract: Information extraction from copy-heavy documents, characterized by massive volumes of structurally similar content, represents a critical yet understudied challenge in enterprise document processing. We present a systematic framework that strategically combines OCR engines with Large Language Models (LLMs) to optimize the accuracy-efficiency trade-off inherent in repetitive document extraction tasks. Unlike existing approaches that pursue universal solutions, our method exploits document-specific characteristics through intelligent strategy selection. We implement and evaluate 25 configurations across three extraction paradigms (direct, replacement, and table-based) on identity documents spanning four formats (PNG, DOCX, XLSX, PDF). Through table-based extraction methods, our adaptive framework delivers outstanding results: F1=1.0 accuracy with 0.97s latency for structured documents, and F1=0.997 accuracy with 0.6 s for challenging image inputs when integrated with PaddleOCR, all while maintaining sub-second processing speeds. The 54 times performance improvement compared with multimodal methods over naive approaches, coupled with format-aware routing, enables processing of heterogeneous document streams at production scale. Beyond the specific application to identity extraction, this work establishes a general principle: the repetitive nature of copy-heavy tasks can be transformed from a computational burden into an optimization opportunity through structure-aware method selection.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10138","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.645015","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Zilong Wang, Xiaoyu Shen","raw_content_length":1556,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["F1=1.0","Large Language Models","PNG","PDF","OCR"],"persons":[],"locations":["XLSX"],"monetary":[]},"char_count":1555,"language_detected":"en","key_concepts":{"key_phrases":["Hybrid OCR-LLM Framework","Enterprise","arXiv251010138v1 Announce Type","new Abstract","Information extraction","copy-heavy documents","massive volumes","structurally similar content","a critical yet understudied challenge","enterprise document processing"],"filter_categories":{"ai_ml":["Hybrid OCR-LLM Framework"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Hybrid OCR-LLM Framework":2.0,"Enterprise":2.0,"arXiv251010138v1 Announce Type":1.0,"new Abstract":1.0,"Information extraction":1.0,"copy-heavy documents":1.0,"massive volumes":1.0,"structurally similar content":1.0,"a critical yet understudied challenge":1.0,"enterprise document processing":1.0}},"age_hours":2.7486006219444445,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8901,"joy":0.0145,"surprise":0.0672,"sadness":0.0053,"fear":0.0065,"anger":0.0125,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a framework for optimizing document extraction using OCR and LLMs. While it demonstrates improved efficiency (54x performance improvement) and accuracy (F1=1.0, F1=0.997), it's in the early stages of development and lacks real-world deployment data. The sustainability impact is indirect, potentially reducing energy consumption associated with document processing, but this is not explicitly quantified.","key_impact_metrics":["54 times performance improvement","F1=1.0 accuracy"],"technology_tags":["OCR","Large Language Models","Information Extraction"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:09:49.690832Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a1d0eccef007","title":"Adversarial Attacks on Downstream Weather Forecasting Models: Application to Tropical Cyclone Trajectory Prediction","content":"arXiv:2510.10140v1 Announce Type: new Abstract: Deep learning based weather forecasting (DLWF) models leverage past weather observations to generate future forecasts, supporting a wide range of downstream tasks, including tropical cyclone (TC) trajectory prediction. In this paper, we investigate their vulnerability to adversarial attacks, where subtle perturbations to the upstream weather forecasts can alter the downstream TC trajectory predictions. Although research on adversarial attacks in DLWF models has grown recently, generating perturbed upstream forecasts that reliably steer downstream output toward attacker-specified trajectories remains a challenge. First, conventional TC detection systems are opaque, non-differentiable black boxes, making standard gradient-based attacks infeasible. Second, the extreme rarity of TC events leads to severe class imbalance problem, making it difficult to develop efficient attack methods that will produce the attacker's target trajectories. Furthermore, maintaining physical consistency in adversarially generated forecasts presents another significant challenge. To overcome these limitations, we propose Cyc-Attack, a novel method that perturbs the upstream forecasts of DLWF models to generate adversarial trajectories. First, we pre-train a differentiable surrogate model to approximate the TC detector's output, enabling the construction of gradient-based attacks. Cyc-Attack also employs skewness-aware loss function with kernel dilation strategy to address the imbalance problem. Finally, a distance-based gradient weighting scheme and regularization are used to constrain the perturbations and eliminate spurious trajectories to ensure the adversarial forecasts are realistic and not easily detectable.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10140","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.645436","language":"en","tags":["statml","computer-science","cslg","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":224,"author":"Yue Deng, Francisco Santos, Pang-Ning Tan, Lifeng Luo","raw_content_length":1765,"priority":7,"update_frequency":1,"reading_time_minutes":1.12,"robust_parsing_used":true,"entities":{"organizations":["DLWF","Adversarial Attacks on Downstream Weather Forecasting Models: Application"],"persons":[],"locations":[],"monetary":[]},"char_count":1764,"language_detected":"en","key_concepts":{"key_phrases":["Adversarial Attacks","Downstream Weather Forecasting Models","Application","Tropical Cyclone Trajectory Prediction","adversarial attacks","Announce Type","new Abstract","weather observations","future forecasts","a wide range"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adversarial Attacks":2.0,"Downstream Weather Forecasting Models":2.0,"Application":2.0,"Tropical Cyclone Trajectory Prediction":2.0,"adversarial attacks":2.0,"Announce Type":1.0,"new Abstract":1.0,"weather observations":1.0,"future forecasts":1.0,"a wide range":1.0}},"age_hours":2.74861486,"is_recent":true,"quality_score":1.0,"sentiment_score":0.842,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8316,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7411,"joy":0.0066,"surprise":0.0207,"sadness":0.0143,"fear":0.1615,"anger":0.0382,"disgust":0.0177},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on the vulnerability of deep learning weather forecasting models to adversarial attacks, specifically in the context of tropical cyclone trajectory prediction. While it proposes a novel method (Cyc-Attack) to address limitations in generating realistic adversarial forecasts, it remains in the applied research stage with no deployed units or real-world data demonstrating climate impact. The economic viability is unclear as there are no cost metrics or deployment commitments.","key_impact_metrics":[],"technology_tags":["deep learning","weather forecasting","adversarial attacks","tropical cyclone trajectory prediction"],"sdg_alignment":[13],"analyzed_at":"2025-10-29T11:09:52.699778Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_de3e36a42b10","title":"YOLOv11","content":"arXiv:2510.10141v1 Announce Type: new Abstract: Litchi is a high-value fruit, yet traditional manual selection methods are increasingly inadequate for modern production demands. Integrating UAV-based aerial imagery with deep learning offers a promising solution to enhance efficiency and reduce costs. This paper introduces YOLOv11-Litchi, a lightweight and robust detection model specifically designed for UAV-based litchi detection. Built upon the YOLOv11 framework, the proposed model addresses key challenges such as small target size, large model parameters hindering deployment, and frequent target occlusion. To tackle these issues, three major innovations are incorporated: a multi-scale residual module to improve contextual feature extraction across scales, a lightweight feature fusion method to reduce model size and computational costs while maintaining high accuracy, and a litchi occlusion detection head to mitigate occlusion effects by emphasizing target regions and suppressing background interference. Experimental results validate the model's effectiveness. YOLOv11-Litchi achieves a parameter size of 6.35 MB - 32.5% smaller than the YOLOv11 baseline - while improving mAP by 2.5% to 90.1% and F1-Score by 1.4% to 85.5%. Additionally, the model achieves a frame rate of 57.2 FPS, meeting real-time detection requirements. These findings demonstrate the suitability of YOLOv11-Litchi for UAV-based litchi detection in complex orchard environments, showcasing its potential for broader applications in precision agriculture.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10141","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.645869","language":"en","tags":["eessiv","cslg","preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":207,"author":"Hongxing Peng, Haopei Xie, Weijia Lia, Huanai Liuc, Ximing Li","raw_content_length":1544,"priority":7,"update_frequency":1,"reading_time_minutes":1.035,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["YOLOv11-Litchi"],"locations":[],"monetary":[]},"char_count":1543,"language_detected":"en","key_concepts":{"key_phrases":["arXiv251010141v1 Announce Type","new Abstract","Litchi","a high-value fruit","traditional manual selection methods","modern production demands","UAV-based aerial imagery","deep learning","a promising solution","efficiency"],"filter_categories":{"ai_ml":["deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv251010141v1 Announce Type":1.0,"new Abstract":1.0,"Litchi":1.0,"a high-value fruit":1.0,"traditional manual selection methods":1.0,"modern production demands":1.0,"UAV-based aerial imagery":1.0,"deep learning":1.0,"a promising solution":1.0,"efficiency":1.0}},"age_hours":2.748629205,"is_recent":true,"quality_score":1.0,"sentiment_score":8.6755,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7351,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8929,"joy":0.0336,"surprise":0.0315,"sadness":0.0109,"fear":0.0099,"anger":0.0118,"disgust":0.0094},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":6,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel deep learning model (YOLOv11-Litchi) for UAV-based litchi detection, which can improve efficiency and reduce costs in agriculture. The model has been validated with experimental results, showing a 32.5% reduction in parameter size and a 2.5% improvement in mAP. However, it is still in the applied research stage, with no mention of commercial deployment or real-world operational data beyond the experimental validation.","key_impact_metrics":["32.5% smaller parameter size","2.5% improvement in mAP"],"technology_tags":["deep learning","UAV","precision agriculture"],"sdg_alignment":[2],"analyzed_at":"2025-10-29T11:09:55.926980Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_323cc67afc5a","title":"DiffHeads: Differential Analysis and Inference","content":"arXiv:2510.10142v1 Announce Type: new Abstract: Large language models (LLMs) increasingly mediate decisions in domains where unfair treatment of demographic groups is unacceptable. Existing work probes when biased outputs appear, but gives little insight into the mechanisms that generate them, leaving existing mitigations largely fragile. In this paper, we conduct a systematic investigation LLM unfairness and propose DiffHeads, a lightweight debiasing framework for LLMs. We first compare Direct-Answer (DA) prompting to Chain-of-Thought (CoT) prompting across eight representative open- and closed-source LLMs. DA will trigger the nature bias part of LLM and improve measured unfairness by 534.5%-391.9% in both one-turn and two-turn dialogues. Next, we define a token-to-head contribution score that traces each token's influence back to individual attention heads. This reveals a small cluster of bias heads that activate under DA but stay largely dormant with CoT, providing the first causal link between prompting strategy and bias emergence. Finally, building on this insight, we propose DiffHeads that identifies bias heads through differential activation analysis between DA and CoT, and selectively masks only those heads. DiffHeads reduces unfairness by 49.4%, and 40.3% under DA and CoT, respectively, without harming model utility.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10142","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.646269","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Tingxu Han, Wei Song, Ziqi Ding, Ziming Li, Chunrong Fang, Yuekang Li, Dongfang Liu, Zhenyu Chen, Zhenting Wang","raw_content_length":1348,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["Direct-Answer","Inference arXiv:2510.10142v1","Differential Analysis","LLM","DiffHeads","CoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1347,"language_detected":"en","key_concepts":{"key_phrases":["DiffHeads","Differential Analysis","Inference","LLMs","arXiv251010142v1 Announce Type","new Abstract","Large language models","decisions","domains","unfair treatment"],"filter_categories":{"ai_ml":["LLMs","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"DiffHeads":3.0,"Differential Analysis":2.0,"Inference":2.0,"LLMs":2.0,"arXiv251010142v1 Announce Type":1.0,"new Abstract":1.0,"Large language models":1.0,"decisions":1.0,"domains":1.0,"unfair treatment":1.0}},"age_hours":2.7486444816666666,"is_recent":true,"quality_score":1.0,"sentiment_score":2.213,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5574,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.1566,"joy":0.0023,"surprise":0.0081,"sadness":0.0241,"fear":0.0112,"anger":0.5812,"disgust":0.2165},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":7,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (DiffHeads) for debiasing LLMs, showing a reduction in unfairness by 49.4% and 40.3% under DA and CoT prompting, respectively. The research identifies specific attention heads responsible for bias, providing a causal link and enabling targeted mitigation. While promising, it is currently in the research phase with no deployed applications.","key_impact_metrics":["unfairness reduction 49.4%","unfairness reduction 40.3%"],"technology_tags":["Large Language Models","Debiasing","Artificial Intelligence"],"sdg_alignment":[5,10,16],"analyzed_at":"2025-10-29T11:09:59.427493Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_97118d249fd3","title":"A Unified Frequency Domain Decomposition Framework for Interpretable and Robust Time Series Forecasting","content":"arXiv:2510.10145v1 Announce Type: new Abstract: Current approaches for time series forecasting, whether in the time or frequency domain, predominantly use deep learning models based on linear layers or transformers. They often encode time series data in a black-box manner and rely on trial-and-error optimization solely based on forecasting performance, leading to limited interpretability and theoretical understanding. Furthermore, the dynamics in data distribution over time and frequency domains pose a critical challenge to accurate forecasting. We propose FIRE, a unified frequency domain decomposition framework that provides a mathematical abstraction for diverse types of time series, so as to achieve interpretable and robust time series forecasting. FIRE introduces several key innovations: (i) independent modeling of amplitude and phase components, (ii) adaptive learning of weights of frequency basis components, (iii) a targeted loss function, and (iv) a novel training paradigm for sparse data. Extensive experiments demonstrate that FIRE consistently outperforms state-of-the-art models on long-term forecasting benchmarks, achieving superior predictive performance and significantly enhancing interpretability of time series","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10145","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.646682","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Cheng He, Xijie Liang, Zengrong Zheng, Patrick P. C. Lee, Xu Huang, Zhaoyi Li, Hong Xie, Defu Lian, Enhong Chen","raw_content_length":1244,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["linear","FIRE"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1243,"language_detected":"en","key_concepts":{"key_phrases":["A Unified Frequency Domain Decomposition Framework","Interpretable and Robust Time Series Forecasting","Announce Type","new Abstract","Current approaches","time series forecasting","the time or frequency domain","deep learning models","linear layers","transformers"],"filter_categories":{"ai_ml":["A Unified Frequency Domain Decomposition Framework","deep learning models","transformers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Unified Frequency Domain Decomposition Framework":2.0,"Interpretable and Robust Time Series Forecasting":2.0,"Announce Type":1.0,"new Abstract":1.0,"Current approaches":1.0,"time series forecasting":1.0,"the time or frequency domain":1.0,"deep learning models":1.0,"linear layers":1.0,"transformers":1.0}},"age_hours":2.7486589958333334,"is_recent":true,"quality_score":1.0,"sentiment_score":8.453999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6908,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7571,"joy":0.0074,"surprise":0.0243,"sadness":0.0087,"fear":0.1296,"anger":0.0501,"disgust":0.0229},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new time series forecasting framework. While improved forecasting could indirectly support sustainability efforts (e.g., optimizing energy grids), there are no concrete actions or measurable outcomes related to climate impact at this stage. It's currently at the basic research level, with no deployed units or operational data.","key_impact_metrics":[],"technology_tags":["time series forecasting","frequency domain decomposition","machine learning"],"sdg_alignment":[7,9],"analyzed_at":"2025-10-29T11:10:02.209405Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_35c7ec4dc6ae","title":"A Systematic Study on Generating Web Vulnerability Proof","content":"arXiv:2510.10148v1 Announce Type: new Abstract: Recent advances in Large Language Models (LLMs) have brought remarkable progress in code understanding and reasoning, creating new opportunities and raising new concerns for software security. Among many downstream tasks, generating Proof-of-Concept (PoC) exploits plays a central role in vulnerability reproduction, comprehension, and mitigation. While previous research has focused primarily on zero-day exploitation, the growing availability of rich public information accompanying disclosed CVEs leads to a natural question: can LLMs effectively use this information to automatically generate valid PoCs? In this paper, we present the first empirical study of LLM-based PoC generation for web application vulnerabilities, focusing on the practical feasibility of leveraging publicly disclosed information. We evaluate GPT-4o and DeepSeek-R1 on 100 real-world and reproducible CVEs across three stages of vulnerability disclosure: (1) newly disclosed vulnerabilities with only descriptions, (2) 1-day vulnerabilities with patches, and (3) N-day vulnerabilities with full contextual code. Our results show that LLMs can automatically generate working PoCs in 8%-34% of cases using only public data, with DeepSeek-R1 consistently outperforming GPT-4o. Further analysis shows that supplementing code context improves success rates by 17%-20%, with function-level providing 9%-13% improvement than file-level ones. Further integrating adaptive reasoning strategies to prompt refinement significantly improves success rates to 68%-72%. Our findings suggest that LLMs could reshape vulnerability exploitation dynamics. To date, 23 newly generated PoCs have been accepted by NVD and Exploit DB.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10148","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.647102","language":"en","tags":["preprints","research","computer-science","csse","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Mengyao Zhao, Kaixuan Li, Lyuye Zhang, Wenjing Dang, Chenggong Ding, Sen Chen, Zheli Liu","raw_content_length":1739,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","LLM","PoC","DeepSeek-R1"],"persons":["Proof"],"locations":[],"monetary":[]},"char_count":1738,"language_detected":"en","key_concepts":{"key_phrases":["A Systematic Study","Generating Web Vulnerability Proof","arXiv251010148v1","Announce Type","new Abstract","Recent advances","Large Language Models","LLMs","remarkable progress","code understanding"],"filter_categories":{"research_academic":["A Systematic Study"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Systematic Study":2.0,"Generating Web Vulnerability Proof":2.0,"arXiv251010148v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable progress":1.0,"code understanding":1.0}},"age_hours":2.7486740638888887,"is_recent":true,"quality_score":1.0,"sentiment_score":9.5005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9001,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.579,"joy":0.0197,"surprise":0.0265,"sadness":0.0077,"fear":0.3051,"anger":0.0418,"disgust":0.0202},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores using LLMs to generate Proof-of-Concept exploits for web vulnerabilities. While it doesn't directly address climate change, it could indirectly improve the security of systems that support sustainability efforts. The study is in the applied research phase, with some PoCs generated and accepted by NVD and Exploit DB.","key_impact_metrics":["PoCs generated with 8-72% success rate","23 PoCs accepted by NVD and Exploit DB"],"technology_tags":["Large Language Models","Web Vulnerability","Proof-of-Concept Exploits"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T11:10:05.743365Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5c7320bf2647","title":"Robust Learning of Diffusion Models with Extremely Noisy Conditions","content":"arXiv:2510.10149v1 Announce Type: new Abstract: Conditional diffusion models have the generative controllability by incorporating external conditions. However, their performance significantly degrades with noisy conditions, such as corrupted labels in the image generation or unreliable observations or states in the control policy generation. This paper introduces a robust learning framework to address extremely noisy conditions in conditional diffusion models. We empirically demonstrate that existing noise-robust methods fail when the noise level is high. To overcome this, we propose learning pseudo conditions as surrogates for clean conditions and refining pseudo ones progressively via the technique of temporal ensembling. Additionally, we develop a Reverse-time Diffusion Condition (RDC) technique, which diffuses pseudo conditions to reinforce the memorization effect and further facilitate the refinement of the pseudo conditions. Experimentally, our approach achieves state-of-the-art performance across a range of noise levels on both class-conditional image generation and visuomotor policy generation tasks.The code can be accessible via the project page https://robustdiffusionpolicy.github.io","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10149","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.647503","language":"en","tags":["research","cslg","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Xin Chen, Gillian Dobbie, Xinyu Wang, Feng Liu, Di Wang, Jingfeng Zhang","raw_content_length":1213,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":["Extremely Noisy Conditions arXiv:2510.10149v1 Announce Type","Robust Learning of Diffusion Models","RDC","Diffusion Condition"],"persons":[],"locations":[],"monetary":[]},"char_count":1212,"language_detected":"en","key_concepts":{"key_phrases":["Robust Learning","Diffusion Models","Extremely Noisy Conditions","arXiv251010149v1","Announce Type","new Abstract","Conditional diffusion models","the generative controllability","external conditions","their performance"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robust Learning":2.0,"Diffusion Models":2.0,"Extremely Noisy Conditions":2.0,"arXiv251010149v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Conditional diffusion models":1.0,"the generative controllability":1.0,"external conditions":1.0,"their performance":1.0}},"age_hours":2.748688167777778,"is_recent":true,"quality_score":1.0,"sentiment_score":2.7185000000000006,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4563,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.871,"joy":0.0149,"surprise":0.0375,"sadness":0.0097,"fear":0.0168,"anger":0.0278,"disgust":0.0223},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper presents a novel method for improving the robustness of diffusion models under noisy conditions, demonstrating state-of-the-art performance in image and visuomotor policy generation. While the research is promising, it is still in the applied research phase with no clear path to economic viability or large-scale deployment. The impact on climate is indirect, potentially enabling more efficient control policies in various sectors.","key_impact_metrics":["State-of-the-art performance across a range of noise levels"],"technology_tags":["Diffusion Models","Machine Learning","Image Generation","Visuomotor Policy"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:10:09.086060Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d7b28655bdff","title":"Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective","content":"arXiv:2510.10150v1 Announce Type: new Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) can enhance LLM reasoning, its training process poses a critical risk: entropy collapse. This phenomenon is a rapid loss of policy diversity, stemming from the exploration-exploitation imbalance and leading to a lack of generalization. Recent entropy-intervention methods aim to prevent \\coloredtext{entropy collapse}, yet their underlying mechanisms remain unclear. In this paper, we conduct a quantitative analysis to reveal token-level entropy changes and how existing entropy intervention methods help avoid entropy collapse. Our findings point out a fundamental limitation of existing methods: they attempt to control entropy dynamics indirectly. By only affecting related factors, such as the advantage signal and generation probability, their effectiveness is inherently limited and could potentially fail. To address this limitation, we introduce an entropy-change-aware reweighting scheme, namely Stabilizing Token-level Entropy-changE via Reweighting (STEER), that adaptively stabilizes entropy dynamics through fine-grained token-level adjustments. Our approach mitigates over-exploitation while fostering robust exploration. Extensive experiments demonstrate that STEER significantly mitigates entropy collapse, stabilizes entropy dynamics, and achieves stronger downstream performance across various mathematical reasoning benchmarks \\footnote{Our code is available at https://github.com/zz-haooo/STEER.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10150","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.647911","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Zhezheng Hao, Hong Wang, Haoyang Liu, Jian Luo, Jiarui Yu, Hande Dong, Qiang Lin, Can Wang, Jiawei Chen","raw_content_length":1525,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["LLM","An Entropy Change Perspective"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1524,"language_detected":"en","key_concepts":{"key_phrases":["RLVR","Entropy Interventions","An Entropy Change Perspective","Announce Type","new Abstract","Reinforcement Learning","Verifiable Rewards","LLM reasoning","its training process","a critical risk"],"filter_categories":{"ai_ml":["Reinforcement Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RLVR":3.0,"Entropy Interventions":2.0,"An Entropy Change Perspective":2.0,"Announce Type":1.0,"new Abstract":1.0,"Reinforcement Learning":1.0,"Verifiable Rewards":1.0,"LLM reasoning":1.0,"its training process":1.0,"a critical risk":1.0}},"age_hours":2.748702961111111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.5964999999999998,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8807,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4471,"joy":0.0072,"surprise":0.0411,"sadness":0.018,"fear":0.441,"anger":0.0299,"disgust":0.0157},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new method (STEER) to stabilize entropy dynamics in Reinforcement Learning with Verifiable Rewards (RLVR) for LLMs. The concrete action is the development of a token-level reweighting scheme. The evidence supporting the claims is based on experiments showing that STEER mitigates entropy collapse and achieves stronger downstream performance on mathematical reasoning benchmarks. The stage of deployment is currently at the applied research level, with code available but no indication of real-world deployment.","key_impact_metrics":["Mitigates entropy collapse","Stronger downstream performance"],"technology_tags":["Reinforcement Learning","Large Language Models","Entropy Control"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:10:12.528209Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95133cead0e9","title":"Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer","content":"arXiv:2510.10152v1 Announce Type: new Abstract: In this work, we present Color3D, a highly adaptable framework for colorizing both static and dynamic 3D scenes from monochromatic inputs, delivering visually diverse and chromatically vibrant reconstructions with flexible user-guided control. In contrast to existing methods that focus solely on static scenarios and enforce multi-view consistency by averaging color variations which inevitably sacrifice both chromatic richness and controllability, our approach is able to preserve color diversity and steerability while ensuring cross-view and cross-time consistency. In particular, the core insight of our method is to colorize only a single key view and then fine-tune a personalized colorizer to propagate its color to novel views and time steps. Through personalization, the colorizer learns a scene-specific deterministic color mapping underlying the reference view, enabling it to consistently project corresponding colors to the content in novel views and video frames via its inherent inductive bias. Once trained, the personalized colorizer can be applied to infer consistent chrominance for all other images, enabling direct reconstruction of colorful 3D scenes with a dedicated Lab color space Gaussian splatting representation. The proposed framework ingeniously recasts complicated 3D colorization as a more tractable single image paradigm, allowing seamless integration of arbitrary image colorization models with enhanced flexibility and controllability. Extensive experiments across diverse static and dynamic 3D colorization benchmarks substantiate that our method can deliver more consistent and chromatically rich renderings with precise user control. Project Page https://yecongwan.github.io/Color3D/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10152","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.648320","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Yecong Wan, Mingwen Shao, Renlong Wu, Wangmeng Zuo","raw_content_length":1773,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1772,"language_detected":"en","key_concepts":{"key_phrases":["Color3D","Controllable and Consistent 3D Colorization","Personalized Colorizer","Announce Type","new Abstract","this work","a highly adaptable framework","both static and dynamic 3D scenes","monochromatic inputs","visually diverse and chromatically vibrant reconstructions"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Color3D":3.0,"Controllable and Consistent 3D Colorization":2.0,"Personalized Colorizer":2.0,"Announce Type":1.0,"new Abstract":1.0,"this work":1.0,"a highly adaptable framework":1.0,"both static and dynamic 3D scenes":1.0,"monochromatic inputs":1.0,"visually diverse and chromatically vibrant reconstructions":1.0}},"age_hours":2.7487174327777777,"is_recent":true,"quality_score":0.7,"sentiment_score":8.9225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7845,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8297,"joy":0.091,"surprise":0.0511,"sadness":0.0033,"fear":0.0065,"anger":0.0122,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method for 3D colorization. While potentially useful for various applications, it lacks concrete actions or measurable outcomes related to sustainability. The research is in its early stages, with no deployment or quantifiable impact on climate change or other sustainability dimensions.","key_impact_metrics":[],"technology_tags":["3D Colorization","Gaussian Splatting","Image Processing"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:10:15.141352Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_eb9871a6d451","title":"CompassNav: Steering From Path Imitation To Decision Understanding In Navigation","content":"arXiv:2510.10154v1 Announce Type: new Abstract: The dominant paradigm for training Large Vision-Language Models (LVLMs) in navigation relies on imitating expert trajectories. This approach reduces the complex navigation task to a sequence-to-sequence replication of a single correct path, fundamentally limiting the agent's ability to explore and generalize. In this work, we argue for and introduce a new paradigm: a shift from Path Imitation to Decision Understanding. The goal of this paradigm is to build agents that do not just follow, but truly understand how to navigate. We materialize this through two core contributions: first, we introduce Compass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning (RFT) subset provides a panoramic view of the decision landscape by annotating all feasible actions with A* geodesic distances. Second, we design a novel gap-aware hybrid reward function that dynamically adapts its feedback to decision certainty, shifting between decisive signals for optimal actions and nuanced scores to encourage exploration. Integrated into an SFT-then-RFT recipe, our CompassNav agent is trained not to memorize static routes, but to develop an internal ``compass'' that constantly intuits the direction to the goal by evaluating the relative quality of all possible moves. This approach enables our 7B agent to set a new state-of-the-art on Goal navigation benchmarks, outperforming even larger proprietary models, and achieve robust real-world goal navigation on a physical robot.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10154","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.648746","language":"en","tags":["preprints","research","computer-science","csro","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":219,"author":"LinFeng Li, Jian Zhao, Yuan Xie, Xin Tan, Xuelong Li","raw_content_length":1535,"priority":7,"update_frequency":1,"reading_time_minutes":1.095,"robust_parsing_used":true,"entities":{"organizations":["Compass","RFT","Navigation arXiv:2510.10154v1 Announce Type","Path Imitation to Decision"],"persons":[],"locations":[],"monetary":[]},"char_count":1534,"language_detected":"en","key_concepts":{"key_phrases":["Path Imitation","Decision Understanding","CompassNav","Navigation","arXiv251010154v1","Announce Type","new Abstract","The dominant paradigm","Large Vision-Language Models","LVLMs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Path Imitation":3.0,"Decision Understanding":3.0,"CompassNav":2.0,"Navigation":2.0,"arXiv251010154v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"The dominant paradigm":1.0,"Large Vision-Language Models":1.0,"LVLMs":1.0}},"age_hours":2.7487331544444444,"is_recent":true,"quality_score":1.0,"sentiment_score":4.8709999999999996,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0258,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7843,"joy":0.0167,"surprise":0.0656,"sadness":0.0115,"fear":0.0535,"anger":0.0453,"disgust":0.023},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article presents a new approach to training navigation AI, resulting in improved performance on goal navigation benchmarks and real-world robot navigation. The concrete action is the development and testing of the CompassNav agent. The evidence includes outperforming larger proprietary models and achieving robust real-world navigation, suggesting a pilot-stage deployment.","key_impact_metrics":["New state-of-the-art on Goal navigation benchmarks","22k-trajectory dataset"],"technology_tags":["Large Vision-Language Models","Reinforcement Learning","Robotics"],"sdg_alignment":[9,11,13],"analyzed_at":"2025-10-29T11:10:18.154331Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b2eb805b8d56","title":"ReMix: Towards a Unified View of Consistent Character Generation and Editing","content":"arXiv:2510.10156v1 Announce Type: new Abstract: Recent advances in large-scale text-to-image diffusion models (e.g., FLUX.1) have greatly improved visual fidelity in consistent character generation and editing. However, existing methods rarely unify these tasks within a single framework. Generation-based approaches struggle with fine-grained identity consistency across instances, while editing-based methods often lose spatial controllability and instruction alignment. To bridge this gap, we propose ReMix, a unified framework for character-consistent generation and editing. It constitutes two core components: the ReMix Module and IP-ControlNet. The ReMix Module leverages the multimodal reasoning ability of MLLMs to edit semantic features of input images and adapt instruction embeddings to the native DiT backbone without fine-tuning. While this ensures coherent semantic layouts, pixel-level consistency and pose controllability remain challenging. To address this, IP-ControlNet extends ControlNet to decouple semantic and layout cues from reference images and introduces an {\\epsilon}-equivariant latent space that jointly denoises the reference and target images within a shared noise space. Inspired by convergent evolution and quantum decoherence,i.e., where environmental noise drives state convergence, this design promotes feature alignment in the hidden space, enabling consistent object generation while preserving identity. ReMix supports a wide range of tasks, including personalized generation, image editing, style transfer, and multi-condition synthesis. Extensive experiments validate its effectiveness and efficiency as a unified framework for character-consistent image generation and editing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10156","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.649546","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":218,"author":"Benjia Zhou, Bin Fu, Pei Cheng, Yanru Wang, Jiayuan Fan, Tao Chen","raw_content_length":1722,"priority":7,"update_frequency":1,"reading_time_minutes":1.09,"robust_parsing_used":true,"entities":{"organizations":["IP-ControlNet","the ReMix Module","ReMix","DiT","ReMix Module"],"persons":[],"locations":[],"monetary":[]},"char_count":1721,"language_detected":"en","key_concepts":{"key_phrases":["ReMix","a Unified View","Consistent Character Generation","Editing","arXiv251010156v1 Announce Type","new Abstract","Recent advances","image","visual fidelity","consistent character generation"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"ReMix":2.0,"a Unified View":2.0,"Consistent Character Generation":2.0,"Editing":2.0,"arXiv251010156v1 Announce Type":1.0,"new Abstract":1.0,"Recent advances":1.0,"image":1.0,"visual fidelity":1.0,"consistent character generation":1.0}},"age_hours":2.7487638819444444,"is_recent":true,"quality_score":1.0,"sentiment_score":6.242,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2484,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8977,"joy":0.0101,"surprise":0.0358,"sadness":0.0132,"fear":0.0132,"anger":0.0187,"disgust":0.0114},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (ReMix) for image generation and editing. While it improves AI capabilities, there's no direct link to GHG emissions reduction or climate adaptation. The technology is in the early research stage, with no deployed units or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["AI","Image Generation","Diffusion Models","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T11:10:21.215275Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dfa00516d83c","title":"BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation","content":"arXiv:2510.10157v1 Announce Type: new Abstract: Multi-LLM systems enhance the creativity of large language models by simulating human collective intelligence but suffer from significant drawbacks, such as high computational costs and inference latency. To address these limitations, we propose BILLY (BlendIng persona vectors for Large Language model creativitY), a training-free framework that captures the benefits of multi-LLM collaboration, i.e. inducing diverse perspectives and specialized expertise, within a single model. BILLY operates by extracting and blending multiple distinct persona vectors directly in the model's activation space. We steer the model's generation process with this merged vector while inference, enabling multi-perspective output without explicit multi-LLM communication. Our experiments across creativity-oriented benchmarks demonstrate that BILLY surpasses single model prompting and traditional multi-LLM approaches, while substantially reducing inference time and computational costs. Our analyses further reveal that distinct persona vectors can be blended to achieve both effective control over complementary aspects of generation and greater interpretability.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10157","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.649932","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Tsung-Min Pai, Jui-I Wang, Li-Chun Lu, Shao-Hua Sun, Hung-Yi Lee, Kai-Wei Chang","raw_content_length":1200,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["BILLY","BlendIng","Multi-LLM","Merging Persona Vectors for Creative Generation arXiv:2510.10157v1 Announce Type"],"persons":["Large Language"],"locations":["BILLY"],"monetary":[]},"char_count":1199,"language_detected":"en","key_concepts":{"key_phrases":["BILLY","Large Language Models","Merging Persona Vectors","Creative Generation","arXiv251010157v1 Announce Type","new Abstract","Multi-LLM systems","the creativity","large language models","human collective intelligence"],"filter_categories":{"ai_ml":["Large Language Models","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BILLY":3.0,"Large Language Models":2.0,"Merging Persona Vectors":2.0,"Creative Generation":2.0,"arXiv251010157v1 Announce Type":1.0,"new Abstract":1.0,"Multi-LLM systems":1.0,"the creativity":1.0,"large language models":1.0,"human collective intelligence":1.0}},"age_hours":2.748779271111111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.695500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7391,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8271,"joy":0.064,"surprise":0.0179,"sadness":0.0579,"fear":0.0101,"anger":0.0125,"disgust":0.0105},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":4,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (BILLY) to improve the efficiency of LLMs, potentially reducing computational costs and inference time. While this could indirectly reduce energy consumption associated with LLM training and operation, the impact is theoretical and not quantified in terms of specific energy savings or emissions reductions. The research is in an early stage, lacking deployment or real-world validation.","key_impact_metrics":["reduced inference time","reduced computational costs"],"technology_tags":["Large Language Models","AI efficiency","Persona Vectors"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T11:10:24.157701Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_dca74cbb6d52","title":"SaFiRe: Saccade","content":"arXiv:2510.10160v1 Announce Type: new Abstract: Referring Image Segmentation (RIS) aims to segment the target object in an image given a natural language expression. While recent methods leverage pre-trained vision backbones and more training corpus to achieve impressive results, they predominantly focus on simple expressions--short, clear noun phrases like \"red car\" or \"left girl\". This simplification often reduces RIS to a key word/concept matching problem, limiting the model's ability to handle referential ambiguity in expressions. In this work, we identify two challenging real-world scenarios: object-distracting expressions, which involve multiple entities with contextual cues, and category-implicit expressions, where the object class is not explicitly stated. To address the challenges, we propose a novel framework, SaFiRe, which mimics the human two-phase cognitive process--first forming a global understanding, then refining it through detail-oriented inspection. This is naturally supported by Mamba's scan-then-update property, which aligns with our phased design and enables efficient multi-cycle refinement with linear complexity. We further introduce aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous referring expressions. Extensive experiments on both standard and proposed datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10160","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.651110","language":"en","tags":["computer-science","csai","preprints","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Zhenjie Mao, Yuhuan Yang, Chaofan Ma, Dongsheng Jiang, Jiangchao Yao, Ya Zhang, Yanfeng Wang","raw_content_length":1404,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["RIS"],"persons":[],"locations":["SaFiRe"],"monetary":[]},"char_count":1403,"language_detected":"en","key_concepts":{"key_phrases":["SaFiRe Saccade","RIS","Announce Type","new Abstract","Image Segmentation","the target object","an image","a natural language expression","recent methods","pre-trained vision backbones"],"filter_categories":{"ai_ml":["pre-trained vision backbones"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SaFiRe Saccade":2.0,"RIS":2.0,"Announce Type":1.0,"new Abstract":1.0,"Image Segmentation":1.0,"the target object":1.0,"an image":1.0,"a natural language expression":1.0,"recent methods":1.0,"pre-trained vision backbones":1.0}},"age_hours":2.748822350555556,"is_recent":true,"quality_score":1.0,"sentiment_score":9.4425,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8885,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9042,"joy":0.0119,"surprise":0.0592,"sadness":0.007,"fear":0.0027,"anger":0.0085,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (SaFiRe) for improved image segmentation, but it's currently in the research stage with no deployed applications or measurable environmental outcomes. While the improved AI could potentially be applied to sustainability-related tasks in the future (e.g., identifying deforestation), there is no concrete action or evidence of this happening yet. The technical credibility is high due to the peer-reviewed nature of the publication, but deployment readiness is low.","key_impact_metrics":[],"technology_tags":["AI","Image Segmentation","Referring Image Segmentation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:10:27.277926Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5fac4612f7aa","title":"Large Language Model Sourcing: A Survey","content":"arXiv:2510.10161v1 Announce Type: new Abstract: The rapid advancement of large language models (LLMs) has revolutionized artificial intelligence, shifting from supporting objective tasks (e.g., recognition) to empowering subjective decision-making (e.g., planning, decision). This marks the dawn of general and powerful AI, with applications spanning a wide range of fields, including programming, education, healthcare, finance, and law. However, their deployment introduces multifaceted risks. Due to the black-box nature of LLMs and the human-like quality of their generated content, issues such as hallucinations, bias, unfairness, and copyright infringement become particularly significant. In this context, sourcing information from multiple perspectives is essential. This survey presents a systematic investigation into provenance tracking for content generated by LLMs, organized around four interrelated dimensions that together capture both model- and data-centric perspectives. From the model perspective, Model Sourcing treats the model as a whole, aiming to distinguish content generated by specific LLMs from content authored by humans. Model Structure Sourcing delves into the internal generative mechanisms, analyzing architectural components that shape the outputs of model. From the data perspective, Training Data Sourcing focuses on internal attribution, tracing the origins of generated content back to the training data of model. In contrast, External Data Sourcing emphasizes external validation, identifying external information used to support or influence the responses of model. Moreover, we also propose a dual-paradigm taxonomy that classifies existing sourcing methods into prior-based (proactive traceability embedding) and posterior-based (retrospective inference) approaches. Traceability across these dimensions enhances the transparency, accountability, and trustworthiness of LLMs deployment in real-world applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10161","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.651545","language":"en","tags":["computer-science","csai","preprints","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Liang Pang, Kangxi Wu, Sunhao Dai, Zihao Wei, Zenghao Duan, Jia Gu, Xiang Li, Zhiyi Yin, Jun Xu, Huawei Shen, Xueqi Cheng","raw_content_length":1959,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Language Model Sourcing"],"locations":[],"monetary":[]},"char_count":1956,"language_detected":"en","key_concepts":{"key_phrases":["Large Language Model Sourcing","A Survey","arXiv251010161v1 Announce Type","new Abstract","The rapid advancement","large language models","LLMs","artificial intelligence","objective tasks","eg recognition"],"filter_categories":{"ai_ml":["Large Language Model Sourcing","large language models","artificial intelligence"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Large Language Model Sourcing":2.0,"A Survey":2.0,"arXiv251010161v1 Announce Type":1.0,"new Abstract":1.0,"The rapid advancement":1.0,"large language models":1.0,"LLMs":1.0,"artificial intelligence":1.0,"objective tasks":1.0,"eg recognition":1.0}},"age_hours":2.7488376086111113,"is_recent":true,"quality_score":1.0,"sentiment_score":9.158,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8316,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.73,"joy":0.0279,"surprise":0.1984,"sadness":0.0056,"fear":0.0192,"anger":0.0114,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article is a survey of methods for tracing the origins of content generated by LLMs. While it addresses potential risks like bias and unfairness, it doesn't present concrete actions or measurable outcomes related to climate impact or sustainability. It's primarily focused on research and methodology, not deployment or impact assessment.","key_impact_metrics":[],"technology_tags":["Large Language Models","AI Ethics","Provenance Tracking"],"sdg_alignment":[16],"analyzed_at":"2025-10-29T11:10:30.151532Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_58d0508715db","title":"SparseUWSeg: Active Sparse Point","content":"arXiv:2510.10163v1 Announce Type: new Abstract: Semantic segmentation is essential to automate underwater imagery analysis with ecology monitoring purposes. Unfortunately, fine grained underwater scene analysis is still an open problem even for top performing segmentation models. The high cost of obtaining dense, expert-annotated, segmentation labels hinders the supervision of models in this domain. While sparse point-labels are easier to obtain, they introduce challenges regarding which points to annotate and how to propagate the sparse information. We present SparseUWSeg, a novel framework that addresses both issues. SparseUWSeg employs an active sampling strategy to guide annotators, maximizing the value of their point labels. Then, it propagates these sparse labels with a hybrid approach leverages both the best of SAM2 and superpixel-based methods. Experiments on two diverse underwater datasets demonstrate the benefits of SparseUWSeg over state-of-the-art approaches, achieving up to +5\\% mIoU over D+NN. Our main contribution is the design and release of a simple but effective interactive annotation tool, integrating our algorithms. It enables ecology researchers to leverage foundation models and computer vision to efficiently generate high-quality segmentation masks to process their data.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10163","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.651942","language":"en","tags":["preprints","cscv","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"C\\'esar Borja, Carlos Plou, Rub\\'en Martinez-Cant\\'in, Ana C. Murillo","raw_content_length":1314,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":["Active Sparse Point arXiv:2510.10163v1 Announce Type: new Abstract"],"persons":[],"locations":["SAM2"],"monetary":[]},"char_count":1313,"language_detected":"en","key_concepts":{"key_phrases":["SparseUWSeg","Active Sparse Point","arXiv251010163v1","Announce Type","new Abstract","Semantic segmentation","underwater imagery analysis","ecology monitoring purposes","fine grained underwater scene analysis","an open problem"],"filter_categories":{"ai_ml":["fine grained underwater scene analysis"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SparseUWSeg":2.0,"Active Sparse Point":2.0,"arXiv251010163v1":1.0,"Announce Type":1.0,"new Abstract":1.0,"Semantic segmentation":1.0,"underwater imagery analysis":1.0,"ecology monitoring purposes":1.0,"fine grained underwater scene analysis":1.0,"an open problem":1.0}},"age_hours":2.7488524375,"is_recent":true,"quality_score":1.0,"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5527,"joy":0.0051,"surprise":0.0176,"sadness":0.263,"fear":0.077,"anger":0.0353,"disgust":0.0492},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel framework, SparseUWSeg, for improving semantic segmentation of underwater imagery, which can aid in ecology monitoring. The concrete action is the design and release of an interactive annotation tool. The evidence supporting claims is the reported +5% mIoU improvement over D+NN on two datasets, but there's no information about actual deployment or real-world usage yet.","key_impact_metrics":["+5% mIoU over D+NN"],"technology_tags":["semantic segmentation","active learning","underwater imagery analysis"],"sdg_alignment":[14],"analyzed_at":"2025-10-29T11:10:33.340469Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c274c7bbe4f2","title":"Concise Reasoning in the Lens of Lagrangian Optimization","content":"arXiv:2510.10168v1 Announce Type: new Abstract: Concise reasoning in large language models seeks to generate only essential intermediate steps needed to arrive at a final answer, thereby alleviating issues of overthinking. Most proposed approaches hinge on carefully hand-crafted heuristics, struggling to balance concision with performance, often failing to adapt across domains and model scales. In this work, we address these challenges by introducing a principled and pragmatic strategy, performance-aware length updating (PALU). As a principled algorithm, PALU formulates concise reasoning as a constrained optimization problem, minimizing response length subject to a performance constraint, and then applies Lagrangian optimization to convert it into a tractable unconstrained problem. As a pragmatic solution, PALU streamlines complicated update rules through three approximations: (i) estimating performance with off-policy rollouts, (ii) truncating the Lagrange multiplier to two extremes, and (iii) replacing gradient-based updates with quantile-driven length adjustments. PALU reduces output length by 65% while improving accuracy by 15% when applied to DeepSeek-Distill-Qwen-1.5B, averaged over five benchmarks, outperforming a range of alternative methods. Furthermore, PALU is demonstrated to adapt across both domain (logic, STEM and math) and model scale (1.5B, 7B, 14B) entrenching the algorithm as a practical and effective concise reasoning approach.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10168","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.652748","language":"en","tags":["preprints","csai","research","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Chengqian Gao, Haonan Li, Taylor W. Killian, Jianshu She, Renxi Wang, Liqun Ma, Zhoujun Cheng, Shibo Hao, Zhiqiang Xu","raw_content_length":1471,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1470,"language_detected":"en","key_concepts":{"key_phrases":["Concise Reasoning","the Lens","Lagrangian Optimization","arXiv251010168v1 Announce Type","new Abstract","Concise reasoning","large language models","only essential intermediate steps","a final answer","issues"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Concise Reasoning":2.0,"the Lens":2.0,"Lagrangian Optimization":2.0,"arXiv251010168v1 Announce Type":1.0,"new Abstract":1.0,"Concise reasoning":1.0,"large language models":1.0,"only essential intermediate steps":1.0,"a final answer":1.0,"issues":1.0}},"age_hours":2.7488812072222224,"is_recent":true,"quality_score":0.7,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8928,"joy":0.0063,"surprise":0.0112,"sadness":0.0422,"fear":0.0186,"anger":0.0168,"disgust":0.0122},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel algorithm (PALU) for improving the conciseness and accuracy of large language models. While the algorithm shows promise in reducing output length and improving accuracy, it is currently in the applied research stage, with no evidence of real-world deployment or economic viability. The climate impact is indirect, potentially improving efficiency of AI systems, but not directly reducing emissions.","key_impact_metrics":["output length reduced by 65%","accuracy improved by 15%"],"technology_tags":["large language models","constrained optimization","machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T11:10:36.606911Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a2c090265661","title":"Chord Colourizer: A Near Real","content":"arXiv:2510.10173v1 Announce Type: new Abstract: This paper introduces Chord Colourizer, a near real-time system that detects the musical key of an audio signal and visually represents it through a novel graphical user interface (GUI). The system assigns colours to musical notes based on Isaac Newton's original colour wheel, preserving historical links between pitch and hue, and also integrates an Arduino-controlled LED display using 3D-printed star-shaped diffusers to offer a physical ambient media representation. The method employs Constant-Q Transform (CQT) chroma features for chord estimation and visualization, followed by threshold-based filtering and tonal enhancement to isolate the root, third, and fifth. A confidence score is computed for each detection to ensure reliability, and only chords with moderate to very strong certainty are visualized. The graphical interface dynamically updates a colour-coded keyboard layout, while the LED display provides the same colour information via spatial feedback. This multi-modal system enhances user interaction with harmonic content, offering innovative possibilities for education and artistic performance. Limitations include slight latency and the inability to detect extended chords, which future development will aim to address through refined filtering, adaptive thresholds, and support for more complex harmonies such as sevenths and augmented chords. Future work will also explore integration with alternative visualization styles, and the comparison of audio analysis libraries to improve detection speed and precision. Plans also include formal user testing to evaluate perception, usability, and cross-cultural interpretations of colour-pitch mappings.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.10173","published_date":"2025-10-14T04:00:00","collected_date":"2025-10-14T06:39:38.653563","language":"en","tags":["cscy","eessas","preprints","research","cssd","cshc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":234,"author":"Paul Haimes","raw_content_length":1725,"priority":7,"update_frequency":1,"reading_time_minutes":1.17,"robust_parsing_used":true,"entities":{"organizations":["Constant-Q Transform","Arduino","CQT"],"persons":["keyboard layout","Isaac Newton's","Chord Colourizer"],"locations":[],"monetary":[]},"char_count":1724,"language_detected":"en","key_concepts":{"key_phrases":["Chord Colourizer","A Near Real","new Abstract","This paper","a near real-time system","the musical key","an audio signal","a novel graphical user interface","GUI","The system"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Chord Colourizer":3.0,"A Near Real":2.0,"new Abstract":1.0,"This paper":1.0,"a near real-time system":1.0,"the musical key":1.0,"an audio signal":1.0,"a novel graphical user interface":1.0,"GUI":1.0,"The system":1.0}},"age_hours":2.748912264722222,"is_recent":true,"quality_score":1.0,"sentiment_score":7.786999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5574,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8744,"joy":0.0506,"surprise":0.0388,"sadness":0.0025,"fear":0.0094,"anger":0.014,"disgust":0.0102},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":1,"deployment_readiness":3,"systemic_impact":1,"justice_equity":3,"innovation_quality":5,"evidence_strength":4,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a prototype system for visualizing musical chords. While innovative, it has no direct or measurable impact on climate change or sustainability. The system is in the early stages of development, with no deployed units or quantified environmental benefits.","key_impact_metrics":[],"technology_tags":["audio analysis","visualization","LED display"],"sdg_alignment":[],"analyzed_at":"2025-10-29T11:10:39.225486Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
