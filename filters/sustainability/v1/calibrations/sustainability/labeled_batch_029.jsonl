{"id":"science_arxiv_cs_98b4ad787dbc","title":"UNCLE: Benchmarking Uncertainty Expressions in Long","content":"arXiv:2505.16922v2 Announce Type: replace Abstract: Large Language Models (LLMs) are prone to hallucination, particularly in long-form generations. A promising direction to mitigate hallucination is to teach LLMs to express uncertainty explicitly when they lack sufficient knowledge. However, existing work lacks direct and fair evaluation of LLMs' ability to express uncertainty effectively in long-form generation. To address this gap, we first introduce UNCLE, a benchmark designed to evaluate uncertainty expression in both long- and short-form question answering (QA). UNCLE covers five domains and includes more than 1,000 entities, each with paired short- and long-form QA items. Our dataset is the first to directly link short- and long-form QA through aligned questions and gold-standard answers. Along with UNCLE, we propose a suite of new metrics to assess the models' capabilities to selectively express uncertainty. We then demonstrate that current models fail to convey uncertainty appropriately in long-form generation. We further explore both prompt-based and training-based methods to improve models' performance, with the training-based methods yielding greater gains. Further analysis of alignment gaps between short- and long-form uncertainty expression highlights promising directions for future research using UNCLE.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16922","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.447107","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":184,"author":"Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Dong Yu, Nigel Collier, Deqing Yang","raw_content_length":1339,"priority":7,"update_frequency":1,"reading_time_minutes":0.92,"robust_parsing_used":true,"entities":{"organizations":["Benchmarking Uncertainty Expressions","UNCLE"],"persons":[],"locations":[],"monetary":[]},"char_count":1338,"language_detected":"en","key_concepts":{"key_phrases":["UNCLE","Benchmarking Uncertainty Expressions","Long","LLMs","uncertainty","Announce Type","Large Language Models","long-form generations","A promising direction","hallucination"],"filter_categories":{"ai_ml":["Benchmarking Uncertainty Expressions","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"UNCLE":3.0,"Benchmarking Uncertainty Expressions":2.0,"Long":2.0,"LLMs":2.0,"uncertainty":2.0,"Announce Type":1.0,"Large Language Models":1.0,"long-form generations":1.0,"A promising direction":1.0,"hallucination":1.0}},"age_hours":2.780635358888889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.5165,"joy":0.0052,"surprise":0.0119,"sadness":0.014,"fear":0.429,"anger":0.0118,"disgust":0.0117},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a benchmark (UNCLE) for evaluating uncertainty expression in LLMs. While improved LLMs could indirectly support sustainability by improving access to information and potentially optimizing resource use, the direct climate impact is minimal. The technical credibility is relatively high due to the introduction of new metrics and analysis of existing models, but deployment readiness is low as it's primarily a research tool.","key_impact_metrics":["Entities with paired short- and long-form QA items: >1,000"],"technology_tags":["Large Language Models","Uncertainty Quantification","Question Answering"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:56:40.188299Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c04a6ceeed09","title":"Search Wisely: Mitigating Sub","content":"arXiv:2505.17281v2 Announce Type: replace Abstract: Agentic Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by enabling dynamic, multi-step reasoning and information retrieval. However, these systems often exhibit sub-optimal search behaviors like over-search (retrieving redundant information) and under-search (failing to retrieve necessary information), which hinder efficiency and reliability. This work formally defines and quantifies these behaviors, revealing their prevalence across multiple QA datasets and agentic RAG systems (e.g., one model could have avoided searching in 27.7% of its search steps). Furthermore, we demonstrate a crucial link between these inefficiencies and the models' uncertainty regarding their own knowledge boundaries, where response accuracy correlates with model's uncertainty in its search decisions. To address this, we propose $\\beta$-GRPO, a reinforcement learning-based training method that incorporates confidence threshold to reward high-certainty search decisions. Experiments on seven QA benchmarks show that $\\beta$-GRPO enable a 3B model with better agentic RAG ability, outperforming other strong baselines with a 4% higher average exact match score.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.17281","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.447503","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":158,"author":"Peilin Wu, Mian Zhang, Xinlu Zhang, Xinya Du, Zhiyu Zoey Chen","raw_content_length":1235,"priority":7,"update_frequency":1,"reading_time_minutes":0.79,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models"],"persons":["RAG"],"locations":[],"monetary":[]},"char_count":1234,"language_detected":"en","key_concepts":{"key_phrases":["Search","Sub","arXiv250517281v2 Announce Type","Abstract","Agentic Retrieval-Augmented Generation RAG systems","Large Language Models","LLMs","dynamic multi-step reasoning","information retrieval","these systems"],"filter_categories":{"healthcare_tech":["Search"],"research_academic":["Search"],"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Search":2.0,"Sub":2.0,"arXiv250517281v2 Announce Type":1.0,"Abstract":1.0,"Agentic Retrieval-Augmented Generation RAG systems":1.0,"Large Language Models":1.0,"LLMs":1.0,"dynamic multi-step reasoning":1.0,"information retrieval":1.0,"these systems":1.0}},"age_hours":2.7806502558333337,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8057,"joy":0.0061,"surprise":0.0118,"sadness":0.0599,"fear":0.0147,"anger":0.0651,"disgust":0.0366},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a reinforcement learning method to improve the efficiency of agentic RAG systems, reducing unnecessary search steps. While it shows a 4% improvement in exact match score on QA benchmarks, it is still in the research phase with no real-world deployment. The climate impact is indirect, potentially reducing energy consumption of LLMs, but this is not quantified.","key_impact_metrics":["4% higher average exact match score","27.7% of search steps avoided"],"technology_tags":["Reinforcement Learning","Large Language Models","Retrieval-Augmented Generation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:56:43.904211Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8f1489994336","title":"Inference","content":"arXiv:2505.20081v3 Announce Type: replace Abstract: Aligning large language models with human feedback at inference time has received increasing attention due to its flexibility. Existing methods rely on generating multiple responses from the base policy for search using a reward model, which can be considered as searching in a discrete response space. However, these methods struggle to explore informative candidates when the base policy is weak or the candidate set is small, resulting in limited effectiveness. In this paper, to address this problem, we propose Simple Energy Adaptation ($\\textbf{SEA}$), a simple yet effective algorithm for inference-time alignment. In contrast to expensive search over the discrete space, SEA directly adapts original responses from the base policy toward the optimal one via gradient-based sampling in continuous latent space. Specifically, SEA formulates inference as an iterative optimization procedure on an energy function over actions in the continuous space defined by the optimal policy, enabling simple and effective alignment. For instance, despite its simplicity, SEA outperforms the second-best baseline with a relative improvement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on MATH. Our code is publicly available at https://github.com/yuanyige/sea","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20081","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.449072","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Yige Yuan, Teng Xiao, Li Yunfan, Bingbing Xu, Shuchang Tao, Yunqi Qiu, Huawei Shen, Xueqi Cheng","raw_content_length":1323,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["SEA","Simple Energy Adaptation"],"persons":[],"locations":[],"monetary":[]},"char_count":1322,"language_detected":"en","key_concepts":{"key_phrases":["Inference","the base policy","arXiv250520081v3 Announce Type","Abstract","large language models","human feedback","inference time","increasing attention","its flexibility","Existing methods"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Inference":2.0,"the base policy":2.0,"arXiv250520081v3 Announce Type":1.0,"Abstract":1.0,"large language models":1.0,"human feedback":1.0,"inference time":1.0,"increasing attention":1.0,"its flexibility":1.0,"Existing methods":1.0}},"age_hours":2.7807103016666668,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8779,"joy":0.0104,"surprise":0.0443,"sadness":0.0278,"fear":0.01,"anger":0.0171,"disgust":0.0125},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm (SEA) for improving the alignment of large language models, showing performance improvements on AdvBench (77.51%) and MATH (16.36%). While the technology could potentially be used to improve the efficiency of AI models used in climate applications, it's currently in the research phase with no deployed units or concrete climate impact metrics provided. The vaporware flag is set because it's an early-stage concept with no deployment data.","key_impact_metrics":["Improvement on AdvBench 77.51%","Improvement on MATH 16.36%"],"technology_tags":["Large Language Models","Inference Optimization","AI Alignment"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:56:46.987415Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c1d2ee87ff2b","title":"BiomedSQL: Text","content":"arXiv:2505.20321v3 Announce Type: replace Abstract: Biomedical researchers increasingly rely on large-scale structured databases for complex analytical tasks. However, current text-to-SQL systems often struggle to map qualitative scientific questions into executable SQL, particularly when implicit domain reasoning is required. We introduce BiomedSQL, the first benchmark explicitly designed to evaluate scientific reasoning in text-to-SQL generation over a real-world biomedical knowledge base. BiomedSQL comprises 68,000 question/SQL query/answer triples generated from templates and grounded in a harmonized BigQuery knowledge base that integrates gene-disease associations, causal inference from omics data, and drug approval records. Each question requires models to infer domain-specific criteria, such as genome-wide significance thresholds, effect directionality, or trial phase filtering, rather than rely on syntactic translation alone. We evaluate a range of open- and closed-source LLMs across prompting strategies and interaction paradigms. Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0% execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%, both well below the expert baseline of 90.0%. BiomedSQL provides a new foundation for advancing text-to-SQL systems capable of supporting scientific discovery through robust reasoning over structured biomedical knowledge bases. Our dataset is publicly available at https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source at https://github.com/NIH-CARD/biomedsql.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20321","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.449486","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Mathew J. Koretsky, Maya Willey, Adi Asija, Owen Bianchi, Chelsea X. Alvarado, Tanay Nayak, Nicole Kuznetsov, Sungwon Kim, Mike A. Nalls, Daniel Khashabi, Faraz Faghri","raw_content_length":1596,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["BigQuery","SQL"],"persons":[],"locations":["BiomedSQL"],"monetary":[]},"char_count":1595,"language_detected":"en","key_concepts":{"key_phrases":["BiomedSQL","Text","SQL","arXiv250520321v3 Announce Type","Abstract","Biomedical researchers","large-scale structured databases","complex analytical tasks","qualitative scientific questions","executable SQL"],"filter_categories":{"research_academic":["Biomedical researchers"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"BiomedSQL":3.0,"Text":2.0,"SQL":2.0,"arXiv250520321v3 Announce Type":1.0,"Abstract":1.0,"Biomedical researchers":1.0,"large-scale structured databases":1.0,"complex analytical tasks":1.0,"qualitative scientific questions":1.0,"executable SQL":1.0}},"age_hours":2.780724886388889,"is_recent":true,"quality_score":1.0,"sentiment_score":3.409,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3182,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8855,"joy":0.0073,"surprise":0.0542,"sadness":0.007,"fear":0.0193,"anger":0.0161,"disgust":0.0106},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article introduces a new benchmark, BiomedSQL, for evaluating text-to-SQL systems in the biomedical domain. While the dataset and code are publicly available, it's still in the research phase, with no immediate deployment or measurable climate impact. The technical credibility is high due to the grounding in a real-world knowledge base and the evaluation of LLMs, but it's primarily a research tool at this stage.","key_impact_metrics":["Execution accuracy: 59.0%","Execution accuracy: 62.6%"],"technology_tags":["Text-to-SQL","Large Language Models","Biomedical Knowledge Base"],"sdg_alignment":[3,9],"analyzed_at":"2025-10-28T20:56:59.061495Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3fafa843ca6b","title":"The Shape of Adversarial Influence: Characterizing LLM Latent Spaces with Persistent Homology","content":"arXiv:2505.20435v2 Announce Type: replace Abstract: Existing interpretability methods for Large Language Models (LLMs) often fall short by focusing on linear directions or isolated features, overlooking the high-dimensional, nonlinear, and relational geometry within model representations. This study focuses on how adversarial inputs systematically affect the internal representation spaces of LLMs, a topic which remains poorly understood. We propose persistent homology (PH), a tool from topological data analysis, as a principled framework to characterize the multi-scale dynamics within LLM activations. Using PH, we systematically analyze six state-of-the-art models under two distinct adversarial conditions, indirect prompt injection and backdoor fine-tuning, and identify a consistent topological signature of adversarial influence. Across architectures and model sizes, adversarial inputs induce ``topological compression'', where the latent space becomes structurally simpler, collapsing from varied, compact, small-scale features into fewer, dominant, and more dispersed large-scale ones. This topological signature is statistically robust across layers, highly discriminative, and provides interpretable insights into how adversarial effects emerge and propagate. By quantifying the shape of activations and neuronal information flow, our architecture-agnostic framework reveals fundamental invariants of representational change, offering a complementary perspective to existing interpretability methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20435","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.449887","language":"en","tags":["computer-science","cslg","csai","preprints","cscg","mathat","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Aideen Fay, In\\'es Garc\\'ia-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod","raw_content_length":1518,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["LLM","Large Language Models"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1517,"language_detected":"en","key_concepts":{"key_phrases":["The Shape","Adversarial Influence","LLM Latent Spaces","Persistent Homology","LLMs","arXiv250520435v2 Announce Type","Abstract","Existing interpretability methods","Large Language Models","linear directions"],"filter_categories":{"ai_ml":["LLM Latent Spaces","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Shape":2.0,"Adversarial Influence":2.0,"LLM Latent Spaces":2.0,"Persistent Homology":2.0,"LLMs":2.0,"arXiv250520435v2 Announce Type":1.0,"Abstract":1.0,"Existing interpretability methods":1.0,"Large Language Models":1.0,"linear directions":1.0}},"age_hours":2.7807394444444444,"is_recent":true,"quality_score":1.0,"sentiment_score":1.2850000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.743,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7958,"joy":0.0057,"surprise":0.0485,"sadness":0.0422,"fear":0.0257,"anger":0.0455,"disgust":0.0366},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on understanding how adversarial inputs affect LLM internal representation spaces using persistent homology. While it identifies a consistent topological signature of adversarial influence, it is at a basic research stage with no deployed technology or measured outcomes related to direct climate impact or sustainability. The research is peer-reviewed and uses specific metrics related to the topological compression of latent spaces.","key_impact_metrics":["Topological compression of latent space","Number of dominant large-scale features"],"technology_tags":["Large Language Models","Adversarial Influence","Persistent Homology","Topological Data Analysis"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:57:01.745924Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a471bef367d1","title":"Trans","content":"arXiv:2505.20875v3 Announce Type: replace Abstract: Large Language Models (LLMs) are predominantly evaluated on Standard American English (SAE), often overlooking the diversity of global English varieties. This narrow focus may raise fairness concerns as degraded performance on non-standard varieties can lead to unequal benefits for users worldwide. Therefore, it is critical to extensively evaluate the linguistic robustness of LLMs on multiple non-standard English varieties. We introduce Trans-EnV, a framework that automatically transforms SAE datasets into multiple English varieties to evaluate the linguistic robustness. Our framework combines (1) linguistics expert knowledge to curate variety-specific features and transformation guidelines from linguistic literature and corpora, and (2) LLM-based transformations to ensure both linguistic validity and scalability. Using Trans-EnV, we transform six benchmark datasets into 38 English varieties and evaluate seven state-of-the-art LLMs. Our results reveal significant performance disparities, with accuracy decreasing by up to 46.3% on non-standard varieties. These findings highlight the importance of comprehensive linguistic robustness evaluation across diverse English varieties. Each construction of Trans-EnV was validated through rigorous statistical testing and consultation with a researcher in the field of second language acquisition, ensuring its linguistic validity. Our code and datasets are publicly available at https://github.com/jiyounglee-0523/TransEnV and https://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20875","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.450282","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":195,"author":"Jiyoung Lee, Seungho Kim, Jieun Han, Jun-Min Lee, Kitaek Kim, Alice Oh, Edward Choi","raw_content_length":1623,"priority":7,"update_frequency":1,"reading_time_minutes":0.975,"robust_parsing_used":true,"entities":{"organizations":["Trans","Standard American English","Trans-EnV","SAE"],"persons":["corpora"],"locations":[],"monetary":[]},"char_count":1622,"language_detected":"en","key_concepts":{"key_phrases":["Trans","LLMs","arXiv250520875v3 Announce Type","Large Language Models","Standard American English","SAE","the diversity","global English varieties","This narrow focus","fairness concerns"],"filter_categories":{"ai_ml":["Trans","Large Language Models"],"business_innovation":["Trans"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Trans":3.0,"LLMs":2.0,"arXiv250520875v3 Announce Type":1.0,"Large Language Models":1.0,"Standard American English":1.0,"SAE":1.0,"the diversity":1.0,"global English varieties":1.0,"This narrow focus":1.0,"fairness concerns":1.0}},"age_hours":2.780754656944444,"is_recent":true,"quality_score":0.7,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8911,"joy":0.0116,"surprise":0.0232,"sadness":0.009,"fear":0.0119,"anger":0.038,"disgust":0.0152},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":7,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":true,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the fairness and robustness of LLMs across different English dialects. While it doesn't directly address climate change, it promotes equity by ensuring that AI benefits are accessible to a wider range of users, including those from marginalized communities. The framework is validated through statistical testing and expert consultation.","key_impact_metrics":["accuracy decreasing by up to 46.3% on non-standard varieties","38 English varieties transformed"],"technology_tags":["Large Language Models","Natural Language Processing"],"sdg_alignment":[4,10],"analyzed_at":"2025-10-28T20:57:04.481740Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_56245abf4442","title":"Can Large Reasoning Models Self","content":"arXiv:2505.21444v2 Announce Type: replace Abstract: Recent successes of reinforcement learning (RL) in training large reasoning models motivate the question of whether self-training - the process where a model learns from its own judgments - can be sustained within RL. In this work, we study this question using majority voting as a simple self-feedback mechanism. On a comprehensive set of experiments on both synthetic and real reasoning tasks, we find that this basic approach improves not only the model's reasoning performance, but also its capability of generating better quality feedback for the next RL iteration, driving further model improvement. Yet our analysis also reveals a critical limitation of such a self-training paradigm - prolonged RL with self-reward leads to reward hacking where models learn to maximize training (pseudo-)reward, resulting in sudden and complete performance collapse. Together, these results highlight feedback design as the central challenge and call for future research on mechanisms to enable prolonged self-improvement.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21444","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.455885","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Sheikh Shafayat, Fahim Tajwar, Ruslan Salakhutdinov, Jeff Schneider, Andrea Zanette","raw_content_length":1067,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1066,"language_detected":"en","key_concepts":{"key_phrases":["Can Large Reasoning Models Self","Announce Type","Abstract","Recent successes","reinforcement learning","large reasoning models","the question","whether self-training - the process","a model","its own judgments"],"filter_categories":{"ai_ml":["reinforcement learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Can Large Reasoning Models Self":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent successes":1.0,"reinforcement learning":1.0,"large reasoning models":1.0,"the question":1.0,"whether self-training - the process":1.0,"a model":1.0,"its own judgments":1.0}},"age_hours":2.780769895,"is_recent":true,"quality_score":0.7,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8291,"joy":0.0756,"surprise":0.0319,"sadness":0.0067,"fear":0.0095,"anger":0.0228,"disgust":0.0245},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes research on improving reasoning models using reinforcement learning and self-feedback. The concrete action is the experimentation with majority voting as a self-feedback mechanism. The evidence is based on experiments on synthetic and real reasoning tasks, but it's still in the research phase with no deployed technology or measurable real-world impact on sustainability.","key_impact_metrics":["Improvement in reasoning performance","Quality of feedback generated"],"technology_tags":["Reinforcement Learning","Reasoning Models","Self-Training"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:57:08.567725Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_faba56544aa5","title":"FlashDLM: Accelerating Diffusion Language Model Inference via Efficient KV Caching and Guided Diffusion","content":"arXiv:2505.21467v2 Announce Type: replace Abstract: Diffusion language models offer parallel token generation and inherent bidirectionality, promising more efficient and powerful sequence modeling compared to autoregressive approaches. However, state-of-the-art diffusion models (e.g., Dream 7B, LLaDA 8B) suffer from slow inference. While they match the quality of similarly sized autoregressive (AR) models (e.g., Qwen2.5 7B, Llama3 8B), their iterative denoising requires multiple full-sequence forward passes, resulting in high computational costs and latency, particularly for long input prompts and long-context scenarios. Furthermore, parallel token generation introduces token incoherence problems, and current sampling heuristics suffer from significant quality drops with decreasing denoising steps. We address these limitations with two training-free techniques. First, we propose FreeCache, a Key-Value (KV) approximation caching technique that reuses stable KV projections across denoising steps, effectively reducing the computational cost of DLM inference. Second, we introduce Guided Diffusion, a training-free method that uses a lightweight pretrained autoregressive model to supervise token unmasking, dramatically reducing the total number of denoising iterations without sacrificing quality. We conduct extensive evaluations on open-source reasoning benchmarks, and our combined methods deliver an average of 12.14x end-to-end speedup across various tasks with negligible accuracy degradation. For the first time, diffusion language models achieve a comparable and even faster latency as the widely adopted autoregressive models. Our work successfully paved the way for scaling up the diffusion language model to a broader scope of applications across different domains.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21467","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.456341","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Zhanqiu Hu, Jian Meng, Yash Akhauri, Mohamed S. Abdelfattah, Jae-sun Seo, Zhiru Zhang, Udit Gupta","raw_content_length":1791,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1790,"language_detected":"en","key_concepts":{"key_phrases":["Diffusion Language Model Inference","Efficient KV Caching and Guided Diffusion","arXiv250521467v2 Announce Type","Abstract","Diffusion language models","parallel token generation and inherent bidirectionality","more efficient and powerful sequence modeling","autoregressive approaches","the-art","Dream 7B"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Diffusion Language Model Inference":2.0,"Efficient KV Caching and Guided Diffusion":2.0,"arXiv250521467v2 Announce Type":1.0,"Abstract":1.0,"Diffusion language models":1.0,"parallel token generation and inherent bidirectionality":1.0,"more efficient and powerful sequence modeling":1.0,"autoregressive approaches":1.0,"the-art":1.0,"Dream 7B":1.0}},"age_hours":2.7807852972222222,"is_recent":true,"quality_score":0.7,"sentiment_score":9.232,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8464,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8559,"joy":0.0066,"surprise":0.0381,"sadness":0.0386,"fear":0.0116,"anger":0.0147,"disgust":0.0346},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to accelerating diffusion language model inference, potentially reducing the energy consumption associated with large language models. The concrete action is the development of two training-free techniques, FreeCache and Guided Diffusion, which resulted in a 12.14x speedup with negligible accuracy degradation. While promising, the technology is still in the applied research phase, with no mention of deployed units or real-world operational data.","key_impact_metrics":["12.14x end-to-end speedup"],"technology_tags":["Diffusion Language Model","KV Caching","Guided Diffusion"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-28T20:57:11.188049Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f17c2b14ac3b","title":"Adaptive Frontier Exploration on Graphs with Applications to Network","content":"arXiv:2505.21671v2 Announce Type: replace Abstract: We study a sequential decision-making problem on a $n$-node graph $\\mathcal{G}$ where each node has an unknown label from a finite set $\\mathbf{\\Omega}$, drawn from a joint distribution $\\mathcal{P}$ that is Markov with respect to $\\mathcal{G}$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $\\mathcal{G}$ is a forest. Our implementation runs in $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|^2)$ time while using $\\mathcal{O}(n \\cdot |\\mathbf{\\Omega}|^2)$ oracle calls to $\\mathcal{P}$ and $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21671","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.456812","language":"en","tags":["csds","mathoc","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":187,"author":"Davin Choo, Yuqi Pan, Tonghan Wang, Milind Tambe, Alastair van Heerden, Cheryl Johnson","raw_content_length":1415,"priority":7,"update_frequency":1,"reading_time_minutes":0.935,"robust_parsing_used":true,"entities":{"organizations":["Gittins","Adaptive Frontier Exploration on Graphs"],"persons":["Markov","\\mathcal{O}(n^2"],"locations":[],"monetary":["n$-node","\\mathcal{G}$","\\mathbf{\\Omega}$"]},"char_count":1414,"language_detected":"en","key_concepts":{"key_phrases":["Adaptive Frontier Exploration","Graphs","Applications","Network","mathcalG","arXiv250521671v2 Announce Type","Abstract","a sequential decision-making problem","a n-node graph","each node"],"filter_categories":{"ai_ml":["Network"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Adaptive Frontier Exploration":2.0,"Graphs":2.0,"Applications":2.0,"Network":2.0,"mathcalG":2.0,"arXiv250521671v2 Announce Type":1.0,"Abstract":1.0,"a sequential decision-making problem":1.0,"a n-node graph":1.0,"each node":1.0}},"age_hours":2.780800013611111,"is_recent":true,"quality_score":1.0,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8915,"joy":0.0231,"surprise":0.0586,"sadness":0.0039,"fear":0.0044,"anger":0.0139,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel algorithm for adaptive frontier exploration on graphs, with potential applications in various domains. The concrete action is the development and testing of a Gittins index-based policy. Evidence is provided through experiments on synthetic and real-world graphs, with a specific example in HIV testing simulations showing improved detection rates. The innovation is at the applied research stage, with no current deployment.","key_impact_metrics":["half the population tested","nearly all positive cases detected"],"technology_tags":["graph algorithms","sequential decision-making","Gittins index"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:57:14.234090Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7e1892d45b6c","title":"CAST: Contrastive Adaptation and Distillation for Semi","content":"arXiv:2505.21904v4 Announce Type: replace Abstract: Instance segmentation demands costly per-pixel annotations and computationally expensive models. We introduce CAST, a semi-supervised knowledge distillation (SSKD) framework that compresses pre-trained vision foundation models (VFM) into compact experts using limited labeled and abundant unlabeled data. CAST unfolds in three stages: (1) domain adaptation of the VFM(s) via self-training with contrastive calibration, (2) knowledge transfer through a unified multi-objective loss, and (3) student refinement to mitigate residual pseudo-label bias. Central to CAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask and class scores to extract informative negatives and enforce clear inter-instance margins. By maintaining this contrastive signal across both adaptation and distillation, we align teacher and student embeddings and fully leverage unlabeled images. On Cityscapes and ADE20K, our ~11x smaller student improves over its zero-shot VFM teacher(s) by +8.5 and +7.1 AP, surpasses adapted teacher(s) by +3.4 and +1.5 AP, and further outperforms state-of-the-art SSKD methods on both benchmarks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21904","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.457217","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu","raw_content_length":1177,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["CAST","VFM","vision foundation models","Contrastive Adaptation and Distillation"],"persons":[],"locations":[],"monetary":[]},"char_count":1176,"language_detected":"en","key_concepts":{"key_phrases":["CAST","Contrastive Adaptation","Distillation","Semi","arXiv250521904v4 Announce Type","Abstract","Instance segmentation","pixel","computationally expensive models","a semi-supervised knowledge distillation SSKD framework"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"CAST":4.0,"Contrastive Adaptation":2.0,"Distillation":2.0,"Semi":2.0,"arXiv250521904v4 Announce Type":1.0,"Abstract":1.0,"Instance segmentation":1.0,"pixel":1.0,"computationally expensive models":1.0,"a semi-supervised knowledge distillation SSKD framework":1.0}},"age_hours":2.7808147908333334,"is_recent":true,"quality_score":1.0,"sentiment_score":4.614,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0772,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9031,"joy":0.0122,"surprise":0.0502,"sadness":0.0051,"fear":0.0083,"anger":0.0154,"disgust":0.0057},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel semi-supervised knowledge distillation framework (CAST) for instance segmentation, achieving improved performance and model compression. The concrete action is the development and testing of this framework on benchmark datasets (Cityscapes and ADE20K), with measurable outcomes like +8.5 and +7.1 AP improvement over the zero-shot VFM teacher. However, it remains at the applied research stage with no real-world deployment.","key_impact_metrics":["+8.5 AP on Cityscapes","+7.1 AP on ADE20K"],"technology_tags":["semi-supervised learning","knowledge distillation","instance segmentation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:17.127365Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_848de0124457","title":"DvD: Unleashing a Generative Paradigm for Document Dewarping via Coordinates","content":"arXiv:2505.21975v2 Announce Type: replace Abstract: Document dewarping aims to rectify deformations in photographic document images, thus improving text readability, which has attracted much attention and made great progress, but it is still challenging to preserve document structures. Given recent advances in diffusion models, it is natural for us to consider their potential applicability to document dewarping. However, it is far from straightforward to adopt diffusion models in document dewarping due to their unfaithful control on highly complex document images (e.g., 2000$times$3000 resolution). In this paper, we propose DvD, the first generative model to tackle document Dewarping via a Diffusion framework. To be specific, DvD introduces a coordinate-level denoising instead of typical pixel-level denoising, generating a mapping for deformation rectification. In addition, we further propose a time-variant condition refinement mechanism to enhance the preservation of document structures. In experiments, we find that current document dewarping benchmarks can not evaluate dewarping models comprehensively. To this end, we present AnyPhotoDoc6300, a rigorously designed large-scale document dewarping benchmark comprising 6,300 real image pairs across three distinct domains, enabling fine-grained evaluation of dewarping models. Comprehensive experiments demonstrate that our proposed DvD can achieve state-of-the-art performance with acceptable computational efficiency on multiple metrics across various benchmarks, including DocUNet, DIR300, and AnyPhotoDoc6300. The new benchmark and code will be publicly available at https://github.com/hanquansanren/DvD.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21975","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.457667","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":216,"author":"Weiguang Zhang, Huangcheng Lu, Maizhen Ning, Xiaowei Huang, Wei Wang, Kaizhu Huang, Qiufeng Wang","raw_content_length":1677,"priority":7,"update_frequency":1,"reading_time_minutes":1.08,"robust_parsing_used":true,"entities":{"organizations":["Coordinates arXiv:2505.21975v2","Diffusion","Dewarping","DvD"],"persons":[],"locations":[],"monetary":[]},"char_count":1676,"language_detected":"en","key_concepts":{"key_phrases":["DvD","a Generative Paradigm","Document Dewarping","Coordinates","diffusion models","Announce Type","Abstract","Document dewarping","deformations","photographic document images"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"DvD":2.0,"a Generative Paradigm":2.0,"Document Dewarping":2.0,"Coordinates":2.0,"diffusion models":2.0,"Announce Type":1.0,"Abstract":1.0,"Document dewarping":1.0,"deformations":1.0,"photographic document images":1.0}},"age_hours":2.7808295641666665,"is_recent":true,"quality_score":1.0,"sentiment_score":9.43,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.886,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9214,"joy":0.033,"surprise":0.0222,"sadness":0.0048,"fear":0.0067,"anger":0.0069,"disgust":0.005},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new algorithm (DvD) for document dewarping. While it introduces a new benchmark (AnyPhotoDoc6300) and achieves state-of-the-art performance on multiple metrics, there's no direct link to climate impact or sustainability. The technology is at the applied research stage, with no deployment data available.","key_impact_metrics":["State-of-the-art performance on DocUNet","State-of-the-art performance on DIR300","State-of-the-art performance on AnyPhotoDoc6300"],"technology_tags":["Document dewarping","Diffusion models","Generative models"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:57:19.975073Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_741c487b9c7d","title":"Let's Reason Formally: Natural","content":"arXiv:2505.23703v3 Announce Type: replace Abstract: Enhancing the mathematical reasoning capabilities of LLMs has garnered significant attention in both the mathematical and computer science communities. Recent works have made substantial progress in both Natural Language (NL) reasoning and Formal Language (FL) reasoning by leveraging the potential of pure Reinforcement Learning (RL) methods on base models. However, RL approaches struggle to impart new capabilities not presented in the base model, highlighting the need to integrate more knowledge like FL into NL math reasoning effectively. Yet, this integration is challenging due to inherent disparities in problem structure and reasoning format between NL and FL. To address these challenges, we introduce **NL-FL HybridReasoning (NFL-HR)**, an end-to-end framework designed to incorporate the FL expert into NL math problem-solving. To bridge the NL and FL input format gap, we propose the NL-FL Problem Alignment method, which reformulates the Question-Answering (QA) problems in NL as existence theorems in FL. Subsequently, the Mixed Problem Input technique we provide enables the FL reasoner to handle both QA and existence problems concurrently. Lastly, we mitigate the NL and FL output format gap in reasoning through an LLM-based Answer Extraction mechanism. Comprehensive experiments demonstrate that the NFL-HR framework achieves **89.80**% and **84.34%** accuracy rates on the MATH-500 and the AMC benchmarks, surpassing the NL baseline by **4.60%** and **4.82%**, respectively. Notably, some problems resolved by our framework remain unsolved by the NL baseline model even under a larger number of trials.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23703","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.458947","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":240,"author":"Ruida Wang, Yuxin Li, Yi R. Fung, Tong Zhang","raw_content_length":1677,"priority":7,"update_frequency":1,"reading_time_minutes":1.2,"robust_parsing_used":true,"entities":{"organizations":["NFL","Reinforcement Learning","Natural Language"],"persons":["Formal Language"],"locations":[],"monetary":[]},"char_count":1676,"language_detected":"en","key_concepts":{"key_phrases":["Reason","Announce Type","Abstract","the mathematical reasoning capabilities","LLMs","significant attention","Recent works","substantial progress","the potential","base models"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reason":2.0,"Announce Type":1.0,"Abstract":1.0,"the mathematical reasoning capabilities":1.0,"LLMs":1.0,"significant attention":1.0,"Recent works":1.0,"substantial progress":1.0,"the potential":1.0,"base models":1.0}},"age_hours":2.7808729180555556,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8767,"joy":0.0202,"surprise":0.0341,"sadness":0.0376,"fear":0.0151,"anger":0.0103,"disgust":0.006},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (NFL-HR) for enhancing mathematical reasoning in LLMs. While the framework achieves improved accuracy rates on benchmarks (89.80% and 84.34% on MATH-500 and AMC), it is currently in the applied research stage with no real-world deployment or economic viability demonstrated. The sustainability impact is indirect, as improved AI reasoning could potentially contribute to solving sustainability challenges, but there are no concrete actions or measurable outcomes related to environmental impact at this stage.","key_impact_metrics":["Accuracy rate on MATH-500: 89.80%","Accuracy rate on AMC benchmarks: 84.34%"],"technology_tags":["Natural Language Processing","Formal Language Reasoning","Reinforcement Learning","Large Language Models"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:57:23.240149Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_99a14cb7ff2c","title":"MAGREF: Masked Guidance for Any","content":"arXiv:2505.23742v2 Announce Type: replace Abstract: We tackle the task of any-reference video generation, which aims to synthesize videos conditioned on arbitrary types and combinations of reference subjects, together with textual prompts. This task faces persistent challenges, including identity inconsistency, entanglement among multiple reference subjects, and copy-paste artifacts. To address these issues, we introduce MAGREF, a unified and effective framework for any-reference video generation. Our approach incorporates masked guidance and a subject disentanglement mechanism, enabling flexible synthesis conditioned on diverse reference images and textual prompts. Specifically, masked guidance employs a region-aware masking mechanism combined with pixel-wise channel concatenation to preserve appearance features of multiple subjects along the channel dimension. This design preserves identity consistency and maintains the capabilities of the pre-trained backbone, without requiring any architectural changes. To mitigate subject confusion, we introduce a subject disentanglement mechanism which injects the semantic values of each subject derived from the text condition into its corresponding visual region. Additionally, we establish a four-stage data pipeline to construct diverse training pairs, effectively alleviating copy-paste artifacts. Extensive experiments on a comprehensive benchmark demonstrate that MAGREF consistently outperforms existing state-of-the-art approaches, paving the way for scalable, controllable, and high-fidelity any-reference video synthesis. Code and model can be found at: https://github.com/MAGREF-Video/MAGREF","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23742","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.459359","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Yufan Deng, Yuanyang Yin, Xun Guo, Yizhi Wang, Jacob Zhiyuan Fang, Shenghai Yuan, Yiding Yang, Angtian Wang, Bo Liu, Haibin Huang, Chongyang Ma","raw_content_length":1661,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1660,"language_detected":"en","key_concepts":{"key_phrases":["MAGREF","Masked Guidance","Any","arXiv250523742v2","Announce Type","Abstract","the task","any-reference video generation","which","videos"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"MAGREF":3.0,"Masked Guidance":2.0,"Any":2.0,"arXiv250523742v2":1.0,"Announce Type":1.0,"Abstract":1.0,"the task":1.0,"any-reference video generation":1.0,"which":1.0,"videos":1.0}},"age_hours":2.7808866616666665,"is_recent":true,"quality_score":0.7,"sentiment_score":8.591999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7184,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.952,"joy":0.0041,"surprise":0.0092,"sadness":0.0058,"fear":0.0117,"anger":0.0126,"disgust":0.0046},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for video generation. While the technology itself doesn't directly address climate change, its potential to reduce the need for physical video shoots and travel could indirectly contribute to sustainability. The research is published on arXiv, suggesting peer review, but there are no deployed units or measured outcomes related to sustainability.","key_impact_metrics":[],"technology_tags":["AI","Video Generation","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:25.965558Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6ecb96a32a3d","title":"ThinkGeo: Evaluating Tool","content":"arXiv:2505.23752v2 Announce Type: replace Abstract: Recent progress in large language models (LLMs) has enabled tool-augmented agents capable of solving complex real-world tasks through step-by-step reasoning. However, existing evaluations often focus on general-purpose or multimodal scenarios, leaving a gap in domain-specific benchmarks that assess tool-use capabilities in complex remote sensing use cases. We present ThinkGeo, an agentic benchmark designed to evaluate LLM-driven agents on remote sensing tasks via structured tool use and multi-step planning. Inspired by tool-interaction paradigms, ThinkGeo includes human-curated queries spanning a wide range of real-world applications such as urban planning, disaster assessment and change analysis, environmental monitoring, transportation analysis, aviation monitoring, recreational infrastructure, and industrial site analysis. Queries are grounded in satellite or aerial imagery, including both optical RGB and SAR data, and require agents to reason through a diverse toolset. We implement a ReAct-style interaction loop and evaluate both open and closed-source LLMs (e.g., GPT-4o, Qwen2.5) on 486 structured agentic tasks with 1,773 expert-verified reasoning steps. The benchmark reports both step-wise execution metrics and final answer correctness. Our analysis reveals notable disparities in tool accuracy and planning consistency across models. ThinkGeo provides the first extensive testbed for evaluating how tool-enabled LLMs handle spatial reasoning in remote sensing.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23752","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.459791","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Akashah Shabbir, Muhammad Akhtar Munir, Akshay Dudhane, Muhammad Umer Sheikh, Muhammad Haris Khan, Paolo Fraccaro, Juan Bernabe Moreno, Fahad Shahbaz Khan, Salman Khan","raw_content_length":1540,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["RGB","ThinkGeo"],"persons":[],"locations":[],"monetary":[]},"char_count":1539,"language_detected":"en","key_concepts":{"key_phrases":["ThinkGeo","Evaluating Tool","arXiv250523752v2","Announce Type","Abstract","Recent progress","large language models","LLMs","tool-augmented agents","complex real-world tasks"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ThinkGeo":3.0,"Evaluating Tool":2.0,"arXiv250523752v2":1.0,"Announce Type":1.0,"Abstract":1.0,"Recent progress":1.0,"large language models":1.0,"LLMs":1.0,"tool-augmented agents":1.0,"complex real-world tasks":1.0}},"age_hours":2.780901414722222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8915,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7783,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8951,"joy":0.0058,"surprise":0.0216,"sadness":0.0037,"fear":0.0393,"anger":0.0214,"disgust":0.0131},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a benchmark (ThinkGeo) for evaluating LLMs in remote sensing tasks, which could indirectly contribute to sustainability by improving the efficiency and accuracy of environmental monitoring, disaster assessment, and urban planning. The benchmark includes 486 structured agentic tasks with 1,773 expert-verified reasoning steps, providing some evidence for its technical credibility, but it is still in the applied research phase with no deployed units.","key_impact_metrics":["486 structured agentic tasks","1,773 expert-verified reasoning steps"],"technology_tags":["LLM","remote sensing","agentic benchmark"],"sdg_alignment":[9,11,13,15],"analyzed_at":"2025-10-28T20:57:28.838007Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c79070f5cd57","title":"FlowNIB: An Information Bottleneck Analysis of Bidirectional vs. Unidirectional Language Models","content":"arXiv:2506.00859v3 Announce Type: replace Abstract: Bidirectional language models have better context understanding and perform better than unidirectional models on natural language understanding tasks, yet the theoretical reasons behind this advantage remain unclear. In this work, we investigate this disparity through the lens of the Information Bottleneck (IB) principle, which formalizes a trade-off between compressing input information and preserving task-relevant content. We propose FlowNIB, a dynamic and scalable method for estimating mutual information during training that addresses key limitations of classical IB approaches, including computational intractability and fixed trade-off schedules. Theoretically, we show that bidirectional models retain more mutual information and exhibit higher effective dimensionality than unidirectional models. To support this, we present a generalized framework for measuring representational complexity and prove that bidirectional representations are strictly more informative under mild conditions. We further validate our findings through extensive experiments across multiple models and tasks using FlowNIB, revealing how information is encoded and compressed throughout training. Together, our work provides a principled explanation for the effectiveness of bidirectional architectures and introduces a practical tool for analyzing information flow in deep language models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.00859","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.460345","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":181,"author":"Md Kowsher, Nusrat Jahan Prottasha, Shiyun Xu, Shetu Mohanto, Ozlem Garibay, Niloofar Yousefi, Chen Chen","raw_content_length":1432,"priority":7,"update_frequency":1,"reading_time_minutes":0.905,"robust_parsing_used":true,"entities":{"organizations":["An Information Bottleneck Analysis of Bidirectional","Unidirectional Language Models arXiv:2506.00859v3","the Information Bottleneck"],"persons":[],"locations":[],"monetary":[]},"char_count":1431,"language_detected":"en","key_concepts":{"key_phrases":["FlowNIB An Information Bottleneck Analysis","Bidirectional","Unidirectional Language Models","arXiv250600859v3 Announce Type","Abstract","Bidirectional language models","better context understanding","unidirectional models","natural language understanding tasks","the theoretical reasons"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"FlowNIB An Information Bottleneck Analysis":2.0,"Bidirectional":2.0,"Unidirectional Language Models":2.0,"arXiv250600859v3 Announce Type":1.0,"Abstract":1.0,"Bidirectional language models":1.0,"better context understanding":1.0,"unidirectional models":1.0,"natural language understanding tasks":1.0,"the theoretical reasons":1.0}},"age_hours":2.7809149874999997,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1005,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8201,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8297,"joy":0.0162,"surprise":0.0763,"sadness":0.0099,"fear":0.0178,"anger":0.0286,"disgust":0.0217},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical analysis and a novel method (FlowNIB) for understanding language models. While it doesn't directly address climate change, understanding and improving AI efficiency could indirectly reduce the energy consumption of large language models, which is a growing concern. The research is validated through experiments and presents metrics on information retention and dimensionality.","key_impact_metrics":["Mutual information retained","Effective dimensionality"],"technology_tags":["Information Bottleneck","Language Models","AI Efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:31.509818Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_0f0b506e60f9","title":"Propagation","content":"arXiv:2506.01342v2 Announce Type: replace Abstract: Identifying the impact scope and scale is critical for software supply chain vulnerability assessment. However, existing studies face substantial limitations. First, prior studies either work at coarse package-level granularity, producing many false positives, or fail to accomplish whole-ecosystem vulnerability propagation analysis. Second, although vulnerability assessment indicators like CVSS characterize individual vulnerabilities, no metric exists to specifically quantify the dynamic impact of vulnerability propagation across software supply chains. To address these limitations and enable accurate and comprehensive vulnerability impact assessment, we propose a novel approach: (i) a hierarchical worklist-based algorithm for whole-ecosystem and call-graph-level vulnerability propagation analysis and (ii) the Vulnerability Propagation Scoring System (VPSS), a dynamic metric to quantify the scope and evolution of vulnerability impacts in software supply chains. We implement a prototype of our approach in the Java Maven ecosystem and evaluate it on 100 real-world vulnerabilities. Experimental results demonstrate that our approach enables effective ecosystem-wide vulnerability propagation analysis, and provides a practical, quantitative measure of vulnerability impact through VPSS.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01342","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.468286","language":"en","tags":["csse","computer-science","preprints","cscr","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Bonan Ruan, Zhiwei Lin, Jiahao Liu, Chuqi Zhang, Kaihang Ji, Zhenkai Liang","raw_content_length":1353,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["CVSS","VPSS","Propagation arXiv:2506.01342v2 Announce Type: replace Abstract","the Vulnerability Propagation Scoring System"],"persons":[],"locations":[],"monetary":[]},"char_count":1352,"language_detected":"en","key_concepts":{"key_phrases":["Propagation","Announce Type","Abstract","the impact scope","scale","software supply chain vulnerability assessment","existing studies","substantial limitations","prior studies","coarse package-level granularity"],"filter_categories":{"ai_ml":["software supply chain vulnerability assessment"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Propagation":2.0,"Announce Type":1.0,"Abstract":1.0,"the impact scope":1.0,"scale":1.0,"software supply chain vulnerability assessment":1.0,"existing studies":1.0,"substantial limitations":1.0,"prior studies":1.0,"coarse package-level granularity":1.0}},"age_hours":2.7809284188888888,"is_recent":true,"quality_score":1.0,"sentiment_score":2.8925,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4215,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7696,"joy":0.0034,"surprise":0.0252,"sadness":0.087,"fear":0.0293,"anger":0.0254,"disgust":0.0602},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel approach to vulnerability propagation analysis in software supply chains, which indirectly supports sustainability by improving the security and reliability of software used in climate-related technologies. While the approach is implemented in a prototype and evaluated on real-world vulnerabilities, there is no direct deployment or measurable impact on GHG emissions or other sustainability metrics. The VPSS metric provides a quantitative measure of vulnerability impact, but its direct link to environmental sustainability is weak.","key_impact_metrics":["VPSS score","Number of vulnerabilities identified"],"technology_tags":["Software vulnerability analysis","Supply chain security"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-28T20:57:34.650439Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2c97691b861e","title":"MotionSight: Boosting Fine","content":"arXiv:2506.01674v2 Announce Type: replace Abstract: Despite advancements in Multimodal Large Language Models (MLLMs), their proficiency in fine-grained video motion understanding remains critically limited. They often lack inter-frame differencing and tend to average or ignore subtle visual cues. Furthermore, while visual prompting has shown potential in static images, its application to video's temporal complexities, particularly for fine-grained motion understanding, remains largely unexplored. We investigate whether inherent capability can be unlocked and boost MLLMs' motion perception and enable distinct visual signatures tailored to decouple object and camera motion cues. In this study, we introduce MotionSight, a novel zero-shot method pioneering object-centric visual spotlight and motion blur as visual prompts to effectively improve fine-grained motion understanding without training. To convert this into valuable data assets, we curated MotionVid-QA, the first large-scale dataset for fine-grained video motion understanding, with hierarchical annotations including SFT and preference data, {\\Theta}(40K) video clips and {\\Theta}(87K) QAs. Experiments show MotionSight achieves state-of-the-art open-source performance and competitiveness with commercial models. In particular, for fine-grained motion understanding we present a novel zero-shot technique and a large-scale, high-quality dataset. All the code and annotations will be publicly available.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01674","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.468793","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":186,"author":"Yipeng Du, Tiehan Fan, Kepan Nan, Rui Xie, Penghao Zhou, Xiang Li, Jian Yang, Zhenheng Yang, Ying Tai","raw_content_length":1474,"priority":7,"update_frequency":1,"reading_time_minutes":0.93,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Large Language Models","MotionVid","MotionSight"],"persons":[],"locations":[],"monetary":[]},"char_count":1473,"language_detected":"en","key_concepts":{"key_phrases":["MotionSight","Fine","Announce Type","Abstract","advancements","Multimodal Large Language Models","MLLMs","their proficiency","fine-grained video motion understanding","inter-frame differencing"],"filter_categories":{"ai_ml":["Multimodal Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MotionSight":2.0,"Fine":2.0,"Announce Type":1.0,"Abstract":1.0,"advancements":1.0,"Multimodal Large Language Models":1.0,"MLLMs":1.0,"their proficiency":1.0,"fine-grained video motion understanding":1.0,"inter-frame differencing":1.0}},"age_hours":2.7809427372222224,"is_recent":true,"quality_score":1.0,"sentiment_score":3.194,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3612,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9385,"joy":0.0024,"surprise":0.016,"sadness":0.0135,"fear":0.0045,"anger":0.012,"disgust":0.0131},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research introduces a novel zero-shot method, MotionSight, for improving fine-grained motion understanding in MLLMs. The concrete action is the creation of a new method and a large-scale dataset, MotionVid-QA, with 40K video clips and 87K QAs. The evidence is based on experiments showing state-of-the-art open-source performance, but it's still in the research phase with no deployment.","key_impact_metrics":["40K video clips","87K QAs"],"technology_tags":["Multimodal Large Language Models","video motion understanding","visual prompting"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:57:37.704716Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2472fcb7b869","title":"FreeTacMan: Robot-free Visuo","content":"arXiv:2506.01941v2 Announce Type: replace Abstract: Enabling robots with contact-rich manipulation remains a pivotal challenge in robot learning, which is substantially hindered by the data collection gap, including its inefficiency and limited sensor setup. While prior work has explored handheld paradigms, their rod-based mechanical structures remain rigid and unintuitive, providing limited tactile feedback and posing challenges for human operators. Motivated by the dexterity and force feedback of human motion, we propose FreeTacMan, a human-centric and robot-free data collection system for accurate and efficient robot manipulation. Concretely, we design a wearable gripper with dual visuo-tactile sensors for data collection, which can be worn by human fingers for intuitive control. A high-precision optical tracking system is introduced to capture end-effector poses while synchronizing visual and tactile feedback simultaneously. We leverage FreeTacMan to collect a large-scale multimodal dataset, comprising over 3000k paired visual-tactile images with end-effector poses, 10k demonstration trajectories across 50 diverse contact-rich manipulation tasks. FreeTacMan achieves multiple improvements in data collection performance compared to prior works, and enables effective policy learning for contact-rich manipulation tasks with self-collected dataset. The full suite of hardware specifications and the dataset will be released to facilitate reproducibility and support research in visuo-tactile manipulation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01941","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.469703","language":"en","tags":["research","csro","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Longyan Wu, Checheng Yu, Jieji Ren, Li Chen, Yufei Jiang, Ran Huang, Guoying Gu, Hongyang Li","raw_content_length":1527,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Visuo","Announce Type"],"locations":[],"monetary":[]},"char_count":1526,"language_detected":"en","key_concepts":{"key_phrases":["Robot-free Visuo","Announce Type","Abstract","Enabling robots","contact-rich manipulation","a pivotal challenge","robot learning","which","the data collection gap","its inefficiency and limited sensor setup"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Robot-free Visuo":2.0,"Announce Type":1.0,"Abstract":1.0,"Enabling robots":1.0,"contact-rich manipulation":1.0,"a pivotal challenge":1.0,"robot learning":1.0,"which":1.0,"the data collection gap":1.0,"its inefficiency and limited sensor setup":1.0}},"age_hours":2.7809718352777777,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8685,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2263,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.5759,"joy":0.0073,"surprise":0.0157,"sadness":0.04,"fear":0.19,"anger":0.0726,"disgust":0.0984},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving robot manipulation through better data collection. While it doesn't directly address climate change, improved robotic manipulation could potentially lead to efficiencies in various industries, indirectly reducing emissions. The system has generated a dataset of 3000k paired visual-tactile images and 10k demonstration trajectories, but it's still in the research and development phase.","key_impact_metrics":["3000k paired visual-tactile images","10k demonstration trajectories"],"technology_tags":["robot manipulation","visuo-tactile sensors","optical tracking"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:40.637744Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c21ebb7f6c8c","title":"IMAGHarmony: Controllable Image Editing with Consistent Object Quantity and Layout","content":"arXiv:2506.01949v2 Announce Type: replace Abstract: Recent diffusion models have advanced image editing by improving fidelity and controllability across creative and personalized applications. However, multi-object scenes remain challenging, as reliable control over object categories, counts, and spatial layout is difficult to achieve. For that, we first study quantity and layout consistent image editing, abbreviated as QL-Edit, which targets control of object quantity and spatial layout in multi-object scenes. Then, we present IMAGHarmony, a straightforward framework featuring a plug-and-play harmony aware (HA) module that fuses perception semantics while modeling object counts and locations, resulting in accurate edits and strong structural consistency. We further observe that diffusion models are sensitive to the choice of initial noise and tend to prefer certain noise patterns. Based on this finding, we present a preference-guided noise selection (PNS) strategy that selects semantically aligned initial noise through vision and language matching, thereby further improving generation stability and layout consistency in multiple object editing. To support evaluation, we develop HarmonyBench, a comprehensive benchmark that covers a diverse range of quantity and layout control scenarios. Extensive experiments demonstrate that IMAGHarmony outperforms prior methods in both structural alignment and semantic accuracy, utilizing only 200 training images and 10.6M of trainable parameters. Code, models, and data are available at https://github.com/muzishen/IMAGHarmony.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.01949","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.470130","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":208,"author":"Fei Shen, Yutong Gao, Jian Yu, Xiaoyu Du, Jinhui Tang","raw_content_length":1588,"priority":7,"update_frequency":1,"reading_time_minutes":1.04,"robust_parsing_used":true,"entities":{"organizations":["Consistent Object Quantity","IMAGHarmony","Layout arXiv:2506.01949v2","QL-Edit"],"persons":[],"locations":[],"monetary":[]},"char_count":1587,"language_detected":"en","key_concepts":{"key_phrases":["IMAGHarmony","Controllable Image Editing","Consistent Object Quantity","Layout","spatial layout","Announce Type","Abstract","Recent diffusion models","advanced image","fidelity"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"IMAGHarmony":2.0,"Controllable Image Editing":2.0,"Consistent Object Quantity":2.0,"Layout":2.0,"spatial layout":2.0,"Announce Type":1.0,"Abstract":1.0,"Recent diffusion models":1.0,"advanced image":1.0,"fidelity":1.0}},"age_hours":2.7809866355555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.5015,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7003,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9247,"joy":0.0197,"surprise":0.0276,"sadness":0.0043,"fear":0.0115,"anger":0.008,"disgust":0.0041},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":2,"systemic_impact":1,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework (IMAGHarmony) for controllable image editing. While the technology itself doesn't directly address climate change, it demonstrates improved performance using only 200 training images and 10.6M trainable parameters, suggesting potential resource efficiency gains in AI model development. The research is in the early stages, with code and models available but no real-world deployment.","key_impact_metrics":["200 training images","10.6M trainable parameters"],"technology_tags":["diffusion models","image editing","artificial intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:57:43.310197Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2b32890fd89a","title":"OASIS: Online Sample Selection for Continual Visual Instruction Tuning","content":"arXiv:2506.02011v2 Announce Type: replace Abstract: In continual instruction tuning (CIT) scenarios, where new instruction tuning data continuously arrive in an online streaming manner, training delays from large-scale data significantly hinder real-time adaptation. Data selection can mitigate this overhead, but existing strategies often rely on pretrained reference models, which are impractical in CIT setups since future data are unknown. Recent reference model-free online sample selection methods address this, but typically select a fixed number of samples per batch (e.g., top-k), making them vulnerable to distribution shifts where informativeness varies across batches. To address these limitations, we propose OASIS, an adaptive online sample selection approach for CIT that (1) selects informative samples by estimating each sample's informativeness relative to all previously seen data, beyond batch-level constraints, and (2) minimizes informative redundancy of selected samples through iterative selection score updates. Experiments on various large foundation models show that OASIS, using only 25 percent of the data, achieves comparable performance to full-data training and outperforms the state-of-the-art sampling methods.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.02011","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.470555","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":165,"author":"Minjae Lee, Minhyuk Seo, Tingyu Qu, Tinne Tuytelaars, Jonghyun Choi","raw_content_length":1245,"priority":7,"update_frequency":1,"reading_time_minutes":0.825,"robust_parsing_used":true,"entities":{"organizations":["CIT","OASIS"],"persons":[],"locations":[],"monetary":[]},"char_count":1244,"language_detected":"en","key_concepts":{"key_phrases":["OASIS","Online Sample Selection","Continual Visual Instruction Tuning","Announce Type","Abstract","continual instruction tuning CIT scenarios","new instruction tuning data","an online streaming manner","training delays","large-scale data"],"filter_categories":{"ai_ml":["training delays"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"OASIS":2.0,"Online Sample Selection":2.0,"Continual Visual Instruction Tuning":2.0,"Announce Type":1.0,"Abstract":1.0,"continual instruction tuning CIT scenarios":1.0,"new instruction tuning data":1.0,"an online streaming manner":1.0,"training delays":1.0,"large-scale data":1.0}},"age_hours":2.7810016597222225,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8657,"joy":0.0051,"surprise":0.0273,"sadness":0.0353,"fear":0.025,"anger":0.0263,"disgust":0.0153},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the efficiency of continual instruction tuning for large foundation models, potentially reducing the computational resources and energy required for training. The article claims OASIS achieves comparable performance to full-data training using only 25% of the data, but this is based on experiments and not real-world deployment. It is still in the applied research stage.","key_impact_metrics":["25 percent data usage","comparable performance to full-data training"],"technology_tags":["machine learning","data selection","continual learning"],"sdg_alignment":[4,9,12],"analyzed_at":"2025-10-28T20:57:46.161720Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b87fd5ef870a","title":"Dissecting Logical Reasoning in LLMs: A Fine","content":"arXiv:2506.04810v2 Announce Type: replace Abstract: Logical reasoning is a core capability for large language models (LLMs), yet existing benchmarks that rely solely on final-answer accuracy fail to capture the quality of the reasoning process. To address this, we introduce FineLogic, a fine-grained evaluation framework that assesses logical reasoning across three dimensions: overall accuracy, stepwise soundness, and representation-level probing. Leveraging this framework, we conduct a comprehensive study on how different supervision formats in fine-tuning shape reasoning abilities. We fine-tune LLMs on four supervision styles: one in natural language and three symbolic variants. We find a key trade-off: natural language supervision excels at generalization to out-of-distribution and long-chain problems, whereas symbolic supervision is superior at instilling structurally sound, atomic reasoning steps. Furthermore, our probing analysis indicates that fine-tuning primarily refines the model's step-by-step generation process, rather than improving its ability to converge on an answer early. Together, our framework and analysis provide a more rigorous lens for evaluating and improving logical reasoning in LLMs. The code is available at https://github.com/YujunZhou/FineLogic.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04810","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.470963","language":"en","tags":["cslo","computer-science","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Yujun Zhou, Jiayi Ye, Zipeng Ling, Yufei Han, Yue Huang, Haomin Zhuang, Zhenwen Liang, Kehan Guo, Taicheng Guo, Xiangqi Wang, Xiangliang Zhang","raw_content_length":1292,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["FineLogic","Dissecting Logical Reasoning"],"persons":[],"locations":[],"monetary":[]},"char_count":1291,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Logical Reasoning","arXiv250604810v2 Announce Type","Abstract","Logical reasoning","a core capability","large language models","existing benchmarks","final-answer accuracy","the quality"],"filter_categories":{"ai_ml":["LLMs","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Logical Reasoning":2.0,"arXiv250604810v2 Announce Type":1.0,"Abstract":1.0,"Logical reasoning":1.0,"a core capability":1.0,"large language models":1.0,"existing benchmarks":1.0,"final-answer accuracy":1.0,"the quality":1.0}},"age_hours":2.781016401111111,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8156,"joy":0.0075,"surprise":0.0606,"sadness":0.0257,"fear":0.0156,"anger":0.0388,"disgust":0.0363},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the logical reasoning capabilities of LLMs, which could indirectly support sustainability efforts by enabling better data analysis and decision-making in climate-related fields. However, there are no concrete actions or measurable outcomes directly related to reducing GHG emissions or promoting environmental sustainability at this stage. The research is still in the applied research phase, with no deployment or commercialization mentioned.","key_impact_metrics":[],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:48.995305Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_feb0cd02b67c","title":"Can Vision Language Models Infer Human Gaze Direction? A Controlled Study","content":"arXiv:2506.05412v2 Announce Type: replace Abstract: The ability to infer what others are looking at is a critical component of a theory of mind that underpins natural human-AI interaction. We characterized this skill in 111 Vision Language Models (VLMs) and human participants (N = 65) using photos taken with manipulated difficulty and variability. We found that 94 of the 111 VLMs were not better than random guessing, while humans achieved near-ceiling accuracy. VLMs respond with each choice almost equally frequently. Are they randomly guessing? At least for five top-tier VLMs, their performance was above chance, declined with increasing task difficulty, but barely varied across different prompts and scene objects. These behavioral patterns cannot be explained by considering VLMs as random guessers. Instead, they likely utilize head orientation but not eye appearance to infer gaze direction, such that their performance is imperfect, subject to the task difficulty, but robust to superficial perceptual variations. This suggests that VLMs, lacking effective gaze inference skills, have yet to become technologies that can naturally interact with humans, but the potential remains.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05412","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.471765","language":"en","tags":["cscl","computer-science","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":175,"author":"Zory Zhang, Pinyuan Feng, Bingyang Wang, Tianwei Zhao, Suyang Yu, Qingying Gao, Hokin Deng, Ziqiao Ma, Yijiang Li, Dezhi Luo","raw_content_length":1193,"priority":7,"update_frequency":1,"reading_time_minutes":0.875,"robust_parsing_used":true,"entities":{"organizations":["Vision Language Models"],"persons":["VLMs"],"locations":[],"monetary":[]},"char_count":1192,"language_detected":"en","key_concepts":{"key_phrases":["Vision Language Models","A Controlled Study","VLMs","Announce Type","Abstract","The ability","what","others","a critical component","a theory"],"filter_categories":{"research_academic":["A Controlled Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Vision Language Models":2.0,"A Controlled Study":2.0,"VLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"The ability":1.0,"what":1.0,"others":1.0,"a critical component":1.0,"a theory":1.0}},"age_hours":2.781046216944444,"is_recent":true,"quality_score":1.0,"sentiment_score":3.8609999999999998,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2278,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8406,"joy":0.0056,"surprise":0.0713,"sadness":0.0136,"fear":0.008,"anger":0.0168,"disgust":0.0442},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the capabilities of VLMs to infer human gaze, finding that most perform poorly. While the research is technically sound and peer-reviewed, it's in the early stages and doesn't directly address climate change or sustainability, but it is a step towards more natural human-AI interaction which could have indirect impacts.","key_impact_metrics":["94 out of 111 VLMs performed no better than random guessing","Humans achieved near-ceiling accuracy"],"technology_tags":["Vision Language Models","Artificial Intelligence","Gaze Inference"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:52.929226Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a7dbd176c19b","title":"Feedback Guidance of Diffusion Models","content":"arXiv:2506.06085v2 Announce Type: replace Abstract: While Classifier-Free Guidance (CFG) has become standard for improving sample fidelity in conditional diffusion models, it can harm diversity and induce memorization by applying constant guidance regardless of whether a particular sample needs correction. We propose FeedBack Guidance (FBG), which uses a state-dependent coefficient to self-regulate guidance amounts based on need. Our approach is derived from first principles by assuming the learned conditional distribution is linearly corrupted by the unconditional distribution, contrasting with CFG's implicit multiplicative assumption. Our scheme relies on feedback of its own predictions about the conditional signal informativeness to adapt guidance dynamically during inference, challenging the view of guidance as a fixed hyperparameter. The approach is benchmarked on ImageNet512x512, where it significantly outperforms Classifier-Free Guidance and is competitive to Limited Interval Guidance (LIG) while benefitting from a strong mathematical framework. On Text-To-Image generation, we demonstrate that, as anticipated, our approach automatically applies higher guidance scales for complex prompts than for simpler ones and that it can be easily combined with existing guidance schemes such as CFG or LIG.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.06085","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.472165","language":"en","tags":["research","cscv","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":176,"author":"Felix Koulischer, Florian Handke, Johannes Deleu, Thomas Demeester, Luca Ambrogioni","raw_content_length":1321,"priority":7,"update_frequency":1,"reading_time_minutes":0.88,"robust_parsing_used":true,"entities":{"organizations":["Classifier-Free Guidance","CFG"],"persons":[],"locations":[],"monetary":[]},"char_count":1320,"language_detected":"en","key_concepts":{"key_phrases":["Feedback Guidance","Diffusion Models","arXiv250606085v2 Announce Type","Abstract","Classifier-Free Guidance","CFG","sample fidelity","conditional diffusion models","diversity","memorization"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Feedback Guidance":2.0,"Diffusion Models":2.0,"arXiv250606085v2 Announce Type":1.0,"Abstract":1.0,"Classifier-Free Guidance":1.0,"CFG":1.0,"sample fidelity":1.0,"conditional diffusion models":1.0,"diversity":1.0,"memorization":1.0}},"age_hours":2.7810600316666663,"is_recent":true,"quality_score":1.0,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8321,"joy":0.0085,"surprise":0.0132,"sadness":0.0117,"fear":0.0188,"anger":0.0494,"disgust":0.0662},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel approach to improve the fidelity and diversity of diffusion models, which could indirectly impact sustainability by improving the efficiency of AI models used in various sectors. The article benchmarks the proposed method on ImageNet512x512 and Text-To-Image generation, showing improved performance compared to existing methods. However, it is still in the research phase with no immediate deployment or quantifiable environmental impact.","key_impact_metrics":["Improved ImageNet512x512 performance","Improved Text-To-Image generation"],"technology_tags":["Diffusion Models","Classifier-Free Guidance","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:57:56.180872Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3cd62da664ac","title":"Intention","content":"arXiv:2506.08902v2 Announce Type: replace Abstract: Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or compute resources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on $36$ state-based and $4$ image-based benchmark tasks demonstrate that the proposed method achieves $1.8 \\times$ median improvement in returns and increases success rates by $36\\%$. Website: https://chongyi-zheng.github.io/infom Code: https://github.com/chongyi-zheng/infom","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.08902","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.474268","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":239,"author":"Chongyi Zheng, Seohong Park, Sergey Levine, Benjamin Eysenbach","raw_content_length":1733,"priority":7,"update_frequency":1,"reading_time_minutes":1.195,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1732,"language_detected":"en","key_concepts":{"key_phrases":["Intention","Announce Type","Abstract","Large-scale pre","training","machine learning research","large foundation models","anyone","the community","those"],"filter_categories":{"ai_ml":["training","machine learning research"],"research_academic":["machine learning research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Intention":2.0,"Announce Type":1.0,"Abstract":1.0,"Large-scale pre":1.0,"training":1.0,"machine learning research":1.0,"large foundation models":1.0,"anyone":1.0,"the community":1.0,"those":1.0}},"age_hours":2.781119452222222,"is_recent":true,"quality_score":0.7,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9074,"joy":0.0266,"surprise":0.0439,"sadness":0.0035,"fear":0.0042,"anger":0.0107,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (InFOM) for pre-training reinforcement learning models, showing a 1.8x median improvement in returns and a 36% increase in success rates across benchmark tasks. While the research is promising, it is still in the applied research stage with no real-world deployments or economic viability demonstrated. The potential climate impact is indirect, as it could improve the efficiency of RL agents used in climate-related applications, but this is not explicitly addressed or quantified.","key_impact_metrics":["1.8x median improvement in returns","36% increase in success rates"],"technology_tags":["reinforcement learning","machine learning","flow matching"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:00.344519Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3a93a8f25efc","title":"ReasonMed: A 370K Multi","content":"arXiv:2506.09513v3 Announce Type: replace Abstract: Reasoning-based large language models have excelled in mathematics and programming, yet their potential in knowledge-intensive medical question answering remains underexplored and insufficiently validated in clinical contexts. To bridge this gap, we introduce ReasonMed, the largest medical reasoning dataset to date, comprising 370k high-quality examples distilled from 1.75 million initial reasoning paths generated by complementary LLMs and curated through a cost-efficient easy-medium-difficult (EMD) pipeline. ReasonMed is built through a multi-agent generation, verification, and refinement process, in which an Error Refiner improves reasoning paths by correcting error-prone steps identified by a verifier. Using ReasonMed, we investigate effective strategies for training medical reasoning models and find that integrating detailed CoT reasoning with concise answer summaries yields the most robust fine-tuning results. Models trained on ReasonMed set a new benchmark: ReasonMed-7B surpasses the prior best sub-10B models by 4.17% and even exceeds LLaMA3.1-70B on PubMedQA by 4.60%. When scaled to ReasonMed-14B, it remains highly competitive, underscoring consistent scaling potential. The codes and datasets are available at https://github.com/YuSun-Work/ReasonMed.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.09513","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.474713","language":"en","tags":["csma","computer-science","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Yu Sun, Xingyu Qian, Weiwen Xu, Hao Zhang, Chenghao Xiao, Long Li, Deli Zhao, Wenbing Huang, Tingyang Xu, Qifeng Bai, Yu Rong","raw_content_length":1329,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":["CoT","ReasonMed","EMD","K Multi arXiv:2506.09513v3 Announce"],"persons":[],"locations":[],"monetary":[]},"char_count":1328,"language_detected":"en","key_concepts":{"key_phrases":["ReasonMed","arXiv250609513v3 Announce Type","Abstract","Reasoning-based large language models","mathematics","programming","their potential","knowledge-intensive medical question","clinical contexts","this gap"],"filter_categories":{"ai_ml":["Reasoning-based large language models"],"engineering":["programming"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ReasonMed":3.0,"arXiv250609513v3 Announce Type":1.0,"Abstract":1.0,"Reasoning-based large language models":1.0,"mathematics":1.0,"programming":1.0,"their potential":1.0,"knowledge-intensive medical question":1.0,"clinical contexts":1.0,"this gap":1.0}},"age_hours":2.7811340416666663,"is_recent":true,"quality_score":1.0,"sentiment_score":8.1245,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6249,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8398,"joy":0.0082,"surprise":0.0321,"sadness":0.0173,"fear":0.059,"anger":0.0321,"disgust":0.0115},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a large language model (LLM) dataset for medical reasoning. While improved medical reasoning could indirectly contribute to sustainability by optimizing healthcare resource allocation, the direct climate impact is minimal at this stage. The project is currently in the applied research phase, with the dataset and code available but no deployed applications.","key_impact_metrics":["4.17% performance increase","4.60% performance increase"],"technology_tags":["Large Language Models","Medical Reasoning","Artificial Intelligence"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:58:03.123462Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b6fa10ea9dae","title":"Think With Videos For Agentic Long","content":"arXiv:2506.10821v4 Announce Type: replace Abstract: Long-video understanding~(LVU) is a challenging problem in computer vision. Existing methods either downsample frames for single-pass reasoning, sacrificing fine-grained details, or depend on textual reasoning over task-agnostic representations, hindering task-specific perception and exploration. In this paper, we propose VideoExplorer, a framework grounded in the principle of ``thinking with video'', which naturally intertwines planning, temporal grounding, and scalable perception into a coherent reasoning process. Rather than reasoning over a static context, VideoExplorer iteratively formulates sub-questions, locates relevant moments, and performs task-oriented, temporally scalable video understanding until reaching the final answer, enabling faithful, efficient, and interpretable reasoning. To address the lack of LVU training resources, we construct a long-video reasoning dataset using difficulty-adaptive sampling to ensure high-quality trajectories on complex tasks. Building on this dataset, we design a two-stage training pipeline: supervised trajectory initialization followed by trajectory-level preference optimization, encouraging adaptive temporal grounding and iterative information integration guided by downstream rewards. Extensive evaluations on popular long-video understanding and reasoning benchmarks demonstrate VideoExplorer's significant advantage over existing baselines, highlighting its robustness, adaptability, and efficiency. Our code is made publicly available in this repository(https://github.com/yhy-2000/VideoDeepResearch).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.10821","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.475128","language":"en","tags":["computer-science","preprints","csai","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Yan Shu, Nicu Sebe, Ji-Rong Wen, Zhicheng Dou","raw_content_length":1623,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["LVU"],"persons":["Announce Type","VideoExplorer"],"locations":[],"monetary":[]},"char_count":1622,"language_detected":"en","key_concepts":{"key_phrases":["Videos","Agentic Long","arXiv250610821v4","Announce Type","Abstract","Long-video understandingLVU","a challenging problem","computer vision","Existing methods","either downsample frames"],"filter_categories":{"ai_ml":["computer vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Videos":2.0,"Agentic Long":2.0,"arXiv250610821v4":1.0,"Announce Type":1.0,"Abstract":1.0,"Long-video understandingLVU":1.0,"a challenging problem":1.0,"computer vision":1.0,"Existing methods":1.0,"either downsample frames":1.0}},"age_hours":2.7811488375,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.821,"joy":0.0093,"surprise":0.0386,"sadness":0.023,"fear":0.0509,"anger":0.0393,"disgust":0.0179},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel AI framework for long-video understanding. While potentially useful for optimizing various processes, including those related to sustainability, it is currently in the basic research phase with no concrete deployments or measurable outcomes related to climate impact. The technical credibility is high due to the research nature and public code availability.","key_impact_metrics":[],"technology_tags":["AI","Computer Vision","Long-Video Understanding"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:05.886797Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_fd7ff1bccbf0","title":"Rethinking Losses for Diffusion Bridge Samplers","content":"arXiv:2506.10982v2 Announce Type: replace Abstract: Diffusion bridges are a promising class of deep-learning methods for sampling from unnormalized distributions. Recent works show that the Log Variance (LV) loss consistently outperforms the reverse Kullback-Leibler (rKL) loss when using the reparametrization trick to compute rKL-gradients. While the on-policy LV loss yields identical gradients to the rKL loss when combined with the log-derivative trick for diffusion samplers with non-learnable forward processes, this equivalence does not hold for diffusion bridges or when diffusion coefficients are learned. Based on this insight we argue that for diffusion bridges the LV loss does not represent an optimization objective that can be motivated like the rKL loss via the data processing inequality. Our analysis shows that employing the rKL loss with the log-derivative trick (rKL-LD) does not only avoid these conceptual problems but also consistently outperforms the LV loss. Experimental results with different types of diffusion bridges on challenging benchmarks show that samplers trained with the rKL-LD loss achieve better performance. From a practical perspective we find that rKL-LD requires significantly less hyperparameter optimization and yields more stable training behavior.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.10982","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.475559","language":"en","tags":["statml","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Sebastian Sanokowski, Lukas Gruber, Christoph Bartmann, Sepp Hochreiter, Sebastian Lehner","raw_content_length":1298,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["Kullback-Leibler"],"persons":["the Log Variance","Announce Type"],"locations":[],"monetary":[]},"char_count":1297,"language_detected":"en","key_concepts":{"key_phrases":["Losses","Diffusion Bridge Samplers","Announce Type","Abstract","Diffusion bridges","a promising class","deep-learning methods","unnormalized distributions","Recent works","the Log Variance LV loss"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Losses":2.0,"Diffusion Bridge Samplers":2.0,"Announce Type":1.0,"Abstract":1.0,"Diffusion bridges":1.0,"a promising class":1.0,"deep-learning methods":1.0,"unnormalized distributions":1.0,"Recent works":1.0,"the Log Variance LV loss":1.0}},"age_hours":2.781164151111111,"is_recent":true,"quality_score":1.0,"sentiment_score":0.8875,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8225,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8452,"joy":0.0464,"surprise":0.0753,"sadness":0.0076,"fear":0.0079,"anger":0.0092,"disgust":0.0085},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving the efficiency of diffusion bridge samplers, a deep learning method. While the improved efficiency could potentially reduce computational energy consumption, the impact is theoretical and not directly tied to a deployed technology or measured outcome. The research is in the early stages, with no clear path to economic viability or deployment at scale.","key_impact_metrics":["Better performance on challenging benchmarks"],"technology_tags":["Diffusion bridges","Deep learning","Sampling methods"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:08.703413Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_11ec408f016e","title":"Not All Clients Are Equal: Collaborative Model Personalization on Heterogeneous Multi","content":"arXiv:2506.11024v2 Announce Type: replace Abstract: As AI becomes more personal, e.g., Agentic AI, there is an increasing need for personalizing models for various use cases. Personalized federated learning (PFL) enables each client to collaboratively leverage other clients' knowledge for better adaptation to the task of interest, without privacy risks. Despite its potential, existing PFL methods remain confined to rather simplified scenarios where data and models are the same across clients. To move towards realistic scenarios, we propose FedMosaic, a method that jointly addresses data and model heterogeneity with a task-relevance-aware model aggregation strategy to reduce parameter interference, and a dimension-invariant module that enables knowledge sharing across heterogeneous architectures without huge computational cost. To mimic the real-world task diversity, we propose a multi-modal PFL benchmark spanning 40 distinct tasks with distribution shifts over time. The empirical study shows that FedMosaic outperforms the state-of-the-art PFL methods, excelling in both personalization and generalization capabilities under challenging, realistic scenarios.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11024","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.475953","language":"en","tags":["csdc","computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":155,"author":"Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars","raw_content_length":1174,"priority":7,"update_frequency":1,"reading_time_minutes":0.775,"robust_parsing_used":true,"entities":{"organizations":["FedMosaic","PFL"],"persons":["Agentic AI"],"locations":[],"monetary":[]},"char_count":1173,"language_detected":"en","key_concepts":{"key_phrases":["Not All Clients","Collaborative Model Personalization","Heterogeneous Multi","models","Announce Type","Abstract","an increasing need","various use cases","Personalized federated learning","PFL"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Not All Clients":2.0,"Collaborative Model Personalization":2.0,"Heterogeneous Multi":2.0,"models":2.0,"Announce Type":1.0,"Abstract":1.0,"an increasing need":1.0,"various use cases":1.0,"Personalized federated learning":1.0,"PFL":1.0}},"age_hours":2.781179207222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8635,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7727,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9205,"joy":0.009,"surprise":0.0332,"sadness":0.0051,"fear":0.0155,"anger":0.0114,"disgust":0.0053},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new federated learning method (FedMosaic) to improve personalization and generalization in AI models. While it addresses data and model heterogeneity, it's still in the early stages of development with no concrete deployment or measured outcomes. The benchmark is proposed to mimic real-world task diversity, but lacks real-world validation.","key_impact_metrics":[],"technology_tags":["federated learning","personalized AI","model aggregation"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:11.319146Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_024b513fabf0","title":"Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks","content":"arXiv:2506.11113v3 Announce Type: replace Abstract: Peer review is essential for maintaining academic quality, but the increasing volume of submissions places a significant burden on reviewers. Large language models (LLMs) offer potential assistance in this process, yet their susceptibility to textual adversarial attacks raises reliability concerns. This paper investigates the robustness of LLMs used as automated reviewers in the presence of such attacks. We focus on three key questions: (1) The effectiveness of LLMs in generating reviews compared to human reviewers. (2) The impact of adversarial attacks on the reliability of LLM-generated reviews. (3) Challenges and potential mitigation strategies for LLM-based review. Our evaluation reveals significant vulnerabilities, as text manipulations can distort LLM assessments. We offer a comprehensive evaluation of LLM performance in automated peer reviewing and analyze its robustness against adversarial attacks. Our findings emphasize the importance of addressing adversarial risks to ensure AI strengthens, rather than compromises, the integrity of scholarly communication.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11113","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.476341","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":153,"author":"Tzu-Ling Lin, Wei-Chih Chen, Teng-Fang Hsiao, Hou-I Liu, Ya-Hsin Yeh, Yu Kai Chan, Wen-Sheng Lien, Po-Yen Kuo, Philip S. Yu, Hong-Han Shuai","raw_content_length":1135,"priority":7,"update_frequency":1,"reading_time_minutes":0.765,"robust_parsing_used":true,"entities":{"organizations":["LLM","Automated Peer Review","the Vulnerability of Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1134,"language_detected":"en","key_concepts":{"key_phrases":["the Reviewer","the Vulnerability","Large Language Models","Automated Peer Review","Textual Adversarial Attacks","LLMs","arXiv250611113v3 Announce Type","Abstract","Peer review","academic quality"],"filter_categories":{"ai_ml":["Large Language Models"],"research_academic":["Automated Peer Review","Peer review","academic quality"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"the Reviewer":2.0,"the Vulnerability":2.0,"Large Language Models":2.0,"Automated Peer Review":2.0,"Textual Adversarial Attacks":2.0,"LLMs":2.0,"arXiv250611113v3 Announce Type":1.0,"Abstract":1.0,"Peer review":1.0,"academic quality":1.0}},"age_hours":2.7811953102777776,"is_recent":true,"quality_score":1.0,"sentiment_score":0.41549999999999976,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9169,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2343,"joy":0.005,"surprise":0.0067,"sadness":0.0166,"fear":0.6694,"anger":0.0383,"disgust":0.0296},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper investigates the vulnerability of LLMs in automated peer review under adversarial attacks. While it doesn't directly address climate change, it explores the reliability of AI systems, which could indirectly impact sustainability efforts if AI is used to evaluate or promote unsustainable practices. The research is in an early stage, focusing on evaluation rather than deployment.","key_impact_metrics":[],"technology_tags":["Large Language Models","Adversarial Attacks"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:14.092686Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_65fcc93070e1","title":"A Survey of Foundation Models for IoT: Taxonomy and Criteria","content":"arXiv:2506.12263v3 Announce Type: replace Abstract: Foundation models have gained growing interest in the IoT domain due to their reduced reliance on labeled data and strong generalizability across tasks, which address key limitations of traditional machine learning approaches. However, most existing foundation model based methods are developed for specific IoT tasks, making it difficult to compare approaches across IoT domains and limiting guidance for applying them to new tasks. This survey aims to bridge this gap by providing a comprehensive overview of current methodologies and organizing them around four shared performance objectives by different domains: efficiency, context-awareness, safety, and security & privacy. For each objective, we review representative works, summarize commonly-used techniques and evaluation metrics. This objective-centric organization enables meaningful cross-domain comparisons and offers practical insights for selecting and designing foundation model based solutions for new IoT tasks. We conclude with key directions for future research to guide both practitioners and researchers in advancing the use of foundation models in IoT applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12263","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.477150","language":"en","tags":["research","cssy","computer-science","cslg","csai","preprints","eesssy","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":161,"author":"Hui Wei, Dong Yoon Lee, Shubham Rohal, Zhizhang Hu, Ryan Rossi, Shiwei Fang, Shijia Pan","raw_content_length":1192,"priority":7,"update_frequency":1,"reading_time_minutes":0.805,"robust_parsing_used":true,"entities":{"organizations":["IoT"],"persons":[],"locations":[],"monetary":[]},"char_count":1191,"language_detected":"en","key_concepts":{"key_phrases":["A Survey","Foundation Models","IoT","Taxonomy","Criteria","arXiv250612263v3 Announce Type","Abstract","Foundation models","growing interest","the IoT domain"],"filter_categories":{"engineering":["IoT","the IoT domain"],"healthcare_tech":["IoT"],"ai_ml":["the IoT domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Survey":2.0,"Foundation Models":2.0,"IoT":2.0,"Taxonomy":2.0,"Criteria":2.0,"arXiv250612263v3 Announce Type":1.0,"Abstract":1.0,"Foundation models":1.0,"growing interest":1.0,"the IoT domain":1.0}},"age_hours":2.7812242655555557,"is_recent":true,"quality_score":1.0,"sentiment_score":8.982,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7964,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.798,"joy":0.0164,"surprise":0.1376,"sadness":0.014,"fear":0.0139,"anger":0.0137,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This is a survey paper analyzing foundation models for IoT. It identifies key performance objectives (efficiency, context-awareness, safety, security & privacy) but does not present concrete deployments or measured outcomes. It remains at the research stage, lacking real-world validation.","key_impact_metrics":[],"technology_tags":["Foundation Models","Internet of Things","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:16.663103Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ba4842a733d1","title":"Language Surgery in Multilingual Large Language Models","content":"arXiv:2506.12450v2 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for language-specific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), a novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLC's strong cross-lingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current large-scale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces a practical solution for enhancing their monolingual and cross-lingual performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12450","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.477559","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":164,"author":"Joanito Agili Lopo, Muhammad Ravi Shulthan Habibi, Tack Hwa Wong, Muhammad Ilham Ghozali, Fajri Koto, Genta Indra Winata, Peerat Limkonchotiwat, Alham Fikri Aji, Samuel Cahyawijaya","raw_content_length":1367,"priority":7,"update_frequency":1,"reading_time_minutes":0.82,"robust_parsing_used":true,"entities":{"organizations":["Inference-Time Language Control"],"persons":["Language Surgery"],"locations":[],"monetary":[]},"char_count":1366,"language_detected":"en","key_concepts":{"key_phrases":["Language Surgery","Multilingual Large Language Models","LLMs","arXiv250612450v2 Announce Type","Large Language Models","remarkable generalization capabilities","tasks","languages","natural language processing","This paper"],"filter_categories":{"ai_ml":["Multilingual Large Language Models","Large Language Models","natural language processing"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Language Surgery":2.0,"Multilingual Large Language Models":2.0,"LLMs":2.0,"arXiv250612450v2 Announce Type":1.0,"Large Language Models":1.0,"remarkable generalization capabilities":1.0,"tasks":1.0,"languages":1.0,"natural language processing":1.0,"This paper":1.0}},"age_hours":2.7812381883333335,"is_recent":true,"quality_score":1.0,"sentiment_score":8.634500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7269,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7197,"joy":0.0566,"surprise":0.0497,"sadness":0.0071,"fear":0.1123,"anger":0.0324,"disgust":0.0222},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (ITLC) for improving cross-lingual language control in LLMs. While it advances understanding of representation alignment, it's currently at the basic research stage with no deployed units or measured outcomes related to direct environmental impact. The vaporware flag is raised due to the lack of deployment.","key_impact_metrics":[],"technology_tags":["Large Language Models","Cross-lingual Control","Inference-Time Language Control"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:19.482613Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_677b8011e967","title":"I$^2$RF-TFCKD: Intra","content":"arXiv:2506.13127v2 Announce Type: replace Abstract: In this paper, we propose an intra-inter representation fusion knowledge distillation (KD) framework with time-frequency calibration (I$^2$RF-TFCKD) for SE, which achieves distillation through the fusion of multi-layer teacher-student feature flows. Different from previous distillation strategies for SE, the proposed framework fully utilizes the time-frequency differential information of speech while promoting global knowledge flow. Firstly, we construct a collaborative distillation paradigm for intra-set and inter-set correlations. Within a correlated set, multi-layer teacher-student features are pairwise matched for calibrated distillation. Subsequently, we generate representative features from each correlated set through residual fusion to form the fused feature set that enables inter-set knowledge interaction. Secondly, we propose a multi-layer interactive distillation based on dual-stream time-frequency cross-calibration, which calculates the teacher-student similarity calibration weights in the time and frequency domains respectively and performs cross-weighting, thus enabling refined allocation of distillation contributions across different layers according to speech characteristics. The proposed distillation strategy is applied to the dual-path dilated convolutional recurrent network (DPDCRN) that ranked first in the SE track of the L3DAS23 challenge. To evaluate the effectiveness of I$^2$RF-TFCKD, we conduct experiments on both single-channel and multi-channel SE datasets. Objective evaluations demonstrate that the proposed KD strategy consistently and effectively improves the performance of the low-complexity student model and outperforms other distillation schemes.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.13127","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.478344","language":"en","tags":["computer-science","preprints","cssd","eessas","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":214,"author":"Jiaming Cheng, Ruiyu Liang, Ye Ni, Chao Xu, Jing Li, Wei Zhou, Rui Liu, Bj\\\"orn W. Schuller, Xiaoshuai Hao","raw_content_length":1757,"priority":7,"update_frequency":1,"reading_time_minutes":1.07,"robust_parsing_used":true,"entities":{"organizations":["Intra arXiv:2506.13127v2 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1756,"language_detected":"en","key_concepts":{"key_phrases":["I2RF-TFCKD","Intra","arXiv250613127v2 Announce Type","Abstract","this paper","time-frequency calibration","which","distillation","the fusion","multi-layer teacher-student feature flows"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"I2RF-TFCKD":3.0,"Intra":2.0,"arXiv250613127v2 Announce Type":1.0,"Abstract":1.0,"this paper":1.0,"time-frequency calibration":1.0,"which":1.0,"distillation":1.0,"the fusion":1.0,"multi-layer teacher-student feature flows":1.0}},"age_hours":2.7812685719444445,"is_recent":true,"quality_score":1.0,"sentiment_score":6.806,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3612,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8682,"joy":0.0546,"surprise":0.0458,"sadness":0.0044,"fear":0.006,"anger":0.0146,"disgust":0.0064},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a knowledge distillation framework for speech enhancement (SE). While SE can indirectly contribute to sustainability by improving communication efficiency and reducing energy consumption in related applications, the direct climate impact is minimal. The technology is at the applied research stage, with objective evaluations demonstrating performance improvements but no real-world deployments.","key_impact_metrics":["Performance improvement on SE datasets"],"technology_tags":["Knowledge Distillation","Speech Enhancement","Deep Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:22.252774Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_97eaf8e1ba70","title":"LDI: Localized Data Imputation for Text","content":"arXiv:2506.16616v2 Announce Type: replace Abstract: Missing values are pervasive in real-world tabular data and can significantly impair downstream analysis. Imputing them is especially challenging in text-rich tables, where dependencies are implicit, complex, and dispersed across long textual fields. Recent work has explored using Large Language Models (LLMs) for data imputation, yet existing approaches typically process entire tables or loosely related contexts, which can compromise accuracy, scalability, and explainability. We introduce LDI, a novel framework that leverages LLMs through localized reasoning, selecting a compact, contextually relevant subset of attributes and tuples for each missing value. This targeted selection reduces noise, improves scalability, and provides transparent attribution by revealing which data influenced each prediction. Through extensive experiments on real and synthetic datasets, we demonstrate that LDI consistently outperforms state-of-the-art imputation methods, achieving up to 8% higher accuracy with hosted LLMs and even greater gains with local models. The improved interpretability and robustness also make LDI well-suited for high-stakes data management applications.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.16616","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.479737","language":"en","tags":["csdb","research","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":159,"author":"Soroush Omidvartehrani, Davood Rafiei","raw_content_length":1226,"priority":7,"update_frequency":1,"reading_time_minutes":0.795,"robust_parsing_used":true,"entities":{"organizations":["Localized Data Imputation for Text arXiv:2506.16616v2 Announce Type","Large Language Models","LDI"],"persons":[],"locations":[],"monetary":[]},"char_count":1225,"language_detected":"en","key_concepts":{"key_phrases":["LDI","Localized Data Imputation","Text","Announce Type","Abstract","Missing values","real-world tabular data","downstream analysis","them","text-rich tables"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"LDI":2.0,"Localized Data Imputation":2.0,"Text":2.0,"Announce Type":1.0,"Abstract":1.0,"Missing values":1.0,"real-world tabular data":1.0,"downstream analysis":1.0,"them":1.0,"text-rich tables":1.0}},"age_hours":2.7812827530555553,"is_recent":true,"quality_score":1.0,"sentiment_score":6.692,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3384,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.6724,"joy":0.0032,"surprise":0.0458,"sadness":0.0575,"fear":0.0883,"anger":0.0412,"disgust":0.0916},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (LDI) for data imputation using LLMs, achieving up to 8% higher accuracy compared to existing methods. The concrete action is the development and testing of this framework on real and synthetic datasets. However, it's still in the applied research stage with no current deployment, limiting its immediate impact.","key_impact_metrics":["Accuracy improvement with hosted LLMs: 8%","Accuracy gains with local models: Greater than 8%"],"technology_tags":["Large Language Models","Data Imputation","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:25.408350Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7f1a9c642d9a","title":"The Role of Model Confidence on Bias Effects in Measured Uncertainties for Vision","content":"arXiv:2506.16724v2 Announce Type: replace Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases have greater effects in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence is associated with greater bias-induced underestimation of epistemic uncertainty, resulting in overconfident estimates, whereas it has no significant effect on the direction of bias effect in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.16724","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.480176","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Xinyi Liu, Weiguang Wang, Hangfeng He","raw_content_length":1564,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["Large Language Models","VQA","Visual Question Answering"],"persons":[],"locations":[],"monetary":[]},"char_count":1563,"language_detected":"en","key_concepts":{"key_phrases":["The Role","Model Confidence","Bias Effects","Measured Uncertainties","Vision","epistemic uncertainty","which","Announce Type","Abstract","the growing adoption"],"filter_categories":{"ai_ml":["Measured Uncertainties","Vision"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Role":2.0,"Model Confidence":2.0,"Bias Effects":2.0,"Measured Uncertainties":2.0,"Vision":2.0,"epistemic uncertainty":2.0,"which":2.0,"Announce Type":1.0,"Abstract":1.0,"the growing adoption":1.0}},"age_hours":2.781296965277778,"is_recent":true,"quality_score":1.0,"sentiment_score":3.091,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.3818,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7386,"joy":0.0399,"surprise":0.0432,"sadness":0.0083,"fear":0.1418,"anger":0.0203,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research focuses on improving the reliability of Large Language Models (LLMs) used in Visual Question Answering (VQA) tasks by addressing bias in uncertainty quantification. The concrete action is the experimentation and analysis of how prompt-introduced bias affects epistemic and aleatoric uncertainty in GPT-4o and Qwen2-VL. The evidence is based on experimental results and analysis of model confidence levels, but it is still in the research phase with no deployed technology or measured environmental outcomes.","key_impact_metrics":["Underestimation of epistemic uncertainty","Effects on aleatoric uncertainty estimation"],"technology_tags":["Large Language Models","Visual Question Answering","Uncertainty Quantification"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:28.517529Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e7ee2188919","title":"Little By Little: Continual Learning via Self-Activated Sparse Mixture","content":"arXiv:2506.21035v2 Announce Type: replace Abstract: Continual learning (CL) with large pre-trained models is challenged by catastrophic forgetting and task interference. Existing LoRA-based Mixture-of-Experts (MoE) approaches mitigate forgetting by assigning and freezing task-specific adapters, but suffer from interference, redundancy, and ambiguous routing due to coarse adapter-level selection. However, this design introduces three key challenges: 1) Interference: Activating full LoRA experts per input leads to subspace interference and prevents selective reuse of useful components across tasks. 2) Redundancy: Newly added experts often duplicate or contradict existing knowledge due to unnecessary activation of unrelated ranks and insufficient reuse of relevant ones. 3) Ambiguity: Overlapping features across tasks confuse the router, resulting in unstable expert assignments. As more experts accumulate, earlier task routing degrades, accelerating forgetting. We propose MoRA, a Mixture-of-Rank Adaptive learning approaches with self-activated and sparse rank activation for CL. Unlike mixing multiple low-rank matrices, MoRA decomposes each rank-r update into r rank-one components, each treated as an independent expert, enabling fine-grained rank-one expert utilization while mitigating interference and redundancy. To avoid ambiguous routing, we propose that each rank-one expert can infer its own relevance via intermediate activations. Coupled with our proposed rank pruning and activation budgets, MoRA adaptively selects a sparse mixture of ranks per input. We validate MoRA on continual learning benchmarks using CLIP and language models, analyzing both in-domain learning and out-of-domain forgetting/generalization during fine-tuning. MoRA shows significant effectiveness in enhancing CL with PTMs, and improving generalization while mitigating forgetting.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.21035","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.481446","language":"en","tags":["research","preprints","computer-science","cslg","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":241,"author":"Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong","raw_content_length":1880,"priority":7,"update_frequency":1,"reading_time_minutes":1.205,"robust_parsing_used":true,"entities":{"organizations":["LoRA"],"persons":[],"locations":[],"monetary":[]},"char_count":1879,"language_detected":"en","key_concepts":{"key_phrases":["Little By Little Continual Learning","Self-Activated Sparse Mixture","arXiv250621035v2 Announce Type","Abstract","Continual learning","large pre-trained models","catastrophic forgetting and task interference","Experts","MoE","task-specific adapters"],"filter_categories":{"ai_ml":["large pre-trained models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Little By Little Continual Learning":2.0,"Self-Activated Sparse Mixture":2.0,"arXiv250621035v2 Announce Type":1.0,"Abstract":1.0,"Continual learning":1.0,"large pre-trained models":1.0,"catastrophic forgetting and task interference":1.0,"Experts":1.0,"MoE":1.0,"task-specific adapters":1.0}},"age_hours":2.781342901388889,"is_recent":true,"quality_score":1.0,"sentiment_score":0.9765000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8047,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9055,"joy":0.0034,"surprise":0.0177,"sadness":0.0144,"fear":0.0298,"anger":0.0169,"disgust":0.0124},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a novel continual learning method (MoRA) to improve the efficiency and reduce the forgetting of large pre-trained models. While the method shows promise in enhancing continual learning benchmarks, it is still in the applied research stage with no mention of real-world deployment or economic viability. The climate impact is indirect, as it could potentially improve the efficiency of AI models used in climate-related applications.","key_impact_metrics":["Significant effectiveness in enhancing CL with PTMs","Improving generalization while mitigating forgetting"],"technology_tags":["Continual Learning","Mixture-of-Experts","Sparse Activation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:58:31.437757Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b97037b2cd5d","title":"Evaluating Sound Similarity Metrics for Differentiable, Iterative Sound","content":"arXiv:2506.22628v2 Announce Type: replace Abstract: Manual sound design with a synthesizer is inherently iterative: an artist compares the synthesized output to a mental target, adjusts parameters, and repeats until satisfied. Iterative sound-matching automates this workflow by continually programming a synthesizer under the guidance of a loss function (or similarity measure) toward a target sound. Prior comparisons of loss functions have typically favored one metric over another, but only within narrow settings: limited synthesis methods, few loss types, often without blind listening tests. This leaves open the question of whether a universally optimal loss exists, or the choice of loss remains a creative decision conditioned on the synthesis method and the sound designer's preference. We propose differentiable iterative sound-matching as the natural extension of the available literature, since it combines the manual approach to sound design with modern advances in machine learning. To analyze the variability of loss function performance across synthesizers, we implemented a mix of four novel and established differentiable loss functions, and paired them with differentiable subtractive, additive, and AM synthesizers. For each of the sixteen synthesizer--loss combinations, we ran 300 randomized sound-matching trials. Performance was measured using parameter differences, spectrogram-distance metrics, and manually assigned listening scores. We observed a moderate level of consistency among the three performance measures. Our post-hoc analysis shows that the loss function performance is highly dependent on the synthesizer. These findings underscore the value of expanding the scope of sound-matching experiments and developing new similarity metrics tailored to specific synthesis techniques rather than pursuing one-size-fits-all solutions.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.22628","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.481893","language":"en","tags":["computer-science","preprints","cssd","eessas","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":253,"author":"Amir Salimi, Abram Hindle, Osmar R. Zaiane","raw_content_length":1867,"priority":7,"update_frequency":1,"reading_time_minutes":1.265,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1866,"language_detected":"en","key_concepts":{"key_phrases":["Sound Similarity Metrics","Differentiable","a synthesizer","Announce Type","Abstract","Manual sound design","an artist","the synthesized output","a mental target","parameters"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sound Similarity Metrics":2.0,"Differentiable":2.0,"a synthesizer":2.0,"Announce Type":1.0,"Abstract":1.0,"Manual sound design":1.0,"an artist":1.0,"the synthesized output":1.0,"a mental target":1.0,"parameters":1.0}},"age_hours":2.78135788,"is_recent":true,"quality_score":0.7,"sentiment_score":3.9884999999999997,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.2023,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9265,"joy":0.0202,"surprise":0.0159,"sadness":0.0031,"fear":0.0052,"anger":0.0149,"disgust":0.0142},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores methods for automated sound design, which has indirect and speculative links to sustainability. The article focuses on the performance of different loss functions in sound matching, measured by parameter differences, spectrogram-distance metrics, and listening scores. It is in the applied research phase, with randomized sound-matching trials but no real-world deployment.","key_impact_metrics":["parameter differences","spectrogram-distance metrics"],"technology_tags":["differentiable loss functions","sound synthesis"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:33.881922Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_8c39caa3c123","title":"Generative AI-enhanced Low","content":"arXiv:2506.23488v2 Announce Type: replace Abstract: Wireless communication systems face challenges in meeting the demand for higher data rates and reliable connectivity in complex environments. Stacked intelligent metasurfaces (SIMs) have emerged as a promising technology for advanced wave-domain signal processing, where mobile SIMs can outperform fixed counterparts. In this paper, we propose a novel unmanned aerial vehicle (UAV)-mounted SIM (UAV-SIM) assisted communication system within low-altitude economy (LAE) networks, where UAVs act as both cache-enabled base stations and mobile SIM carriers to enhance uplink transmissions. To maximize network capacity, we formulate a UAV-SIM-based joint optimization problem (USBJOP) that integrates user association, UAV-SIM three-dimensional positioning, and multi-layer SIM phase shift design. Due to the non-convexity and NP-hardness of USBJOP, we decompose it into three subproblems, which are the association between UAV-SIMs and users optimization problem (AUUOP), the UAV location optimization problem (ULOP), and the UAV-SIM phase shifts optimization problem (USPSOP). Then, we solve them through an alternating optimization strategy. Specifically, AUUOP and ULOP are transformed into convex forms solvable via the CVX tool, while USPSOP is addressed by a generative artificial intelligence (GAI)-based hybrid optimization algorithm. Simulation results show that the proposed approach achieves approximately 1.5 times higher network capacity compared with suboptimal schemes, effectively mitigates multi-user interference with increasing SIM layers and meta-atoms, and reduces runtime by 10\\% while maintaining solution quality, thereby demonstrating its practicality for real-world deployments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.23488","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.482314","language":"en","tags":["research","csni","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":227,"author":"Geng Sun, Mingzhe Fan, Lei Zhang, Hongyang Pan, Jiahui Li, Chuang Zhang, Linyao Li, Changyuan Zhao, Chau Yuen","raw_content_length":1754,"priority":7,"update_frequency":1,"reading_time_minutes":1.135,"robust_parsing_used":true,"entities":{"organizations":["UAV-SIM","UAVs","LAE","SIM"],"persons":["Generative AI-enhanced","USBJOP"],"locations":[],"monetary":[]},"char_count":1753,"language_detected":"en","key_concepts":{"key_phrases":["Generative AI-enhanced Low","arXiv250623488v2 Announce Type","Abstract","challenges","the demand","higher data rates","reliable connectivity","complex environments","intelligent metasurfaces","SIMs"],"filter_categories":{"ai_ml":["Generative AI-enhanced Low"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Generative AI-enhanced Low":2.0,"arXiv250623488v2 Announce Type":1.0,"Abstract":1.0,"challenges":1.0,"the demand":1.0,"higher data rates":1.0,"reliable connectivity":1.0,"complex environments":1.0,"intelligent metasurfaces":1.0,"SIMs":1.0}},"age_hours":2.781373632222222,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8567,"joy":0.0241,"surprise":0.0588,"sadness":0.0062,"fear":0.0346,"anger":0.0134,"disgust":0.0063},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The paper proposes a UAV-SIM assisted communication system to enhance uplink transmissions in low-altitude economy networks. Simulation results show a 1.5 times higher network capacity compared to suboptimal schemes and a 10% reduction in runtime. However, this is still in the simulation stage, lacking real-world deployment and economic viability analysis.","key_impact_metrics":["1.5 times higher network capacity","10% reduction in runtime"],"technology_tags":["UAV","Metasurface","Generative AI"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:36.791367Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ece5b205e1d5","title":"Disambiguation","content":"arXiv:2507.03336v3 Announce Type: replace Abstract: Large language models (LLMs) are increasingly tasked with invoking enterprise APIs, yet they routinely falter when near-duplicate tools vie for the same user intent or when required arguments are left underspecified. We introduce DiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a disambiguation-centric, three-stage pipeline that (i) synthesizes persona-driven, multi-turn dialogues in which the assistant must distinguish among highly similar tools, (ii) performs supervised fine-tuning of open-source models with reasoning traces across 3B - 70B parameters, and (iii) evaluates real-world readiness via a dynamic suite that redeploys each model in a live agentic loop and reports end-to-end goal completion alongside conventional static metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE raise tool-invocation success by 27 pp over GPT-4o and by 49 pp over Claude-3.5-Sonnet, both under optimized prompting. To spur further research, we release an open corpus of 5000 production-grade enterprise API specifications paired with rigorously validated, disambiguation-focused dialogues, offering a practical blueprint for building reliable, enterprise-ready tool-calling agents.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.03336","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.483526","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Ashutosh Hathidara, Julien Yu, Sebastian Schreiber","raw_content_length":1279,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["DiaFORGE","DiaBENCH"],"persons":[],"locations":[],"monetary":[]},"char_count":1278,"language_detected":"en","key_concepts":{"key_phrases":["arXiv250703336v3","Announce Type","Abstract","Large language models","LLMs","enterprise APIs","when near-duplicate tools","the same user intent","required arguments","DiaFORGE"],"filter_categories":{"ai_ml":["Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv250703336v3":1.0,"Announce Type":1.0,"Abstract":1.0,"Large language models":1.0,"LLMs":1.0,"enterprise APIs":1.0,"when near-duplicate tools":1.0,"the same user intent":1.0,"required arguments":1.0,"DiaFORGE":1.0}},"age_hours":2.7814190908333334,"is_recent":true,"quality_score":1.0,"sentiment_score":2.9905000000000004,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4019,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.6865,"joy":0.0045,"surprise":0.0473,"sadness":0.0171,"fear":0.184,"anger":0.0338,"disgust":0.0267},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the reliability of LLMs in enterprise API tool invocation, which could indirectly support sustainability efforts by making software tools more efficient and reliable. The concrete action is the development of a new framework (DiaFORGE) and benchmark (DiaBENCH). Evidence is provided through performance metrics (27 pp improvement over GPT-4o) and the release of an open corpus. It's currently in the applied research stage, with no mention of real-world deployment.","key_impact_metrics":["tool-invocation success by 27 pp","tool-invocation success by 49 pp"],"technology_tags":["Large Language Models","API Tool Invocation","Dialogue Systems"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:39.871325Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_93b99a999e11","title":"Efficiency","content":"arXiv:2507.06223v2 Announce Type: replace Abstract: Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose \\ours\\footnote{https://github.com/zhiyuanpeng/EER-FLOPs.} for LLM-based rerankers: RPP (ranking metrics per PetaFLOP), measuring how much ranking quality (e.g., NDCG or MRR) a method achieves per PetaFLOP, and QPP (queries per PetaFLOP), measuring how many queries can be processed per PetaFLOP. Accompanied by the new metrics, an interpretable FLOPs estimator is developed to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architectures, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.06223","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.483943","language":"en","tags":["computer-science","cslg","preprints","csai","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":194,"author":"Zhiyuan Peng, Ting-ruen Wei, Tingyu Song, Yilun Zhao","raw_content_length":1432,"priority":7,"update_frequency":1,"reading_time_minutes":0.97,"robust_parsing_used":true,"entities":{"organizations":["RPP","NDCG"],"persons":["QPP"],"locations":[],"monetary":[]},"char_count":1431,"language_detected":"en","key_concepts":{"key_phrases":["Efficiency","arXiv250706223v2 Announce Type","Large Language Models","LLMs","tasks","information retrieval","strong performance","their high computational demands","practical deployment","Existing studies"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Efficiency":2.0,"arXiv250706223v2 Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"tasks":1.0,"information retrieval":1.0,"strong performance":1.0,"their high computational demands":1.0,"practical deployment":1.0,"Existing studies":1.0}},"age_hours":2.7814348147222225,"is_recent":true,"quality_score":1.0,"sentiment_score":9.1125,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8225,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9291,"joy":0.0144,"surprise":0.0249,"sadness":0.0093,"fear":0.0031,"anger":0.011,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes new metrics (RPP and QPP) to evaluate the efficiency of LLM-based rerankers, focusing on ranking quality and query processing per PetaFLOP. While it addresses computational demands, it's still in the research phase with no real-world deployment. The impact on climate is indirect, potentially reducing energy consumption of large language models if adopted.","key_impact_metrics":["ranking metrics per PetaFLOP","queries per PetaFLOP"],"technology_tags":["Large Language Models","Information Retrieval","Efficiency Metrics"],"sdg_alignment":[7,9,12],"analyzed_at":"2025-10-28T20:58:43.136941Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d3d60dca180a","title":"LLMs Encode Harmfulness and Refusal Separately","content":"arXiv:2507.11878v3 Announce Type: replace Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand harmfulness beyond just refusing? Prior work has shown that LLMs' refusal behaviors can be mediated by a one-dimensional subspace, i.e., a refusal direction. In this work, we identify a new dimension to analyze safety mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a separate concept from refusal. There exists a harmfulness direction that is distinct from the refusal direction. As causal evidence, steering along the harmfulness direction can lead LLMs to interpret harmless instructions as harmful, but steering along the refusal direction tends to elicit refusal responses directly without reversing the model's judgment on harmfulness. Furthermore, using our identified harmfulness concept, we find that certain jailbreak methods work by reducing the refusal signals without reversing the model's internal belief of harmfulness. We also find that adversarially finetuning models to accept harmful instructions has minimal impact on the model's internal belief of harmfulness. These insights lead to a practical safety application: The model's latent harmfulness representation can serve as an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing over-refusals that is robust to finetuning attacks. For instance, our Latent Guard achieves performance comparable to or better than Llama Guard 3 8B, a dedicated finetuned safeguard model, across different jailbreak methods. Our findings suggest that LLMs' internal understanding of harmfulness is more robust than their refusal decision to diverse input instructions, offering a new perspective to study AI safety.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.11878","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.485584","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":248,"author":"Jiachen Zhao, Jing Huang, Zhengxuan Wu, David Bau, Weiyan Shi","raw_content_length":1744,"priority":7,"update_frequency":1,"reading_time_minutes":1.24,"robust_parsing_used":true,"entities":{"organizations":["Encode Harmfulness and Refusal"],"persons":[],"locations":[],"monetary":[]},"char_count":1743,"language_detected":"en","key_concepts":{"key_phrases":["LLMs Encode Harmfulness","Refusal","LLMs","Announce Type","Abstract","harmful instructions","Prior work","LLMs refusal behaviors","a one-dimensional subspace","this work"],"filter_categories":{"ai_ml":["LLMs Encode Harmfulness"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs Encode Harmfulness":2.0,"Refusal":2.0,"LLMs":2.0,"Announce Type":1.0,"Abstract":1.0,"harmful instructions":1.0,"Prior work":1.0,"LLMs refusal behaviors":1.0,"a one-dimensional subspace":1.0,"this work":1.0}},"age_hours":2.781479044722222,"is_recent":true,"quality_score":1.0,"sentiment_score":0.6709999999999999,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8658,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3885,"joy":0.0031,"surprise":0.0038,"sadness":0.0149,"fear":0.068,"anger":0.1411,"disgust":0.3807},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper identifies a novel method for analyzing safety mechanisms in LLMs, specifically harmfulness, which is encoded separately from refusal. The research provides causal evidence by steering LLMs along the harmfulness direction and observing changes in interpretation. The Latent Guard achieves performance comparable to Llama Guard 3 8B, a dedicated finetuned safeguard model, across different jailbreak methods.","key_impact_metrics":["Performance comparable to Llama Guard 3 8B"],"technology_tags":["Large Language Models","AI Safety","Jailbreak Detection"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-28T20:58:46.354299Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9a77104fdedf","title":"FLEXITOKENS: Flexible Tokenization for Evolving Language Models","content":"arXiv:2507.12720v3 Announce Type: replace Abstract: Language models (LMs) are challenging to adapt to new data distributions by simple finetuning. This is due to the rigidity of their subword tokenizers, which typically remain unchanged during adaptation. This inflexibility often leads to inefficient tokenization, causing overfragmentation of out-of-distribution domains, unseen languages, or scripts. In this work, we develop byte-level LMs with learnable tokenizers to make tokenization adaptive. Our models include a submodule that learns to predict boundaries between the input byte sequence, encoding it into variable-length segments. Existing tokenizer-free methods train this boundary predictor using an auxiliary loss that enforces a fixed compression rate across the training corpus, introducing a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective that enables significantly greater flexibility during adaptation. Evaluating across multiple multilingual benchmarks, morphologically diverse tasks, and domains, we demonstrate that FLEXITOKENS consistently reduces token over-fragmentation and achieves up to 10% improvements on downstream task performance compared to subword and other gradient-based tokenizers. Code and data for our experiments will be released at https://github.com/owos/flexitokens","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.12720","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.486777","language":"en","tags":["research","preprints","computer-science","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Abraham Toluwase Owodunni, Orevaoghene Ahia, Sachin Kumar","raw_content_length":1341,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["FLEXITOKENS"],"persons":[],"locations":[],"monetary":[]},"char_count":1340,"language_detected":"en","key_concepts":{"key_phrases":["FLEXITOKENS Flexible Tokenization","Evolving Language Models","Announce Type","Abstract","Language models","LMs","new data distributions","simple finetuning","the rigidity","their subword tokenizers"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"FLEXITOKENS Flexible Tokenization":2.0,"Evolving Language Models":2.0,"Announce Type":1.0,"Abstract":1.0,"Language models":1.0,"LMs":1.0,"new data distributions":1.0,"simple finetuning":1.0,"the rigidity":1.0,"their subword tokenizers":1.0}},"age_hours":2.781521461388889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.946,"joy":0.0042,"surprise":0.0173,"sadness":0.0032,"fear":0.0041,"anger":0.0163,"disgust":0.0089},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents research on a new tokenization method for language models, FLEXITOKENS, which aims to improve efficiency and reduce token over-fragmentation. The concrete action is the development and evaluation of this method across multiple benchmarks, demonstrating up to 10% improvements in downstream task performance. However, it's still in the research phase, with no deployed units or commercial applications mentioned, hence the low deployment readiness.","key_impact_metrics":["10% improvements on downstream task performance","reduces token over-fragmentation"],"technology_tags":["language models","tokenization","byte-level LMs"],"sdg_alignment":[],"analyzed_at":"2025-10-28T20:58:49.747968Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_03bb0ff2a8a8","title":"A Kernel Distribution Closeness Testing","content":"arXiv:2507.12843v2 Announce Type: replace Abstract: The distribution closeness testing (DCT) assesses whether the distance between a distribution pair is at least $\\epsilon$-far. Existing DCT methods mainly measure discrepancies between a distribution pair defined on discrete one-dimensional spaces (e.g., using total variation), which limits their applications to complex data (e.g., images). To extend DCT to more types of data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful measurement of the distributional discrepancy between two complex distributions, into DCT scenarios. However, we find that MMD's value can be the same for many pairs of distributions that have different norms in the same reproducing kernel Hilbert space (RKHS), making MMD less informative when assessing the closeness levels for multiple distribution pairs. To mitigate the issue, we design a new measurement of distributional discrepancy, norm-adaptive MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions. Based on the asymptotic distribution of NAMMD, we finally propose the NAMMD-based DCT to assess the closeness levels of a distribution pair. Theoretically, we prove that NAMMD-based DCT has higher test power compared to MMD-based DCT, with bounded type-I error, which is also validated by extensive experiments on many types of data (e.g., synthetic noise, real images). Furthermore, we also apply the proposed NAMMD for addressing the two-sample testing problem and find NAMMD-based two-sample test has higher test power than the MMD-based two-sample test in both theory and experiments.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.12843","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.487183","language":"en","tags":["statml","computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":236,"author":"Zhijian Zhou, Liuhua Peng, Xunye Tian, Feng Liu","raw_content_length":1627,"priority":7,"update_frequency":1,"reading_time_minutes":1.18,"robust_parsing_used":true,"entities":{"organizations":["MMD","RKHS"],"persons":["Hilbert"],"locations":[],"monetary":["at least $\\epsilon$-far"]},"char_count":1626,"language_detected":"en","key_concepts":{"key_phrases":["A Kernel Distribution Closeness Testing","DCT","a distribution pair","Announce Type","Abstract","The distribution closeness testing","the distance","Existing DCT methods","discrepancies","discrete one-dimensional spaces"],"filter_categories":{"ai_ml":["a distribution pair"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Kernel Distribution Closeness Testing":2.0,"DCT":2.0,"a distribution pair":2.0,"Announce Type":1.0,"Abstract":1.0,"The distribution closeness testing":1.0,"the distance":1.0,"Existing DCT methods":1.0,"discrepancies":1.0,"discrete one-dimensional spaces":1.0}},"age_hours":2.7815365188888888,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8337,"joy":0.0119,"surprise":0.0317,"sadness":0.0067,"fear":0.0593,"anger":0.0306,"disgust":0.0261},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (NAMMD) for distribution closeness testing. While the method is theoretically proven to have higher test power and validated by experiments, it is still in the basic research phase with no concrete deployments or measurable outcomes related to sustainability. The potential climate impact is low as it is a statistical method and not a direct climate technology.","key_impact_metrics":["Higher test power compared to MMD-based DCT","Bounded type-I error"],"technology_tags":["Distribution Closeness Testing","Maximum Mean Discrepancy","Norm-Adaptive MMD"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:52.468154Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2c15e46353f7","title":"ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human","content":"arXiv:2507.13468v2 Announce Type: replace Abstract: The integration of large language models (LLMs) into conversational robots has made human-robot conversations more dynamic. Yet, LLM-powered conversational robots remain prone to errors, e.g., misunderstanding user intent, prematurely interrupting users, or failing to respond altogether. Detecting and addressing these failures is critical for preventing conversational breakdowns, avoiding task disruptions, and sustaining user trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal dataset of LLM-powered conversational robot failures during human-robot conversations and encourages researchers to benchmark machine learning models designed to detect robot failures. The dataset includes 16 hours of dyadic human-robot interactions, incorporating facial, speech, and head movement features. Each interaction is annotated with the presence or absence of robot errors from the system perspective, and perceived user intention to correct for a mismatch between robot behavior and user expectation. Participants are invited to form teams and develop machine learning models that detect these failures using multimodal data. Submissions will be evaluated using various performance metrics, including detection accuracy and false positive rate. This challenge represents another key step toward improving failure detection in human-robot interaction through social signal analysis.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.13468","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.487600","language":"en","tags":["csro","computer-science","csai","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Shiye Cao, Maia Stiber, Amama Mahmood, Maria Teresa Parreira, Wendy Ju, Micol Spitale, Hatice Gunes, Chien-Ming Huang","raw_content_length":1455,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Failures"],"locations":[],"monetary":[]},"char_count":1454,"language_detected":"en","key_concepts":{"key_phrases":["ERRHRI 20 Challenge","Multimodal Detection","Errors","Failures","Human","Announce Type","Abstract","The integration","large language models","LLMs"],"filter_categories":{"ai_ml":["Failures","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ERRHRI 20 Challenge":2.0,"Multimodal Detection":2.0,"Errors":2.0,"Failures":2.0,"Human":2.0,"Announce Type":1.0,"Abstract":1.0,"The integration":1.0,"large language models":1.0,"LLMs":1.0}},"age_hours":2.7815512427777778,"is_recent":true,"quality_score":1.0,"sentiment_score":0.27000000000000024,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.946,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.4443,"joy":0.0031,"surprise":0.0089,"sadness":0.0407,"fear":0.4054,"anger":0.056,"disgust":0.0416},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article describes a challenge to improve error detection in human-robot interaction using machine learning. While it could potentially improve the efficiency of robots in various applications, including those with sustainability implications, it's currently in the applied research phase with no deployed technology or measurable climate impact. The dataset and challenge provide some evidence, but it's not independently verified.","key_impact_metrics":["detection accuracy","false positive rate"],"technology_tags":["machine learning","robotics","human-robot interaction"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:58:55.095715Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ab6b9a1ff7d9","title":"Towards Urban Planing AI Agent in the Age of Agentic AI","content":"arXiv:2507.14730v4 Announce Type: replace Abstract: Generative AI, large language models, and agentic AI have emerged separately of urban planning. However, the convergence between AI and urban planning presents an interesting opportunity towards AI urban planners. Existing studies conceptualizes urban planning as a generative AI task, where AI synthesizes land-use configurations under geospatial, social, and human-centric constraints and reshape automated urban design. We further identify critical gaps of existing generative urban planning studies: 1) the generative structure has to be predefined with strong assumption: all of adversarial generator-discriminator, forward and inverse diffusion structures, hierarchical zone-POI generative structure are predefined by humans; 2) ignore the power of domain expert developed tools: domain urban planners have developed various tools in the urban planning process guided by urban theory, while existing pure neural networks based generation ignore the power of the tools developed by urban planner practitioners. To address these limitations, we outline a future research direction agentic urban AI planner, calling for a new synthesis of agentic AI and participatory urbanism.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.14730","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.487984","language":"en","tags":["research","csai","computer-science","preprints","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Rui Liu, Tao Zhe, Zhong-Ren Peng, Necati Catbas, Xinyue Ye, Dongjie Wang, Yanjie Fu","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Generative AI"],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["urban planning","Urban Planing AI Agent","the Age","Agentic AI","arXiv250714730v4 Announce Type","Abstract","Generative AI","large language models","agentic AI","the convergence"],"filter_categories":{"ai_ml":["Urban Planing AI Agent","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"urban planning":3.0,"Urban Planing AI Agent":2.0,"the Age":2.0,"Agentic AI":2.0,"arXiv250714730v4 Announce Type":1.0,"Abstract":1.0,"Generative AI":1.0,"large language models":1.0,"agentic AI":1.0,"the convergence":1.0}},"age_hours":2.781569316388889,"is_recent":true,"quality_score":1.0,"sentiment_score":8.352500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6705,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8461,"joy":0.0218,"surprise":0.0792,"sadness":0.0051,"fear":0.0224,"anger":0.0167,"disgust":0.0087},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper proposes a new research direction for AI in urban planning, focusing on agentic AI. It identifies limitations in existing generative urban planning studies and suggests integrating domain expert tools. The research is at a basic research stage with no deployed technology or measurable outcomes yet.","key_impact_metrics":[],"technology_tags":["Agentic AI","Urban Planning","Generative AI"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-28T20:58:59.816334Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7bb66cfeaa2a","title":"Understanding Teen Overreliance on AI Companion Chatbots Through Self","content":"arXiv:2507.15783v3 Announce Type: replace Abstract: AI companion chatbots are increasingly popular with teens, while these interactions are entertaining, they also risk overuse that can potentially disrupt offline daily life. We examined how adolescents describe reliance on AI companions, mapping their experiences onto behavioral addiction frameworks and exploring pathways to disengagement, by analyzing 318 Reddit posts made by users who self-disclosed as 13-17 years old on the Character.AI subreddit. We found teens often begin using chatbots for support or creative play, but these activities can deepen into strong attachments marked by conflict, withdrawal, tolerance, relapse, and mood regulation. Reported consequences include sleep loss, academic decline, and strained real-world connections. Disengagement commonly arises when teens recognize harm, re-engage with offline life, or encounter restrictive platform changes. We highlight specific risks of character-based companion chatbots based on teens' perspectives and introduce a design framework (CARE) for guidance for safer systems and setting directions for future teen-centered research.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.15783","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.488364","language":"en","tags":["cscy","computer-science","csai","preprints","cshc","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Mohammad Namvarpour (Matt), Brandon Brofsky, Jessica Medina, Mamtaj Akter, Afsaneh Razi","raw_content_length":1158,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["platform chang"],"locations":[],"monetary":[]},"char_count":1157,"language_detected":"en","key_concepts":{"key_phrases":["Teen Overreliance","AI Companion Chatbots","Self","arXiv250715783v3 Announce Type","AI companion chatbots","teens","these interactions","overuse","offline daily life","adolescents"],"filter_categories":{"ai_ml":["AI Companion Chatbots"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Teen Overreliance":2.0,"AI Companion Chatbots":2.0,"Self":2.0,"arXiv250715783v3 Announce Type":1.0,"AI companion chatbots":1.0,"teens":1.0,"these interactions":1.0,"overuse":1.0,"offline daily life":1.0,"adolescents":1.0}},"age_hours":2.7815917244444446,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8085,"joy":0.0189,"surprise":0.0211,"sadness":0.0166,"fear":0.0783,"anger":0.0276,"disgust":0.0289},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research analyzes existing Reddit data to understand the negative impacts of AI companion chatbots on teenagers. While it identifies potential harms like sleep loss and academic decline, it doesn't directly address climate change or environmental sustainability. The study is based on observational data and proposes a design framework, but lacks concrete actions or deployed solutions.","key_impact_metrics":["Sleep loss","Academic decline"],"technology_tags":["AI companion chatbots","Behavioral addiction"],"sdg_alignment":[3,4],"analyzed_at":"2025-10-28T20:59:02.354530Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_90ced760c31c","title":"Leveraging Personalized PageRank and Higher","content":"arXiv:2507.16347v2 Announce Type: replace Abstract: Graph Neural Networks (GNNs) excel in node classification tasks but often assume homophily, where connected nodes share similar labels. This assumption does not hold in many real-world heterophilic graphs. Existing models for heterophilic graphs primarily rely on pairwise relationships, overlooking multi-scale information from higher-order structures. This leads to suboptimal performance, particularly under noise from conflicting class information across nodes. To address these challenges, we propose HPGNN, a novel model integrating Higher-order Personalized PageRank with Graph Neural Networks. HPGNN introduces an efficient high-order approximation of Personalized PageRank (PPR) to capture long-range and multi-scale node interactions. This approach reduces computational complexity and mitigates noise from surrounding information. By embedding higher-order structural information into convolutional networks, HPGNN effectively models key interactions across diverse graph dimensions. Extensive experiments on benchmark datasets demonstrate HPGNN's effectiveness. The model achieves better performance than five out of seven state-of-the-art methods on heterophilic graphs in downstream tasks while maintaining competitive performance on homophilic graphs. HPGNN's ability to balance multi-scale information and robustness to noise makes it a versatile solution for real-world graph learning challenges. Codes are available at https://github.com/streetcorner/HPGNN.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.16347","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.488778","language":"en","tags":["computer-science","cslg","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Yumeng Wang, Zengyi Wo, Wenjun Wang, Xingcheng Fu, Minglai Shao","raw_content_length":1528,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Graph Neural Networks","PPR","HPGNN"],"persons":[],"locations":["Personalized PageRank","node"],"monetary":[]},"char_count":1527,"language_detected":"en","key_concepts":{"key_phrases":["Personalized PageRank","arXiv250716347v2 Announce Type","Abstract","Graph Neural Networks","GNNs","node classification tasks","connected nodes","similar labels","This assumption","many real-world heterophilic graphs"],"filter_categories":{"ai_ml":["Graph Neural Networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Personalized PageRank":2.0,"arXiv250716347v2 Announce Type":1.0,"Abstract":1.0,"Graph Neural Networks":1.0,"GNNs":1.0,"node classification tasks":1.0,"connected nodes":1.0,"similar labels":1.0,"This assumption":1.0,"many real-world heterophilic graphs":1.0}},"age_hours":2.7816061544444444,"is_recent":true,"quality_score":1.0,"sentiment_score":7.929500000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5859,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9371,"joy":0.0049,"surprise":0.0273,"sadness":0.0109,"fear":0.0031,"anger":0.0076,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel graph neural network model (HPGNN) for heterophilic graphs. While it demonstrates improved performance on benchmark datasets, it remains at the research stage with no concrete deployments or evidence of economic viability. The potential climate impact is theoretical, as the model's application to climate-related problems is not explicitly demonstrated.","key_impact_metrics":["Better performance than five out of seven state-of-the-art methods","Reduced computational complexity"],"technology_tags":["Graph Neural Networks","Personalized PageRank"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:59:06.585136Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_719f9a3d00bb","title":"Zebra","content":"arXiv:2507.16746v2 Announce Type: replace Abstract: Humans often use visual aids, for example diagrams or sketches, when solving complex problems. Training multimodal models to do the same, known as Visual Chain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf visual CoT performance, which hinders reinforcement learning, and (2) the lack of high-quality visual CoT training data. We introduce $\\textbf{Zebra-CoT}$, a diverse large-scale dataset with 182,384 samples, containing logically coherent interleaved text-image reasoning traces. We focus on four categories of tasks where sketching or visual reasoning is especially natural, spanning scientific questions such as geometry, physics, and algorithms; 2D visual reasoning tasks like visual search and jigsaw puzzles; 3D reasoning tasks including 3D multi-hop inference, embodied and robot planning; visual logic problems and strategic games like chess. Fine-tuning the Anole-7B model on the Zebra-CoT training corpus results in an improvement of +12% in our test-set accuracy and yields up to +13% performance gain on standard VLM benchmark evaluations. Fine-tuning Bagel-7B yields a model that generates high-quality interleaved visual reasoning chains, underscoring Zebra-CoT's effectiveness for developing multimodal reasoning abilities. We open-source our dataset and models to support development and evaluation of visual CoT.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.16746","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.489171","language":"en","tags":["computer-science","cslg","preprints","cscv","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":193,"author":"Ang Li, Charles Wang, Deqing Fu, Kaiyu Yue, Zikui Cai, Wang Bill Zhu, Ollie Liu, Peng Guo, Willie Neiswanger, Furong Huang, Tom Goldstein, Micah Goldblum","raw_content_length":1411,"priority":7,"update_frequency":1,"reading_time_minutes":0.965,"robust_parsing_used":true,"entities":{"organizations":["CoT","Visual Chain of Thought"],"persons":[],"locations":[],"monetary":[]},"char_count":1410,"language_detected":"en","key_concepts":{"key_phrases":["Zebra","Announce Type","Abstract","Humans","visual aids","example diagrams","sketches","complex problems","multimodal models","Visual Chain"],"filter_categories":{"ai_ml":["visual aids"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Zebra":2.0,"Announce Type":1.0,"Abstract":1.0,"Humans":1.0,"visual aids":1.0,"example diagrams":1.0,"sketches":1.0,"complex problems":1.0,"multimodal models":1.0,"Visual Chain":1.0}},"age_hours":2.781622002222222,"is_recent":true,"quality_score":0.7,"sentiment_score":1.8755,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6249,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.887,"joy":0.006,"surprise":0.0419,"sadness":0.0261,"fear":0.011,"anger":0.0173,"disgust":0.0107},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a new dataset (Zebra-CoT) for training multimodal AI models. While the AI itself doesn't directly impact climate, it could potentially be used in the future to optimize resource use or accelerate scientific discovery related to sustainability. The dataset and models are open-sourced, increasing accessibility and reproducibility.","key_impact_metrics":["+12% in test-set accuracy","+13% performance gain on standard VLM benchmark evaluations"],"technology_tags":["multimodal AI","visual reasoning","machine learning"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-28T20:59:09.615554Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f37815d4807a","title":"Controllable Hybrid Captioner for Improved Long","content":"arXiv:2507.17047v3 Announce Type: replace Abstract: Video data, especially long-form video, is extremely dense and high-dimensional. Text-based summaries of video content offer a way to represent query-relevant content in a much more compact manner than raw video. In addition, textual representations are easily ingested by state-of-the-art large language models (LLMs), which enable reasoning over video content to answer complex natural language queries. To solve this issue, we rely on the progressive construction of a text-based memory by a video captioner operating on shorter chunks of the video, where spatio-temporal modeling is computationally feasible. We explore ways to improve the quality of the activity log comprised solely of short video captions. Because the video captions tend to be focused on human actions, and questions may pertain to other information in the scene, we seek to enrich the memory with static scene descriptions using Vision Language Models (VLMs). Our video understanding system relies on the LaViLa video captioner in combination with a LLM to answer questions about videos. We first explored different ways of partitioning the video into meaningful segments such that the textual descriptions more accurately reflect the structure of the video content. Furthermore, we incorporated static scene descriptions into the captioning pipeline using LLaVA VLM, resulting in a more detailed and complete caption log and expanding the space of questions that are answerable from the textual memory. Finally, we have successfully fine-tuned the LaViLa video captioner to produce both action and scene captions, significantly improving the efficiency of the captioning pipeline compared to using separate captioning models for the two tasks. Our model, controllable hybrid captioner, can alternate between different types of captions according to special input tokens that signals scene changes detected in the video.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.17047","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.489612","language":"en","tags":["computer-science","csai","cscv","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":285,"author":"Kuleen Sasse, Efsun Sarioglu Kayi, Arun Reddy","raw_content_length":1949,"priority":7,"update_frequency":1,"reading_time_minutes":1.425,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1948,"language_detected":"en","key_concepts":{"key_phrases":["Controllable Hybrid Captioner","Improved Long","video content","arXiv250717047v3 Announce Type","Abstract","Video data","especially long-form video","Text-based summaries","a way","query-relevant content"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Controllable Hybrid Captioner":2.0,"Improved Long":2.0,"video content":2.0,"arXiv250717047v3 Announce Type":1.0,"Abstract":1.0,"Video data":1.0,"especially long-form video":1.0,"Text-based summaries":1.0,"a way":1.0,"query-relevant content":1.0}},"age_hours":2.7816376883333334,"is_recent":true,"quality_score":0.7,"sentiment_score":8.953,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7906,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.943,"joy":0.0205,"surprise":0.0209,"sadness":0.0025,"fear":0.0019,"anger":0.0055,"disgust":0.0058},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper focuses on improving video captioning using AI models. While it aims to improve the efficiency of AI models, there is no direct or measurable impact on climate change or sustainability. The research is in the applied research stage, with no deployment data available.","key_impact_metrics":["Efficiency of captioning pipeline improved","Accuracy of video content description improved"],"technology_tags":["Video Captioning","Vision Language Models","Large Language Models"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:59:13.745516Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9fb7575f9774","title":"From Feedback to Checklists: Grounded Evaluation of AI","content":"arXiv:2507.17717v2 Announce Type: replace Abstract: AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters (prepared in accordance with the HIPAA safe harbor standard) from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms a baseline approach in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklist's robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, our checklist offers a practical tool for flagging notes that may fall short of our defined quality standards.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.17717","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.490599","language":"en","tags":["cscl","computer-science","csai","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":166,"author":"Karen Zhou, John Giorgi, Pranav Mani, Peng Xu, Davis Liang, Chenhao Tan","raw_content_length":1239,"priority":7,"update_frequency":1,"reading_time_minutes":0.83,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1238,"language_detected":"en","key_concepts":{"key_phrases":["Feedback","Checklists","Grounded Evaluation","arXiv250717717v2 Announce Type","Abstract","AI-generated clinical notes","healthcare","their quality","a challenge","high subjectivity"],"filter_categories":{"ai_ml":["AI-generated clinical notes"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Feedback":2.0,"Checklists":2.0,"Grounded Evaluation":2.0,"arXiv250717717v2 Announce Type":1.0,"Abstract":1.0,"AI-generated clinical notes":1.0,"healthcare":1.0,"their quality":1.0,"a challenge":1.0,"high subjectivity":1.0}},"age_hours":2.7816518899999996,"is_recent":true,"quality_score":1.0,"sentiment_score":1.1580000000000001,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7684,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9302,"joy":0.0024,"surprise":0.0143,"sadness":0.0084,"fear":0.011,"anger":0.0177,"disgust":0.0161},"emotion_method":"local"},"sustainability_analysis":{"content_type":"technology_deployment","innovation_stage":"commercial","climate_impact_potential":3,"technical_credibility":7,"economic_viability":5,"deployment_readiness":7,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":true,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":true},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"The article describes a deployed AI medical scribe system using data from over 21,000 clinical encounters. The system's performance is evaluated using a feedback-derived checklist, showing improved coverage and predictive power compared to a baseline. This suggests a commercial stage deployment with measurable outcomes and some independent validation through offline evaluations.","key_impact_metrics":["21,000 clinical encounters","Improved coverage"],"technology_tags":["AI","Medical Scribe","LLM"],"sdg_alignment":[3],"analyzed_at":"2025-10-28T20:59:16.614550Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_692f89f1faa0","title":"FMI Meets SystemC: A Framework for Cross","content":"arXiv:2507.18339v2 Announce Type: replace Abstract: As systems become more complex, the demand for thorough testing and virtual prototyping grows. To simulate whole systems, multiple tools are usually needed to cover different parts. These parts include the hardware of a system and the environment with which the system interacts. The Functional Mock-up Interface (FMI) standard for co-simulation can be used to connect these tools. The control part of modern systems is usually a computing unit, such as a System-on-a-Chip (SoC) or Microcontroller Unit (MCU), which executes software from a connected memory and interacts with peripherals. To develop software without requiring access to physical hardware, full-system simulators, the so-called Virtual Platforms (VPs), are commonly used. The IEEE-standardized framework for VP development is SystemC TLM. SystemC provides interfaces and concepts that enable modular design and model exchange. However, SystemC lacks native FMI support, which limits the integration into broader co-simulation environments. This paper presents a novel framework to control and interact with SystemC-based VPs using the FMI. We present a case study showing how a simulated temperature sensor in a SystemC simulation can obtain temperature values from an external tool via FMI. This approach allows the unmodified target software to run on the VP and receive realistic environmental input data such as temperature, velocity, or acceleration values from other tools. Thus, extensive software testing and verification is enabled. By having tests ready and the software pre-tested using a VP once the physical hardware is available, certifications like ISO 26262 can be done earlier.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2507.18339","published_date":"2025-10-10T04:00:00","collected_date":"2025-10-10T06:41:18.491049","language":"en","tags":["csse","csdc","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":250,"author":"Nils Bosbach, Meik Schmidt, Lukas J\\\"unger, Matthias Berthold, Rainer Leupers","raw_content_length":1718,"priority":7,"update_frequency":1,"reading_time_minutes":1.25,"robust_parsing_used":true,"entities":{"organizations":["MCU","IEEE","TLM","The Functional Mock-up Interface","Virtual Platforms","FMI","Microcontroller Unit"],"persons":["Announce Type","FMI Meets"],"locations":[],"monetary":[]},"char_count":1713,"language_detected":"en","key_concepts":{"key_phrases":["FMI","SystemC","A Framework","Cross","arXiv250718339v2 Announce Type","Abstract","systems","thorough testing","virtual prototyping grows","whole systems"],"filter_categories":{"engineering":["systems"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"FMI":3.0,"SystemC":2.0,"A Framework":2.0,"Cross":2.0,"arXiv250718339v2 Announce Type":1.0,"Abstract":1.0,"systems":1.0,"thorough testing":1.0,"virtual prototyping grows":1.0,"whole systems":1.0}},"age_hours":2.7816681808333334,"is_recent":true,"quality_score":1.0,"sentiment_score":4.0325,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1935,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8564,"joy":0.0253,"surprise":0.0798,"sadness":0.007,"fear":0.0146,"anger":0.0119,"disgust":0.0051},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a framework for co-simulation using FMI and SystemC, enabling more thorough testing and verification of software for complex systems. While it doesn't directly reduce GHG emissions, it can indirectly contribute by improving the efficiency and reliability of systems, potentially leading to reduced energy consumption. The framework is at the applied research stage, with a case study demonstrating its functionality, but lacks deployment data or economic viability analysis.","key_impact_metrics":[],"technology_tags":["co-simulation","FMI","SystemC","Virtual Platform"],"sdg_alignment":[9],"analyzed_at":"2025-10-28T20:59:19.500447Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
