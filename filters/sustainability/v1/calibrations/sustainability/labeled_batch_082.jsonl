{"id":"science_arxiv_cs_69778a317ff2","title":"A Knowledge-Informed Deep Learning Paradigm for Generalizable and Stability","content":"arXiv:2504.14241v2 Announce Type: replace Abstract: Car-following models (CFMs) are fundamental to traffic flow analysis and autonomous driving. Although calibrated physics-based and trained data-driven CFMs can replicate human driving behavior, their reliance on specific datasets limits generalization across diverse scenarios and reduces reliability in real-world deployment. Moreover, these models typically focus on behavioral fidelity and do not support the explicit optimization of local and string stability, which are increasingly important for the safe and efficient operation of autonomous vehicles (AVs). To address these limitations, we propose a Knowledge-Informed Deep Learning (KIDL) paradigm that distills the generalization capabilities of pre-trained Large Language Models (LLMs) into a lightweight and stability-aware neural architecture. LLMs are used to extract fundamental car-following knowledge beyond dataset-specific patterns, and this knowledge is transferred to a reliable, tractable, and computationally efficient model through knowledge distillation. KIDL also incorporates stability constraints directly into its training objective, ensuring that the resulting model not only emulates human-like behavior but also satisfies the local and string stability requirements essential for real-world AV deployment. We evaluate KIDL on the real-world NGSIM and HighD datasets, comparing its performance with representative physics-based, data-driven, and hybrid CFMs. Both empirical and theoretical results consistently demonstrate KIDL's superior behavioral generalization and traffic flow stability, offering a robust and scalable solution for next-generation traffic systems.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14241","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.862116","language":"en","tags":["research","csai","preprints","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":215,"author":"Chengming Wang, Dongyao Jia, Wei Wang, Dong Ngoduy, Bei Peng, Jianping Wang","raw_content_length":1703,"priority":7,"update_frequency":1,"reading_time_minutes":1.075,"robust_parsing_used":true,"entities":{"organizations":["a Knowledge-Informed Deep Learning","Large Language Models"],"persons":[],"locations":[],"monetary":[]},"char_count":1702,"language_detected":"en","key_concepts":{"key_phrases":["A Knowledge-Informed Deep Learning Paradigm","Generalizable","Stability","arXiv250414241v2 Announce Type","Abstract","Car-following models","CFMs","traffic flow analysis","autonomous driving","calibrated physics-based and trained data-driven CFMs"],"filter_categories":{"ai_ml":["A Knowledge-Informed Deep Learning Paradigm"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Knowledge-Informed Deep Learning Paradigm":2.0,"Generalizable":2.0,"Stability":2.0,"arXiv250414241v2 Announce Type":1.0,"Abstract":1.0,"Car-following models":1.0,"CFMs":1.0,"traffic flow analysis":1.0,"autonomous driving":1.0,"calibrated physics-based and trained data-driven CFMs":1.0}},"age_hours":2.771237806666667,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.931,"joy":0.0061,"surprise":0.022,"sadness":0.0046,"fear":0.0148,"anger":0.012,"disgust":0.0095},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research proposes a new AI model (KIDL) for car-following that aims to improve traffic flow stability and generalization. The model is evaluated on real-world datasets (NGSIM and HighD), demonstrating superior behavioral generalization and traffic flow stability compared to existing models. However, it is still in the research phase with no deployed units or customer contracts, limiting its deployment readiness and economic viability.","key_impact_metrics":["superior behavioral generalization","traffic flow stability"],"technology_tags":["Knowledge-Informed Deep Learning","Car-Following Models","Autonomous Vehicles"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:50:49.315492Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d958300033b1","title":"Cyclic Proofs in Hoare Logic and its Reverse","content":"arXiv:2504.14283v2 Announce Type: replace Abstract: We examine the relationships between axiomatic and cyclic proof systems for the partial and total versions of Hoare logic and those of its dual, known as reverse Hoare logic (or sometimes incorrectness logic). In the axiomatic proof systems for these logics, the proof rules for looping constructs involve an explicit loop invariant, which in the case of the total versions additionally require a well-founded termination measure. In the cyclic systems, these are replaced by rules that simply unroll the loops, together with a principle allowing the formation of cycles in the proof, subject to a global soundness condition that ensures the well-foundedness of the circular reasoning. Interestingly, the cyclic soundness conditions for partial Hoare logic and its reverse are similar and essentially coinductive in character, while those for the total versions are also similar and essentially inductive. We show that these cyclic systems are sound, by direct argument, and relatively complete, by translation from axiomatic to cyclic proofs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14283","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.862523","language":"en","tags":["research","preprints","cslo","cspl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":163,"author":"James Brotherston, Quang Loc Le, Gauri Desai, Yukihiro Oda","raw_content_length":1096,"priority":7,"update_frequency":1,"reading_time_minutes":0.815,"robust_parsing_used":true,"entities":{"organizations":["Hoare","Cyclic Proofs","Hoare Logic"],"persons":[],"locations":[],"monetary":[]},"char_count":1095,"language_detected":"en","key_concepts":{"key_phrases":["Cyclic Proofs","Hoare Logic","its Reverse","Announce Type","the relationships","axiomatic and cyclic proof systems","the partial and total versions","Hoare logic","those","reverse Hoare logic"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cyclic Proofs":2.0,"Hoare Logic":2.0,"its Reverse":2.0,"Announce Type":1.0,"the relationships":1.0,"axiomatic and cyclic proof systems":1.0,"the partial and total versions":1.0,"Hoare logic":1.0,"those":1.0,"reverse Hoare logic":1.0}},"age_hours":2.771253308611111,"is_recent":true,"quality_score":1.0,"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.9355,"joy":0.0086,"surprise":0.0365,"sadness":0.0048,"fear":0.0031,"anger":0.0077,"disgust":0.0037},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper explores theoretical improvements to proof systems for Hoare logic, which could potentially lead to more efficient software verification. While better software verification could indirectly contribute to sustainability by improving the reliability of climate models or optimizing energy consumption in software, this is a very indirect and speculative link. The research is at a basic research stage with no immediate deployment or measurable outcomes.","key_impact_metrics":[],"technology_tags":["Formal verification","Hoare logic","Software engineering"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:50:52.299381Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_b7d07f139058","title":"Safe Autonomous Environmental Contact for Soft Robots using Control Barrier Functions","content":"arXiv:2504.14755v2 Announce Type: replace Abstract: Robots built from soft materials will inherently apply lower environmental forces than their rigid counterparts, and therefore may be more suitable in sensitive settings with unintended contact. However, these robots' applied forces result from both their design and their control system in closed-loop, and therefore, ensuring bounds on these forces requires controller synthesis for safety as well. This article introduces the first feedback controller for a soft manipulator that formally meets a safety specification with respect to environmental contact. In our proof-of-concept setting, the robot's environment has known geometry and is deformable with a known elastic modulus. Our approach maps a bound on applied forces to a safe set of positions of the robot's tip via predicted deformations of the environment. Then, a quadratic program with Control Barrier Functions in its constraints is used to supervise a nominal feedback signal, verifiably maintaining the robot's tip within this safe set. Hardware experiments on a multi-segment soft pneumatic robot demonstrate that the proposed framework successfully maintains a positive safety margin. This framework represents a fundamental shift in perspective on control and safety for soft robots, implementing a formally verifiable logic specification on their pose and contact forces.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.14755","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.862930","language":"en","tags":["research","preprints","eesssy","cssy","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Akua K. Dickson, Juan C. Pacheco Garcia, Meredith L. Anderson, Ran Jing, Sarah Alizadeh-Shabdiz, Audrey X. Wang, Charles DeLorey, Zach J. Patterson, Andrew P. Sabelhaus","raw_content_length":1397,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Control Barrier Functions arXiv:2504.14755v2","Safe Autonomous Environmental Contact"],"persons":["Control Ba"],"locations":[],"monetary":[]},"char_count":1396,"language_detected":"en","key_concepts":{"key_phrases":["Safe Autonomous Environmental Contact","Soft Robots","Control Barrier Functions","arXiv250414755v2 Announce Type","Abstract","Robots","soft materials","lower environmental forces","their rigid counterparts","sensitive settings"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Safe Autonomous Environmental Contact":2.0,"Soft Robots":2.0,"Control Barrier Functions":2.0,"arXiv250414755v2 Announce Type":1.0,"Abstract":1.0,"Robots":1.0,"soft materials":1.0,"lower environmental forces":1.0,"their rigid counterparts":1.0,"sensitive settings":1.0}},"age_hours":2.771268254722222,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9377,"joy":0.0093,"surprise":0.0204,"sadness":0.0056,"fear":0.0075,"anger":0.0106,"disgust":0.0088},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":4,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":true},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This article presents a feedback controller for soft robots that maintains a safety margin during environmental contact. The concrete action is hardware experiments on a soft pneumatic robot, demonstrating the framework's ability to maintain a positive safety margin. The evidence is based on experimental results and a formally verifiable logic specification, but the climate impact is indirect, potentially enabling safer interaction with sensitive environments in the future.","key_impact_metrics":["positive safety margin"],"technology_tags":["soft robotics","control barrier functions","robotics safety"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:50:55.292202Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_7720aff6d730","title":"On Developers' Self","content":"arXiv:2504.16485v3 Announce Type: replace Abstract: AI code generation tools have gained significant popularity among developers, who use them to assist in software development due to their capability to generate code. Existing studies mainly explored the quality, e.g., correctness and security, of AI-generated code, while in real-world software development, the prerequisite is to distinguish AI-generated code from human-written code, which emphasizes the need to explicitly declare AI-generated code by developers. To this end, this study intends to understand the ways developers use to self-declare AI-generated code and explore the reasons why developers choose to self-declare or not. We conducted a mixed-methods study consisting of two phases. In the first phase, we mined GitHub repositories and collected 613 instances of AI-generated code snippets. In the second phase, we conducted a follow-up practitioners' survey, which received 111 valid responses. Our research revealed the practices followed by developers to self-declare AI-generated code. Most practitioners (76.6%) always or sometimes self-declare AI-generated code. In contrast, other practitioners (23.4%) noted that they never self-declare AI-generated code. The reasons for self-declaring AI-generated code include the need to track and monitor the code for future review and debugging, and ethical considerations. The reasons for not self-declaring AI-generated code include extensive modifications to AI-generated code and the developers' perception that self-declaration is an unnecessary activity. We finally provided guidelines for practitioners to self-declare AI-generated code, addressing ethical and code quality concerns.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.16485","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.863367","language":"en","tags":["research","csse","csai","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":231,"author":"Syed Mohammad Kashif, Peng Liang, Amjed Tahir","raw_content_length":1710,"priority":7,"update_frequency":1,"reading_time_minutes":1.155,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1709,"language_detected":"en","key_concepts":{"key_phrases":["Developers Self","AI-generated code","arXiv250416485v3 Announce Type","Abstract","AI code generation tools","significant popularity","developers","who","them","software development"],"filter_categories":{"ai_ml":["AI-generated code"],"engineering":["software development"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Developers Self":2.0,"AI-generated code":2.0,"arXiv250416485v3 Announce Type":1.0,"Abstract":1.0,"AI code generation tools":1.0,"significant popularity":1.0,"developers":1.0,"who":1.0,"them":1.0,"software development":1.0}},"age_hours":2.771283773611111,"is_recent":true,"quality_score":0.7,"sentiment_score":9.18,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.836,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9197,"joy":0.0213,"surprise":0.0363,"sadness":0.0031,"fear":0.0033,"anger":0.0088,"disgust":0.0075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":5,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This research explores developer practices around self-declaring AI-generated code, finding that 76.6% sometimes or always self-declare. While it doesn't directly reduce emissions, it addresses ethical considerations in software development, which can indirectly influence sustainability by promoting responsible technology use. The study uses a mixed-methods approach, including mining GitHub repositories and conducting a practitioner survey, lending some credibility to the findings.","key_impact_metrics":["76.6% practitioners self-declare","23.4% practitioners never self-declare"],"technology_tags":["AI code generation","Software development"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:50:58.184880Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_96eca4676fe6","title":"Exploring human","content":"arXiv:2504.16548v2 Announce Type: replace Abstract: There has been extensive prior work exploring how psychological factors such as anthropomorphism affect the adoption of Shared Autonomous Vehicles (SAVs). However, limited research has been conducted on how prompt strategies in large language models (LLM)-powered conversational SAV agents affect users' perceptions, experiences, and intentions to adopt such technology. In this work, we investigate how conversational SAV agents powered by LLMs drive these psychological factors, such as psychological ownership, the sense of possession a user may come to feel towards an entity or object they may not legally own. We designed four SAV agents with varying levels of anthropomorphic characteristics and psychological ownership triggers. Quantitative measures of psychological ownership, anthropomorphism, quality of service, disclosure tendency, sentiment of SAV responses, and overall acceptance were collected after participants interacted with each SAV. Qualitative feedback was also gathered regarding the experience of psychological ownership during the interactions. The results indicate that an SAV designed to be more anthropomorphic and to induce psychological ownership improved users' perceptions of the SAV's human-like qualities, and its responses were perceived as more positive but also more subjective compared to the control conditions. Qualitative findings support established routes to psychological ownership in the SAV context and suggest that the conversational agent's perceived performance may also influence psychological ownership. Both quantitative and qualitative outcomes highlight the importance of personalization in designing effective SAV interactions. These findings provide practical guidance for designing conversational SAV agents that enhance user experience and adoption.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.16548","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.863790","language":"en","tags":["research","csai","preprints","cshc","computer-science","cset","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":246,"author":"Lirui Guo, Michael G. Burke, Wynita M. Griggs","raw_content_length":1863,"priority":7,"update_frequency":1,"reading_time_minutes":1.23,"robust_parsing_used":true,"entities":{"organizations":["Shared Autonomous Vehicles","SAV"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1862,"language_detected":"en","key_concepts":{"key_phrases":["human","arXiv250416548v2 Announce Type","Abstract","extensive prior work","how psychological factors","anthropomorphism","the adoption","Shared Autonomous Vehicles","SAVs","limited research"],"filter_categories":{"research_academic":["limited research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"human":2.0,"arXiv250416548v2 Announce Type":1.0,"Abstract":1.0,"extensive prior work":1.0,"how psychological factors":1.0,"anthropomorphism":1.0,"the adoption":1.0,"Shared Autonomous Vehicles":1.0,"SAVs":1.0,"limited research":1.0}},"age_hours":2.771298330555555,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.912,"joy":0.0229,"surprise":0.0381,"sadness":0.0045,"fear":0.0087,"anger":0.0079,"disgust":0.0059},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article explores the impact of LLM-powered conversational agents in shared autonomous vehicles (SAVs) on user perception and adoption. While it presents quantitative measures of psychological ownership, anthropomorphism, quality of service, disclosure tendency, sentiment of SAV responses, and overall acceptance, it remains at the research stage with no actual deployment or measurable environmental impact. The study focuses on user experience and personalization, not direct climate benefits.","key_impact_metrics":["Psychological ownership","Anthropomorphism"],"technology_tags":["Shared Autonomous Vehicles","Large Language Models","Conversational Agents"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:51:01.310654Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a918054ab113","title":"Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning","content":"arXiv:2504.17192v4 Announce Type: replace Abstract: Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, particularly from the authors of those papers, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins. Code is available at: https://github.com/going-doer/Paper2Code.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.17192","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.864199","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":196,"author":"Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":0.98,"robust_parsing_used":true,"entities":{"organizations":["LLM","PaperCoder"],"persons":["Large Language Models"],"locations":[],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["Paper2Code","Automating","Code Generation","Scientific Papers","Machine Learning","Announce Type","Abstract","the rapid growth","machine learning research","corresponding code implementations"],"filter_categories":{"ai_ml":["Machine Learning","machine learning research"],"research_academic":["machine learning research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Paper2Code":2.0,"Automating":2.0,"Code Generation":2.0,"Scientific Papers":2.0,"Machine Learning":2.0,"Announce Type":1.0,"Abstract":1.0,"the rapid growth":1.0,"machine learning research":1.0,"corresponding code implementations":1.0}},"age_hours":2.7713148527777776,"is_recent":true,"quality_score":1.0,"sentiment_score":8.072,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6144,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8934,"joy":0.0117,"surprise":0.0457,"sadness":0.0123,"fear":0.0107,"anger":0.0169,"disgust":0.0092},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research automates code generation from scientific papers, potentially accelerating the development and deployment of machine learning models for climate solutions. The technical credibility is supported by model-based and human evaluations, including author feedback. However, it is still in the early stages of development with no deployed units or customer contracts, limiting its immediate impact and economic viability.","key_impact_metrics":["PaperBench benchmark surpassing strong baselines"],"technology_tags":["Large Language Models","Code Generation","Machine Learning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:04.057144Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_026d96d485ca","title":"Dynamic r-index: An Updatable Self","content":"arXiv:2504.19482v3 Announce Type: replace Abstract: A self-index is a compressed data structure that supports locate queries--reporting all positions where a given pattern occurs in a string while maintaining the string in compressed form. While many self-indexes have been proposed, developing dynamically updatable ones supporting string insertions and deletions remains a challenge. The r-index (Gagie et al., JACM'20) is a representative static self-index based on the run-length Burrows-Wheeler transform (RLBWT), designed for highly repetitive strings. We present the dynamic r-index, a dynamic extension of the r-index that achieves updates in LCP-bounded time. The dynamic r-index supports count queries in $\\mathcal{O}(m \\log r / \\log \\log r)$ time and locate queries in $\\mathcal{O}(m \\log r / \\log \\log r + \\mathsf{occ} \\log r)$ time, using $\\mathcal{O}(r)$ words of space, where $m$ is the length of a query with $\\mathsf{occ}$ occurrences and $r$ is the number of runs in the RLBWT. Crucially, update operations are supported in $\\mathcal{O}((m + L_{\\mathsf{max}}) \\log n)$ time for a substring of length $m$, where $L_{\\mathsf{max}}$ is the maximum LCP value; the average running time is $\\mathcal{O}((m + L_{\\mathsf{avg}}) \\log n)$, where $L_{\\mathsf{avg}}$ is the average LCP value. This LCP-bounded complexity is particularly advantageous for highly repetitive strings where LCP values are typically small. We experimentally demonstrate the practical efficiency of the dynamic r-index on various highly repetitive datasets.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.19482","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.864629","language":"en","tags":["computer-science","csds","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":221,"author":"Takaaki Nishimoto, Yasuo Tabei","raw_content_length":1541,"priority":7,"update_frequency":1,"reading_time_minutes":1.105,"robust_parsing_used":true,"entities":{"organizations":["Gagie","LCP"],"persons":[],"locations":[],"monetary":["\\mathsf{occ}$"]},"char_count":1540,"language_detected":"en","key_concepts":{"key_phrases":["Dynamic r-index","An Updatable Self","arXiv250419482v3 Announce Type","Abstract","A self-index","a compressed data structure","locate queries","all positions","a given pattern","a string"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Dynamic r-index":2.0,"An Updatable Self":2.0,"arXiv250419482v3 Announce Type":1.0,"Abstract":1.0,"A self-index":1.0,"a compressed data structure":1.0,"locate queries":1.0,"all positions":1.0,"a given pattern":1.0,"a string":1.0}},"age_hours":2.7713323141666666,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3445,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8689,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9176,"joy":0.011,"surprise":0.0561,"sadness":0.0049,"fear":0.0022,"anger":0.0055,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a dynamic extension of the r-index for compressed data storage, which could potentially reduce energy consumption in data centers by improving data compression and retrieval efficiency. The technical credibility is relatively high due to the mention of specific performance metrics and algorithms, but deployment readiness is low as it's still in the research phase. Economic viability is unclear as there's no cost analysis provided.","key_impact_metrics":["O(r) words of space","O((m + L_{\\mathsf{max}}) \\log n) time for updates"],"technology_tags":["data compression","self-index","Burrows-Wheeler transform"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:07.183217Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2e7a5bc68bf2","title":"Multimodal Language Models See Better When They Look Shallower","content":"arXiv:2504.21447v2 Announce Type: replace Abstract: Multimodal large language models (MLLMs) typically extract visual features from the final layers of a pretrained Vision Transformer (ViT). This widespread deep-layer bias, however, is largely driven by empirical convention rather than principled analysis. While prior studies suggest that different ViT layers capture different types of information, with shallower layers focusing on fine visual details and deeper layers aligning more closely with textual semantics, the impact of this variation on MLLM performance remains underexplored. We present the first comprehensive study of visual layer selection for MLLMs, analyzing representation similarity across ViT layers to establish shallow, middle, and deep layer groupings. Through extensive evaluation of MLLMs (1.4B-7B parameters) across 10 benchmarks encompassing 60+ tasks, we find that while deep layers excel in semantic-rich tasks like OCR, shallow and middle layers significantly outperform them on fine-grained visual tasks including counting, positioning, and object localization. Building on these insights, we propose a lightweight feature fusion method that strategically incorporates shallower layers, achieving consistent improvements over both single-layer and specialized fusion baselines. Our work offers the first principled study of visual layer selection in MLLMs, showing that MLLMs can often see better when they look shallower.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2504.21447","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.865032","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Haoran Chen, Junyan Lin, Xinghao Chen, Yue Fan, Jianfeng Dong, Xin Jin, Hui Su, Jinlan Fu, Xiaoyu Shen","raw_content_length":1458,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Multimodal Language Models See Better","ViT","Vision Transformer"],"persons":[],"locations":[],"monetary":[]},"char_count":1457,"language_detected":"en","key_concepts":{"key_phrases":["Multimodal Language Models","Shallower","arXiv250421447v2 Announce Type","Abstract","Multimodal large language models","MLLMs","visual features","the final layers","a pretrained Vision Transformer","ViT"],"filter_categories":{"ai_ml":["Multimodal large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Multimodal Language Models":2.0,"Shallower":2.0,"arXiv250421447v2 Announce Type":1.0,"Abstract":1.0,"Multimodal large language models":1.0,"MLLMs":1.0,"visual features":1.0,"the final layers":1.0,"a pretrained Vision Transformer":1.0,"ViT":1.0}},"age_hours":2.7713473208333337,"is_recent":true,"quality_score":1.0,"sentiment_score":8.243,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6486,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9173,"joy":0.0041,"surprise":0.0135,"sadness":0.0065,"fear":0.0103,"anger":0.0166,"disgust":0.0316},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents research on improving the performance of multimodal language models by strategically selecting visual layers. While the research is credible and shows improvements on benchmarks, it is still in the early stages of development and lacks concrete deployment or quantifiable environmental impact. The vaporware flag is raised because it is an early-stage concept.","key_impact_metrics":["Improvements over baselines across 10 benchmarks","MLLMs (1.4B-7B parameters)"],"technology_tags":["Multimodal Language Models","Vision Transformer"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:51:10.219007Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_1820a4fab4f1","title":"Cognitio Emergens: Agency, Dimensions, and Dynamics in Human","content":"arXiv:2505.03105v2 Announce Type: replace Abstract: Human-AI scientific collaboration has evolved from tool-user relationships into co-evolutionary partnerships. When AlphaFold improved protein structure prediction, researchers engaged with an epistemic partner that transformed their approach to structure-function problems. Yet existing frameworks position AI as either sophisticated tool or potential risk, overlooking how scientific understanding emerges through recursive interaction. We introduce Cognitio Emergens (CE), a framework that captures the co-evolutionary nature of human-AI epistemic partnerships. Drawing from autopoiesis theory, social systems theory, and organizational modularity, CE integrates three components: Agency Configurations modeling how authority distributes through Directed, Contributory, and Partnership modes, with partnerships oscillating dynamically rather than following linear progression; Epistemic Dimensions capturing six capabilities along Discovery, Integration, and Projection axes, creating distinctive \"capability signatures\" that guide strategic development; and Partnership Dynamics identifying evolutionary forces including epistemic alienation, where researchers lose interpretive control over knowledge they formally endorse. The framework equips researchers to diagnose dimensional imbalances, institutional leaders to design governance structures supporting multiple agency configurations, and policymakers to develop evaluations beyond simple performance metrics. By reconceptualizing human-AI collaboration as fundamentally co-evolutionary, CE provides conceptual tools for cultivating partnerships that preserve epistemic integrity while enabling transformative breakthroughs neither humans nor AI could achieve independently.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.03105","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.865483","language":"en","tags":["research","csai","preprints","cshc","cscy","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":200,"author":"Xule Lin","raw_content_length":1790,"priority":7,"update_frequency":1,"reading_time_minutes":1.0,"robust_parsing_used":true,"entities":{"organizations":["Directed, Contributory","Dimensions"],"persons":["Cognitio Emergens"],"locations":["Epistemi"],"monetary":[]},"char_count":1785,"language_detected":"en","key_concepts":{"key_phrases":["Cognitio Emergens","Agency","Dimensions","Dynamics","Human","arXiv250503105v2 Announce Type","Abstract","Human-AI scientific collaboration","tool-user relationships","co-evolutionary partnerships"],"filter_categories":{"ai_ml":["Human-AI scientific collaboration"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Cognitio Emergens":2.0,"Agency":2.0,"Dimensions":2.0,"Dynamics":2.0,"Human":2.0,"arXiv250503105v2 Announce Type":1.0,"Abstract":1.0,"Human-AI scientific collaboration":1.0,"tool-user relationships":1.0,"co-evolutionary partnerships":1.0}},"age_hours":2.771361430833333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8331,"joy":0.008,"surprise":0.0532,"sadness":0.0171,"fear":0.0319,"anger":0.0382,"disgust":0.0187},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a framework for human-AI collaboration in scientific research. While it could potentially lead to breakthroughs that address climate change, it is currently at the basic research stage with no concrete deployments or measurable outcomes related to sustainability. The technical credibility is relatively high due to its grounding in established theories, but economic viability and deployment readiness are low.","key_impact_metrics":[],"technology_tags":["Artificial Intelligence","Scientific Collaboration","Epistemic Partnerships"],"sdg_alignment":[4,9,17],"analyzed_at":"2025-10-29T09:51:13.297219Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_ad12a25a12c3","title":"Deep Learning for Sports Video Event Detection: Tasks, Datasets, Methods, and Challenges","content":"arXiv:2505.03991v3 Announce Type: replace Abstract: Video event detection has become a cornerstone of modern sports analytics, powering automated performance evaluation, content generation, and tactical decision-making. Recent advances in deep learning have driven progress in related tasks such as Temporal Action Localization (TAL), which detects extended action segments; Action Spotting (AS), which identifies a representative timestamp; and Precise Event Spotting (PES), which pinpoints the exact frame of an event. Although closely connected, their subtle differences often blur the boundaries between them, leading to confusion in both research and practical applications. Furthermore, prior surveys either address generic video event detection or broader sports video tasks, but largely overlook the unique temporal granularity and domain-specific challenges of event spotting. In addition, most existing sports video surveys focus on elite-level competitions while neglecting the wider community of everyday practitioners. This survey addresses these gaps by: (i) clearly delineating TAL, AS, and PES and their respective use cases; (ii) introducing a structured taxonomy of state of the art approaches including temporal modeling strategies, multimodal frameworks, and data-efficient pipelines tailored for AS and PES; and (iii) critically assessing benchmark datasets and evaluation protocols, highlighting limitations such as reliance on broadcast quality footage and metrics that over reward permissive multilabel predictions. By synthesizing current research and exposing open challenges, this work provides a comprehensive foundation for developing temporally precise, generalizable, and practically deployable sports event detection systems for both the research and industry communities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.03991","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.865914","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":237,"author":"Hao Xu, Arbind Agrahari Baniya, Sam Well, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal","raw_content_length":1805,"priority":7,"update_frequency":1,"reading_time_minutes":1.185,"robust_parsing_used":true,"entities":{"organizations":["Challenges arXiv:2505.03991v3","TAL","Temporal Action Localization","PES"],"persons":["Action Spotting","Deep Learning for Sports Video Event Detection: Tasks"],"locations":[],"monetary":[]},"char_count":1804,"language_detected":"en","key_concepts":{"key_phrases":["which","Deep Learning","Sports Video Event Detection","Tasks","Datasets","Methods","Challenges","arXiv250503991v3","Announce Type","Video event detection"],"filter_categories":{"ai_ml":["Deep Learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"which":3.0,"Deep Learning":2.0,"Sports Video Event Detection":2.0,"Tasks":2.0,"Datasets":2.0,"Methods":2.0,"Challenges":2.0,"arXiv250503991v3":1.0,"Announce Type":1.0,"Video event detection":1.0}},"age_hours":2.7713770725,"is_recent":true,"quality_score":1.0,"sentiment_score":7.383500000000001,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4767,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8978,"joy":0.0159,"surprise":0.0538,"sadness":0.0046,"fear":0.0097,"anger":0.0135,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article is a survey of deep learning methods for sports video event detection. While it could potentially contribute to sustainability by improving resource allocation in sports (e.g., reducing travel for scouting), it's currently at the research stage with no concrete deployments or measurable outcomes related to climate impact. The technical credibility is high due to its survey nature and focus on state-of-the-art approaches, but deployment readiness is low.","key_impact_metrics":[],"technology_tags":["deep learning","video event detection","computer vision"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:51:16.090852Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e02140f24317","title":"System Prompt Optimization with Meta","content":"arXiv:2505.09666v2 Announce Type: replace Abstract: Large Language Models (LLMs) have shown remarkable capabilities, with optimizing their input prompts playing a pivotal role in maximizing their performance. However, while LLM prompts consist of both the task-agnostic system prompts and task-specific user prompts, existing work on prompt optimization has focused on user prompts specific to individual queries or tasks, and largely overlooked the system prompt that is, once optimized, applicable across different tasks and domains. Motivated by this, we introduce the novel problem of bilevel system prompt optimization, whose objective is to design system prompts that are robust to diverse user prompts and transferable to unseen tasks. To tackle this problem, we then propose a meta-learning framework, which meta-learns the system prompt by optimizing it over various user prompts across multiple datasets, while simultaneously updating the user prompts in an iterative manner to ensure synergy between them. We conduct experiments on 14 unseen datasets spanning 5 different domains, on which we show that our approach produces system prompts that generalize effectively to diverse user prompts. Also, our findings reveal that the optimized system prompt enables rapid adaptation even to unseen tasks, requiring fewer optimization steps for test-time user prompts while achieving improved performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.09666","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.866740","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":201,"author":"Yumin Choi, Jinheon Baek, Sung Ju Hwang","raw_content_length":1410,"priority":7,"update_frequency":1,"reading_time_minutes":1.005,"robust_parsing_used":true,"entities":{"organizations":["LLM"],"persons":[],"locations":[],"monetary":[]},"char_count":1409,"language_detected":"en","key_concepts":{"key_phrases":["System Prompt Optimization","Meta","Announce Type","Large Language Models","LLMs","remarkable capabilities","their input prompts","a pivotal role","their performance","LLM prompts"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"System Prompt Optimization":2.0,"Meta":2.0,"Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"remarkable capabilities":1.0,"their input prompts":1.0,"a pivotal role":1.0,"their performance":1.0,"LLM prompts":1.0}},"age_hours":2.7714065697222225,"is_recent":true,"quality_score":1.0,"sentiment_score":9.6685,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9337,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8719,"joy":0.0088,"surprise":0.0915,"sadness":0.0072,"fear":0.0087,"anger":0.0084,"disgust":0.0035},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a meta-learning framework to optimize system prompts for LLMs, which can improve performance across diverse tasks. The concrete action is the development and testing of this framework on 14 unseen datasets. While the research shows improved performance, it is still in the applied research phase and lacks deployment data or economic viability analysis.","key_impact_metrics":["Improved performance on 14 unseen datasets","Fewer optimization steps for test-time user prompts"],"technology_tags":["Large Language Models","Meta-Learning","Prompt Engineering"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:51:19.237399Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_95305d64768c","title":"MergeBench: A Benchmark for Merging Domain","content":"arXiv:2505.10833v3 Announce Type: replace Abstract: Model merging provides a scalable alternative to multi-task training by combining specialized finetuned models through parameter arithmetic, enabling efficient deployment without the need for joint training or access to all task data. While recent methods have shown promise, existing evaluations are limited in both model scale and task diversity, leaving open questions about their applicability to large, domain-specialized LLMs. To tackle the challenges, we introduce MergeBench, a comprehensive evaluation suite designed to assess model merging at scale. MergeBench builds on state-of-the-art open-source language models, including Llama and Gemma families at 2B to 9B scales, and covers five key domains: instruction following, mathematics, multilingual understanding, coding and safety. We standardize finetuning and evaluation protocols, and assess eight representative merging methods across multi-task performance, forgetting and runtime efficiency. Based on extensive experiments, we provide practical guidelines for algorithm selection and share insights showing that model merging tends to perform better on stronger base models, with techniques such as merging coefficient tuning and sparsification improving knowledge retention. However, several challenges remain, including the computational cost on large models, the gap for in-domain performance compared to multi-task models, and the underexplored role of model merging in standard LLM training pipelines. We hope MergeBench provides a foundation for future research to advance the understanding and practical application of model merging. Our project page is at \\href{https://yifei-he.github.io/mergebench/}{https://yifei-he.github.io/mergebench/}.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.10833","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.867548","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":226,"author":"Yifei He, Siqi Zeng, Yuzheng Hu, Rui Yang, Tong Zhang, Han Zhao","raw_content_length":1771,"priority":7,"update_frequency":1,"reading_time_minutes":1.13,"robust_parsing_used":true,"entities":{"organizations":["MergeBench","Gemma"],"persons":[],"locations":[],"monetary":[]},"char_count":1770,"language_detected":"en","key_concepts":{"key_phrases":["MergeBench","A Benchmark","Merging Domain","arXiv250510833v3 Announce Type","Abstract","Model merging","a scalable alternative","multi-task training","specialized finetuned models","parameter arithmetic enabling efficient deployment"],"filter_categories":{"ai_ml":["Merging Domain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"MergeBench":2.0,"A Benchmark":2.0,"Merging Domain":2.0,"arXiv250510833v3 Announce Type":1.0,"Abstract":1.0,"Model merging":1.0,"a scalable alternative":1.0,"multi-task training":1.0,"specialized finetuned models":1.0,"parameter arithmetic enabling efficient deployment":1.0}},"age_hours":2.7714376233333335,"is_recent":true,"quality_score":1.0,"sentiment_score":7.4695,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4939,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9208,"joy":0.0105,"surprise":0.0446,"sadness":0.0038,"fear":0.0066,"anger":0.0089,"disgust":0.0047},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces MergeBench, a benchmark for evaluating model merging techniques for large language models. While model merging could potentially reduce computational costs associated with training and deploying large models, leading to indirect energy savings, the impact is theoretical at this stage. The paper focuses on research and evaluation, with no deployed technology or measured outcomes in terms of energy consumption or emissions reduction.","key_impact_metrics":["Model scales at 2B to 9B parameters","Runtime efficiency improvements"],"technology_tags":["Model Merging","Large Language Models"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:51:22.245766Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_048bac50c249","title":"What's Inside Your Diffusion Model? A Score","content":"arXiv:2505.11128v3 Announce Type: replace Abstract: Recent advances in diffusion models have demonstrated their remarkable ability to capture complex image distributions, but the geometric properties of the learned data manifold remain poorly understood. We address this gap by introducing a score-based Riemannian metric that leverages the Stein score function from diffusion models to characterize the intrinsic geometry of the data manifold without requiring explicit parameterization. Our approach defines a metric tensor in the ambient space that stretches distances perpendicular to the manifold while preserving them along tangential directions, effectively creating a geometry where geodesics naturally follow the manifold's contours. We develop efficient algorithms for computing these geodesics and demonstrate their utility for both interpolation between data points and extrapolation beyond the observed data distribution. Through experiments on synthetic data with known geometry, Rotated MNIST, and complex natural images via Stable Diffusion, we show that our score-based geodesics capture meaningful transformations that respect the underlying data distribution. Our method consistently outperforms baseline approaches on perceptual metrics (LPIPS) and distribution-level metrics (FID, KID), producing smoother, more realistic image transitions. These results reveal the implicit geometric structure learned by diffusion models and provide a principled way to navigate the manifold of natural images through the lens of Riemannian geometry.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.11128","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.867957","language":"en","tags":["research","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":205,"author":"Simone Azeglio, Arianna Di Bernardo","raw_content_length":1557,"priority":7,"update_frequency":1,"reading_time_minutes":1.025,"robust_parsing_used":true,"entities":{"organizations":["Score arXiv:2505.11128v3 Announce Type:"],"persons":["Stein"],"locations":[],"monetary":[]},"char_count":1556,"language_detected":"en","key_concepts":{"key_phrases":["What","Your Diffusion Model","A Score","diffusion models","arXiv250511128v3 Announce Type","Abstract","Recent advances","their remarkable ability","complex image distributions","the geometric properties"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"Your Diffusion Model":2.0,"A Score":2.0,"diffusion models":2.0,"arXiv250511128v3 Announce Type":1.0,"Abstract":1.0,"Recent advances":1.0,"their remarkable ability":1.0,"complex image distributions":1.0,"the geometric properties":1.0}},"age_hours":2.7714517341666665,"is_recent":true,"quality_score":1.0,"sentiment_score":7.2485,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4497,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7864,"joy":0.0286,"surprise":0.1505,"sadness":0.009,"fear":0.008,"anger":0.0131,"disgust":0.0044},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel method for understanding the geometry of data manifolds learned by diffusion models, potentially leading to more efficient and realistic image generation. The concrete action is the development of a score-based Riemannian metric and algorithms for computing geodesics. Evidence is provided through experiments on synthetic and real image datasets, with performance evaluated using LPIPS, FID, and KID metrics. The technology is at a basic research stage with no deployment.","key_impact_metrics":["LPIPS score","FID score"],"technology_tags":["diffusion models","Riemannian geometry","machine learning"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:51:25.491246Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_2852df2289e2","title":"Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features","content":"arXiv:2505.12151v3 Announce Type: replace Abstract: Large language models have recently made great strides in reasoning task performance through chain-of-thought (CoT) strategies trained via reinforcement learning; however, these \"reasoning large language models\" (RLLMs) remain imperfect reasoners, and understanding the frequencies and causes of their failure modes is important for both users and developers. We test o1-mini, o3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, and Grok 3 Mini Beta on graph coloring as a variable-complexity constraint-satisfaction logic problem, and find evidence from both error rate comparisons and CoT/explanation text analysis that RLLMs are prone to hallucinate graph edges not specified in the prompt. This phenomenon persists across multiple problem complexity levels and semantic frames, and it appears to account for a significant fraction of the incorrect answers from every tested model, and the vast majority of them for some models. We also validate the generalizability of this input-conflicting hallucination phenomenon with smaller-scale experiments on a type of stable matching problem. Our results indicate that RLLMs may possess broader issues with misrepresentation of problem specifics, and we offer suggestions for design choices to mitigate this weakness.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12151","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.868370","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":185,"author":"Alex Heyman, Joel Zylberberg","raw_content_length":1330,"priority":7,"update_frequency":1,"reading_time_minutes":0.925,"robust_parsing_used":true,"entities":{"organizations":["Claude 3.7 Sonnet","Hallucinating Critical Problem Features","CoT","DeepSeek-R1"],"persons":["Grok 3 Mini Beta"],"locations":[],"monetary":[]},"char_count":1329,"language_detected":"en","key_concepts":{"key_phrases":["Reasoning Large Language Model Errors Arise","Hallucinating Critical Problem","arXiv250512151v3 Announce Type","Large language models","great strides","reasoning task performance","thought","reinforcement learning","large language models","imperfect reasoners"],"filter_categories":{"ai_ml":["Reasoning Large Language Model Errors Arise","Large language models","reinforcement learning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reasoning Large Language Model Errors Arise":2.0,"Hallucinating Critical Problem":2.0,"arXiv250512151v3 Announce Type":1.0,"Large language models":1.0,"great strides":1.0,"reasoning task performance":1.0,"thought":1.0,"reinforcement learning":1.0,"large language models":1.0,"imperfect reasoners":1.0}},"age_hours":2.771468450555555,"is_recent":true,"quality_score":1.0,"sentiment_score":1.3655,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7269,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9045,"joy":0.0065,"surprise":0.0216,"sadness":0.0364,"fear":0.0121,"anger":0.0108,"disgust":0.0081},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":1,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper identifies a flaw in reasoning large language models (RLLMs) related to hallucinating problem features, specifically in graph coloring and stable matching problems. While the research is scientifically sound and identifies a potential weakness in AI systems, it is still in the basic research phase with no immediate deployment or measurable environmental impact. The study quantifies error rates across different models, providing a metric for analysis.","key_impact_metrics":["Error rate comparisons","Fraction of incorrect answers"],"technology_tags":["Large Language Models","Artificial Intelligence"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:51:28.567060Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c22800cbfa34","title":"GUI-Shift: Enhancing VLM","content":"arXiv:2505.12493v3 Announce Type: replace Abstract: Training effective Vision-Language Models (VLMs) for GUI agents typically depends on large-scale annotated datasets, whose collection is both labor-intensive and error-prone. We introduce K-step GUI Transition, a self-supervised inverse dynamics task in which VLMs learn GUI dynamics by predicting the initial action that causes a transition between two GUI states. This approach eliminates the need for natural language instructions and enables scalable dataset construction from existing GUI trajectories or automated exploration. Building on this task, we propose GUI-Shift, a reinforcement learning (RL) framework that combines rule-based optimization with data filtering to improve VLM performance. We conduct extensive experiments using multiple VLM backbones across four benchmarks, spanning GUI task automation (AndroidControl, GUI Odyssey) and GUI grounding (ScreenSpot-v2, ScreenSpot-Pro). Our results show that training on GUI-Shift generalizes well to both GUI automation and grounding tasks, yielding up to an 11.2% increase in GUI automation accuracy. This study underscores the potential of self-supervised RL to leverage unlabeled GUI trajectories and offers a scalable alternative to training with annotated samples.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.12493","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.868764","language":"en","tags":["csai","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Longxi Gao, Li Zhang, Pengzhi Gao, Wei Liu, Jian Luan, Mengwei Xu","raw_content_length":1286,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["Vision-Language Models","AndroidControl","GUI","VLM"],"persons":["GUI Odyssey"],"locations":[],"monetary":[]},"char_count":1285,"language_detected":"en","key_concepts":{"key_phrases":["GUI-Shift","VLM","VLMs","arXiv250512493v3 Announce Type","Abstract","effective Vision-Language Models","GUI agents","large-scale annotated datasets","whose collection","K-step GUI Transition"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"GUI-Shift":2.0,"VLM":2.0,"VLMs":2.0,"arXiv250512493v3 Announce Type":1.0,"Abstract":1.0,"effective Vision-Language Models":1.0,"GUI agents":1.0,"large-scale annotated datasets":1.0,"whose collection":1.0,"K-step GUI Transition":1.0}},"age_hours":2.7714839719444444,"is_recent":true,"quality_score":1.0,"sentiment_score":9.158,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8316,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8455,"joy":0.0058,"surprise":0.01,"sadness":0.007,"fear":0.0913,"anger":0.0249,"disgust":0.0154},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a self-supervised reinforcement learning framework (GUI-Shift) to improve VLM performance in GUI automation and grounding tasks. The concrete action is the development of this framework and its testing on benchmarks, yielding up to an 11.2% increase in GUI automation accuracy. However, it is still in the applied research stage with no real-world deployments, hence the low scores.","key_impact_metrics":["GUI automation accuracy increase 11.2%"],"technology_tags":["Vision-Language Models","Reinforcement Learning","GUI Automation"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:31.874421Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_461adce90b25","title":"Meta","content":"arXiv:2505.13428v2 Announce Type: replace Abstract: We study the Student Project Allocation problem with lecturer preferences over Students (SPA-S), an extension of the well-known Stable Marriage and Hospital Residents problem. In this model, students have preferences over projects, each project is offered by a single lecturer, and lecturers have preferences over students. The goal is to compute a stable matching which is an assignment of students to projects (and thus to lecturers) such that no student or lecturer has an incentive to deviate from their current assignment. While motivated by the university setting, this problem arises in many allocation settings where limited resources are offered by agents with their own preferences, such as in wireless networks. We establish new structural results for the set of stable matchings in SPA-S by developing the theory of meta-rotations, a generalisation of the well-known notion of rotations from the Stable Marriage problem. Each meta-rotation corresponds to a minimal set of changes that transforms one stable matching into another within the lattice of stable matchings. The set of meta-rotations, ordered by their precedence relations, forms the meta-rotation poset. We prove that there is a one-to-one correspondence between the set of stable matchings and the closed subsets of the meta-rotation poset. By developing this structure, we provide a foundation for the design of efficient algorithms for enumerating and counting stable matchings, and for computing other optimal stable matchings, such as egalitarian or minimum-cost matchings, which have not been previously studied in SPA-S.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.13428","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.869178","language":"en","tags":["computer-science","csgt","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":245,"author":"Peace Ayegba, Sofiat Olaosebikan","raw_content_length":1656,"priority":7,"update_frequency":1,"reading_time_minutes":1.225,"robust_parsing_used":true,"entities":{"organizations":["SPA-S","Meta arXiv:2505.13428v2 Announce Type: replace Abstract","the Student Project Allocation","Stable Marriage and","Students"],"persons":[],"locations":[],"monetary":[]},"char_count":1653,"language_detected":"en","key_concepts":{"key_phrases":["students","Meta","preferences","projects","lecturers","arXiv250513428v2 Announce Type","Abstract","the Student Project Allocation problem","lecturer preferences","Students"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"students":3.0,"Meta":2.0,"preferences":2.0,"projects":2.0,"lecturers":2.0,"arXiv250513428v2 Announce Type":1.0,"Abstract":1.0,"the Student Project Allocation problem":1.0,"lecturer preferences":1.0,"Students":1.0}},"age_hours":2.7714996783333334,"is_recent":true,"quality_score":0.7,"sentiment_score":2.5305,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4939,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8939,"joy":0.0202,"surprise":0.0631,"sadness":0.0079,"fear":0.0025,"anger":0.0093,"disgust":0.0031},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":false,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for optimizing resource allocation, which could potentially be applied to various sustainability-related problems, such as allocating renewable energy projects or managing resources in wireless networks. However, it is currently in the basic research phase and lacks concrete deployment or measurable outcomes in terms of GHG emissions reduction or other environmental benefits. The technical credibility is relatively high due to the mathematical rigor and potential for peer review.","key_impact_metrics":[],"technology_tags":["optimization algorithms","resource allocation"],"sdg_alignment":[9,17],"analyzed_at":"2025-10-29T09:51:34.667398Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f55073f1125d","title":"Game of Trust: How Trustworthy Does Your Blockchain Think You Are?","content":"arXiv:2505.14551v2 Announce Type: replace Abstract: We investigate how a blockchain can distill the collective belief of its nodes regarding the trustworthiness of a (sub)set of nodes into a {\\em reputation system} that reflects the probability of correctly performing a task. To address this question, we introduce a framework that breaks it down into two sub-problems: 1. (Information Extraction): How can the system distill trust information from a function of the nodes' true beliefs? 2. (Incentive Design): How can we incentivize nodes to truthfully report such information? To tackle the first sub-problem, we adapt, in a non-trivial manner, the well-known PageRank algorithm to our problem. For the second, we define a new class of games, called Trustworthy Reputation games (TRep games), which aim to extract the collective beliefs on trust from the actions of rational participants. We then propose a concrete TRep game whose utility function leverages Personalized PageRank and can be instantiated through a straightforward blockchain rewards mechanism. Building on this, we show how the TRep game enables the design of a reputation system. Such systems can enhance the robustness, scalability, and efficiency of blockchain and DeFi solutions. For instance, we demonstrate how such a system can be used within a Proof-of-Reputation blockchain.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.14551","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.869972","language":"en","tags":["cscr","research","csai","csgt","preprints","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":203,"author":"Petros Drineas, Rohit Nema, Rafail Ostrovsky, Vassilis Zikas","raw_content_length":1360,"priority":7,"update_frequency":1,"reading_time_minutes":1.015,"robust_parsing_used":true,"entities":{"organizations":["Incentive Design","PageRank","TRep"],"persons":[],"locations":[],"monetary":[]},"char_count":1353,"language_detected":"en","key_concepts":{"key_phrases":["Trust","Trustworthy","Your Blockchain","You","arXiv250514551v2","Announce Type","Abstract","a blockchain","the collective belief","its nodes"],"filter_categories":{"ai_ml":["Your Blockchain"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Trust":2.0,"Trustworthy":2.0,"Your Blockchain":2.0,"You":2.0,"arXiv250514551v2":1.0,"Announce Type":1.0,"Abstract":1.0,"a blockchain":1.0,"the collective belief":1.0,"its nodes":1.0}},"age_hours":2.771531882777778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.593,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9186,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9259,"joy":0.0118,"surprise":0.0306,"sadness":0.0029,"fear":0.0091,"anger":0.013,"disgust":0.0067},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for a blockchain-based reputation system to enhance the robustness and efficiency of blockchain and DeFi solutions. It adapts the PageRank algorithm and proposes a new class of games (TRep games) to incentivize truthful reporting of trust information. While the potential impact on scalability and efficiency is noted, there are no concrete deployments or measured outcomes at this stage, keeping it at the basic research level.","key_impact_metrics":[],"technology_tags":["blockchain","reputation system","PageRank","DeFi"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:37.631130Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_6e1ada062c34","title":"CausalDynamics: A large","content":"arXiv:2505.16620v2 Announce Type: replace Abstract: Causal discovery for dynamical systems poses a major challenge in fields where active interventions are infeasible. Most methods used to investigate these systems and their associated benchmarks are tailored to deterministic, low-dimensional and weakly nonlinear time-series data. To address these limitations, we present CausalDynamics, a large-scale benchmark and extensible data generation framework to advance the structural discovery of dynamical causal models. Our benchmark consists of true causal graphs derived from thousands of both linearly and nonlinearly coupled ordinary and stochastic differential equations as well as two idealized climate models. We perform a comprehensive evaluation of state-of-the-art causal discovery algorithms for graph reconstruction on systems with noisy, confounded, and lagged dynamics. CausalDynamics consists of a plug-and-play, build-your-own coupling workflow that enables the construction of a hierarchy of physical systems. We anticipate that our framework will facilitate the development of robust causal discovery algorithms that are broadly applicable across domains while addressing their unique challenges. We provide a user-friendly implementation and documentation on https://kausable.github.io/CausalDynamics.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.16620","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.870375","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Benjamin Herdeanu, Juan Nathaniel, Carla Roesch, Jatan Buch, Gregor Ramien, Johannes Haux, Pierre Gentine","raw_content_length":1320,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["CausalDynamics"],"persons":[],"locations":[],"monetary":[]},"char_count":1319,"language_detected":"en","key_concepts":{"key_phrases":["CausalDynamics","arXiv250516620v2 Announce Type","Abstract","Causal discovery","dynamical systems","a major challenge","fields","active interventions","Most methods","these systems"],"filter_categories":{"research_academic":["Causal discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CausalDynamics":3.0,"arXiv250516620v2 Announce Type":1.0,"Abstract":1.0,"Causal discovery":1.0,"dynamical systems":1.0,"a major challenge":1.0,"fields":1.0,"active interventions":1.0,"Most methods":1.0,"these systems":1.0}},"age_hours":2.771546625,"is_recent":true,"quality_score":1.0,"sentiment_score":7.0025,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4005,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7998,"joy":0.0257,"surprise":0.0962,"sadness":0.0253,"fear":0.0321,"anger":0.0142,"disgust":0.0066},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a benchmark and data generation framework (CausalDynamics) for causal discovery in dynamical systems, including idealized climate models. While it aims to advance the development of robust causal discovery algorithms, it is currently in the basic research stage with no deployed technology or measured outcomes. The potential climate impact is theoretical, as it could indirectly improve climate modeling, but there are no concrete actions or quantified results yet.","key_impact_metrics":[],"technology_tags":["causal discovery","dynamical systems","climate modeling"],"sdg_alignment":[9,13],"analyzed_at":"2025-10-29T09:51:40.512141Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cf04367fe3f3","title":"Automated Capability Evaluation of Foundation Models","content":"arXiv:2505.17228v2 Announce Type: replace Abstract: Current evaluation frameworks for foundation models rely heavily on static, manually curated benchmarks, limiting their ability to capture the full breadth of model capabilities. This paper introduces Active learning for Capability Evaluation (ACE), a novel framework for scalable, automated, and fine-grained evaluation of foundation models. ACE leverages the knowledge embedded in powerful frontier models to decompose a domain into semantically meaningful capabilities and generates diverse evaluation tasks, significantly reducing human effort. In Mathematics, ACE generated 433 capabilities and 11,800 tasks, covering 94% of Wikipedia-defined skills in the domain while introducing novel, coherent ones. To maximize efficiency, ACE fits a capability model in latent semantic space, allowing reliable approximation of a subject model's performance by evaluating only a subset of capabilities via active learning. It reaches within 0.01 RMSE of exhaustive evaluation by evaluating less than half of capabilities. Compared to static datasets, ACE provides more balanced coverage and uncovers fine-grained differences that aggregate metrics fail to capture. Our results demonstrate that ACE provides a more complete and informative picture of model capabilities, which is essential for safe and well-informed deployment of foundation models.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.17228","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.871141","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":188,"author":"Arash Afkanpour, Omkar Dige, Fatemeh Tavakoli, Negin Baghbanzadeh, Farnaz Kohankhaki, Elham Dolatabadi","raw_content_length":1395,"priority":7,"update_frequency":1,"reading_time_minutes":0.94,"robust_parsing_used":true,"entities":{"organizations":["Wikipedia","ACE","Capability Evaluation (ACE"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1394,"language_detected":"en","key_concepts":{"key_phrases":["Automated Capability Evaluation","Foundation Models","foundation models","ACE","Announce Type","Current evaluation frameworks","manually curated benchmarks","their ability","the full breadth","model capabilities"],"filter_categories":{"healthcare_tech":["ACE"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Automated Capability Evaluation":2.0,"Foundation Models":2.0,"foundation models":2.0,"ACE":2.0,"Announce Type":1.0,"Current evaluation frameworks":1.0,"manually curated benchmarks":1.0,"their ability":1.0,"the full breadth":1.0,"model capabilities":1.0}},"age_hours":2.7715753008333333,"is_recent":true,"quality_score":1.0,"sentiment_score":9.221,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8442,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8751,"joy":0.0149,"surprise":0.0661,"sadness":0.0062,"fear":0.0092,"anger":0.021,"disgust":0.0077},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":5,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a novel framework (ACE) for evaluating foundation models, generating capabilities and tasks automatically. While it shows promise in improving model evaluation, its direct climate impact is currently theoretical. The framework is in the applied research stage, with no indication of deployment or economic viability yet.","key_impact_metrics":["94% of Wikipedia-defined skills covered","0.01 RMSE of exhaustive evaluation"],"technology_tags":["Active Learning","Foundation Models","Capability Evaluation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:51:43.284893Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_15f91eacb645","title":"AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models","content":"arXiv:2505.17312v4 Announce Type: replace Abstract: LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.17312","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.871547","language":"en","tags":["research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":156,"author":"Xiangqi Wang, Yue Huang, Yanbo Wang, Xiaonan Luo, Kehan Guo, Yujun Zhou, Xiangliang Zhang","raw_content_length":1209,"priority":7,"update_frequency":1,"reading_time_minutes":0.78,"robust_parsing_used":true,"entities":{"organizations":["LLM","AdaReasoner"],"persons":[],"locations":[],"monetary":[]},"char_count":1208,"language_detected":"en","key_concepts":{"key_phrases":["AdaReasoner","Adaptive Reasoning Enables","More Flexible Thinking","Large Language Models","tasks","Announce Type","LLMs","effective configurations","temperature and reasoning steps","sophisticated reasoning"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"AdaReasoner":3.0,"Adaptive Reasoning Enables":2.0,"More Flexible Thinking":2.0,"Large Language Models":2.0,"tasks":2.0,"Announce Type":1.0,"LLMs":1.0,"effective configurations":1.0,"temperature and reasoning steps":1.0,"sophisticated reasoning":1.0}},"age_hours":2.7715899944444446,"is_recent":true,"quality_score":1.0,"sentiment_score":8.116999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6234,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8905,"joy":0.0107,"surprise":0.032,"sadness":0.0045,"fear":0.0333,"anger":0.0211,"disgust":0.0079},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"AdaReasoner is presented as an LLM-agnostic plugin that automates adaptive reasoning configurations. While it shows promise in improving LLM performance across various tasks, its direct impact on sustainability is currently theoretical. The article lacks information on deployed units or real-world data demonstrating energy savings or emissions reductions.","key_impact_metrics":["Fast convergence","Sublinear policy gap"],"technology_tags":["Large Language Models","Reinforcement Learning","Adaptive Reasoning"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:46.158437Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5fe68cc6a36b","title":"Partition Generative Modeling: Masked Modeling Without Masks","content":"arXiv:2505.18883v2 Announce Type: replace Abstract: Masked generative models (MGMs) are widely used to capture complex data and enable faster generation than autoregressive models (AR) through parallel decoding. However, MGMs typically operate on fixed-length inputs, which can be inefficient: early in sampling, most tokens are masked and carry no information, leading to wasted computation. In contrast, AR models process only tokens generated previously, making early iterations faster. In this work, we introduce the Partition Generative Model (PGM), a novel approach that combines the strengths of AR and MGMs. Rather than masking, PGM partitions tokens into two groups and employs sparse attention to block information flow between them. Since there is no information flow between partitions, the model can process the previously-generated tokens only during sampling, while retaining the ability to generate tokens in parallel and in any order. On OpenWebText, PGMs offer at least $5\\times$ improvements in sampling latency and throughput, while producing samples with superior Generative Perplexity, compared to Masked Diffusion Language Models. On ImageNet, PGMs achieve a $7.5\\times$ higher throughput than MaskGIT, with only a slight increase in FID (5.54 vs. 5.35). With twice as many sampling steps, the FID reduces to 4.56 while while being $3.9\\times$ faster than MaskGIT. Finally, PGMs integrate seamlessly with MGM distillation, providing further inference speedups.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.18883","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.872342","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":212,"author":"Justin Deschenaux, Lan Tran, Caglar Gulcehre","raw_content_length":1484,"priority":7,"update_frequency":1,"reading_time_minutes":1.06,"robust_parsing_used":true,"entities":{"organizations":["PGM"],"persons":[],"locations":[],"monetary":[]},"char_count":1483,"language_detected":"en","key_concepts":{"key_phrases":["Partition Generative Modeling","Masked Modeling","Masks","MGMs","arXiv250518883v2 Announce Type","Abstract","Masked generative models","complex data","faster generation","autoregressive models"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Partition Generative Modeling":2.0,"Masked Modeling":2.0,"Masks":2.0,"MGMs":2.0,"arXiv250518883v2 Announce Type":1.0,"Abstract":1.0,"Masked generative models":1.0,"complex data":1.0,"faster generation":1.0,"autoregressive models":1.0}},"age_hours":2.771621011666667,"is_recent":true,"quality_score":1.0,"sentiment_score":1.7015000000000002,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.6597,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7736,"joy":0.0055,"surprise":0.0342,"sadness":0.0412,"fear":0.0053,"anger":0.0652,"disgust":0.075},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel machine learning model (PGM) that improves sampling latency and throughput compared to existing methods. The concrete action is the development and testing of this model on datasets like OpenWebText and ImageNet, showing performance improvements. While promising, it's still in the research phase with no deployed units.","key_impact_metrics":["5x improvements in sampling latency and throughput on OpenWebText","7.5x higher throughput than MaskGIT on ImageNet"],"technology_tags":["Generative Modeling","Machine Learning","Sparse Attention"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:49.272398Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_cd1472d04dc3","title":"The Role of Video Generation in Enhancing Data","content":"arXiv:2505.19495v2 Announce Type: replace Abstract: Video action understanding tasks in real-world scenarios always suffer data limitations. In this paper, we address the data-limited action understanding problem by bridging data scarcity. We propose a novel method that employs a text-to-video diffusion transformer to generate annotated data for model training. This paradigm enables the generation of realistic annotated data on an infinite scale without human intervention. We proposed the information enhancement strategy and the uncertainty-based label smoothing tailored to generate sample training. Through quantitative and qualitative analysis, we observed that real samples generally contain a richer level of information than generated samples. Based on this observation, the information enhancement strategy is proposed to enhance the informative content of the generated samples from two aspects: the environments and the characters. Furthermore, we observed that some low-quality generated samples might negatively affect model training. To address this, we devised the uncertainty-based label smoothing strategy to increase the smoothing of these samples, thus reducing their impact. We demonstrate the effectiveness of the proposed method on four datasets across five tasks and achieve state-of-the-art performance for zero-shot action recognition.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.19495","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.872737","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":183,"author":"Wei Li, Dezhao Luo, Dongbao Yang, Zhenhang Li, Weiping Wang, Yu Zhou","raw_content_length":1365,"priority":7,"update_frequency":1,"reading_time_minutes":0.915,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1364,"language_detected":"en","key_concepts":{"key_phrases":["The Role","Video Generation","Enhancing Data","arXiv250519495v2 Announce Type","Video action","tasks","real-world scenarios","data limitations","this paper","the data-limited action understanding problem"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"The Role":2.0,"Video Generation":2.0,"Enhancing Data":2.0,"arXiv250519495v2 Announce Type":1.0,"Video action":1.0,"tasks":1.0,"real-world scenarios":1.0,"data limitations":1.0,"this paper":1.0,"the data-limited action understanding problem":1.0}},"age_hours":2.7716358380555555,"is_recent":true,"quality_score":0.7,"sentiment_score":2.0029999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.5994,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.8351,"joy":0.01,"surprise":0.0111,"sadness":0.0131,"fear":0.0687,"anger":0.0317,"disgust":0.0302},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a method for generating annotated video data to improve action understanding models. While the method demonstrates state-of-the-art performance in zero-shot action recognition, it's still in the applied research phase with no deployed units or real-world impact data. The potential climate impact is indirect and relies on the application of improved action recognition in sustainability-related fields.","key_impact_metrics":["State-of-the-art performance for zero-shot action recognition"],"technology_tags":["text-to-video diffusion transformer","data augmentation","action recognition"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:51:52.152344Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_93ec1a847b31","title":"Beyond Demonstrations: Dynamic Vector Construction from Latent Representations","content":"arXiv:2505.20318v2 Announce Type: replace Abstract: In-Context derived Vector (ICV) methods extract task-relevant representations from large language models (LLMs) and reinject them during inference, achieving comparable performance to few-shot In-Context Learning (ICL) without repeated demonstration processing. However, existing ICV methods remain sensitive to ICL-specific factors, often use coarse or semantically fragmented representations as the source of the vector, and rely on heuristic-based injection positions, limiting their applicability. To address these issues, we propose Dynamic Vector (DyVec), which incorporates an Exhaustive Query Rotation (EQR) strategy to extract robust semantically aggregated latent representations by mitigating variance introduced by ICL. It then applies Dynamic Latent Segmentation and Injection to adaptively partition representations based on task complexity and leverages REINFORCE-based optimization to learn optimal injection positions for each segment. Experiments results show that DyVec outperforms few-shot ICL, LoRA, and prior ICV baselines. Further analysis highlights the effectiveness of dynamically segmenting and injecting semantically aggregated latent representations. DyVec provides a lightweight and data-efficient solution for inference-time task adaptation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20318","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.873130","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":162,"author":"Wang Cai, Hsiu-Yuan Huang, Zhixiang Wang, Yunfang Wu","raw_content_length":1329,"priority":7,"update_frequency":1,"reading_time_minutes":0.81,"robust_parsing_used":true,"entities":{"organizations":["ICV","DyVec","Dynamic Vector Construction","ICL","EQR","Dynamic Vector"],"persons":[],"locations":[],"monetary":[]},"char_count":1324,"language_detected":"en","key_concepts":{"key_phrases":["Demonstrations","Latent Representations","arXiv250520318v2 Announce Type","Abstract","ICV","task-relevant representations","large language models","LLMs","them","inference"],"filter_categories":{"ai_ml":["large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Demonstrations":2.0,"Latent Representations":2.0,"arXiv250520318v2 Announce Type":1.0,"Abstract":1.0,"ICV":1.0,"task-relevant representations":1.0,"large language models":1.0,"LLMs":1.0,"them":1.0,"inference":1.0}},"age_hours":2.771651261388889,"is_recent":true,"quality_score":1.0,"sentiment_score":6.5954999999999995,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.3191,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9196,"joy":0.0084,"surprise":0.0418,"sadness":0.0058,"fear":0.0057,"anger":0.0117,"disgust":0.007},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new method (DyVec) for improving the efficiency of large language models (LLMs) by reducing the need for repeated demonstration processing. While the paper claims DyVec outperforms existing methods, it is still in the research phase with no mention of deployed units or real-world applications. The impact on climate is indirect, potentially reducing energy consumption of LLMs, but this is not quantified.","key_impact_metrics":["Performance compared to few-shot ICL","Performance compared to LoRA"],"technology_tags":["Large Language Models","In-Context Learning","Machine Learning Efficiency"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:51:55.260452Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_83fd5298075f","title":"FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information","content":"arXiv:2505.20650v2 Announce Type: replace Abstract: Accurately understanding numbers from financial reports is fundamental to how markets, regulators, algorithms, and normal people read the economy and the world, yet even with XBRL (eXtensible Business Reporting Language) designed to tag every figure with standardized accounting concepts, mapping thousands of facts to over 10,000 U.S. GAAP concepts remains costly, inconsistent, and error-prone. Existing benchmarks define tagging as flat, single-step, extreme classification over small subsets of US-GAAP concepts, overlooking both the taxonomy's hierarchical semantics and the structured nature of real tagging, where each fact must be represented as a contextualized multi-field output. These simplifications prevent fair evaluation of large language models (LLMs) under realistic reporting conditions. To address these gaps, we introduce FinTagging, the first comprehensive benchmark for structure-aware and full-scope XBRL tagging, designed to evaluate LLMs' ability to extract and align financial facts through numerical reasoning and taxonomy alignment across text and tables. We define two subtasks: FinNI for numeric identification, which extracts numerical entities and their types from XBRL reports, and FinCL for concept linking, which maps each extracted entity to the corresponding concept in the full US-GAAP taxonomy. Together, these subtasks produce a structured representation of each financial fact. We evaluate diverse LLMs under zero-shot settings and analyze their performance across both subtasks and overall tagging accuracy. Results show that LLMs generalize well in numeric identification but struggle with fine-grained concept linking, revealing current limitations in structure-aware reasoning for accurate financial disclosure. All code and datasets are available on GitHub and Hugging Face.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20650","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.873576","language":"en","tags":["research","csai","csce","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":252,"author":"Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji Feng, Fengran Mo, Shengyuan Lin, Qinchuan Zhang, Kaiwen He, Chenri Luo, Jianxing Chen, Junwei Wu, Jimin Huang, Guojun Xiong, Xiao-Yang Liu, Qianqian Xie, Jian-Yun Nie","raw_content_length":1874,"priority":7,"update_frequency":1,"reading_time_minutes":1.26,"robust_parsing_used":true,"entities":{"organizations":["FinTagging"],"persons":[],"locations":["U.S."],"monetary":[]},"char_count":1873,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Structuring","Financial Information","arXiv250520650v2 Announce Type","Abstract","numbers","financial reports","how markets","regulators","normal people"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":2.0,"Structuring":2.0,"Financial Information":2.0,"arXiv250520650v2 Announce Type":1.0,"Abstract":1.0,"numbers":1.0,"financial reports":1.0,"how markets":1.0,"regulators":1.0,"normal people":1.0}},"age_hours":2.7716666355555555,"is_recent":true,"quality_score":1.0,"sentiment_score":4.4864999999999995,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1027,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.7214,"joy":0.0034,"surprise":0.0536,"sadness":0.0548,"fear":0.0083,"anger":0.125,"disgust":0.0335},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a benchmark (FinTagging) for evaluating LLMs' ability to extract and structure financial information, specifically XBRL tagging. While it doesn't directly reduce GHG emissions, it aims to improve the accuracy and efficiency of financial reporting, which could indirectly support sustainability initiatives by enabling better tracking and analysis of environmental performance. The research is in the applied research stage, with code and datasets available, but no actual deployment in real-world financial systems is mentioned.","key_impact_metrics":["Numeric Identification Accuracy","Concept Linking Accuracy"],"technology_tags":["Large Language Models","XBRL","Financial Reporting"],"sdg_alignment":[8,9,12],"analyzed_at":"2025-10-29T09:51:58.382491Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4455199f50ef","title":"Automating eHMI Action Design with LLMs for Automated Vehicle Communication","content":"arXiv:2505.20711v2 Announce Type: replace Abstract: The absence of explicit communication channels between automated vehicles (AVs) and other road users requires the use of external Human-Machine Interfaces (eHMIs) to convey messages effectively in uncertain scenarios. Currently, most eHMI studies employ predefined text messages and manually designed actions to perform these messages, which limits the real-world deployment of eHMIs, where adaptability in dynamic scenarios is essential. Given the generalizability and versatility of large language models (LLMs), they could potentially serve as automated action designers for the message-action design task. To validate this idea, we make three contributions: (1) We propose a pipeline that integrates LLMs and 3D renderers, using LLMs as action designers to generate executable actions for controlling eHMIs and rendering action clips. (2) We collect a user-rated Action-Design Scoring dataset comprising a total of 320 action sequences for eight intended messages and four representative eHMI modalities. The dataset validates that LLMs can translate intended messages into actions close to a human level, particularly for reasoning-enabled LLMs. (3) We introduce two automated raters, Action Reference Score (ARS) and Vision-Language Models (VLMs), to benchmark 18 LLMs, finding that the VLM aligns with human preferences yet varies across eHMI modalities.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20711","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.873969","language":"en","tags":["research","preprints","cshc","csro","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":197,"author":"Ding Xia, Xinyue Gui, Fan Gao, Dongyuan Li, Mark Colley, Takeo Igarashi","raw_content_length":1414,"priority":7,"update_frequency":1,"reading_time_minutes":0.985,"robust_parsing_used":true,"entities":{"organizations":["Automated Vehicle Communication arXiv:2505.20711v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1413,"language_detected":"en","key_concepts":{"key_phrases":["Action Design","LLMs","Automated Vehicle Communication","eHMIs","arXiv250520711v2","Announce Type","Abstract","The absence","explicit communication channels","automated vehicles"],"filter_categories":{"ai_ml":["LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Action Design":2.0,"LLMs":2.0,"Automated Vehicle Communication":2.0,"eHMIs":2.0,"arXiv250520711v2":1.0,"Announce Type":1.0,"Abstract":1.0,"The absence":1.0,"explicit communication channels":1.0,"automated vehicles":1.0}},"age_hours":2.771682365555556,"is_recent":true,"quality_score":1.0,"sentiment_score":5.8895,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.4699,"joy":0.0068,"surprise":0.0272,"sadness":0.0114,"fear":0.4615,"anger":0.0141,"disgust":0.0091},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores using LLMs to automate the design of eHMIs for automated vehicles. The concrete action is the development of a pipeline integrating LLMs and 3D renderers, and the creation of a dataset with 320 action sequences. However, this is still in the research phase, with no deployed technology or measurable environmental outcomes yet.","key_impact_metrics":["320 action sequences","8 intended messages"],"technology_tags":["LLMs","eHMI","Automated Vehicles"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:52:01.194158Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_555bdc6f3267","title":"An LLM","content":"arXiv:2505.20854v2 Announce Type: replace Abstract: Large Language Models (LLMs) and other automated techniques have been increasingly used to support software developers by generating software artifacts such as code snippets, patches, and comments. However, accurately assessing the correctness of these generated artifacts remains a significant challenge. On one hand, human evaluation provides high accuracy but is labor-intensive and lacks scalability. On the other hand, many automatic evaluation metrics are scalable and require minimal human effort, but they often fail to accurately reflect the actual correctness of generated software artifacts. In this paper, we present SE-Jury, the first evaluation metric for LLM-as-Ensemble-Judge specifically designed to accurately assess the correctness of generated software artifacts. SE-Jury first defines five distinct evaluation strategies, each implemented by an independent judge. A dynamic team selection mechanism then identifies the most appropriate subset of judges as a team to produce a final correctness score through ensembling. We evaluate SE-Jury across a diverse set of software engineering (SE) benchmarks that span three popular SE tasks: code generation, automated program repair, and code summarization. Results demonstrate that SE-Jury consistently achieves a higher correlation with human judgments, with improvements ranging from 29.6% to 140.8% over existing automatic metrics. SE-Jury reaches agreement levels with human annotators that are close to inter-annotator agreement in code generation and program repair. These findings underscore SE-Jury's potential as a scalable and reliable alternative to human evaluation in these SE tasks.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.20854","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.874465","language":"en","tags":["research","csse","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":234,"author":"Xin Zhou, Kisub Kim, Ting Zhang, Martin Weyssow, Luis F. Gomes, Guang Yang, Kui Liu, Xin Xia, David Lo","raw_content_length":1717,"priority":7,"update_frequency":1,"reading_time_minutes":1.17,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1714,"language_detected":"en","key_concepts":{"key_phrases":["An LLM","arXiv250520854v2","Announce Type","Large Language Models","LLMs","other automated techniques","software developers","software artifacts","code snippets","patches"],"filter_categories":{"ai_ml":["An LLM","Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"An LLM":2.0,"arXiv250520854v2":1.0,"Announce Type":1.0,"Large Language Models":1.0,"LLMs":1.0,"other automated techniques":1.0,"software developers":1.0,"software artifacts":1.0,"code snippets":1.0,"patches":1.0}},"age_hours":2.771697355277778,"is_recent":true,"quality_score":0.7,"sentiment_score":9.158,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8316,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9297,"joy":0.0177,"surprise":0.0216,"sadness":0.0111,"fear":0.0042,"anger":0.0095,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel evaluation metric (SE-Jury) for assessing the correctness of LLM-generated software artifacts. While the research shows improved correlation with human judgments (29.6% to 140.8% improvement), it's still in the applied research stage with no deployed units or operational data. The potential climate impact is indirect, as better software development tools could lead to more efficient software and potentially reduce energy consumption, but this is not directly measured or quantified.","key_impact_metrics":["Improvement over existing metrics: 29.6% to 140.8%","Agreement levels with human annotators"],"technology_tags":["Large Language Models","Software Engineering","Code Generation","Automated Program Repair","Code Summarization"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:52:04.479975Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_28c3368f0418","title":"HoliTom: Holistic Token Merging for Fast Video Large Language Models","content":"arXiv:2505.21334v3 Announce Type: replace Abstract: Video large language models (video LLMs) excel at video comprehension but face significant computational inefficiency due to redundant video tokens. Existing token pruning methods offer solutions. However, approaches operating within the LLM (inner-LLM pruning), such as FastV, incur intrinsic computational overhead in shallow layers. In contrast, methods performing token pruning before the LLM (outer-LLM pruning) primarily address spatial redundancy within individual frames or limited temporal windows, neglecting the crucial global temporal dynamics and correlations across longer video sequences. This leads to sub-optimal spatio-temporal reduction and does not leverage video compressibility fully. Crucially, the synergistic potential and mutual influence of combining these strategies remain unexplored. To further reduce redundancy, we introduce HoliTom, a novel training-free holistic token merging framework. HoliTom employs outer-LLM pruning through global redundancy-aware temporal segmentation, followed by spatial-temporal merging to reduce visual tokens by over 90%, significantly alleviating the LLM's computational burden. Complementing this, we introduce a robust inner-LLM token similarity-based merging approach, designed for superior performance and compatibility with outer-LLM pruning. Evaluations demonstrate our method's promising efficiency-performance trade-off on LLaVA-OneVision-7B, reducing computational costs to 6.9% of FLOPs while maintaining 99.1% of the original performance. Furthermore, we achieve a 2.28x reduction in Time-To-First-Token (TTFT) and a 1.32x acceleration in decoding throughput, highlighting the practical benefits of our integrated pruning approach for efficient video LLMs inference.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21334","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.874892","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":222,"author":"Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang","raw_content_length":1794,"priority":7,"update_frequency":1,"reading_time_minutes":1.11,"robust_parsing_used":true,"entities":{"organizations":["LLM","HoliTom"],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1793,"language_detected":"en","key_concepts":{"key_phrases":["HoliTom","Holistic Token Merging","Fast Video Large Language Models","arXiv250521334v3 Announce Type","Abstract","Video large language models","video LLMs","video comprehension","significant computational inefficiency","redundant video tokens"],"filter_categories":{"ai_ml":["Fast Video Large Language Models","Video large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"HoliTom":2.0,"Holistic Token Merging":2.0,"Fast Video Large Language Models":2.0,"arXiv250521334v3 Announce Type":1.0,"Abstract":1.0,"Video large language models":1.0,"video LLMs":1.0,"video comprehension":1.0,"significant computational inefficiency":1.0,"redundant video tokens":1.0}},"age_hours":2.7717127408333333,"is_recent":true,"quality_score":1.0,"sentiment_score":8.214,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6428,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8837,"joy":0.0111,"surprise":0.0308,"sadness":0.0271,"fear":0.0058,"anger":0.0267,"disgust":0.0148},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":6,"technical_credibility":7,"economic_viability":5,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (HoliTom) for reducing computational costs in video large language models, leading to energy savings. The method achieves a 90% reduction in visual tokens and reduces computational costs to 6.9% of FLOPs, while maintaining 99.1% of original performance. This is currently at the applied research stage, with promising efficiency metrics but no evidence of real-world deployment.","key_impact_metrics":["90% reduction in visual tokens","6.9% of FLOPs"],"technology_tags":["Video Large Language Models","Token Pruning","AI Efficiency"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:52:07.704288Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c24e472405a1","title":"Any-to","content":"arXiv:2505.21593v3 Announce Type: replace Abstract: Diffusion models have recently emerged as powerful tools for camera simulation, enabling both geometric transformations and realistic optical effects. Among these, image-based bokeh rendering has shown promising results, but diffusion for video bokeh remains unexplored. Existing image-based methods are plagued by temporal flickering and inconsistent blur transitions, while current video editing methods lack explicit control over the focus plane and bokeh intensity. These issues limit their applicability for controllable video bokeh. In this work, we propose a one-step diffusion framework for generating temporally coherent, depth-aware video bokeh rendering. The framework employs a multi-plane image (MPI) representation adapted to the focal plane to condition the video diffusion model, thereby enabling it to exploit strong 3D priors from pretrained backbones. To further enhance temporal stability, depth robustness, and detail preservation, we introduce a progressive training strategy. Experiments on synthetic and real-world benchmarks demonstrate superior temporal coherence, spatial accuracy, and controllability, outperforming prior baselines. This work represents the first dedicated diffusion framework for video bokeh generation, establishing a new baseline for temporally coherent and controllable depth-of-field effects.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21593","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.875301","language":"en","tags":["research","csai","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":179,"author":"Yang Yang, Siming Zheng, Qirui Yang, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li, Peng-Tao Jiang","raw_content_length":1395,"priority":7,"update_frequency":1,"reading_time_minutes":0.895,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1394,"language_detected":"en","key_concepts":{"key_phrases":["Any","arXiv250521593v3 Announce Type","Abstract","Diffusion models","powerful tools","camera simulation","both geometric transformations","realistic optical effects","these","image-based bokeh rendering"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Any":2.0,"arXiv250521593v3 Announce Type":1.0,"Abstract":1.0,"Diffusion models":1.0,"powerful tools":1.0,"camera simulation":1.0,"both geometric transformations":1.0,"realistic optical effects":1.0,"these":1.0,"image-based bokeh rendering":1.0}},"age_hours":2.7717275238888885,"is_recent":true,"quality_score":0.7,"sentiment_score":4.742,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":-0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.777,"joy":0.0043,"surprise":0.0249,"sadness":0.0929,"fear":0.0517,"anger":0.0173,"disgust":0.0319},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":1,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new diffusion framework for video bokeh generation. While it demonstrates superior temporal coherence and spatial accuracy compared to baselines, it is currently in the research phase with no deployed technology or measurable environmental impact. The potential for sustainability impact is low as it's a visual effect and not directly related to climate change mitigation or adaptation.","key_impact_metrics":[],"technology_tags":["diffusion models","video bokeh rendering","multi-plane image"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:52:10.425729Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4e4dd54548b0","title":"PrivATE: Differentially Private Confidence Intervals for Average Treatment Effects","content":"arXiv:2505.21641v2 Announce Type: replace Abstract: The average treatment effect (ATE) is widely used to evaluate the effectiveness of drugs and other medical interventions. In safety-critical applications like medicine, reliable inferences about the ATE typically require valid uncertainty quantification, such as through confidence intervals (CIs). However, estimating treatment effects in these settings often involves sensitive data that must be kept private. In this work, we present PrivATE, a novel machine learning framework for computing CIs for the ATE under differential privacy. Specifically, we focus on deriving valid privacy-preserving CIs for the ATE from observational data. Our PrivATE framework consists of three steps: (i) estimating the differentially private ATE through output perturbation; (ii) estimating the differentially private variance in a doubly robust manner; and (iii) constructing the CIs while accounting for the uncertainty from both the estimation and privatization steps. Our PrivATE framework is model agnostic, doubly robust, and ensures valid CIs. We demonstrate the effectiveness of our framework using synthetic and real-world medical datasets. To the best of our knowledge, we are the first to derive a general, doubly robust framework for valid CIs of the ATE under ($\\varepsilon,\\delta$)-differential privacy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.21641","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.875701","language":"en","tags":["statme","cscr","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":189,"author":"Maresa Schr\\\"oder, Justin Hartenstein, Stefan Feuerriegel","raw_content_length":1357,"priority":7,"update_frequency":1,"reading_time_minutes":0.945,"robust_parsing_used":true,"entities":{"organizations":["ATE","Differentially Private Confidence Intervals for Average Treatment Effects arXiv:2505.21641v2 Announce"],"persons":[],"locations":[],"monetary":[]},"char_count":1356,"language_detected":"en","key_concepts":{"key_phrases":["Differentially Private Confidence Intervals","Average Treatment Effects","arXiv250521641v2 Announce Type","Abstract","The average treatment effect","ATE","the effectiveness","drugs","other medical interventions","safety-critical applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Differentially Private Confidence Intervals":2.0,"Average Treatment Effects":2.0,"arXiv250521641v2 Announce Type":1.0,"Abstract":1.0,"The average treatment effect":1.0,"ATE":1.0,"the effectiveness":1.0,"drugs":1.0,"other medical interventions":1.0,"safety-critical applications":1.0}},"age_hours":2.771743077777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.8585,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7717,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9193,"joy":0.0051,"surprise":0.0285,"sadness":0.0047,"fear":0.0234,"anger":0.0117,"disgust":0.0073},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":5,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (PrivATE) for computing differentially private confidence intervals for average treatment effects, which is relevant to medical interventions. The framework is demonstrated using synthetic and real-world medical datasets, suggesting it's beyond the conceptual stage, but there's no evidence of real-world deployment or impact measurement yet. The technical credibility is supported by the mention of doubly robust estimation and differential privacy, but economic viability and deployment readiness are low at this stage.","key_impact_metrics":["Differentially private ATE","Differentially private variance"],"technology_tags":["Differential Privacy","Average Treatment Effect Estimation","Machine Learning"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:52:13.560868Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_649b63bc9dce","title":"SpatialSplat: Efficient Semantic 3D from Sparse Unposed Images","content":"arXiv:2505.23044v2 Announce Type: replace Abstract: A major breakthrough in 3D reconstruction is the feedforward paradigm to generate pixel-wise 3D points or Gaussian primitives from sparse, unposed images. To further incorporate semantics while avoiding the significant memory and storage costs of high-dimensional semantic features, existing methods extend this paradigm by associating each primitive with a compressed semantic feature vector. However, these methods have two major limitations: (a) the naively compressed feature compromises expressiveness, affecting the model's ability to capture fine-grained semantics, and (b) the pixel-wise primitive prediction introduces redundancy in overlapping areas, causing unnecessary memory overhead. To this end, we introduce \\textbf{SpatialSplat}, a feedforward framework that produces redundancy-aware Gaussians and capitalizes on a dual-field semantic representation. Particularly, with the insight that primitives within the same instance exhibit high semantic consistency, we decompose the semantic representation into a coarse feature field that encodes uncompressed semantics with minimal primitives, and a fine-grained yet low-dimensional feature field that captures detailed inter-instance relationships. Moreover, we propose a selective Gaussian mechanism, which retains only essential Gaussians in the scene, effectively eliminating redundant primitives. Our proposed Spatialsplat learns accurate semantic information and detailed instances prior with more compact 3D Gaussians, making semantic 3D reconstruction more applicable. We conduct extensive experiments to evaluate our method, demonstrating a remarkable 60\\% reduction in scene representation parameters while achieving superior performance over state-of-the-art methods. The code is available at https://github.com/shengyuuu/SpatialSplat.git","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23044","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.876105","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":229,"author":"Yu Sheng, Jiajun Deng, Xinran Zhang, Yu Zhang, Bei Hua, Yanyong Zhang, Jianmin Ji","raw_content_length":1864,"priority":7,"update_frequency":1,"reading_time_minutes":1.145,"robust_parsing_used":true,"entities":{"organizations":["Efficient Semantic 3D","Sparse Unposed Images arXiv:2505.23044v2"],"persons":["Gaussian"],"locations":[],"monetary":[]},"char_count":1863,"language_detected":"en","key_concepts":{"key_phrases":["SpatialSplat","Efficient Semantic 3D","Sparse Unposed Images","Announce Type","Abstract","A major breakthrough","3D reconstruction","the feedforward paradigm","pixel-wise 3D points","Gaussian primitives"],"filter_categories":{"research_academic":["A major breakthrough"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SpatialSplat":2.0,"Efficient Semantic 3D":2.0,"Sparse Unposed Images":2.0,"Announce Type":1.0,"Abstract":1.0,"A major breakthrough":1.0,"3D reconstruction":1.0,"the feedforward paradigm":1.0,"pixel-wise 3D points":1.0,"Gaussian primitives":1.0}},"age_hours":2.771758351388889,"is_recent":true,"quality_score":1.0,"sentiment_score":7.202,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.4404,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9015,"joy":0.0183,"surprise":0.0379,"sadness":0.0061,"fear":0.0075,"anger":0.0155,"disgust":0.0132},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":4,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method for efficient semantic 3D reconstruction, achieving a 60% reduction in scene representation parameters. While promising, it is still in the research phase with no deployed applications or economic viability demonstrated. The github repository suggests code availability, but no real-world deployments are mentioned.","key_impact_metrics":["60% reduction in scene representation parameters"],"technology_tags":["3D reconstruction","semantic segmentation","Gaussian primitives"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:16.733388Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_d7714b0797b5","title":"Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios","content":"arXiv:2505.23118v2 Announce Type: replace Abstract: Effective clinical decision-making depends on iterative, multimodal reasoning across diverse sources of evidence. The recent emergence of multimodal reasoning models has significantly transformed the landscape of solving complex tasks. Although such models have achieved notable success in mathematics and science, their application to medical domains remains underexplored. In this work, we propose \\textit{MedE$^2$}, a two-stage post-training pipeline that elicits and then enhances multimodal reasoning for medical domains. In Stage-I, we fine-tune models using 2,000 text-only data samples containing precisely orchestrated reasoning demonstrations to elicit reasoning behaviors. In Stage-II, we further enhance the model's reasoning capabilities using 1,500 rigorously curated multimodal medical cases, aligning model reasoning outputs with our proposed multimodal medical reasoning preference. Extensive experiments demonstrate the efficacy and reliability of \\textit{MedE$^2$} in improving the reasoning performance of medical multimodal models. Notably, models trained with \\textit{MedE$^2$} consistently outperform baselines across multiple medical multimodal benchmarks. Additional validation on larger models and under inference-time scaling further confirms the robustness and practical utility of our approach.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23118","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.876508","language":"en","tags":["research","csai","preprints","cscl","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":168,"author":"Zhongzhen Huang, Linjie Mu, Yakun Zhu, Xiangyu Zhao, Shaoting Zhang, Xiaofan Zhang","raw_content_length":1376,"priority":7,"update_frequency":1,"reading_time_minutes":0.84,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Elicit","Announce Type"],"locations":[],"monetary":[]},"char_count":1375,"language_detected":"en","key_concepts":{"key_phrases":["Elicit","Enhance","Multimodal Reasoning","Medical Scenarios","arXiv250523118v2","Announce Type","Effective clinical decision-making","iterative multimodal reasoning","diverse sources","evidence"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Elicit":2.0,"Enhance":2.0,"Multimodal Reasoning":2.0,"Medical Scenarios":2.0,"arXiv250523118v2":1.0,"Announce Type":1.0,"Effective clinical decision-making":1.0,"iterative multimodal reasoning":1.0,"diverse sources":1.0,"evidence":1.0}},"age_hours":2.771772988888889,"is_recent":true,"quality_score":1.0,"sentiment_score":9.2405,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8481,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9056,"joy":0.0204,"surprise":0.0361,"sadness":0.0083,"fear":0.01,"anger":0.0149,"disgust":0.0048},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a two-stage post-training pipeline for improving multimodal reasoning in medical domains. The concrete action is fine-tuning models with 2,000 text-only data samples and 1,500 multimodal medical cases. The evidence supporting claims is the reported outperformance of models trained with the proposed pipeline across multiple medical multimodal benchmarks, but there is no independent verification or deployment data.","key_impact_metrics":["2,000 text-only data samples","1,500 multimodal medical cases"],"technology_tags":["multimodal reasoning","medical AI","post-training pipeline"],"sdg_alignment":[3],"analyzed_at":"2025-10-29T09:52:19.742458Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9f15d7c15713","title":"Epistemic Errors of Imperfect Multitask Learners When Distributions Shift","content":"arXiv:2505.23496v2 Announce Type: replace Abstract: Uncertainty-aware machine learners, such as Bayesian neural networks, output a quantification of uncertainty instead of a point prediction. In this work, we provide uncertainty-aware learners with a principled framework to characterize, and identify ways to eliminate, errors that arise from reducible (epistemic) uncertainty. We introduce a principled definition of epistemic error, and provide a decompositional epistemic error bound which operates in the very general setting of imperfect multitask learning under distribution shift. In this setting, the training (source) data may arise from multiple tasks, the test (target) data may differ systematically from the source data tasks, and/or the learner may not arrive at an accurate characterization of the source data. Our bound separately attributes epistemic errors to each of multiple aspects of the learning procedure and environment. As corollaries of the general result, we provide epistemic error bounds specialized to the settings of Bayesian transfer learning and distribution shift within $\\epsilon$-neighborhoods. We additionally leverage the terms in our bound to provide a novel definition of negative transfer.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.23496","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.877111","language":"en","tags":["statml","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Sabina J. Sloman, Michele Caprio, Samuel Kaski","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["Imperfect Multitask Learners"],"persons":[],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["Epistemic Errors","Imperfect Multitask Learners","Distributions","Announce Type","Abstract","Uncertainty-aware machine learners","Bayesian neural networks","a quantification","uncertainty","a point prediction"],"filter_categories":{"ai_ml":["Uncertainty-aware machine learners","Bayesian neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Epistemic Errors":2.0,"Imperfect Multitask Learners":2.0,"Distributions":2.0,"Announce Type":1.0,"Abstract":1.0,"Uncertainty-aware machine learners":1.0,"Bayesian neural networks":1.0,"a quantification":1.0,"uncertainty":1.0,"a point prediction":1.0}},"age_hours":2.7717877902777777,"is_recent":true,"quality_score":1.0,"sentiment_score":0.4409999999999997,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.9118,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.7902,"joy":0.0071,"surprise":0.0157,"sadness":0.0142,"fear":0.1332,"anger":0.0236,"disgust":0.016},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":1,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for improving the uncertainty quantification of machine learning models under distribution shift. While it could potentially improve the reliability of climate models or other sustainability-related applications, it is currently at the basic research stage with no deployed technology or measured outcomes. The vaporware flag is raised because it is an early-stage concept without validation.","key_impact_metrics":[],"technology_tags":["Bayesian Neural Networks","Machine Learning","Uncertainty Quantification"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:22.687526Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_a797dc9d80a8","title":"A Constructive Framework for Nondeterministic Automata via Time","content":"arXiv:2505.24110v4 Announce Type: replace Abstract: We present a formal and constructive simulation framework for nondeterministic finite automata (NFAs) using time-shared, depth-unrolled feedforward networks (TS-FFNs), i.e., acyclic unrolled computations with shared parameters that are functionally equivalent to unrolled recurrent or state-space models. Unlike prior approaches that rely on explicit recurrent architectures or post hoc extraction methods, our formulation symbolically encodes automaton states as binary vectors, transitions as sparse matrix transformations, and nondeterministic branching-including $\\varepsilon$-closures-as compositions of shared thresholded updates. We prove that every regular language can be recognized exactly by such a shared-parameter unrolled feedforward network, with parameter count independent of input length. Our construction yields a constructive equivalence between NFAs and neural networks and demonstrates \\emph{empirical learnability}: these networks can be trained via gradient descent on supervised acceptance data to recover the target automaton behavior. This learnability, formalized in Proposition 5.1, is the crux of this work. Extensive experiments validate the theoretical results, achieving perfect or near-perfect agreement on acceptance, state propagation, and closure dynamics. This work clarifies the correspondence between automata theory and modern neural architectures, showing that unrolled feedforward networks can perform precise, interpretable, and trainable symbolic computation.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2505.24110","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.877559","language":"en","tags":["research","preprints","csfl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":190,"author":"Sahil Rajesh Dhayalkar","raw_content_length":1557,"priority":7,"update_frequency":1,"reading_time_minutes":0.95,"robust_parsing_used":true,"entities":{"organizations":["Time arXiv:2505.24110v4"],"persons":[],"locations":["automaton"],"monetary":[]},"char_count":1556,"language_detected":"en","key_concepts":{"key_phrases":["A Constructive Framework","Nondeterministic Automata","Time","Announce Type","Abstract","a formal and constructive simulation framework","nondeterministic finite automata","NFAs","time-shared depth-unrolled feedforward networks","TS-FFNs"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"A Constructive Framework":2.0,"Nondeterministic Automata":2.0,"Time":2.0,"Announce Type":1.0,"Abstract":1.0,"a formal and constructive simulation framework":1.0,"nondeterministic finite automata":1.0,"NFAs":1.0,"time-shared depth-unrolled feedforward networks":1.0,"TS-FFNs":1.0}},"age_hours":2.7718031255555555,"is_recent":true,"quality_score":1.0,"sentiment_score":6.7,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.34,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8841,"joy":0.0424,"surprise":0.038,"sadness":0.0043,"fear":0.0081,"anger":0.017,"disgust":0.0062},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a theoretical framework for simulating nondeterministic finite automata using neural networks. While the research demonstrates empirical learnability and validates theoretical results, it remains at the basic research stage with no immediate deployment or measurable impact on climate or sustainability. The focus is on theoretical equivalence and training, not practical application for environmental problems.","key_impact_metrics":["Perfect or near-perfect agreement on acceptance, state propagation, and closure dynamics"],"technology_tags":["Nondeterministic Finite Automata","Neural Networks","Time-Shared Feedforward Networks"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:52:25.513052Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f213b5825399","title":"What Makes LLMs Effective Sequential Recommenders? A Study on Preference Intensity and Temporal Context","content":"arXiv:2506.02261v2 Announce Type: replace Abstract: Sequential recommendation systems aspire to profile users by interpreting their interaction histories, echoing how humans make decisions by weighing experience, relative preference strength, and situational relevance. Yet, existing large language model (LLM)-based recommenders often fall short of mimicking the flexible, context-aware decision strategies humans exhibit, neglecting the structured, dynamic, and context-aware mechanisms fundamental to human behaviors. To bridge this gap, we propose RecPO, a preference optimization framework that models structured feedback and contextual delay to emulate human-like prioritization in sequential recommendation. RecPO exploits adaptive reward margins based on inferred preference hierarchies and temporal signals, enabling the model to favor immediately relevant items and to distinguish between varying degrees of preference and aversion. Extensive experiments across five real-world datasets demonstrate that RecPO not only yields performance gains over state-of-the-art baselines, but also mirrors key characteristics of human decision-making: favoring timely satisfaction, maintaining coherent preferences, and exercising discernment under shifting contexts.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.02261","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.878341","language":"en","tags":["csir","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":154,"author":"Zhongyu Ouyang, Qianlong Wen, Chunhui Zhang, Yanfang Ye, Soroush Vosoughi","raw_content_length":1266,"priority":7,"update_frequency":1,"reading_time_minutes":0.77,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["RecPO","Sequential Recommenders"],"locations":[],"monetary":[]},"char_count":1265,"language_detected":"en","key_concepts":{"key_phrases":["What","LLMs","A Study","Preference Intensity","Temporal Context","humans","Announce Type","Abstract","Sequential recommendation systems aspire","users"],"filter_categories":{"ai_ml":["LLMs"],"research_academic":["A Study"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"What":2.0,"LLMs":2.0,"A Study":2.0,"Preference Intensity":2.0,"Temporal Context":2.0,"humans":2.0,"Announce Type":1.0,"Abstract":1.0,"Sequential recommendation systems aspire":1.0,"users":1.0}},"age_hours":2.771833460277778,"is_recent":true,"quality_score":1.0,"sentiment_score":9.01,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.802,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.887,"joy":0.0051,"surprise":0.0501,"sadness":0.0117,"fear":0.0131,"anger":0.0146,"disgust":0.0182},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a preference optimization framework (RecPO) for sequential recommendation systems, aiming to improve their ability to mimic human decision-making. While the experiments show performance gains over baselines on real-world datasets, the impact on sustainability is indirect and theoretical. The framework is at the applied research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":["Performance gains over state-of-the-art baselines","Mirrors key characteristics of human decision-making"],"technology_tags":["Large Language Models","Recommendation Systems","Preference Optimization"],"sdg_alignment":[9,12],"analyzed_at":"2025-10-29T09:52:28.344360Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_38bbf9cbb05a","title":"Solving Inverse Problems with FLAIR","content":"arXiv:2506.02680v2 Announce Type: replace Abstract: Flow-based latent generative models such as Stable Diffusion 3 are able to generate images with remarkable quality, even enabling photorealistic text-to-image generation. Their impressive performance suggests that these models should also constitute powerful priors for inverse imaging problems, but that approach has not yet led to comparable fidelity. There are several key obstacles: (i) the data likelihood term is usually intractable; (ii) learned generative models cannot be directly conditioned on the distorted observations, leading to conflicting objectives between data likelihood and prior; and (iii) the reconstructions can deviate from the observed data. We present FLAIR, a novel, training-free variational framework that leverages flow-based generative models as prior for inverse problems. To that end, we introduce a variational objective for flow matching that is agnostic to the type of degradation, and combine it with deterministic trajectory adjustments to guide the prior towards regions which are more likely under the posterior. To enforce exact consistency with the observed data, we decouple the optimization of the data fidelity and regularization terms. Moreover, we introduce a time-dependent calibration scheme in which the strength of the regularization is modulated according to off-line accuracy estimates. Results on standard imaging benchmarks demonstrate that FLAIR consistently outperforms existing diffusion- and flow-based methods in terms of reconstruction quality and sample diversity. Our code is available at https://inverseflair.github.io/.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.02680","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.878764","language":"en","tags":["eessiv","research","preprints","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Julius Erbach, Dominik Narnhofer, Andreas Dombos, Bernt Schiele, Jan Eric Lenssen, Konrad Schindler","raw_content_length":1638,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["FLAIR arXiv:2506.02680v2 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1637,"language_detected":"en","key_concepts":{"key_phrases":["Inverse Problems","FLAIR","arXiv250602680v2 Announce Type","Abstract","Flow-based latent generative models","Stable Diffusion","images","remarkable quality","image","Their impressive performance"],"filter_categories":{"ai_ml":["FLAIR"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Inverse Problems":2.0,"FLAIR":2.0,"arXiv250602680v2 Announce Type":1.0,"Abstract":1.0,"Flow-based latent generative models":1.0,"Stable Diffusion":1.0,"images":1.0,"remarkable quality":1.0,"image":1.0,"Their impressive performance":1.0}},"age_hours":2.7718489727777778,"is_recent":true,"quality_score":1.0,"sentiment_score":5.703,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.1406,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8327,"joy":0.0255,"surprise":0.075,"sadness":0.0064,"fear":0.0381,"anger":0.0144,"disgust":0.0078},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel framework (FLAIR) for solving inverse imaging problems, which could potentially improve the efficiency and accuracy of image reconstruction in various fields. The framework leverages flow-based generative models and introduces a variational objective for flow matching. While the paper demonstrates improved reconstruction quality on standard imaging benchmarks, it is currently in the applied research stage with no clear path to economic viability or large-scale deployment.","key_impact_metrics":["Reconstruction quality","Sample diversity"],"technology_tags":["Flow-based generative models","Inverse imaging","Variational framework"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:31.176447Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_522dc9ed3af5","title":"Robustness in Both Domains: CLIP Needs a Robust Text Encoder","content":"arXiv:2506.03355v2 Announce Type: replace Abstract: Adversarial input attacks can cause a significant shift of CLIP embeddings. This can affect the downstream robustness of models incorporating CLIP in the pipeline, such as text-to-image generative models or large vision language models. While some efforts have been done towards making the CLIP image encoders robust, the robustness of text encoders remains unexplored. In this work, we cover this gap in the literature. We propose LEAF: an efficient adversarial finetuning method for the text domain, with the ability to scale to large CLIP models. Our models significantly improve the zero-shot adversarial accuracy in the text domain, while maintaining the vision performance provided by robust image encoders. When combined with text-to-image diffusion models, we can improve the generation quality under adversarial noise. In multimodal retrieval tasks, LEAF improves the recall under adversarial noise over standard CLIP models. Finally, we show that robust text encoders facilitate better reconstruction of input text from its embedding via direct optimization. We open-source our code ( https://github.com/LIONS-EPFL/LEAF ) and models ( https://huggingface.co/LEAF-CLIP ).","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.03355","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.879164","language":"en","tags":["research","csai","preprints","cslg","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":173,"author":"Elias Abad Rocamora, Christian Schlarmann, Naman Deep Singh, Yongtao Wu, Matthias Hein, Volkan Cevher","raw_content_length":1233,"priority":7,"update_frequency":1,"reading_time_minutes":0.865,"robust_parsing_used":true,"entities":{"organizations":["CLIP"],"persons":["Domains"],"locations":[],"monetary":[]},"char_count":1232,"language_detected":"en","key_concepts":{"key_phrases":["CLIP","Both Domains","a Robust Text Encoder","arXiv250603355v2 Announce Type","Abstract","Adversarial input attacks","a significant shift","CLIP embeddings","the downstream robustness","models"],"filter_categories":{"ai_ml":["Both Domains"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"CLIP":3.0,"Both Domains":2.0,"a Robust Text Encoder":2.0,"arXiv250603355v2 Announce Type":1.0,"Abstract":1.0,"Adversarial input attacks":1.0,"a significant shift":1.0,"CLIP embeddings":1.0,"the downstream robustness":1.0,"models":1.0}},"age_hours":2.7718645563888886,"is_recent":true,"quality_score":1.0,"sentiment_score":6.48,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.296,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8562,"joy":0.003,"surprise":0.0105,"sadness":0.0083,"fear":0.0619,"anger":0.0269,"disgust":0.0332},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel method (LEAF) for improving the robustness of text encoders in CLIP models against adversarial attacks. While the method shows promise in improving zero-shot adversarial accuracy and generation quality, it is still in the applied research phase with no clear path to economic viability or large-scale deployment. The open-sourced code and models enhance transparency and reproducibility.","key_impact_metrics":["Improved zero-shot adversarial accuracy","Improved recall under adversarial noise"],"technology_tags":["Adversarial finetuning","Text encoder robustness"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:34.169029Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e9c0cea71ae0","title":"DenseDPO: Fine","content":"arXiv:2506.03517v2 Announce Type: replace Abstract: Direct Preference Optimization (DPO) has recently been applied as a post-training technique for text-to-video diffusion models. To obtain training data, annotators are asked to provide preferences between two videos generated from independent noise. However, this approach prohibits fine-grained comparisons, and we point out that it biases the annotators towards low-motion clips as they often contain fewer visual artifacts. In this work, we introduce DenseDPO, a method that addresses these shortcomings by making three contributions. First, we create each video pair for DPO by denoising corrupted copies of a ground truth video. This results in aligned pairs with similar motion structures while differing in local details, effectively neutralizing the motion bias. Second, we leverage the resulting temporal alignment to label preferences on short segments rather than entire clips, yielding a denser and more precise learning signal. With only one-third of the labeled data, DenseDPO greatly improves motion generation over vanilla DPO, while matching it in text alignment, visual quality, and temporal consistency. Finally, we show that DenseDPO unlocks automatic preference annotation using off-the-shelf Vision Language Models (VLMs): GPT accurately predicts segment-level preferences similar to task-specifically fine-tuned video reward models, and DenseDPO trained on these labels achieves performance close to using human labels.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.03517","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.879596","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":206,"author":"Ziyi Wu, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ashkan Mirzaei, Igor Gilitschenski, Sergey Tulyakov, Aliaksandr Siarohin","raw_content_length":1495,"priority":7,"update_frequency":1,"reading_time_minutes":1.03,"robust_parsing_used":true,"entities":{"organizations":["DPO","Direct Preference Optimization"],"persons":[],"locations":[],"monetary":[]},"char_count":1494,"language_detected":"en","key_concepts":{"key_phrases":["arXiv250603517v2 Announce Type","Abstract","Direct Preference Optimization","DPO","a post-training technique","video","training data","annotators","preferences","two videos"],"filter_categories":{"ai_ml":["a post-training technique"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"arXiv250603517v2 Announce Type":1.0,"Abstract":1.0,"Direct Preference Optimization":1.0,"DPO":1.0,"a post-training technique":1.0,"video":1.0,"training data":1.0,"annotators":1.0,"preferences":1.0,"two videos":1.0}},"age_hours":2.7718800249999997,"is_recent":true,"quality_score":1.0,"sentiment_score":7.6335,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5267,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.7352,"joy":0.008,"surprise":0.0092,"sadness":0.0088,"fear":0.033,"anger":0.0835,"disgust":0.1223},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a novel method (DenseDPO) for improving text-to-video diffusion models. The concrete action is the development and testing of a new training technique. The evidence supporting claims includes improved motion generation with one-third of the labeled data compared to vanilla DPO. This is currently in the applied research stage, with no indication of deployment.","key_impact_metrics":["One-third of the labeled data","Improved motion generation"],"technology_tags":["Direct Preference Optimization","Text-to-video diffusion models"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:52:37.289378Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_4440d4054a47","title":"Contour Errors: An Ego","content":"arXiv:2506.04122v2 Announce Type: replace Abstract: Finding reliable matches is essential in multi-object tracking to ensure the accuracy and reliability of perception systems in safety-critical applications such as autonomous vehicles. Effective matching mitigates perception errors, enhancing object identification and tracking for improved performance and safety. However, traditional metrics such as Intersection over Union (IoU) and Center Point Distances (CPDs), which are effective in 2D image planes, often fail to find critical matches in complex 3D scenes. To address this limitation, we introduce Contour Errors (CEs), an ego or object-centric metric for identifying matches of interest in tracking scenarios from a functional perspective. By comparing bounding boxes in the ego vehicle's frame, contour errors provide a more functionally relevant assessment of object matches. Extensive experiments on the nuScenes dataset demonstrate that contour errors improve the reliability of matches over the state-of-the-art 2D IoU and CPD metrics in tracking-by-detection methods. In 3D car tracking, our results show that Contour Errors reduce functional failures (FPs/FNs) by 80% at close ranges and 60% at far ranges compared to IoU in the evaluation stage.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.04122","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.879994","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":178,"author":"Sharang Kaul, Mario Berk, Thiemo Gerbich, Abhinav Valada","raw_content_length":1265,"priority":7,"update_frequency":1,"reading_time_minutes":0.89,"robust_parsing_used":true,"entities":{"organizations":["Center Point Distances","Intersection over Union"],"persons":["An Ego arXiv:2506.04122v2 Announce Type","Contour Errors"],"locations":[],"monetary":[]},"char_count":1264,"language_detected":"en","key_concepts":{"key_phrases":["Contour Errors","An Ego","Announce Type","Abstract","reliable matches","multi-object tracking","the accuracy","reliability","perception systems","safety-critical applications"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Contour Errors":2.0,"An Ego":2.0,"Announce Type":1.0,"Abstract":1.0,"reliable matches":1.0,"multi-object tracking":1.0,"the accuracy":1.0,"reliability":1.0,"perception systems":1.0,"safety-critical applications":1.0}},"age_hours":2.7718954952777777,"is_recent":true,"quality_score":1.0,"sentiment_score":9.455,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.891,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8898,"joy":0.0052,"surprise":0.0235,"sadness":0.0521,"fear":0.0095,"anger":0.0102,"disgust":0.0097},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":5,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a new metric (Contour Errors) that improves object tracking in autonomous vehicles, leading to safer operation and potentially reduced accidents. The metric is validated on the nuScenes dataset, showing an 80% reduction in functional failures at close ranges and a 60% reduction at far ranges compared to IoU. However, it's still in the research phase with no clear path to commercial viability or large-scale deployment.","key_impact_metrics":["Functional failures reduced by 80%","Functional failures reduced by 60%"],"technology_tags":["autonomous vehicles","object tracking","computer vision"],"sdg_alignment":[9,11],"analyzed_at":"2025-10-29T09:52:40.522366Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_5107677d8ee5","title":"NIMO: a Nonlinear Interpretable MOdel","content":"arXiv:2506.05059v2 Announce Type: replace Abstract: Deep learning has achieved remarkable success across many domains, but it has also created a growing demand for interpretability in model predictions. Although many explainable machine learning methods have been proposed, post-hoc explanations lack guaranteed fidelity and are sensitive to hyperparameter choices, highlighting the appeal of inherently interpretable models. For example, linear regression provides clear feature effects through its coefficients. However, such models are often outperformed by more complex neural networks (NNs) that usually lack inherent interpretability. To address this dilemma, we introduce NIMO, a framework that combines inherent interpretability with the expressive power of neural networks. Building on the simple linear regression, NIMO is able to provide flexible and intelligible feature effects. Relevantly, we develop an optimization method based on parameter elimination, that allows for optimizing the NN parameters and linear coefficients effectively and efficiently. By relying on adaptive ridge regression we can easily incorporate sparsity as well. We show empirically that our model can provide faithful and intelligible feature effects while maintaining good predictive performance.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05059","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.880824","language":"en","tags":["statml","research","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":172,"author":"Shijian Xu, Marcello Massimo Negri, Volker Roth","raw_content_length":1288,"priority":7,"update_frequency":1,"reading_time_minutes":0.86,"robust_parsing_used":true,"entities":{"organizations":["linear","NIMO"],"persons":[],"locations":[],"monetary":[]},"char_count":1287,"language_detected":"en","key_concepts":{"key_phrases":["NIMO","a Nonlinear Interpretable MOdel","arXiv250605059v2 Announce Type","Abstract","Deep learning","remarkable success","many domains","a growing demand","interpretability","model predictions"],"filter_categories":{"ai_ml":["Deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"NIMO":2.0,"a Nonlinear Interpretable MOdel":2.0,"arXiv250605059v2 Announce Type":1.0,"Abstract":1.0,"Deep learning":1.0,"remarkable success":1.0,"many domains":1.0,"a growing demand":1.0,"interpretability":1.0,"model predictions":1.0}},"age_hours":2.7719256750000003,"is_recent":true,"quality_score":1.0,"sentiment_score":8.9225,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.7845,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8921,"joy":0.0511,"surprise":0.0339,"sadness":0.0033,"fear":0.005,"anger":0.0091,"disgust":0.0055},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This article presents a novel machine learning model (NIMO) that aims to improve interpretability while maintaining predictive performance. While the model could potentially be applied to various sustainability-related problems (e.g., predicting energy consumption or optimizing resource allocation), there are no concrete deployments or measured outcomes presented in the abstract. The research is still in the early stages, lacking real-world validation.","key_impact_metrics":[],"technology_tags":["machine learning","interpretability","neural networks"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:43.469668Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_af36a40bf1d1","title":"Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model","content":"arXiv:2506.05289v2 Announce Type: replace Abstract: Autoregressive image generation aims to predict the next token based on previous ones. However, this process is challenged by the bidirectional dependencies inherent in conventional image tokenizations, which creates a fundamental misalignment with the unidirectional nature of autoregressive models. To resolve this, we introduce AliTok, a novel Aligned Tokenizer that alters the dependency structure of the token sequence. AliTok employs a bidirectional encoder constrained by a causal decoder, a design that compels the encoder to produce a token sequence with both semantic richness and forward-dependency. Furthermore, by incorporating prefix tokens and employing a two-stage tokenizer training process to enhance reconstruction performance, AliTok achieves high fidelity and predictability simultaneously. Building upon AliTok, a standard decoder-only autoregressive model with just 177M parameters achieves a gFID of 1.44 and an IS of 319.5 on the ImageNet-256 benchmark. Scaling up to 662M parameters, our model reaches a gFID of 1.28, surpassing the state-of-the-art diffusion method while achieving a 10x faster sampling speed. The code and weights are available at https://github.com/ali-vilab/alitok.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.05289","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.881209","language":"en","tags":["preprints","computer-science","cscv","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":171,"author":"Pingyu Wu, Kai Zhu, Yu Liu, Longxiang Tang, Jian Yang, Yansong Peng, Wei Zhai, Yang Cao, Zheng-Jun Zha","raw_content_length":1265,"priority":7,"update_frequency":1,"reading_time_minutes":0.855,"robust_parsing_used":true,"entities":{"organizations":["AliTok"],"persons":["Aligned Tokenizer"],"locations":[],"monetary":[]},"char_count":1264,"language_detected":"en","key_concepts":{"key_phrases":["Sequence Modeling Alignment","Tokenizer","Autoregressive Model","AliTok","Announce Type","Abstract","Autoregressive image generation","previous ones","this process","the bidirectional dependencies"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Sequence Modeling Alignment":2.0,"Tokenizer":2.0,"Autoregressive Model":2.0,"AliTok":2.0,"Announce Type":1.0,"Abstract":1.0,"Autoregressive image generation":1.0,"previous ones":1.0,"this process":1.0,"the bidirectional dependencies":1.0}},"age_hours":2.771940592777778,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8778,"joy":0.0057,"surprise":0.0395,"sadness":0.0106,"fear":0.0397,"anger":0.0203,"disgust":0.0065},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel image tokenization method (AliTok) that improves the efficiency of autoregressive image generation. While faster sampling speeds (10x) are mentioned, the direct climate impact is unclear. The technology is in the applied research stage, with performance metrics (gFID, IS) provided, but lacking deployment or economic viability data.","key_impact_metrics":["gFID of 1.28","10x faster sampling speed"],"technology_tags":["image generation","autoregressive models","tokenization"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:52:46.176799Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_258ef9b59b9c","title":"Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video","content":"arXiv:2506.07180v2 Announce Type: replace Abstract: As video large language models (Video-LLMs) become increasingly integrated into real-world applications that demand grounded multimodal reasoning, ensuring their factual consistency and reliability is of critical importance. However, sycophancy, the tendency of these models to align with user input even when it contradicts the visual evidence, undermines their trustworthiness in such contexts. Current sycophancy research has largely overlooked its specific manifestations in the video-language domain, resulting in a notable absence of systematic benchmarks and targeted evaluations to understand how Video-LLMs respond under misleading user input. To fill this gap, we propose VISE (Video-LLM Sycophancy Benchmarking and Evaluation), the first benchmark designed to evaluate sycophantic behavior in state-of-the-art Video-LLMs across diverse question formats, prompt biases, and visual reasoning tasks. Specifically, VISE pioneeringly brings linguistic perspectives on sycophancy into the video domain, enabling fine-grained analysis across multiple sycophancy types and interaction patterns. Furthermore, we propose two potential training-free mitigation strategies, revealing potential paths for reducing sycophantic bias: (i) enhancing visual grounding through interpretable key-frame selection and (ii) steering model behavior away from sycophancy via targeted, inference-time intervention on its internal neural representations. Our code is available at https://github.com/William030422/Video-Sycophancy.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.07180","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.882019","language":"en","tags":["research","csai","preprints","cscl","computer-science","cscv","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":191,"author":"Wenrui Zhou, Mohamed Hendy, Shu Yang, Qingsong Yang, Zikun Guo, Yuyu Luo, Lijie Hu, Di Wang","raw_content_length":1567,"priority":7,"update_frequency":1,"reading_time_minutes":0.955,"robust_parsing_used":true,"entities":{"organizations":["Video-LLM Sycophancy Benchmarking and Evaluation","Video arXiv:2506.07180v2 Announce Type:"],"persons":[],"locations":[],"monetary":[]},"char_count":1566,"language_detected":"en","key_concepts":{"key_phrases":["Flattery","Motion","Benchmarking","Analyzing","Sycophancy","Video","arXiv250607180v2 Announce Type","Abstract","video large language models","Video-LLMs"],"filter_categories":{"ai_ml":["video large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Flattery":2.0,"Motion":2.0,"Benchmarking":2.0,"Analyzing":2.0,"Sycophancy":2.0,"Video":2.0,"arXiv250607180v2 Announce Type":1.0,"Abstract":1.0,"video large language models":1.0,"Video-LLMs":1.0}},"age_hours":2.771971443888889,"is_recent":true,"quality_score":1.0,"sentiment_score":5.258000000000001,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0516,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8919,"joy":0.0128,"surprise":0.0137,"sadness":0.0112,"fear":0.0268,"anger":0.0224,"disgust":0.0213},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":7,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving the reliability of Video-LLMs by addressing sycophancy. The concrete action is the development of a benchmark (VISE) and two potential mitigation strategies. The evidence strength is high due to the research nature and the availability of code, but it is still in the basic research stage with no deployed technology or measured outcomes in real-world climate applications.","key_impact_metrics":[],"technology_tags":["Video Large Language Models","AI Reliability","Sycophancy Mitigation"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:52:48.950500Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_c34d98311b5d","title":"Learning to Reason Across Parallel Samples for LLM Reasoning","content":"arXiv:2506.09014v2 Announce Type: replace Abstract: Scaling test-time compute brings substantial performance gains for large language models (LLMs). By sampling multiple answers and heuristically aggregate their answers (e.g., either through majority voting or using verifiers to rank the answers), one can achieve consistent performance gains in math domains. In this paper, we propose a new way to leverage such multiple sample set. We train a compact LLM, called Sample Set Aggregator (SSA), that takes a concatenated sequence of multiple samples and output the final answer, optimizing it for the answer accuracy with reinforcement learning. Experiments on five reasoning datasets demonstrate both the efficacy and efficiency of SSA. Notably, SSA improves over naive majority voting by 8% pass@5 on MATH. Furthermore, our 3B SSA surpasses model-based re-ranking with a much larger 72B process reward model. Our analysis also shows promising generalization ability of SSA, across sample set sizes, base model families and scales, and tasks. By separating LLMs to generate answers and LLMs to analyze and aggregate sampled answers, our approach can work with the outputs from premier black box models easily and efficiently.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.09014","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.882443","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":182,"author":"Jianing Qi, Xi Ye, Hao Tang, Zhigang Zhu, Eunsol Choi","raw_content_length":1227,"priority":7,"update_frequency":1,"reading_time_minutes":0.91,"robust_parsing_used":true,"entities":{"organizations":["SSA","LLM"],"persons":[],"locations":["Sample"],"monetary":[]},"char_count":1226,"language_detected":"en","key_concepts":{"key_phrases":["Reason","Parallel Samples","LLM Reasoning","arXiv250609014v2 Announce Type","Abstract","Scaling test-time compute","substantial performance gains","large language models","LLMs","multiple answers"],"filter_categories":{"ai_ml":["LLM Reasoning","large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Reason":2.0,"Parallel Samples":2.0,"LLM Reasoning":2.0,"arXiv250609014v2 Announce Type":1.0,"Abstract":1.0,"Scaling test-time compute":1.0,"substantial performance gains":1.0,"large language models":1.0,"LLMs":1.0,"multiple answers":1.0}},"age_hours":2.7719878002777776,"is_recent":true,"quality_score":1.0,"sentiment_score":8.404,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6808,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8781,"joy":0.062,"surprise":0.0409,"sadness":0.0031,"fear":0.0027,"anger":0.0093,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":4,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article proposes a new method for improving LLM reasoning by training a smaller model to aggregate multiple samples. The concrete action is the training and evaluation of the Sample Set Aggregator (SSA) on reasoning datasets, with a reported 8% improvement over majority voting on the MATH dataset. This is currently in the applied research stage, with no evidence of real-world deployment.","key_impact_metrics":["8% pass@5 improvement on MATH"],"technology_tags":["Large Language Models","Reinforcement Learning","Sample Aggregation"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:52:52.052700Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_e57726e859aa","title":"CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision","content":"arXiv:2506.11034v2 Announce Type: replace Abstract: Large language models (LLMs) have shown remarkable ability in various language tasks, especially with their emergent in-context learning capability. Extending LLMs to incorporate visual inputs, large vision-language models (LVLMs) have shown impressive performance in tasks such as recognition and visual question answering (VQA). Despite increasing interest in the utility of LLMs in causal reasoning tasks such as causal discovery and counterfactual reasoning, there has been relatively little work showcasing the abilities of LVLMs on visual causal reasoning tasks. We take this opportunity to formally introduce a comprehensive causal reasoning benchmark for multi-modal in-context learning from LVLMs. Our CausalVLBench encompasses three representative tasks: causal structure inference, intervention target prediction, and counterfactual prediction. We evaluate the ability of state-of-the-art open-source LVLMs on our causal reasoning tasks across three causal representation learning datasets and demonstrate their fundamental strengths and weaknesses. We hope that our benchmark elucidates the drawbacks of existing vision-language models and motivates new directions and paradigms in improving the visual causal reasoning abilities of LVLMs.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11034","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.882851","language":"en","tags":["research","csai","preprints","cscl","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Aneesh Komanduri, Karuna Bhaila, Xintao Wu","raw_content_length":1304,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["VQA"],"persons":[],"locations":[],"monetary":[]},"char_count":1303,"language_detected":"en","key_concepts":{"key_phrases":["LLMs","Visual Causal Reasoning","Large Vision","arXiv250611034v2","Announce Type","Large language models","remarkable ability","various language tasks","context","visual inputs"],"filter_categories":{"ai_ml":["LLMs","Large language models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"LLMs":3.0,"Visual Causal Reasoning":2.0,"Large Vision":2.0,"arXiv250611034v2":1.0,"Announce Type":1.0,"Large language models":1.0,"remarkable ability":1.0,"various language tasks":1.0,"context":1.0,"visual inputs":1.0}},"age_hours":2.7720024808333332,"is_recent":true,"quality_score":1.0,"sentiment_score":9.139999999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.828,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5145,"joy":0.0685,"surprise":0.3548,"sadness":0.0057,"fear":0.0249,"anger":0.0212,"disgust":0.0103},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":2,"technical_credibility":6,"economic_viability":2,"deployment_readiness":2,"systemic_impact":3,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper introduces a benchmark for visual causal reasoning in large vision-language models (LVLMs). While it aims to improve the capabilities of LVLMs, it is currently in the basic research stage with no deployed technology or measured outcomes related to sustainability. The potential climate impact is low as it's focused on improving AI models, not directly addressing environmental issues.","key_impact_metrics":[],"technology_tags":["Large Language Models","Visual Causal Reasoning","AI"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:52:55.092329Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_835bd69bc018","title":"RedDebate: Safer Responses through Multi","content":"arXiv:2506.11083v2 Announce Type: replace Abstract: We introduce RedDebate, a novel multi-agent debate framework that provides the foundation for Large Language Models (LLMs) to identify and mitigate their unsafe behaviours. Existing AI safety approaches often rely on costly human evaluation or isolated single-model assessment, both constrained by scalability and prone to oversight failures. RedDebate employs collaborative argumentation among multiple LLMs across diverse debate scenarios, enabling them to critically evaluate one another's reasoning and systematically uncover unsafe failure modes through fully automated red-teaming. We further integrate distinct long-term memory modules that preserve safety-relevant insights from debate interactions and leverage them during subsequent inference, facilitating continuous refinement of model behaviour. Empirical evaluation on safety benchmarks across a diverse set of models demonstrates that RedDebate substantially reduces unsafe outputs. While debate alone allows LLMs to refine their behaviour, the addition of memory yields further significant reductions. To the best of our knowledge, RedDebate is the first fully automated framework to unify multi-agent debate and red-teaming to progressively enhance LLM safety without human intervention.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.11083","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.883250","language":"en","tags":["research","computer-science","preprints","cscl","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":169,"author":"Ali Asad, Stephen Obadinma, Radin Shayanfar, Xiaodan Zhu","raw_content_length":1307,"priority":7,"update_frequency":1,"reading_time_minutes":0.845,"robust_parsing_used":true,"entities":{"organizations":["RedDebate","RedDeba","Large Language Models"],"persons":["Safer Responses"],"locations":[],"monetary":[]},"char_count":1306,"language_detected":"en","key_concepts":{"key_phrases":["RedDebate","Safer Responses","Multi","arXiv250611083v2 Announce Type","Abstract","a novel multi-agent debate framework","the foundation","Large Language Models","LLMs","their unsafe behaviours"],"filter_categories":{"ai_ml":["Large Language Models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"RedDebate":4.0,"Safer Responses":2.0,"Multi":2.0,"arXiv250611083v2 Announce Type":1.0,"Abstract":1.0,"a novel multi-agent debate framework":1.0,"the foundation":1.0,"Large Language Models":1.0,"LLMs":1.0,"their unsafe behaviours":1.0}},"age_hours":2.772016702777778,"is_recent":true,"quality_score":1.0,"sentiment_score":6.0115,"sentiment_category":"positive","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":0.2023,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.5459,"joy":0.0159,"surprise":0.0163,"sadness":0.0076,"fear":0.3881,"anger":0.0175,"disgust":0.0086},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":6,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":5,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a novel framework (RedDebate) for improving LLM safety, which could indirectly impact sustainability by reducing the potential for AI to promote misinformation or harmful practices. However, the impact is theoretical and there are no deployed units or operational data to demonstrate concrete reductions in environmental harm. The article mentions empirical evaluation on safety benchmarks, suggesting some level of metric-based assessment.","key_impact_metrics":["reduces unsafe outputs"],"technology_tags":["AI Safety","Large Language Models","Red-Teaming"],"sdg_alignment":[9,16],"analyzed_at":"2025-10-29T09:52:58.266901Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_9d2fbbf80ce8","title":"Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time Text","content":"arXiv:2506.12311v2 Announce Type: replace Abstract: Real-time text-to-speech (TTS) for Modern Hebrew is challenging due to the language's orthographic complexity. Existing solutions ignore crucial phonetic features such as stress that remain underspecified even when vowel marks are added. To address these limitations, we introduce Phonikud, a lightweight, open-source Hebrew grapheme-to-phoneme (G2P) system that outputs fully-specified IPA transcriptions. Our approach adapts an existing diacritization model with lightweight adaptors, incurring negligible additional latency. We also contribute the ILSpeech dataset of transcribed Hebrew speech with IPA annotations, serving as a benchmark for Hebrew G2P, as training data for TTS systems, and enabling audio-to-IPA for evaluating TTS performance while capturing important phonetic details. Our results demonstrate that Phonikud G2P conversion more accurately predicts phonemes from Hebrew text compared to prior methods, and that this enables training of effective real-time Hebrew TTS models with superior speed-accuracy trade-offs. We release our code, data, and models at https: //phonikud.github.io.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12311","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.883693","language":"en","tags":["research","cssd","preprints","cscl","eessas","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":151,"author":"Yakov Kolani, Maxim Melichov, Cobi Calev, Morris Alper","raw_content_length":1159,"priority":7,"update_frequency":1,"reading_time_minutes":0.755,"robust_parsing_used":true,"entities":{"organizations":["IPA","ILSpeech","TTS","Phonikud","Modern Hebrew"],"persons":[],"locations":[],"monetary":[]},"char_count":1158,"language_detected":"en","key_concepts":{"key_phrases":["Phonikud","Hebrew Grapheme","Phoneme Conversion","Real-Time Text","arXiv250612311v2 Announce Type","Abstract","Real-time text","speech","TTS","Modern Hebrew"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Phonikud":3.0,"Hebrew Grapheme":2.0,"Phoneme Conversion":2.0,"Real-Time Text":2.0,"arXiv250612311v2 Announce Type":1.0,"Abstract":1.0,"Real-time text":1.0,"speech":1.0,"TTS":1.0,"Modern Hebrew":1.0}},"age_hours":2.77203299,"is_recent":true,"quality_score":1.0,"sentiment_score":2.706,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4588,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.9451,"joy":0.0099,"surprise":0.0233,"sadness":0.0047,"fear":0.0063,"anger":0.007,"disgust":0.0038},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":7,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":6,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article describes a new grapheme-to-phoneme system for Hebrew, which could potentially improve the accessibility of text-to-speech technology. While the technology is open-source and shows improved accuracy compared to prior methods, its direct climate impact is minimal. The project is still in the applied research phase, with code, data, and models released but no large-scale deployment mentioned.","key_impact_metrics":["Superior speed-accuracy trade-offs compared to prior methods"],"technology_tags":["Grapheme-to-Phoneme Conversion","Text-to-Speech"],"sdg_alignment":[4,9],"analyzed_at":"2025-10-29T09:53:01.443584Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3541a8f63a3a","title":"Why AI Agents Still Need You: Findings from Developer","content":"arXiv:2506.12347v3 Announce Type: replace Abstract: Software Engineering Agents (SWE agents) can autonomously perform development tasks on benchmarks like SWE Bench, but still face challenges when tackling complex and ambiguous real-world tasks. Consequently, SWE agents are often designed to allow interactivity with developers, enabling collaborative problem-solving. To understand how developers collaborate with SWE agents and the barriers they face in such interactions, we observed 19 developers using an in-IDE agent to resolve 33 open issues in repositories to which they had previously contributed. Participants successfully resolved about half of these issues, with those solving issues incrementally having greater success than those using a one-shot approach. Participants who actively collaborated with the agent and iterated on its outputs were also more successful, though they faced challenges in trusting the agent's responses and collaborating on debugging and testing. Our findings suggest that to facilitate successful collaborations, both SWE agents and developers should actively contribute to tasks throughout all stages of the software development process. SWE agents can enable this by challenging and engaging in discussions with developers, rather than being conclusive or sycophantic.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.12347","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.884093","language":"en","tags":["research","csse","preprints","cshc","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":180,"author":"Aayush Kumar, Yasharth Bajpai, Sumit Gulwani, Gustavo Soares, Emerson Murphy-Hill","raw_content_length":1313,"priority":7,"update_frequency":1,"reading_time_minutes":0.9,"robust_parsing_used":true,"entities":{"organizations":[],"persons":[],"locations":[],"monetary":[]},"char_count":1312,"language_detected":"en","key_concepts":{"key_phrases":["SWE agents","AI Agents","You","Findings","Developer","developers","arXiv250612347v3 Announce Type","Abstract","Software Engineering Agents","development tasks"],"filter_categories":{"ai_ml":["AI Agents"],"engineering":["Software Engineering Agents","development tasks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SWE agents":3.0,"AI Agents":2.0,"You":2.0,"Findings":2.0,"Developer":2.0,"developers":2.0,"arXiv250612347v3 Announce Type":1.0,"Abstract":1.0,"Software Engineering Agents":1.0,"development tasks":1.0}},"age_hours":2.772048191666667,"is_recent":true,"quality_score":0.7,"sentiment_score":7.7495,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5499,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8544,"joy":0.0074,"surprise":0.0105,"sadness":0.0069,"fear":0.0769,"anger":0.0273,"disgust":0.0166},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":1,"technical_credibility":6,"economic_viability":2,"deployment_readiness":3,"systemic_impact":2,"justice_equity":3,"innovation_quality":5,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research explores the collaboration between developers and AI agents in software engineering. While the research identifies challenges and potential improvements in this collaboration, it does not directly address climate change or environmental sustainability. The study observes 19 developers resolving 33 open issues, but there's no quantification of environmental impact.","key_impact_metrics":["50% issue resolution rate"],"technology_tags":["AI agents","software engineering","collaborative problem-solving"],"sdg_alignment":[],"analyzed_at":"2025-10-29T09:53:04.051579Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f70e5fd7df14","title":"Bures","content":"arXiv:2506.14020v3 Announce Type: replace Abstract: Graph generation has emerged as a critical task in fields ranging from drug discovery to circuit design. Contemporary approaches, notably diffusion and flow-based models, have achieved solid graph generative performance through constructing a probability path that interpolates between reference and data distributions. However, these methods typically model the evolution of individual nodes and edges independently and use linear interpolations to build the path. This disentangled interpolation breaks the interconnected patterns of graphs, making the constructed probability path irregular and non-smooth, which causes poor training dynamics and faulty sampling convergence. To address the limitation, this paper first presents a theoretically grounded framework for probability path construction in graph generative models. Specifically, we model the joint evolution of the nodes and edges by representing graphs as connected systems parameterized by Markov random fields (MRF). We then leverage the optimal transport displacement between MRF objects to design a smooth probability path that ensures the co-evolution of graph components. Based on this, we introduce BWFlow, a flow-matching framework for graph generation that utilizes the derived optimal probability path to benefit the training and sampling algorithm design. Experimental evaluations in plain graph generation and molecule generation validate the effectiveness of BWFlow with competitive performance, better training convergence, and efficient sampling.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.14020","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.884918","language":"en","tags":["statml","research","csai","preprints","cslg","computer-science","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Keyue Jiang, Jiahao Cui, Xiaowen Dong, Laura Toni","raw_content_length":1579,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":[],"persons":["Announce Type"],"locations":[],"monetary":[]},"char_count":1578,"language_detected":"en","key_concepts":{"key_phrases":["Bures","Announce Type","Abstract","Graph generation","a critical task","fields","drug discovery","circuit design","Contemporary approaches","notably diffusion and flow-based models"],"filter_categories":{"research_academic":["drug discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Bures":2.0,"Announce Type":1.0,"Abstract":1.0,"Graph generation":1.0,"a critical task":1.0,"fields":1.0,"drug discovery":1.0,"circuit design":1.0,"Contemporary approaches":1.0,"notably diffusion and flow-based models":1.0}},"age_hours":2.7720749566666663,"is_recent":true,"quality_score":0.7,"sentiment_score":4.1105,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1779,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8747,"joy":0.0313,"surprise":0.0741,"sadness":0.0046,"fear":0.0045,"anger":0.0081,"disgust":0.0027},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":2,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This paper presents a new graph generation framework (BWFlow) with improved training convergence and efficient sampling. While graph generation has applications in drug discovery and circuit design, its direct climate impact is currently theoretical and requires further development and deployment in specific sustainability-related applications to demonstrate concrete GHG emission reductions or other environmental benefits. The research is peer-reviewed, increasing its credibility, but it's still in the early stages of development.","key_impact_metrics":["Better training convergence","Efficient sampling"],"technology_tags":["Graph generation","Flow-matching","Markov random fields"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:53:07.170743Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_f6ae614b03b5","title":"SHeRLoc: Synchronized Heterogeneous Radar Place Recognition for Cross","content":"arXiv:2506.15175v2 Announce Type: replace Abstract: Despite the growing adoption of radar in robotics, the majority of research has been confined to homogeneous sensor types, overlooking the integration and cross-modality challenges inherent in heterogeneous radar technologies. This leads to significant difficulties in generalizing across diverse radar data types, with modality-aware approaches that could leverage the complementary strengths of heterogeneous radar remaining unexplored. To bridge these gaps, we propose SHeRLoc, the first deep network tailored for heterogeneous radar, which utilizes RCS polar matching to align multimodal radar data. Our hierarchical optimal transport-based feature aggregation method generates rotationally robust multi-scale descriptors. By employing FFT-similarity-based data mining and adaptive margin-based triplet loss, SHeRLoc enables FOV-aware metric learning. SHeRLoc achieves an order of magnitude improvement in heterogeneous radar place recognition, increasing recall@1 from below 0.1 to 0.9 on a public dataset and outperforming state of-the-art methods. Also applicable to LiDAR, SHeRLoc paves the way for cross-modal place recognition and heterogeneous sensor SLAM. The supplementary materials and source code are available at https://sites.google.com/view/radar-sherloc.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.15175","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.885711","language":"en","tags":["csro","computer-science","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":167,"author":"Hanjun Kim, Minwoo Jung, Wooseong Yang, Ayoung Kim","raw_content_length":1326,"priority":7,"update_frequency":1,"reading_time_minutes":0.835,"robust_parsing_used":true,"entities":{"organizations":["FOV"],"persons":[],"locations":[],"monetary":[]},"char_count":1325,"language_detected":"en","key_concepts":{"key_phrases":["SHeRLoc","Synchronized Heterogeneous Radar Place Recognition","Cross","arXiv250615175v2 Announce Type","Abstract","the growing adoption","radar","robotics","the majority","research"],"filter_categories":{"healthcare_tech":["research"],"research_academic":["research"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"SHeRLoc":2.0,"Synchronized Heterogeneous Radar Place Recognition":2.0,"Cross":2.0,"arXiv250615175v2 Announce Type":1.0,"Abstract":1.0,"the growing adoption":1.0,"radar":1.0,"robotics":1.0,"the majority":1.0,"research":1.0}},"age_hours":2.7721041294444446,"is_recent":true,"quality_score":1.0,"sentiment_score":4.212,"sentiment_category":"neutral","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.1576,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.8409,"joy":0.0089,"surprise":0.0735,"sadness":0.0195,"fear":0.0257,"anger":0.0212,"disgust":0.0104},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"applied_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":3,"systemic_impact":4,"justice_equity":3,"innovation_quality":7,"evidence_strength":6,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":true,"has_peer_review":false,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"The article presents a novel deep network (SHeRLoc) for heterogeneous radar place recognition, demonstrating a significant improvement in recall@1 from below 0.1 to 0.9 on a public dataset. While promising, it is still in the applied research stage with no deployed units or customer contracts mentioned, limiting its immediate sustainability impact. The potential for climate impact is indirect, as improved robotics could lead to more efficient systems, but this is not explicitly quantified.","key_impact_metrics":["recall@1 improvement: 0.1 to 0.9"],"technology_tags":["radar","robotics","deep learning","place recognition","SLAM"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:53:10.225182Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
{"id":"science_arxiv_cs_3ce88e25e1f1","title":"Discrete Compositional Generation via General Soft Operators and Robust Reinforcement Learning","content":"arXiv:2506.17007v2 Announce Type: replace Abstract: A major bottleneck in scientific discovery consists of narrowing an exponentially large set of objects, such as proteins or molecules, to a small set of promising candidates with desirable properties. While this process can rely on expert knowledge, recent methods leverage reinforcement learning (RL) guided by a proxy reward function to enable this filtering. By employing various forms of entropy regularization, these methods aim to learn samplers that generate diverse candidates that are highly rated by the proxy function. In this work, we make two main contributions. First, we show that these methods are liable to generate overly diverse, suboptimal candidates in large search spaces. To address this issue, we introduce a novel unified operator that combines several regularized RL operators into a general framework that better targets peakier sampling distributions. Secondly, we offer a novel, robust RL perspective of this filtering process. The regularization can be interpreted as robustness to a compositional form of uncertainty in the proxy function (i.e., the true evaluation of a candidate differs from the proxy's evaluation). Our analysis leads us to a novel, easy-to-use algorithm we name trajectory general mellowmax (TGM): we show it identifies higher quality, diverse candidates than baselines in both synthetic and real-world tasks. Code: https://github.com/marcojira/tgm.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2506.17007","published_date":"2025-10-13T04:00:00","collected_date":"2025-10-13T06:41:04.886110","language":"en","tags":["computer-science","cslg","preprints","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":210,"author":"Marco Jiralerspong, Esther Derman, Danilo Vucetic, Nikolay Malkin, Bilun Sun, Tianyu Zhang, Pierre-Luc Bacon, Gauthier Gidel","raw_content_length":1454,"priority":7,"update_frequency":1,"reading_time_minutes":1.05,"robust_parsing_used":true,"entities":{"organizations":["Robust Reinforcement Learning arXiv:2506.17007v2 Announce Type"],"persons":[],"locations":[],"monetary":[]},"char_count":1453,"language_detected":"en","key_concepts":{"key_phrases":["Discrete Compositional Generation","General Soft Operators","Robust Reinforcement Learning","arXiv250617007v2 Announce Type","Abstract","A major bottleneck","scientific discovery","an exponentially large set","objects","proteins"],"filter_categories":{"ai_ml":["Robust Reinforcement Learning"],"research_academic":["scientific discovery"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Discrete Compositional Generation":2.0,"General Soft Operators":2.0,"Robust Reinforcement Learning":2.0,"arXiv250617007v2 Announce Type":1.0,"Abstract":1.0,"A major bottleneck":1.0,"scientific discovery":1.0,"an exponentially large set":1.0,"objects":1.0,"proteins":1.0}},"age_hours":2.7721195077777776,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8779,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9125,"joy":0.0112,"surprise":0.0354,"sadness":0.0047,"fear":0.0097,"anger":0.0154,"disgust":0.0111},"emotion_method":"local"},"sustainability_analysis":{"content_type":"breakthrough_research","innovation_stage":"basic_research","climate_impact_potential":3,"technical_credibility":7,"economic_viability":3,"deployment_readiness":2,"systemic_impact":4,"justice_equity":3,"innovation_quality":6,"evidence_strength":7,"investment_signals":{"has_funding":false,"has_patents":false,"has_customers":false,"has_metrics":false,"has_peer_review":true,"has_deployment":false},"verification_indicators":{"owid_indicator":false,"ipcc_alignment":false,"iea_data":false,"third_party_verified":false,"regulatory_approved":false},"flags":{"greenwashing_risk":false,"vaporware_risk":true,"fossil_transition":false},"reasoning":"This research focuses on improving reinforcement learning algorithms for identifying promising molecules or proteins, which *could* indirectly contribute to sustainability by accelerating the discovery of materials for clean energy or carbon capture. However, there are no concrete actions or measurable outcomes related to sustainability in this article. It is at the basic research stage, with no deployment or economic viability demonstrated.","key_impact_metrics":[],"technology_tags":["reinforcement learning","molecule discovery","protein discovery"],"sdg_alignment":[9],"analyzed_at":"2025-10-29T09:53:12.704700Z","analyzed_by":"gemini-api-batch","filter_name":"sustainability"}}
