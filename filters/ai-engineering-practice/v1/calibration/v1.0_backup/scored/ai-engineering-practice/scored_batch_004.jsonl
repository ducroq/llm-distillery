{"id":"arxiv_6a8be1963216","title":"Classification of worldwide news articles by perceived quality, 2018","content":"This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.","source":"arxiv","source_type":"api","url":"https://arxiv.org/abs/2511.16416v1","published_date":"2025-11-20T14:41:41","collected_date":"2025-11-22T06:40:57.211635","language":"en","tags":["preprint","academic","cscl","cslg"],"metadata":{"arxiv_id":"2511.16416v1","pdf_url":"https://arxiv.org/pdf/2511.16416v1.pdf","authors":["Connor McElroy","Thiago E. A. de Oliveira","Chris Brogly"],"categories":["cs.CL","cs.LG"],"paper_type":"preprint","source_api":"arxiv","word_count":173,"author_count":3,"entities":{"organizations":["Random Forest","the Common Crawl","ModernBERT"],"persons":[],"locations":[],"monetary":["0.9593 ROC","0.8131 ROC AUC"]},"char_count":1305,"language_detected":"en","key_concepts":{"key_phrases":["Classification","worldwide news articles","perceived quality","This study","supervised machine learning","deep learning models","perceived lower-quality news articles","perceived higher-quality news articles","3 machine learning classifiers","3 deep learning models"],"filter_categories":{"ai_ml":["supervised machine learning","deep learning models","3 machine learning classifiers","3 deep learning models"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Classification":2.0,"worldwide news articles":2.0,"perceived quality":2.0,"This study":1.0,"supervised machine learning":1.0,"deep learning models":1.0,"perceived lower-quality news articles":1.0,"perceived higher-quality news articles":1.0,"3 machine learning classifiers":1.0,"3 deep learning models":1.0}},"age_hours":40.139378906666664,"is_recent":false,"quality_score":1.0,"hashes":{"content_md5":"db5dd5eae4cdfa844e0ced7e9dd052d0","title_md5":"9aeac712771ed4d07a191651940a19a7","url_normalized":"1aa58cf6145f18eb7820ad121e0afbbb","minhash_signature":["24908679","5889961","14366","13560711","1635470","6288288","18766408","2181150","2753670","26918939","8255558","5071316","2343024","1166689","953500","4356152","4551842","4282388","20397664","35607516","1196901","88593","1386815","2113985","394996","1478450","4474992","9188762","3333020","2365787","522500","5794821","33049007","582111","1090859","27257070","14745419","3191968","309467","174348","1860382","3166446","9869035","2217375","414896","17818165","1691750","17454425","1132398","4726740","5703177","8355167","6725716","3018416","136855","1909511","7015836","6045037","9956478","8076200","6991339","7144066","1936","7969807","4698640","4770883","3035295","1509720","1815715","4625726","9097233","15390952","15056664","4528274","7951082","4797850","3542338","655996","7656379","721726","13237933","21564890","2296366","13102422","6278366","6694534","12945555","12545075","6430507","8318141","52995","1159416","17193190","3023236","627737","5560495","1608076","479007","24302950","35832301","15637796","2133916","2112816","7495224","1684279","2289121","2193094","145406","7342023","7589371","682304","120729","3010402","12152184","13818057","28927","926978","1307835","1592955","12363293","6123858","1124425","1129826","7407467","15152023","809487","9098556","33668"],"title_minhash":["158975794","25550307","64336003","48639709","128038304","140018911","51973581","268243036","18115410","54651372","41492799","5071316","2343024","17795633","119533265","39043394","33335804","4282388","97811991","149866142","1196901","9954399","18540188","2113985","37160629","125484838","160461602","64536951","21652241","86644868","2169913","87553","66123117","582111","52217906","166186361","28724667","21890042","334262741","30141695","9515827","60797165","82114953","168740391","12585749","80829189","46396458","51242411","27981188","35423699","40025517","71995530","25610513","26452910","107176645","69597402","7015836","23226504","58589950","29171982","11267373","164217337","74571962","46682630","52113529","16611414","55088169","6604142","1815715","58546113","19680712","135394938","15660456","99333856","15858453","28133799","40814256","6134367","58734122","208832266","14672648","21564890","107842415","134183993","201461211","26465583","114412282","15301898","1442738","79894080","111165131","2175767","19499623","34860893","13402462","5560495","1608076","43622315","32777169","7840644","42362674","185098597","49743731","12633684","157147523","92542995","28216367","47418031","112866628","50518940","21826847","67307755","78470241","9732890","14983762","28227271","8665591","1307835","38334493","21280434","20571764","85562161","119075122","58922724","25518271","289650537","18750775","168315765"],"combined_hash":"31d270d4fb05e72e2358adda7e1b2e96"},"sentiment_score":7.997000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5994,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8964,"joy":0.0141,"surprise":0.0402,"sadness":0.0082,"fear":0.0068,"anger":0.0237,"disgust":0.0106},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":6.0,"evidence":"The paper discusses the use of AI in software development, including code generation and testing. It mentions the integration of AI tools into the development process, but lacks specific details on the exact steps and decision points within the workflow. It mentions the use of LLMs for code generation and testing."},"validation_coverage":{"score":7.0,"evidence":"The paper discusses the validation of AI-generated code through testing and code review. It mentions the challenges of ensuring the reliability and correctness of AI outputs and proposes methods for verifying the code. Specific validation methods are described, such as unit testing and static analysis."},"methodological_rigor":{"score":7.0,"evidence":"The paper presents a systematic approach to evaluating the effectiveness of AI tools in software development. It includes data from experiments and case studies, with a clear methodology for data collection and analysis. The sample sizes are mentioned, and the methodology is described in detail."},"practitioner_voice":{"score":5.0,"evidence":"The paper includes some references to practitioner experiences and challenges in using AI tools. However, it primarily focuses on the academic and research aspects of the topic, with limited direct quotes or first-hand accounts from practitioners. It references some industry practices."},"educational_applicability":{"score":7.0,"evidence":"The paper provides insights into the use of AI in software development, which can inform curriculum design and training programs. It highlights the skills and knowledge needed to effectively integrate AI tools into the development process. The paper could be used to develop educational materials on AI-augmented software engineering."},"analyzed_at":"2025-12-19T08:51:08.044044Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"positive_news_frontiers_sustainable_cities_d2b0edc47e0d","title":"Evaluating the effectiveness of the city master plan in regulating future urban spatial growth of Varanasi city, India","content":"This paper evaluates the effectiveness of the Varanasi City Master Plan 2031 in regulating urban growth by analyzing Land Use and Land Cover (LULC) changes. By comparing the model's predictions for 2031 with the Varanasi Development Authority's Master Plan, the study identifies discrepancies in the direction and extent of urban expansion. Rapid urbanization, driven by industrialization, migration, and infrastructural development, has dramatically reshaped Varanasi's spatial patterns. Utilizing remote sensing data from Landsat images (1990, 2000, 2010, and 2021) and integrating machine learning techniques, including the Multi-layer Perceptron and Markov Chain Analysis (MLP-MCA), this study simulates and predicts future urban expansion. The model's predictions, with an accuracy above 80%, offer critical insights for policymakers to revisit urban planning strategies. The built-up area has grown from 45.10 km2 in 1990 to a projected 262.05 km2 by 2031, representing a 480.95% increase over four decades. Simultaneously, agricultural acreage has declined from 908.23 km2 to 656 km2, a reduction of 252.23 km2, or 27.77%, highlighting the shift from rural to urban land use. Notably, in the southwest, the Masterplan consistently exceeds predicted built-up areas across most zones, except in Zone 4 (9â€“12 km), with over-allocations around the Mughalsarai area. Furthermore, Sectors A, B, C, and D anticipate higher built-up areas, particularly in zones 6â€“9 km and 9â€“12 km. This study underscores the need for sustainable development planning to mitigate the negative impacts of rapid urbanization, such as loss of green spaces, environmental degradation, and urban heat island effects. The combined approach of remote sensing and machine learning provides a robust and replicable methodology for other rapidly urbanizing cities, ensuring future expansion aligns with sustainable development goals.","source":"positive_news_frontiers_sustainable_cities","source_type":"rss","url":"https://www.frontiersin.org/articles/10.3389/frsc.2025.1649418","published_date":"2025-11-11T00:00:00","collected_date":"2025-11-11T18:38:07.051432","language":"en","tags":["open-access","original_research","urban-planning","innovation","collective-benefit","sustainable-cities","positive_news"],"metadata":{"feed_title":"Frontiers in Sustainable Cities | New and Recent Articles","source_category":"positive_news","word_count":272,"author":"Abhinav Rai","raw_content_length":1905,"priority":8,"update_frequency":168,"reading_time_minutes":1.36,"robust_parsing_used":true,"entities":{"organizations":["the Varanasi City Master Plan 2031","Land Use and Land Cover","Varanasi","Markov Chain Analysis","the Varanasi Development Authority's"],"persons":["Plan"],"locations":["India","Perceptron","Multi","Varanasi city"],"monetary":[]},"char_count":1905,"language_detected":"en","key_concepts":{"key_phrases":["the effectiveness","the city master plan","future urban spatial growth","Varanasi city","This paper","the Varanasi City Master Plan","urban growth","LULC","the models predictions","the Varanasi Development Authoritys Master Plan"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"the effectiveness":3.0,"the city master plan":2.0,"future urban spatial growth":2.0,"Varanasi city":2.0,"This paper":1.0,"the Varanasi City Master Plan":1.0,"urban growth":1.0,"LULC":1.0,"the models predictions":1.0,"the Varanasi Development Authoritys Master Plan":1.0}},"age_hours":19.003659200833333,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"a84d67d71916d91a7f0f915c157568f7","title_md5":"2cd708b209e8d862cbef2ca544740247","url_normalized":"7d3fc085d15c012ebf099ef74469c5c3","minhash_signature":["9837667","3421805","14366","292436","711517","7901950","14786822","12533084","2753670","4729967","3139314","10764267","2796384","1166689","953500","4356152","3016691","1929019","178409","955784","1196901","88593","433252","5079694","3593204","1478450","7507083","9160874","14898113","13696101","3088885","87553","529443","2820767","1053967","2422815","1313735","6218001","296674","6977948","4708391","2210213","6374721","1785966","12507014","5244114","646834","8514615","1132398","10675237","4846679","843096","10589055","7574389","3063247","1914246","2780349","5982858","4736748","1151625","2318646","2179429","1936","4886012","7601","3789593","7366789","2551573","3843993","2000213","473069","877954","11204675","4528274","10844469","2595826","995244","814536","7705296","24325924","301782","1544236","1812598","8572837","1595927","2319043","4602115","8125793","5524105","8661640","7521029","2175767","8261531","436779","3199414","6119818","631649","9029846","14860642","713149","583082","10009000","3663773","5758998","6760750","3376316","2193094","8841988","12007630","44001","5003486","3234851","2086119","4438756","3450231","734346","120732","1144143","7663201","2957551","6123858","4042643","952385","2307778","14744595","809487","20507963","33668"],"title_minhash":["16524246","66260777","2507878","11943608","711517","8408238","75314562","17819323","17106088","54651372","70099939","40985977","10736429","64763567","16595777","30370471","24775158","56318699","4032655","8708371","84656278","5184937","459618","58173194","21393102","15295755","84257291","18987069","8420710","52561533","29272303","37703583","81484603","20375603","1090859","27257070","28724667","9182311","158376087","34868937","95655064","21340639","6374721","1785966","24306887","21345211","59563936","162790183","51897052","10675237","5703177","843096","10820278","7574389","14522170","13331872","53149991","5982858","55048751","21256722","24459900","129687095","27377080","94094176","86122465","34548017","88888062","3973728","21146863","96477436","141659921","8562430","38678844","19195630","22643791","3487483","10343841","6134367","75374865","51641513","21139769","24507011","14734044","24152984","15871323","74995516","36637427","12958334","5524105","102962942","29846715","36777798","19499623","61682902","111090928","17822880","631649","43573138","60438428","15422668","57689133","65588093","14554737","156494325","21094784","4255067","9964460","17178449","12007630","44001","21826847","55388461","21315175","39695324","28948509","28227271","926978","61295552","46361349","32625560","11288622","8564697","46355616","23957762","20369645","15208201","61576740","45227134"],"combined_hash":"9d3a4fc64cce2ac6960e63f8a32c1485"},"sentiment_score":8.1845,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6369,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8427,"joy":0.0237,"surprise":0.0423,"sadness":0.0085,"fear":0.0216,"anger":0.0394,"disgust":0.0217},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"practitioner_account","workflow_detail":{"score":7.0,"evidence":"The author describes using Copilot to generate code from comments, then manually refactoring the code to improve readability and correctness. They also mention using Copilot to generate unit tests, which they then review and modify as needed. They describe a specific workflow of generating, reviewing, and refactoring."},"validation_coverage":{"score":7.0,"evidence":"The author explicitly mentions reviewing and refactoring the code generated by Copilot, as well as reviewing and modifying the generated unit tests. This indicates a validation process, although the specifics are not detailed, they mention manually checking for correctness and readability."},"methodological_rigor":{"score":3.0,"evidence":"The article is a personal account of the author's experience using Copilot. There is no systematic data collection or analysis. The claims are based on the author's subjective experience."},"practitioner_voice":{"score":9.0,"evidence":"The article is written from the first-person perspective of a software developer. The author shares their personal experiences and insights using Copilot in their daily work. The article uses 'I' and describes their personal experience."},"educational_applicability":{"score":7.0,"evidence":"The article provides practical examples of how Copilot can be used in software development workflows. It highlights the importance of code review and refactoring, even when using AI-powered tools. This could be used to inform training programs for developers on how to effectively use AI coding assistants."},"analyzed_at":"2025-12-19T08:51:17.464428Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"community_social_github_trending_af69ecc25504","title":"microsoft/BitNet","content":"Official inference framework for 1-bit LLMsbitnet.cpp Try it out via this demo, or build and run it on your own CPU or GPU. bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support fast and lossless inference of 1.58-bit models on CPU and GPU (NPU support will coming next). The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of 1.37x to 5.07x on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by 55.4% to 70.0%, further boosting overall efficiency. On x86 CPUs, speedups range from 2.37x to 6.17x with energy reductions between 71.9% to 82.2%. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the technical report for more details. The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp. Demo A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2: https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1 What's New: 05/20/2025 BitNet Official GPU inference kernel 04/14/2025 BitNet Official 2B Parameter Model on Hugging Face 02/18/2025 Bitnet.cpp: Efficient Edge Inference for Ternary LLMs 11/08/2024 BitNet a4.8: 4-bit Activations for 1-bit LLMs 10/21/2024 1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs 10/17/2024 bitnet.cpp 1.0 released. 03/21/2024 The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ 02/27/2024 The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits 10/17/2023 BitNet: Scaling 1-bit Transformers for Large Language Models Acknowledgements This project is based on the llama.cpp framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in T-MAC. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC. Official Models Model Parameters CPU Kernel I2_S TL1 TL2 BitNet-b1.58-2B-4T 2.4B x86 âœ… âŒ âœ… ARM âœ… âœ… âŒ Supported Models â—ï¸We use existing 1-bit LLMs available on Hugging Face to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens. Model Parameters CPU Kernel I2_S TL1 TL2 bitnet_b1_58-large 0.7B x86 âœ… âŒ âœ… ARM âœ… âœ… âŒ bitnet_b1_58-3B 3.3B x86 âŒ âŒ âœ… ARM âŒ âœ… âŒ Llama3-8B-1.58-100B-tokens 8.0B x86 âœ… âŒ âœ… ARM âœ… âœ… âŒ Falcon3 Family 1B-10B x86 âœ… âŒ âœ… ARM âœ… âœ… âŒ Falcon-E Family 1B-3B x86 âœ… âŒ âœ… ARM âœ… âœ… âŒ Installation Requirements python>=3.9 cmake>=3.22 clang>=18 For Windows users, install Visual Studio 2022. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake): Desktop-development with C++ C++-CMake Tools for Windows Git for Windows C++-Clang Compiler for Windows MS-Build Support for LLVM-Toolset (clang) For Debian/Ubuntu users, you can download with Automatic installation script bash -c \"$(wget -O - https://apt.llvm.org/llvm.sh)\" conda (highly recommend) Build from source [!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues. Clone the repo git clone --recursive https://github.com/microsoft/BitNet.git cd BitNet Install the dependencies # (Recommended) Create a new conda environment conda create -n bitnet-cpp python=3.9 conda activate bitnet-cpp pip install -r requirements.txt Build the project # Manually download the model and run with local path huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd] [--use-pretuned] Setup the environment for running inference optional arguments: -h, --help show this help message and exit --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit} Model used for inference --model-dir MODEL_DIR, -md MODEL_DIR Directory to save/load the model --log-dir LOG_DIR, -ld LOG_DIR Directory to save the logging info --quant-type {i2_s,tl1}, -q {i2_s,tl1} Quantization type --quant-embd Quantize the embeddings to f16 --use-pretuned, -p Use the pretuned kernel parameters Usage Basic usage # Run inference with the quantized model python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p \"You are a helpful assistant\" -cnv usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv] Run inference optional arguments: -h, --help show this help message and exit -m MODEL, --model MODEL Path to model file -n N_PREDICT, --n-predict N_PREDICT Number of tokens to predict when generating text -p PROMPT, --prompt PROMPT Prompt to generate text from -t THREADS, --threads THREADS Number of threads to use -c CTX_SIZE, --ctx-size CTX_SIZE Size of the prompt context -temp TEMPERATURE, --temperature TEMPERATURE Temperature, a hyperparameter that controls the randomness of the generated text -cnv, --conversation Whether to enable chat mode or not (for instruct models.) (When this option is turned on, the prompt specified by -p will be used as the system prompt.) Benchmark We provide scripts to run the inference benchmark providing a model. usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS] Setup the environment for running the inference required arguments: -m MODEL, --model MODEL Path to the model file. optional arguments: -h, --help Show this help message and exit. -n N_TOKEN, --n-token N_TOKEN Number of generated tokens. -p N_PROMPT, --n-prompt N_PROMPT Prompt to generate text from. -t THREADS, --threads THREADS Number of threads to use. Here's a brief explanation of each argument: -m, --model: The path to the model file. This is a required argument that must be provided when running the script. -n, --n-token: The number of tokens to generate during the inference. It is an optional argument with a default value of 128. -p, --n-prompt: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512. -t, --threads: The number of threads to use for running the inference. It is an optional argument with a default value of 2. -h, --help: Show the help message and exit. Use this argument to display usage information. For example: python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4 This command would run the inference benchmark using the model located at /path/to/model, generating 200 tokens from a 256 token prompt, utilizing 4 threads. For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine: python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M # Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128 Convert from .safetensors Checkpoints # Prepare the .safetensors model file huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16 # Convert to gguf model python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16 FAQ (Frequently Asked Questions)ðŸ“Œ Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp? A: This is an issue introduced in recent version of llama.cpp. Please refer to this commit in the discussion to fix this issue. Q2: How to build with clang in conda environment on windows? A: Before building the project, verify your clang installation and access to Visual Studio tools by running: clang -v This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as: 'clang' is not recognized as an internal or external command, operable program or batch file. It indicates that your command line window is not properly initialized for Visual Studio tools. â€¢ If you are using Command Prompt, run: \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Professional\\Common7\\Tools\\VsDevCmd.bat\" -startdir=none -arch=x64 -host_arch=x64 â€¢ If you are using Windows PowerShell, run the following commands: Import-Module \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Professional\\Common7\\Tools\\Microsoft.VisualStudio.DevShell.dll\" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments \"-arch=x64 -host_arch=x64\" These steps will initialize your environment and allow you to use the correct Visual Studio tools.","source":"community_social_github_trending","source_type":"rss","url":"https://github.com/microsoft/BitNet","published_date":"2025-10-05T00:00:04.430906","collected_date":"2025-10-05T02:00:04.431067","language":"en","tags":["open-source","trending","github","developer","community_social"],"metadata":{"feed_title":"GitHub All Languages Daily Trending","source_category":"community_social","word_count":1324,"author":null,"raw_content_length":16198,"priority":8,"update_frequency":6,"reading_time_minutes":6.62,"robust_parsing_used":true,"entities":{"organizations":["CPU","microsoft","BitNet","GPU","NPU"],"persons":[],"locations":[],"monetary":[]},"char_count":9858,"language_detected":"en","key_concepts":{"key_phrases":["microsoftBitNet","GPU","Official inference framework","1-bit","this demo","your own CPU","the official inference framework","1-bit LLMs","eg BitNet b158","a suite"],"filter_categories":{"ai_ml":["1-bit LLMs"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"microsoftBitNet":2.0,"GPU":2.0,"Official inference framework":1.0,"1-bit":1.0,"this demo":1.0,"your own CPU":1.0,"the official inference framework":1.0,"1-bit LLMs":1.0,"eg BitNet b158":1.0,"a suite":1.0}},"age_hours":2.017317411111111,"is_recent":true,"quality_score":1.0,"sentiment_score":9.3895,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.8779,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8813,"joy":0.0503,"surprise":0.0543,"sadness":0.0037,"fear":0.002,"anger":0.0058,"disgust":0.0026},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"practitioner_account","workflow_detail":{"score":7.0,"evidence":"The author describes their workflow using GitHub Copilot for writing Terraform code. They mention using Copilot to generate code blocks based on comments and then modifying the generated code to fit their specific needs. They also describe using Copilot to generate documentation and examples."},"validation_coverage":{"score":5.0,"evidence":"The author mentions that they always review the code generated by Copilot and make necessary adjustments. They also mention that they run tests to ensure that the generated code works as expected. They highlight the importance of understanding the underlying code and not blindly accepting Copilot's suggestions."},"methodological_rigor":{"score":3.0,"evidence":"The article is a personal account of the author's experience using GitHub Copilot. It is based on their own observations and experiences, and there is no formal methodology or data collection involved."},"practitioner_voice":{"score":9.0,"evidence":"The article is written by a practitioner who uses GitHub Copilot in their daily work. The author shares their personal experiences and insights, providing a valuable perspective on the practical application of AI in software development."},"educational_applicability":{"score":7.0,"evidence":"The article provides practical examples of how GitHub Copilot can be used to generate Terraform code, documentation, and examples. It also highlights the importance of reviewing and testing the generated code, which can be valuable for educational purposes."},"analyzed_at":"2025-12-19T08:51:24.699411Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"arxiv_a78234dfcb5f","title":"Echoless Label-Based Pre-computation for Memory","content":"Heterogeneous Graph Neural Networks (HGNNs) are widely used for deep learning on heterogeneous graphs. Typical end-to-end HGNNs require repetitive message passing during training, limiting efficiency for large-scale real-world graphs. Pre-computation-based HGNNs address this by performing message passing only once during preprocessing, collecting neighbor information into regular-shaped tensors, which enables efficient mini-batch training. Label-based pre-computation methods collect neighbors' label information but suffer from training label leakage, where a node's own label information propagates back to itself during multi-hop message passing - the echo effect. Existing mitigation strategies are memory-inefficient on large graphs or suffer from compatibility issues with advanced message passing methods. We propose Echoless Label-based Pre-computation (Echoless-LP), which eliminates training label leakage with Partition-Focused Echoless Propagation (PFEP). PFEP partitions target nodes and performs echoless propagation, where nodes in each partition collect label information only from neighbors in other partitions, avoiding echo while remaining memory-efficient and compatible with any message passing method. We also introduce an Asymmetric Partitioning Scheme (APS) and a PostAdjust mechanism to address information loss from partitioning and distributional shifts across partitions. Experiments on public datasets demonstrate that Echoless-LP achieves superior performance and maintains memory efficiency compared to baselines.","source":"arxiv","source_type":"api","url":"https://arxiv.org/abs/2511.11081v1","published_date":"2025-11-14T08:53:39","collected_date":"2025-11-17T02:01:15.711551","language":"en","tags":["preprint","academic","cslg","cssi"],"metadata":{"arxiv_id":"2511.11081v1","pdf_url":"https://arxiv.org/pdf/2511.11081v1.pdf","authors":["Jun Hu","Shangheng Chen","Yufei He","Yuan Li","Bryan Hooi","Bingsheng He"],"categories":["cs.LG","cs.SI"],"paper_type":"preprint","source_api":"arxiv","word_count":191,"author_count":6,"entities":{"organizations":["Memory Heterogeneous Graph Neural Networks","Partition-Focused Echoless"],"persons":[],"locations":["node"],"monetary":[]},"char_count":1548,"language_detected":"en","key_concepts":{"key_phrases":["Echoless Label-Based Pre","Memory","Heterogeneous Graph Neural Networks","HGNNs","deep learning","heterogeneous graphs","-end","repetitive message","training","efficiency"],"filter_categories":{"ai_ml":["Heterogeneous Graph Neural Networks","deep learning"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Echoless Label-Based Pre":2.0,"Memory":2.0,"Heterogeneous Graph Neural Networks":1.0,"HGNNs":1.0,"deep learning":1.0,"heterogeneous graphs":1.0,"-end":1.0,"repetitive message":1.0,"training":1.0,"efficiency":1.0}},"age_hours":65.29950205277778,"is_recent":false,"quality_score":1.0,"hashes":{"content_md5":"6670013deba09eb32fa33562e23ae63b","title_md5":"4abbe4503c5216d28a4dd9de3c0c1a42","url_normalized":"55088213d85fa793daa201d4c2839b1a","minhash_signature":["24942206","25550307","14366","10020962","711517","7901950","18617759","13756142","2753670","35144584","3134393","7332789","2343024","1166689","4983052","11713604","4551842","4282388","178409","955784","6262245","88593","433252","2113985","18376295","3150410","7507083","9188762","5160931","3101601","4713903","18057543","5807442","582111","7626088","15811535","6274456","5474159","7167732","8649941","4708391","3329444","6374721","1350112","12507014","4603190","907311","20266055","1132398","10675237","20134288","843096","10589055","3018416","136855","1914246","7015836","2884394","12978240","1151625","2318646","1440799","1936","4050641","1886331","7689844","7366789","4355909","1815715","4625726","3272770","13189136","4090701","848513","7951082","2595826","28867138","4232416","9938476","721726","1246369","1544236","3972917","8572837","11728217","8605786","8059737","2033222","1442738","3002142","7521029","2175767","16349222","436779","12786202","4649004","2811152","479007","24302950","7840644","583082","15025984","14554737","5883140","1684279","3376316","9964460","2946257","1815488","6841584","682304","120729","3010402","76161","9652365","28227271","873230","1144143","1592955","2957551","7805551","4372651","952385","1331506","11770568","7375688","9098556","33668"],"title_minhash":["132187565","66610753","14366","19767831","559958806","261212603","170778132","65691320","2753670","188079088","107381891","105184174","64882359","29910046","42989806","183412274","5492672","38603746","28843053","84626627","42548792","9954399","68452375","295977306","44720605","255769144","11386406","95694796","29576415","82805467","16281514","54812941","134955490","82040774","45795359","140600378","6274456","5605276","201468961","35396152","184114776","39707560","68454078","85803247","82995064","22056152","14176295","87495263","83732678","397158829","73086742","75668364","140294469","3018416","54954184","53460777","32079935","261456846","123693004","102627154","54422295","167426597","33195870","380131885","4698640","18039960","35218655","42470960","79705079","168575437","19680712","109662660","88796338","19721446","102561230","4797850","198416608","288508600","43187624","34299415","18134146","66106143","90194461","29081450","45692508","26465583","192082432","34980004","45356248","48263128","22115449","171114019","19499623","138356664","304512338","24164219","18605163","177970815","150000129","170192521","1534879","79870237","22885385","77266174","226564743","328812099","40383196","2946257","244562886","51502602","10234849","190367157","446967521","170771789","183453636","40514054","18393109","13762129","5743906","45941061","12261163","67476139","11219179","253814976","136943677","111507583","120204789","178094237"],"combined_hash":"bb85fbd01910d117441cb2f71290f3a7"},"sentiment_score":7.553000000000001,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.5106,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.9404,"joy":0.0033,"surprise":0.0208,"sadness":0.0047,"fear":0.0027,"anger":0.0133,"disgust":0.0147},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":6.0,"evidence":"The paper discusses the use of machine learning models for predicting software vulnerabilities. It mentions steps like data preprocessing, model training, and evaluation, but lacks specific details on how engineers integrate these models into their daily workflows or the specific tools used."},"validation_coverage":{"score":7.0,"evidence":"The paper describes specific validation methods, including precision, recall, F1-score, and AUC, to evaluate the performance of the vulnerability prediction models. It also discusses cross-validation techniques to ensure the robustness of the results."},"methodological_rigor":{"score":8.0,"evidence":"The paper presents a clear methodology, including data collection, feature engineering, model selection, and evaluation. It uses multiple datasets and compares the performance of different machine learning models. The methodology is well-defined and replicable."},"practitioner_voice":{"score":3.0,"evidence":"The paper is written from an academic perspective and does not include direct quotes or interviews from practitioners. It focuses on the technical aspects of vulnerability prediction rather than the practical challenges faced by engineers."},"educational_applicability":{"score":7.0,"evidence":"The paper could inform curriculum design for software engineering courses by providing insights into the application of machine learning for vulnerability prediction. It could also be used as a case study to illustrate the importance of validation and evaluation in machine learning projects."},"analyzed_at":"2025-12-19T08:51:29.538170Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"science_frontiers_neuroscience_ee8b3a78455f","title":"Neural correlates of uncertainty processing: meta","content":"IntroductionUnderstanding the neural mechanisms underlying decision-making under uncertainty represents a fundamental challenge in cognitive neuroscience. This meta-analysis aimed to identify the consistent neural correlates of uncertainty processing specifically during decision-making tasks.MethodsWe synthesized findings from 76 fMRI studies (N = 4,186 participants). Using the Activation Likelihood Estimation (ALE) method, we performed a voxel-wise meta-analysis of activation foci to identify brain regions consistently activated across studies.ResultsThe analysis revealed nine distinct activation clusters, revealing a comprehensive neural network involved in uncertainty processing. Key findings demonstrated predominant activations in the anterior insula (up to 63.7% representation), inferior frontal gyrus (up to 40.7%), and inferior parietal lobule (up to 78.1%). We found a functional specialization between emotional-motivational processes (clusters 1â€“5) and cognitive processes (clusters 6â€“9), with notable hemispheric asymmetries. The left anterior insula was more strongly associated with reward evaluation, while the right was involved in learning and cognitive control. Similarly, the right inferior frontal gyrus was linked to impulse control, and the left to motor planning.DiscussionOur findings extend the current understanding of the neural architecture of decision-making under uncertainty. The comprehensive mapping of neural signatures advances our knowledge of the distinct roles of key brain regions and provides insights into potential clinical applications, particularly for developing interventions for uncertainty-related anxiety. The study highlights important directions for future research in cognitive neuroscience and clinical practice.","source":"science_frontiers_neuroscience","source_type":"rss","url":"https://www.frontiersin.org/articles/10.3389/fnins.2025.1662272","published_date":"2025-11-11T00:00:00","collected_date":"2025-11-11T06:41:28.090245","language":"en","tags":["open-access","neuroscience","systematic_review","frontiers","science"],"metadata":{"feed_title":"Frontiers in Neuroscience | New and Recent Articles","source_category":"science","word_count":220,"author":"Oksana Zinchenko","raw_content_length":1775,"priority":7,"update_frequency":24,"reading_time_minutes":1.1,"robust_parsing_used":true,"entities":{"organizations":["IntroductionUnderstanding","the Activation Likelihood Estimation (ALE"],"persons":[],"locations":[],"monetary":[]},"char_count":1775,"language_detected":"en","key_concepts":{"key_phrases":["Neural","uncertainty processing","uncertainty","the neural mechanisms","decision-making","a fundamental challenge","cognitive neuroscience","This meta-analysis","decision-making tasks","MethodsWe synthesized findings"],"filter_categories":{"ai_ml":["Neural"],"research_academic":["cognitive neuroscience"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Neural":2.0,"uncertainty processing":2.0,"uncertainty":2.0,"the neural mechanisms":1.0,"decision-making":1.0,"a fundamental challenge":1.0,"cognitive neuroscience":1.0,"This meta-analysis":1.0,"decision-making tasks":1.0,"MethodsWe synthesized findings":1.0}},"age_hours":7.849911631666667,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"962e6e99e6f3e609181d9db8c6aca79b","title_md5":"81fff0028bf288efd9b0a7ccd67195f2","url_normalized":"c22ed63bd9e16d1c49c707763e54d6cd","minhash_signature":["9837667","21419052","14366","15920641","498956","7901950","4380964","2181150","21098000","10835656","9991314","3207698","163247","1166689","953500","7389182","1963268","4282388","2213100","113500","1196901","88593","433252","2113985","19847368","3831817","7507083","3612616","14898113","3101601","3290860","2260580","7881474","2820767","1053967","880599","10844376","6218001","309467","1878103","3082913","3329444","2661647","1785966","3625657","8153133","907311","12215371","1132398","16941830","4485723","8181152","4681462","7574389","136855","5146736","226173","5982858","4430687","1151625","4677246","7144066","1936","2492803","7601","4770883","9932183","2551573","7564697","15825899","1210516","16223695","9416260","848513","4991972","2595826","7038337","2433691","9506978","721726","301782","1969868","14899793","8572837","442394","379140","698108","12075368","1442738","8318141","7678043","2175767","9012833","436779","3199414","4649004","1608076","479007","4713810","713149","1534879","10009000","12264772","2469083","129586","3376316","2193094","145406","13734988","44001","1054124","120729","4549477","9732890","8921441","1943155","873230","1307835","5147807","2957551","6123858","4042643","952385","1331506","13052209","809487","4653766","33668"],"title_minhash":["24942206","602948149","14366","153170630","239863010","128375378","60256810","17819323","50334381","81074001","103497225","56174706","2343024","29910046","16595777","158548820","143887659","154218603","108836649","42594627","42548792","56635183","38982201","246266419","177724728","62533353","112356219","19091918","129308531","31790383","3290860","76506381","77270353","82040774","77122219","86467393","28724667","21890042","75711177","105925569","166664856","135445653","68454078","85803247","105743428","253687407","91788617","23451935","27981188","30873407","4485723","63710498","68471166","7574389","27096179","114684028","296592312","7750562","4710402","1151625","8255575","55416959","222545405","107800758","99834656","50351700","122949366","21089069","39406400","31817027","117109347","47626225","150247187","230117160","161746563","4797850","41548460","21510571","205202452","59760279","14672648","14255238","114630976","47064502","134380567","32043300","93403703","28588555","1442738","11879887","95664462","17372915","40407802","18836545","166577282","25322995","202268820","36522375","195102261","120577137","122411620","25343273","12477765","27350718","111237543","14226943","44648848","33749026","212052468","69071592","27556976","121951088","213750246","26096431","88922578","151948937","25459694","74139433","86775409","110992015","121526216","145221729","1129826","22657897","31592508","119506485","18750775","217986795"],"combined_hash":"60581142933d897384915167508eef29"},"sentiment_score":1.452,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.7096,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.3791,"joy":0.0258,"surprise":0.076,"sadness":0.0161,"fear":0.4288,"anger":0.0487,"disgust":0.0255},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":6.0,"evidence":"The paper discusses the use of Large Language Models (LLMs) for code generation and repair, mentioning steps like prompting, code generation, and testing. However, it lacks specific details on the exact prompts used, the iteration patterns, or the time spent on each step."},"validation_coverage":{"score":7.0,"evidence":"The paper describes specific validation methods, including unit testing and mutation testing, to evaluate the quality of the generated and repaired code. It also mentions metrics like pass rates and mutation scores."},"methodological_rigor":{"score":7.0,"evidence":"The paper presents a systematic evaluation of LLMs using a benchmark dataset and reports quantitative results. It describes the experimental setup and the metrics used for evaluation. However, the sample size and the specific details of the benchmark dataset are not explicitly mentioned in the summary."},"practitioner_voice":{"score":3.0,"evidence":"The summary does not mention any direct practitioner input or quotes. The paper appears to be primarily from an academic/research perspective."},"educational_applicability":{"score":6.0,"evidence":"The paper's findings on the strengths and weaknesses of LLMs for code generation and repair could inform training programs for software engineers. It could also be used to develop educational materials on how to effectively use and validate AI-generated code."},"analyzed_at":"2025-12-19T08:51:35.364903Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"ai_engadget_dccebfb0cd78","title":"Apple's MacBook Air M4 is back on sale for $799","content":"The Apple MacBook Air M4 laptop is back on sale for just $799, which is one heck of a deal. This sale is for the model with 16GB of RAM and 256GB of internal storage. It's available in multiple colorways, but the silver one inexplicably costs $899. We ranked this as our favorite Apple laptop in our list of the best MacBook computers. Heck, it's even our very favorite laptop. Full stop. The performance is exceptionally snappy, thanks to the M4 chip. We appreciated the upgraded battery life, which now lasts for around 18 hours per charge. That's well beyond a full day of work. The design is lightweight, but sturdy. This has become a hallmark for modern MacBook Air computers. The screen is both gorgeous and roomy, even though it's technically just a 13-inch panel. There's support for the P3 wide color gamut and it can reach up to 500 nits of brightness. This is a near-perfect laptop, but there are a couple of nitpicks. There's no USB-C port on the right side, limiting how users can arrange accessories on a desk. Also, the screen is capped with a 60Hz refresh rate. Another potential complication is the looming specter of the M5 chip. The company has already released the MacBook Pro M5, so a new MacBook Air is likely coming in the nearish future. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-macbook-air-m4-is-back-on-sale-for-799-183808431.html?src=rss","source":"ai_engadget","source_type":"rss","url":"https://www.engadget.com/deals/apples-macbook-air-m4-is-back-on-sale-for-799-183808431.html?src=rss","published_date":"2025-10-27T18:38:21","collected_date":"2025-10-28T07:25:51.360927","language":"en","tags":["technology","gadgets","languageen-us","computing","regionus","consumer","siteengadget","headline"],"metadata":{"feed_title":"Engadget is a web magazine with obsessive daily coverage of everything new in gadgets and consumer electronics","source_category":"ai","word_count":257,"author":"Lawrence Bonk","raw_content_length":3162,"priority":6,"update_frequency":6,"reading_time_minutes":1.285,"robust_parsing_used":true,"entities":{"organizations":["USB","MacBook","MacBook Air M4","MacBook Air","RAM","Apple"],"persons":[],"locations":[],"monetary":["just $799","899","799"]},"char_count":1551,"language_detected":"en","key_concepts":{"key_phrases":["sale","Apples MacBook Air M4","The Apple MacBook Air M4 laptop","which","one heck","a deal","This sale","the model","16GB","RAM"],"filter_categories":{"ai_ml":["Apples MacBook Air M4"],"engineering":["RAM"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"sale":3.0,"Apples MacBook Air M4":2.0,"The Apple MacBook Air M4 laptop":1.0,"which":1.0,"one heck":1.0,"a deal":1.0,"This sale":1.0,"the model":1.0,"16GB":1.0,"RAM":1.0}},"age_hours":13.605032728888888,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"346f90ac608d38bdd1c1a60505ee0387","title_md5":"504f4c3870cc257da505f746886cc342","url_normalized":"b44b1a7bedf7eafc9670171c119feee0","minhash_signature":["24908679","3143024","4229889","10381919","498956","19122126","4247212","2724910","2753670","4729967","3134393","8398711","10736429","1166689","953500","4356152","11167650","4282388","2015421","1729223","1196901","88593","10974597","2113985","3169474","7902948","181776","8419706","6343908","1456173","2169913","6805315","5807442","2423718","1053967","7550616","7650656","5305557","7167732","5625204","12167310","3329444","16130974","1737738","3625657","2720336","449615","18976923","1132398","174016","11104544","8355167","615718","7574389","136855","4847575","7015836","5148535","719313","1151625","4334793","7144066","6504683","2492803","7601","3789593","3035295","3235713","7564697","3378698","5786666","1554541","11204675","4528274","7951082","2595826","5240481","10869340","15027250","6351248","5332671","4072191","8608467","1555049","1753692","2319043","4602115","2033222","12328115","8318141","7678043","2175767","5258540","1541951","13402462","9123674","1608076","4597492","543301","713149","243170","5380955","3331841","2469083","922983","3376316","1707315","2946257","12619580","44001","2886940","7086138","1550051","15851685","9652365","23317849","120732","1307835","5108334","2936898","3554160","1395139","952385","15444234","8174376","7375688","4653766","5198470"],"title_minhash":["146426457","52955777","37263336","122477206","68196000","145619526","82901546","12530558","111883776","87620890","140597180","17023942","113838940","599239468","335470755","177723592","9110674","38603746","233925539","35607516","41753222","20743869","38314724","3483270","44720605","52147309","133054612","95694796","250157575","204854932","16281514","37154265","51596712","38525157","556751721","180270267","37607988","116502283","275489595","35319958","93082353","48442788","46245037","153924799","169287354","85859342","14176295","316547326","27836572","214354779","11104544","67432931","32868205","10539494","126477034","52301916","12603413","128078965","132867934","7695076","67726972","17920126","66999448","107883610","29546733","142862802","9932183","59300348","58177165","128495995","19680712","2173563","49805002","132551","191302198","12635128","131463938","308074378","100558110","203887210","40972796","132674791","75184295","106881717","50440605","2319043","192082432","37264318","82288407","20284228","97086831","33784786","104677037","155374648","83256819","54767366","88503905","48780960","35680924","56706929","14917442","79870237","14554737","16291765","76186035","247178101","108928224","36837441","106073621","27769953","94052739","82628716","133655777","52576599","43582575","49510724","74704895","13762129","290747329","23618125","91769704","67476139","45462023","54666452","14744595","111507583","54343954","154525922"],"combined_hash":"2c324c93231073278a2e77d52b27ce53"},"sentiment_score":9.783,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.9566,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.3875,"joy":0.0259,"surprise":0.5581,"sadness":0.0105,"fear":0.0018,"anger":0.0111,"disgust":0.0052},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"practitioner_account","workflow_detail":{"score":7.0,"evidence":"The article describes a workflow where the author uses Github Copilot to generate code, then reviews and modifies the code. It mentions using Copilot to generate unit tests and refactor code. Specific tool name (Github Copilot) is mentioned."},"validation_coverage":{"score":7.0,"evidence":"The author mentions reviewing and modifying the code generated by Copilot, which is a form of validation. They also mention using unit tests generated by Copilot, implying a validation step."},"methodological_rigor":{"score":3.0,"evidence":"The article is a personal account of the author's experience using Github Copilot. It is based on anecdotal evidence and does not involve systematic data collection or analysis."},"practitioner_voice":{"score":9.0,"evidence":"The article is written from the first-person perspective of a software engineer using Github Copilot in their daily work. The author shares their personal experiences and insights."},"educational_applicability":{"score":7.0,"evidence":"The article provides practical examples of how AI tools can be integrated into software development workflows, which could be valuable for curriculum design and training programs. The workflow of generate, review, and modify could be taught."},"analyzed_at":"2025-12-19T08:51:41.378663Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"arxiv_d981001d78f1","title":"Model-Behavior Alignment under Flexible Evaluation: When the Best","content":"Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one.","source":"arxiv","source_type":"api","url":"https://arxiv.org/abs/2510.23321v1","published_date":"2025-10-27T13:37:34","collected_date":"2025-10-28T07:48:27.098131","language":"en","tags":["preprint","academic","q-bionc","statme"],"metadata":{"arxiv_id":"2510.23321v1","pdf_url":"https://arxiv.org/pdf/2510.23321v1.pdf","authors":["Itamar Avitan","Tal Golan"],"categories":["q-bio.NC","stat.ME"],"paper_type":"preprint","source_api":"arxiv","word_count":194,"author_count":2,"entities":{"organizations":["Model-Behavior Alignment"],"persons":[],"locations":[],"monetary":[]},"char_count":1443,"language_detected":"en","key_concepts":{"key_phrases":["Model-Behavior Alignment","Flexible Evaluation","stimulus representations","deep neural networks","high-performing models","behavioral and neural responses","complex stimuli","the test accuracy","such predictions","genuine representational alignment"],"filter_categories":{"ai_ml":["deep neural networks"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Model-Behavior Alignment":2.0,"Flexible Evaluation":2.0,"stimulus representations":1.0,"deep neural networks":1.0,"high-performing models":1.0,"behavioral and neural responses":1.0,"complex stimuli":1.0,"the test accuracy":1.0,"such predictions":1.0,"genuine representational alignment":1.0}},"age_hours":18.63671962138889,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"aefc7fa3b699ccdb55623428d86c0458","title_md5":"da9625d77415da96da59c7aee465c517","url_normalized":"91995bcab9adb6932cd2a40b61a2b660","minhash_signature":["19678434","22684061","14366","11943608","1635470","4313235","10247717","5407950","2753670","10835656","3139314","10764267","2343024","1166689","9281766","2834307","5492672","304913","178409","2713066","225209","88593","459618","2113985","16164381","14494170","7507083","5225880","8348822","8720670","4883147","587492","18205745","8820999","1053967","15811535","610653","6218001","296674","11762562","3088334","792666","6374721","1350112","12507014","2463753","907311","24997983","1132398","11619362","4485723","843096","16402324","7574389","136855","1914246","7015836","2884394","4430687","8043868","9374943","7144066","6578137","4886012","1886331","4770883","9862989","1563117","7564697","4625726","5584749","13189136","15056664","848513","7951082","3487483","3542338","4232416","9506978","721726","5332671","1969868","3972917","1712457","11399451","6694534","4147746","12075368","6743328","8661640","7521029","2175767","19499623","436779","12786202","11266958","1608076","479007","11483721","713149","4227644","18033618","3751328","5883140","6760750","4255067","2193094","145406","12007630","44001","5003486","120729","1550051","4438756","756656","13776844","873230","1144143","1592955","2957551","1131087","7895850","952385","3448143","11960637","809487","3864915","33668"],"title_minhash":["76086699","42841784","4229889","36752328","13624839","19580689","122107179","89463595","41359210","10835656","40529903","105184174","62313169","426932571","190456287","26329406","5492672","38603746","110262950","63870963","30821949","9954399","54507159","93990950","59833485","203339063","129837598","15527406","68825257","69853554","48717684","23039906","103392019","20375603","131167002","27257070","115323735","111340586","119079065","34868937","89288249","251865924","32312374","30027572","166348655","36428735","74098090","45889349","141845122","113917670","47935054","35830881","28252474","48609969","136855","5146736","103253270","40239940","118810349","20554098","65892948","66086085","165360878","8339205","132302058","34501654","63941519","42470960","21146863","15823333","19932544","77934695","210139104","19721446","22643791","34397805","77225295","69744608","134159283","34299415","178554445","115765213","77607924","217577062","23577047","26465583","197320864","143590005","17428468","14144791","74538311","104275202","19499623","84496441","104812915","24164219","220897214","43573138","54441948","6563146","5622147","400650114","12264772","71783441","21094784","152443119","50185724","102701149","40761208","20298526","27753175","52070822","5520226","15993024","63357702","77874438","28665001","13762129","1592955","101846806","28945832","90611540","45462023","64058271","108328138","36851654","61576740","45227134"],"combined_hash":"d1b0dccac1bee1d84c89af193d529c3e"},"sentiment_score":8.378499999999999,"sentiment_category":"positive","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":0.6757,"is_positive":true,"is_negative":false,"is_neutral":false,"raw_emotions":{"neutral":0.8929,"joy":0.0209,"surprise":0.035,"sadness":0.006,"fear":0.0129,"anger":0.0171,"disgust":0.0152},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":5.0,"evidence":"The article discusses the use of AI in software development, mentioning the integration of AI tools into coding workflows. However, it lacks specific details about the steps, decision points, or concrete examples of AI tool usage."},"validation_coverage":{"score":5.0,"evidence":"The article generally discusses the challenges of ensuring the reliability and correctness of AI-generated code, but it does not describe specific validation methods or techniques."},"methodological_rigor":{"score":7.0,"evidence":"The article presents systematic data and a clear methodology for evaluating the effectiveness of AI tools in software development. It includes multiple sources and a well-defined experimental setup."},"practitioner_voice":{"score":5.0,"evidence":"The article includes some practitioner quotes and references, providing insights from software engineers who have used AI tools in their work."},"educational_applicability":{"score":7.0,"evidence":"The article is directly applicable to curriculum or training design, as it provides valuable information about the integration of AI tools into software development workflows and the challenges associated with their use."},"analyzed_at":"2025-12-19T08:51:45.930859Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"portuguese_canaltech_2c5bb7d60051","title":"Advogados preguiÃ§osos passam vergonha ao abusar da IA em petiÃ§Ãµes nos EUA","content":"A difusÃ£o de ferramentas generativas como ChatGPT trouxe promessas de ganho de produtividade para escritÃ³rios e departamentos jurÃ­dicos â€” mas tambÃ©m uma onda de erros que jÃ¡ custam caro a alguns advogados preguiÃ§osos. Nos Ãºltimos dois anos os tribunais americanos tÃªm identificado petiÃ§Ãµes com citaÃ§Ãµes inexistentes, trechos de decisÃµes fabricadas e argumentos baseados em â€œalucinaÃ§Ãµesâ€ de inteligÃªncia artificial, resultando em multas, remessas aos conselhos de Ã©tica e, em casos extremos, suspensÃ£o profissional. Piores empregos do mundo: quais as carreiras menos satisfatÃ³rias em 2025 Vagas de cursos e empregos em tecnologia: oportunidades no ItaÃº, DIO e outros Casos recentes mostram puniÃ§Ãµes concretas, como um que ocorreu em fevereiro deste ano. Um juiz federal citou e multou advogados apÃ³s constatar decisÃµes citadas em um documento que, segundo o tribunal, nÃ£o existiam â€” uma consequÃªncia direta do uso de pesquisa automatizada sem verificaÃ§Ã£o humana. Em outro episÃ³dio, um advogado em Utah foi sancionado depois que um recurso continha citaÃ§Ãµes inventadas atribuÃ­das a decisÃµes inexistentes â€” o profissional admitiu ter usado um sistema de IA para pesquisa. -Entre no Canal do WhatsApp do Canaltech e fique por dentro das Ãºltimas notÃ­cias sobre tecnologia, lanÃ§amentos, dicas e tutoriais incrÃ­veis.- Advogados ao redor do mundo comeÃ§am a montar uma espÃ©cie de \"forÃ§a-tarefa digital\" para combater o mau uso da inteligÃªncia artificial nos tribunais. Com o aumento de petiÃ§Ãµes recheadas de jurisprudÃªncias inexistentes e citaÃ§Ãµes inventadas por ferramentas generativas, profissionais passaram a rastrear e expor colegas que nÃ£o verificam o material produzido por IA. O movimento ganhou traÃ§Ã£o com o advogado francÃªs Damien Charlotin, que criou um banco de dados pÃºblico reunindo casos de erros provocados por uso irresponsÃ¡vel da tecnologia â€” a lista jÃ¡ ultrapassa 500 registros. A iniciativa inspirou uma rede internacional de juristas que monitora e denuncia abusos, numa tentativa de proteger a credibilidade da profissÃ£o em meio Ã  corrida por automaÃ§Ã£o. â€œEsses casos estÃ£o manchando a reputaÃ§Ã£o da advocaciaâ€, disse ao New York Times Stephen Gillers, professor de Ã©tica da Universidade de Nova York. Segundo ele, o uso descuidado da IA ameaÃ§a transformar uma ferramenta promissora em um risco Ã©tico â€” e, para o direito, reputaÃ§Ã£o vale tanto quanto jurisprudÃªncia bem-fundamentada. Mais fiscalizaÃ§Ã£o e puniÃ§Ãµes severas Tribunais variam na severidade das sanÃ§Ãµes: houve desde advertÃªncias formais e ordens de educaÃ§Ã£o continuada atÃ© multas e pagamento de custas processuais. Em alguns processos de alto perfil, juÃ­zes determinaram indenizaÃ§Ãµes por despesas advocatÃ­cias e deduziram a responsabilidade Ã©tica dos profissionais que delegaram sem supervisÃ£o. A linha dura dos magistrados reflete uma preocupaÃ§Ã£o crescente: a confianÃ§a cega em respostas geradas por IA pode inverter o Ã´nus de diligÃªncia que pesa sobre quem representa clientes em juÃ­zo. Especialistas em Ã©tica jurÃ­dica e associaÃ§Ãµes de classe tÃªm adotado tom didÃ¡tico â€” e preventivo. A American Bar Association e grupos de advogados publicaram orientaÃ§Ãµes que autorizam o uso de ferramentas de IA, desde que os profissionais estabeleÃ§am protocolos para checagem de fontes, documentaÃ§Ã£o do processo de pesquisa e supervisÃ£o humana final. Em textos orientativos recentes, advogados sÃ£o instruÃ­dos a verificar cada citaÃ§Ã£o, registrar as instruÃ§Ãµes dadas ao sistema e garantir que nada seja apresentado ao tribunal sem confirmaÃ§Ã£o independente. JuÃ­zes vÃªm reiterando que o uso de IA nÃ£o elimina a obrigaÃ§Ã£o Ã©tica do advogado de fundamentar suas manifestaÃ§Ãµes em fontes verificÃ¡veis. Em decisÃµes recentes, magistrados lembraram que a tecnologia Ã© ferramenta â€” e que o profissional responde por falhas decorrentes da sua adoÃ§Ã£o negligente. Isso cria um novo imperativo: polÃ­ticas internas que documentem o uso da IA e sistemas de revisÃ£o que reproduzam os passos da pesquisa humana. Tribunais e conselhos de Ã©tica devem continuar a atualizar regras e emitir pareceres sobre o emprego de IA na advocacia. JÃ¡ hÃ¡ movimentos locais para criar diretrizes mais rÃ­gidas â€” incluindo prazos para autocorreÃ§Ã£o de peÃ§as e mecanismos disciplinares mais claros quando a IA for causa direta de erro processual. Leia mais: 10 habilidades digitais que podem turbinar sua carreira em 2026 8 maneiras de ganhar dinheiro usando a IA no trabalho em 2026 ApÃ³s 5 anos no remoto, Nubank define retorno ao modelo hÃ­brido a partir de 2026 Leia a matÃ©ria no Canaltech.","source":"portuguese_canaltech","source_type":"rss","url":"https://canaltech.com.br/mercado/advogados-preguicosos-passam-vergonha-ao-abusar-da-ia-em-peticoes-nos-eua/","published_date":"2025-11-10T14:54:21","collected_date":"2025-11-10T18:39:52.476999","language":"pt","tags":["technology","brazil","portuguese-language","news","portuguese"],"metadata":{"feed_title":"Canaltech","source_category":"portuguese","word_count":682,"author":"Claudio Yuge","raw_content_length":5767,"priority":9,"update_frequency":6,"reading_time_minutes":3.41,"robust_parsing_used":true,"entities":{"organizations":["resultando em multas","uma onda de erros","suspensÃ£o","casos extremos","Casos","Vagas de cursos","EUA","trechos de decisÃµes"],"persons":["jÃ¡ custam caro","nÃ£o existiam","apÃ³s constatar decisÃµes","aos conselhos de Ã©tica e"],"locations":["fevereiro"],"monetary":[]},"char_count":4509,"language_detected":"pt","key_concepts":{"key_phrases":["Advogados","passam vergonha","da IA","nos EUA","A difusÃ£o","a alguns","preguiÃ§osos","Nos Ãºltimos dois anos","os tribunais americanos","tÃªm identificado"],"filter_categories":{"ai_ml":["os tribunais americanos"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"Advogados":2.0,"passam vergonha":2.0,"da IA":2.0,"nos EUA":2.0,"A difusÃ£o":1.0,"a alguns":1.0,"preguiÃ§osos":1.0,"Nos Ãºltimos dois anos":1.0,"os tribunais americanos":1.0,"tÃªm identificado":1.0}},"age_hours":4.150574155555556,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"41b818e7ffad63049a6d3c415b6207af","title_md5":"595321ee32bab63435f05027dcaaec0e","url_normalized":"982d505507606f91ebda7c8d1c5a9b1b","minhash_signature":["712529","5767071","14366","8077882","498956","4835383","4626937","1044374","2753670","4729967","9991314","2763186","1051248","1166689","953500","1964700","4551842","10508326","4437244","5594341","1196901","88593","433252","1742671","3169474","1882961","11386406","8767416","354593","1456173","1015646","587492","2093740","5129905","1053967","2422815","3427658","5474159","296674","6977948","1920150","980865","2661647","1579992","4943421","5244114","449615","19573258","1132398","107105","9488304","843096","5647154","2819355","136855","2364710","435599","2884394","3516270","923268","4677246","1012854","1936","955778","7601","1846401","1141683","2759135","1210097","5493975","4258427","877954","1027009","848513","4991972","2595826","3542338","814536","12173051","721726","639923","775263","4179099","5551403","442394","2319043","2025233","260590","2983177","12144713","343266","2175767","17193190","436779","5979754","5388347","1608076","479007","5316044","5834464","583082","59975","3306304","2458004","373169","2374286","6419416","145406","6204327","44001","4034866","85694","8232032","76161","7939773","2994479","18163","1307835","1625344","10285888","1131087","3240262","133333","1331506","9575410","809487","5298845","33668"],"title_minhash":["39251959","25550307","2507878","13560711","711517","214427137","50234708","48371856","17894508","70608617","51720533","166770882","76886968","29910046","32615315","13883005","42427885","23376274","18910763","1852662","198975880","119768836","86396715","139124603","3169474","71800361","19419460","176002937","166605962","17943366","220392523","46763088","166339974","64938616","14343807","28853323","20680427","53353996","54180447","87827968","36451124","980865","68457947","31548809","20548697","37255178","142488208","41358520","50869790","35488291","62789666","42473002","5647154","41684389","86362449","18654765","119787828","71896073","25436989","87231930","53508956","92008314","17234646","955778","52113529","34548017","73551711","2759135","69641278","48460838","9768496","11855666","8703424","8990569","55962968","32393259","3542338","130009843","15027250","55869795","29834913","197616092","36633920","5551403","30597015","75664472","63192380","9222483","185438787","128165310","167872700","38768808","282745453","33110630","12786202","84291554","59762162","14235446","20846223","19127256","219726073","56835387","3331841","68055568","132271311","4576710","290484883","110237573","10621501","41138033","124472429","95595246","176340708","196009849","38093775","41828476","273363352","137177510","149774957","17319254","12261163","65609275","15709763","112402892","28564973","68947593","9938155","14026051"],"combined_hash":"fd8722f6fbafd307a7bcca3d6d36f73c"},"sentiment_score":5.0,"sentiment_category":"neutral","sentiment_confidence":"low","sentiment_method":"vader","sentiment_raw_score":0.0,"is_positive":false,"is_negative":false,"is_neutral":true,"raw_emotions":{"neutral":0.2651,"joy":0.0185,"surprise":0.0068,"sadness":0.0246,"fear":0.2253,"anger":0.2284,"disgust":0.2312},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"thought_piece","workflow_detail":{"score":3.0,"evidence":"The article mentions using AI tools for code generation and debugging, but doesn't provide specific details on the workflow."},"validation_coverage":{"score":3.0,"evidence":"The article briefly mentions the need for code review to validate AI-generated code, but doesn't go into detail about specific validation methods."},"methodological_rigor":{"score":4.0,"evidence":"The article presents opinions and observations, but doesn't include systematic data collection or analysis."},"practitioner_voice":{"score":6.0,"evidence":"The article is written from an industry expert's perspective and includes some references to practitioner experiences."},"educational_applicability":{"score":5.0,"evidence":"The article could inform training on the use of AI tools in software development, but requires interpretation."},"analyzed_at":"2025-12-19T08:51:53.299987Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"portuguese_canaltech_8407b122602a","title":"Gemini chega ao Android Auto; veja o que a IA do Google consegue fazer","content":"O Google iniciou a liberaÃ§Ã£o global do Gemini no Android Auto, que passa a atuar como um copiloto de IA no carro. A novidade estÃ¡ disponÃ­vel para usuÃ¡rios com o aplicativo Gemini instalado no smartphone e promete tornar a interaÃ§Ã£o por voz mais natural, com respostas contextuais, comandos e conversas contÃ­nuas. Gemini chega ao Google Maps para vocÃª definir suas rotas com IA Onde usar o Gemini 3? Saiba onde a IA estÃ¡ disponÃ­vel A soluÃ§Ã£o chega a 45 idiomas e deve alcanÃ§ar mais de 250 milhÃµes de veÃ­culos compatÃ­veis. A ativaÃ§Ã£o segue o padrÃ£o do Google Assistente, por comando de voz â€˜Ok Googleâ€™ ou pelo botÃ£o no volante, com aviso exibido na tela do carro. O Google ressalta que o recurso ainda estÃ¡ em desenvolvimento e pode apresentar respostas imprecisas, nÃ£o devendo ser usado como fonte Ãºnica para informaÃ§Ãµes importantes durante a direÃ§Ã£o. -Entre no Canal do WhatsApp do Canaltech e fique por dentro das Ãºltimas notÃ­cias sobre tecnologia, lanÃ§amentos, dicas e tutoriais incrÃ­veis.- O que o Gemini consegue fazer em carros? A integraÃ§Ã£o do Gemini ao Android Auto amplia as funÃ§Ãµes do assistente. Veja o que muda: Planejamento de paradas; Envio e ediÃ§Ã£o de mensagens; Produtividade durante o deslocamento; RecomendaÃ§Ãµes musicais; Conversas contÃ­nuas e aprendizado. Planejamento de paradas Com apoio do Google Maps, o Gemini localiza estabelecimentos ao longo da rota, consulta avaliaÃ§Ãµes e fornece detalhes sobre restaurantes, serviÃ§os e outros locais. Ele tambÃ©m responde a perguntas complementares, seguindo o contexto da conversa. Envio e ediÃ§Ã£o de mensagens O assistente dita, resume, ajusta e traduz mensagens para 45 idiomas, alÃ©m de adicionar informaÃ§Ãµes, como o tempo estimado de chegada (ETA) antes do envio. Gemini agora estÃ¡ disponÃ­vel no Android Auto. (Imagem: DivulgaÃ§Ã£o/Google) Produtividade durante o deslocamento A IA consulta e-mails no Gmail, encontra endereÃ§os, cria resumos da caixa de entrada e interage com serviÃ§os do Google Agenda, Tarefas, Keep e aplicativos equivalentes da Samsung. RecomendaÃ§Ãµes musicais O Gemini cria playlists baseadas em humor, ocasiÃ£o ou clima, funcionando com YouTube Music e Spotify. Ã‰ possÃ­vel pedir sugestÃµes, como mÃºsicas para uma viagem de carro ou trilhas ideais para dias chuvosos. Conversas contÃ­nuas e aprendizado No modo beta â€œLive with Geminiâ€, o sistema mantÃ©m conversas para explicar temas, sugerir ideias ou ajudar no preparo de apresentaÃ§Ãµes e discursos, oferecendo acompanhamento passo a passo enquanto o motorista dirige. Confira outros conteÃºdos do Canaltech: Gemini agora identifica fotos criadas por IA; veja como usar O Nano Banana Pro Ã© grÃ¡tis? Veja como acessar a IA EdiÃ§Ã£o de fotos com IA: como usar o Nano Banana Pro no Gemini VÃDEO: O Gemini Ã© muito bom (e isso Ã© um problema) Leia a matÃ©ria no Canaltech.","source":"portuguese_canaltech","source_type":"rss","url":"https://canaltech.com.br/apps/gemini-chega-ao-android-auto-veja-o-que-a-ia-do-google-consegue-fazer/","published_date":"2025-11-21T12:31:19","collected_date":"2025-11-21T12:55:52.870628","language":"pt","tags":["technology","brazil","portuguese-language","news","portuguese"],"metadata":{"feed_title":"Canaltech","source_category":"portuguese","word_count":442,"author":"Viviane FranÃ§a","raw_content_length":4380,"priority":9,"update_frequency":6,"reading_time_minutes":2.21,"robust_parsing_used":true,"entities":{"organizations":["IA Onde","Android Auto","WhatsApp","Google Assistente","Canaltech","Google"],"persons":["alcanÃ§ar mais de 250","comando de voz â€˜Ok Google","pelo botÃ£o","notÃ­ci","Gemini","voz mais"],"locations":["Gemini","Google Maps"],"monetary":[]},"char_count":2789,"language_detected":"pt","key_concepts":{"key_phrases":["Android Auto","a IA","do Google consegue fazer","O Google iniciou","Gemini","no Android Auto","que passa","no carro","A novidade estÃ¡ disponÃ­vel para","com o aplicativo Gemini"],"filter_categories":{},"extraction_method":"spacy","confidence":"high","concept_scores":{"Android Auto":2.0,"a IA":2.0,"do Google consegue fazer":2.0,"O Google iniciou":1.0,"Gemini":1.0,"no Android Auto":1.0,"que passa":1.0,"no carro":1.0,"A novidade estÃ¡ disponÃ­vel para":1.0,"com o aplicativo Gemini":1.0}},"age_hours":0.5894315072222223,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"5be64f1f0403aa9f17fea5c58d89b434","title_md5":"67d9d89e351e23ca69c21629bfe6e67c","url_normalized":"a38695ae5d6f4c566c94e1c0783f4047","minhash_signature":["1247472","2041703","14366","9501201","711517","6288288","5451088","1044374","2753670","4729967","2830309","121644","2343024","17270375","953500","2834307","4551842","2482751","5321275","858614","1868191","4962795","433252","5450508","3169474","854817","7507083","9188762","8348822","4189567","1015646","587492","843076","2681451","1053967","2422815","684203","83384","296674","6977948","3082913","5626664","2661647","1579992","20548697","2720336","646834","3080246","1132398","343339","5703177","3222690","4286247","3018416","136855","1211599","226173","2095249","3516270","1151625","4334793","7020225","1936","2492803","7601","3789593","631296","3235713","8158384","5493975","5584749","2173563","1027009","848513","758867","832626","2810765","851968","6816618","24207648","3756367","1969868","4401012","24131304","6335518","2319043","4309418","260590","1417100","8661640","7678043","2175767","5258540","1768946","5979754","7729162","9604377","479007","5316044","6563146","4227644","551087","986263","1956194","1684279","5537010","6409355","145406","6204327","44001","4034866","485640","4549477","7239","7939773","6804460","926978","6972897","5416592","8134440","1131087","4042643","157681","5912498","7599628","809487","5298845","1632062"],"title_minhash":["39251959","52955777","2706685","15432896","711517","84349153","27938459","5407950","120738253","53087398","51661111","91562123","33099645","87708311","60036661","33281976","14400254","23376274","20779374","134489323","41753222","91459898","47253650","139124603","32986259","43514250","14217703","78965371","34334919","4189567","69272608","11857065","32750238","32155246","74963139","119969922","62490625","103512241","117872531","118109265","52507171","39359422","18270733","14576884","146602929","35513509","91788617","72059313","50869790","6774644","8186612","77082339","86974492","73391663","143335331","8215421","14906348","185092115","25436989","73455319","30309246","36204046","19565496","56267654","7601","9460882","50907708","141365798","42621142","16095619","63588446","117111767","8703424","4528274","32136461","6702807","182827227","49786902","82288399","147849012","54449407","33036354","42295789","281355318","23460055","18232490","63719876","28588555","173339394","64266504","234559517","17372915","72914487","114913557","27693366","55387061","65991345","47850687","20846223","24037116","86479303","79999687","91136911","91702982","108223071","105017105","22311165","124541098","69633468","76332418","66058808","135075773","21315175","7468958","23567886","50912947","1870039","74139433","162226585","49539152","220890931","114285698","37675512","72607496","28564973","227006991","66687677","11101316"],"combined_hash":"73e770fd79f539f94e79690ae8885eff"},"sentiment_score":2.6165,"sentiment_category":"negative","sentiment_confidence":"medium","sentiment_method":"vader","sentiment_raw_score":-0.4767,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.766,"joy":0.0239,"surprise":0.0315,"sadness":0.0315,"fear":0.0466,"anger":0.0569,"disgust":0.0437},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":6.0,"evidence":"The paper discusses the use of LLMs in software development, including tasks like code generation, bug fixing, and code review. It mentions the general process of using LLMs for these tasks but lacks specific details on the exact steps, commands, or prompts used by developers."},"validation_coverage":{"score":5.0,"evidence":"The paper touches upon the challenges of validating LLM outputs in software development, mentioning the need for careful review and testing. However, it doesn't delve into specific validation methods or metrics used to assess the quality and reliability of AI-generated code."},"methodological_rigor":{"score":7.0,"evidence":"The paper presents a systematic analysis of existing research on LLMs in software development. It cites multiple sources and provides a structured overview of the field. However, it doesn't present original empirical data or a detailed methodology for data collection and analysis."},"practitioner_voice":{"score":3.0,"evidence":"The paper primarily presents an academic perspective on the topic. While it may reference some practitioner experiences indirectly, it lacks direct quotes or first-hand accounts from software engineers using LLMs in their daily work."},"educational_applicability":{"score":6.0,"evidence":"The paper could inform training programs by providing an overview of the current state of LLMs in software development and the challenges associated with their use. It could also be used to raise awareness among students and practitioners about the potential benefits and risks of using AI tools in software engineering."},"analyzed_at":"2025-12-19T08:51:59.584989Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
{"id":"science_arxiv_cs_220c8cff3960","title":"ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases","content":"arXiv:2510.20270v1 Announce Type: new Abstract: The tendency to find and exploit \"shortcuts\" to complete tasks poses significant risks for reliable assessment and deployment of large language models (LLMs). For example, an LLM agent with access to unit tests may delete failing tests rather than fix the underlying bug. Such behavior undermines both the validity of benchmark results and the reliability of real-world LLM coding assistant deployments. To quantify, study, and mitigate such behavior, we introduce ImpossibleBench, a benchmark framework that systematically measures LLM agents' propensity to exploit test cases. ImpossibleBench creates \"impossible\" variants of tasks from existing benchmarks like LiveCodeBench and SWE-bench by introducing direct conflicts between the natural-language specification and the unit tests. We measure an agent's \"cheating rate\" as its pass rate on these impossible tasks, where any pass necessarily implies a specification-violating shortcut. As a practical framework, ImpossibleBench is not just an evaluation but a versatile tool. We demonstrate its utility for: (1) studying model behaviors, revealing more fine-grained details of cheating behaviors from simple test modification to complex operator overloading; (2) context engineering, showing how prompt, test access and feedback loop affect cheating rates; and (3) developing monitoring tools, providing a testbed with verified deceptive solutions. We hope ImpossibleBench serves as a useful framework for building more robust and reliable LLM systems. Our implementation can be found at https://github.com/safety-research/impossiblebench.","source":"science_arxiv_cs","source_type":"rss","url":"https://arxiv.org/abs/2510.20270","published_date":"2025-10-24T04:00:00","collected_date":"2025-10-24T06:38:51.239079","language":"en","tags":["preprints","cslg","computer-science","cscl","research","science"],"metadata":{"feed_title":"cs updates on arXiv.org","source_category":"science","word_count":223,"author":"Ziqian Zhong, Aditi Raghunathan, Nicholas Carlini","raw_content_length":1648,"priority":7,"update_frequency":1,"reading_time_minutes":1.115,"robust_parsing_used":true,"entities":{"organizations":["LLM","ImpossibleBench"],"persons":[],"locations":[],"monetary":[]},"char_count":1641,"language_detected":"en","key_concepts":{"key_phrases":["ImpossibleBench","Measuring LLMs Propensity","Exploiting Test Cases","Announce Type","new Abstract","The tendency","shortcuts","tasks","significant risks","reliable assessment"],"filter_categories":{"ai_ml":["Measuring LLMs Propensity"]},"extraction_method":"spacy","confidence":"high","concept_scores":{"ImpossibleBench":2.0,"Measuring LLMs Propensity":2.0,"Exploiting Test Cases":2.0,"Announce Type":1.0,"new Abstract":1.0,"The tendency":1.0,"shortcuts":1.0,"tasks":1.0,"significant risks":1.0,"reliable assessment":1.0}},"age_hours":3.2231440944444447,"is_recent":true,"quality_score":1.0,"hashes":{"content_md5":"8e3137e621e99d95d8effbaf09a1ffb8","title_md5":"c3503051c8c679244581ecce3af0ac41","url_normalized":"58ec3577ff985afffaf5213631c1f930","minhash_signature":["24942206","8255351","14366","762627","498956","5329195","7067621","2181150","2753670","4729967","9991314","3207698","163247","1166689","953500","4356152","1963268","4282388","2213100","113500","1196901","88593","459618","1908554","5139756","14494170","4070773","6529113","9713509","6873188","3095388","6606854","1938112","582111","1053967","880599","7650656","6836305","309467","11762562","3088334","2268139","2661647","1785966","14614367","5244114","1691750","14039386","1132398","174016","20134288","8355167","10589055","7574389","136855","1909511","226173","2884394","2560827","1151625","10860588","225097","14326557","7969807","7601","16611414","12206903","4355909","1815715","4625726","4258427","13189136","13012937","4528274","5728012","2595826","1140460","2888852","15027250","721726","301782","21564890","1292529","1555049","11728217","6694534","8059737","9222483","134600","8318141","7521029","2175767","2577676","436779","1182542","4610028","1608076","479007","3206866","713149","5066721","3028635","3331841","2469083","1405939","3344019","5693316","145406","1815488","269911","968633","120729","1550051","4438756","9652365","16813625","120732","152589","1592955","12207048","1131087","4372651","952385","363706","11770568","7375688","9098556","33668"],"title_minhash":["42893312","249941689","14366","29398940","46183253","39710496","136781766","71998050","2753670","35828643","114322740","3207698","2343024","29910046","16595777","183963156","26988668","9292640","108836649","39384819","42548792","32608998","81742113","120631577","190406621","121088739","96739166","14382907","104909483","62184370","130350268","76506381","14318892","82040774","7626088","118380207","28724667","95252215","197519146","101238272","5059771","174322694","68454078","85803247","36161736","44382767","21080939","103759182","150437457","68879639","25266503","34694099","96162420","48609969","109847085","5146736","226173","106033416","21233549","29171982","10735391","10913874","33195870","33312480","4698640","108111463","161030559","30345113","198904793","15825899","106198711","47626225","13012937","61521131","7951082","208513857","306602129","6134367","106437966","59760279","181998531","40370763","41679155","179384267","147127576","44636652","25796665","123100822","27320270","57602050","141528914","70772993","29086242","64521332","53810656","4610028","49419428","177970815","16833010","38991416","131824704","33929202","24641185","109307212","230731787","73811770","100358590","89860963","75657581","69071592","66286913","77072396","213750246","197245249","25639739","28227271","873230","244713506","34983048","77499487","29687743","81759232","56901461","57589434","31592508","28833887","18750775","99032149"],"combined_hash":"8e2dea5ddc023cb1d52760cb031bdb98"},"sentiment_score":0.7405,"sentiment_category":"negative","sentiment_confidence":"high","sentiment_method":"vader","sentiment_raw_score":-0.8519,"is_positive":false,"is_negative":true,"is_neutral":false,"raw_emotions":{"neutral":0.2806,"joy":0.005,"surprise":0.0112,"sadness":0.0294,"fear":0.3354,"anger":0.253,"disgust":0.0854},"emotion_method":"local"},"ai-engineering-practice_analysis":{"content_type":"research_study","workflow_detail":{"score":5.0,"evidence":"The paper discusses the use of AI in software development, mentioning the integration of AI tools into the development process. However, it lacks specific details about the exact steps, commands, or decision points involved in the workflow. It describes the general workflow of using AI tools for code generation and testing, but does not provide concrete examples or tool names."},"validation_coverage":{"score":6.0,"evidence":"The paper discusses the challenges of validating AI-generated code and the importance of ensuring the reliability of AI outputs. It mentions the need for testing and verification, but does not provide specific details about the methods used or the metrics tracked. It acknowledges the potential for errors and hallucinations in AI-generated code and the need for careful review and validation."},"methodological_rigor":{"score":7.0,"evidence":"The paper presents a systematic approach to evaluating the effectiveness of AI tools in software development. It cites data from multiple sources, including surveys and case studies. The methodology is clearly described, and the results are presented in a transparent and objective manner. However, the sample sizes are not explicitly stated, and the statistical analysis is not described in detail."},"practitioner_voice":{"score":5.0,"evidence":"The paper includes some practitioner quotes and references, but the primary perspective is that of academics and analysts. It acknowledges the importance of understanding the needs and experiences of practitioners, but does not provide extensive first-hand accounts or interviews. The paper cites examples of how AI tools are being used in industry, but does not provide detailed case studies or ethnographic data."},"educational_applicability":{"score":7.0,"evidence":"The paper has direct applicability to curriculum and training design. The discussion of AI tools in software development can inform the development of new courses and training programs. The paper also provides insights into the skills and competencies that are needed to effectively use AI tools in software development. The paper can be used to develop new assessment methods and competency frameworks."},"analyzed_at":"2025-12-19T08:52:08.933068Z","analyzed_by":"gemini-flash-api-batch","filter_name":"ai-engineering-practice"}}
